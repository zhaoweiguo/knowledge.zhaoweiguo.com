

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="zh-CN" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="zh-CN" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>6.4.2. Serving &mdash; 新溪-gordon V1.7.22 文档</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="搜索" href="../../search.html" />
    <link rel="next" title="6.4.3. Models" href="Models.html" />
    <link rel="prev" title="6.4.1. 常用" href="normal.html" /> 

  
  <script src="../../_static/js/modernizr.min.js"></script>
  <script src="../../_static/js/jquery.min.js"></script>


<!-- 评论插件 gittalk start -->
<!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script> -->
<!-- 评论插件 gittalk end -->


</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> 新溪-gordon
          

          
          </a>

          
            
            
              <div class="version">
                V1.7.22
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">AI</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../normal.html">1. 常用</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../normals/normal.html">1.1. 常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../normals/AIGC.html">1.2. AIGC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../normals/ml.html">1.3. 机器学习machine learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../normals/bi.html">1.4. BI(Business Intelligence)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../normals/deep_learning.html">1.5. 深度学习</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../normals/deep_learnings/normal.html">1.5.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../normals/deep_learnings/history.html">1.5.2. 历史</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../normals/monitor.html">1.6. monitor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../normals/algorithm.html">1.7. 相关算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../normals/tool.html">1.8. 工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../normals/question.html">1.9. 常见问题</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../theory.html">2. 理论</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../theories/ReAct.html">2.1. ReAct框架</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../theories/Reflection.html">2.2. Reflection反思</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../theories/math.html">2.3. 数学</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../theories/bag-of-words.html">2.4. bag-of-words</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../theories/word2vec.html">2.5. Word2Vec</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../theories/doc2vec.html">2.6. Doc2Vec</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../theories/FastText.html">2.7. FastText</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../theories/LDA.html">2.8. LDA-Latent Dirichlet Allocation(潜在狄利克雷分配)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../theories/overfitting-underfitting.html">2.9. overfitting&amp;underfitting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../theories/evaluate.html">2.10. evaluate评估</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../theories/RAG.html">2.11. RAG</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../theories/Agent.html">2.12. Agent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../theories/LLM.html">2.13. LLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../theories/prompt_engineering.html">2.14. Prompt Engineering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../theories/finetune.html">2.15. LLM调优(finetune)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM.html">3. 大模型</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../LLMs/normal.html">3.1. 常用</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/normals/normal.html">3.1.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/normals/package.html">3.1.2. 依赖安装</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/normals/encoder.html">3.1.3. 编码-解码器</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/normals/usage.html">3.1.4. 使用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/normals/tmp.html">3.1.5. 临时</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLMs/model.html">3.2. 著名模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/models/LLaMA.html">3.2.1. LLaMA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/models/ChatGLM.html">3.2.2. ChatGLM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/models/BERT.html">3.2.3. BERT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/models/GPT.html">3.2.4. GPT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/models/BART.html">3.2.5. BART</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/models/T5.html">3.2.6. T5</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/models/ChatRWKV.html">3.2.7. ChatRWKV</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/models/Open-Assistant.html">3.2.8. Open-Assistant</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLMs/finetune.html">3.3. 调优</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../LLMs/fileformat.html">3.4. 文件格式</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/fileformats/GGML.html">3.4.1. GGML系列文件格式</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/fileformats/ONNX.html">3.4.2. ONNX</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/fileformats/ONNXs/normal.html">常用</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/fileformats/ONNXs/ONNX.html">ONNX</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/fileformats/ONNXs/onnxruntime.html">onnxruntime</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/fileformats/ONNXs/skl2onnx.html">skl2onnx</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/fileformats/NCNN.html">3.4.3. NCNN</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLMs/openai.html">3.5. 商业项目</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/openais/normal.html">3.5.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/openais/openai.html">3.5.2. OpenAI</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLMs/prompt.html">3.6. Prompt 提示词</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/prompts/demo_chinese.html">3.6.1. 中文</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/prompts/demo_english.html">3.6.2. English</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/prompts/skill.html">3.6.3. 示例</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../NLP.html">4. NLP</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../NLPs/normal.html">4.1. 常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../NLPs/preprocess.html">4.2. 预处理</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../NLPs/preprocesses/normal.html">4.2.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../NLPs/preprocesses/%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E5%8F%96.html">4.2.2. 关键词提取</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../NLPs/preprocesses/%E5%88%86%E8%AF%8D.html">4.2.3. 分词</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../NLPs/preprocesses/%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90.html">4.2.4. 情感分析</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../NLPs/preprocesses/%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA.html">4.2.5. 文本表示</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../NLPs/preprocesses/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6.html">4.2.6. 注意力机制</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../NLPs/preprocesses/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B.html">4.2.7. 语言模型</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../NLPs/NER.html">4.3. NER-命名实体识别</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../NLPs/NERs/normal.html">4.3.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../NLPs/NERs/seq-label.html">4.3.2. 序列标注</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../NLPs/NERs/BiLSTM%2BCRF.html">4.3.3. BiLSTM+CRF</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../NLPs/NERs/history.html">4.3.4. 历史</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../NLPs/summary.html">4.4. 总结-摘要</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../NLPs/summarys/normal.html">4.4.1. 通用</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../library.html">5. 函数库</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/normal.html">5.1. 常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/Image.html">5.2. Image图像处理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/Video.html">5.3. Video视频</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/IPython.html">5.4. IPython</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/IPythons/normal.html">5.4.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/IPythons/magic.html">5.4.2. 魔法命令 </a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/IPythons/display.html">5.4.3. display函数</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/Jupyter.html">5.5. Jupyter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/NumPy.html">5.6. NumPy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/NumPys/normal.html">5.6.1. 通用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/NumPys/Ndarray.html">5.6.2. Ndarray 对象</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/NumPys/function.html">5.6.3. 通用函数</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/Pandas.html">5.7. Pandas</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Pandas/normal.html">5.7.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Pandas/example_subset.html">5.7.2. 实例-subset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Pandas/example_analysis.html">5.7.3. 实例-统计分析</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Pandas/example_sql.html">5.7.4. 利用pandas实现SQL操作</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Pandas/example_default_value.html">5.7.5. 实例-缺失值的处理</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Pandas/example_multi_index.html">5.7.6. 多层索引的使用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Pandas/practice.html">5.7.7. 实践</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../libraries/Pandas/practices/practice_2012ObamaElect.html">实践-2012年奥巴马总统连任选举</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Pandas/api_input_output.html">5.7.8. API-输入输出</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Pandas/api_General.html">5.7.9. API-General functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Pandas/api_Series.html">5.7.10. API-Series</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Pandas/api_DataFrame.html">5.7.11. API-DataFrame</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Pandas/api_Index.html">5.7.12. API-index</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/Matplotlib.html">5.8. Matplotlib</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Matplotlibs/normal.html">5.8.1. 基本</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Matplotlibs/install.html">5.8.2. 安装</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Matplotlibs/pyplot.html">5.8.3. pyplot </a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Matplotlibs/matplotlib.patches.html">5.8.4. matplotlib.patches</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Matplotlibs/example.html">5.8.5. 实例</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../libraries/Matplotlibs/examples/plot.html">折线图plot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libraries/Matplotlibs/examples/bar.html">条形图bar</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libraries/Matplotlibs/examples/hist.html">直方图hist</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libraries/Matplotlibs/examples/scatter.html">散点图scatter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libraries/Matplotlibs/examples/stackplot.html">面积图stackplot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libraries/Matplotlibs/examples/pie.html">饼图pie</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libraries/Matplotlibs/examples/box.html">箱型图box</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libraries/Matplotlibs/examples/multi.html">多图合并multi</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Matplotlibs/pylab.html">5.8.6. pylab子包</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/SciPy.html">5.9. SciPy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/SciPys/normal.html">5.9.1. 常用</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/sklearn.html">5.10. sklearn</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/sklearns/normal.html">5.10.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/sklearns/supervised.html">5.10.2. 监督学习</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../libraries/sklearns/superviseds/glm.html">广义线性模型</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/sklearns/unsupervised.html">5.10.3. 无监督学习</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/statsmodels.html">5.11. statsmodels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/OpenCV.html">5.12. OpenCV</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/OpenCVs/normal.html">5.12.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/OpenCVs/example.html">5.12.2. 实例</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/OpenCVs/struct.html">5.12.3. 代码类结构</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/Seaborn.html">5.13. Seaborn</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Seaborns/normal.html">5.13.1. 常用</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/jieba.html">5.14. jieba中文分词</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/gensim.html">5.15. gensim: 文本主题建模和相似性分析</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/gensims/normal.html">5.15.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/gensims/Core_Tutorials.html">5.15.2. Core Tutorials</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/gensims/Tutorials.html">5.15.3. Tutorials: Learning Oriented Lessons</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/gensims/How-to_Guides.html">5.15.4. How-to Guides: Solve a Problem</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/LAC.html">5.16. LAC-百度词法分析工具</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../../framework.html">6. 学习框架</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../normal.html">6.1. 常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pytorch.html">6.2. PyTorch</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../pytorchs/normal.html">6.2.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../pytorchs/nn.html">6.2.2. nn模块</a></li>
<li class="toctree-l3"><a class="reference internal" href="../pytorchs/PyTorch.html">6.2.3. PyTorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../pytorchs/ExecuTorch.html">6.2.4. ExecuTorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../pytorchs/torchrun.html">6.2.5. torchrun (Elastic Launch)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../huggingface.html">6.3. huggingface</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../huggingfaces/normal.html">6.3.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../huggingfaces/huggingface_hub.html">6.3.2. Hugging Face Hub</a></li>
<li class="toctree-l3"><a class="reference internal" href="../huggingfaces/lib_python.html">6.3.3. Hub Python Library</a></li>
<li class="toctree-l3"><a class="reference internal" href="../huggingfaces/Datasets.html">6.3.4. Datasets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../huggingfaces/Transformers.html">6.3.5. Transformers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../huggingfaces/Transformers_V4.45.2.html">6.3.6. Transformers 4.45.2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../huggingfaces/Tokenizers_V0.13.3.html">6.3.7. Tokenizers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../huggingfaces/Text_Generation_Inference_main.html">6.3.8. Text Generation Inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../huggingfaces/Evaluate.html">6.3.9. Evaluate</a></li>
<li class="toctree-l3"><a class="reference internal" href="../huggingfaces/PEFT.html">6.3.10. PEFT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../huggingfaces/PEFT_V0.13.0.html">6.3.11. PEFT 0.13.0</a></li>
<li class="toctree-l3"><a class="reference internal" href="../huggingfaces/TRL.html">6.3.12. TRL - Transformer Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../huggingfaces/blog_decoding-methods.html">6.3.13. 博文: decoding methods of LLM with transformers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../huggingfaces/collect.html">6.3.14. 收集</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../huggingfaces/collects/resources.html">resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../huggingfaces/collects/model.html">model</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="../vLLM.html">6.4. vLLM</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="normal.html">6.4.1. 常用</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">6.4.2. Serving</a></li>
<li class="toctree-l3"><a class="reference internal" href="Models.html">6.4.3. Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="Usage.html">6.4.4. Usage</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../mxnet.html">6.5. mxnet库</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../mxnets/ndarray.html">6.5.1. nd模块</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../mxnets/ndarrays/ndarray.html">ndarray</a></li>
<li class="toctree-l4"><a class="reference internal" href="../mxnets/ndarrays/ndarray.random.html">ndarray.random</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../mxnets/gluon.html">6.5.2. gluon模块</a></li>
<li class="toctree-l3"><a class="reference internal" href="../mxnets/autograd.html">6.5.3. autograd模块</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../tensorflow.html">6.6. tensorflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Keras.html">6.7. Keras</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../Keras/normal.html">6.7.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Keras/demo.html">6.7.2. 实例</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Keras/demos/binary_classification.html">二分类问题</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Keras/demos/multiclass_classification.html">多分类问题</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Keras/demos/regression.html">回归问题</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../other.html">6.8. 其他</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../website.html">7. 关键网站</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../websites/Papers%20with%20Code.html">7.1. Papers with Code</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../websites/Kaggle.html">7.2. Kaggle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../websites/ArXiv.html">7.3. ArXiv 学术论文预印本平台</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../websites/video.html">7.4. 视频相关</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../websites/normal.html">7.5. 通用</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../practice.html">8. 实践</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../practices/OCR.html">8.1. OCR</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../practices/OCRs/normal.html">8.1.1. 常用</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../practices/AIML.html">8.2. AIML</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../practices/AIMLs/normal.html">8.2.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../practices/AIMLs/spec.html">8.2.2. AIML 2.1 Documentation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../opensource.html">9. 开源项目</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../opensources/Agent.html">9.1. Agent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../opensources/RAG.html">9.2. RAG</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../opensources/normal.html">9.3. 常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../opensources/ui.html">9.4. UI界面</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../opensources/finetune.html">9.5. 调优</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../opensources/search.html">9.6. 搜索</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../opensources/LLM-Inference-Engine.html">9.7. LLM Inference Engines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../opensources/LLM-Inference-Tool.html">9.8. 模型推理平台</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../opensources/LLM-inference-accelerate.html">9.9. LLM推理加速</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../opensources/Evaluate.html">9.10. LLM评估</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../opensources/platform.html">9.11. AI平台</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../dataset.html">10. 数据集</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../datasets/normal.html">10.1. 常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../datasets/chinese.html">10.2. 中文数据集</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../datasets/huggingface.html">10.3. dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../datasets/website.html">10.4. 数据集相关网站</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../Evaluate.html">11. Evaluate评测</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Evaluates/TruLens.html">11.1. TruLens</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Evaluates/Ragas.html">11.2. Ragas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Evaluates/DeepEval.html">11.3. DeepEval</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Evaluates/UpTrain.html">11.4. UpTrain</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Evaluates/huggingface.html">11.5. evaluate</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">新溪-gordon</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../framework.html"><span class="section-number">6. </span>学习框架</a> &raquo;</li>
        
          <li><a href="../vLLM.html"><span class="section-number">6.4. </span>vLLM</a> &raquo;</li>
        
      <li><span class="section-number">6.4.2. </span>Serving</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/frameworks/vLLMs/Serving.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            <nav id="local-table-of-contents" role="navigation" aria-labelledby="local-table-of-contents-title">
              <h4 id="local-table-of-contents-title">On This Page</h4>
              <ul>
<li><a class="reference internal" href="#">6.4.2. Serving</a><ul>
<li><a class="reference internal" href="#openai-compatible-server">OpenAI Compatible Server</a><ul>
<li><a class="reference internal" href="#supported-apis">Supported APIs</a></li>
<li><a class="reference internal" href="#chat-template">Chat Template</a></li>
<li><a class="reference internal" href="#cli-reference">CLI Reference</a><ul>
<li><a class="reference internal" href="#configuration-file">Configuration file</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#deploying-with-docker">Deploying with Docker</a><ul>
<li><a class="reference internal" href="#use-vllms-official-docker-image">Use vLLM’s Official Docker Image</a></li>
<li><a class="reference internal" href="#building-vllms-docker-image-from-source">Building vLLM’s Docker Image from Source</a></li>
</ul>
</li>
<li><a class="reference internal" href="#deploying-with-kubernetes">Deploying with Kubernetes</a></li>
<li><a class="reference internal" href="#distributed-inference-and-serving">Distributed Inference and Serving</a><ul>
<li><a class="reference internal" href="#how-to-decide-the-distributed-inference-strategy">How to decide the distributed inference strategy?</a></li>
<li><a class="reference internal" href="#details-for-distributed-inference-and-serving">Details for Distributed Inference and Serving</a></li>
<li><a class="reference internal" href="#multi-node-inference-and-serving">Multi-Node Inference and Serving</a></li>
</ul>
</li>
<li><a class="reference internal" href="#production-metrics">Production Metrics</a></li>
</ul>
</li>
</ul>

            </nav>
  <table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference external" href="/index.html">主页</a></p></td>
<td><p><a class="reference internal" href="../../genindex.html"><span class="std std-ref">索引</span></a></p></td>
<td><p><a class="reference internal" href="../../py-modindex.html"><span class="std std-ref">模块索引</span></a></p></td>
<td><p><a class="reference internal" href="../../search.html"><span class="std std-ref">搜索页面</span></a></p></td>
</tr>
</tbody>
</table>
<section id="serving">
<h1><span class="section-number">6.4.2. </span>Serving<a class="headerlink" href="#serving" title="此标题的永久链接">¶</a></h1>
<section id="openai-compatible-server">
<h2>OpenAI Compatible Server<a class="headerlink" href="#openai-compatible-server" title="此标题的永久链接">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">vllm</span> <span class="n">serve</span> <span class="n">NousResearch</span><span class="o">/</span><span class="n">Meta</span><span class="o">-</span><span class="n">Llama</span><span class="o">-</span><span class="mi">3</span><span class="o">-</span><span class="mi">8</span><span class="n">B</span><span class="o">-</span><span class="n">Instruct</span> <span class="o">--</span><span class="n">dtype</span> <span class="n">auto</span> <span class="o">--</span><span class="n">api</span><span class="o">-</span><span class="n">key</span> <span class="n">token</span><span class="o">-</span><span class="n">abc123</span>
</pre></div>
</div>
<p>normal format:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Hello!&quot;</span><span class="p">}</span>
</pre></div>
</div>
<section id="supported-apis">
<h3>Supported APIs<a class="headerlink" href="#supported-apis" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><dl class="simple">
<dt>OpenAI APIs:</dt><dd><ul>
<li><p>Completions API (/v1/completions)</p></li>
<li><p>Chat Completions API (/v1/chat/completions)</p></li>
<li><p>Embeddings API (/v1/embeddings)</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>custom APIs</dt><dd><ul>
<li><p>Tokenizer API (/tokenize, /detokenize)</p></li>
<li><p>Pooling API (/pooling)</p></li>
<li><p>Score API (/score)</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="chat-template">
<h3>Chat Template<a class="headerlink" href="#chat-template" title="此标题的永久链接">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">vllm</span> <span class="n">serve</span> <span class="o">&lt;</span><span class="n">model</span><span class="o">&gt;</span> <span class="o">--</span><span class="n">chat</span><span class="o">-</span><span class="n">template</span> <span class="o">./</span><span class="n">path</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">chat</span><span class="o">-</span><span class="n">template</span><span class="o">.</span><span class="n">jinja</span>
</pre></div>
</div>
<p>OpenAI spec accept a new format which specifies both a type and a text field.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="p">[{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="s2">&quot;Classify this sentiment: vLLM is wonderful!&quot;</span><span class="p">}]}</span>
</pre></div>
</div>
</section>
<section id="cli-reference">
<h3>CLI Reference<a class="headerlink" href="#cli-reference" title="此标题的永久链接">¶</a></h3>
<section id="configuration-file">
<h4>Configuration file<a class="headerlink" href="#configuration-file" title="此标题的永久链接">¶</a></h4>
<p>config.yaml:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">host</span><span class="p">:</span> <span class="s2">&quot;127.0.0.1&quot;</span>
<span class="n">port</span><span class="p">:</span> <span class="mi">6379</span>
<span class="n">uvicorn</span><span class="o">-</span><span class="n">log</span><span class="o">-</span><span class="n">level</span><span class="p">:</span> <span class="s2">&quot;info&quot;</span>
</pre></div>
</div>
<p>指定 yaml 文件:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">vllm</span> <span class="n">serve</span> <span class="n">SOME_MODEL</span> <span class="o">--</span><span class="n">config</span> <span class="n">config</span><span class="o">.</span><span class="n">yaml</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="deploying-with-docker">
<h2>Deploying with Docker<a class="headerlink" href="#deploying-with-docker" title="此标题的永久链接">¶</a></h2>
<section id="use-vllms-official-docker-image">
<h3>Use vLLM’s Official Docker Image<a class="headerlink" href="#use-vllms-official-docker-image" title="此标题的永久链接">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">docker</span> <span class="n">run</span> <span class="o">--</span><span class="n">runtime</span> <span class="n">nvidia</span> <span class="o">--</span><span class="n">gpus</span> <span class="nb">all</span> \
    <span class="o">-</span><span class="n">v</span> <span class="o">~/.</span><span class="n">cache</span><span class="o">/</span><span class="n">huggingface</span><span class="p">:</span><span class="o">/</span><span class="n">root</span><span class="o">/.</span><span class="n">cache</span><span class="o">/</span><span class="n">huggingface</span> \
    <span class="o">--</span><span class="n">env</span> <span class="s2">&quot;HUGGING_FACE_HUB_TOKEN=&lt;secret&gt;&quot;</span> \
    <span class="o">-</span><span class="n">p</span> <span class="mi">8000</span><span class="p">:</span><span class="mi">8000</span> \
    <span class="o">--</span><span class="n">ipc</span><span class="o">=</span><span class="n">host</span> \
    <span class="n">vllm</span><span class="o">/</span><span class="n">vllm</span><span class="o">-</span><span class="n">openai</span><span class="p">:</span><span class="n">latest</span> \
    <span class="o">--</span><span class="n">model</span> <span class="n">mistralai</span><span class="o">/</span><span class="n">Mistral</span><span class="o">-</span><span class="mi">7</span><span class="n">B</span><span class="o">-</span><span class="n">v0</span><span class="mf">.1</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>You can either use the ipc=host flag or –shm-size flag to allow the container to access the host’s shared memory. vLLM uses PyTorch, which uses shared memory to share data between processes under the hood, particularly for tensor parallel inference.</p>
</div>
</section>
<section id="building-vllms-docker-image-from-source">
<h3>Building vLLM’s Docker Image from Source<a class="headerlink" href="#building-vllms-docker-image-from-source" title="此标题的永久链接">¶</a></h3>
<p>optionally specifies: –build-arg max_jobs=8 –build-arg nvcc_threads=2:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">DOCKER_BUILDKIT</span><span class="o">=</span><span class="mi">1</span> <span class="n">docker</span> <span class="n">build</span> <span class="o">.</span> <span class="o">--</span><span class="n">target</span> <span class="n">vllm</span><span class="o">-</span><span class="n">openai</span> <span class="o">--</span><span class="n">tag</span> <span class="n">vllm</span><span class="o">/</span><span class="n">vllm</span><span class="o">-</span><span class="n">openai</span>
</pre></div>
</div>
</section>
</section>
<section id="deploying-with-kubernetes">
<h2>Deploying with Kubernetes<a class="headerlink" href="#deploying-with-kubernetes" title="此标题的永久链接">¶</a></h2>
</section>
<section id="distributed-inference-and-serving">
<h2>Distributed Inference and Serving<a class="headerlink" href="#distributed-inference-and-serving" title="此标题的永久链接">¶</a></h2>
<section id="how-to-decide-the-distributed-inference-strategy">
<h3>How to decide the distributed inference strategy?<a class="headerlink" href="#how-to-decide-the-distributed-inference-strategy" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p>Single GPU (no distributed inference): If your model fits in a single GPU, you probably don’t need to use distributed inference. Just use the single GPU to run the inference.</p></li>
<li><p>Single-Node Multi-GPU (tensor parallel inference): If your model is too large to fit in a single GPU, but it can fit in a single node with multiple GPUs, you can use tensor parallelism. The tensor parallel size is the number of GPUs you want to use. For example, if you have 4 GPUs in a single node, you can set the tensor parallel size to 4.</p></li>
<li><p>Multi-Node Multi-GPU (tensor parallel plus pipeline parallel inference): If your model is too large to fit in a single node, you can use tensor parallel together with pipeline parallelism. The tensor parallel size is the number of GPUs you want to use in each node, and the pipeline parallel size is the number of nodes you want to use. For example, if you have 16 GPUs in 2 nodes (8GPUs per node), you can set the tensor parallel size to 8 and the pipeline parallel size to 2.</p></li>
</ul>
</section>
<section id="details-for-distributed-inference-and-serving">
<h3>Details for Distributed Inference and Serving<a class="headerlink" href="#details-for-distributed-inference-and-serving" title="此标题的永久链接">¶</a></h3>
<p>run API server on 4 GPUs:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">vllm</span> <span class="n">serve</span> <span class="n">facebook</span><span class="o">/</span><span class="n">opt</span><span class="o">-</span><span class="mi">13</span><span class="n">b</span> <span class="o">--</span><span class="n">tensor</span><span class="o">-</span><span class="n">parallel</span><span class="o">-</span><span class="n">size</span> <span class="mi">4</span>
</pre></div>
</div>
<p>run API server on 8 GPUs with pipeline parallelism and tensor parallelism:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">vllm</span> <span class="n">serve</span> <span class="n">gpt2</span> \
    <span class="o">--</span><span class="n">tensor</span><span class="o">-</span><span class="n">parallel</span><span class="o">-</span><span class="n">size</span> <span class="mi">4</span> \
    <span class="o">--</span><span class="n">pipeline</span><span class="o">-</span><span class="n">parallel</span><span class="o">-</span><span class="n">size</span> <span class="mi">2</span>
</pre></div>
</div>
</section>
<section id="multi-node-inference-and-serving">
<h3>Multi-Node Inference and Serving<a class="headerlink" href="#multi-node-inference-and-serving" title="此标题的永久链接">¶</a></h3>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>It is important to make sure the execution environment is the same on all nodes, including the model path, the Python environment. The recommended way is to use docker images to ensure the same environment, and hide the heterogeneity of the host machines via mapping them into the same docker configuration.</p>
</div>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>Administrative privileges are needed when to access GPU performance counters when running profiling and tracing tools.</p>
</div>
<p>Pick a node as the head node, and run the following command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bash</span> <span class="n">run_cluster</span><span class="o">.</span><span class="n">sh</span> \
                  <span class="n">vllm</span><span class="o">/</span><span class="n">vllm</span><span class="o">-</span><span class="n">openai</span> \
                  <span class="o">&lt;</span><span class="n">ip_of_head_node</span><span class="o">&gt;</span> \
                  <span class="o">--</span><span class="n">head</span> \
                  <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">the</span><span class="o">/</span><span class="n">huggingface</span><span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="ow">in</span><span class="o">/</span><span class="n">this</span><span class="o">/</span><span class="n">node</span>
</pre></div>
</div>
<p>On the rest of the worker nodes, run the following command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bash</span> <span class="n">run_cluster</span><span class="o">.</span><span class="n">sh</span> \
                  <span class="n">vllm</span><span class="o">/</span><span class="n">vllm</span><span class="o">-</span><span class="n">openai</span> \
                  <span class="o">&lt;</span><span class="n">ip_of_head_node</span><span class="o">&gt;</span> \
                  <span class="o">--</span><span class="n">worker</span> \
                  <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">the</span><span class="o">/</span><span class="n">huggingface</span><span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="ow">in</span><span class="o">/</span><span class="n">this</span><span class="o">/</span><span class="n">node</span>
</pre></div>
</div>
<p>进入容器:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">docker</span> <span class="n">exec</span> <span class="o">-</span><span class="n">it</span> <span class="n">node</span> <span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">bash</span>
</pre></div>
</div>
<p>像在一个node上一样执行(set the tensor parallel size to the number of GPUs in each node, and the pipeline parallel size to the number of nodes):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">vllm</span> <span class="n">serve</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">the</span><span class="o">/</span><span class="n">model</span><span class="o">/</span><span class="ow">in</span><span class="o">/</span><span class="n">the</span><span class="o">/</span><span class="n">container</span> \
    <span class="o">--</span><span class="n">tensor</span><span class="o">-</span><span class="n">parallel</span><span class="o">-</span><span class="n">size</span> <span class="mi">8</span> \
    <span class="o">--</span><span class="n">pipeline</span><span class="o">-</span><span class="n">parallel</span><span class="o">-</span><span class="n">size</span> <span class="mi">2</span>
</pre></div>
</div>
</section>
</section>
<section id="production-metrics">
<h2>Production Metrics<a class="headerlink" href="#production-metrics" title="此标题的永久链接">¶</a></h2>
<p>get the latest metrics from the server:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ curl http://0.0.0.0:8000/metrics
vllm:iteration_tokens_total_sum{model_name=&quot;unsloth/Llama-3.2-1B-Instruct&quot;} 0.0
vllm:iteration_tokens_total_bucket{le=&quot;1.0&quot;,model_name=&quot;unsloth/Llama-3.2-1B-Instruct&quot;} 3.0
...
</pre></div>
</div>
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference external" href="/index.html">主页</a></p></td>
<td><p><a class="reference internal" href="../../genindex.html"><span class="std std-ref">索引</span></a></p></td>
<td><p><a class="reference internal" href="../../py-modindex.html"><span class="std std-ref">模块索引</span></a></p></td>
<td><p><a class="reference internal" href="../../search.html"><span class="std std-ref">搜索页面</span></a></p></td>
</tr>
</tbody>
</table>
</section>
</section>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="Models.html" class="btn btn-neutral float-right" title="6.4.3. Models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="normal.html" class="btn btn-neutral" title="6.4.1. 常用" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>
  
  <div id="gitalk-container"></div>
  <div role="contentinfo">
    <p>
        &copy; Copyright 2010-2025, 新溪-gordon.

    </p>
  </div>
  <div>备案号 <a href="http://www.beian.miit.gov.cn">京ICP备16018553号</a></div><div>Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a></div>. 


</footer>

<script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?042289284b8eb33866001347a3e0b129";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
</script>     
        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'V1.7.22',
            LANGUAGE:'zh-CN',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="../../_static/sphinx_highlight.js"></script>
      <script type="text/javascript" src="../../_static/clipboard.min.js"></script>
      <script type="text/javascript" src="../../_static/copybutton.js"></script>
      <script type="text/javascript" src="../../_static/translations.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>

  

  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });


      // var gitalk = new Gitalk({
      //         clientID: '565177626b5d46427009',
      //         clientSecret: 'b2a36e67e1d2a73e43667f46d571c2624f8e1026',
      //         repo: 'knowledge',
      //         owner: 'zhaoweiguo',
      //         admin: ['zhaoweiguo'],
      //         id: location.pathname,      // Ensure uniqueness and length less than 50
      //         distractionFreeMode: false  // Facebook-like distraction free mode
      //       })
      // gitalk.render('gitalk-container')

  </script>


<script type="text/javascript" src="../../_static/js/table-of-contents-sidebar.js"></script>
<!-- <script type="text/javascript" src="https://table-of-contents-sidebar.github.io/table-of-contents-sidebar-lib/table-of-contents-sidebar.js"></script> -->
<script type="text/javascript">
    window.onload = function(e){
        TableOfContents.init({
            basePath: "https://table-of-contents-sidebar.github.io/table-of-contents-sidebar-lib/",
            querySelector: "body" // or other css querySelector
        });
    }
</script> 

</body>
</html>