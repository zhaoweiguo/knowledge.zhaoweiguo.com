

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="zh-CN" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="zh-CN" > <!--<![endif]-->
<head>


<!-- start added 2025-04-14   增加对markdown中公式的支持 -->
<script>
window.MathJax = {
    tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true
    },
    options: {
        ignoreHtmlClass: "tex2jax_ignore|mathjax_ignore",
        processHtmlClass: "tex2jax_process|mathjax_process|math|output_area"
    }
};
</script>
<script defer="defer" src="https://fastly.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<!-- end added 2025-04-14   增加对markdown中公式的支持 -->


<!-- start added 2025-08-06   增加对mermaid图的支持 -->
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', function() {
    mermaid.initialize({
        startOnLoad: true,
        theme: 'default',
        flowchart: { useMaxWidth: true }
    });
});
</script>
<!--  end added 2025-08-06   增加对mermaid图的支持 -->




  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Hugging Face Hub &mdash; 新溪-gordon V2025.11 文档</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
    <link rel="index" title="索引" href="../../../genindex.html" />
    <link rel="search" title="搜索" href="../../../search.html" />
    <link rel="next" title="Hub Python Library" href="lib_python.html" />
    <link rel="prev" title="7.3.1. 常用" href="../normal.html" /> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>
  <script src="../../../_static/js/jquery.min.js"></script>


<!-- 评论插件 gittalk start -->
<!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script> -->
<!-- 评论插件 gittalk end -->


</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../index.html" class="icon icon-home"> 新溪-gordon
          

          
          </a>

          
            
            
              <div class="version">
                V2025.11
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">AI</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../normal.html">1. 常用</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../normals/normal.html">1.1. 常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../normals/AIGC.html">1.2. AIGC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../normals/ml.html">1.3. 机器学习machine learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../normals/bi.html">1.4. BI(Business Intelligence)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../normals/deep_learning.html">1.5. 深度学习</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../normals/deep_learnings/normal.html">1.5.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../normals/deep_learnings/history.html">1.5.2. 历史</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../normals/monitor.html">1.6. monitor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../normals/algorithm.html">1.7. 相关算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../normals/tool.html">1.8. 工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../normals/question.html">1.9. 常见问题</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../normals/%E6%9C%BA%E5%99%A8%E4%BA%BA.html">1.10. 机器人领域</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../theory.html">2. 理论</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../theories/key.html">2.1. 关键定义</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/Recommenders/CF%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4.html">2.1.1. 协同过滤（Collaborative Filtering, CF）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/Recommenders/MF%E6%A6%82%E7%8E%87%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3.html">2.1.2. MF(Matrix Factorization，矩阵分解)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/Recommenders/PMF%E6%A6%82%E7%8E%87%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3.html">2.1.3. PMF（Probabilistic Matrix Factorization，概率矩阵分解）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/Recommenders/Two-TowerModels%E5%8F%8C%E5%A1%94%E6%A8%A1%E5%9E%8B.html">2.1.4. Two-Tower Models（双塔模型）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/Parallelism/normal.html">2.1.5. 通用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/Parallelism/PipelineParallelism.html">2.1.6. Pipeline Parallelism</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/Parallelism/TensorParallesim.html">2.1.7. Tensor Parallesim</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/func_activations/activation_Sigmoid.html">2.1.8. 激活函数-Sigmoid</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/func_activations/activation_RELU.html">2.1.9. 激活函数-ReLU</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/func_activations/activation_Leaky-ReLU.html">2.1.10. 激活函数-Leaky ReLU</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/func_activations/activation_Tanh.html">2.1.11. 激活函数-Tanh</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/func_activations/activation_GELU.html">2.1.12. 激活函数-GELU</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/func_activations/normalization_L1.html">2.1.13. 归一化-L1</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/func_activations/normalization_L2.html">2.1.14. 归一化-L2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/func_activations/probabilistic_Softmax.html">2.1.15. 概率分布-Softmax</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/func_activations/probabilistic_logSoftmax.html">2.1.16. 概率分布-logsoftmax</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/func_activations/probabilistic_Sparsemax.html">2.1.17. 概率分布-Sparsemax</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/func_loss/classify_cross_entropy.html">2.1.18. 损失函数-分类-cross-entropy(交叉熵)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/func_loss/classify_NLL.html">2.1.19. 损失函数-分类-负对数似然损失NLL Loss</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/func_loss/classify_log.html">2.1.20. 损失函数-分类-对数损失(Log Loss)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/func_loss/classify_kl.html">2.1.21. 损失函数-分类-KL 散度(KL Loss)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/func_loss/regression_MSE.html">2.1.22. 损失函数-回归-均方误差(MSE)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/func_loss/regression_MAE.html">2.1.23. 损失函数-回归-平均绝对误差(MAE)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/func_loss/regression_Huber.html">2.1.24. 损失函数-回归-Huber 损失</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/func_loss/regression_log_cosh.html">2.1.25. 损失函数-回归-对数余弦损失(Log-Cosh Loss)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/func_loss/%E6%9D%83%E9%87%8D%E8%A1%B0%E5%87%8F-L2%E6%AD%A3%E5%88%99%E5%8C%96.html">2.1.26. 权重衰减(L2正则化)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/func_optims/GD.html">2.1.27. GD(梯度下降)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/func_optims/SGD.html">2.1.28. SGD随机梯度下降</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/func_optims/RMSprop.html">2.1.29. RMSprop</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/func_optims/Adam.html">2.1.30. Adam</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/func_optims/AdamW.html">2.1.31. AdamW</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/func_optims/Momentum.html">2.1.32. Momentum</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/ners/HMM-%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B.html">2.1.33. HMM-隐马尔可夫模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/ners/WWM-%E5%85%A8%E8%AF%8DMask.html">2.1.34. WWM-Whole Word Masking</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/ners/CRF-%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA.html">2.1.35. CRF-条件随机场</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/dls/ANN.html">2.1.36. ANN(NN)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/dls/DNN-%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html">2.1.37. 深度神经网络(Deep Neural Network, DNN)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/dls/CNN-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html">2.1.38. 卷积神经网络(Convolutional Neural Network, CNN)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/dls/RNN-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91.html">2.1.39. RNN: 循环神经网(Recurrent Neural Network, RNN)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/dls/LSTM-%E9%95%BF%E7%9F%AD%E6%97%B6%E8%AE%B0%E5%BF%86.html">2.1.40. LSTM: 长短时记忆(Long Short Term Memory, LSTM)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/dl_theorys/propagation.html">2.1.41. 前向/反向传播</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/dl_theorys/LinearLayer.html">2.1.42. Linear Layer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/dl_theorys/FFN.html">2.1.43. Feedforward Network-前馈网络</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/dl_theorys/LayerNorm.html">2.1.44. LayerNorm(层归一化)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/dl_theorys/WeightTying.html">2.1.45. Weight Tying</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/dl_theorys/GreedyDecoding.html">2.1.46. Greedy Decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/dl_theorys/ImageGrounding.html">2.1.47. Image Grounding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/dl_theorys/Perplexity.html">2.1.48. Perplexity(PPL)困惑度</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/3Ds/ManhattanWorld%E6%9B%BC%E5%93%88%E9%A1%BF%E4%B8%96%E7%95%8C.html">2.1.49. Manhattan World(曼哈顿世界)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/3Ds/HoughTransform%E9%9C%8D%E5%A4%AB%E5%8F%98%E6%8D%A2.html">2.1.50. Hough Transform（霍夫变换）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/3Ds/PolarCoordinateSystem%E6%9E%81%E5%9D%90%E6%A0%87%E8%A1%A8%E7%A4%BA%E6%B3%95.html">2.1.51. 极坐标表示法(Polar Coordinate System)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/3Ds/GaussianSphere%E9%AB%98%E6%96%AF%E7%90%83.html">2.1.52. Gaussian Sphere（高斯球）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/3Ds/edge_direction%E8%BE%B9%E7%BC%98%E6%96%B9%E5%90%91.html">2.1.53. 边缘方向 Edge Direction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/3Ds/NormalVector%E6%B3%95%E5%90%91%E9%87%8F.html">2.1.54. NormalVector法向量</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/others/AllReduce.html">2.1.55. AllReduce</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/others/BPE.html">2.1.56. BPE</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/others/Embedding%E6%A8%A1%E5%9E%8B.html">2.1.57. Embedding 模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/others/K-Means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95.html">2.1.58. K-Means聚类算法</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/others/LLM.html">2.1.59. LLM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/others/deeplearning.html">2.1.60. 深度学习相关</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/others/other.html">2.1.61. 其他</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/others/%E5%88%A4%E5%88%AB%E5%BC%8F%E6%A8%A1%E5%9E%8Bvs%E7%94%9F%E6%88%90%E5%BC%8F%E6%A8%A1%E5%9E%8B.html">2.1.62. 判别式模型vs生成式模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/others/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%A9%BA%E9%97%B4.html">2.1.63. 欧几里得空间(Euclidean space)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/keys/others/%E7%9F%A2%E9%87%8F%E5%8C%96%E8%AE%A1%E7%AE%97.html">2.1.64. 矢量化计算(Vectorize calculations)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../theories/tmp.html">2.2. 临时</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/ReAct.html">2.2.1. ReAct框架</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/Reflection.html">2.2.2. Reflection反思</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/math.html">2.2.3. 数学</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/bag-of-words.html">2.2.4. bag-of-words</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/word2vec.html">2.2.5. Word2Vec</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/doc2vec.html">2.2.6. Doc2Vec</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/FastText.html">2.2.7. FastText</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/LDA.html">2.2.8. LDA-Latent Dirichlet Allocation(潜在狄利克雷分配)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/overfitting-underfitting.html">2.2.9. overfitting&amp;underfitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/RAG.html">2.2.10. RAG</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/Agent.html">2.2.11. Agent</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/LLM.html">2.2.12. LLM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/prompt_engineering.html">2.2.13. Prompt Engineering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/finetune.html">2.2.14. LLM调优(finetune)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/Workflow.html">2.2.15. Workflow</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/0normal.html">2.2.16. 通用</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../LLM.html">3. 大模型</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../LLMs/normal.html">3.1. 常用</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/normals/normal.html">3.1.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/normals/package.html">3.1.2. 依赖安装</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/normals/encoder.html">3.1.3. 编码-解码器</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/normals/usage.html">3.1.4. 使用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/normals/tmp.html">3.1.5. 临时</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../LLMs/model.html">3.2. 著名模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/models/Qwen3.html">3.2.1. Qwen3</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/models/DeepSeek.html">3.2.2. DeepSeek-R1-推理模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/models/LLaMA.html">3.2.3. LLaMA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/models/ChatGLM.html">3.2.4. ChatGLM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/models/BERT.html">3.2.5. BERT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/models/OpenAI.html">3.2.6. OpenAI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/models/BART.html">3.2.7. BART</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/models/T5.html">3.2.8. T5</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/models/ChatRWKV.html">3.2.9. ChatRWKV</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/models/Open-Assistant.html">3.2.10. Open-Assistant</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/models/OpenGVLab.html">3.2.11. OpenGVLab</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../LLMs/finetune.html">3.3. 调优</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../LLMs/Quantization%E9%87%8F%E5%8C%96.html">3.4. 模型量化(Quantization)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/Quantizations/normal.html">3.4.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/Quantizations/GGUF.html">3.4.2. GGUF 文件</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../LLMs/fileformat.html">3.5. 文件格式</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/fileformats/normal.html">3.5.1. 通用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/fileformats/GGML.html">3.5.2. GGML系列文件格式</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/fileformats/ONNX.html">3.5.3. ONNX</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../LLMs/fileformats/ONNXs/normal.html">常用</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../LLMs/fileformats/ONNXs/ONNX.html">ONNX</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../LLMs/fileformats/ONNXs/onnxruntime.html">onnxruntime</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../LLMs/fileformats/ONNXs/skl2onnx.html">skl2onnx</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/fileformats/NCNN.html">3.5.4. NCNN</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../LLMs/openai.html">3.6. 商业项目</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/openais/normal.html">3.6.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/openais/openai.html">3.6.2. OpenAI</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../LLMs/prompt.html">3.7. Prompt 提示词</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/prompts/demo_chinese.html">3.7.1. 中文</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/prompts/demo_english.html">3.7.2. English</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/prompts/skill.html">3.7.3. 示例</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../LLMs/Android.html">3.8. Android版LLM相关</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/Androids/normal.html">3.8.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/Androids/Android%E7%89%88%E9%83%A8%E7%BD%B2.html">3.8.2. Android版部署</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/Androids/GPU.html">3.8.3. GPU</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../RAG.html">4. RAG相关</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../NLP.html">5. NLP</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../NLPs/normal.html">5.1. 常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../NLPs/preprocess.html">5.2. 预处理</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../NLPs/preprocesses/normal.html">5.2.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../NLPs/preprocesses/%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E5%8F%96.html">5.2.2. 关键词提取</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../NLPs/preprocesses/%E5%88%86%E8%AF%8D.html">5.2.3. 分词</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../NLPs/preprocesses/%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90.html">5.2.4. 情感分析</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../NLPs/preprocesses/%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA.html">5.2.5. 文本表示</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../NLPs/preprocesses/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6.html">5.2.6. 注意力机制</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../NLPs/preprocesses/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B.html">5.2.7. 语言模型</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../NLPs/NER.html">5.3. NER-命名实体识别</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../NLPs/NERs/normal.html">5.3.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../NLPs/NERs/seq-label.html">5.3.2. 序列标注</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../NLPs/NERs/BiLSTM%2BCRF.html">5.3.3. BiLSTM+CRF</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../NLPs/NERs/history.html">5.3.4. 历史</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../NLPs/summary.html">5.4. 总结-摘要</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../NLPs/summarys/normal.html">5.4.1. 通用</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../library.html">6. 函数库</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/normal.html">6.1. 常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/Image.html">6.2. Image图像处理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/Video.html">6.3. Video视频</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/IPython.html">6.4. IPython</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/IPythons/normal.html">6.4.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/IPythons/magic.html">6.4.2. 魔法命令 </a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/IPythons/display.html">6.4.3. display函数</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/Jupyter.html">6.5. Jupyter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/NumPy.html">6.6. NumPy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/NumPys/normal.html">6.6.1. 通用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/NumPys/Ndarray.html">6.6.2. Ndarray 对象</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/NumPys/function.html">6.6.3. 通用函数</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/Pandas.html">6.7. Pandas</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Pandas/normal.html">6.7.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Pandas/example_subset.html">6.7.2. 实例-subset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Pandas/example_analysis.html">6.7.3. 实例-统计分析</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Pandas/example_sql.html">6.7.4. 利用pandas实现SQL操作</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Pandas/example_default_value.html">6.7.5. 实例-缺失值的处理</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Pandas/example_multi_index.html">6.7.6. 多层索引的使用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Pandas/practice.html">6.7.7. 实践</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../libraries/Pandas/practices/practice_2012ObamaElect.html">实践-2012年奥巴马总统连任选举</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Pandas/api_input_output.html">6.7.8. API-输入输出</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Pandas/api_General.html">6.7.9. API-General functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Pandas/api_Series.html">6.7.10. API-Series</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Pandas/api_DataFrame.html">6.7.11. API-DataFrame</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Pandas/api_Index.html">6.7.12. API-index</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/Matplotlib.html">6.8. Matplotlib</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Matplotlibs/normal.html">6.8.1. 基本</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Matplotlibs/install.html">6.8.2. 安装</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Matplotlibs/pyplot.html">6.8.3. pyplot </a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Matplotlibs/matplotlib.patches.html">6.8.4. matplotlib.patches</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Matplotlibs/example.html">6.8.5. 实例</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../libraries/Matplotlibs/examples/plot.html">折线图plot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../libraries/Matplotlibs/examples/bar.html">条形图bar</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../libraries/Matplotlibs/examples/hist.html">直方图hist</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../libraries/Matplotlibs/examples/scatter.html">散点图scatter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../libraries/Matplotlibs/examples/stackplot.html">面积图stackplot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../libraries/Matplotlibs/examples/pie.html">饼图pie</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../libraries/Matplotlibs/examples/box.html">箱型图box</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../libraries/Matplotlibs/examples/multi.html">多图合并multi</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Matplotlibs/pylab.html">6.8.6. pylab子包</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/SciPy.html">6.9. SciPy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/SciPys/normal.html">6.9.1. 常用</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/sklearn.html">6.10. sklearn</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/sklearns/normal.html">6.10.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/sklearns/supervised.html">6.10.2. 监督学习</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../libraries/sklearns/superviseds/glm.html">广义线性模型</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/sklearns/unsupervised.html">6.10.3. 无监督学习</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/statsmodels.html">6.11. statsmodels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/OpenCV.html">6.12. OpenCV</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/OpenCVs/normal.html">6.12.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/OpenCVs/example.html">6.12.2. 实例</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/OpenCVs/struct.html">6.12.3. 代码类结构</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/Seaborn.html">6.13. Seaborn</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Seaborns/normal.html">6.13.1. 常用</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/jieba.html">6.14. jieba中文分词</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/gensim.html">6.15. gensim: 文本主题建模和相似性分析</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/gensims/normal.html">6.15.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/gensims/Core_Tutorials.html">6.15.2. Core Tutorials</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/gensims/Tutorials.html">6.15.3. Tutorials: Learning Oriented Lessons</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/gensims/How-to_Guides.html">6.15.4. How-to Guides: Solve a Problem</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/LAC.html">6.16. LAC-百度词法分析工具</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../../../framework.html">7. 学习框架</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../normal.html">7.1. 常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../pytorch.html">7.2. PyTorch</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../pytorchs/normal.html">7.2.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../pytorchs/nn.html">7.2.2. nn模块</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../pytorchs/PyTorch.html">7.2.3. PyTorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../pytorchs/ExecuTorch.html">7.2.4. ExecuTorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../pytorchs/torchrun.html">7.2.5. torchrun (Elastic Launch)</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="../../huggingface.html">7.3. huggingface</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../normal.html">7.3.1. 常用</a><ul class="current">
<li class="toctree-l4 current"><a class="current reference internal" href="#">Hugging Face Hub</a></li>
<li class="toctree-l4"><a class="reference internal" href="lib_python.html">Hub Python Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="Datasets.html">Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="Text_Generation_Inference_main.html">TGI: Text Generation Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="Evaluate.html">Evaluate</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Transformers.html">7.3.2. Transformers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Transformers/Transformers.html">Transformers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Transformers/Transformers_V4.45.2.html">Transformers 4.45.2</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Tokenizers_V0.13.3.html">7.3.3. Tokenizers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../PEFT.html">7.3.4. PEFT</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../PEFT/PEFT.html">PEFT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../PEFT/PEFT_V0.13.0.html">PEFT 0.13.0</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Accelerate.html">7.3.5. Accelerate</a></li>
<li class="toctree-l3"><a class="reference internal" href="../TRL.html">7.3.6. TRL - Transformer Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../collect.html">7.3.7. 收集</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../collects/resources.html">resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../collects/model.html">model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../collects/blog_decoding-methods.html">博文: decoding methods of LLM with transformers</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../vLLM.html">7.4. vLLM</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../vLLMs/normal.html">7.4.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../vLLMs/vLLM_doc.html">7.4.2. vLLM官方文档</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../llama.cpp.html">7.5. llama.cpp框架</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../llama.cpps/normal.html">7.5.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../llama.cpps/llama-cpp-python.html">7.5.2. Python bindings for llama.cpp</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../DeepSpeed.html">7.6. DeepSpeed</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../DeepSpeeds/huggingface.html">7.6.1. huggingface</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../DeepSpeeds/ZeRO.html">7.6.2. Zero Redundancy Optimizer (ZeRO)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../DeepSpeeds/deepspeed_doc.html">7.6.3. DeepSpeed</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../mxnet.html">7.7. mxnet库</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mxnets/ndarray.html">7.7.1. nd模块</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../mxnets/ndarrays/ndarray.html">ndarray</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../mxnets/ndarrays/ndarray.random.html">ndarray.random</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnets/gluon.html">7.7.2. gluon模块</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnets/autograd.html">7.7.3. autograd模块</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../tensorflow.html">7.8. tensorflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Keras.html">7.9. Keras</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Keras/normal.html">7.9.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Keras/demo.html">7.9.2. 实例</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Keras/demos/binary_classification.html">二分类问题</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Keras/demos/multiclass_classification.html">多分类问题</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Keras/demos/regression.html">回归问题</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../other.html">7.10. 其他</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../website.html">8. 关键网站</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../websites/Papers%20with%20Code.html">8.1. Papers with Code</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../websites/Kaggle.html">8.2. Kaggle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../websites/ArXiv.html">8.3. ArXiv 学术论文预印本平台</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../websites/video.html">8.4. 视频相关</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../websites/normal.html">8.5. 通用</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../practice.html">9. 实践</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../practices/OCR.html">9.1. OCR</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../practices/OCRs/normal.html">9.1.1. 常用</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../practices/AIML.html">9.2. AIML</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../practices/AIMLs/normal.html">9.2.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../practices/AIMLs/spec.html">9.2.2. AIML 2.1 Documentation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../opensource.html">10. 开源项目</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../opensources/Agent.html">10.1. Agent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../opensources/RAG.html">10.2. RAG</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../opensources/normal.html">10.3. 常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../opensources/ui.html">10.4. UI界面</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../opensources/finetune.html">10.5. 调优</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../opensources/search.html">10.6. 搜索</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../opensources/LLM-Inference-Engine.html">10.7. LLM Inference Engines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../opensources/LLM-Inference-Tool.html">10.8. 模型推理平台</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../opensources/LLM-inference-accelerate.html">10.9. LLM推理加速</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../opensources/Evaluate.html">10.10. LLM评估</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../opensources/platform.html">10.11. AI平台</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../dataset.html">11. 数据集</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../datasets/normal.html">11.1. 常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../datasets/chinese.html">11.2. 中文数据集</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../datasets/chinese_image.html">11.3. 中文图片相关数据集</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../datasets/huggingface.html">11.4. dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../datasets/website.html">11.5. 数据集相关网站</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../model.html">12. 常见模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cuda.html">13. 图形&amp;计算加速技术</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../cudas/normal.html">13.1. 常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../cudas/cuda.html">13.2. cuda</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../Evaluate.html">14. Evaluate评测</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../Evaluates/normal.html">14.1. 通用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../Evaluates/TruLens.html">14.2. TruLens</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../Evaluates/Ragas.html">14.3. Ragas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../Evaluates/DeepEval.html">14.4. DeepEval</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../Evaluates/UpTrain.html">14.5. UpTrain</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../Evaluates/huggingface.html">14.6. evaluate</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../%E4%BC%A0%E7%BB%9FAI.html">15. 传统AI</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">新溪-gordon</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../../framework.html"><span class="section-number">7. </span>学习框架</a> &raquo;</li>
        
          <li><a href="../../huggingface.html"><span class="section-number">7.3. </span>huggingface</a> &raquo;</li>
        
          <li><a href="../normal.html"><span class="section-number">7.3.1. </span>常用</a> &raquo;</li>
        
      <li>Hugging Face Hub</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../../_sources/frameworks/huggingfaces/normals/huggingface_hub.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            <nav id="local-table-of-contents" role="navigation" aria-labelledby="local-table-of-contents-title">
              <h4 id="local-table-of-contents-title">On This Page</h4>
              <ul>
<li><a class="reference internal" href="#">Hugging Face Hub</a><ul>
<li><a class="reference internal" href="#repositories">Repositories</a></li>
<li><a class="reference internal" href="#models">Models</a><ul>
<li><a class="reference internal" href="#integrated-libraries">Integrated Libraries</a><ul>
<li><a class="reference internal" href="#transformers">Transformers</a></li>
<li><a class="reference internal" href="#adapter-transformers">Adapter Transformers</a></li>
<li><a class="reference internal" href="#allennlp">AllenNLP</a></li>
<li><a class="reference internal" href="#asteroid">Asteroid</a></li>
<li><a class="reference internal" href="#espnet">ESPnet</a></li>
<li><a class="reference internal" href="#fastai">fastai</a></li>
<li><a class="reference internal" href="#keras">Keras</a></li>
<li><a class="reference internal" href="#ml-agents">ML-Agents</a></li>
<li><a class="reference internal" href="#paddlenlp">PaddleNLP</a></li>
<li><a class="reference internal" href="#rl-baselines3-zoo">RL-Baselines3-Zoo</a></li>
<li><a class="reference internal" href="#sample-factory">Sample Factory</a></li>
<li><a class="reference internal" href="#sentence-transformers">Sentence Transformers</a></li>
<li><a class="reference internal" href="#spacy">spaCy</a></li>
<li><a class="reference internal" href="#spanmarker">SpanMarker</a></li>
<li><a class="reference internal" href="#speechbrain">SpeechBrain</a></li>
<li><a class="reference internal" href="#stable-baselines3">Stable-Baselines3</a></li>
<li><a class="reference internal" href="#stanza">Stanza</a></li>
<li><a class="reference internal" href="#tensorboard">TensorBoard</a></li>
<li><a class="reference internal" href="#timm">timm</a></li>
<li><a class="reference internal" href="#transformers-js">Transformers.js</a></li>
</ul>
</li>
<li><a class="reference internal" href="#widgets">Widgets 部件</a><ul>
<li><a class="reference internal" href="#widgets-examples">Widgets examples</a></li>
<li><a class="reference internal" href="#some-links-to-examples">some links to examples</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#datasets">Datasets</a><ul>
<li><a class="reference internal" href="#using-datasets">Using Datasets</a></li>
<li><a class="reference internal" href="#adding-new-datasets">Adding new datasets</a></li>
</ul>
</li>
<li><a class="reference internal" href="#spaces">Spaces</a></li>
</ul>
</li>
</ul>

            </nav>
  <table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference external" href="/index.html">主页</a></p></td>
<td><p><a class="reference internal" href="../../../genindex.html"><span class="std std-ref">索引</span></a></p></td>
<td><p><a class="reference internal" href="../../../py-modindex.html"><span class="std std-ref">模块索引</span></a></p></td>
<td><p><a class="reference internal" href="../../../search.html"><span class="std std-ref">搜索页面</span></a></p></td>
</tr>
</tbody>
</table>
<section id="hugging-face-hub">
<h1>Hugging Face Hub<a class="headerlink" href="#hugging-face-hub" title="此标题的永久链接">¶</a></h1>
<ul class="simple">
<li><p>Hugging Face Hub 是一个拥有超过 120k 模型、20k 数据集和 50k 演示应用程序 （Spaces） 的平台</p></li>
</ul>
<section id="repositories">
<h2>Repositories<a class="headerlink" href="#repositories" title="此标题的永久链接">¶</a></h2>
<ul class="simple">
<li><p>Models, Spaces, and Datasets are hosted on the Hugging Face Hub as Git repositories, which means that version control and collaboration are core elements of the Hub.</p></li>
</ul>
<p>Cloning repositories 克隆存储库:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">huggingface</span><span class="o">.</span><span class="n">co</span><span class="o">/&lt;</span><span class="n">your</span><span class="o">-</span><span class="n">username</span><span class="o">&gt;/&lt;</span><span class="n">your</span><span class="o">-</span><span class="n">model</span><span class="o">-</span><span class="n">name</span><span class="o">&gt;</span>
<span class="n">git</span> <span class="n">clone</span> <span class="n">git</span><span class="nd">@hf</span><span class="o">.</span><span class="n">co</span><span class="p">:</span><span class="o">&lt;</span><span class="n">your</span><span class="o">-</span><span class="n">username</span><span class="o">&gt;/&lt;</span><span class="n">your</span><span class="o">-</span><span class="n">model</span><span class="o">-</span><span class="n">name</span><span class="o">&gt;</span>
</pre></div>
</div>
</section>
<section id="models">
<h2>Models<a class="headerlink" href="#models" title="此标题的永久链接">¶</a></h2>
<p>常见的机器学习文档工具包括:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>- 模型卡(Model Cards):自动生成描述模型性能、用途、局限性等信息的标准文档。
- 数据表(Data Sheets):自动生成数据集的元数据、组成、收集方法等信息的标准文档。
- 报告生成器(Reporting):根据模型试验结果自动生成试验报告。
- 文档extractors:从代码注释、函数签名等自动提取文档。
- 可视化工具(Visualization):通过关系图、流程图等可视化展示系统结构。
- 笔记本工具(Notebooks):像Jupyter等笔记本可以嵌入文档、代码、结果展示。
</pre></div>
</div>
<section id="integrated-libraries">
<h3>Integrated Libraries<a class="headerlink" href="#integrated-libraries" title="此标题的永久链接">¶</a></h3>
<p>HuggingFace Supported Libraries:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>+----------------------------+---------------+---------+-------------------+-------------+
| Library                    | Inference API | Widgets | Download from Hub | Push to Hub |
+============================+===============+=========+===================+=============+
| 🤗 Transformers            | ✅            | ✅      | ✅                | ✅          |
+----------------------------+---------------+---------+-------------------+-------------+
| 🤗 Diffusers               | ❌            | ❌      | ✅                | ✅          |
+----------------------------+---------------+---------+-------------------+-------------+
| Adapter Transformers       | ❌            | ❌      | ✅                | ✅          |
+----------------------------+---------------+---------+-------------------+-------------+
| AllenNLP                   | ✅            | ✅      | ✅                | ❌          |
+----------------------------+---------------+---------+-------------------+-------------+
| Asteroid                   | ✅            | ✅      | ✅                | ❌          |
+----------------------------+---------------+---------+-------------------+-------------+
| BERTopic                   | ✅            | ✅      | ✅                | ✅          |
+----------------------------+---------------+---------+-------------------+-------------+
| docTR                      | ✅            | ✅      | ✅                | ❌          |
+----------------------------+---------------+---------+-------------------+-------------+
| ESPnet                     | ✅            | ✅      | ✅                | ❌          |
+----------------------------+---------------+---------+-------------------+-------------+
| fastai                     | ✅            | ✅      | ✅                | ✅          |
+----------------------------+---------------+---------+-------------------+-------------+
| Keras                      | ❌            | ❌      | ✅                | ✅          |
+----------------------------+---------------+---------+-------------------+-------------+
| Flair                      | ✅            | ✅      | ✅                | ❌          |
+----------------------------+---------------+---------+-------------------+-------------+
| MBRL-Lib                   | ❌            | ❌      | ✅                | ✅          |
+----------------------------+---------------+---------+-------------------+-------------+
| ML-Agents                  | ❌            | ❌      | ✅                | ✅          |
+----------------------------+---------------+---------+-------------------+-------------+
| NeMo                       | ✅            | ✅      | ✅                | ❌          |
+----------------------------+---------------+---------+-------------------+-------------+
| PaddleNLP                  | ✅            | ✅      | ✅                | ✅          |
+----------------------------+---------------+---------+-------------------+-------------+
| Pyannote                   | ❌            | ❌      | ✅                | ❌          |
+----------------------------+---------------+---------+-------------------+-------------+
| PyCTCDecode                | ❌            | ❌      | ✅                | ❌          |
+----------------------------+---------------+---------+-------------------+-------------+
| Pythae                     | ❌            | ❌      | ✅                | ✅          |
+----------------------------+---------------+---------+-------------------+-------------+
| RL-Baselines3-Zoo          | ❌            | ✅      | ✅                | ✅          |
+----------------------------+---------------+---------+-------------------+-------------+
| Sample Factory             | ❌            | ✅      | ✅                | ✅          |
+----------------------------+---------------+---------+-------------------+-------------+
| Sentence Transformers      | ✅            | ✅      | ✅                | ✅          |
+----------------------------+---------------+---------+-------------------+-------------+
| spaCy                      | ✅            | ✅      | ✅                | ✅          |
+----------------------------+---------------+---------+-------------------+-------------+
| SpanMarker                 | ✅            | ✅      | ✅                | ✅          |
+----------------------------+---------------+---------+-------------------+-------------+
| Scikit Learn (using skops) | ✅            | ✅      | ✅                | ✅          |
+----------------------------+---------------+---------+-------------------+-------------+
| Speechbrain                | ✅            | ✅      | ✅                | ❌          |
+----------------------------+---------------+---------+-------------------+-------------+
| Stable-Baselines3          | ❌            | ✅      | ✅                | ✅          |
+----------------------------+---------------+---------+-------------------+-------------+
| TensorFlowTTS              | ❌            | ❌      | ✅                | ❌          |
+----------------------------+---------------+---------+-------------------+-------------+
| Timm                       | ✅            | ✅      | ✅                | ✅          |
+----------------------------+---------------+---------+-------------------+-------------+
| Transformers.js            | ❌            | ❌      | ✅                | ❌          |
+----------------------------+---------------+---------+-------------------+-------------+
</pre></div>
</div>
<ul>
<li><p>HuggingFace Supported Libraries Description <a class="reference external" href="https://huggingface.co/docs/hub/models-libraries">各lib库具体链接参见</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Library                  Description
🤗 Transformers          State-of-the-art NLP for Pytorch, TensorFlow, and JAX
🤗 Diffusers             A modular toolbox for inference and training of diffusion models
Adapter Transformers     Extends 🤗Transformers with Adapters.
AllenNLP                 An open-source NLP research library, built on PyTorch.
Asteroid                 Pytorch-based audio source separation toolkit
BERTopic                 BERTopic is a topic modeling library for text and images
docTR                    Models and datasets for OCR-related tasks in PyTorch &amp; TensorFlow
ESPnet                   End-to-end speech processing toolkit (e.g. TTS)
fastai                   Library to train fast and accurate models with state-of-the-art outputs.
Keras                    Library that uses a consistent and simple API to build models leveraging TensorFlow and its ecosystem.
Flair                    Very simple framework for state-of-the-art NLP.
MBRL-Lib                 PyTorch implementations of MBRL Algorithms.
ML-Agents                Enables games and simulations made with Unity to serve as environments for training intelligent agents.
NeMo                     Conversational AI toolkit built for researchers
PaddleNLP                Easy-to-use and powerful NLP library built on PaddlePaddle
Pyannote                 Neural building blocks for speaker diarization.
PyCTCDecode              Language model supported CTC decoding for speech recognition
Pythae                   Unifyed framework for Generative Autoencoders in Python
RL-Baselines3-Zoo        Training framework for Reinforcement Learning, using Stable Baselines3.
Sample Factory           Codebase for high throughput asynchronous reinforcement learning.
Sentence Transformers    Compute dense vector representations for sentences, paragraphs, and images.
spaCy                    Advanced Natural Language Processing in Python and Cython.
SpanMarker               Familiar, simple and state-of-the-art Named Entity Recognition.
ScikitLearn(using skops) Machine Learning in Python.
Speechbrain              A PyTorch Powered Speech Toolkit.
Stable-Baselines3        Set of reliable implementations of deep reinforcement learning algorithms in PyTorch
TensorFlowTTS            Real-time state-of-the-art speech synthesis architectures.
Timm                     Collection of image models, scripts, pretrained weights, etc.
Transformers.js          State-of-the-art Machine Learning for the web. Run 🤗 Transformers directly in your browser, with no need for a server!
</pre></div>
</div>
</li>
</ul>
<section id="transformers">
<h4>Transformers<a class="headerlink" href="#transformers" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>transformers is a library with state-of-the-art Machine Learning for Pytorch, TensorFlow and JAX. It provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.</p></li>
</ul>
<p>You can find models for many different tasks:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">01.</span> <span class="n">Extracting</span> <span class="n">the</span> <span class="n">answer</span> <span class="kn">from</span><span class="w"> </span><span class="nn">a</span> <span class="n">context</span> <span class="p">(</span><span class="n">question</span><span class="o">-</span><span class="n">answering</span><span class="p">)</span><span class="o">.</span>
<span class="mf">02.</span> <span class="n">Creating</span> <span class="n">summaries</span> <span class="kn">from</span><span class="w"> </span><span class="nn">a</span> <span class="n">large</span> <span class="n">text</span> <span class="p">(</span><span class="n">summarization</span><span class="p">)</span><span class="o">.</span>
<span class="mf">03.</span> <span class="n">Classify</span> <span class="n">text</span> <span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">g</span><span class="o">.</span> <span class="k">as</span> <span class="n">spam</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">spam</span><span class="p">,</span> <span class="n">text</span><span class="o">-</span><span class="n">classification</span><span class="p">)</span><span class="o">.</span>
<span class="mf">04.</span> <span class="n">Generate</span> <span class="n">a</span> <span class="n">new</span> <span class="n">text</span> <span class="k">with</span> <span class="n">models</span> <span class="n">such</span> <span class="k">as</span> <span class="n">GPT</span> <span class="p">(</span><span class="n">text</span><span class="o">-</span><span class="n">generation</span><span class="p">)</span><span class="o">.</span>
<span class="mf">05.</span> <span class="n">Identify</span> <span class="n">parts</span> <span class="n">of</span> <span class="n">speech</span> <span class="p">(</span><span class="n">verb</span><span class="p">,</span> <span class="n">subject</span><span class="p">,</span> <span class="n">etc</span><span class="o">.</span><span class="p">)</span>
        <span class="ow">or</span> <span class="n">entities</span> <span class="p">(</span><span class="n">country</span><span class="p">,</span> <span class="n">organization</span><span class="p">,</span> <span class="n">etc</span><span class="o">.</span><span class="p">)</span> <span class="ow">in</span> <span class="n">a</span> <span class="n">sentence</span> <span class="p">(</span><span class="n">token</span><span class="o">-</span><span class="n">classification</span><span class="p">)</span><span class="o">.</span>
<span class="mf">06.</span> <span class="n">Transcribe</span> <span class="n">audio</span> <span class="n">files</span> <span class="n">to</span> <span class="n">text</span> <span class="p">(</span><span class="n">automatic</span><span class="o">-</span><span class="n">speech</span><span class="o">-</span><span class="n">recognition</span><span class="p">)</span><span class="o">.</span>
<span class="mf">07.</span> <span class="n">Classify</span> <span class="n">the</span> <span class="n">speaker</span> <span class="ow">or</span> <span class="n">language</span> <span class="ow">in</span> <span class="n">an</span> <span class="n">audio</span> <span class="n">file</span> <span class="p">(</span><span class="n">audio</span><span class="o">-</span><span class="n">classification</span><span class="p">)</span><span class="o">.</span>
<span class="mf">08.</span> <span class="n">Detect</span> <span class="n">objects</span> <span class="ow">in</span> <span class="n">an</span> <span class="n">image</span> <span class="p">(</span><span class="nb">object</span><span class="o">-</span><span class="n">detection</span><span class="p">)</span><span class="o">.</span>
<span class="mf">09.</span> <span class="n">Segment</span> <span class="n">an</span> <span class="n">image</span> <span class="p">(</span><span class="n">image</span><span class="o">-</span><span class="n">segmentation</span><span class="p">)</span><span class="o">.</span>
<span class="mf">10.</span> <span class="n">Do</span> <span class="n">Reinforcement</span> <span class="n">Learning</span> <span class="p">(</span><span class="n">reinforcement</span><span class="o">-</span><span class="n">learning</span><span class="p">)</span>
</pre></div>
</div>
<p>Using existing models:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># With pipeline, just specify the task and the model id from the Hub.</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;text-generation&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;distilgpt2&quot;</span><span class="p">)</span>

<span class="c1"># If you want more control, you will need to define the tokenizer and model.</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;distilgpt2&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;distilgpt2&quot;</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><dl class="simple">
<dt>其他资源</dt><dd><ul>
<li><p>Transformers library: <a class="reference external" href="https://github.com/huggingface/transformers">https://github.com/huggingface/transformers</a></p></li>
<li><p>Transformers docs: <a class="reference external" href="https://huggingface.co/docs/transformers/index">https://huggingface.co/docs/transformers/index</a></p></li>
<li><p>Share a model guide: <a class="reference external" href="https://huggingface.co/docs/transformers/model_sharing">https://huggingface.co/docs/transformers/model_sharing</a></p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="adapter-transformers">
<h4>Adapter Transformers<a class="headerlink" href="#adapter-transformers" title="此标题的永久链接">¶</a></h4>
<p>安装:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">U</span> <span class="n">adapter</span><span class="o">-</span><span class="n">transformers</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">adapter-transformers</span></code> is a library that extends 🤗 transformers by allowing to integrate, train and use Adapters and other efficient fine-tuning methods. The library is fully compatible with 🤗 transformers. Adapters are small learnt layers inserted within each layer of a pre-trained model. You can learn more about this in the <a class="reference external" href="https://arxiv.org/abs/2007.07779">original paper</a>.</p></li>
<li><p>Adapter Hub repository: <a class="reference external" href="https://github.com/adapter-hub/hub">https://github.com/adapter-hub/hub</a></p></li>
<li><p>AdapterHub: <a class="reference external" href="https://adapterhub.ml/explore/">https://adapterhub.ml/explore/</a></p></li>
<li><p>official guide: <a class="reference external" href="https://docs.adapterhub.ml/index.html">https://docs.adapterhub.ml/index.html</a></p></li>
<li><p>Adapter Transformers library: <a class="reference external" href="https://github.com/adapter-hub/adapter-transformers">https://github.com/adapter-hub/adapter-transformers</a></p></li>
<li><p>Integration with Hub docs: <a class="reference external" href="https://docs.adapterhub.ml/huggingface_hub.html">https://docs.adapterhub.ml/huggingface_hub.html</a></p></li>
</ul>
<p>示例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelWithHeads</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelWithHeads</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">)</span>
<span class="n">adapter_name</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">load_adapter</span><span class="p">(</span><span class="s2">&quot;AdapterHub/bert-base-uncased-pf-emotion&quot;</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="s2">&quot;hf&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">active_adapters</span> <span class="o">=</span> <span class="n">adapter_name</span>
</pre></div>
</div>
<p>find all Adapter Models programmatically:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">list_adapters</span>
<span class="c1"># source can be &quot;ah&quot; (AdapterHub), &quot;hf&quot; (hf.co) or None (for both, default)</span>
<span class="n">adapter_infos</span> <span class="o">=</span> <span class="n">list_adapters</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="s2">&quot;hf&quot;</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="allennlp">
<h4>AllenNLP<a class="headerlink" href="#allennlp" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>allennlp is a NLP library for developing state-of-the-art models on different linguistic tasks. It provides high-level abstractions and APIs for common components and models in modern NLP. It also provides an extensible framework that makes it easy to run and manage NLP experiments.</p></li>
</ul>
<a class="reference internal image-reference" href="https://img.zhaoweiguo.com/uPic/2023/07/cWfYz0.jpg"><img alt="https://img.zhaoweiguo.com/uPic/2023/07/cWfYz0.jpg" src="https://img.zhaoweiguo.com/uPic/2023/07/cWfYz0.jpg" style="width: 50%; height: 300px;" /></a>
<ul class="simple">
<li><p>AllenNLP website: <a class="reference external" href="https://allenai.org/allennlp">https://allenai.org/allennlp</a></p></li>
<li><p>AllenNLP repository: <a class="reference external" href="https://github.com/allenai/allennlp">https://github.com/allenai/allennlp</a></p></li>
</ul>
<p>示例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">allennlp_models</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">allennlp.predictors.predictor</span><span class="w"> </span><span class="kn">import</span> <span class="n">Predictor</span>

<span class="n">predictor</span> <span class="o">=</span> <span class="n">Predictor</span><span class="o">.</span><span class="n">from_path</span><span class="p">(</span><span class="s2">&quot;hf://allenai/bidaf-elmo&quot;</span><span class="p">)</span>
<span class="n">predictor_input</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;passage&quot;</span><span class="p">:</span> <span class="s2">&quot;My name is Wolfgang and I live in Berlin&quot;</span><span class="p">,</span>
    <span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="s2">&quot;Where do I live?&quot;</span>
<span class="p">}</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">predict_json</span><span class="p">(</span><span class="n">predictor_input</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="asteroid">
<h4>Asteroid<a class="headerlink" href="#asteroid" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>asteroid is a Pytorch toolkit for audio source separation. It enables fast experimentation on common datasets with support for a large range of datasets and recipes to reproduce papers.</p></li>
<li><p>models page: <a class="reference external" href="https://huggingface.co/models?filter=asteroid">https://huggingface.co/models?filter=asteroid</a></p></li>
</ul>
<figure class="align-default">
<a class="reference internal image-reference" href="https://img.zhaoweiguo.com/uPic/2023/07/V6D7ii.jpg"><img alt="https://img.zhaoweiguo.com/uPic/2023/07/V6D7ii.jpg" src="https://img.zhaoweiguo.com/uPic/2023/07/V6D7ii.jpg" style="width: 400px;" /></a>
</figure>
<ul class="simple">
<li><p>Asteroid website: <a class="reference external" href="https://asteroid-team.github.io/">https://asteroid-team.github.io/</a></p></li>
<li><p>Asteroid library: <a class="reference external" href="https://github.com/asteroid-team/asteroid">https://github.com/asteroid-team/asteroid</a></p></li>
<li><p>Integration docs: <a class="reference external" href="https://github.com/asteroid-team/asteroid/blob/master/docs/source/readmes/pretrained_models.md">https://github.com/asteroid-team/asteroid/blob/master/docs/source/readmes/pretrained_models.md</a></p></li>
</ul>
<p>示例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">asteroid.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">ConvTasNet</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ConvTasNet</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;mpariente/ConvTasNet_WHAM_sepclean&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="espnet">
<h4>ESPnet<a class="headerlink" href="#espnet" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>espnet is an end-to-end toolkit for speech processing, including automatic speech recognition, text to speech, speech enhancement, dirarization and other tasks.</p></li>
</ul>
<figure class="align-default">
<a class="reference internal image-reference" href="https://img.zhaoweiguo.com/uPic/2023/07/EPEBlv.jpg"><img alt="https://img.zhaoweiguo.com/uPic/2023/07/EPEBlv.jpg" src="https://img.zhaoweiguo.com/uPic/2023/07/EPEBlv.jpg" style="width: 400px;" /></a>
</figure>
<ul class="simple">
<li><p>ESPnet model zoo repository: <a class="reference external" href="https://github.com/espnet/espnet_model_zoo">https://github.com/espnet/espnet_model_zoo</a></p></li>
<li><p>ESPnet docs: <a class="reference external" href="https://espnet.github.io/espnet/index.html">https://espnet.github.io/espnet/index.html</a></p></li>
<li><p>Integration docs: <a class="reference external" href="https://github.com/asteroid-team/asteroid/blob/master/docs/source/readmes/pretrained_models.md">https://github.com/asteroid-team/asteroid/blob/master/docs/source/readmes/pretrained_models.md</a></p></li>
</ul>
<p>示例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">soundfile</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">espnet2.bin.tts_inference</span><span class="w"> </span><span class="kn">import</span> <span class="n">Text2Speech</span>

<span class="n">text2speech</span> <span class="o">=</span> <span class="n">Text2Speech</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;model_name&quot;</span><span class="p">)</span>
<span class="n">speech</span> <span class="o">=</span> <span class="n">text2speech</span><span class="p">(</span><span class="s2">&quot;foobar&quot;</span><span class="p">)[</span><span class="s2">&quot;wav&quot;</span><span class="p">]</span>
<span class="n">soundfile</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;out.wav&quot;</span><span class="p">,</span> <span class="n">speech</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">text2speech</span><span class="o">.</span><span class="n">fs</span><span class="p">,</span> <span class="s2">&quot;PCM_16&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="fastai">
<h4>fastai<a class="headerlink" href="#fastai" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>fastai is an open-source Deep Learning library that leverages PyTorch and Python to provide high-level components to train fast and accurate neural networks with state-of-the-art outputs on text, vision, and tabular data.</p></li>
<li><p>models page: <a class="reference external" href="https://huggingface.co/models?library=fastai&amp;sort=downloads">https://huggingface.co/models?library=fastai&amp;sort=downloads</a></p></li>
</ul>
<p>安装:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">huggingface_hub</span><span class="p">[</span><span class="s2">&quot;fastai&quot;</span><span class="p">]</span>
</pre></div>
</div>
<ul class="simple">
<li><p>fastai course: <a class="reference external" href="https://course.fast.ai/">https://course.fast.ai/</a></p></li>
<li><p>fastai website: <a class="reference external" href="https://www.fast.ai/">https://www.fast.ai/</a></p></li>
<li><p>Integration with Hub docs: <a class="reference external" href="https://docs.fast.ai/huggingface.html">https://docs.fast.ai/huggingface.html</a></p></li>
<li><p>Integration with Hub announcement: <a class="reference external" href="https://huggingface.co/blog/fastai">https://huggingface.co/blog/fastai</a></p></li>
</ul>
<p>示例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">from_pretrained_fastai</span>

<span class="n">learner</span> <span class="o">=</span> <span class="n">from_pretrained_fastai</span><span class="p">(</span><span class="s2">&quot;espejelomar/identify-my-cat&quot;</span><span class="p">)</span>

<span class="n">_</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">probs</span> <span class="o">=</span> <span class="n">learner</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Probability it&#39;s a cat: </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">probs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

<span class="c1"># Probability it&#39;s a cat: 100.00%</span>
</pre></div>
</div>
</section>
<section id="keras">
<h4>Keras<a class="headerlink" href="#keras" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>keras is an open-source machine learning library that uses a consistent and simple API to build models leveraging TensorFlow and its ecosystem.</p></li>
<li><p>Keras Developer Guides: <a class="reference external" href="https://keras.io/guides/">https://keras.io/guides/</a></p></li>
<li><p>Keras examples: <a class="reference external" href="https://keras.io/examples/">https://keras.io/examples/</a></p></li>
<li><p>Keras examples on 🤗 Hub: <a class="reference external" href="https://huggingface.co/keras-io">https://huggingface.co/keras-io</a></p></li>
<li><p>Keras learning resources: <a class="reference external" href="https://keras.io/getting_started/learning_resources/#moocs">https://keras.io/getting_started/learning_resources/#moocs</a></p></li>
</ul>
<p>示例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">from_pretrained_keras</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">from_pretrained_keras</span><span class="p">(</span><span class="s2">&quot;keras-io/mobile-vit-xxs&quot;</span><span class="p">)</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">prediction</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;The image is a </span><span class="si">{</span><span class="n">classes</span><span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">prediction</span><span class="p">))]</span><span class="si">}</span><span class="s1">!&#39;</span><span class="p">)</span>

<span class="c1"># The image is a sunflower!</span>
</pre></div>
</div>
</section>
<section id="ml-agents">
<h4>ML-Agents<a class="headerlink" href="#ml-agents" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>ml-agents is an open-source toolkit that enables games and simulations made with Unity to serve as environments for training intelligent agents.</p></li>
</ul>
<p>安装:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Clone the repository</span>
<span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">Unity</span><span class="o">-</span><span class="n">Technologies</span><span class="o">/</span><span class="n">ml</span><span class="o">-</span><span class="n">agents</span>

<span class="c1"># Go inside the repository and install the package</span>
<span class="n">cd</span> <span class="n">ml</span><span class="o">-</span><span class="n">agents</span>
<span class="n">pip3</span> <span class="n">install</span> <span class="o">-</span><span class="n">e</span> <span class="o">./</span><span class="n">ml</span><span class="o">-</span><span class="n">agents</span><span class="o">-</span><span class="n">envs</span>
<span class="n">pip3</span> <span class="n">install</span> <span class="o">-</span><span class="n">e</span> <span class="o">./</span><span class="n">ml</span><span class="o">-</span><span class="n">agents</span>
</pre></div>
</div>
<ul class="simple">
<li><p>ML-Agents documentation: <a class="reference external" href="https://github.com/Unity-Technologies/ml-agents/blob/develop/docs/Hugging-Face-Integration.md">https://github.com/Unity-Technologies/ml-agents/blob/develop/docs/Hugging-Face-Integration.md</a></p></li>
<li><p>Official Unity ML-Agents Spaces demos: <a class="reference external" href="https://huggingface.co/unity">https://huggingface.co/unity</a></p></li>
</ul>
<p>示例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mlagents</span><span class="o">-</span><span class="n">load</span><span class="o">-</span><span class="n">from</span><span class="o">-</span><span class="n">hf</span> <span class="o">--</span><span class="n">repo</span><span class="o">-</span><span class="nb">id</span><span class="o">=</span><span class="s2">&quot;Art-phys/poca-SoccerTwos_500M&quot;</span> <span class="o">--</span><span class="n">local</span><span class="o">-</span><span class="nb">dir</span><span class="o">=</span><span class="s2">&quot;./downloads&quot;</span>
</pre></div>
</div>
</section>
<section id="paddlenlp">
<h4>PaddleNLP<a class="headerlink" href="#paddlenlp" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>Leveraging the PaddlePaddle framework, PaddleNLP is an easy-to-use and powerful NLP library with awesome pre-trained model zoo, supporting wide-range of NLP tasks from research to industrial applications.</p></li>
</ul>
<p>安装:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">U</span> <span class="n">paddlenlp</span>
</pre></div>
</div>
<p>示例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">paddlenlp.transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForMaskedLM</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;PaddlePaddle/ernie-1.0-base-zh&quot;</span><span class="p">,</span> <span class="n">from_hf_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForMaskedLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;PaddlePaddle/ernie-1.0-base-zh&quot;</span><span class="p">,</span> <span class="n">from_hf_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">tokenizer</span><span class="o">.</span><span class="n">save_to_hf_hub</span><span class="p">(</span><span class="n">repo_id</span><span class="o">=</span><span class="s2">&quot;&lt;my_org_name&gt;/&lt;my_repo_name&gt;&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_to_hf_hub</span><span class="p">(</span><span class="n">repo_id</span><span class="o">=</span><span class="s2">&quot;&lt;my_org_name&gt;/&lt;my_repo_name&gt;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="rl-baselines3-zoo">
<h4>RL-Baselines3-Zoo<a class="headerlink" href="#rl-baselines3-zoo" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>rl-baselines3-zoo is a training framework for Reinforcement Learning using Stable Baselines3.</p></li>
<li><p>RL-Baselines3-Zoo official trained models: <a class="reference external" href="https://huggingface.co/sb3">https://huggingface.co/sb3</a></p></li>
<li><p>RL-Baselines3-Zoo documentation: <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">https://github.com/DLR-RM/rl-baselines3-zoo</a></p></li>
</ul>
<p>示例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Download ppo SpaceInvadersNoFrameskip-v4 model and save it into the logs/ folder</span>
<span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">rl_zoo3</span><span class="o">.</span><span class="n">load_from_hub</span> <span class="o">--</span><span class="n">algo</span> <span class="n">dqn</span> <span class="o">--</span><span class="n">env</span> <span class="n">SpaceInvadersNoFrameskip</span><span class="o">-</span><span class="n">v4</span> <span class="o">-</span><span class="n">f</span> <span class="n">logs</span><span class="o">/</span> <span class="o">-</span><span class="n">orga</span> <span class="n">sb3</span>
<span class="n">python</span> <span class="n">enjoy</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">algo</span> <span class="n">dqn</span> <span class="o">--</span><span class="n">env</span> <span class="n">SpaceInvadersNoFrameskip</span><span class="o">-</span><span class="n">v4</span>  <span class="o">-</span><span class="n">f</span> <span class="n">logs</span><span class="o">/</span>
</pre></div>
</div>
</section>
<section id="sample-factory">
<h4>Sample Factory<a class="headerlink" href="#sample-factory" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>sample-factory is a codebase for high throughput asynchronous reinforcement learning. It has integrations with the Hugging Face Hub to share models with evaluation results and training metrics.</p></li>
<li><p>Repository: <a class="reference external" href="https://github.com/alex-petrenko/sample-factory">https://github.com/alex-petrenko/sample-factory</a></p></li>
</ul>
<p>安装:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">sample</span><span class="o">-</span><span class="n">factory</span>
</pre></div>
</div>
<p>示例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">sample_factory</span><span class="o">.</span><span class="n">huggingface</span><span class="o">.</span><span class="n">load_from_hub</span> <span class="o">-</span><span class="n">r</span> <span class="o">&lt;</span><span class="n">HuggingFace_repo_id</span><span class="o">&gt;</span> <span class="o">-</span><span class="n">d</span> <span class="o">&lt;</span><span class="n">train_dir_path</span><span class="o">&gt;</span>
</pre></div>
</div>
</section>
<section id="sentence-transformers">
<h4>Sentence Transformers<a class="headerlink" href="#sentence-transformers" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>sentence-transformers is a library that provides easy methods to compute embeddings (dense vector representations) for sentences, paragraphs and images. Texts are embedded in a vector space such that similar text is close, which enables applications such as semantic search, clustering, and retrieval.</p></li>
</ul>
<figure class="align-default">
<a class="reference internal image-reference" href="https://img.zhaoweiguo.com/uPic/2023/07/WkkFtA.jpg"><img alt="https://img.zhaoweiguo.com/uPic/2023/07/WkkFtA.jpg" src="https://img.zhaoweiguo.com/uPic/2023/07/WkkFtA.jpg" style="width: 400px;" /></a>
</figure>
<ul class="simple">
<li><p>Sentence Transformers library: <a class="reference external" href="https://github.com/UKPLab/sentence-transformers">https://github.com/UKPLab/sentence-transformers</a></p></li>
<li><p>Sentence Transformers docs: <a class="reference external" href="https://www.sbert.net/">https://www.sbert.net/</a></p></li>
<li><p>Integration with Hub announcement: <a class="reference external" href="https://huggingface.co/blog/sentence-transformers-in-the-hub">https://huggingface.co/blog/sentence-transformers-in-the-hub</a></p></li>
</ul>
<p>示例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sentence_transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">SentenceTransformer</span><span class="p">,</span> <span class="n">util</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="s1">&#39;multi-qa-MiniLM-L6-cos-v1&#39;</span><span class="p">)</span>

<span class="n">query_embedding</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;How big is London&#39;</span><span class="p">)</span>
<span class="n">passage_embedding</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">([</span><span class="s1">&#39;London has 9,787,426 inhabitants at the 2011 census&#39;</span><span class="p">,</span>
                                  <span class="s1">&#39;London is known for its finacial district&#39;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Similarity:&quot;</span><span class="p">,</span> <span class="n">util</span><span class="o">.</span><span class="n">dot_score</span><span class="p">(</span><span class="n">query_embedding</span><span class="p">,</span> <span class="n">passage_embedding</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="spacy">
<h4>spaCy<a class="headerlink" href="#spacy" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>spaCy is a popular library for advanced Natural Language Processing used widely across industry. spaCy makes it easy to use and train pipelines for tasks like named entity recognition, text classification, part of speech tagging and more, and lets you build powerful applications to process and analyze large volumes of text.</p></li>
</ul>
<p>安装:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">spacy</span><span class="o">-</span><span class="n">huggingface</span><span class="o">-</span><span class="n">hub</span>
</pre></div>
</div>
<p>示例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Using spacy.load().</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">spacy</span>
<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;en_core_web_sm&quot;</span><span class="p">)</span>

<span class="c1"># Importing as module.</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">en_core_web_sm</span>
<span class="n">nlp</span> <span class="o">=</span> <span class="n">en_core_web_sm</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="spanmarker">
<h4>SpanMarker<a class="headerlink" href="#spanmarker" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>SpanMarker is a framework for training powerful Named Entity Recognition models using familiar encoders such as BERT, RoBERTa and DeBERTa. Tightly implemented on top of the 🤗 Transformers library, SpanMarker can take good advantage of it. As a result, SpanMarker will be intuitive to use for anyone familiar with Transformers.</p></li>
</ul>
<p>安装:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">U</span> <span class="n">span_marker</span>
</pre></div>
</div>
<ul class="simple">
<li><p>SpanMarker repository: <a class="reference external" href="https://github.com/tomaarsen/SpanMarkerNER">https://github.com/tomaarsen/SpanMarkerNER</a></p></li>
<li><p>SpanMarker docs: <a class="reference external" href="https://tomaarsen.github.io/SpanMarkerNER">https://tomaarsen.github.io/SpanMarkerNER</a></p></li>
</ul>
<p>示例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">span_marker</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpanMarkerModel</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SpanMarkerModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;tomaarsen/span-marker-bert-base-fewnerd-fine-super&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="speechbrain">
<h4>SpeechBrain<a class="headerlink" href="#speechbrain" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>speechbrain is an open-source and all-in-one conversational toolkit for audio/speech. The goal is to create a single, flexible, and user-friendly toolkit that can be used to easily develop state-of-the-art speech technologies, including systems for speech recognition, speaker recognition, speech enhancement, speech separation, language identification, multi-microphone signal processing, and many others.</p></li>
</ul>
<p>示例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torchaudio</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">speechbrain.pretrained</span><span class="w"> </span><span class="kn">import</span> <span class="n">EncoderClassifier</span>

<span class="n">classifier</span> <span class="o">=</span> <span class="n">EncoderClassifier</span><span class="o">.</span><span class="n">from_hparams</span><span class="p">(</span>
    <span class="n">source</span><span class="o">=</span><span class="s2">&quot;speechbrain/urbansound8k_ecapa&quot;</span>
<span class="p">)</span>
<span class="n">out_prob</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">text_lab</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">classify_file</span><span class="p">(</span><span class="s1">&#39;speechbrain/urbansound8k_ecapa/dog_bark.wav&#39;</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>SpeechBrain website: <a class="reference external" href="https://speechbrain.github.io/">https://speechbrain.github.io/</a></p></li>
<li><p>SpeechBrain docs: <a class="reference external" href="https://speechbrain.readthedocs.io/en/latest/index.html">https://speechbrain.readthedocs.io/en/latest/index.html</a></p></li>
</ul>
</section>
<section id="stable-baselines3">
<h4>Stable-Baselines3<a class="headerlink" href="#stable-baselines3" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>stable-baselines3 is a set of reliable implementations of reinforcement learning algorithms in PyTorch.</p></li>
</ul>
<p>安装:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">stable</span><span class="o">-</span><span class="n">baselines3</span>
<span class="n">pip</span> <span class="n">install</span> <span class="n">huggingface</span><span class="o">-</span><span class="n">sb3</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Hugging Face Stable-Baselines3 documentation: <a class="reference external" href="https://github.com/huggingface/huggingface_sb3#hugging-face--x-stable-baselines3-v20">https://github.com/huggingface/huggingface_sb3#hugging-face–x-stable-baselines3-v20</a></p></li>
<li><p>Stable-Baselines3 documentation: <a class="reference external" href="https://stable-baselines3.readthedocs.io/en/master/">https://stable-baselines3.readthedocs.io/en/master/</a></p></li>
</ul>
</section>
<section id="stanza">
<h4>Stanza<a class="headerlink" href="#stanza" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>stanza is a collection of accurate and efficient tools for the linguistic analysis of many human languages. Starting from raw text to syntactic analysis and entity recognition, Stanza brings state-of-the-art NLP models to languages of your choosing.</p></li>
<li><p>stanza docs: <a class="reference external" href="https://stanfordnlp.github.io/stanza/">https://stanfordnlp.github.io/stanza/</a></p></li>
</ul>
<p>示例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">stanza</span>

<span class="n">nlp</span> <span class="o">=</span> <span class="n">stanza</span><span class="o">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="s1">&#39;en&#39;</span><span class="p">)</span> <span class="c1"># download th English model and initialize an English neural pipeline</span>
<span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="s2">&quot;Barack Obama was born in Hawaii.&quot;</span><span class="p">)</span> <span class="c1"># run annotation over a sentence</span>
</pre></div>
</div>
</section>
<section id="tensorboard">
<h4>TensorBoard<a class="headerlink" href="#tensorboard" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>TensorBoard provides tooling for tracking and visualizing metrics as well as visualizing models. All repositories that contain TensorBoard traces have an automatic tab with a hosted TensorBoard instance for anyone to check it out without any additional effort!</p></li>
<li><p>TensorBoard documentation: <a class="reference external" href="https://www.tensorflow.org/tensorboard">https://www.tensorflow.org/tensorboard</a></p></li>
</ul>
</section>
<section id="timm">
<h4>timm<a class="headerlink" href="#timm" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>timm, also known as pytorch-image-models, is an open-source collection of state-of-the-art PyTorch image models, pretrained weights, and utility scripts for training, inference, and validation.</p></li>
</ul>
<figure class="align-default">
<a class="reference internal image-reference" href="https://img.zhaoweiguo.com/uPic/2023/07/neP2Ex.jpg"><img alt="https://img.zhaoweiguo.com/uPic/2023/07/neP2Ex.jpg" src="https://img.zhaoweiguo.com/uPic/2023/07/neP2Ex.jpg" style="width: 400px;" /></a>
</figure>
<p>示例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">timm</span>

<span class="c1"># Loading https://huggingface.co/timm/eca_nfnet_l0</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">timm</span><span class="o">.</span><span class="n">create_model</span><span class="p">(</span><span class="s2">&quot;hf-hub:timm/eca_nfnet_l0&quot;</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>timm (pytorch-image-models) GitHub Repo: <a class="reference external" href="https://github.com/rwightman/pytorch-image-models">https://github.com/rwightman/pytorch-image-models</a></p></li>
<li><p>timm documentation: <a class="reference external" href="https://huggingface.co/docs/timm">https://huggingface.co/docs/timm</a></p></li>
</ul>
</section>
<section id="transformers-js">
<h4>Transformers.js<a class="headerlink" href="#transformers-js" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>Transformers.js is a JavaScript library for running 🤗 Transformers directly in your browser, with no need for a server! It is designed to be functionally equivalent to the original Python library, meaning you can run the same pretrained models using a very similar API.</p></li>
</ul>
<p>安装:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">npm</span> <span class="n">i</span> <span class="nd">@xenova</span><span class="o">/</span><span class="n">transformers</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Transformers.js repository: <a class="reference external" href="https://github.com/xenova/transformers.js">https://github.com/xenova/transformers.js</a></p></li>
<li><p>Transformers.js docs: <a class="reference external" href="https://huggingface.co/docs/transformers.js">https://huggingface.co/docs/transformers.js</a></p></li>
<li><p>Transformers.js demo: <a class="reference external" href="https://xenova.github.io/transformers.js/">https://xenova.github.io/transformers.js/</a></p></li>
</ul>
<p>示例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">Use</span> <span class="n">a</span> <span class="n">different</span> <span class="n">model</span> <span class="k">for</span> <span class="n">sentiment</span><span class="o">-</span><span class="n">analysis</span>
<span class="n">let</span> <span class="n">pipe</span> <span class="o">=</span> <span class="k">await</span> <span class="n">pipeline</span><span class="p">(</span><span class="s1">&#39;sentiment-analysis&#39;</span><span class="p">,</span> <span class="s1">&#39;nlptown/bert-base-multilingual-uncased-sentiment&#39;</span><span class="p">);</span>
</pre></div>
</div>
</section>
</section>
<section id="widgets">
<h3>Widgets 部件<a class="headerlink" href="#widgets" title="此标题的永久链接">¶</a></h3>
<section id="widgets-examples">
<h4>Widgets examples<a class="headerlink" href="#widgets-examples" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p><a class="reference external" href="https://huggingface.co/spacy/en_core_web_sm?text=My+name+is+Sarah+and+I+live+in+London">Named Entity Recognition</a> using <a class="reference external" href="https://spacy.io/">spaCy</a>.</p></li>
<li><p><a class="reference external" href="https://huggingface.co/google/vit-base-patch16-224">Image Classification</a> using <a class="reference external" href="https://github.com/huggingface/transformers">🤗Transformers</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/julien-c/ljspeech_tts_train_tacotron2_raw_phn_tacotron_g2p_en_no_space_train">Text to Speech</a> using <a class="reference external" href="https://github.com/espnet/espnet">ESPnet</a>.</p></li>
<li><p><a class="reference external" href="https://huggingface.co/osanseviero/full-sentence-distillroberta3">Sentence Similarity</a> using <a class="reference external" href="https://github.com/UKPLab/sentence-transformers">Sentence Transformers</a>.</p></li>
<li><p>详细内容: <a class="reference external" href="https://huggingface.co/docs/hub/models-widgets#whats-a-widget">https://huggingface.co/docs/hub/models-widgets#whats-a-widget</a></p></li>
</ul>
</section>
<section id="some-links-to-examples">
<h4>some links to examples<a class="headerlink" href="#some-links-to-examples" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>text-classification, for instance <a class="reference external" href="https://huggingface.co/roberta-large-mnli">roberta-large-mnli</a></p></li>
<li><p>token-classification, for instance <a class="reference external" href="https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english">dbmdz/bert-large-cased-finetuned-conll03-english</a></p></li>
<li><p>question-answering, for instance <a class="reference external" href="https://huggingface.co/distilbert-base-uncased-distilled-squad">distilbert-base-uncased-distilled-squad</a></p></li>
<li><p>translation, for instance <a class="reference external" href="https://huggingface.co/t5-base">t5-base</a></p></li>
<li><p>summarization, for instance <a class="reference external" href="https://huggingface.co/facebook/bart-large-cnn">facebook/bart-large-cnn</a></p></li>
<li><p>conversational, for instance <a class="reference external" href="https://huggingface.co/facebook/blenderbot-400M-distill">facebook/blenderbot-400M-distill</a></p></li>
<li><p>text-generation, for instance <a class="reference external" href="https://huggingface.co/gpt2">gpt2</a></p></li>
<li><p>fill-mask, for instance <a class="reference external" href="https://huggingface.co/distilroberta-base">distilroberta-base</a></p></li>
<li><p>zero-shot-classification (implemented on top of a nli text-classification model), for instance <a class="reference external" href="https://huggingface.co/facebook/bart-large-mnli">facebook/bart-large-mnli</a></p></li>
<li><p>table-question-answering, for instance <a class="reference external" href="https://huggingface.co/google/tapas-base-finetuned-wtq">google/tapas-base-finetuned-wtq</a></p></li>
<li><p>sentence-similarity, for instance <a class="reference external" href="https://huggingface.co/osanseviero/full-sentence-distillroberta2">osanseviero/full-sentence-distillroberta2</a></p></li>
<li><p>详细内容: <a class="reference external" href="https://huggingface.co/docs/hub/models-widgets#what-are-all-the-possible-taskwidget-types">https://huggingface.co/docs/hub/models-widgets#what-are-all-the-possible-taskwidget-types</a></p></li>
</ul>
</section>
</section>
</section>
<section id="datasets">
<h2>Datasets<a class="headerlink" href="#datasets" title="此标题的永久链接">¶</a></h2>
<ul class="simple">
<li><p>🤗 Datasets documentation: <a class="reference external" href="https://huggingface.co/docs/datasets/index">https://huggingface.co/docs/datasets/index</a></p></li>
<li><p>dataset card: <a class="reference external" href="https://huggingface.co/docs/hub/datasets-cards">https://huggingface.co/docs/hub/datasets-cards</a></p></li>
<li><p>main datasets page: <a class="reference external" href="https://huggingface.co/datasets">https://huggingface.co/datasets</a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>打开指定数据集时，可以点击按钮``Use in dataset library``查看使用方法</p>
</div>
<section id="using-datasets">
<h3>Using Datasets<a class="headerlink" href="#using-datasets" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p>Some datasets on the Hub contain a loading script, which allows you to easily load the dataset when you need it.</p></li>
<li><p>Many datasets however do not need to include a loading script, for instance when their data is stored directly in the repository in formats such as CSV, JSON and Parquet. 🤗 Datasets can load those kinds of datasets automatically without a loading script.</p></li>
<li><p>tutorials: <a class="reference external" href="https://huggingface.co/docs/datasets/tutorial">https://huggingface.co/docs/datasets/tutorial</a></p></li>
<li><p>how-to guides: <a class="reference external" href="https://huggingface.co/docs/datasets/how_to">https://huggingface.co/docs/datasets/how_to</a></p></li>
<li><p>更多详情参见: Datasets documentation</p></li>
</ul>
</section>
<section id="adding-new-datasets">
<h3>Adding new datasets<a class="headerlink" href="#adding-new-datasets" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><dl class="simple">
<dt>三种方法:</dt><dd><ul>
<li><p>Add files manually to the repository through the UI</p></li>
<li><p>Push files with the <code class="docutils literal notranslate"><span class="pre">push_to_hub</span></code> method from 🤗 Datasets</p></li>
<li><p>Use Git to commit and push your dataset files</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
</section>
<section id="spaces">
<h2>Spaces<a class="headerlink" href="#spaces" title="此标题的永久链接">¶</a></h2>
<ul class="simple">
<li><p>Hugging Face Spaces: <a class="reference external" href="https://huggingface.co/spaces">https://huggingface.co/spaces</a></p></li>
</ul>
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference external" href="/index.html">主页</a></p></td>
<td><p><a class="reference internal" href="../../../genindex.html"><span class="std std-ref">索引</span></a></p></td>
<td><p><a class="reference internal" href="../../../py-modindex.html"><span class="std std-ref">模块索引</span></a></p></td>
<td><p><a class="reference internal" href="../../../search.html"><span class="std std-ref">搜索页面</span></a></p></td>
</tr>
</tbody>
</table>
</section>
</section>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="lib_python.html" class="btn btn-neutral float-right" title="Hub Python Library" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../normal.html" class="btn btn-neutral" title="7.3.1. 常用" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>
  
  <div id="gitalk-container"></div>
  <div role="contentinfo">
    <p>
        &copy; Copyright 2010-2025, 新溪-gordon.

    </p>
  </div>
  <div>备案号 <a href="http://www.beian.miit.gov.cn">京ICP备16018553号</a></div><div>Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a></div>. 


</footer>

<script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?042289284b8eb33866001347a3e0b129";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
</script>     
        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../',
            VERSION:'V2025.11',
            LANGUAGE:'zh-CN',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../../../_static/doctools.js"></script>
      <script type="text/javascript" src="../../../_static/sphinx_highlight.js"></script>
      <script type="text/javascript" src="../../../_static/clipboard.min.js"></script>
      <script type="text/javascript" src="../../../_static/copybutton.js"></script>
      <script type="text/javascript" src="../../../_static/translations.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>

  

  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });


      // var gitalk = new Gitalk({
      //         clientID: '565177626b5d46427009',
      //         clientSecret: 'b2a36e67e1d2a73e43667f46d571c2624f8e1026',
      //         repo: 'knowledge',
      //         owner: 'zhaoweiguo',
      //         admin: ['zhaoweiguo'],
      //         id: location.pathname,      // Ensure uniqueness and length less than 50
      //         distractionFreeMode: false  // Facebook-like distraction free mode
      //       })
      // gitalk.render('gitalk-container')

  </script>


<script type="text/javascript" src="../../../_static/js/table-of-contents-sidebar.js"></script>
<!-- <script type="text/javascript" src="https://table-of-contents-sidebar.github.io/table-of-contents-sidebar-lib/table-of-contents-sidebar.js"></script> -->
<script type="text/javascript">
    window.onload = function(e){
        TableOfContents.init({
            basePath: "https://table-of-contents-sidebar.github.io/table-of-contents-sidebar-lib/",
            querySelector: "body" // or other css querySelector
        });
    }
</script> 

</body>
</html>