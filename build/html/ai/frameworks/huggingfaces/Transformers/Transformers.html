

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="zh-CN" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="zh-CN" > <!--<![endif]-->
<head>


<!-- start added 2025-04-14   å¢åŠ å¯¹markdownä¸­å…¬å¼çš„æ”¯æŒ -->
<script>
window.MathJax = {
    tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true
    },
    options: {
        ignoreHtmlClass: "tex2jax_ignore|mathjax_ignore",
        processHtmlClass: "tex2jax_process|mathjax_process|math|output_area"
    }
};
</script>
<script defer="defer" src="https://fastly.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<!-- end added 2025-04-14   å¢åŠ å¯¹markdownä¸­å…¬å¼çš„æ”¯æŒ -->


  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Transformers &mdash; æ–°æºª-gordon V2025.06 æ–‡æ¡£</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
    <link rel="index" title="ç´¢å¼•" href="../../../genindex.html" />
    <link rel="search" title="æœç´¢" href="../../../search.html" />
    <link rel="next" title="Transformers 4.45.2" href="Transformers_V4.45.2.html" />
    <link rel="prev" title="7.3.2. Transformers" href="../Transformers.html" /> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>
  <script src="../../../_static/js/jquery.min.js"></script>


<!-- è¯„è®ºæ’ä»¶ gittalk start -->
<!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script> -->
<!-- è¯„è®ºæ’ä»¶ gittalk end -->


</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../index.html" class="icon icon-home"> æ–°æºª-gordon
          

          
          </a>

          
            
            
              <div class="version">
                V2025.06
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">AI</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../normal.html">1. å¸¸ç”¨</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../normals/normal.html">1.1. å¸¸ç”¨</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../normals/AIGC.html">1.2. AIGC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../normals/ml.html">1.3. æœºå™¨å­¦ä¹ machine learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../normals/bi.html">1.4. BI(Business Intelligence)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../normals/deep_learning.html">1.5. æ·±åº¦å­¦ä¹ </a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../normals/deep_learnings/normal.html">1.5.1. å¸¸ç”¨</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../normals/deep_learnings/history.html">1.5.2. å†å²</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../normals/monitor.html">1.6. monitor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../normals/algorithm.html">1.7. ç›¸å…³ç®—æ³•</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../normals/tool.html">1.8. å·¥å…·</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../normals/question.html">1.9. å¸¸è§é—®é¢˜</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../normals/%E6%9C%BA%E5%99%A8%E4%BA%BA.html">1.10. æœºå™¨äººé¢†åŸŸ</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../theory.html">2. ç†è®º</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../theories/tmp.html">2.1. ä¸´æ—¶</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/ReAct.html">2.1.1. ReActæ¡†æ¶</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/Reflection.html">2.1.2. Reflectionåæ€</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/math.html">2.1.3. æ•°å­¦</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/bag-of-words.html">2.1.4. bag-of-words</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/word2vec.html">2.1.5. Word2Vec</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/doc2vec.html">2.1.6. Doc2Vec</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/FastText.html">2.1.7. FastText</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/LDA.html">2.1.8. LDA-Latent Dirichlet Allocation(æ½œåœ¨ç‹„åˆ©å…‹é›·åˆ†é…)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/overfitting-underfitting.html">2.1.9. overfitting&amp;underfitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/RAG.html">2.1.10. RAG</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/Agent.html">2.1.11. Agent</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/LLM.html">2.1.12. LLM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/RL.html">2.1.13. RL-å¼ºåŒ–å­¦ä¹ </a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/prompt_engineering.html">2.1.14. Prompt Engineering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/finetune.html">2.1.15. LLMè°ƒä¼˜(finetune)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../theories/tmps/Workflow.html">2.1.16. Workflow</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../LLM.html">3. å¤§æ¨¡å‹</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../LLMs/normal.html">3.1. å¸¸ç”¨</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/normals/normal.html">3.1.1. å¸¸ç”¨</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/normals/package.html">3.1.2. ä¾èµ–å®‰è£…</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/normals/encoder.html">3.1.3. ç¼–ç -è§£ç å™¨</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/normals/usage.html">3.1.4. ä½¿ç”¨</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/normals/tmp.html">3.1.5. ä¸´æ—¶</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../LLMs/model.html">3.2. è‘—åæ¨¡å‹</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/models/Qwen3.html">3.2.1. Qwen3</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/models/DeepSeek.html">3.2.2. DeepSeek-R1-æ¨ç†æ¨¡å‹</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/models/LLaMA.html">3.2.3. LLaMA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/models/ChatGLM.html">3.2.4. ChatGLM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/models/BERT.html">3.2.5. BERT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/models/OpenAI.html">3.2.6. OpenAI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/models/BART.html">3.2.7. BART</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/models/T5.html">3.2.8. T5</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/models/ChatRWKV.html">3.2.9. ChatRWKV</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/models/Open-Assistant.html">3.2.10. Open-Assistant</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/models/OpenGVLab.html">3.2.11. OpenGVLab</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../LLMs/finetune.html">3.3. è°ƒä¼˜</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../LLMs/Quantization%E9%87%8F%E5%8C%96.html">3.4. æ¨¡å‹é‡åŒ–(Quantization)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/Quantizations/normal.html">3.4.1. å¸¸ç”¨</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/Quantizations/GGUF.html">3.4.2. GGUF æ–‡ä»¶</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../LLMs/fileformat.html">3.5. æ–‡ä»¶æ ¼å¼</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/fileformats/normal.html">3.5.1. é€šç”¨</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/fileformats/GGML.html">3.5.2. GGMLç³»åˆ—æ–‡ä»¶æ ¼å¼</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/fileformats/ONNX.html">3.5.3. ONNX</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../LLMs/fileformats/ONNXs/normal.html">å¸¸ç”¨</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../LLMs/fileformats/ONNXs/ONNX.html">ONNX</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../LLMs/fileformats/ONNXs/onnxruntime.html">onnxruntime</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../LLMs/fileformats/ONNXs/skl2onnx.html">skl2onnx</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/fileformats/NCNN.html">3.5.4. NCNN</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../LLMs/openai.html">3.6. å•†ä¸šé¡¹ç›®</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/openais/normal.html">3.6.1. å¸¸ç”¨</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/openais/openai.html">3.6.2. OpenAI</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../LLMs/prompt.html">3.7. Prompt æç¤ºè¯</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/prompts/demo_chinese.html">3.7.1. ä¸­æ–‡</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/prompts/demo_english.html">3.7.2. English</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/prompts/skill.html">3.7.3. ç¤ºä¾‹</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../LLMs/Android.html">3.8. Androidç‰ˆLLMç›¸å…³</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/Androids/normal.html">3.8.1. å¸¸ç”¨</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/Androids/Android%E7%89%88%E9%83%A8%E7%BD%B2.html">3.8.2. Androidç‰ˆéƒ¨ç½²</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LLMs/Androids/GPU.html">3.8.3. GPU</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../RAG.html">4. RAGç›¸å…³</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../NLP.html">5. NLP</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../NLPs/normal.html">5.1. å¸¸ç”¨</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../NLPs/preprocess.html">5.2. é¢„å¤„ç†</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../NLPs/preprocesses/normal.html">5.2.1. å¸¸ç”¨</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../NLPs/preprocesses/%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E5%8F%96.html">5.2.2. å…³é”®è¯æå–</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../NLPs/preprocesses/%E5%88%86%E8%AF%8D.html">5.2.3. åˆ†è¯</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../NLPs/preprocesses/%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90.html">5.2.4. æƒ…æ„Ÿåˆ†æ</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../NLPs/preprocesses/%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA.html">5.2.5. æ–‡æœ¬è¡¨ç¤º</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../NLPs/preprocesses/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6.html">5.2.6. æ³¨æ„åŠ›æœºåˆ¶</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../NLPs/preprocesses/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B.html">5.2.7. è¯­è¨€æ¨¡å‹</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../NLPs/NER.html">5.3. NER-å‘½åå®ä½“è¯†åˆ«</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../NLPs/NERs/normal.html">5.3.1. å¸¸ç”¨</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../NLPs/NERs/seq-label.html">5.3.2. åºåˆ—æ ‡æ³¨</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../NLPs/NERs/BiLSTM%2BCRF.html">5.3.3. BiLSTM+CRF</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../NLPs/NERs/history.html">5.3.4. å†å²</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../NLPs/summary.html">5.4. æ€»ç»“-æ‘˜è¦</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../NLPs/summarys/normal.html">5.4.1. é€šç”¨</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../library.html">6. å‡½æ•°åº“</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/normal.html">6.1. å¸¸ç”¨</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/Image.html">6.2. Imageå›¾åƒå¤„ç†</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/Video.html">6.3. Videoè§†é¢‘</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/IPython.html">6.4. IPython</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/IPythons/normal.html">6.4.1. å¸¸ç”¨</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/IPythons/magic.html">6.4.2. é­”æ³•å‘½ä»¤ </a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/IPythons/display.html">6.4.3. displayå‡½æ•°</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/Jupyter.html">6.5. Jupyter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/NumPy.html">6.6. NumPy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/NumPys/normal.html">6.6.1. é€šç”¨</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/NumPys/Ndarray.html">6.6.2. Ndarray å¯¹è±¡</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/NumPys/function.html">6.6.3. é€šç”¨å‡½æ•°</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/Pandas.html">6.7. Pandas</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Pandas/normal.html">6.7.1. å¸¸ç”¨</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Pandas/example_subset.html">6.7.2. å®ä¾‹-subset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Pandas/example_analysis.html">6.7.3. å®ä¾‹-ç»Ÿè®¡åˆ†æ</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Pandas/example_sql.html">6.7.4. åˆ©ç”¨pandaså®ç°SQLæ“ä½œ</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Pandas/example_default_value.html">6.7.5. å®ä¾‹-ç¼ºå¤±å€¼çš„å¤„ç†</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Pandas/example_multi_index.html">6.7.6. å¤šå±‚ç´¢å¼•çš„ä½¿ç”¨</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Pandas/practice.html">6.7.7. å®è·µ</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../libraries/Pandas/practices/practice_2012ObamaElect.html">å®è·µ-2012å¹´å¥¥å·´é©¬æ€»ç»Ÿè¿ä»»é€‰ä¸¾</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Pandas/api_input_output.html">6.7.8. API-è¾“å…¥è¾“å‡º</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Pandas/api_General.html">6.7.9. API-General functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Pandas/api_Series.html">6.7.10. API-Series</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Pandas/api_DataFrame.html">6.7.11. API-DataFrame</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Pandas/api_Index.html">6.7.12. API-index</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/Matplotlib.html">6.8. Matplotlib</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Matplotlibs/normal.html">6.8.1. åŸºæœ¬</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Matplotlibs/install.html">6.8.2. å®‰è£…</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Matplotlibs/pyplot.html">6.8.3. pyplot </a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Matplotlibs/matplotlib.patches.html">6.8.4. matplotlib.patches</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Matplotlibs/example.html">6.8.5. å®ä¾‹</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../libraries/Matplotlibs/examples/plot.html">æŠ˜çº¿å›¾plot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../libraries/Matplotlibs/examples/bar.html">æ¡å½¢å›¾bar</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../libraries/Matplotlibs/examples/hist.html">ç›´æ–¹å›¾hist</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../libraries/Matplotlibs/examples/scatter.html">æ•£ç‚¹å›¾scatter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../libraries/Matplotlibs/examples/stackplot.html">é¢ç§¯å›¾stackplot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../libraries/Matplotlibs/examples/pie.html">é¥¼å›¾pie</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../libraries/Matplotlibs/examples/box.html">ç®±å‹å›¾box</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../libraries/Matplotlibs/examples/multi.html">å¤šå›¾åˆå¹¶multi</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Matplotlibs/pylab.html">6.8.6. pylabå­åŒ…</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/SciPy.html">6.9. SciPy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/SciPys/normal.html">6.9.1. å¸¸ç”¨</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/sklearn.html">6.10. sklearn</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/sklearns/normal.html">6.10.1. å¸¸ç”¨</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/sklearns/supervised.html">6.10.2. ç›‘ç£å­¦ä¹ </a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../libraries/sklearns/superviseds/glm.html">å¹¿ä¹‰çº¿æ€§æ¨¡å‹</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/sklearns/unsupervised.html">6.10.3. æ— ç›‘ç£å­¦ä¹ </a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/statsmodels.html">6.11. statsmodels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/OpenCV.html">6.12. OpenCV</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/OpenCVs/normal.html">6.12.1. å¸¸ç”¨</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/OpenCVs/example.html">6.12.2. å®ä¾‹</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/OpenCVs/struct.html">6.12.3. ä»£ç ç±»ç»“æ„</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/Seaborn.html">6.13. Seaborn</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/Seaborns/normal.html">6.13.1. å¸¸ç”¨</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/jieba.html">6.14. jiebaä¸­æ–‡åˆ†è¯</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/gensim.html">6.15. gensim: æ–‡æœ¬ä¸»é¢˜å»ºæ¨¡å’Œç›¸ä¼¼æ€§åˆ†æ</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/gensims/normal.html">6.15.1. å¸¸ç”¨</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/gensims/Core_Tutorials.html">6.15.2. Core Tutorials</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/gensims/Tutorials.html">6.15.3. Tutorials: Learning Oriented Lessons</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../libraries/gensims/How-to_Guides.html">6.15.4. How-to Guides: Solve a Problem</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../libraries/LAC.html">6.16. LAC-ç™¾åº¦è¯æ³•åˆ†æå·¥å…·</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../../../framework.html">7. å­¦ä¹ æ¡†æ¶</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../normal.html">7.1. å¸¸ç”¨</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../pytorch.html">7.2. PyTorch</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../pytorchs/normal.html">7.2.1. å¸¸ç”¨</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../pytorchs/nn.html">7.2.2. nnæ¨¡å—</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../pytorchs/PyTorch.html">7.2.3. PyTorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../pytorchs/ExecuTorch.html">7.2.4. ExecuTorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../pytorchs/torchrun.html">7.2.5. torchrun (Elastic Launch)</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="../../huggingface.html">7.3. huggingface</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../normal.html">7.3.1. å¸¸ç”¨</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../normals/huggingface_hub.html">Hugging Face Hub</a></li>
<li class="toctree-l4"><a class="reference internal" href="../normals/lib_python.html">Hub Python Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../normals/Datasets.html">Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../normals/Text_Generation_Inference_main.html">TGI: Text Generation Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../normals/Evaluate.html">Evaluate</a></li>
</ul>
</li>
<li class="toctree-l3 current"><a class="reference internal" href="../Transformers.html">7.3.2. Transformers</a><ul class="current">
<li class="toctree-l4 current"><a class="current reference internal" href="#">Transformers</a></li>
<li class="toctree-l4"><a class="reference internal" href="Transformers_V4.45.2.html">Transformers 4.45.2</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Tokenizers_V0.13.3.html">7.3.3. Tokenizers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../PEFT.html">7.3.4. PEFT</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../PEFT/PEFT.html">PEFT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../PEFT/PEFT_V0.13.0.html">PEFT 0.13.0</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Accelerate.html">7.3.5. Accelerate</a></li>
<li class="toctree-l3"><a class="reference internal" href="../TRL.html">7.3.6. TRL - Transformer Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../collect.html">7.3.7. æ”¶é›†</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../collects/resources.html">resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../collects/model.html">model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../collects/blog_decoding-methods.html">åšæ–‡: decoding methods of LLM with transformers</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../vLLM.html">7.4. vLLM</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../vLLMs/normal.html">7.4.1. å¸¸ç”¨</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../vLLMs/vLLM_doc.html">7.4.2. vLLMå®˜æ–¹æ–‡æ¡£</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../llama.cpp.html">7.5. llama.cppæ¡†æ¶</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../llama.cpps/normal.html">7.5.1. å¸¸ç”¨</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../llama.cpps/llama-cpp-python.html">7.5.2. Python bindings for llama.cpp</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../DeepSpeed.html">7.6. DeepSpeed</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../DeepSpeeds/huggingface.html">7.6.1. huggingface</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../DeepSpeeds/ZeRO.html">7.6.2. Zero Redundancy Optimizer (ZeRO)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../DeepSpeeds/deepspeed_doc.html">7.6.3. DeepSpeed</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../mxnet.html">7.7. mxnetåº“</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../mxnets/ndarray.html">7.7.1. ndæ¨¡å—</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../mxnets/ndarrays/ndarray.html">ndarray</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../mxnets/ndarrays/ndarray.random.html">ndarray.random</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnets/gluon.html">7.7.2. gluonæ¨¡å—</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../mxnets/autograd.html">7.7.3. autogradæ¨¡å—</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../tensorflow.html">7.8. tensorflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Keras.html">7.9. Keras</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Keras/normal.html">7.9.1. å¸¸ç”¨</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Keras/demo.html">7.9.2. å®ä¾‹</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Keras/demos/binary_classification.html">äºŒåˆ†ç±»é—®é¢˜</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Keras/demos/multiclass_classification.html">å¤šåˆ†ç±»é—®é¢˜</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Keras/demos/regression.html">å›å½’é—®é¢˜</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../other.html">7.10. å…¶ä»–</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../website.html">8. å…³é”®ç½‘ç«™</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../websites/Papers%20with%20Code.html">8.1. Papers with Code</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../websites/Kaggle.html">8.2. Kaggle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../websites/ArXiv.html">8.3. ArXiv å­¦æœ¯è®ºæ–‡é¢„å°æœ¬å¹³å°</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../websites/video.html">8.4. è§†é¢‘ç›¸å…³</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../websites/normal.html">8.5. é€šç”¨</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../practice.html">9. å®è·µ</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../practices/OCR.html">9.1. OCR</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../practices/OCRs/normal.html">9.1.1. å¸¸ç”¨</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../practices/AIML.html">9.2. AIML</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../practices/AIMLs/normal.html">9.2.1. å¸¸ç”¨</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../practices/AIMLs/spec.html">9.2.2. AIML 2.1 Documentation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../opensource.html">10. å¼€æºé¡¹ç›®</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../opensources/Agent.html">10.1. Agent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../opensources/RAG.html">10.2. RAG</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../opensources/normal.html">10.3. å¸¸ç”¨</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../opensources/ui.html">10.4. UIç•Œé¢</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../opensources/finetune.html">10.5. è°ƒä¼˜</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../opensources/search.html">10.6. æœç´¢</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../opensources/LLM-Inference-Engine.html">10.7. LLM Inference Engines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../opensources/LLM-Inference-Tool.html">10.8. æ¨¡å‹æ¨ç†å¹³å°</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../opensources/LLM-inference-accelerate.html">10.9. LLMæ¨ç†åŠ é€Ÿ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../opensources/Evaluate.html">10.10. LLMè¯„ä¼°</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../opensources/platform.html">10.11. AIå¹³å°</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../dataset.html">11. æ•°æ®é›†</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../datasets/normal.html">11.1. å¸¸ç”¨</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../datasets/chinese.html">11.2. ä¸­æ–‡æ•°æ®é›†</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../datasets/chinese_image.html">11.3. ä¸­æ–‡å›¾ç‰‡ç›¸å…³æ•°æ®é›†</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../datasets/huggingface.html">11.4. dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../datasets/website.html">11.5. æ•°æ®é›†ç›¸å…³ç½‘ç«™</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../model.html">12. å¸¸è§æ¨¡å‹</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cuda.html">13. å›¾å½¢&amp;è®¡ç®—åŠ é€ŸæŠ€æœ¯</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../cudas/normal.html">13.1. å¸¸ç”¨</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../cudas/cuda.html">13.2. cuda</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../Evaluate.html">14. Evaluateè¯„æµ‹</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../Evaluates/normal.html">14.1. é€šç”¨</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../Evaluates/TruLens.html">14.2. TruLens</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../Evaluates/Ragas.html">14.3. Ragas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../Evaluates/DeepEval.html">14.4. DeepEval</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../Evaluates/UpTrain.html">14.5. UpTrain</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../Evaluates/huggingface.html">14.6. evaluate</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../%E4%BC%A0%E7%BB%9FAI.html">15. ä¼ ç»ŸAI</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">æ–°æºª-gordon</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../../framework.html"><span class="section-number">7. </span>å­¦ä¹ æ¡†æ¶</a> &raquo;</li>
        
          <li><a href="../../huggingface.html"><span class="section-number">7.3. </span>huggingface</a> &raquo;</li>
        
          <li><a href="../Transformers.html"><span class="section-number">7.3.2. </span>Transformers</a> &raquo;</li>
        
      <li>Transformers</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../../_sources/frameworks/huggingfaces/Transformers/Transformers.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            <nav id="local-table-of-contents" role="navigation" aria-labelledby="local-table-of-contents-title">
              <h4 id="local-table-of-contents-title">On This Page</h4>
              <ul>
<li><a class="reference internal" href="#">Transformers</a><ul>
<li><a class="reference internal" href="#id2">ç®€ä»‹</a></li>
<li><a class="reference internal" href="#get-started">GET STARTED</a><ul>
<li><a class="reference internal" href="#quick-tour">Quick tour</a><ul>
<li><a class="reference internal" href="#pipeline">Pipeline</a></li>
<li><a class="reference internal" href="#autoclass">AutoClass</a></li>
<li><a class="reference internal" href="#custom-model-builds">Custom model builds</a></li>
<li><a class="reference internal" href="#trainer">Trainer</a></li>
</ul>
</li>
<li><a class="reference internal" href="#installation">Installation</a></li>
<li><a class="reference internal" href="#id3">ç¯å¢ƒå˜é‡</a><ul>
<li><a class="reference internal" href="#fetch-models-and-tokenizers-to-use-offline">Fetch models and tokenizers to use offline</a><ul>
<li><a class="reference internal" href="#use-the-from-pretrained-and-save-pretrained-workflow">Use the from_pretrained() and save_pretrained() workflow</a></li>
<li><a class="reference internal" href="#programmatically-download-files-with-the-huggingface-hub-library">Programmatically download files with the huggingface_hub library</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#tutorials">TUTORIALS</a><ul>
<li><a class="reference internal" href="#pipelines-for-inference">Pipelines for inference</a></li>
<li><a class="reference internal" href="#load-pretrained-instances-with-an-autoclass">Load pretrained instances with an AutoClass</a><ul>
<li><a class="reference internal" href="#autotokenizer">AutoTokenizer</a></li>
<li><a class="reference internal" href="#autoimageprocessor">AutoImageProcessor</a></li>
<li><a class="reference internal" href="#autofeatureextractor">AutoFeatureExtractor</a></li>
<li><a class="reference internal" href="#autoprocessor">AutoProcessor</a></li>
<li><a class="reference internal" href="#automodel">AutoModel</a></li>
</ul>
</li>
<li><a class="reference internal" href="#preprocess-data">Preprocess data</a><ul>
<li><a class="reference internal" href="#natural-language-processing">Natural Language Processing</a><ul>
<li><a class="reference internal" href="#pad">Pad</a></li>
<li><a class="reference internal" href="#truncation">Truncation</a></li>
<li><a class="reference internal" href="#build-tensors">Build tensors</a></li>
</ul>
</li>
<li><a class="reference internal" href="#audio">Audio</a><ul>
<li><a class="reference internal" href="#pading">Pading</a></li>
</ul>
</li>
<li><a class="reference internal" href="#computer-vision">Computer vision</a><ul>
<li><a class="reference internal" href="#image-augmentation">image augmentation</a></li>
<li><a class="reference internal" href="#id4">Pading</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#fine-tune-a-pretrained-model">Fine-tune a pretrained model</a><ul>
<li><a class="reference internal" href="#train-with-pytorch-trainer">Train with PyTorch Trainer</a><ul>
<li><a class="reference internal" href="#training-hyperparameters">Training hyperparameters</a></li>
<li><a class="reference internal" href="#evaluate">Evaluate</a></li>
<li><a class="reference internal" href="#id6">Trainer</a></li>
</ul>
</li>
<li><a class="reference internal" href="#train-in-native-pytorch">Train in native PyTorch</a><ul>
<li><a class="reference internal" href="#dataloader">DataLoader</a></li>
<li><a class="reference internal" href="#optimizer-and-learning-rate-scheduler">Optimizer and learning rate scheduler</a></li>
<li><a class="reference internal" href="#training-loop">Training loop</a></li>
<li><a class="reference internal" href="#id7">Evaluate</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#train-with-a-script">Train with a script</a></li>
<li><a class="reference internal" href="#distributed-training-with-accelerate">Distributed training with Accelerate</a><ul>
<li><a class="reference internal" href="#backward">Backward</a></li>
</ul>
</li>
<li><a class="reference internal" href="#transformers-agent">Transformers Agent</a><ul>
<li><a class="reference internal" href="#id8">ç¤ºä¾‹</a></li>
<li><a class="reference internal" href="#quickstart">Quickstart</a><ul>
<li><a class="reference internal" href="#single-execution-run">Single execution (run)</a></li>
<li><a class="reference internal" href="#chat-based-execution-chat">Chat-based execution (chat)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id9">åŸç†</a><ul>
<li><a class="reference internal" href="#agents">Agents</a></li>
<li><a class="reference internal" href="#tools">Tools</a></li>
</ul>
</li>
<li><a class="reference internal" href="#resource">Resource</a><ul>
<li><a class="reference internal" href="#a-curated-set-of-tools">A curated set of tools</a></li>
<li><a class="reference internal" href="#custom-tools">Custom tools</a></li>
</ul>
</li>
<li><a class="reference internal" href="#code-generation">Code generation</a></li>
<li><a class="reference internal" href="#practice">Practice</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#task-guides">TASK GUIDES</a><ul>
<li><a class="reference internal" href="#id11">NATURAL LANGUAGE PROCESSING</a></li>
<li><a class="reference internal" href="#id12">AUDIO</a></li>
<li><a class="reference internal" href="#id13">COMPUTER VISION</a></li>
<li><a class="reference internal" href="#multimodal">MULTIMODAL</a></li>
</ul>
</li>
<li><a class="reference internal" href="#developer-guides">DEVELOPER GUIDES</a><ul>
<li><a class="reference internal" href="#transformers-notebooks-with-examples">Transformers Notebooks with examples</a></li>
<li><a class="reference internal" href="#community-resources">Community resources</a></li>
</ul>
</li>
<li><a class="reference internal" href="#performance-and-scalability">PERFORMANCE AND SCALABILITY</a></li>
<li><a class="reference internal" href="#conceptual-guides">CONCEPTUAL GUIDES</a><ul>
<li><a class="reference internal" href="#philosophy">Philosophy</a><ul>
<li><a class="reference internal" href="#main-concepts">Main concepts</a></li>
</ul>
</li>
<li><a class="reference internal" href="#glossary">Glossary</a><ul>
<li><a class="reference internal" href="#feed-forward-chunking">feed forward chunking</a></li>
<li><a class="reference internal" href="#image-patch">image patch</a></li>
</ul>
</li>
<li><a class="reference internal" href="#how-transformers-solve-tasks">How Transformers solve tasks</a></li>
<li><a class="reference internal" href="#the-transformer-model-family">The Transformer model family</a><ul>
<li><a class="reference internal" href="#id14">Computer vision</a></li>
<li><a class="reference internal" href="#id15">Natural language processing</a></li>
<li><a class="reference internal" href="#id16">Audio</a></li>
<li><a class="reference internal" href="#id17">Multimodal</a></li>
<li><a class="reference internal" href="#reinforcement-learning">Reinforcement learning</a></li>
</ul>
</li>
<li><a class="reference internal" href="#summary-of-the-tokenizers">Summary of the tokenizers</a></li>
<li><a class="reference internal" href="#padding-and-truncation">Padding and truncation</a></li>
<li><a class="reference internal" href="#model-training-anatomy">Model training anatomy</a><ul>
<li><a class="reference internal" href="#anatomy-of-models-operations">Anatomy of Modelâ€™s Operations</a></li>
<li><a class="reference internal" href="#anatomy-of-models-memory">Anatomy of Modelâ€™s Memory</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#api">API</a><ul>
<li><a class="reference internal" href="#main-classes">MAIN CLASSES</a><ul>
<li><a class="reference internal" href="#id18">Agents</a></li>
<li><a class="reference internal" href="#auto-classes">Auto Classes</a></li>
<li><a class="reference internal" href="#callbacks">Callbacks</a></li>
<li><a class="reference internal" href="#logging">Logging</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
  <table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference external" href="/index.html">ä¸»é¡µ</a></p></td>
<td><p><a class="reference internal" href="../../../genindex.html"><span class="std std-ref">ç´¢å¼•</span></a></p></td>
<td><p><a class="reference internal" href="../../../py-modindex.html"><span class="std std-ref">æ¨¡å—ç´¢å¼•</span></a></p></td>
<td><p><a class="reference internal" href="../../../search.html"><span class="std std-ref">æœç´¢é¡µé¢</span></a></p></td>
</tr>
</tbody>
</table>
<section id="transformers">
<h1>Transformers<a class="headerlink" href="#transformers" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h1>
<div class="admonition note">
<p class="admonition-title">å¤‡æ³¨</p>
<p>æœ¬æ–‡æ¡£æ˜¯å‚è€ƒè‡ª <code class="docutils literal notranslate"><span class="pre">v4.34.1</span></code> ç‰ˆæœ¬</p>
</div>
<ul class="simple">
<li><p>from: <a class="reference external" href="https://huggingface.co/docs/transformers/v4.23.1/en/index">https://huggingface.co/docs/transformers/v4.23.1/en/index</a></p></li>
</ul>
<section id="id2">
<h2>ç®€ä»‹<a class="headerlink" href="#id2" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<ol class="arabic">
<li><p>GET STARTED:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">provides</span> <span class="n">a</span> <span class="n">quick</span> <span class="n">tour</span> <span class="n">of</span> <span class="n">the</span> <span class="n">library</span> <span class="ow">and</span> <span class="n">installation</span> <span class="n">instructions</span> <span class="n">to</span> <span class="n">get</span> <span class="n">up</span> <span class="ow">and</span> <span class="n">running</span><span class="o">.</span>
</pre></div>
</div>
</li>
<li><p>TUTORIALS:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>are a great place to start if youâ€™re a beginner.
This section will help you gain the basic skills you need to start using the library.
</pre></div>
</div>
</li>
<li><p>HOW-TO GUIDES:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">show</span> <span class="n">you</span> <span class="n">how</span> <span class="n">to</span> <span class="n">achieve</span> <span class="n">a</span> <span class="n">specific</span> <span class="n">goal</span><span class="p">,</span>
<span class="n">like</span> <span class="n">finetuning</span> <span class="n">a</span> <span class="n">pretrained</span> <span class="n">model</span> <span class="k">for</span> <span class="n">language</span> <span class="n">modeling</span>
<span class="ow">or</span> <span class="n">how</span> <span class="n">to</span> <span class="n">write</span> <span class="ow">and</span> <span class="n">share</span> <span class="n">a</span> <span class="n">custom</span> <span class="n">model</span><span class="o">.</span>
</pre></div>
</div>
</li>
<li><p>CONCEPTUAL GUIDES:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>offers more discussion and explanation of the underlying concepts
    and ideas behind models, tasks, and the design philosophy of ğŸ¤— Transformers.
</pre></div>
</div>
</li>
<li><p>API: describes all classes and functions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">MAIN</span> <span class="n">CLASSES</span>
    <span class="n">details</span> <span class="n">the</span> <span class="n">most</span> <span class="n">important</span> <span class="n">classes</span> <span class="n">like</span> <span class="n">configuration</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="ow">and</span> <span class="n">pipeline</span><span class="o">.</span>
<span class="n">MODELS</span>
    <span class="n">details</span> <span class="n">the</span> <span class="n">classes</span> <span class="ow">and</span> <span class="n">functions</span> <span class="n">related</span> <span class="n">to</span> <span class="n">each</span> <span class="n">model</span> <span class="n">implemented</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">library</span><span class="o">.</span>
<span class="n">INTERNAL</span>
    <span class="n">HELPERS</span> <span class="n">details</span> <span class="n">utility</span> <span class="n">classes</span> <span class="ow">and</span> <span class="n">functions</span> <span class="n">used</span> <span class="n">internally</span><span class="o">.</span>
</pre></div>
</div>
</li>
</ol>
</section>
<section id="get-started">
<h2>GET STARTED<a class="headerlink" href="#get-started" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<section id="quick-tour">
<h3>Quick tour<a class="headerlink" href="#quick-tour" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>å®‰è£…:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">transformers</span> <span class="n">datasets</span>
<span class="c1"># optional</span>
<span class="n">sentiment</span>
<span class="n">pip</span> <span class="n">install</span> <span class="n">tensorflow</span>
</pre></div>
</div>
<section id="pipeline">
<h4>Pipeline<a class="headerlink" href="#pipeline" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>Task List:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">+------------------------------+-----------------+-----------------------------------------------+</span>
<span class="o">|</span> <span class="n">Task</span>                         <span class="o">|</span> <span class="n">Modality</span>        <span class="o">|</span> <span class="n">Pipeline</span> <span class="n">identifier</span>                           <span class="o">|</span>
<span class="o">+==============================+=================+===============================================+</span>
<span class="o">|</span> <span class="n">Text</span> <span class="n">classification</span>          <span class="o">|</span> <span class="n">NLP</span>             <span class="o">|</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;sentiment-analysis&quot;</span><span class="p">)</span>           <span class="o">|</span>
<span class="o">+------------------------------+-----------------+-----------------------------------------------+</span>
<span class="o">|</span> <span class="n">Text</span> <span class="n">generation</span>              <span class="o">|</span> <span class="n">NLP</span>             <span class="o">|</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;text-generation&quot;</span><span class="p">)</span>              <span class="o">|</span>
<span class="o">+------------------------------+-----------------+-----------------------------------------------+</span>
<span class="o">|</span> <span class="n">Summarization</span>                <span class="o">|</span> <span class="n">NLP</span>             <span class="o">|</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;summarization&quot;</span><span class="p">)</span>                <span class="o">|</span>
<span class="o">+------------------------------+-----------------+-----------------------------------------------+</span>
<span class="o">|</span> <span class="n">Image</span> <span class="n">classification</span>         <span class="o">|</span> <span class="n">Computer</span> <span class="n">vision</span> <span class="o">|</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;image-classification&quot;</span><span class="p">)</span>         <span class="o">|</span>
<span class="o">+------------------------------+-----------------+-----------------------------------------------+</span>
<span class="o">|</span> <span class="n">Image</span> <span class="n">segmentation</span>           <span class="o">|</span> <span class="n">Computer</span> <span class="n">vision</span> <span class="o">|</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;image-segmentation&quot;</span><span class="p">)</span>           <span class="o">|</span>
<span class="o">+------------------------------+-----------------+-----------------------------------------------+</span>
<span class="o">|</span> <span class="n">Object</span> <span class="n">detection</span>             <span class="o">|</span> <span class="n">Computer</span> <span class="n">vision</span> <span class="o">|</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;object-detection&quot;</span><span class="p">)</span>             <span class="o">|</span>
<span class="o">+------------------------------+-----------------+-----------------------------------------------+</span>
<span class="o">|</span> <span class="n">Audio</span> <span class="n">classification</span>         <span class="o">|</span> <span class="n">Audio</span>           <span class="o">|</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;audio-classification&quot;</span><span class="p">)</span>         <span class="o">|</span>
<span class="o">+------------------------------+-----------------+-----------------------------------------------+</span>
<span class="o">|</span> <span class="n">Automatic</span> <span class="n">speech</span> <span class="n">recognition</span> <span class="o">|</span> <span class="n">Audio</span>           <span class="o">|</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;automatic-speech-recognition&quot;</span><span class="p">)</span> <span class="o">|</span>
<span class="o">+------------------------------+-----------------+-----------------------------------------------+</span>
<span class="o">|</span> <span class="n">Visual</span> <span class="n">question</span> <span class="n">answering</span>    <span class="o">|</span> <span class="n">Multimodal</span>      <span class="o">|</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;vqa&quot;</span><span class="p">)</span>                          <span class="o">|</span>
<span class="o">+------------------------------+-----------------+-----------------------------------------------+</span>
<span class="o">|</span> <span class="n">Document</span> <span class="n">question</span> <span class="n">answering</span>  <span class="o">|</span> <span class="n">Multimodal</span>      <span class="o">|</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;document-question-answering&quot;</span><span class="p">)</span>  <span class="o">|</span>
<span class="o">+------------------------------+-----------------+-----------------------------------------------+</span>
<span class="o">|</span> <span class="n">Image</span> <span class="n">captioning</span>             <span class="o">|</span> <span class="n">Multimodal</span>      <span class="o">|</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;image-to-text&quot;</span><span class="p">)</span>                <span class="o">|</span>
<span class="o">+------------------------------+-----------------+-----------------------------------------------+</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">classifier</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;sentiment-analysis&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">classifier</span><span class="p">(</span><span class="s2">&quot;We are very happy to show you the ğŸ¤— Transformers library.&quot;</span><span class="p">)</span>
<span class="go">[{&#39;label&#39;: &#39;POSITIVE&#39;, &#39;score&#39;: 0.9998}]</span>
</pre></div>
</div>
<p>Example: iterate over an entire dataset of automatic speech:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span>

<span class="c1"># è¯­éŸ³è¯†åˆ«pipeline(speech_recognizer)</span>
<span class="n">sr</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;automatic-speech-recognition&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;facebook/wav2vec2-base-960h&quot;</span><span class="p">)</span>

<span class="c1"># è½½å…¥æ•°æ®</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span><span class="p">,</span> <span class="n">Audio</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;PolyAI/minds14&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;en-US&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>

<span class="c1"># ç¡®ä¿ç›¸åŒçš„ sampling rate</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">cast_column</span><span class="p">(</span><span class="s2">&quot;audio&quot;</span><span class="p">,</span> <span class="n">Audio</span><span class="p">(</span><span class="n">sampling_rate</span><span class="o">=</span><span class="n">sr</span><span class="o">.</span><span class="n">feature_extractor</span><span class="o">.</span><span class="n">sampling_rate</span><span class="p">))</span>

<span class="c1"># æ‰§è¡Œtask</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">sr</span><span class="p">(</span><span class="n">dataset</span><span class="p">[:</span><span class="mi">4</span><span class="p">][</span><span class="s2">&quot;audio&quot;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">([</span><span class="n">d</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">result</span><span class="p">])</span>
</pre></div>
</div>
<p>Example: Use another model and tokenizer in the pipeline:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>

<span class="c1"># æŒ‡å®šmodelå’Œtokenizer</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;sentiment-analysis&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">)</span>

<span class="c1"># æ‰§è¡Œ</span>
<span class="n">classifier</span><span class="p">(</span><span class="s2">&quot;Nous sommes trÃ¨s heureux de vous prÃ©senter la bibliothÃ¨que ğŸ¤— Transformers.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="autoclass">
<h4>AutoClass<a class="headerlink" href="#autoclass" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>AutoTokenizer:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>

<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>

<span class="c1"># Pass your text to the tokenizer:</span>
<span class="n">encoding</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;We are very happy to show you the ğŸ¤— Transformers library.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">encoding</span><span class="p">)</span>
<span class="c1"># {</span>
<span class="c1">#         &#39;input_ids&#39;: [101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103, 100, 58263, 13299, 119, 102],</span>
<span class="c1">#        &#39;token_type_ids&#39;: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="c1">#        &#39;attention_mask&#39;: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</span>
<span class="c1"># }</span>

<span class="c1"># accept a list of inputs, and pad and truncate the text to return a batch with uniform length</span>
<span class="n">pt_batch</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
    <span class="p">[</span><span class="s2">&quot;We are very happy to show you the ğŸ¤— Transformers library.&quot;</span><span class="p">,</span> <span class="s2">&quot;We hope you don&#39;t hate it.&quot;</span><span class="p">],</span>
    <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
    <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>AutoModel:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># For text (or sequence) classification, you should load `AutoModelForSequenceClassification`</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>

<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="n">pt_model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>

<span class="c1"># pass your preprocessed batch of inputs directly to the model</span>
<span class="n">pt_outputs</span> <span class="o">=</span> <span class="n">pt_model</span><span class="p">(</span><span class="o">**</span><span class="n">pt_batch</span><span class="p">)</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>

<span class="c1"># outputs the final activations in the logits attribute</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">pt_predictions</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">pt_outputs</span><span class="o">.</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">pt_predictions</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">0.0021</span><span class="p">,</span> <span class="mf">0.0018</span><span class="p">,</span> <span class="mf">0.0115</span><span class="p">,</span> <span class="mf">0.2121</span><span class="p">,</span> <span class="mf">0.7725</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.2084</span><span class="p">,</span> <span class="mf">0.1826</span><span class="p">,</span> <span class="mf">0.1969</span><span class="p">,</span> <span class="mf">0.1755</span><span class="p">,</span> <span class="mf">0.2365</span><span class="p">]],</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">SoftmaxBackward0</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
<p>Save a model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pt_save_directory</span> <span class="o">=</span> <span class="s2">&quot;./pt_save_pretrained&quot;</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">pt_save_directory</span><span class="p">)</span>
<span class="n">pt_model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">pt_save_directory</span><span class="p">)</span>

<span class="c1"># load</span>
<span class="n">pt_model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;./pt_save_pretrained&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="custom-model-builds">
<h4>Custom model builds<a class="headerlink" href="#custom-model-builds" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># ä½¿ç”¨AutoConfigåŠ è½½è¦ä¿®æ”¹çš„é¢„è®­ç»ƒæ¨¡å‹ç”Ÿæˆè‡ªå®šä¹‰é…ç½®</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoConfig</span>
<span class="n">my_config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;distilbert-base-uncased&quot;</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

<span class="c1"># ä½¿ç”¨AutoModelåŸºäºè‡ªå®šä¹‰é…ç½®åˆ›å»ºæ¨¡å‹</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModel</span>
<span class="n">my_model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">my_config</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="trainer">
<h4>Trainer<a class="headerlink" href="#trainer" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ol class="arabic">
<li><p>A PreTrainedModel or a torch.nn.Module:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;distilbert-base-uncased&quot;</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>TrainingArguments åŒ…å«å¯ä»¥æ›´æ”¹çš„æ¨¡å‹è¶…å‚æ•°ï¼Œä¾‹å¦‚å­¦ä¹ ç‡ã€æ‰¹é‡å¤§å°å’Œè¦è®­ç»ƒçš„å‘¨æœŸæ•°:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">TrainingArguments</span>

<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;path/to/save/folder/&quot;</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">2e-5</span><span class="p">,</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>é¢„å¤„ç†ç±»ï¼Œå¦‚tokenizer, image processor, feature extractor, or processor:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;distilbert-base-uncased&quot;</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>åŠ è½½æ•°æ®é›†:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;rotten_tomatoes&quot;</span><span class="p">)</span>  <span class="c1"># doctest: +IGNORE_RESULT</span>
</pre></div>
</div>
</li>
<li><p>ä½¿ç”¨mapåº”ç”¨æ•´ä¸ªæ•°æ®é›†:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">tokenize_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_dataset</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>ä½¿ç”¨DataCollatorWithPaddingä»æ•°æ®é›†åˆ›å»ºä¸€æ‰¹ç¤ºä¾‹:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataCollatorWithPadding</span>
<span class="n">data_collator</span> <span class="o">=</span> <span class="n">DataCollatorWithPadding</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ol>
<p>ä½¿ç”¨Trainer:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Trainer</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span>
    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span>
    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">data_collator</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span>
<span class="p">)</span>  <span class="c1"># doctest: +SKIP</span>
</pre></div>
</div>
<p>å¼€å§‹è®­ç»ƒ:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
</section>
</section>
<section id="installation">
<h3>Installation<a class="headerlink" href="#installation" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul>
<li><p>default install:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">transformers</span>

<span class="c1"># éªŒè¯</span>
<span class="n">python</span> <span class="o">-</span><span class="n">c</span> <span class="s2">&quot;from transformers import pipeline; print(pipeline(&#39;sentiment-analysis&#39;)(&#39;we love you&#39;))&quot;</span>
</pre></div>
</div>
</li>
<li><p>cpuç‰ˆå®‰è£…(install Transformers and a deep learning library in one line):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="s1">&#39;transformers[torch]&#39;</span>         <span class="c1"># å®‰è£… ğŸ¤— Transformers å’Œ PyTorch</span>

<span class="n">pip</span> <span class="n">install</span> <span class="s1">&#39;transformers[tf-cpu]&#39;</span>        <span class="c1"># å®‰è£… ğŸ¤— Transformers å’Œ TensorFlow 2.0</span>
</pre></div>
</div>
</li>
<li><p>æºç å®‰è£…:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">git</span><span class="o">+</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">huggingface</span><span class="o">/</span><span class="n">transformers</span>


<span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">huggingface</span><span class="o">/</span><span class="n">transformers</span><span class="o">.</span><span class="n">git</span>
<span class="n">cd</span> <span class="n">transformers</span>
<span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">e</span> <span class="o">.</span>
</pre></div>
</div>
</li>
</ul>
<p>æ£€æŸ¥æ˜¯å¦å®‰è£…æ­£ç¡®:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">c</span> <span class="s2">&quot;from transformers import pipeline; print(pipeline(&#39;sentiment-analysis&#39;)(&#39;we love you&#39;))&quot;</span>

<span class="c1"># æŸ¥çœ‹ç‰ˆæœ¬</span>
<span class="nb">print</span><span class="p">(</span><span class="n">transformers</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
</pre></div>
</div>
<p>é™„åŠ æ¨¡å—:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="s1">&#39;transformers[audio]&#39;</span>
<span class="n">pip</span> <span class="n">install</span> <span class="s1">&#39;transformers[torch]&#39;</span>
<span class="n">pip</span> <span class="n">install</span> <span class="s1">&#39;transformers[tf-cpu]&#39;</span>
</pre></div>
</div>
</section>
<section id="id3">
<h3>ç¯å¢ƒå˜é‡<a class="headerlink" href="#id3" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>ä½¿ç”¨condaä¸‹è½½çš„æ¨¡å‹æ–‡ä»¶åœ°å€:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>&lt;env_path&gt;/lib/pythonX.Y/site-packages/transformers/models
ç¤ºä¾‹:
/home/username/miniconda/envs/myenv/lib/python3.7/site-packages/transformers/models


æ¯ä¸ªç¯å¢ƒéƒ½æœ‰è‡ªå·±çš„æ¨¡å‹æ–‡ä»¶å‰¯æœ¬,å¹¶ä¸”ç¯å¢ƒä¹‹é—´ç›¸äº’éš”ç¦»ã€‚
å¯ä»¥é€šè¿‡è®¾ç½®`TRANSFORMERS_CACHE`ç¯å¢ƒå˜é‡æ¥è¦†ç›–è¿™ä¸€é»˜è®¤è¡Œä¸º
</pre></div>
</div>
<section id="fetch-models-and-tokenizers-to-use-offline">
<h4>Fetch models and tokenizers to use offline<a class="headerlink" href="#fetch-models-and-tokenizers-to-use-offline" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<section id="use-the-from-pretrained-and-save-pretrained-workflow">
<h5>Use the from_pretrained() and save_pretrained() workflow<a class="headerlink" href="#use-the-from-pretrained-and-save-pretrained-workflow" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ol class="arabic">
<li><p>Download your files ahead of time with PreTrainedModel.from_pretrained():</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSeq2SeqLM</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;bigscience/T0_3B&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSeq2SeqLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;bigscience/T0_3B&quot;</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Save your files to a specified directory with PreTrainedModel.save_pretrained():</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="s2">&quot;./your/path/bigscience_t0&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="s2">&quot;./your/path/bigscience_t0&quot;</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Now when youâ€™re offline, reload your files with PreTrainedModel.from_pretrained() from the specified directory:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;./your/path/bigscience_t0&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;./your/path/bigscience_t0&quot;</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ol>
</section>
<section id="programmatically-download-files-with-the-huggingface-hub-library">
<h5>Programmatically download files with the huggingface_hub library<a class="headerlink" href="#programmatically-download-files-with-the-huggingface-hub-library" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ol class="arabic">
<li><p>Install the huggingface_hub library in your virtual environment:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">pip</span> <span class="n">install</span> <span class="n">huggingface_hub</span>
</pre></div>
</div>
</li>
<li><p>Use the hf_hub_download function to download a file to a specific path:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">hf_hub_download</span>

<span class="n">hf_hub_download</span><span class="p">(</span><span class="n">repo_id</span><span class="o">=</span><span class="s2">&quot;bigscience/T0_3B&quot;</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s2">&quot;config.json&quot;</span><span class="p">,</span> <span class="n">cache_dir</span><span class="o">=</span><span class="s2">&quot;./your/path/bigscience_t0&quot;</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Once your file is downloaded and locally cached, specify itâ€™s local path to load and use it:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoConfig</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;./your/path/bigscience_t0/config.json&quot;</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ol>
</section>
</section>
</section>
</section>
<section id="tutorials">
<h2>TUTORIALS<a class="headerlink" href="#tutorials" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<section id="pipelines-for-inference">
<h3>Pipelines for inference<a class="headerlink" href="#pipelines-for-inference" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>Start by creating a pipeline() and specify an inference task:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span>
<span class="n">generator</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;automatic-speech-recognition&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Pass your input text to the pipeline():</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">generator</span><span class="p">(</span><span class="s2">&quot;https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac&quot;</span><span class="p">)</span>
<span class="p">{</span><span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="s1">&#39;I HAVE A DREAM BUT ONE DAY THIS NATION WILL RISE UP LIVE UP THE TRUE MEANING OF ITS TREES&#39;</span><span class="p">}</span>
</pre></div>
</div>
</section>
<section id="load-pretrained-instances-with-an-autoclass">
<h3>Load pretrained instances with an AutoClass<a class="headerlink" href="#load-pretrained-instances-with-an-autoclass" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<div class="admonition note">
<p class="admonition-title">å¤‡æ³¨</p>
<p>Remember, architecture refers to the skeleton of the model and checkpoints are the weights for a given architecture. For example, BERT is an <strong>architecture</strong>, while bert-base-uncased is a <strong>checkpoint</strong>. Model is a general term that can mean either architecture or checkpoint.</p>
</div>
<section id="autotokenizer">
<h4>AutoTokenizer<a class="headerlink" href="#autotokenizer" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<div class="admonition note">
<p class="admonition-title">å¤‡æ³¨</p>
<p>Nearly every NLP task begins with a tokenizer. A tokenizer converts your input into a format that can be processed by the model.</p>
</div>
<p>Load a tokenizer with AutoTokenizer.from_pretrained():</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>tokenize your input as shown below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sequence</span> <span class="o">=</span> <span class="s2">&quot;In a hole in the ground there lived a hobbit.&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">encoded_input</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">encoded_input</span><span class="p">)</span>
<span class="go">{&#39;input_ids&#39;: [101, 1999, 1037, 4920, ...],</span>
<span class="go"> &#39;token_type_ids&#39;: [0, 0, 0, 0, 0, 0, ...],</span>
<span class="go"> &#39;attention_mask&#39;: [1, 1, 1, 1, 1, 1, ...]}</span>
</pre></div>
</div>
<p>Return your input by decoding the input_ids:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">encoded_input</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">])</span>
<span class="go">&quot;[CLS] in a hole in the ground there lived a hobbit.[SEP]&quot;</span>
<span class="go"># è¯´æ˜: two special tokens</span>
<span class="go"># CLS: classifier</span>
<span class="go"># SEP: separator</span>
</pre></div>
</div>
</section>
<section id="autoimageprocessor">
<h4>AutoImageProcessor<a class="headerlink" href="#autoimageprocessor" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>For vision tasks, an image processor processes the image into the correct input format:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoImageProcessor</span>
<span class="n">image_processor</span> <span class="o">=</span> <span class="n">AutoImageProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;google/vit-base-patch16-224&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="autofeatureextractor">
<h4>AutoFeatureExtractor<a class="headerlink" href="#autofeatureextractor" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>For audio tasks, a feature extractor processes the audio signal the correct input format:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoFeatureExtractor</span>
<span class="n">feature_extractor</span> <span class="o">=</span> <span class="n">AutoFeatureExtractor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;facebook/wav2vec2-base&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="autoprocessor">
<h4>AutoProcessor<a class="headerlink" href="#autoprocessor" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p>Multimodal tasks require a processor that combines two types of preprocessing tools.</p></li>
<li><p>For example, the <code class="docutils literal notranslate"><span class="pre">LayoutLMV2</span></code> model requires an image processor to handle images and a tokenizer to handle text; a processor combines both of them.</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoProcessor</span>
<span class="n">processor</span> <span class="o">=</span> <span class="n">AutoProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;microsoft/layoutlmv2-base-uncased&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="automodel">
<h4>AutoModel<a class="headerlink" href="#automodel" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>AutoModelFor classes let you load a pretrained model for a given task(sequence classification):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;distilbert-base-uncased&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>reuse the same checkpoint to load an architecture for a different task(token classification):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForTokenClassification</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForTokenClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;distilbert-base-uncased&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">å¤‡æ³¨</p>
<p>Generally, we recommend using the AutoTokenizer class and the AutoModelFor class to load pretrained instances of models. This will ensure you load the correct architecture every time.</p>
</div>
</section>
</section>
<section id="preprocess-data">
<h3>Preprocess data<a class="headerlink" href="#preprocess-data" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p>Before you can train a model on a dataset, it needs to be preprocessed into the expected model input format.</p></li>
<li><p>Whether your data is text, images, or audio, they need to be converted and assembled into batches of tensors.</p></li>
</ul>
<p>Transformers provides a set of preprocessing classes to help prepare your data for the model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>1. Text
    use `Tokenizer` to convert text into a sequence of tokens, and assemble them into tensors.
2. Speech and audio
    use `Feature` extractor to extract sequential features
        from audio waveforms and convert them into tensors.
3. Image inputs
    use `ImageProcessor` to convert images into tensors.
4. Multimodal inputs,
    use `Processor` to combine a tokenizer and a feature extractor or image processor.
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">å¤‡æ³¨</p>
<p><code class="docutils literal notranslate"><span class="pre">AutoProcessor</span></code> always works and automatically chooses the correct class for the model youâ€™re using, whether youâ€™re using a tokenizer, image processor, feature extractor or processor.</p>
</div>
<section id="natural-language-processing">
<h4>Natural Language Processing<a class="headerlink" href="#natural-language-processing" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p>The main tool for preprocessing textual data is a tokenizer.</p></li>
<li><p>A tokenizer splits text into tokens according to a set of rules.</p></li>
<li><p>The tokens are converted into numbers and then tensors, which become the model inputs.</p></li>
<li><p>Any additional inputs required by the model are added by the tokenizer.</p></li>
</ul>
<section id="pad">
<h5>Pad<a class="headerlink" href="#pad" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ul class="simple">
<li><p>Sentences arenâ€™t always the same length which can be an issue because tensors, the model inputs, need to have a uniform shape.</p></li>
<li><p>Padding is a strategy for ensuring tensors are rectangular by adding a special padding token to shorter sentences.</p></li>
</ul>
<p>ç¤ºä¾‹:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch_sentences</span> <span class="o">=</span> <span class="p">[</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="s2">&quot;But what about second breakfast?&quot;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="s2">&quot;Don&#39;t think he knows about second breakfast, Pip.&quot;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="s2">&quot;What about elevensies?&quot;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">encoded_input</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">batch_sentences</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">encoded_input</span><span class="p">)</span>
<span class="go">{&#39;input_ids&#39;: [[101, 1252, 1184, 1164, ..., 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">               [101, 1790, 112, 189, ..., 6462, 117, 21902, 1643, 119, 102],</span>
<span class="go">               [101, 1327, 1164, 545, ..., 0, 0, 0, 0, 0, 0, 0, 0]],</span>
<span class="go"> &#39;token_type_ids&#39;: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],</span>
<span class="go"> &#39;attention_mask&#39;: [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],</span>
<span class="go">                    [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]}</span>
</pre></div>
</div>
</section>
<section id="truncation">
<h5>Truncation<a class="headerlink" href="#truncation" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ul class="simple">
<li><p>On the other end of the spectrum, sometimes a sequence may be too long for a model to handle.</p></li>
<li><p>In this case, youâ€™ll need to truncate the sequence to a shorter length.</p></li>
<li><p>Set the truncation parameter to True to truncate a sequence to the maximum length accepted by the model</p></li>
</ul>
<p>ç¤ºä¾‹:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch_sentences</span> <span class="o">=</span> <span class="p">[</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="s2">&quot;But what about second breakfast?&quot;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="s2">&quot;Don&#39;t think he knows about second breakfast, Pip.&quot;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="s2">&quot;What about elevensies?&quot;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">encoded_input</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">batch_sentences</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">encoded_input</span><span class="p">)</span>
<span class="go">{&#39;input_ids&#39;: [[101, 1252, 1184, 1164, ..., 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">               [101, 1790, 112, 189, ..., 6462, 117, 21902, 1643, 119, 102],</span>
<span class="go">               [101, 1327, 1164, 545, ..., 0, 0, 0, 0, 0, 0, 0, 0]],</span>
<span class="go"> &#39;token_type_ids&#39;: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],</span>
<span class="go"> &#39;attention_mask&#39;: [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="go">                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],</span>
<span class="go">                    [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]}</span>
</pre></div>
</div>
</section>
<section id="build-tensors">
<h5>Build tensors<a class="headerlink" href="#build-tensors" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ul class="simple">
<li><p>Finally, you want the tokenizer to return the actual tensors that get fed to the model.</p></li>
<li><p>Set the return_tensors parameter to either pt for PyTorch, or tf for TensorFlow</p></li>
</ul>
<p>ç¤ºä¾‹:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&gt;&gt;</span> <span class="n">batch_sentences</span> <span class="o">=</span> <span class="p">[</span>
<span class="o">&gt;&gt;</span>     <span class="s2">&quot;But what about second breakfast?&quot;</span><span class="p">,</span>
<span class="o">&gt;&gt;</span>     <span class="s2">&quot;Don&#39;t think he knows about second breakfast, Pip.&quot;</span><span class="p">,</span>
<span class="o">&gt;&gt;</span>     <span class="s2">&quot;What about elevensies?&quot;</span><span class="p">,</span>
<span class="o">&gt;&gt;</span> <span class="p">]</span>
<span class="o">&gt;&gt;</span> <span class="n">encoded_input</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">batch_sentences</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">encoded_input</span><span class="p">)</span>
<span class="p">{</span><span class="s1">&#39;input_ids&#39;</span><span class="p">:</span> <span class="n">tensor</span><span class="p">([[</span><span class="mi">101</span><span class="p">,</span> <span class="mi">1252</span><span class="p">,</span> <span class="mi">1184</span><span class="p">,</span> <span class="mi">1164</span><span class="p">,</span> <span class="mi">1248</span><span class="p">,</span> <span class="mi">6462</span><span class="p">,</span> <span class="mi">136</span><span class="p">,</span> <span class="mi">102</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                      <span class="p">[</span><span class="mi">101</span><span class="p">,</span> <span class="mi">1790</span><span class="p">,</span> <span class="mi">112</span><span class="p">,</span> <span class="mi">189</span><span class="p">,</span> <span class="mi">1341</span><span class="p">,</span> <span class="mi">1119</span><span class="p">,</span> <span class="mi">3520</span><span class="p">,</span> <span class="mi">1164</span><span class="p">,</span> <span class="mi">1248</span><span class="p">,</span> <span class="mi">6462</span><span class="p">,</span> <span class="mi">117</span><span class="p">,</span> <span class="mi">21902</span><span class="p">,</span> <span class="mi">1643</span><span class="p">,</span> <span class="mi">119</span><span class="p">,</span> <span class="mi">102</span><span class="p">],</span>
                      <span class="p">[</span><span class="mi">101</span><span class="p">,</span> <span class="mi">1327</span><span class="p">,</span> <span class="mi">1164</span><span class="p">,</span> <span class="mi">5450</span><span class="p">,</span> <span class="mi">23434</span><span class="p">,</span> <span class="mi">136</span><span class="p">,</span> <span class="mi">102</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]),</span>
 <span class="s1">&#39;token_type_ids&#39;</span><span class="p">:</span> <span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                           <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                           <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]),</span>
 <span class="s1">&#39;attention_mask&#39;</span><span class="p">:</span> <span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                           <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                           <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])}</span>
</pre></div>
</div>
</section>
</section>
<section id="audio">
<h4>Audio<a class="headerlink" href="#audio" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p>For audio tasks, youâ€™ll need a <code class="docutils literal notranslate"><span class="pre">feature</span> <span class="pre">extractor</span></code> to prepare your dataset for the model.</p></li>
<li><p>The feature extractor is designed to extract features from raw audio data, and convert them into tensors.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">å¤‡æ³¨</p>
<p>Remember you should always resample your audio datasetâ€™s sampling rate to match the sampling rate of the dataset used to pretrain a model!</p>
</div>
<p>è·å–æ•°æ®:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span><span class="p">,</span> <span class="n">Audio</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;PolyAI/minds14&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;en-US&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>

<span class="c1"># upsample the sampling rate to 16kHz:</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">cast_column</span><span class="p">(</span><span class="s2">&quot;audio&quot;</span><span class="p">,</span> <span class="n">Audio</span><span class="p">(</span><span class="n">sampling_rate</span><span class="o">=</span><span class="mi">16_000</span><span class="p">))</span>
</pre></div>
</div>
<p>Load the feature extractor:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoFeatureExtractor</span>
<span class="n">feature_extractor</span> <span class="o">=</span> <span class="n">AutoFeatureExtractor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;facebook/wav2vec2-base&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Pass the audio array to the feature extractor:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">audio_input</span> <span class="o">=</span> <span class="p">[</span><span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;audio&quot;</span><span class="p">][</span><span class="s2">&quot;array&quot;</span><span class="p">]]</span>
<span class="n">feature_extractor</span><span class="p">(</span><span class="n">audio_input</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">16000</span><span class="p">)</span>
</pre></div>
</div>
<section id="pading">
<h5>Pading<a class="headerlink" href="#pading" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<p>æŸ¥çœ‹æ•°æ®é•¿åº¦:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;audio&quot;</span><span class="p">][</span><span class="s2">&quot;array&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
<span class="p">(</span><span class="mi">173398</span><span class="p">,)</span>

<span class="n">dataset</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s2">&quot;audio&quot;</span><span class="p">][</span><span class="s2">&quot;array&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
<span class="p">(</span><span class="mi">106496</span><span class="p">,)</span>
</pre></div>
</div>
<p>è¡¥é½:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">preprocess_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
    <span class="n">audio_arrays</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;array&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">[</span><span class="s2">&quot;audio&quot;</span><span class="p">]]</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">feature_extractor</span><span class="p">(</span>
        <span class="n">audio_arrays</span><span class="p">,</span>
        <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">16000</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">max_length</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span>
        <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">inputs</span>
<span class="n">processed_dataset</span> <span class="o">=</span> <span class="n">preprocess_function</span><span class="p">(</span><span class="n">dataset</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
<p>ä¸¤æ¬¡æŸ¥çœ‹æ•°æ®é•¿åº¦:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;audio&quot;</span><span class="p">][</span><span class="s2">&quot;array&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
<span class="p">(</span><span class="mi">100000</span><span class="p">,)</span>

<span class="n">dataset</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s2">&quot;audio&quot;</span><span class="p">][</span><span class="s2">&quot;array&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
<span class="p">(</span><span class="mi">100000</span><span class="p">,)</span>
</pre></div>
</div>
</section>
</section>
<section id="computer-vision">
<h4>Computer vision<a class="headerlink" href="#computer-vision" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p>For computer vision tasks, youâ€™ll need an <code class="docutils literal notranslate"><span class="pre">image</span> <span class="pre">processor</span></code> to prepare your dataset for the model.</p></li>
<li><p>Image preprocessing consists of several steps that convert images into the input expected by the model.</p></li>
<li><p>These steps include but are not limited to resizing, normalizing, color channel correction, and converting images to tensors.</p></li>
</ul>
<p>è½½å…¥æ•°æ®:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;food101&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train[:100]&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>æŸ¥çœ‹å›¾ç‰‡:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;image&quot;</span><span class="p">]</span>
</pre></div>
</div>
<p>Load the image processor:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoImageProcessor</span>
<span class="n">image_processor</span> <span class="o">=</span> <span class="n">AutoImageProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;google/vit-base-patch16-224&quot;</span><span class="p">)</span>
</pre></div>
</div>
<section id="image-augmentation">
<h5>image augmentation<a class="headerlink" href="#image-augmentation" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<div class="admonition note">
<p class="admonition-title">å¤‡æ³¨</p>
<p>è¿™å„¿ç”¨çš„æ˜¯torchvisionâ€™s transforms moduleï¼Œè¿˜å¯ä»¥ç”¨å…¶ä»–å›¾åƒå¢å¼ºæ–¹æ³•ï¼Œå¦‚: <a class="reference external" href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification_albumentations.ipynb">Albumentations</a> å’Œ <a class="reference external" href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification_kornia.ipynb">Kornia</a></p>
</div>
<p>resizing:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.transforms</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomResizedCrop</span><span class="p">,</span> <span class="n">ColorJitter</span><span class="p">,</span> <span class="n">Compose</span>

<span class="n">size</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">image_processor</span><span class="o">.</span><span class="n">size</span><span class="p">[</span><span class="s2">&quot;shortest_edge&quot;</span><span class="p">]</span>
    <span class="k">if</span> <span class="s2">&quot;shortest_edge&quot;</span> <span class="ow">in</span> <span class="n">image_processor</span><span class="o">.</span><span class="n">size</span>
    <span class="k">else</span> <span class="p">(</span><span class="n">image_processor</span><span class="o">.</span><span class="n">size</span><span class="p">[</span><span class="s2">&quot;height&quot;</span><span class="p">],</span> <span class="n">image_processor</span><span class="o">.</span><span class="n">size</span><span class="p">[</span><span class="s2">&quot;width&quot;</span><span class="p">])</span>
<span class="p">)</span>

<span class="c1"># éšæœºè£å‰ªå’Œå˜åŒ–é¢œè‰²</span>
<span class="c1"># RandomResizedCropä¼šéšæœºè£å‰ªå›¾ç‰‡çš„åŒºåŸŸã€‚</span>
<span class="c1"># ColorJitterä¼šéšæœºæ”¹å˜å›¾åƒçš„äº®åº¦ã€å¯¹æ¯”åº¦ç­‰å‚æ•°ã€‚</span>
<span class="n">_transforms</span> <span class="o">=</span> <span class="n">Compose</span><span class="p">([</span><span class="n">RandomResizedCrop</span><span class="p">(</span><span class="n">size</span><span class="p">),</span> <span class="n">ColorJitter</span><span class="p">(</span><span class="n">brightness</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)])</span>
</pre></div>
</div>
<p>combines image augmentation and image preprocessing for a batch of images and generates pixel_values:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># å¯¹æ¯ä¸ªå›¾åƒexampleåº”ç”¨_transforms</span>
<span class="c1"># å¹¶å°†è½¬æ¢åçš„å›¾åƒä¿å­˜åœ¨exampleçš„pixel_valuesä¸­</span>
<span class="k">def</span><span class="w"> </span><span class="nf">transforms</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
    <span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="n">_transforms</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">))</span> <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">]]</span>
    <span class="n">examples</span><span class="p">[</span><span class="s2">&quot;pixel_values&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">image_processor</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">do_resize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)[</span><span class="s2">&quot;pixel_values&quot;</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">examples</span>
</pre></div>
</div>
<p>apply the transforms on the fly:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span><span class="o">.</span><span class="n">set_transform</span><span class="p">(</span><span class="n">transforms</span><span class="p">)</span>
</pre></div>
</div>
<p>The image has been randomly cropped and itâ€™s color properties are different:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="n">img</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;pixel_values&quot;</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">å¤‡æ³¨</p>
<p>dataset[0][â€œpixel_valuesâ€]æ¯æ¬¡ç»“æœä¸ä¸€æ ·ã€‚åŸå› æ˜¯ä½¿ç”¨äº†``dataset.set_transform(transforms)``ï¼Œæ¯æ¬¡éå†datasetæ—¶,è¿™äº›éšæœºæ“ä½œéƒ½ä¼šé‡æ–°åº”ç”¨,æ‰€ä»¥åŒä¸€ä¸ªæ ·æœ¬ç»è¿‡å¢å¼ºä¹‹åçš„pixel_valueså°±ä¼šæœ‰æ‰€ä¸åŒã€‚è¿™ä¹Ÿæ­£æ˜¯æ•°æ®å¢å¼ºçš„ç›®çš„,é€šè¿‡éšæœºæ“ä½œåˆ›é€ æ›´å¤šä¸åŒçš„è®­ç»ƒæ ·æœ¬,æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚æ€»ç»“æ¥è¯´,dataset[0]æœ¬èº«ä¸å˜,ä½†å¢å¼ºåpixel_valuesä¸åŒ,æ˜¯å› ä¸ºéšæœºå¢å¼ºå¼•èµ·çš„ã€‚è¿™å¯¹æé«˜æ¨¡å‹é²æ£’æ€§æ˜¯æœ‰å¸®åŠ©çš„ã€‚</p>
</div>
</section>
<section id="id4">
<h5>Pading<a class="headerlink" href="#id4" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">collate_fn</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
    <span class="n">pixel_values</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="s2">&quot;pixel_values&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">]</span>
    <span class="n">encoding</span> <span class="o">=</span> <span class="n">image_processor</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">pixel_values</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">]</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;pixel_values&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">encoding</span><span class="p">[</span><span class="s2">&quot;pixel_values&quot;</span><span class="p">]</span>
    <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;pixel_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">encoding</span><span class="p">[</span><span class="s2">&quot;pixel_mask&quot;</span><span class="p">]</span>
    <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>
    <span class="k">return</span> <span class="n">batch</span>
</pre></div>
</div>
<ul class="simple">
<li><p>åœ¨PyTorchä¸­,collate_fnå‡½æ•°çš„ä½œç”¨æ˜¯åœ¨ä½¿ç”¨DataLoaderåŠ è½½æ•°æ®æ—¶å¯¹ä¸€ä¸ªbatchçš„æ•°æ®è¿›è¡Œé¢„å¤„ç†ã€‚</p></li>
<li><p>collate_fnä¼šåœ¨æ¯ä¸ªbatchè¢«åŠ è½½åæ‰§è¡Œ,å®ƒæ¥å—ä¸€ä¸ªbatchçš„æ•°æ®ä½œä¸ºè¾“å…¥,å¹¶è¿”å›batchçš„æ•°æ®ä½œä¸ºè¾“å‡ºã€‚</p></li>
</ul>
<p>å¸¸è§çš„ä½¿ç”¨collate_fnçš„åœºæ™¯æœ‰:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>- å½“æ ·æœ¬çš„æ•°æ®æ ¼å¼ä¸åŒæ—¶,collate_fnå¯ä»¥å°†å…¶è½¬æ¢ä¸ºç›¸åŒæ ¼å¼ã€‚
    ä¾‹å¦‚æ ·æœ¬åŒ…æ‹¬å›¾åƒå’Œæ–‡æœ¬,collate_fnå¯ä»¥å°†å…¶è½¬æ¢ä¸ºåŒæ ·çš„å¼ é‡æ ¼å¼ã€‚
- å½“batchä¸­çš„æ ·æœ¬é•¿åº¦ä¸åŒæ—¶,collate_fnå¯ä»¥é€šè¿‡paddingå°†å…¶è¡¥é½åˆ°ç›¸åŒé•¿åº¦ã€‚
    ä¾‹å¦‚å¤„ç†NLPä»»åŠ¡ä¸­çš„æ–‡æœ¬æ•°æ®ã€‚
- å¯¹batchä¸­çš„æ ·æœ¬è¿›è¡Œé¢å¤–çš„é¢„å¤„ç†
    ä¾‹å¦‚å›¾åƒå¢å¼ºã€æ–‡æœ¬tokenizeç­‰ã€‚
- æ„å»ºè‡ªå®šä¹‰çš„æ•°æ®ç»“æ„ä½œä¸ºbatchçš„è¾“å‡º
    ä¾‹å¦‚ä¸ºæ£€æµ‹ä»»åŠ¡æ„å»º(images, targets)çš„ç»“æ„ã€‚
- åœ¨è®­ç»ƒè¯­éŸ³è¯†åˆ«æ¨¡å‹æ—¶,collate_fnå¯ä»¥å°†éŸ³é¢‘æ ·æœ¬paddingåˆ°ç›¸åŒé•¿åº¦,å¹¶æ„å»ºé•¿åº¦å˜é‡ç­‰ã€‚
</pre></div>
</div>
</section>
</section>
</section>
<section id="fine-tune-a-pretrained-model">
<h3>Fine-tune a pretrained model<a class="headerlink" href="#fine-tune-a-pretrained-model" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>å®‰è£…åŒ…:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>!pip install datasets transformers accelerate evaluate
</pre></div>
</div>
<p>load data:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;yelp_review_full&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">][</span><span class="mi">100</span><span class="p">]</span>
<span class="go">{&#39;label&#39;: 0,</span>
<span class="go"> &#39;text&#39;: &#39;My expectations for McDonal...&#39;}</span>
</pre></div>
</div>
<p>token:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;bert-base-cased&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;bert-base-cased&quot;</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<p>å–å°éƒ¨åˆ†æ•°æ®ä»¥èŠ‚çœæ—¶é—´(å¯é€‰):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">DatasetDict</span><span class="p">,</span> <span class="n">Dataset</span>

<span class="n">small_train_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span>
<span class="n">small_test_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span>
<span class="n">small_dataset</span> <span class="o">=</span> <span class="n">DatasetDict</span><span class="p">({</span>
    <span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="n">small_train_dataset</span><span class="p">,</span>
    <span class="s1">&#39;test&#39;</span><span class="p">:</span> <span class="n">small_test_dataset</span>
<span class="p">})</span>
</pre></div>
</div>
<p>æ‰¹å¤„ç†token:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">tokenized_datasets</span> <span class="o">=</span> <span class="n">small_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">small_tokenized_train_dataset</span> <span class="o">=</span> <span class="n">tokenized_datasets</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span>
<span class="n">small_tokenized_test_dataset</span> <span class="o">=</span> <span class="n">tokenized_datasets</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span>
</pre></div>
</div>
<section id="train-with-pytorch-trainer">
<h4>Train with PyTorch Trainer<a class="headerlink" href="#train-with-pytorch-trainer" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<section id="training-hyperparameters">
<h5>Training hyperparameters<a class="headerlink" href="#training-hyperparameters" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<p>Specify where to save the checkpoints from your training:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">TrainingArguments</span>
<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span><span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;test_trainer&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>monitor your evaluation metrics during fine-tuning(å¯é€‰):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">TrainingArguments</span><span class="p">,</span> <span class="n">Trainer</span>
<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span><span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;test_trainer&quot;</span><span class="p">,</span> <span class="n">evaluation_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="evaluate">
<h5>Evaluate<a class="headerlink" href="#evaluate" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Trainer</span></code> does not automatically evaluate model performance during training.</p></li>
<li><p>You should add <code class="docutils literal notranslate"><span class="pre">compute_metrics</span></code> param to <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> object.</p></li>
</ul>
<p><a class="reference external" href="https://huggingface.co/docs/evaluate/index">Evaluate</a> library provides a simple accuracy function:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>

<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>convert the predictions to logits (remember all ğŸ¤— Transformers models return logits):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>
    <span class="n">logits</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id6">
<h5>Trainer<a class="headerlink" href="#id6" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<p>Create a Trainer object:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">small_tokenized_train_dataset</span><span class="p">,</span>
    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">small_tokenized_eval_dataset</span><span class="p">,</span>
    <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>fine-tune begin:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
</section>
</section>
<section id="train-in-native-pytorch">
<h4>Train in native PyTorch<a class="headerlink" href="#train-in-native-pytorch" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>æ¸…é™¤ç¯å¢ƒèŠ‚çœèµ„æº:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">del</span> <span class="n">model</span>
<span class="k">del</span> <span class="n">trainer</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</pre></div>
</div>
<p>manually postprocess tokenized_dataset to prepare it for training:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tokenized_datasets</span> <span class="o">=</span> <span class="n">tokenized_datasets</span><span class="o">.</span><span class="n">remove_columns</span><span class="p">([</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>
<span class="n">tokenized_datasets</span> <span class="o">=</span> <span class="n">tokenized_datasets</span><span class="o">.</span><span class="n">rename_column</span><span class="p">(</span><span class="s2">&quot;label&quot;</span><span class="p">,</span> <span class="s2">&quot;labels&quot;</span><span class="p">)</span>

<span class="c1"># Set the format of the dataset to return PyTorch tensors instead of lists:</span>
<span class="n">tokenized_datasets</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="s2">&quot;torch&quot;</span><span class="p">)</span>

<span class="n">small_tokenized_train_dataset</span> <span class="o">=</span> <span class="n">tokenized_datasets</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span>
<span class="n">small_tokenized_test_dataset</span> <span class="o">=</span> <span class="n">tokenized_datasets</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span>
</pre></div>
</div>
<section id="dataloader">
<h5>DataLoader<a class="headerlink" href="#dataloader" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<p>Create a DataLoader:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>

<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">small_tokenized_train_dataset</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">eval_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">small_tokenized_test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="optimizer-and-learning-rate-scheduler">
<h5>Optimizer and learning rate scheduler<a class="headerlink" href="#optimizer-and-learning-rate-scheduler" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<p>Create an optimizer and learning rate scheduler to fine-tune the model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">AdamW</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-5</span><span class="p">)</span>
</pre></div>
</div>
<p>Create the default learning rate scheduler from Trainer:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_scheduler</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">num_training_steps</span> <span class="o">=</span> <span class="n">num_epochs</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)</span>
<span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">get_scheduler</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">num_warmup_steps</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_training_steps</span><span class="o">=</span><span class="n">num_training_steps</span>
<span class="p">)</span>
</pre></div>
</div>
<p>specify device to use a GPU:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="training-loop">
<h5>Training loop<a class="headerlink" href="#training-loop" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<p>åŸºæœ¬çš„å¾ªç¯è®­ç»ƒé€»è¾‘:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">tqdm.auto</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>

<span class="n">progress_bar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_training_steps</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">train_dataloader</span><span class="p">:</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>       <span class="c1"># å‰å‘ä¼ æ’­</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">loss</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>                <span class="c1"># åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>               <span class="c1"># ä½¿ç”¨ä¼˜åŒ–å™¨æ›´æ–°å‚æ•°</span>
        <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>            <span class="c1"># ä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦å™¨æ›´æ–°å­¦ä¹ ç‡</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>          <span class="c1"># æ¸…é›¶ä¼˜åŒ–å™¨çš„æ¢¯åº¦</span>
        <span class="n">progress_bar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id7">
<h5>Evaluate<a class="headerlink" href="#id7" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<p>åŸºæœ¬çš„æ¨¡å‹è¯„ä¼°é€»è¾‘:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">evaluate</span>

<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>    <span class="c1"># åŠ è½½è¯„ä¼°æŒ‡æ ‡</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>                          <span class="c1"># å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼</span>
<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">eval_dataloader</span><span class="p">:</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>             <span class="c1"># å…³é—­autograd engineè¿›è¡Œæ¨ç†</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>      <span class="c1"># æ¨¡å‹å‰å‘ä¼ æ’­è®¡ç®—</span>

    <span class="n">logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">logits</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>        <span class="c1"># è®¡ç®—é¢„æµ‹ç±»åˆ«</span>
    <span class="n">metric</span><span class="o">.</span><span class="n">add_batch</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">])</span>     <span class="c1"># å°†é¢„æµ‹ç»“æœå’Œæ ‡ç­¾ä¼ å…¥metricè¿›è¡ŒæŒ‡æ ‡è®¡ç®—</span>

<span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>                      <span class="c1"># èšåˆæ‰¹æ¬¡ç»“æœ,å¾—åˆ°æœ€ç»ˆè¯„ä¼°æŒ‡æ ‡æ•°é‡</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="train-with-a-script">
<h3>Train with a script<a class="headerlink" href="#train-with-a-script" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p>æœ¬èŠ‚ä¸»è¦å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ç°æˆçš„è„šæœ¬æ¥ç›´æ¥å®ç°ç›¸åº”çš„åŠŸèƒ½</p></li>
<li><p>ä¸»è¦å¦‚ä¸‹é¢2ä¸ªç”±ç¤¾åŒºè´¡çŒ®çš„è„šæœ¬ç¤ºä¾‹ <a class="reference external" href="https://github.com/huggingface/transformers/tree/main/examples/research_projects">research projects</a> å’Œ <a class="reference external" href="https://github.com/huggingface/transformers/tree/main/examples/legacy">legacy examples</a></p></li>
</ul>
<div class="admonition warning">
<p class="admonition-title">è­¦å‘Š</p>
<p>These scripts are not actively maintained and require a specific version of ğŸ¤— Transformers that will most likely be incompatible with the latest version of the library.</p>
</div>
<p>è¿è¡Œè„šæœ¬ç¤ºä¾‹:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">examples</span><span class="o">/</span><span class="n">pytorch</span><span class="o">/</span><span class="n">summarization</span><span class="o">/</span><span class="n">run_summarization</span><span class="o">.</span><span class="n">py</span> \
    <span class="o">--</span><span class="n">model_name_or_path</span> <span class="n">t5</span><span class="o">-</span><span class="n">small</span> \
    <span class="o">--</span><span class="n">do_train</span> \
    <span class="o">--</span><span class="n">do_eval</span> \
    <span class="o">--</span><span class="n">dataset_name</span> <span class="n">cnn_dailymail</span> \
    <span class="o">--</span><span class="n">dataset_config</span> <span class="s2">&quot;3.0.0&quot;</span> \
    <span class="o">--</span><span class="n">source_prefix</span> <span class="s2">&quot;summarize: &quot;</span> \
    <span class="o">--</span><span class="n">output_dir</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">tst</span><span class="o">-</span><span class="n">summarization</span> \
    <span class="o">--</span><span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">4</span> \
    <span class="o">--</span><span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="mi">4</span> \
    <span class="o">--</span><span class="n">overwrite_output_dir</span> \
    <span class="o">--</span><span class="n">predict_with_generate</span>
</pre></div>
</div>
</section>
<section id="distributed-training-with-accelerate">
<h3>Distributed training with Accelerate<a class="headerlink" href="#distributed-training-with-accelerate" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p>æœ¬èŠ‚ä¸»è¦è®²äº†ä¸€ä¸ªåˆ†å¸ƒå¼è®­ç»ƒçš„å·¥å…·: <code class="docutils literal notranslate"><span class="pre">Accelerate</span></code></p></li>
</ul>
<p>å®‰è£…:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">accelerate</span>
</pre></div>
</div>
<section id="backward">
<h4>Backward<a class="headerlink" href="#backward" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>ä½¿ç”¨ <code class="docutils literal notranslate"><span class="pre">Accelerate</span></code> åªéœ€è¦åšå¦‚ä¸‹ä¿®æ”¹:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">+</span> <span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
  <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AdamW</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span><span class="p">,</span> <span class="n">get_scheduler</span>

<span class="o">+</span> <span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>

  <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">3e-5</span><span class="p">)</span>

<span class="o">-</span> <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="o">-</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="o">+</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">eval_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span>
<span class="o">+</span>     <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">eval_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span>
<span class="o">+</span> <span class="p">)</span>

  <span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">3</span>
  <span class="n">num_training_steps</span> <span class="o">=</span> <span class="n">num_epochs</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)</span>
  <span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">get_scheduler</span><span class="p">(</span>
      <span class="s2">&quot;linear&quot;</span><span class="p">,</span>
      <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
      <span class="n">num_warmup_steps</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
      <span class="n">num_training_steps</span><span class="o">=</span><span class="n">num_training_steps</span>
  <span class="p">)</span>

  <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_training_steps</span><span class="p">))</span>

  <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">train_dataloader</span><span class="p">:</span>
<span class="o">-</span>         <span class="n">batch</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
          <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
          <span class="n">loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">loss</span>
<span class="o">-</span>         <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="o">+</span>         <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

          <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
          <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
          <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
          <span class="n">progress_bar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="transformers-agent">
<h3>Transformers Agent<a class="headerlink" href="#transformers-agent" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<div class="admonition warning">
<p class="admonition-title">è­¦å‘Š</p>
<p>Transformers Agent is an experimental API which is subject to change at any time. Results returned by the agents can vary as the APIs or underlying models are prone to change.</p>
</div>
<ul class="simple">
<li><p>building on the concept of tools and agents.</p></li>
<li><p>In short, it provides a natural language API on top of transformers: we define a set of curated tools and design an agent to interpret natural language and to use these tools.</p></li>
</ul>
<section id="id8">
<h4>ç¤ºä¾‹<a class="headerlink" href="#id8" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>å‘½ä»¤:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">agent</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;Caption the following image&quot;</span><span class="p">,</span> <span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
<img alt="https://img.zhaoweiguo.com/uPic/2023/08/B49pjD.png" src="https://img.zhaoweiguo.com/uPic/2023/08/B49pjD.png" />
<p>å‘½ä»¤:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">agent</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;Read the following text out loud&quot;</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">)</span>
</pre></div>
</div>
<img alt="https://img.zhaoweiguo.com/uPic/2023/08/vtKK41.png" src="https://img.zhaoweiguo.com/uPic/2023/08/vtKK41.png" />
<p>å‘½ä»¤:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">agent</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
    <span class="s2">&quot;In the following `document`, where will the TRRF Scientific Advisory Council Meeting take place?&quot;</span><span class="p">,</span>
    <span class="n">document</span><span class="o">=</span><span class="n">document</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<img alt="https://img.zhaoweiguo.com/uPic/2023/08/2cLcOq.png" src="https://img.zhaoweiguo.com/uPic/2023/08/2cLcOq.png" />
</section>
<section id="quickstart">
<h4>Quickstart<a class="headerlink" href="#quickstart" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>å®‰è£…:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">transformers</span><span class="p">[</span><span class="n">agents</span><span class="p">]</span>
</pre></div>
</div>
<p>logging in to have access to the Inference API:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">huggingface_hub</span><span class="w"> </span><span class="kn">import</span> <span class="n">login</span>
<span class="n">login</span><span class="p">(</span><span class="s2">&quot;&lt;YOUR_TOKEN&gt;&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>instantiate the agent:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">HfAgent</span>

<span class="c1"># Starcoder</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">HfAgent</span><span class="p">(</span><span class="s2">&quot;https://api-inference.huggingface.co/models/bigcode/starcoder&quot;</span><span class="p">)</span>
<span class="c1"># StarcoderBase</span>
<span class="c1"># agent = HfAgent(&quot;https://api-inference.huggingface.co/models/bigcode/starcoderbase&quot;)</span>
<span class="c1"># OpenAssistant</span>
<span class="c1"># agent = HfAgent(url_endpoint=&quot;https://api-inference.huggingface.co/models/OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5&quot;)</span>

<span class="c1">## OpenAI</span>
<span class="c1"># pip install openai</span>
<span class="c1"># from transformers import OpenAiAgent</span>
<span class="c1"># agent = OpenAiAgent(model=&quot;text-davinci-003&quot;, api_key=&quot;&lt;your_api_key&gt;&quot;)</span>
</pre></div>
</div>
<section id="single-execution-run">
<h5>Single execution (run)<a class="headerlink" href="#single-execution-run" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">agent</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;Draw me a picture of rivers and lakes.&quot;</span><span class="p">)</span>


<span class="n">picture</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;Generate a picture of rivers and lakes.&quot;</span><span class="p">)</span>
<span class="n">updated_picture</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;Transform the image in `picture` to add an island to it.&quot;</span><span class="p">,</span> <span class="n">picture</span><span class="o">=</span><span class="n">picture</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="chat-based-execution-chat">
<h5>Chat-based execution (chat)<a class="headerlink" href="#chat-based-execution-chat" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">agent</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span><span class="s2">&quot;Generate a picture of rivers and lakes&quot;</span><span class="p">)</span>
<span class="n">agent</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span><span class="s2">&quot;Transform the picture so that there is a rock in there&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="id9">
<h4>åŸç†<a class="headerlink" href="#id9" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2023/08/1kTPz2.jpg" src="https://img.zhaoweiguo.com/uPic/2023/08/1kTPz2.jpg" />
</figure>
<section id="agents">
<h5>Agents<a class="headerlink" href="#agents" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ul class="simple">
<li><p>The â€œagentâ€ here is a large language model, and weâ€™re prompting it so that it has access to a specific set of tools.</p></li>
</ul>
</section>
<section id="tools">
<h5>Tools<a class="headerlink" href="#tools" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ul class="simple">
<li><p>Tools are very simple: theyâ€™re a single function, with a name, and a description. We then use these toolsâ€™ descriptions to prompt the agent. Through the prompt, we show the agent how it would leverage tools to perform what was requested in the query.</p></li>
</ul>
</section>
</section>
<section id="resource">
<h4>Resource<a class="headerlink" href="#resource" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<section id="a-curated-set-of-tools">
<h5>A curated set of tools<a class="headerlink" href="#a-curated-set-of-tools" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ul class="simple">
<li><p>Document question answering: given a document (such as a PDF) in image format, answer a question on this document (<a class="reference external" href="https://huggingface.co/docs/transformers/model_doc/donut">Donut</a>)</p></li>
<li><p>Text question answering: given a long text and a question, answer the question in the text (<a class="reference external" href="https://huggingface.co/docs/transformers/model_doc/flan-t5">Flan_T5</a>)</p></li>
<li><p>Unconditional image captioning: Caption the image! (<a class="reference external" href="https://huggingface.co/docs/transformers/model_doc/blip">BLIP</a>)</p></li>
<li><p>Image question answering: given an image, answer a question on this image (<a class="reference external" href="https://huggingface.co/docs/transformers/model_doc/vilt">VILT</a>)</p></li>
<li><p>Image segmentation: given an image and a prompt, output the segmentation mask of that prompt (<a class="reference external" href="https://huggingface.co/docs/transformers/model_doc/clipseg">CLIPSeg</a>)</p></li>
<li><p>Speech to text: given an audio recording of a person talking, transcribe the speech into text (<a class="reference external" href="https://huggingface.co/docs/transformers/model_doc/whisper">Whisper</a>)</p></li>
<li><p>Text to speech: convert text to speech (<a class="reference external" href="https://huggingface.co/docs/transformers/model_doc/speecht5">SpeechT5</a>)</p></li>
<li><p>Zero-shot text classification: given a text and a list of labels, identify to which label the text corresponds the most (<a class="reference external" href="https://huggingface.co/docs/transformers/model_doc/bart">BART</a>)</p></li>
<li><p>Text summarization: summarize a long text in one or a few sentences (<a class="reference external" href="https://huggingface.co/docs/transformers/model_doc/bart">BART</a>)</p></li>
<li><p>Translation: translate the text into a given language (<a class="reference external" href="https://huggingface.co/docs/transformers/model_doc/nllb">NLLB</a>)</p></li>
</ul>
</section>
<section id="custom-tools">
<h5>Custom tools<a class="headerlink" href="#custom-tools" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ul class="simple">
<li><p>Text downloader: to download a text from a web URL</p></li>
<li><p>Text to image: generate an image according to a prompt, leveraging stable diffusion. <a class="reference external" href="https://huggingface.co/spaces/huggingface-tools/text-to-image">huggingface-tools/text-to-image</a></p></li>
<li><p>Image transformation: modify an image given an initial image and a prompt, leveraging instruct pix2pix stable diffusion</p></li>
<li><p>Text to video: generate a small video according to a prompt, leveraging damo-vilab</p></li>
</ul>
</section>
</section>
<section id="code-generation">
<h4>Code generation<a class="headerlink" href="#code-generation" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>ç¤ºä¾‹:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;Draw me a picture of rivers and lakes&quot;</span><span class="p">,</span> <span class="n">return_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="go">==Code generated by the agent==</span>
<span class="go">from transformers import load_tool</span>
<span class="go">image_generator = load_tool(&quot;huggingface-tools/text-to-image&quot;)</span>
<span class="go">image = image_generator(prompt=&quot;rivers and lakes&quot;)</span>
</pre></div>
</div>
<p>ç¤ºä¾‹:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">agent</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;Draw me a picture of the sea then transform the picture to add an island&quot;</span><span class="p">,</span> <span class="n">return_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="go">==Code generated by the agent==</span>
<span class="go">from transformers import load_tool</span>
<span class="go">image_transformer = load_tool(&quot;huggingface-tools/image-transformation&quot;)</span>
<span class="go">image_generator = load_tool(&quot;huggingface-tools/text-to-image&quot;)</span>
<span class="go">image = image_generator(prompt=&quot;a picture of the sea&quot;)</span>
<span class="go">image = image_transformer(image, prompt=&quot;an island&quot;)</span>
</pre></div>
</div>
<p>ç¤ºä¾‹:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">picture</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;Generate a picture of rivers and lakes.&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">updated_picture</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;Transform the image in `picture` to add an boat to it.&quot;</span><span class="p">,</span> <span class="n">picture</span><span class="o">=</span><span class="n">picture</span><span class="p">,</span> <span class="n">return_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="go">==Code generated by the agent==</span>
<span class="go">image = image_transformer(image=picture, prompt=&quot;a boat&quot;)</span>
</pre></div>
</div>
</section>
<section id="practice">
<h4>Practice<a class="headerlink" href="#practice" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p><a class="reference external" href="https://colab.research.google.com/drive/1c7MHD-T1forUPGcC_jlwsIptOzpG3hSj#scrollTo=Q9rx-nKzDpAW">https://colab.research.google.com/drive/1c7MHD-T1forUPGcC_jlwsIptOzpG3hSj#scrollTo=Q9rx-nKzDpAW</a></p></li>
</ul>
</section>
</section>
</section>
<section id="task-guides">
<h2>TASK GUIDES<a class="headerlink" href="#task-guides" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<section id="id11">
<h3>NATURAL LANGUAGE PROCESSING<a class="headerlink" href="#id11" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>NLP:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Text classification
Token classification
  One of the most common token classification tasks is Named Entity Recognition (NER).
  NER attempts to find a label for each entity in a sentence,
    such as a person, location, or org.
Question answering
Causal language modeling(There are two types of language modeling: `causal` and `masked`)
  Causal language models are frequently used for text generation.
  You can use these models for creative applications
    like choosing your own text adventure or an intelligent coding assistant
        like Copilot or CodeParrot.
Masked language modeling
  it predicts a masked token in a sequence, and the model can attend to tokens bidirectionally
  it is great for tasks that require a good contextual understanding of an entire sequence.
  BERT is an example of a masked language model.
Translation
Summarization
Multiple choice
</pre></div>
</div>
</section>
<section id="id12">
<h3>AUDIO<a class="headerlink" href="#id12" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Audio</span> <span class="n">classification</span>
<span class="n">Automatic</span> <span class="n">speech</span> <span class="n">recognition</span>
</pre></div>
</div>
</section>
<section id="id13">
<h3>COMPUTER VISION<a class="headerlink" href="#id13" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Image classification
Semantic segmentation
  Semantic segmentation assigns a label or class to each individual pixel of an image.
  Common real-world applications of semantic segmentation include:
      training self-driving cars to identify pedestrians and important traffic information,
      identifying cells and abnormalities in medical imagery,
      monitoring environmental changes from satellite imagery.
Video classification
Object detection
  This task is commonly used in autonomous driving for detecting things
    like pedestrians, road signs, and traffic lights.
  Other applications include counting objects in images, image search, and more.
Zero-shot object detection
Zero-shot image classification
Depth estimation

è¯´æ˜:
è¯­ä¹‰åˆ†å‰²éœ€è¦å¤„ç†æ‰€æœ‰åƒç´ ,ç›®æ ‡æ£€æµ‹åªå¤„ç†æ„Ÿå…´è¶£çš„ç›®æ ‡åŒºåŸŸã€‚
è¯­ä¹‰åˆ†å‰²ä¾§é‡å¯¹æ•´ä¸ªåœºæ™¯å…¨é¢ç†è§£,ç›®æ ‡æ£€æµ‹ä¾§é‡æ£€æµ‹ç‰¹å®šæ„Ÿå…´è¶£ç›®æ ‡ã€‚
</pre></div>
</div>
</section>
<section id="multimodal">
<h3>MULTIMODAL<a class="headerlink" href="#multimodal" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Image</span> <span class="n">captioning</span>
<span class="n">Document</span> <span class="n">Question</span> <span class="n">Answering</span>
<span class="n">Text</span> <span class="n">to</span> <span class="n">speech</span>
</pre></div>
</div>
</section>
</section>
<section id="developer-guides">
<h2>DEVELOPER GUIDES<a class="headerlink" href="#developer-guides" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p>ç”Ÿæˆæ–‡æœ¬çš„æ¨¡å‹åŒ…æ‹¬:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">GPT2</span>
<span class="n">XLNet</span>
<span class="n">OpenAI</span> <span class="n">GPT</span>
<span class="n">CTRL</span>
<span class="n">TransformerXL</span>
<span class="n">XLM</span>
<span class="n">Bart</span>
<span class="n">T5</span>
<span class="n">GIT</span>
<span class="n">Whisper</span>
</pre></div>
</div>
<section id="transformers-notebooks-with-examples">
<h3>Transformers Notebooks with examples<a class="headerlink" href="#transformers-notebooks-with-examples" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://huggingface.co/docs/transformers/notebooks">https://huggingface.co/docs/transformers/notebooks</a></p></li>
</ul>
</section>
<section id="community-resources">
<h3>Community resources<a class="headerlink" href="#community-resources" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://huggingface.co/docs/transformers/community">https://huggingface.co/docs/transformers/community</a></p></li>
</ul>
</section>
</section>
<section id="performance-and-scalability">
<h2>PERFORMANCE AND SCALABILITY<a class="headerlink" href="#performance-and-scalability" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p>Trainer supports four hyperparameter search backends currently:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">optuna</span><span class="p">,</span> <span class="n">sigopt</span><span class="p">,</span> <span class="n">raytune</span> <span class="ow">and</span> <span class="n">wandb</span>
</pre></div>
</div>
</section>
<section id="conceptual-guides">
<h2>CONCEPTUAL GUIDES<a class="headerlink" href="#conceptual-guides" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<section id="philosophy">
<h3>Philosophy<a class="headerlink" href="#philosophy" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>three standard classes required to use each model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>1. configuration
2. models
3. a preprocessing class

     1) tokenizer for NLP(AutoTokenizer)
     2) image processor for vision(AutoImageProcessor)
     3) feature extractor for audio(AutoFeatureExtractor)
     4) processor for multimodal inputs(AutoProcessor)
</pre></div>
</div>
<p>On top of those three base classes, the library provides two APIs:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">1.</span> <span class="n">pipeline</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">quickly</span> <span class="n">using</span> <span class="n">a</span> <span class="n">model</span> <span class="k">for</span> <span class="n">inference</span> <span class="n">on</span> <span class="n">a</span> <span class="n">given</span> <span class="n">task</span>
<span class="mf">2.</span> <span class="n">Trainer</span>
    <span class="n">to</span> <span class="n">quickly</span> <span class="n">train</span> <span class="ow">or</span> <span class="n">fine</span><span class="o">-</span><span class="n">tune</span> <span class="n">a</span> <span class="n">PyTorch</span> <span class="n">model</span>
</pre></div>
</div>
<section id="main-concepts">
<h4>Main concepts<a class="headerlink" href="#main-concepts" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p>Model classes can be PyTorch models (torch.nn.Module), Keras models (tf.keras.Model) or JAX/Flax models (flax.linen.Module) that work with the pretrained weights provided in the library.</p></li>
<li><p>Configuration classes store the hyperparameters required to build a model (such as the number of layers and hidden size). You donâ€™t always need to instantiate these yourself. In particular, if you are using a pretrained model without any modification, creating the model will automatically take care of instantiating the configuration (which is part of the model).</p></li>
<li><p>Preprocessing classes convert the raw data into a format accepted by the model. A tokenizer stores the vocabulary for each model and provide methods for encoding and decoding strings in a list of token embedding indices to be fed to a model. Image processors preprocess vision inputs, feature extractors preprocess audio inputs, and a processor handles multimodal inputs.</p></li>
</ul>
<p>All these classes have these three methods:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">from_pretrained</span><span class="p">()</span>
<span class="n">save_pretrained</span><span class="p">()</span>
<span class="n">push_to_hub</span><span class="p">()</span>
</pre></div>
</div>
</section>
</section>
<section id="glossary">
<h3>Glossary<a class="headerlink" href="#glossary" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>attention mask
    è¯¥å‚æ•°å‘æ¨¡å‹æŒ‡ç¤ºå“ªäº›æ ‡è®°åº”è¯¥è¢«å…³æ³¨ï¼Œå“ªäº›æ ‡è®°ä¸åº”è¯¥è¢«å…³æ³¨ã€‚
    ä¸¤ä¸ªæœ‰ä¸åŒçš„é•¿åº¦çš„åºåˆ—æ”¾åœ¨åŒä¸€ä¸ªå¼ é‡ä¸­æ—¶ä½¿ç”¨
    æ³¨æ„æ©ç æ˜¯ä¸€ä¸ªäºŒè¿›åˆ¶å¼ é‡ï¼ŒæŒ‡ç¤ºå¡«å……ç´¢å¼•çš„ä½ç½®ï¼Œä»¥ä¾¿æ¨¡å‹ä¸ä¼šå…³æ³¨å®ƒä»¬

autoencoding models
    See `encoder models` and `masked language modeling`

autoregressive models
    See `causal language modeling` and `decoder models`

backbone
    backbone is the network (embeddings and layers) that outputs the raw hidden states or features.
    It is usually connected to a head which accepts the features as its input to make a prediction.
    For example,
        `ViTModel` is a `backbone` without a specific head on top.
        Other models can also use `VitModel` as a `backbone` such as DPT.

causal language modeling
    é¢„è®­ç»ƒä»»åŠ¡ï¼Œæ¨¡å‹æŒ‰é¡ºåºè¯»å–æ–‡æœ¬å¹¶å¿…é¡»é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯

channel
    å½©è‰²å›¾åƒç”±çº¢ã€ç»¿ã€è“ (RGB) ä¸‰ä¸ªé€šé“ä¸­çš„å€¼çš„æŸç§ç»„åˆç»„æˆï¼Œè€Œç°åº¦å›¾åƒåªæœ‰ä¸€ä¸ªé€šé“
    åœ¨ ğŸ¤— Transformers ä¸­ï¼Œé€šé“å¯ä»¥æ˜¯å›¾åƒå¼ é‡çš„ç¬¬ä¸€ä¸ªæˆ–æœ€åä¸€ä¸ªç»´åº¦ï¼š[ n_channels , height , width ] æˆ– [ height , width , n_channels ]

connectionist temporal classification (CTC)
    ä¸€ç§å…è®¸æ¨¡å‹åœ¨ä¸ç¡®åˆ‡çŸ¥é“è¾“å…¥å’Œè¾“å‡ºå¦‚ä½•å¯¹é½çš„æƒ…å†µä¸‹è¿›è¡Œå­¦ä¹ çš„ç®—æ³•
     CTC é€šå¸¸ç”¨äºè¯­éŸ³è¯†åˆ«ä»»åŠ¡ï¼Œç”±äºå¤šç§åŸå› ï¼ˆä¾‹å¦‚è¯´è¯è€…çš„è¯­é€Ÿä¸åŒï¼‰ï¼Œè¯­éŸ³å¹¶ä¸æ€»æ˜¯ä¸æ–‡æœ¬å®Œå…¨ä¸€è‡´ã€‚

convolution
    ç¥ç»ç½‘ç»œä¸­çš„ä¸€ç§å±‚ï¼Œå…¶ä¸­è¾“å…¥çŸ©é˜µä¸ä¸€ä¸ªè¾ƒå°çš„çŸ©é˜µï¼ˆå†…æ ¸æˆ–è¿‡æ»¤å™¨ï¼‰ç›¸ä¹˜ï¼Œå¹¶å°†å€¼æ±‚å’Œåˆ°ä¸€ä¸ªæ–°çŸ©é˜µä¸­
    å·ç§¯ç¥ç»ç½‘ç»œ (CNN) å¸¸ç”¨äºè®¡ç®—æœºè§†è§‰

decoder input IDs
    This input is specific to encoder-decoder models, and contains the input IDs that will be fed to the decoder.
    These inputs should be used for sequence to sequence tasks, such as translation or summarization, and are usually built in a way specific to each model.

decoder models
    ä¹Ÿå«: autoregressive models
    decoder models involve a pretraining task (called causal language modeling) where the model reads the texts in order and has to predict the next word.
    Itâ€™s usually done by reading the whole sentence with a mask to hide future tokens at a certain timestep.

encoder models
    ä¹Ÿå«: autoencoding models
    encoder models take an input (such as text or images) and transform them into a condensed(å‹ç¼©) numerical representation called an embedding.
    Oftentimes, encoder models are pretrained using techniques like `masked language modeling`,
        which masks parts of the input sequence and forces the model to create more meaningful representations.

feature extraction
    The process of selecting and transforming raw data into a set of features that are more informative and useful for machine learning algorithms.
    Some examples of feature extraction include
        transforming raw text into word embeddings
        and extracting important features such as edges or shapes from image/video data.

feed forward chunking
    å‚è§ä¸‹é¢è¯¦è§£

finetuned models
    Finetuning is a form of transfer learning which involves
        taking a pretrained model, freezing its weights, and replacing the output layer with a newly added model head.
    The model head is trained on your target dataset.

head
    The model head refers to the last layer of a neural network that accepts the raw hidden states and projects them onto a different dimension.
    There is a different model head for each task.
    For example:
        GPT2ForSequenceClassification is a sequence classification head - a linear layer - on top of the base GPT2Model.
        ViTForImageClassification is an image classification head - a linear layer on top of the final hidden state of the CLS token - on top of the base ViTModel.
        Wav2Vec2ForCTC is a language modeling head with CTC on top of the base Wav2Vec2Model.

image patch
    å‚è§ä¸‹é¢è¯¦è§£
    Vision-based Transformers models split an image into smaller patches which are linearly embedded,
        and then passed as a sequence to the model.
    You can find the patch_size - or resolution - of the model in its configuration.


inference
    Inference is the process of evaluating a model on new data after training is complete.

input IDs
    The input ids are often the only required parameters to be passed to the model as input.
    They are token indices, numerical representations of tokens building the sequences that will be used as input by the model.

labels
    The labels are an optional argument which can be passed in order for the model to compute the loss itself.
    These labels should be the expected prediction of the model:
        it will use the standard loss in order to compute the loss between its predictions and the expected value (the label).

masked language modeling (MLM)
    A pretraining task where the model sees a corrupted version of the texts,
        usually done by masking some tokens randomly, and has to predict the original text.

multimodal
    A task that combines texts with another kind of inputs (for instance images).

pipeline
    Transformers ä¸­çš„ç®¡é“æ˜¯ä¸€ä¸ªæŠ½è±¡ï¼ŒæŒ‡çš„æ˜¯æŒ‰ç‰¹å®šé¡ºåºæ‰§è¡Œçš„ä¸€ç³»åˆ—æ­¥éª¤ï¼Œç”¨äºé¢„å¤„ç†å’Œè½¬æ¢æ•°æ®å¹¶ä»æ¨¡å‹è¿”å›é¢„æµ‹

pixel values
    ä¼ é€’ç»™æ¨¡å‹çš„å›¾åƒæ•°å€¼è¡¨ç¤ºçš„å¼ é‡ã€‚
    pixel valuesçš„å½¢çŠ¶ä¸º [ batch_size , num_channels , height , width ]ï¼Œç”±å›¾åƒå¤„ç†å™¨ç”Ÿæˆã€‚

pooling
    é€šè¿‡å–æ± åŒ–ç»´åº¦çš„æœ€å¤§å€¼æˆ–å¹³å‡å€¼ï¼Œå°†çŸ©é˜µç¼©å‡ä¸ºæ›´å°çš„çŸ©é˜µçš„æ“ä½œ
    æ± åŒ–å±‚é€šå¸¸ä½äºå·ç§¯å±‚ä¹‹é—´ï¼Œç”¨äºå¯¹ç‰¹å¾è¡¨ç¤ºè¿›è¡Œä¸‹é‡‡æ ·

position IDs

representation learning
    æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä¸“æ³¨äºå­¦ä¹ åŸå§‹æ•°æ®çš„æœ‰æ„ä¹‰çš„è¡¨ç¤ºã€‚
    è¡¨ç¤ºå­¦ä¹ æŠ€æœ¯çš„ä¸€äº›ç¤ºä¾‹åŒ…æ‹¬è¯åµŒå…¥ã€è‡ªåŠ¨ç¼–ç å™¨å’Œç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GAN)ã€‚

self-attention
    Each element of the input finds out which other elements of the input they should attend to.
    è¾“å…¥çš„æ¯ä¸ªå…ƒç´ éƒ½ä¼šæ‰¾å‡ºå®ƒä»¬åº”è¯¥å…³æ³¨è¾“å…¥çš„å“ªäº›å…¶ä»–å…ƒç´ ã€‚

self-supervised learning
semi-supervised learning

sequence-to-sequence (seq2seq)
    ä»è¾“å…¥ç”Ÿæˆæ–°åºåˆ—çš„æ¨¡å‹ï¼Œä¾‹å¦‚ç¿»è¯‘æ¨¡å‹æˆ–æ‘˜è¦æ¨¡å‹

stride
    åœ¨å·ç§¯æˆ–æ± åŒ–ä¸­ï¼Œæ­¥å¹…æ˜¯æŒ‡å†…æ ¸åœ¨çŸ©é˜µä¸Šç§»åŠ¨çš„è·ç¦»ã€‚
    æ­¥å¹…ä¸º 1 è¡¨ç¤ºå†…æ ¸ä¸€æ¬¡ç§»åŠ¨ä¸€ä¸ªåƒç´ ï¼Œæ­¥å¹…ä¸º 2 è¡¨ç¤ºå†…æ ¸ä¸€æ¬¡ç§»åŠ¨ä¸¤ä¸ªåƒç´ ã€‚

token
    A part of a sentence, usually a word, but can also be a subword (non-common words are often split in subwords) or a punctuation symbol.

token Type IDs
    è¿™äº›éœ€è¦å°†ä¸¤ä¸ªä¸åŒçš„åºåˆ—è¿æ¥åˆ°å•ä¸ªâ€œinput_idsâ€æ¡ç›®ä¸­ï¼Œè¿™é€šå¸¸æ˜¯åœ¨ç‰¹æ®Šæ ‡è®°çš„å¸®åŠ©ä¸‹æ‰§è¡Œçš„ï¼Œ
    ä¾‹å¦‚åˆ†ç±»å™¨ï¼ˆclassifier [CLS] ï¼‰å’Œåˆ†éš”ç¬¦ï¼ˆseparator [SEP] ï¼‰æ ‡è®°ã€‚

transfer learning
    ä¸€ç§æ¶‰åŠé‡‡ç”¨é¢„è®­ç»ƒæ¨¡å‹å¹¶å°†å…¶é€‚åº”ç‰¹å®šäºæ‚¨çš„ä»»åŠ¡çš„æ•°æ®é›†çš„æŠ€æœ¯ã€‚
    æ‚¨å¯ä»¥åˆ©ç”¨ä»ç°æœ‰æ¨¡å‹è·å¾—çš„çŸ¥è¯†ä½œä¸ºèµ·ç‚¹ï¼Œè€Œä¸æ˜¯ä»å¤´å¼€å§‹è®­ç»ƒæ¨¡å‹ã€‚è¿™åŠ å¿«äº†å­¦ä¹ è¿‡ç¨‹å¹¶å‡å°‘äº†æ‰€éœ€çš„è®­ç»ƒæ•°æ®é‡ã€‚
</pre></div>
</div>
<section id="feed-forward-chunking">
<h4>feed forward chunking<a class="headerlink" href="#feed-forward-chunking" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p>from llm</p></li>
<li><p>Feed Forward Chunking æ˜¯ä¸€ç§ç”¨äºå‡å°‘å†…å­˜æ¶ˆè€—çš„æŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯åœ¨ Transformer æ¨¡å‹ä¸­çš„å‰é¦ˆç¥ç»ç½‘ç»œå±‚ï¼ˆFeed Forward Layersï¼‰çš„è®¡ç®—ä¸­</p></li>
</ul>
<p>èƒŒæ™¯ï¼šTransformer æ¨¡å‹ä¸­çš„å‰é¦ˆç½‘ç»œ:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>åœ¨ Transformer æ¨¡å‹çš„æ¯ä¸ªæ®‹å·®æ³¨æ„åŠ›å—ï¼ˆResidual Attention Blockï¼‰ä¸­ï¼Œé€šå¸¸åŒ…å«ä»¥ä¸‹ä¸¤éƒ¨åˆ†ï¼š
    1. è‡ªæ³¨æ„åŠ›å±‚ï¼ˆSelf-Attention Layerï¼‰
    2. å‰é¦ˆç½‘ç»œï¼ˆFeed Forward Networkï¼ŒFFNï¼‰
å‰é¦ˆç½‘ç»œé€šå¸¸ç”±ä¸¤å±‚çº¿æ€§å±‚ç»„æˆï¼š
    ç¬¬ä¸€å±‚å°†è¾“å…¥åµŒå…¥ï¼ˆembeddingï¼‰ä»éšè—å±‚å¤§å°ï¼ˆhidden_sizeï¼‰æŠ•å½±åˆ°ä¸€ä¸ªæ›´é«˜ç»´åº¦çš„ä¸­é—´å±‚å¤§å°ï¼ˆintermediate_sizeï¼‰
    ç¬¬äºŒå±‚å°†ä¸­é—´å±‚çš„è¾“å‡ºå†æŠ•å½±å›éšè—å±‚å¤§å°ã€‚
</pre></div>
</div>
<ul>
<li><p>ä¾‹ï¼šå¯¹äº BERT æ¨¡å‹ï¼Œintermediate_size æ¯” hidden_size æ›´å¤§ï¼Œè¿™æ ·åšæ˜¯ä¸ºäº†å¢åŠ æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç”±äºè¾“å…¥çš„å°ºå¯¸æ˜¯ [batch_size, sequence_length, hidden_size]ï¼Œä¸­é—´å±‚çš„å°ºå¯¸ä¼šå˜ä¸º [batch_size, sequence_length, intermediate_size]ï¼Œåœ¨ intermediate_size è¾ƒå¤§çš„æƒ…å†µä¸‹ï¼Œè¿™ä¼šå ç”¨å¤§é‡å†…å­˜ã€‚</p></li>
<li><p>ã€é—®é¢˜ï¼šå†…å­˜å¼€é”€ã€‘å½“è¾“å…¥æœ‰è¾ƒé•¿çš„åºåˆ—é•¿åº¦ï¼ˆsequence_lengthï¼‰æ—¶ï¼Œå­˜å‚¨è¿™äº›ä¸­é—´åµŒå…¥ä¼šå¯¼è‡´å·¨å¤§çš„å†…å­˜å ç”¨ã€‚å¯¹äºå¤§å‹ Transformer æ¨¡å‹ï¼Œè¿™ç§å†…å­˜å¼€é”€æ˜¯ç“¶é¢ˆä¹‹ä¸€ã€‚</p></li>
<li><p>ã€è§£å†³æ–¹æ¡ˆFeed Forward Chunkingã€‘ä¸»è¦æ€æƒ³æ˜¯ï¼šä¸å†ä¸€æ¬¡æ€§å¯¹æ•´ä¸ªè¾“å…¥åºåˆ—çš„æ‰€æœ‰ä½ç½®è®¡ç®—å‰é¦ˆç½‘ç»œçš„è¾“å‡ºï¼Œè€Œæ˜¯å°†è¾“å…¥åºåˆ—æŒ‰å—ï¼ˆchunkï¼‰è¿›è¡Œåˆ†å‰²ï¼Œé€å—è®¡ç®—å‰é¦ˆå±‚çš„è¾“å‡ºã€‚</p></li>
<li><p>å…·ä½“æ­¥éª¤å¦‚ä¸‹:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>1. å°†è¾“å…¥çš„ [batch_size, sequence_length, hidden_size] åˆ‡åˆ†ä¸ºè‹¥å¹²å°å—ï¼Œæ¯ä¸€å°å—çš„å¤§å°ä¸º [batch_size, chunk_size, hidden_size]
2. å¯¹æ¯ä¸ªå°å—å•ç‹¬è¿›è¡Œå‰é¦ˆç½‘ç»œçš„è®¡ç®—ï¼Œå¾—åˆ°å¯¹åº”çš„è¾“å‡º
3. å°†è¿™äº›å°å—çš„è¾“å‡ºæ‹¼æ¥ï¼ˆconcatï¼‰æˆå®Œæ•´çš„è¾“å‡º [batch_size, sequence_length, hidden_size]
</pre></div>
</div>
</li>
<li><p>ã€å…³é”®ç‚¹ï¼šä¸ºä»€ä¹ˆèƒ½è¿™æ ·åšã€‘å‰é¦ˆç½‘ç»œçš„è®¡ç®—æ˜¯ä½ç½®ç‹¬ç«‹çš„ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œåºåˆ—ä¸­æ¯ä¸ªä½ç½®çš„å‰é¦ˆç½‘ç»œè¾“å‡ºåªä¾èµ–äºè¯¥ä½ç½®çš„è¾“å…¥ï¼Œè€Œä¸ä¼šå—å…¶ä»–ä½ç½®çš„å½±å“ã€‚å› æ­¤ï¼Œå°†åºåˆ—æŒ‰å—åˆ†å‰²å¹¶é€å—è®¡ç®—ï¼Œæœ€ç»ˆæ‹¼æ¥èµ·æ¥çš„ç»“æœå’Œä¸€æ¬¡æ€§è®¡ç®—æ•´ä¸ªåºåˆ—çš„ç»“æœæ˜¯æ•°å­¦ç­‰ä»·çš„ã€‚</p></li>
<li><p>ã€å†…å­˜ä¸è®¡ç®—æ—¶é—´çš„æƒè¡¡ã€‘1.å‡å°‘å†…å­˜æ¶ˆè€—ï¼šé€šè¿‡å°†åºåˆ—åˆ†å—ï¼Œåªéœ€è¦ä¸ºæ¯ä¸ªå°å—åˆ†é…å†…å­˜ï¼Œè€Œä¸æ˜¯æ•´ä¸ªåºåˆ—ï¼Œè¿™æ˜¾è‘—å‡å°‘äº†ä¸­é—´åµŒå…¥çš„å†…å­˜å¼€é”€ã€‚2.å¢åŠ è®¡ç®—æ—¶é—´ï¼šè™½ç„¶å†…å­˜å¼€é”€å‡å°‘äº†ï¼Œä½†è®¡ç®—æ—¶é—´ä¼šå¢åŠ ã€‚åŸå› æ˜¯ï¼Œæ¨¡å‹ä¸èƒ½ä¸€æ¬¡æ€§å¹¶è¡Œè®¡ç®—æ‰€æœ‰åºåˆ—ä½ç½®ï¼Œè€Œæ˜¯éœ€è¦é€å—è®¡ç®—ï¼Œè¿™ä¼šå¸¦æ¥é¢å¤–çš„æ—¶é—´å¼€é”€ã€‚</p></li>
<li><p>ã€æ€»ç»“ã€‘Feed Forward Chunking æ˜¯ä¸€ç§é€šè¿‡é€å—è®¡ç®—å‰é¦ˆç½‘ç»œæ¥é™ä½å†…å­˜å ç”¨çš„æŠ€æœ¯ï¼Œå®ƒåœ¨ Transformer æ¨¡å‹ä¸­å°¤ä¸ºé‡è¦ï¼Œç‰¹åˆ«æ˜¯å½“è¾“å…¥åºåˆ—è¾ƒé•¿ã€éšè—å±‚å’Œä¸­é—´å±‚è¾ƒå¤§æ—¶ã€‚è™½ç„¶è¿™ç§æ–¹æ³•ä¼šå¢åŠ è®¡ç®—æ—¶é—´ï¼Œä½†é€šè¿‡é€‚å½“é€‰æ‹© chunk_sizeï¼Œå¯ä»¥åœ¨è®¡ç®—æ—¶é—´å’Œå†…å­˜ä½¿ç”¨ä¹‹é—´æ‰¾åˆ°ä¸€ä¸ªå¹³è¡¡ã€‚</p></li>
</ul>
</section>
<section id="image-patch">
<h4>image patch<a class="headerlink" href="#image-patch" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul>
<li><p>Image patch æ˜¯è§†è§‰Transformerï¼ˆVision Transformersï¼ŒViTsï¼‰æ¨¡å‹ä¸­çš„ä¸€ä¸ªæ ¸å¿ƒæ¦‚å¿µï¼Œç”¨äºå°†è¾“å…¥å›¾åƒè½¬æ¢ä¸ºé€‚åˆ Transformer å¤„ç†çš„åºåˆ—æ ¼å¼ã€‚</p></li>
<li><p>åœ¨ä¼ ç»Ÿçš„å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ä¸­ï¼Œè¾“å…¥å›¾åƒä¼šç»è¿‡å·ç§¯æ ¸ï¼ˆfiltersï¼‰é€å±‚æå–å±€éƒ¨ç‰¹å¾ã€‚CNNæ“…é•¿æ•æ‰å±€éƒ¨çš„ç©ºé—´å…³ç³»ï¼Œä½†åœ¨å»ºæ¨¡è¿œè·ç¦»ä¾èµ–ï¼ˆlong-range dependenciesï¼‰ä¸Šå­˜åœ¨ä¸€å®šçš„é™åˆ¶ã€‚</p></li>
<li><p>Vision Transformer åˆ™å¼•å…¥äº†å’Œè‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„ Transformer ç±»ä¼¼çš„æ¶æ„ï¼Œè¯•å›¾å°†å›¾åƒä¹Ÿå¤„ç†æˆä¸€ç§åºåˆ—åŒ–è¾“å…¥ï¼Œå¹¶é€šè¿‡è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆSelf-Attentionï¼‰æ¥æ•æ‰å…¨å±€å’Œå±€éƒ¨ç‰¹å¾ã€‚</p></li>
<li><p>ã€å®šä¹‰ã€‘åœ¨ Vision Transformer æ¨¡å‹ä¸­ï¼Œå›¾åƒé¦–å…ˆè¢«åˆ’åˆ†ä¸ºå›ºå®šå¤§å°çš„å°å—ï¼Œç§°ä¸º image patchesï¼Œæ¯ä¸ªå°å—éƒ½æ˜¯å›¾åƒçš„ä¸€ä¸ªå±€éƒ¨åŒºåŸŸã€‚å…·ä½“æ¥è¯´ï¼š</p>
<blockquote>
<div><ul class="simple">
<li><p>1.åˆ’åˆ†å›¾åƒï¼šVision Transformer å°†ä¸€å¼ å›¾åƒï¼ˆä¾‹å¦‚ 224x224 çš„ RGB å›¾åƒï¼‰æŒ‰ç…§å›ºå®šå¤§å°ï¼ˆä¾‹å¦‚ 16x16ï¼‰çš„ç½‘æ ¼åˆ’åˆ†ä¸ºè‹¥å¹²ä¸ªå°å—ï¼ˆpatchesï¼‰ã€‚å¦‚æœå›¾åƒæ˜¯ 224x224ï¼Œä¸” patch å¤§å°æ˜¯ 16x16ï¼Œé‚£ä¹ˆæœ€ç»ˆä¼šå¾—åˆ° (224 / 16) * (224 / 16) = 14 * 14 = 196 ä¸ªå›¾åƒå—ï¼Œæ¯ä¸ªå›¾åƒå—çš„å°ºå¯¸æ˜¯ 16x16x3ï¼ˆRGB å›¾åƒæœ‰ 3 ä¸ªé€šé“ï¼‰ã€‚</p></li>
<li><ol class="arabic simple" start="2">
<li><p>çº¿æ€§åµŒå…¥ï¼šæ¯ä¸ª 16x16x3 çš„å›¾åƒå—ä¼šè¢«å±•å¹³æˆä¸€ä¸ªå‘é‡ï¼ˆ1Dï¼‰ï¼Œç„¶åé€šè¿‡ä¸€ä¸ªçº¿æ€§å˜æ¢ï¼ˆçº¿æ€§å±‚ï¼‰å°†å…¶æ˜ å°„åˆ°æ¨¡å‹çš„åµŒå…¥ç»´åº¦ï¼ˆembedding dimensionï¼‰ï¼Œè¿™ä¸ä¼ ç»Ÿ Transformer çš„è¯å‘é‡ç±»ä¼¼ã€‚</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="3">
<li><p>ä½œä¸ºåºåˆ—è¾“å…¥ Transformerï¼šè¿™äº›åµŒå…¥åçš„å›¾åƒå—ï¼ˆpatchesï¼‰è¢«è§†ä¸ºåºåˆ—çš„å…ƒç´ ï¼Œç±»ä¼¼äº NLP ä¸­çš„è¯å‘é‡ï¼Œä½œä¸ºè¾“å…¥åºåˆ—ä¼ é€’ç»™ Transformerã€‚æ¯ä¸ª patch ç›¸å½“äºè¾“å…¥åºåˆ—ä¸­çš„ä¸€ä¸ªâ€œè¯â€ã€‚</p></li>
</ol>
</li>
</ul>
</div></blockquote>
</li>
<li><p>å› æ­¤ï¼ŒVision Transformer æ¨¡å‹å°†ä¸€å¼ äºŒç»´å›¾åƒè½¬æ¢æˆäº†ä¸€ä¸ªåºåˆ—åŒ–çš„è¡¨ç¤ºå½¢å¼ï¼Œå¹¶é€šè¿‡ Transformer çš„è‡ªæ³¨æ„åŠ›æœºåˆ¶è¿›è¡Œå¤„ç†ã€‚</p></li>
<li><p>ã€1. Patch Size çš„é€‰æ‹©ã€‘Patch size æ˜¯æŒ‡åˆ’åˆ†å›¾åƒæ—¶æ¯ä¸ªå°å—çš„å¤§å°ã€‚è¾ƒå¤§çš„ patch size ä¼šå°†æ›´å¤šçš„å±€éƒ¨ä¿¡æ¯é›†ä¸­åˆ°ä¸€ä¸ª patch ä¸­ï¼Œä½†åŒæ—¶ä¹Ÿä¼šé™ä½å›¾åƒçš„åˆ†è¾¨ç‡ï¼Œå¯èƒ½ä¼šä¸¢å¤±ä¸€äº›ç»†èŠ‚ã€‚è¾ƒå°çš„ patch size åˆ™ä¼šå¢åŠ åºåˆ—é•¿åº¦ï¼ˆæ›´å¤šçš„ patchesï¼‰ï¼Œä½¿å¾— Transformer èƒ½å¤Ÿæ•æ‰æ›´å¤šçš„ç»†èŠ‚ï¼Œä½†ä¹Ÿå¢åŠ äº†è®¡ç®—å¤æ‚åº¦ã€‚ä¾‹å¦‚ï¼Œå¯¹äº 224x224 çš„å›¾åƒï¼Œä½¿ç”¨ 16x16 çš„ patch ä¼šç”Ÿæˆ 196 ä¸ª patchesï¼Œè€Œä½¿ç”¨ 8x8 çš„ patch åˆ™ä¼šç”Ÿæˆ 784 ä¸ª patchesã€‚</p></li>
<li><p>ã€2. çº¿æ€§åµŒå…¥ã€‘æ¯ä¸ª image patch è¢«å±•å¹³æˆä¸€ç»´å‘é‡ï¼Œå¹¶é€šè¿‡çº¿æ€§å±‚å°†å…¶æ˜ å°„åˆ°ä¸€ä¸ªå›ºå®šçš„ç»´åº¦ï¼ˆæ¯”å¦‚ 768 ç»´ï¼‰ï¼Œè¿™ä¸ªæ“ä½œæ˜¯ä¸ºäº†ä½¿æ‰€æœ‰ patches çš„è¡¨ç¤ºç»´åº¦ä¸ Transformer æ¨¡å‹çš„è¾“å…¥ç»´åº¦åŒ¹é…ã€‚</p></li>
<li><p>ã€3. è‡ªæ³¨æ„åŠ›æœºåˆ¶å¦‚ä½•ä½œç”¨äº Patchesã€‘åœ¨ Vision Transformer ä¸­ï¼Œè‡ªæ³¨æ„åŠ›æœºåˆ¶ä¼šå…³æ³¨æ¯ä¸ª patch å’Œå…¶ä»–æ‰€æœ‰ patches ä¹‹é—´çš„å…³ç³»ï¼Œä»è€Œå»ºæ¨¡å…¨å±€ç‰¹å¾ã€‚ä¸ CNN ä¸åŒï¼ŒVision Transformer ä¸å±€é™äºå±€éƒ¨æ„Ÿå—é‡ï¼ˆreceptive fieldï¼‰ï¼Œå®ƒå¯ä»¥ç›´æ¥æ•æ‰å›¾åƒä¸­è¿œè·ç¦»çš„ä¾èµ–å…³ç³»ã€‚</p></li>
<li><p>ã€4. é…ç½®ä¸­çš„ patch_sizeã€‘æ¨¡å‹çš„é…ç½®æ–‡ä»¶é€šå¸¸ä¼šåŒ…å« patch_sizeï¼Œè¿™è¡¨ç¤ºæ¯ä¸ª patch çš„åˆ†è¾¨ç‡ï¼ˆä¾‹å¦‚ 16x16ï¼‰ï¼Œå®ƒç›´æ¥å†³å®šäº†å›¾åƒè¢«åˆ†å‰²çš„ç²’åº¦ã€‚å¯ä»¥ç†è§£ä¸º patch_size æ§åˆ¶äº† Transformer å¤„ç†å›¾åƒçš„â€œå•ä½â€ï¼Œç±»ä¼¼äºåœ¨ NLP ä¸­çš„ tokenï¼ˆè¯å…ƒï¼‰ã€‚</p></li>
<li><p>ã€å›¾åƒå—ï¼ˆpatchesï¼‰çš„é‡è¦æ€§ã€‘</p>
<blockquote>
<div><ul class="simple">
<li><p>å±€éƒ¨ä¸å…¨å±€ç‰¹å¾ç»“åˆï¼šå›¾åƒå—åœ¨æ¨¡å‹ä¸­æ‰®æ¼”äº†è¯å…ƒï¼ˆtokensï¼‰çš„è§’è‰²ï¼Œå®ƒä»¬ä»£è¡¨å›¾åƒçš„å±€éƒ¨ä¿¡æ¯ï¼Œè€Œ Transformer çš„è‡ªæ³¨æ„åŠ›æœºåˆ¶å¯ä»¥åœ¨è¿™äº›å±€éƒ¨ä¿¡æ¯ä¹‹é—´è¿›è¡Œå…¨å±€å»ºæ¨¡ã€‚è¿™ç§æœºåˆ¶ä½¿å¾— ViTs èƒ½å¤ŸåŒæ—¶æ•æ‰åˆ°å›¾åƒçš„ç»†èŠ‚ç‰¹å¾ï¼ˆå±€éƒ¨å—ä¹‹é—´çš„å…³ç³»ï¼‰å’Œæ•´ä½“ç»“æ„ï¼ˆä¸åŒå—çš„è¿œè·ç¦»å…³ç³»ï¼‰ã€‚</p></li>
<li><p>å‡å°‘è®¡ç®—å¤æ‚åº¦ï¼šé€šè¿‡å°†å›¾åƒåˆ’åˆ†ä¸ºè¾ƒå¤§çš„å›¾åƒå—ï¼ŒViT æ¨¡å‹èƒ½å¤Ÿå‡å°‘åºåˆ—é•¿åº¦ï¼Œä»è€Œé™ä½è‡ªæ³¨æ„åŠ›çš„è®¡ç®—å¤æ‚åº¦ã€‚åºåˆ—é•¿åº¦è¶ŠçŸ­ï¼Œè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„è®¡ç®—é‡è¶Šå°ã€‚</p></li>
</ul>
</div></blockquote>
</li>
<li><p>ã€æ€»ç»“ã€‘Image patch æ˜¯ Vision Transformer å°†è¾“å…¥å›¾åƒè½¬æ¢ä¸ºåºåˆ—æ ¼å¼çš„å…³é”®æ­¥éª¤ã€‚é€šè¿‡å°†å›¾åƒåˆ’åˆ†ä¸ºå°çš„å›¾åƒå—ï¼Œå¹¶å°†è¿™äº›å—é€šè¿‡çº¿æ€§åµŒå…¥æ˜ å°„åˆ°å‘é‡è¡¨ç¤ºï¼ŒViT å¯ä»¥åˆ©ç”¨ Transformer çš„è‡ªæ³¨æ„åŠ›æœºåˆ¶æ¥æ•æ‰å›¾åƒçš„å±€éƒ¨å’Œå…¨å±€ç‰¹å¾ã€‚Patch size çš„é€‰æ‹©ä¼šç›´æ¥å½±å“æ¨¡å‹çš„è®¡ç®—å¤æ‚åº¦å’Œå¯¹å›¾åƒç»†èŠ‚çš„æ•æ‰èƒ½åŠ›ã€‚</p></li>
</ul>
</section>
</section>
<section id="how-transformers-solve-tasks">
<h3>How Transformers solve tasks<a class="headerlink" href="#how-transformers-solve-tasks" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<figure class="align-default" id="id20">
<img alt="https://img.zhaoweiguo.com/uPic/2023/08/ZNMFdF.png" src="https://img.zhaoweiguo.com/uPic/2023/08/ZNMFdF.png" />
<figcaption>
<p><span class="caption-text">å¤„ç†è¿‡ç¨‹å›¾: Tokenizer-&gt; Model -&gt; Post-Processing</span><a class="headerlink" href="#id20" title="æ­¤å›¾åƒçš„æ°¸ä¹…é“¾æ¥">Â¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Wav2Vec2</span></code> for audio classification and automatic speech recognition (ASR)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Vision</span> <span class="pre">Transformer</span> <span class="pre">(ViT)</span></code> and <code class="docutils literal notranslate"><span class="pre">ConvNeXT</span></code> for image classification</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DETR</span></code> for object detection</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Mask2Former</span></code> for image segmentation</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">GLPN</span></code> for depth estimation</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">BERT</span></code> for NLP tasks like text classification, token classification and question answering that use an encoder</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">GPT2</span></code> for NLP tasks like text generation that use a decoder</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">BART</span></code> for NLP tasks like summarization and translation that use an encoder-decoder</p></li>
</ul>
<figure class="align-default" id="id21">
<img alt="https://img.zhaoweiguo.com/uPic/2023/08/YtfN6S.jpg" src="https://img.zhaoweiguo.com/uPic/2023/08/YtfN6S.jpg" />
<figcaption>
<p><span class="caption-text">Vision Transformer</span><a class="headerlink" href="#id21" title="æ­¤å›¾åƒçš„æ°¸ä¹…é“¾æ¥">Â¶</a></p>
</figcaption>
</figure>
<figure class="align-default" id="id22">
<img alt="https://img.zhaoweiguo.com/uPic/2023/08/NiMpg0.jpg" src="https://img.zhaoweiguo.com/uPic/2023/08/NiMpg0.jpg" />
<figcaption>
<p><span class="caption-text">Object detection</span><a class="headerlink" href="#id22" title="æ­¤å›¾åƒçš„æ°¸ä¹…é“¾æ¥">Â¶</a></p>
</figcaption>
</figure>
<figure class="align-default" id="id23">
<img alt="https://img.zhaoweiguo.com/uPic/2023/08/3getUU.jpg" src="https://img.zhaoweiguo.com/uPic/2023/08/3getUU.jpg" />
<figcaption>
<p><span class="caption-text">Image segmentation</span><a class="headerlink" href="#id23" title="æ­¤å›¾åƒçš„æ°¸ä¹…é“¾æ¥">Â¶</a></p>
</figcaption>
</figure>
<figure class="align-default" id="id24">
<img alt="https://img.zhaoweiguo.com/uPic/2023/08/TU69J8.jpg" src="https://img.zhaoweiguo.com/uPic/2023/08/TU69J8.jpg" />
<figcaption>
<p><span class="caption-text">Depth estimation</span><a class="headerlink" href="#id24" title="æ­¤å›¾åƒçš„æ°¸ä¹…é“¾æ¥">Â¶</a></p>
</figcaption>
</figure>
</section>
<section id="the-transformer-model-family">
<h3>The Transformer model family<a class="headerlink" href="#the-transformer-model-family" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<section id="id14">
<h4>Computer vision<a class="headerlink" href="#id14" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2023/08/RYzYvS.jpg" src="https://img.zhaoweiguo.com/uPic/2023/08/RYzYvS.jpg" />
</figure>
</section>
<section id="id15">
<h4>Natural language processing<a class="headerlink" href="#id15" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2023/08/FB5ONz.jpg" src="https://img.zhaoweiguo.com/uPic/2023/08/FB5ONz.jpg" />
</figure>
</section>
<section id="id16">
<h4>Audio<a class="headerlink" href="#id16" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2023/08/2MKAWt.jpg" src="https://img.zhaoweiguo.com/uPic/2023/08/2MKAWt.jpg" />
</figure>
</section>
<section id="id17">
<h4>Multimodal<a class="headerlink" href="#id17" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2023/08/tnCfmL.jpg" src="https://img.zhaoweiguo.com/uPic/2023/08/tnCfmL.jpg" />
</figure>
</section>
<section id="reinforcement-learning">
<h4>Reinforcement learning<a class="headerlink" href="#reinforcement-learning" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2023/08/eSDNPe.jpg" src="https://img.zhaoweiguo.com/uPic/2023/08/eSDNPe.jpg" />
</figure>
</section>
</section>
<section id="summary-of-the-tokenizers">
<h3>Summary of the tokenizers<a class="headerlink" href="#summary-of-the-tokenizers" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>3 tokenization algorithms:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">1.</span> <span class="n">word</span><span class="o">-</span><span class="n">based</span>
    <span class="n">very</span> <span class="n">large</span> <span class="n">vocabularies</span>
    <span class="n">large</span> <span class="n">quantity</span> <span class="n">of</span> <span class="n">out</span><span class="o">-</span><span class="n">of</span><span class="o">-</span><span class="n">vocabulary</span> <span class="n">tokens</span>
    <span class="n">loss</span> <span class="n">of</span> <span class="n">meaning</span> <span class="n">across</span> <span class="n">very</span> <span class="n">similar</span> <span class="n">words</span>
<span class="mf">2.</span> <span class="n">character</span><span class="o">-</span><span class="n">based</span>
    <span class="n">very</span> <span class="n">long</span> <span class="n">sequences</span>
    <span class="n">less</span> <span class="n">meaningful</span> <span class="n">individual</span> <span class="n">tokens</span>
<span class="mf">3.</span> <span class="n">subword</span><span class="o">-</span><span class="n">based</span>
    <span class="n">principles</span><span class="p">:</span>
        <span class="n">frequently</span> <span class="n">used</span> <span class="n">words</span> <span class="n">should</span> <span class="ow">not</span> <span class="n">be</span> <span class="n">split</span> <span class="n">into</span> <span class="n">subwords</span>
        <span class="n">rare</span> <span class="n">words</span> <span class="n">should</span> <span class="n">be</span> <span class="n">decompose</span> <span class="n">into</span> <span class="n">meaningful</span> <span class="n">subwords</span>
</pre></div>
</div>
<p>Subword tokenization:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">1.</span> <span class="n">Byte</span><span class="o">-</span><span class="n">Pair</span> <span class="n">Encoding</span> <span class="p">(</span><span class="n">BPE</span><span class="p">)</span>
    <span class="n">GPT</span><span class="o">-</span><span class="mi">2</span>
    <span class="n">RoBERTa</span>
<span class="mf">2.</span> <span class="n">WordPiece</span>
    <span class="n">BERT</span>
    <span class="n">DistilBERT</span>
    <span class="n">Electra</span>
<span class="mf">3.</span> <span class="n">Unigram</span><span class="o">+</span><span class="n">SentencePiece</span><span class="p">(</span><span class="n">é€‚ç”¨äºéç©ºæ ¼åˆ†éš”çš„è¯­è¨€</span><span class="p">)</span>
    <span class="n">XLNet</span>
    <span class="n">ALBERT</span>
    <span class="n">Marian</span>
    <span class="n">T5</span>
</pre></div>
</div>
</section>
<section id="padding-and-truncation">
<h3>Padding and truncation<a class="headerlink" href="#padding-and-truncation" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p>The following table summarizes the recommended way to setup padding and truncation</p></li>
</ul>
<p>padding strategy(boolean or a string):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kc">True</span> <span class="ow">or</span> <span class="s1">&#39;longest&#39;</span>
<span class="n">max_length</span>
<span class="kc">False</span> <span class="ow">or</span> <span class="s1">&#39;do_not_pad</span>
</pre></div>
</div>
<p>truncation strategy(boolean or a string):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>True or &#39;longest_first&#39;
only_second
    å½“è¾“å…¥æ¨¡å‹çš„æ˜¯ä¸¤ä¸ªåºåˆ—çš„é…å¯¹ï¼ˆä¾‹å¦‚ï¼šå¥å­å¯¹ï¼Œæˆ–æ–‡æœ¬å¯¹ï¼‰
    è¿™ç§æˆªæ–­æ–¹å¼é€‚ç”¨äºéœ€è¦ä¿æŒç¬¬ä¸€ä¸ªåºåˆ—å®Œæ•´ï¼Œè€Œå¯¹ç¬¬äºŒä¸ªåºåˆ—è¿›è¡Œè£å‰ªçš„åœºæ™¯ã€‚
only_first
    ä¸only_secondç›¸å
False or &#39;do_not_truncate&#39;
</pre></div>
</div>
<p>no truncation:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">+-----------------------------------+-----------------------------------------------------------------+</span>
<span class="o">|</span> <span class="n">no</span> <span class="n">padding</span>                        <span class="o">|</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">batch_sentences</span><span class="p">)</span>                                      <span class="o">|</span>
<span class="o">+===================================+=================================================================+</span>
<span class="o">|</span> <span class="n">padding</span> <span class="n">to</span> <span class="nb">max</span> <span class="n">sequence</span> <span class="ow">in</span> <span class="n">batch</span>  <span class="o">|</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">batch_sentences</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="ow">or</span>                     <span class="o">|</span>
<span class="o">+-----------------------------------+-----------------------------------------------------------------+</span>
<span class="o">|</span>                                   <span class="o">|</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">batch_sentences</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;longest&#39;</span><span class="p">)</span>                   <span class="o">|</span>
<span class="o">+-----------------------------------+-----------------------------------------------------------------+</span>
<span class="o">|</span> <span class="n">padding</span> <span class="n">to</span> <span class="nb">max</span> <span class="n">model</span> <span class="nb">input</span> <span class="n">length</span> <span class="o">|</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">batch_sentences</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;max_length&#39;</span><span class="p">)</span>                <span class="o">|</span>
<span class="o">+-----------------------------------+-----------------------------------------------------------------+</span>
<span class="o">|</span> <span class="n">padding</span> <span class="n">to</span> <span class="n">specific</span> <span class="n">length</span>        <span class="o">|</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">batch_sentences</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;max_length&#39;</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span> <span class="o">|</span>
<span class="o">+-----------------------------------+-----------------------------------------------------------------+</span>
<span class="o">|</span> <span class="n">padding</span> <span class="n">to</span> <span class="n">a</span> <span class="n">multiple</span> <span class="n">of</span> <span class="n">a</span> <span class="n">value</span>  <span class="o">|</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">batch_sentences</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pad_to_multiple_of</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>  <span class="o">|</span>
<span class="o">+-----------------------------------+-----------------------------------------------------------------+</span>
</pre></div>
</div>
<p>truncation to max model input length:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">+-----------------------------------+-----------------------------------------------------------------------+</span>
<span class="o">|</span> <span class="n">no</span> <span class="n">padding</span>                        <span class="o">|</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">batch_sentences</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="ow">or</span>                        <span class="o">|</span>
<span class="o">+===================================+=======================================================================+</span>
<span class="o">|</span>                                   <span class="o">|</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">batch_sentences</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="n">STRATEGY</span><span class="p">)</span>                       <span class="o">|</span>
<span class="o">+-----------------------------------+-----------------------------------------------------------------------+</span>
<span class="o">|</span> <span class="n">padding</span> <span class="n">to</span> <span class="nb">max</span> <span class="n">sequence</span> <span class="ow">in</span> <span class="n">batch</span>  <span class="o">|</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">batch_sentences</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="ow">or</span>          <span class="o">|</span>
<span class="o">+-----------------------------------+-----------------------------------------------------------------------+</span>
<span class="o">|</span>                                   <span class="o">|</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">batch_sentences</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="n">STRATEGY</span><span class="p">)</span>         <span class="o">|</span>
<span class="o">+-----------------------------------+-----------------------------------------------------------------------+</span>
<span class="o">|</span> <span class="n">padding</span> <span class="n">to</span> <span class="nb">max</span> <span class="n">model</span> <span class="nb">input</span> <span class="n">length</span> <span class="o">|</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">batch_sentences</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;max_length&#39;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="ow">or</span>  <span class="o">|</span>
<span class="o">+-----------------------------------+-----------------------------------------------------------------------+</span>
<span class="o">|</span>                                   <span class="o">|</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">batch_sentences</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;max_length&#39;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="n">STRATEGY</span><span class="p">)</span> <span class="o">|</span>
<span class="o">+-----------------------------------+-----------------------------------------------------------------------+</span>
<span class="o">|</span> <span class="n">padding</span> <span class="n">to</span> <span class="n">specific</span> <span class="n">length</span>        <span class="o">|</span> <span class="n">Not</span> <span class="n">possible</span>                                                          <span class="o">|</span>
<span class="o">+-----------------------------------+-----------------------------------------------------------------------+</span>
</pre></div>
</div>
<p>truncation to specific length:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">+-----------------------------------+--------------------------------------------------------------------------------------+</span>
<span class="o">|</span> <span class="n">no</span> <span class="n">padding</span>                        <span class="o">|</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">batch_sentences</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span> <span class="ow">or</span>                        <span class="o">|</span>
<span class="o">+===================================+======================================================================================+</span>
<span class="o">|</span>                                   <span class="o">|</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">batch_sentences</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="n">STRATEGY</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>                       <span class="o">|</span>
<span class="o">+-----------------------------------+--------------------------------------------------------------------------------------+</span>
<span class="o">|</span> <span class="n">padding</span> <span class="n">to</span> <span class="nb">max</span> <span class="n">sequence</span> <span class="ow">in</span> <span class="n">batch</span>  <span class="o">|</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">batch_sentences</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span> <span class="ow">or</span>          <span class="o">|</span>
<span class="o">+-----------------------------------+--------------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                   <span class="o">|</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">batch_sentences</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="n">STRATEGY</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>         <span class="o">|</span>
<span class="o">+-----------------------------------+--------------------------------------------------------------------------------------+</span>
<span class="o">|</span> <span class="n">padding</span> <span class="n">to</span> <span class="nb">max</span> <span class="n">model</span> <span class="nb">input</span> <span class="n">length</span> <span class="o">|</span> <span class="n">Not</span> <span class="n">possible</span>                                                                         <span class="o">|</span>
<span class="o">+-----------------------------------+--------------------------------------------------------------------------------------+</span>
<span class="o">|</span> <span class="n">padding</span> <span class="n">to</span> <span class="n">specific</span> <span class="n">length</span>        <span class="o">|</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">batch_sentences</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;max_length&#39;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span> <span class="ow">or</span>  <span class="o">|</span>
<span class="o">+-----------------------------------+--------------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                   <span class="o">|</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">batch_sentences</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;max_length&#39;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="n">STRATEGY</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span> <span class="o">|</span>
<span class="o">+-----------------------------------+--------------------------------------------------------------------------------------+</span>
</pre></div>
</div>
</section>
<section id="model-training-anatomy">
<h3>Model training anatomy<a class="headerlink" href="#model-training-anatomy" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul>
<li><p>å½“æ¨¡å‹åŠ è½½åˆ° GPU æ—¶ï¼Œ <code class="docutils literal notranslate"><span class="pre">CUDA</span> <span class="pre">çš„è¿è¡Œæ—¶åº“å’Œå†…æ ¸ï¼ˆkernelsï¼‰</span></code> ä¹Ÿä¼šåŠ è½½ï¼Œè¿™å¯èƒ½ä¼šå ç”¨ 1-2GB å†…å­˜ã€‚ä¸ºäº†æŸ¥çœ‹å®ƒæœ‰å¤šå°‘ï¼Œæˆ‘ä»¬å°†ä¸€ä¸ªå¾®å°çš„å¼ é‡åŠ è½½åˆ° GPU ä¸­ï¼Œè¿™ä¹Ÿä¼šè§¦å‘å†…æ ¸çš„åŠ è½½ã€‚</p></li>
<li><p>å¯ä»¥ç”¨ä¸‹é¢è¯­å¥éªŒè¯:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>   <span class="c1">#</span>
<span class="n">print_gpu_utilization</span><span class="p">()</span>         <span class="c1"># è¿™å„¿åŸºæœ¬å°±æ˜¯å†…æ ¸å ç”¨çš„gpuæ•°</span>

<span class="n">è¯´æ˜</span><span class="p">:</span>
    <span class="n">å†…æ ¸å ç”¨å¤šå°‘å’ŒGPUå‹å·æœ‰å…³</span>
    <span class="n">L20</span><span class="p">(</span><span class="mi">48</span><span class="n">G</span><span class="p">):</span>     <span class="mi">390</span><span class="n">M</span>   <span class="n">NVIDIA</span> <span class="n">L20</span>
    <span class="n">V100</span><span class="p">(</span><span class="mi">32</span><span class="n">G</span><span class="p">):</span>    <span class="mi">366</span><span class="n">M</span>   <span class="n">V100</span><span class="o">-</span><span class="n">SXM2</span>
        <span class="n">Volta</span> <span class="n">æ¶æ„</span>
    <span class="n">V100</span><span class="p">(</span><span class="mi">8</span><span class="n">G</span><span class="p">):</span>     <span class="mi">449</span><span class="n">M</span>   <span class="n">Tesla</span> <span class="n">P4</span>
        <span class="n">Pascal</span> <span class="n">æ¶æ„</span>
</pre></div>
</div>
</li>
<li><p>è¯·æ³¨æ„ï¼Œåœ¨è¾ƒæ–°çš„ GPU ä¸Šï¼Œæ¨¡å‹æœ‰æ—¶ä¼šå ç”¨æ›´å¤šç©ºé—´ï¼Œå› ä¸ºæƒé‡ä»¥ä¼˜åŒ–çš„æ–¹å¼åŠ è½½ï¼Œå¯ä»¥åŠ å¿«æ¨¡å‹çš„ä½¿ç”¨é€Ÿåº¦ã€‚</p></li>
</ul>
<section id="anatomy-of-models-operations">
<h4>Anatomy of Modelâ€™s Operations<a class="headerlink" href="#anatomy-of-models-operations" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>Transformers æ¶æ„åŒ…æ‹¬ 3 ä¸ªä¸»è¦æ“ä½œç»„ï¼ŒæŒ‰è®¡ç®—å¼ºåº¦åˆ†ç»„å¦‚ä¸‹:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>1. Tensor Contractions
    å¤šå¤´æ³¨æ„åŠ›çš„çº¿æ€§å±‚å’Œç»„ä»¶éƒ½è¿›è¡Œæ‰¹é‡çŸ©é˜µ-çŸ©é˜µä¹˜æ³•ã€‚è¿™äº›æ“ä½œæ˜¯è®­ç»ƒ Transformer æ—¶è®¡ç®—é‡æœ€å¤§çš„éƒ¨åˆ†
2. Statistical Normalizations
    Softmax å’Œå±‚å½’ä¸€åŒ–æ¯”å¼ é‡æ”¶ç¼©çš„è®¡ç®—å¼ºåº¦è¦å°ï¼Œå¹¶ä¸”æ¶‰åŠä¸€ä¸ªæˆ–å¤šä¸ªå½’çº¦æ“ä½œï¼Œç„¶åé€šè¿‡æ˜ å°„åº”ç”¨å…¶ç»“æœã€‚
3. Element-wise Operators
    è¿™äº›æ˜¯å‰©ä½™çš„è¿ç®—ç¬¦ï¼šåå·®ã€ä¸¢å¤±ã€æ¿€æ´»å’Œå‰©ä½™è¿æ¥ã€‚è¿™äº›æ˜¯è®¡ç®—å¼ºåº¦æœ€å°çš„æ“ä½œ
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">å¤‡æ³¨</p>
<p>åœ¨åˆ†ææ€§èƒ½ç“¶é¢ˆæ—¶äº†è§£è¿™äº›çŸ¥è¯†å¾ˆæœ‰å¸®åŠ©ã€‚This summary is derived from <a class="reference external" href="https://arxiv.org/abs/2007.00072">Data Movement Is All You Need: A Case Study on Optimizing Transformers 2020</a></p>
</div>
</section>
<section id="anatomy-of-models-memory">
<h4>Anatomy of Modelâ€™s Memory<a class="headerlink" href="#anatomy-of-models-memory" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>è®­ç»ƒæ¨¡å‹ä½¿ç”¨çš„å†…å­˜æ¯”ä»…ä»…å°†æ¨¡å‹æ”¾åœ¨ GPU ä¸Šè¦å¤šå¾—å¤šã€‚è¿™æ˜¯å› ä¸ºè®­ç»ƒæœŸé—´æœ‰è®¸å¤šç»„ä»¶ä½¿ç”¨ GPU å†…å­˜ã€‚ GPU å†…å­˜çš„ç»„æˆéƒ¨åˆ†å¦‚ä¸‹:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">1.</span> <span class="n">model</span> <span class="n">weights</span> <span class="n">æ¨¡å‹æƒé‡</span>
<span class="mf">2.</span> <span class="n">optimizer</span> <span class="n">states</span> <span class="n">ä¼˜åŒ–å™¨çŠ¶æ€</span>
<span class="mf">3.</span> <span class="n">gradients</span> <span class="n">æ¸å˜</span>
<span class="mf">4.</span> <span class="n">forward</span> <span class="n">activations</span> <span class="n">saved</span> <span class="k">for</span> <span class="n">gradient</span> <span class="n">computation</span> <span class="n">ä¸ºæ¢¯åº¦è®¡ç®—ä¿å­˜å‰å‘æ¿€æ´»</span>
<span class="mf">5.</span> <span class="n">temporary</span> <span class="n">buffers</span> <span class="n">ä¸´æ—¶ç¼“å†²åŒº</span>
<span class="mf">6.</span> <span class="n">functionality</span><span class="o">-</span><span class="n">specific</span> <span class="n">memory</span> <span class="n">ç‰¹å®šåŠŸèƒ½å­˜å‚¨å™¨</span>
</pre></div>
</div>
<p>details:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>1. Model Weights:
    4 bytes * number of parameters for fp32 training
    6 bytes * number of parameters for mixed precision training (maintains a model in fp32 and one in fp16 in memory)
2. Optimizer States:
    8 bytes * number of parameters for normal AdamW (maintains 2 states)
    2 bytes * number of parameters for 8-bit AdamW optimizers like bitsandbytes
    4 bytes * number of parameters for optimizers like SGD with momentum (maintains only 1 state)
3. Gradients
    4 bytes * number of parameters for either fp32 or mixed precision training (gradients are always kept in fp32)
4. Forward Activations
    size depends on many factors, the key ones being sequence length, hidden size and batch size.
5. Temporary Memory
    å„ç§ä¸´æ—¶å˜é‡
6. Functionality-specific memory
    ç‰¹æ®Šçš„å†…å­˜éœ€æ±‚ã€‚ä¾‹å¦‚ï¼Œå½“ä½¿ç”¨é›†æŸæœç´¢ç”Ÿæˆæ–‡æœ¬æ—¶ï¼Œè½¯ä»¶éœ€è¦ç»´æŠ¤è¾“å…¥å’Œè¾“å‡ºçš„å¤šä¸ªå‰¯æœ¬
</pre></div>
</div>
</section>
</section>
</section>
<section id="api">
<h2>API<a class="headerlink" href="#api" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<section id="main-classes">
<h3>MAIN CLASSES<a class="headerlink" href="#main-classes" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<section id="id18">
<h4>Agents<a class="headerlink" href="#id18" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>three types of Agents:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>1. `HfAgent` uses inference endpoints for opensource models
2. `LocalAgent` uses a model of your choice locally
3. `OpenAiAgent` uses OpenAI closed models
</pre></div>
</div>
</section>
<section id="auto-classes">
<h4>Auto Classes<a class="headerlink" href="#auto-classes" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>Generic classes:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">AutoConfig</span>
<span class="n">AutoModel</span>
<span class="n">AutoTokenizer</span>

<span class="n">AutoFeatureExtractor</span>
<span class="n">AutoImageProcessor</span>
<span class="n">AutoProcessor</span>
</pre></div>
</div>
<p>Generic pretraining classes:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">AutoModelForPreTraining</span>
</pre></div>
</div>
<p>Natural Language Processing:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">AutoModelForCausalLM</span>
<span class="n">AutoModelForMaskedLM</span>
<span class="n">AutoModelForMaskGeneration</span>
<span class="n">AutoModelForSeq2SeqLM</span>
<span class="n">AutoModelForSequenceClassification</span>
<span class="n">AutoModelForMultipleChoice</span>
<span class="n">AutoModelForNextSentencePrediction</span>
<span class="n">AutoModelForTokenClassification</span>
<span class="n">AutoModelForQuestionAnswering</span>
<span class="n">AutoModelForTextEncoding</span>
</pre></div>
</div>
<p>Computer vision:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">AutoModelForDepthEstimation</span>
<span class="n">AutoModelForImageClassification</span>
<span class="n">AutoModelForVideoClassification</span>
<span class="n">AutoModelForMaskedImageModeling</span>
<span class="n">AutoModelForObjectDetection</span>
<span class="n">AutoModelForImageSegmentation</span>
<span class="n">AutoModelForSemanticSegmentation</span>
<span class="n">AutoModelForInstanceSegmentation</span>
<span class="n">AutoModelForUniversalSegmentation</span>
<span class="n">AutoModelForZeroShotImageClassification</span>
<span class="n">AutoModelForZeroShotObjectDetection</span>
</pre></div>
</div>
<p>Audio:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">AutoModelForAudioClassification</span>
<span class="n">AutoModelForAudioFrameClassification</span>
<span class="n">AutoModelForCTC</span>
<span class="n">AutoModelForSpeechSeq2Seq</span>
<span class="n">AutoModelForAudioXVector</span>
</pre></div>
</div>
<p>Multimodal:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">AutoModelForTableQuestionAnswering</span>
<span class="n">AutoModelForDocumentQuestionAnswering</span>
<span class="n">AutoModelForVisualQuestionAnswering</span>
<span class="n">AutoModelForVision2Seq</span>
</pre></div>
</div>
</section>
<section id="callbacks">
<h4>Callbacks<a class="headerlink" href="#callbacks" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul>
<li><p>The main class that implements callbacks is TrainerCallback.</p></li>
<li><p>By default a Trainer will use the following callbacks:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>`DefaultFlowCallback` which handles the default behavior for logging, saving and evaluation.
`PrinterCallback` or `ProgressCallback` to display progress and print the logs
    the first one is used if you deactivate tqdm through the TrainingArguments
    otherwise itâ€™s the second one
...
</pre></div>
</div>
</li>
</ul>
</section>
<section id="logging">
<h4>Logging<a class="headerlink" href="#logging" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>æ—¥å¿—é»˜è®¤Warningçº§åˆ«ï¼Œå¯ä»¥è°ƒæ•´æˆinfoçº§åˆ«:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">transformers</span>
<span class="n">transformers</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity_info</span><span class="p">()</span>
</pre></div>
</div>
<p>ç¯å¢ƒå˜é‡è®¾ç½®:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">TRANSFORMERS_VERBOSITY</span>
</pre></div>
</div>
<p>Usage:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">logging</span>

<span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity_info</span><span class="p">()</span>
<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">get_logger</span><span class="p">(</span><span class="s2">&quot;transformers&quot;</span><span class="p">)</span>
<span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;INFO&quot;</span><span class="p">)</span>
<span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;WARN&quot;</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference external" href="/index.html">ä¸»é¡µ</a></p></td>
<td><p><a class="reference internal" href="../../../genindex.html"><span class="std std-ref">ç´¢å¼•</span></a></p></td>
<td><p><a class="reference internal" href="../../../py-modindex.html"><span class="std std-ref">æ¨¡å—ç´¢å¼•</span></a></p></td>
<td><p><a class="reference internal" href="../../../search.html"><span class="std std-ref">æœç´¢é¡µé¢</span></a></p></td>
</tr>
</tbody>
</table>
</section>
</section>
</section>
</section>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="Transformers_V4.45.2.html" class="btn btn-neutral float-right" title="Transformers 4.45.2" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../Transformers.html" class="btn btn-neutral" title="7.3.2. Transformers" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>
  
  <div id="gitalk-container"></div>
  <div role="contentinfo">
    <p>
        &copy; Copyright 2010-2025, æ–°æºª-gordon.

    </p>
  </div>
  <div>å¤‡æ¡ˆå· <a href="http://www.beian.miit.gov.cn">äº¬ICPå¤‡16018553å·</a></div><div>Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a></div>. 


</footer>

<script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?042289284b8eb33866001347a3e0b129";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
</script>     
        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../',
            VERSION:'V2025.06',
            LANGUAGE:'zh-CN',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../../../_static/doctools.js"></script>
      <script type="text/javascript" src="../../../_static/sphinx_highlight.js"></script>
      <script type="text/javascript" src="../../../_static/clipboard.min.js"></script>
      <script type="text/javascript" src="../../../_static/copybutton.js"></script>
      <script type="text/javascript" src="../../../_static/translations.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>

  

  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });


      // var gitalk = new Gitalk({
      //         clientID: '565177626b5d46427009',
      //         clientSecret: 'b2a36e67e1d2a73e43667f46d571c2624f8e1026',
      //         repo: 'knowledge',
      //         owner: 'zhaoweiguo',
      //         admin: ['zhaoweiguo'],
      //         id: location.pathname,      // Ensure uniqueness and length less than 50
      //         distractionFreeMode: false  // Facebook-like distraction free mode
      //       })
      // gitalk.render('gitalk-container')

  </script>


<script type="text/javascript" src="../../../_static/js/table-of-contents-sidebar.js"></script>
<!-- <script type="text/javascript" src="https://table-of-contents-sidebar.github.io/table-of-contents-sidebar-lib/table-of-contents-sidebar.js"></script> -->
<script type="text/javascript">
    window.onload = function(e){
        TableOfContents.init({
            basePath: "https://table-of-contents-sidebar.github.io/table-of-contents-sidebar-lib/",
            querySelector: "body" // or other css querySelector
        });
    }
</script> 

</body>
</html>