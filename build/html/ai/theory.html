

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="zh-CN" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="zh-CN" > <!--<![endif]-->
<head>


<!-- start added 2025-04-14   增加对markdown中公式的支持 -->
<script>
window.MathJax = {
    tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true
    },
    options: {
        ignoreHtmlClass: "tex2jax_ignore|mathjax_ignore",
        processHtmlClass: "tex2jax_process|mathjax_process|math|output_area"
    }
};
</script>
<script defer="defer" src="https://fastly.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<!-- end added 2025-04-14   增加对markdown中公式的支持 -->


<!-- start added 2025-08-06   增加对mermaid图的支持 -->
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', function() {
    mermaid.initialize({
        startOnLoad: true,
        theme: 'default',
        flowchart: { useMaxWidth: true }
    });
});
</script>
<!--  end added 2025-08-06   增加对mermaid图的支持 -->




  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>2. 理论 &mdash; 新溪-gordon V2025.10 文档</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
    <link rel="index" title="索引" href="genindex.html" />
    <link rel="search" title="搜索" href="search.html" />
    <link rel="next" title="2.1. 关键定义" href="theories/key.html" />
    <link rel="prev" title="1.10. 机器人领域" href="normals/%E6%9C%BA%E5%99%A8%E4%BA%BA.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>
  <script src="_static/js/jquery.min.js"></script>


<!-- 评论插件 gittalk start -->
<!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script> -->
<!-- 评论插件 gittalk end -->


</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> 新溪-gordon
          

          
          </a>

          
            
            
              <div class="version">
                V2025.10
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">AI</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="normal.html">1. 常用</a><ul>
<li class="toctree-l2"><a class="reference internal" href="normals/normal.html">1.1. 常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="normals/AIGC.html">1.2. AIGC</a></li>
<li class="toctree-l2"><a class="reference internal" href="normals/ml.html">1.3. 机器学习machine learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="normals/bi.html">1.4. BI(Business Intelligence)</a></li>
<li class="toctree-l2"><a class="reference internal" href="normals/deep_learning.html">1.5. 深度学习</a><ul>
<li class="toctree-l3"><a class="reference internal" href="normals/deep_learnings/normal.html">1.5.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="normals/deep_learnings/history.html">1.5.2. 历史</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="normals/monitor.html">1.6. monitor</a></li>
<li class="toctree-l2"><a class="reference internal" href="normals/algorithm.html">1.7. 相关算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="normals/tool.html">1.8. 工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="normals/question.html">1.9. 常见问题</a></li>
<li class="toctree-l2"><a class="reference internal" href="normals/%E6%9C%BA%E5%99%A8%E4%BA%BA.html">1.10. 机器人领域</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">2. 理论</a><ul>
<li class="toctree-l2"><a class="reference internal" href="theories/key.html">2.1. 关键定义</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Recommenders/CF%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4.html">2.1.1. 协同过滤（Collaborative Filtering, CF）</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Recommenders/MF%E6%A6%82%E7%8E%87%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3.html">2.1.2. MF(Matrix Factorization，矩阵分解)</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Recommenders/PMF%E6%A6%82%E7%8E%87%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3.html">2.1.3. PMF（Probabilistic Matrix Factorization，概率矩阵分解）</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Recommenders/Two-TowerModels%E5%8F%8C%E5%A1%94%E6%A8%A1%E5%9E%8B.html">2.1.4. Two-Tower Models（双塔模型）</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Parallelism/normal.html">2.1.5. 通用</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Parallelism/PipelineParallelism.html">2.1.6. Pipeline Parallelism</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Parallelism/TensorParallesim.html">2.1.7. Tensor Parallesim</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_activations/activation_Sigmoid.html">2.1.8. 激活函数-Sigmoid</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_activations/activation_RELU.html">2.1.9. 激活函数-ReLU</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_activations/activation_Leaky-ReLU.html">2.1.10. 激活函数-Leaky ReLU</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_activations/activation_Tanh.html">2.1.11. 激活函数-Tanh</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_activations/activation_GELU.html">2.1.12. 激活函数-GELU</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_activations/normalization_L1.html">2.1.13. 归一化-L1</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_activations/normalization_L2.html">2.1.14. 归一化-L2</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_activations/probabilistic_Softmax.html">2.1.15. 概率分布-Softmax</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_activations/probabilistic_logSoftmax.html">2.1.16. 概率分布-logsoftmax</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_activations/probabilistic_Sparsemax.html">2.1.17. 概率分布-Sparsemax</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_loss/classify_cross_entropy.html">2.1.18. 损失函数-分类-cross-entropy(交叉熵)</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_loss/classify_NLL.html">2.1.19. 损失函数-分类-负对数似然损失NLL Loss</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_loss/classify_log.html">2.1.20. 损失函数-分类-对数损失(Log Loss)</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_loss/classify_kl.html">2.1.21. 损失函数-分类-KL 散度(KL Loss)</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_loss/regression_MSE.html">2.1.22. 损失函数-回归-均方误差(MSE)</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_loss/regression_MAE.html">2.1.23. 损失函数-回归-平均绝对误差(MAE)</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_loss/regression_Huber.html">2.1.24. 损失函数-回归-Huber 损失</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_loss/regression_log_cosh.html">2.1.25. 损失函数-回归-对数余弦损失(Log-Cosh Loss)</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_loss/%E6%9D%83%E9%87%8D%E8%A1%B0%E5%87%8F-L2%E6%AD%A3%E5%88%99%E5%8C%96.html">2.1.26. 权重衰减(L2正则化)</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/GD.html">2.1.27. GD(梯度下降)</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/SGD.html">2.1.28. SGD随机梯度下降</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/RMSprop.html">2.1.29. RMSprop</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/Adam.html">2.1.30. Adam</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/AdamW.html">2.1.31. AdamW</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/Momentum.html">2.1.32. Momentum</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/ners/HMM-%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B.html">2.1.33. HMM-隐马尔可夫模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/ners/WWM-%E5%85%A8%E8%AF%8DMask.html">2.1.34. WWM-Whole Word Masking</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/ners/CRF-%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA.html">2.1.35. CRF-条件随机场</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dls/ANN.html">2.1.36. ANN(NN)</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dls/DNN-%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html">2.1.37. 深度神经网络(Deep Neural Network, DNN)</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dls/CNN-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html">2.1.38. 卷积神经网络(Convolutional Neural Network, CNN)</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dls/RNN-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91.html">2.1.39. RNN: 循环神经网(Recurrent Neural Network, RNN)</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dls/LSTM-%E9%95%BF%E7%9F%AD%E6%97%B6%E8%AE%B0%E5%BF%86.html">2.1.40. LSTM: 长短时记忆(Long Short Term Memory, LSTM)</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/propagation.html">2.1.41. 前向/反向传播</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/LinearLayer.html">2.1.42. Linear Layer</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/FFN.html">2.1.43. Feedforward Network-前馈网络</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/LayerNorm.html">2.1.44. LayerNorm(层归一化)</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/WeightTying.html">2.1.45. Weight Tying</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/GreedyDecoding.html">2.1.46. Greedy Decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/ImageGrounding.html">2.1.47. Image Grounding</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/Perplexity.html">2.1.48. Perplexity(PPL)困惑度</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/ManhattanWorld%E6%9B%BC%E5%93%88%E9%A1%BF%E4%B8%96%E7%95%8C.html">2.1.49. Manhattan World(曼哈顿世界)</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/HoughTransform%E9%9C%8D%E5%A4%AB%E5%8F%98%E6%8D%A2.html">2.1.50. Hough Transform（霍夫变换）</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/PolarCoordinateSystem%E6%9E%81%E5%9D%90%E6%A0%87%E8%A1%A8%E7%A4%BA%E6%B3%95.html">2.1.51. 极坐标表示法(Polar Coordinate System)</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/GaussianSphere%E9%AB%98%E6%96%AF%E7%90%83.html">2.1.52. Gaussian Sphere（高斯球）</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/edge_direction%E8%BE%B9%E7%BC%98%E6%96%B9%E5%90%91.html">2.1.53. 边缘方向 Edge Direction</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/NormalVector%E6%B3%95%E5%90%91%E9%87%8F.html">2.1.54. NormalVector法向量</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/AllReduce.html">2.1.55. AllReduce</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/BPE.html">2.1.56. BPE</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/Embedding%E6%A8%A1%E5%9E%8B.html">2.1.57. Embedding 模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/K-Means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95.html">2.1.58. K-Means聚类算法</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/LLM.html">2.1.59. LLM</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/deeplearning.html">2.1.60. 深度学习相关</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/other.html">2.1.61. 其他</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/%E5%88%A4%E5%88%AB%E5%BC%8F%E6%A8%A1%E5%9E%8Bvs%E7%94%9F%E6%88%90%E5%BC%8F%E6%A8%A1%E5%9E%8B.html">2.1.62. 判别式模型vs生成式模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%A9%BA%E9%97%B4.html">2.1.63. 欧几里得空间(Euclidean space)</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/%E7%9F%A2%E9%87%8F%E5%8C%96%E8%AE%A1%E7%AE%97.html">2.1.64. 矢量化计算(Vectorize calculations)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/tmp.html">2.2. 临时</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/ReAct.html">2.2.1. ReAct框架</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/Reflection.html">2.2.2. Reflection反思</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/math.html">2.2.3. 数学</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/bag-of-words.html">2.2.4. bag-of-words</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/word2vec.html">2.2.5. Word2Vec</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/doc2vec.html">2.2.6. Doc2Vec</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/FastText.html">2.2.7. FastText</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/LDA.html">2.2.8. LDA-Latent Dirichlet Allocation(潜在狄利克雷分配)</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/overfitting-underfitting.html">2.2.9. overfitting&amp;underfitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/RAG.html">2.2.10. RAG</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/Agent.html">2.2.11. Agent</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/LLM.html">2.2.12. LLM</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/RL.html">2.2.13. RL-强化学习</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/prompt_engineering.html">2.2.14. Prompt Engineering</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/finetune.html">2.2.15. LLM调优(finetune)</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/Workflow.html">2.2.16. Workflow</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/0normal.html">2.2.17. 通用</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="LLM.html">3. 大模型</a><ul>
<li class="toctree-l2"><a class="reference internal" href="LLMs/normal.html">3.1. 常用</a><ul>
<li class="toctree-l3"><a class="reference internal" href="LLMs/normals/normal.html">3.1.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="LLMs/normals/package.html">3.1.2. 依赖安装</a></li>
<li class="toctree-l3"><a class="reference internal" href="LLMs/normals/encoder.html">3.1.3. 编码-解码器</a></li>
<li class="toctree-l3"><a class="reference internal" href="LLMs/normals/usage.html">3.1.4. 使用</a></li>
<li class="toctree-l3"><a class="reference internal" href="LLMs/normals/tmp.html">3.1.5. 临时</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="LLMs/model.html">3.2. 著名模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="LLMs/models/Qwen3.html">3.2.1. Qwen3</a></li>
<li class="toctree-l3"><a class="reference internal" href="LLMs/models/DeepSeek.html">3.2.2. DeepSeek-R1-推理模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="LLMs/models/LLaMA.html">3.2.3. LLaMA</a></li>
<li class="toctree-l3"><a class="reference internal" href="LLMs/models/ChatGLM.html">3.2.4. ChatGLM</a></li>
<li class="toctree-l3"><a class="reference internal" href="LLMs/models/BERT.html">3.2.5. BERT</a></li>
<li class="toctree-l3"><a class="reference internal" href="LLMs/models/OpenAI.html">3.2.6. OpenAI</a></li>
<li class="toctree-l3"><a class="reference internal" href="LLMs/models/BART.html">3.2.7. BART</a></li>
<li class="toctree-l3"><a class="reference internal" href="LLMs/models/T5.html">3.2.8. T5</a></li>
<li class="toctree-l3"><a class="reference internal" href="LLMs/models/ChatRWKV.html">3.2.9. ChatRWKV</a></li>
<li class="toctree-l3"><a class="reference internal" href="LLMs/models/Open-Assistant.html">3.2.10. Open-Assistant</a></li>
<li class="toctree-l3"><a class="reference internal" href="LLMs/models/OpenGVLab.html">3.2.11. OpenGVLab</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="LLMs/finetune.html">3.3. 调优</a></li>
<li class="toctree-l2"><a class="reference internal" href="LLMs/Quantization%E9%87%8F%E5%8C%96.html">3.4. 模型量化(Quantization)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="LLMs/Quantizations/normal.html">3.4.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="LLMs/Quantizations/GGUF.html">3.4.2. GGUF 文件</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="LLMs/fileformat.html">3.5. 文件格式</a><ul>
<li class="toctree-l3"><a class="reference internal" href="LLMs/fileformats/normal.html">3.5.1. 通用</a></li>
<li class="toctree-l3"><a class="reference internal" href="LLMs/fileformats/GGML.html">3.5.2. GGML系列文件格式</a></li>
<li class="toctree-l3"><a class="reference internal" href="LLMs/fileformats/ONNX.html">3.5.3. ONNX</a><ul>
<li class="toctree-l4"><a class="reference internal" href="LLMs/fileformats/ONNXs/normal.html">常用</a></li>
<li class="toctree-l4"><a class="reference internal" href="LLMs/fileformats/ONNXs/ONNX.html">ONNX</a></li>
<li class="toctree-l4"><a class="reference internal" href="LLMs/fileformats/ONNXs/onnxruntime.html">onnxruntime</a></li>
<li class="toctree-l4"><a class="reference internal" href="LLMs/fileformats/ONNXs/skl2onnx.html">skl2onnx</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="LLMs/fileformats/NCNN.html">3.5.4. NCNN</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="LLMs/openai.html">3.6. 商业项目</a><ul>
<li class="toctree-l3"><a class="reference internal" href="LLMs/openais/normal.html">3.6.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="LLMs/openais/openai.html">3.6.2. OpenAI</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="LLMs/prompt.html">3.7. Prompt 提示词</a><ul>
<li class="toctree-l3"><a class="reference internal" href="LLMs/prompts/demo_chinese.html">3.7.1. 中文</a></li>
<li class="toctree-l3"><a class="reference internal" href="LLMs/prompts/demo_english.html">3.7.2. English</a></li>
<li class="toctree-l3"><a class="reference internal" href="LLMs/prompts/skill.html">3.7.3. 示例</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="LLMs/Android.html">3.8. Android版LLM相关</a><ul>
<li class="toctree-l3"><a class="reference internal" href="LLMs/Androids/normal.html">3.8.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="LLMs/Androids/Android%E7%89%88%E9%83%A8%E7%BD%B2.html">3.8.2. Android版部署</a></li>
<li class="toctree-l3"><a class="reference internal" href="LLMs/Androids/GPU.html">3.8.3. GPU</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="RAG.html">4. RAG相关</a></li>
<li class="toctree-l1"><a class="reference internal" href="NLP.html">5. NLP</a><ul>
<li class="toctree-l2"><a class="reference internal" href="NLPs/normal.html">5.1. 常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="NLPs/preprocess.html">5.2. 预处理</a><ul>
<li class="toctree-l3"><a class="reference internal" href="NLPs/preprocesses/normal.html">5.2.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="NLPs/preprocesses/%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E5%8F%96.html">5.2.2. 关键词提取</a></li>
<li class="toctree-l3"><a class="reference internal" href="NLPs/preprocesses/%E5%88%86%E8%AF%8D.html">5.2.3. 分词</a></li>
<li class="toctree-l3"><a class="reference internal" href="NLPs/preprocesses/%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90.html">5.2.4. 情感分析</a></li>
<li class="toctree-l3"><a class="reference internal" href="NLPs/preprocesses/%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA.html">5.2.5. 文本表示</a></li>
<li class="toctree-l3"><a class="reference internal" href="NLPs/preprocesses/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6.html">5.2.6. 注意力机制</a></li>
<li class="toctree-l3"><a class="reference internal" href="NLPs/preprocesses/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B.html">5.2.7. 语言模型</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="NLPs/NER.html">5.3. NER-命名实体识别</a><ul>
<li class="toctree-l3"><a class="reference internal" href="NLPs/NERs/normal.html">5.3.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="NLPs/NERs/seq-label.html">5.3.2. 序列标注</a></li>
<li class="toctree-l3"><a class="reference internal" href="NLPs/NERs/BiLSTM%2BCRF.html">5.3.3. BiLSTM+CRF</a></li>
<li class="toctree-l3"><a class="reference internal" href="NLPs/NERs/history.html">5.3.4. 历史</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="NLPs/summary.html">5.4. 总结-摘要</a><ul>
<li class="toctree-l3"><a class="reference internal" href="NLPs/summarys/normal.html">5.4.1. 通用</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="library.html">6. 函数库</a><ul>
<li class="toctree-l2"><a class="reference internal" href="libraries/normal.html">6.1. 常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="libraries/Image.html">6.2. Image图像处理</a></li>
<li class="toctree-l2"><a class="reference internal" href="libraries/Video.html">6.3. Video视频</a></li>
<li class="toctree-l2"><a class="reference internal" href="libraries/IPython.html">6.4. IPython</a><ul>
<li class="toctree-l3"><a class="reference internal" href="libraries/IPythons/normal.html">6.4.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="libraries/IPythons/magic.html">6.4.2. 魔法命令 </a></li>
<li class="toctree-l3"><a class="reference internal" href="libraries/IPythons/display.html">6.4.3. display函数</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="libraries/Jupyter.html">6.5. Jupyter</a></li>
<li class="toctree-l2"><a class="reference internal" href="libraries/NumPy.html">6.6. NumPy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="libraries/NumPys/normal.html">6.6.1. 通用</a></li>
<li class="toctree-l3"><a class="reference internal" href="libraries/NumPys/Ndarray.html">6.6.2. Ndarray 对象</a></li>
<li class="toctree-l3"><a class="reference internal" href="libraries/NumPys/function.html">6.6.3. 通用函数</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="libraries/Pandas.html">6.7. Pandas</a><ul>
<li class="toctree-l3"><a class="reference internal" href="libraries/Pandas/normal.html">6.7.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="libraries/Pandas/example_subset.html">6.7.2. 实例-subset</a></li>
<li class="toctree-l3"><a class="reference internal" href="libraries/Pandas/example_analysis.html">6.7.3. 实例-统计分析</a></li>
<li class="toctree-l3"><a class="reference internal" href="libraries/Pandas/example_sql.html">6.7.4. 利用pandas实现SQL操作</a></li>
<li class="toctree-l3"><a class="reference internal" href="libraries/Pandas/example_default_value.html">6.7.5. 实例-缺失值的处理</a></li>
<li class="toctree-l3"><a class="reference internal" href="libraries/Pandas/example_multi_index.html">6.7.6. 多层索引的使用</a></li>
<li class="toctree-l3"><a class="reference internal" href="libraries/Pandas/practice.html">6.7.7. 实践</a><ul>
<li class="toctree-l4"><a class="reference internal" href="libraries/Pandas/practices/practice_2012ObamaElect.html">实践-2012年奥巴马总统连任选举</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="libraries/Pandas/api_input_output.html">6.7.8. API-输入输出</a></li>
<li class="toctree-l3"><a class="reference internal" href="libraries/Pandas/api_General.html">6.7.9. API-General functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="libraries/Pandas/api_Series.html">6.7.10. API-Series</a></li>
<li class="toctree-l3"><a class="reference internal" href="libraries/Pandas/api_DataFrame.html">6.7.11. API-DataFrame</a></li>
<li class="toctree-l3"><a class="reference internal" href="libraries/Pandas/api_Index.html">6.7.12. API-index</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="libraries/Matplotlib.html">6.8. Matplotlib</a><ul>
<li class="toctree-l3"><a class="reference internal" href="libraries/Matplotlibs/normal.html">6.8.1. 基本</a></li>
<li class="toctree-l3"><a class="reference internal" href="libraries/Matplotlibs/install.html">6.8.2. 安装</a></li>
<li class="toctree-l3"><a class="reference internal" href="libraries/Matplotlibs/pyplot.html">6.8.3. pyplot </a></li>
<li class="toctree-l3"><a class="reference internal" href="libraries/Matplotlibs/matplotlib.patches.html">6.8.4. matplotlib.patches</a></li>
<li class="toctree-l3"><a class="reference internal" href="libraries/Matplotlibs/example.html">6.8.5. 实例</a><ul>
<li class="toctree-l4"><a class="reference internal" href="libraries/Matplotlibs/examples/plot.html">折线图plot</a></li>
<li class="toctree-l4"><a class="reference internal" href="libraries/Matplotlibs/examples/bar.html">条形图bar</a></li>
<li class="toctree-l4"><a class="reference internal" href="libraries/Matplotlibs/examples/hist.html">直方图hist</a></li>
<li class="toctree-l4"><a class="reference internal" href="libraries/Matplotlibs/examples/scatter.html">散点图scatter</a></li>
<li class="toctree-l4"><a class="reference internal" href="libraries/Matplotlibs/examples/stackplot.html">面积图stackplot</a></li>
<li class="toctree-l4"><a class="reference internal" href="libraries/Matplotlibs/examples/pie.html">饼图pie</a></li>
<li class="toctree-l4"><a class="reference internal" href="libraries/Matplotlibs/examples/box.html">箱型图box</a></li>
<li class="toctree-l4"><a class="reference internal" href="libraries/Matplotlibs/examples/multi.html">多图合并multi</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="libraries/Matplotlibs/pylab.html">6.8.6. pylab子包</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="libraries/SciPy.html">6.9. SciPy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="libraries/SciPys/normal.html">6.9.1. 常用</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="libraries/sklearn.html">6.10. sklearn</a><ul>
<li class="toctree-l3"><a class="reference internal" href="libraries/sklearns/normal.html">6.10.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="libraries/sklearns/supervised.html">6.10.2. 监督学习</a><ul>
<li class="toctree-l4"><a class="reference internal" href="libraries/sklearns/superviseds/glm.html">广义线性模型</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="libraries/sklearns/unsupervised.html">6.10.3. 无监督学习</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="libraries/statsmodels.html">6.11. statsmodels</a></li>
<li class="toctree-l2"><a class="reference internal" href="libraries/OpenCV.html">6.12. OpenCV</a><ul>
<li class="toctree-l3"><a class="reference internal" href="libraries/OpenCVs/normal.html">6.12.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="libraries/OpenCVs/example.html">6.12.2. 实例</a></li>
<li class="toctree-l3"><a class="reference internal" href="libraries/OpenCVs/struct.html">6.12.3. 代码类结构</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="libraries/Seaborn.html">6.13. Seaborn</a><ul>
<li class="toctree-l3"><a class="reference internal" href="libraries/Seaborns/normal.html">6.13.1. 常用</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="libraries/jieba.html">6.14. jieba中文分词</a></li>
<li class="toctree-l2"><a class="reference internal" href="libraries/gensim.html">6.15. gensim: 文本主题建模和相似性分析</a><ul>
<li class="toctree-l3"><a class="reference internal" href="libraries/gensims/normal.html">6.15.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="libraries/gensims/Core_Tutorials.html">6.15.2. Core Tutorials</a></li>
<li class="toctree-l3"><a class="reference internal" href="libraries/gensims/Tutorials.html">6.15.3. Tutorials: Learning Oriented Lessons</a></li>
<li class="toctree-l3"><a class="reference internal" href="libraries/gensims/How-to_Guides.html">6.15.4. How-to Guides: Solve a Problem</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="libraries/LAC.html">6.16. LAC-百度词法分析工具</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="framework.html">7. 学习框架</a><ul>
<li class="toctree-l2"><a class="reference internal" href="frameworks/normal.html">7.1. 常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="frameworks/pytorch.html">7.2. PyTorch</a><ul>
<li class="toctree-l3"><a class="reference internal" href="frameworks/pytorchs/normal.html">7.2.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="frameworks/pytorchs/nn.html">7.2.2. nn模块</a></li>
<li class="toctree-l3"><a class="reference internal" href="frameworks/pytorchs/PyTorch.html">7.2.3. PyTorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="frameworks/pytorchs/ExecuTorch.html">7.2.4. ExecuTorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="frameworks/pytorchs/torchrun.html">7.2.5. torchrun (Elastic Launch)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="frameworks/huggingface.html">7.3. huggingface</a><ul>
<li class="toctree-l3"><a class="reference internal" href="frameworks/huggingfaces/normal.html">7.3.1. 常用</a><ul>
<li class="toctree-l4"><a class="reference internal" href="frameworks/huggingfaces/normals/huggingface_hub.html">Hugging Face Hub</a></li>
<li class="toctree-l4"><a class="reference internal" href="frameworks/huggingfaces/normals/lib_python.html">Hub Python Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="frameworks/huggingfaces/normals/Datasets.html">Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="frameworks/huggingfaces/normals/Text_Generation_Inference_main.html">TGI: Text Generation Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="frameworks/huggingfaces/normals/Evaluate.html">Evaluate</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="frameworks/huggingfaces/Transformers.html">7.3.2. Transformers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="frameworks/huggingfaces/Transformers/Transformers.html">Transformers</a></li>
<li class="toctree-l4"><a class="reference internal" href="frameworks/huggingfaces/Transformers/Transformers_V4.45.2.html">Transformers 4.45.2</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="frameworks/huggingfaces/Tokenizers_V0.13.3.html">7.3.3. Tokenizers</a></li>
<li class="toctree-l3"><a class="reference internal" href="frameworks/huggingfaces/PEFT.html">7.3.4. PEFT</a><ul>
<li class="toctree-l4"><a class="reference internal" href="frameworks/huggingfaces/PEFT/PEFT.html">PEFT</a></li>
<li class="toctree-l4"><a class="reference internal" href="frameworks/huggingfaces/PEFT/PEFT_V0.13.0.html">PEFT 0.13.0</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="frameworks/huggingfaces/Accelerate.html">7.3.5. Accelerate</a></li>
<li class="toctree-l3"><a class="reference internal" href="frameworks/huggingfaces/TRL.html">7.3.6. TRL - Transformer Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="frameworks/huggingfaces/collect.html">7.3.7. 收集</a><ul>
<li class="toctree-l4"><a class="reference internal" href="frameworks/huggingfaces/collects/resources.html">resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="frameworks/huggingfaces/collects/model.html">model</a></li>
<li class="toctree-l4"><a class="reference internal" href="frameworks/huggingfaces/collects/blog_decoding-methods.html">博文: decoding methods of LLM with transformers</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="frameworks/vLLM.html">7.4. vLLM</a><ul>
<li class="toctree-l3"><a class="reference internal" href="frameworks/vLLMs/normal.html">7.4.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="frameworks/vLLMs/vLLM_doc.html">7.4.2. vLLM官方文档</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="frameworks/llama.cpp.html">7.5. llama.cpp框架</a><ul>
<li class="toctree-l3"><a class="reference internal" href="frameworks/llama.cpps/normal.html">7.5.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="frameworks/llama.cpps/llama-cpp-python.html">7.5.2. Python bindings for llama.cpp</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="frameworks/DeepSpeed.html">7.6. DeepSpeed</a><ul>
<li class="toctree-l3"><a class="reference internal" href="frameworks/DeepSpeeds/huggingface.html">7.6.1. huggingface</a></li>
<li class="toctree-l3"><a class="reference internal" href="frameworks/DeepSpeeds/ZeRO.html">7.6.2. Zero Redundancy Optimizer (ZeRO)</a></li>
<li class="toctree-l3"><a class="reference internal" href="frameworks/DeepSpeeds/deepspeed_doc.html">7.6.3. DeepSpeed</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="frameworks/mxnet.html">7.7. mxnet库</a><ul>
<li class="toctree-l3"><a class="reference internal" href="frameworks/mxnets/ndarray.html">7.7.1. nd模块</a><ul>
<li class="toctree-l4"><a class="reference internal" href="frameworks/mxnets/ndarrays/ndarray.html">ndarray</a></li>
<li class="toctree-l4"><a class="reference internal" href="frameworks/mxnets/ndarrays/ndarray.random.html">ndarray.random</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="frameworks/mxnets/gluon.html">7.7.2. gluon模块</a></li>
<li class="toctree-l3"><a class="reference internal" href="frameworks/mxnets/autograd.html">7.7.3. autograd模块</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="frameworks/tensorflow.html">7.8. tensorflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="frameworks/Keras.html">7.9. Keras</a><ul>
<li class="toctree-l3"><a class="reference internal" href="frameworks/Keras/normal.html">7.9.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="frameworks/Keras/demo.html">7.9.2. 实例</a><ul>
<li class="toctree-l4"><a class="reference internal" href="frameworks/Keras/demos/binary_classification.html">二分类问题</a></li>
<li class="toctree-l4"><a class="reference internal" href="frameworks/Keras/demos/multiclass_classification.html">多分类问题</a></li>
<li class="toctree-l4"><a class="reference internal" href="frameworks/Keras/demos/regression.html">回归问题</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="frameworks/other.html">7.10. 其他</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="website.html">8. 关键网站</a><ul>
<li class="toctree-l2"><a class="reference internal" href="websites/Papers%20with%20Code.html">8.1. Papers with Code</a></li>
<li class="toctree-l2"><a class="reference internal" href="websites/Kaggle.html">8.2. Kaggle</a></li>
<li class="toctree-l2"><a class="reference internal" href="websites/ArXiv.html">8.3. ArXiv 学术论文预印本平台</a></li>
<li class="toctree-l2"><a class="reference internal" href="websites/video.html">8.4. 视频相关</a></li>
<li class="toctree-l2"><a class="reference internal" href="websites/normal.html">8.5. 通用</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="practice.html">9. 实践</a><ul>
<li class="toctree-l2"><a class="reference internal" href="practices/OCR.html">9.1. OCR</a><ul>
<li class="toctree-l3"><a class="reference internal" href="practices/OCRs/normal.html">9.1.1. 常用</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="practices/AIML.html">9.2. AIML</a><ul>
<li class="toctree-l3"><a class="reference internal" href="practices/AIMLs/normal.html">9.2.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="practices/AIMLs/spec.html">9.2.2. AIML 2.1 Documentation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="opensource.html">10. 开源项目</a><ul>
<li class="toctree-l2"><a class="reference internal" href="opensources/Agent.html">10.1. Agent</a></li>
<li class="toctree-l2"><a class="reference internal" href="opensources/RAG.html">10.2. RAG</a></li>
<li class="toctree-l2"><a class="reference internal" href="opensources/normal.html">10.3. 常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="opensources/ui.html">10.4. UI界面</a></li>
<li class="toctree-l2"><a class="reference internal" href="opensources/finetune.html">10.5. 调优</a></li>
<li class="toctree-l2"><a class="reference internal" href="opensources/search.html">10.6. 搜索</a></li>
<li class="toctree-l2"><a class="reference internal" href="opensources/LLM-Inference-Engine.html">10.7. LLM Inference Engines</a></li>
<li class="toctree-l2"><a class="reference internal" href="opensources/LLM-Inference-Tool.html">10.8. 模型推理平台</a></li>
<li class="toctree-l2"><a class="reference internal" href="opensources/LLM-inference-accelerate.html">10.9. LLM推理加速</a></li>
<li class="toctree-l2"><a class="reference internal" href="opensources/Evaluate.html">10.10. LLM评估</a></li>
<li class="toctree-l2"><a class="reference internal" href="opensources/platform.html">10.11. AI平台</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="dataset.html">11. 数据集</a><ul>
<li class="toctree-l2"><a class="reference internal" href="datasets/normal.html">11.1. 常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="datasets/chinese.html">11.2. 中文数据集</a></li>
<li class="toctree-l2"><a class="reference internal" href="datasets/chinese_image.html">11.3. 中文图片相关数据集</a></li>
<li class="toctree-l2"><a class="reference internal" href="datasets/huggingface.html">11.4. dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="datasets/website.html">11.5. 数据集相关网站</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model.html">12. 常见模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="cuda.html">13. 图形&amp;计算加速技术</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cudas/normal.html">13.1. 常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="cudas/cuda.html">13.2. cuda</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Evaluate.html">14. Evaluate评测</a><ul>
<li class="toctree-l2"><a class="reference internal" href="Evaluates/normal.html">14.1. 通用</a></li>
<li class="toctree-l2"><a class="reference internal" href="Evaluates/TruLens.html">14.2. TruLens</a></li>
<li class="toctree-l2"><a class="reference internal" href="Evaluates/Ragas.html">14.3. Ragas</a></li>
<li class="toctree-l2"><a class="reference internal" href="Evaluates/DeepEval.html">14.4. DeepEval</a></li>
<li class="toctree-l2"><a class="reference internal" href="Evaluates/UpTrain.html">14.5. UpTrain</a></li>
<li class="toctree-l2"><a class="reference internal" href="Evaluates/huggingface.html">14.6. evaluate</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="%E4%BC%A0%E7%BB%9FAI.html">15. 传统AI</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">新溪-gordon</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li><span class="section-number">2. </span>理论</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/theory.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
  <table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference external" href="/index.html">主页</a></p></td>
<td><p><a class="reference internal" href="genindex.html"><span class="std std-ref">索引</span></a></p></td>
<td><p><a class="reference internal" href="py-modindex.html"><span class="std std-ref">模块索引</span></a></p></td>
<td><p><a class="reference internal" href="search.html"><span class="std std-ref">搜索页面</span></a></p></td>
</tr>
</tbody>
</table>
<section id="id2">
<h1><span class="section-number">2. </span>理论<a class="headerlink" href="#id2" title="此标题的永久链接">¶</a></h1>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="theories/key.html">2.1. 关键定义</a><ul>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/Recommenders/CF%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4.html">2.1.1. 协同过滤（Collaborative Filtering, CF）</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Recommenders/CF%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4.html#id1">核心思想一句话概括</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Recommenders/CF%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4.html#id2">协同过滤主要分为两类：</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/Recommenders/CF%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4.html#memory-based-cf">1. 基于内存的协同过滤（Memory-Based CF）</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/Recommenders/CF%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4.html#model-based-cf">2. 基于模型的协同过滤（Model-Based CF）</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Recommenders/CF%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4.html#id3">协同过滤的优缺点</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/Recommenders/CF%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4.html#id4">优点：</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/Recommenders/CF%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4.html#id5">缺点（及常见解决方案）：</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Recommenders/CF%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4.html#id6">总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/Recommenders/MF%E6%A6%82%E7%8E%87%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3.html">2.1.2. MF(Matrix Factorization，矩阵分解)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Recommenders/MF%E6%A6%82%E7%8E%87%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3.html#id1">核心思想：化繁为简</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Recommenders/MF%E6%A6%82%E7%8E%87%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3.html#id2">一个生动的比喻：美食家与食物</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Recommenders/MF%E6%A6%82%E7%8E%87%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3.html#id3">数学表示</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Recommenders/MF%E6%A6%82%E7%8E%87%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3.html#mf">MF 是如何工作的？（训练过程）</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Recommenders/MF%E6%A6%82%E7%8E%87%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3.html#id4">MF 的优势</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Recommenders/MF%E6%A6%82%E7%8E%87%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3.html#id5">总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/Recommenders/PMF%E6%A6%82%E7%8E%87%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3.html">2.1.3. PMF（Probabilistic Matrix Factorization，概率矩阵分解）</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Recommenders/PMF%E6%A6%82%E7%8E%87%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3.html#id1">1. 核心思想：从矩阵分解说起</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Recommenders/PMF%E6%A6%82%E7%8E%87%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3.html#pmf">2. PMF的突破：引入概率视角</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Recommenders/PMF%E6%A6%82%E7%8E%87%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3.html#id2">3. PMF的优势</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Recommenders/PMF%E6%A6%82%E7%8E%87%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3.html#id3">4. 总结与类比</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/Recommenders/Two-TowerModels%E5%8F%8C%E5%A1%94%E6%A8%A1%E5%9E%8B.html">2.1.4. Two-Tower Models（双塔模型）</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Recommenders/Two-TowerModels%E5%8F%8C%E5%A1%94%E6%A8%A1%E5%9E%8B.html#id1">核心思想一句话概括</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Recommenders/Two-TowerModels%E5%8F%8C%E5%A1%94%E6%A8%A1%E5%9E%8B.html#id2">模型结构：为什么叫“双塔”？</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Recommenders/Two-TowerModels%E5%8F%8C%E5%A1%94%E6%A8%A1%E5%9E%8B.html#id3">双塔模型的核心特点和工作流程</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/Recommenders/Two-TowerModels%E5%8F%8C%E5%A1%94%E6%A8%A1%E5%9E%8B.html#id4">1. 离线计算（候选塔的预计算）- 高效的关键</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/Recommenders/Two-TowerModels%E5%8F%8C%E5%A1%94%E6%A8%A1%E5%9E%8B.html#id5">2. 在线服务</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Recommenders/Two-TowerModels%E5%8F%8C%E5%A1%94%E6%A8%A1%E5%9E%8B.html#id6">双塔模型的优势</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Recommenders/Two-TowerModels%E5%8F%8C%E5%A1%94%E6%A8%A1%E5%9E%8B.html#id7">双塔模型的劣势与挑战</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Recommenders/Two-TowerModels%E5%8F%8C%E5%A1%94%E6%A8%A1%E5%9E%8B.html#id8">应用场景</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Recommenders/Two-TowerModels%E5%8F%8C%E5%A1%94%E6%A8%A1%E5%9E%8B.html#id9">总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/Parallelism/normal.html">2.1.5. 通用</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/Parallelism/normal.html#id3">分布式训练的优化目标</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/Parallelism/PipelineParallelism.html">2.1.6. Pipeline Parallelism</a></li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/Parallelism/TensorParallesim.html">2.1.7. Tensor Parallesim</a></li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/func_activations/activation_Sigmoid.html">2.1.8. 激活函数-Sigmoid</a></li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/func_activations/activation_RELU.html">2.1.9. 激活函数-ReLU</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_activations/activation_RELU.html#id2">为什么要用ReLU呢?</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_activations/activation_RELU.html#id3">ReLU的优势在哪儿呢</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_activations/activation_RELU.html#id4">ReLU有什么弱点</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_activations/activation_RELU.html#id5">常见的激活函数</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/func_activations/activation_Leaky-ReLU.html">2.1.10. 激活函数-Leaky ReLU</a></li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/func_activations/activation_Tanh.html">2.1.11. 激活函数-Tanh</a></li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/func_activations/activation_GELU.html">2.1.12. 激活函数-GELU</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_activations/activation_GELU.html#id2">其他</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/func_activations/normalization_L1.html">2.1.13. 归一化-L1</a></li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/func_activations/normalization_L2.html">2.1.14. 归一化-L2</a></li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/func_activations/probabilistic_Softmax.html">2.1.15. 概率分布-Softmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/func_activations/probabilistic_logSoftmax.html">2.1.16. 概率分布-logsoftmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/func_activations/probabilistic_Sparsemax.html">2.1.17. 概率分布-Sparsemax</a></li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/func_loss/classify_cross_entropy.html">2.1.18. 损失函数-分类-cross-entropy(交叉熵)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_loss/classify_cross_entropy.html#id3">定义</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/func_loss/classify_cross_entropy.html#id4">单样本多分类交叉熵的公式</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/func_loss/classify_cross_entropy.html#id5">二分类单样本交叉熵损失的公式</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/func_loss/classify_cross_entropy.html#id6">批量多分类交叉熵损失函数的公式</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/func_loss/classify_cross_entropy.html#id7">生成式语言模型交叉熵损失函数的公式</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_loss/classify_cross_entropy.html#id8">作用</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_loss/classify_cross_entropy.html#id9">使用场景</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_loss/classify_cross_entropy.html#id10">示例</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/func_loss/classify_cross_entropy.html#id11">猜一个单词</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/func_loss/classify_cross_entropy.html#id12">代码讲解</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/func_loss/classify_NLL.html">2.1.19. 损失函数-分类-负对数似然损失NLL Loss</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_loss/classify_NLL.html#id2">核心思想</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_loss/classify_NLL.html#id3">特性</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_loss/classify_NLL.html#id4">示例</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_loss/classify_NLL.html#id5">优点与不足</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/func_loss/classify_log.html">2.1.20. 损失函数-分类-对数损失(Log Loss)</a></li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/func_loss/classify_kl.html">2.1.21. 损失函数-分类-KL 散度(KL Loss)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_loss/classify_kl.html#kl">定义：KL 散度</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/func_loss/classify_kl.html#id1">一、核心概念：衡量两个概率分布的“差异”</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/func_loss/classify_kl.html#id2">二、一个生动的例子：新闻编码</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/func_loss/classify_kl.html#id3">三、重要性质</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/func_loss/classify_kl.html#id4">四、公式</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/func_loss/classify_kl.html#id5">五、主要应用场景</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/func_loss/classify_kl.html#id6">六、变体或替代方法</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_loss/classify_kl.html#id7">KL 散度作为损失函数</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/func_loss/classify_kl.html#id8">工作原理</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/func_loss/classify_kl.html#id9">具体应用场景</a><ul>
<li class="toctree-l5"><a class="reference internal" href="theories/keys/func_loss/classify_kl.html#id10">1. 分类任务（最经典的例子）</a></li>
<li class="toctree-l5"><a class="reference internal" href="theories/keys/func_loss/classify_kl.html#vae-gans">2. 生成模型（如VAE, GANs）</a></li>
<li class="toctree-l5"><a class="reference internal" href="theories/keys/func_loss/classify_kl.html#id11">3. 贝叶斯推理与变分推断</a></li>
<li class="toctree-l5"><a class="reference internal" href="theories/keys/func_loss/classify_kl.html#id12">4. 强化学习</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/func_loss/regression_MSE.html">2.1.22. 损失函数-回归-均方误差(MSE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/func_loss/regression_MAE.html">2.1.23. 损失函数-回归-平均绝对误差(MAE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/func_loss/regression_Huber.html">2.1.24. 损失函数-回归-Huber 损失</a></li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/func_loss/regression_log_cosh.html">2.1.25. 损失函数-回归-对数余弦损失(Log-Cosh Loss)</a></li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/func_loss/%E6%9D%83%E9%87%8D%E8%A1%B0%E5%87%8F-L2%E6%AD%A3%E5%88%99%E5%8C%96.html">2.1.26. 权重衰减(L2正则化)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_loss/%E6%9D%83%E9%87%8D%E8%A1%B0%E5%87%8F-L2%E6%AD%A3%E5%88%99%E5%8C%96.html#id2">数学定义</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_loss/%E6%9D%83%E9%87%8D%E8%A1%B0%E5%87%8F-L2%E6%AD%A3%E5%88%99%E5%8C%96.html#id3">目标</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_loss/%E6%9D%83%E9%87%8D%E8%A1%B0%E5%87%8F-L2%E6%AD%A3%E5%88%99%E5%8C%96.html#id4">作用</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/func_optims/GD.html">2.1.27. GD(梯度下降)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/GD.html#id2">核心思想</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/GD.html#id3">公式</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/GD.html#id4">梯度下降的三种类型</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/GD.html#id5">学习率的重要性</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/GD.html#id6">优缺点</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/GD.html#id7">代码示例说明</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/func_optims/SGD.html">2.1.28. SGD随机梯度下降</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/SGD.html#id2">核心思想</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/SGD.html#id3">公式</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/SGD.html#id4">优缺点</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/func_optims/RMSprop.html">2.1.29. RMSprop</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/RMSprop.html#id2">核心思想</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/RMSprop.html#id3">公式</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/RMSprop.html#id4">优缺点</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/func_optims/Adam.html">2.1.30. Adam</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/Adam.html#id2">核心思想</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/Adam.html#id3">公式</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/Adam.html#id4">优缺点</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/func_optims/AdamW.html">2.1.31. AdamW</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/AdamW.html#adam">Adam 和权重衰减的问题</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/AdamW.html#id2">公式</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/AdamW.html#id3">与Adam的区别</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/AdamW.html#id4">优缺点</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/func_optims/Momentum.html">2.1.32. Momentum</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/Momentum.html#id2">核心思想</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/Momentum.html#id3">公式</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/Momentum.html#id4">优缺点</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/func_optims/Momentum.html#id5">代码示例</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/ners/HMM-%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B.html">2.1.33. HMM-隐马尔可夫模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/ners/HMM-%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B.html#id2">基本概念</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/ners/HMM-%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B.html#id3">通用</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/ners/HMM-%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B.html#id4">示例-今天是晴天,明天的天气是多云的概率</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/ners/WWM-%E5%85%A8%E8%AF%8DMask.html">2.1.34. WWM-Whole Word Masking</a></li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/ners/CRF-%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA.html">2.1.35. CRF-条件随机场</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/ners/CRF-%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA.html#id2">基本概念</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/ners/CRF-%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA.html#id3">模型定义</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/ners/CRF-%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA.html#id4">应用</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/ners/CRF-%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA.html#id5">示例-把’小明喜欢吃苹果’进行词性标注</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/dls/ANN.html">2.1.36. ANN(NN)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dls/ANN.html#id2">神经元</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dls/ANN.html#id3">连接</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dls/ANN.html#id4">神经网络的训练</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/dls/ANN.html#id5">训练算法</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dls/ANN.html#id6">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/dls/DNN-%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html">2.1.37. 深度神经网络(Deep Neural Network, DNN)</a></li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/dls/CNN-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html">2.1.38. 卷积神经网络(Convolutional Neural Network, CNN)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dls/CNN-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/dls/RNN-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91.html">2.1.39. RNN: 循环神经网(Recurrent Neural Network, RNN)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dls/RNN-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/dls/LSTM-%E9%95%BF%E7%9F%AD%E6%97%B6%E8%AE%B0%E5%BF%86.html">2.1.40. LSTM: 长短时记忆(Long Short Term Memory, LSTM)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dls/LSTM-%E9%95%BF%E7%9F%AD%E6%97%B6%E8%AE%B0%E5%BF%86.html#rnn-vs-lstm">RNN vs LSTM</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dls/LSTM-%E9%95%BF%E7%9F%AD%E6%97%B6%E8%AE%B0%E5%BF%86.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/dl_theorys/propagation.html">2.1.41. 前向/反向传播</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/propagation.html#id3">神经元</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/propagation.html#id4">感知机和神经网络</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/dl_theorys/propagation.html#boltzmannboltzmann">Boltzmann机和受限Boltzmann机</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/dl_theorys/propagation.html#rbf">RBF网络</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/dl_theorys/propagation.html#art">ART网络</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/dl_theorys/propagation.html#som">SOM网络</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/propagation.html#forward-propagation">forward propagation 前向传播</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/dl_theorys/propagation.html#id5">1.输入层—-&gt;隐含层</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/dl_theorys/propagation.html#id6">2.隐含层—-&gt;输出层</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/propagation.html#backward-propagation">backward propagation 反向传播</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/dl_theorys/propagation.html#id7">1.计算总误差</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/dl_theorys/propagation.html#w5-w8">2.隐含层—-&gt;输出层(w5-w8)的权值更新</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/dl_theorys/propagation.html#w1-w4">3.输入层—&gt;隐含层的权值(w1-w4)更新</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/propagation.html#frac-1-1-e-n"><span class="math notranslate nohighlight">\(\frac{1}{1+e^{-n}}\)</span> 求导公式推理</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/propagation.html#demo">演示Demo</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/propagation.html#id8">图示例反向传播</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/propagation.html#id9">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/dl_theorys/LinearLayer.html">2.1.42. Linear Layer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/LinearLayer.html#feedforward-layer">为什么叫 Feedforward Layer</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/LinearLayer.html#fully-connected-layer">为什么叫 Fully Connected Layer</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/LinearLayer.html#id2">应用场景与作用</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/dl_theorys/FFN.html">2.1.43. Feedforward Network-前馈网络</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/FFN.html#id2">Feedforward Network 的结构</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/FFN.html#id3">工作原理</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/FFN.html#id4">数学公式</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/dl_theorys/LayerNorm.html">2.1.44. LayerNorm(层归一化)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/LayerNorm.html#post-layernorm">1. Post-LayerNorm</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/dl_theorys/LayerNorm.html#id2">计算公式</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/dl_theorys/LayerNorm.html#id3">特点</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/LayerNorm.html#pre-layernorm">2. Pre-LayerNorm</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/dl_theorys/LayerNorm.html#id4">计算公式</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/dl_theorys/LayerNorm.html#id5">特点</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/dl_theorys/WeightTying.html">2.1.45. Weight Tying</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/WeightTying.html#id2">定义</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/WeightTying.html#id3">为什么使用 Weight Tying</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/WeightTying.html#id4">实际运作方式</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/WeightTying.html#id5">应用场景</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/dl_theorys/GreedyDecoding.html">2.1.46. Greedy Decoding</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/GreedyDecoding.html#id2">定义</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/GreedyDecoding.html#id3">流程</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/GreedyDecoding.html#id4">优缺点</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/GreedyDecoding.html#id5">应用场景</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/GreedyDecoding.html#id6">与其他解码方法的比较</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/dl_theorys/ImageGrounding.html">2.1.47. Image Grounding</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/ImageGrounding.html#id2">定义</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/ImageGrounding.html#grounding">Grounding 的常见方法和流程</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/ImageGrounding.html#id3">应用场景</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/dl_theorys/Perplexity.html">2.1.48. Perplexity(PPL)困惑度</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/Perplexity.html#id2">定义</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/dl_theorys/Perplexity.html#id3">生成式语言模型困惑度</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/Perplexity.html#id4">直观理解</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/Perplexity.html#id5">计算示例</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/Perplexity.html#id6">注意事项</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/dl_theorys/Perplexity.html#id7">总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/3Ds/ManhattanWorld%E6%9B%BC%E5%93%88%E9%A1%BF%E4%B8%96%E7%95%8C.html">2.1.49. Manhattan World(曼哈顿世界)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/ManhattanWorld%E6%9B%BC%E5%93%88%E9%A1%BF%E4%B8%96%E7%95%8C.html#id2">作用</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/ManhattanWorld%E6%9B%BC%E5%93%88%E9%A1%BF%E4%B8%96%E7%95%8C.html#id3">举例说明</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/ManhattanWorld%E6%9B%BC%E5%93%88%E9%A1%BF%E4%B8%96%E7%95%8C.html#non-manhattan-world">拓展: 非曼哈顿世界(Non-Manhattan World)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/3Ds/HoughTransform%E9%9C%8D%E5%A4%AB%E5%8F%98%E6%8D%A2.html">2.1.50. Hough Transform（霍夫变换）</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/HoughTransform%E9%9C%8D%E5%A4%AB%E5%8F%98%E6%8D%A2.html#id1">🌟 一句话理解：</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/HoughTransform%E9%9C%8D%E5%A4%AB%E5%8F%98%E6%8D%A2.html#id2">📐 最经典应用：检测直线</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/HoughTransform%E9%9C%8D%E5%A4%AB%E5%8F%98%E6%8D%A2.html#id3">🔢 直线的参数形式</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/HoughTransform%E9%9C%8D%E5%A4%AB%E5%8F%98%E6%8D%A2.html#id4">🔁 基本原理</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/HoughTransform%E9%9C%8D%E5%A4%AB%E5%8F%98%E6%8D%A2.html#id5">🌀 霍夫变换也可以检测其他形状</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/HoughTransform%E9%9C%8D%E5%A4%AB%E5%8F%98%E6%8D%A2.html#id6">📦 应用场景</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/HoughTransform%E9%9C%8D%E5%A4%AB%E5%8F%98%E6%8D%A2.html#id7">🧠 总结一句话：</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/3Ds/PolarCoordinateSystem%E6%9E%81%E5%9D%90%E6%A0%87%E8%A1%A8%E7%A4%BA%E6%B3%95.html">2.1.51. 极坐标表示法(Polar Coordinate System)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/PolarCoordinateSystem%E6%9E%81%E5%9D%90%E6%A0%87%E8%A1%A8%E7%A4%BA%E6%B3%95.html#id1">🌟 一句话理解：</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/PolarCoordinateSystem%E6%9E%81%E5%9D%90%E6%A0%87%E8%A1%A8%E7%A4%BA%E6%B3%95.html#id2">🧭 具体定义</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/PolarCoordinateSystem%E6%9E%81%E5%9D%90%E6%A0%87%E8%A1%A8%E7%A4%BA%E6%B3%95.html#id3">🔁 极坐标和笛卡尔坐标之间的转换</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/PolarCoordinateSystem%E6%9E%81%E5%9D%90%E6%A0%87%E8%A1%A8%E7%A4%BA%E6%B3%95.html#id4">📐 为什么图像处理里喜欢用它？</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/PolarCoordinateSystem%E6%9E%81%E5%9D%90%E6%A0%87%E8%A1%A8%E7%A4%BA%E6%B3%95.html#id5">📌 应用举例</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/PolarCoordinateSystem%E6%9E%81%E5%9D%90%E6%A0%87%E8%A1%A8%E7%A4%BA%E6%B3%95.html#id6">🧠 总结一句话：</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/3Ds/GaussianSphere%E9%AB%98%E6%96%AF%E7%90%83.html">2.1.52. Gaussian Sphere（高斯球）</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/GaussianSphere%E9%AB%98%E6%96%AF%E7%90%83.html#id1">🌟 一句话理解：</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/GaussianSphere%E9%AB%98%E6%96%AF%E7%90%83.html#id2">高斯图、高斯映射</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/GaussianSphere%E9%AB%98%E6%96%AF%E7%90%83.html#id3">📐 高斯球的基本定义</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/GaussianSphere%E9%AB%98%E6%96%AF%E7%90%83.html#id4">🔄 用途举例</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/3Ds/GaussianSphere%E9%AB%98%E6%96%AF%E7%90%83.html#id5">1. <strong>法向量聚类与可视化</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/3Ds/GaussianSphere%E9%AB%98%E6%96%AF%E7%90%83.html#id6">2. <strong>消失点检测中的方向编码</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/3Ds/GaussianSphere%E9%AB%98%E6%96%AF%E7%90%83.html#id7">3. <strong>光照与环境建模（球面调和）</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/3Ds/GaussianSphere%E9%AB%98%E6%96%AF%E7%90%83.html#id8">4. <strong>深度学习中的方向特征表示</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/GaussianSphere%E9%AB%98%E6%96%AF%E7%90%83.html#id9">🧠 总结一句话：</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/3Ds/edge_direction%E8%BE%B9%E7%BC%98%E6%96%B9%E5%90%91.html">2.1.53. 边缘方向 Edge Direction</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/edge_direction%E8%BE%B9%E7%BC%98%E6%96%B9%E5%90%91.html#d">🔹1.<strong>图像空间中的边缘方向（2D）</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/edge_direction%E8%BE%B9%E7%BC%98%E6%96%B9%E5%90%91.html#id1">🔹2.<strong>三维空间中的边缘方向（3D）</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/edge_direction%E8%BE%B9%E7%BC%98%E6%96%B9%E5%90%91.html#id2">🔹总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/3Ds/NormalVector%E6%B3%95%E5%90%91%E9%87%8F.html">2.1.54. NormalVector法向量</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/NormalVector%E6%B3%95%E5%90%91%E9%87%8F.html#id1">🌟 一句话理解：</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/NormalVector%E6%B3%95%E5%90%91%E9%87%8F.html#id2">📐 数学定义</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/NormalVector%E6%B3%95%E5%90%91%E9%87%8F.html#id3">🧱 举个例子</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/NormalVector%E6%B3%95%E5%90%91%E9%87%8F.html#id4">📊 在计算机视觉/图形学中的作用</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/3Ds/NormalVector%E6%B3%95%E5%90%91%E9%87%8F.html#d">✅ 1. <strong>3D 模型与点云处理</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/3Ds/NormalVector%E6%B3%95%E5%90%91%E9%87%8F.html#id5">✅ 2. <strong>表面平滑与分割</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/3Ds/NormalVector%E6%B3%95%E5%90%91%E9%87%8F.html#id6">✅ 3. <strong>消失点与几何先验</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/NormalVector%E6%B3%95%E5%90%91%E9%87%8F.html#id7">🔄 法向量的获取方式</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/3Ds/NormalVector%E6%B3%95%E5%90%91%E9%87%8F.html#id8">🧠 总结一句话：</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/others/AllReduce.html">2.1.55. AllReduce</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/AllReduce.html#id2">优势</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/AllReduce.html#id3">典型应用</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/others/BPE.html">2.1.56. BPE</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/BPE.html#id2">核心流程</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/BPE.html#id3">优点</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/BPE.html#id4">演示示例</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/BPE.html#id5">使用示例</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/BPE.html#id6">使用场景</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/others/Embedding%E6%A8%A1%E5%9E%8B.html">2.1.57. Embedding 模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/Embedding%E6%A8%A1%E5%9E%8B.html#id2">向量</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/Embedding%E6%A8%A1%E5%9E%8B.html#id3">特征向量</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/Embedding%E6%A8%A1%E5%9E%8B.html#id4">Embedding</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/Embedding%E6%A8%A1%E5%9E%8B.html#id5">向量相似度检索</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/Embedding%E6%A8%A1%E5%9E%8B.html#id6">向量相似度检索算法</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/others/K-Means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95.html">2.1.58. K-Means聚类算法</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/K-Means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95.html#id1">K-Means聚类算法简介</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/K-Means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95.html#id2">一、核心思想</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/K-Means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95.html#id3">二、工作流程（步骤）</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/K-Means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95.html#id4">三、关键概念与优缺点</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/K-Means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95.html#k">四、如何选择K值？</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/K-Means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95.html#id5">五、应用场景</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/K-Means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95.html#id6">总结</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/others/LLM.html">2.1.59. LLM</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/LLM.html#moe">MoE架构</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/LLM.html#nli">NLI</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/LLM.html#id2">生成文本验证</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/LLM.html#safe">SAFE</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/LLM.html#factscore">FActScore</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/LLM.html#id3">参考</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/LLM.html#alce">ALCE</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/LLM.html#id4">训练方法</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/LLM.html#id5">预训练</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/LLM.html#id6">微调</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/LLM.html#id7">再次预训练</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/LLM.html#id8">推理</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/LLM.html#id9">其他</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/LLM.html#id10">消融实验</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/others/deeplearning.html">2.1.60. 深度学习相关</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/deeplearning.html#computation-graph">computation graph(计算图)</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/deeplearning.html#gradients-descent">Gradients Descent 梯度下降</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/deeplearning.html#id3">激活函数</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/deeplearning.html#loss-function">Loss Function 损失函数</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/others/other.html">2.1.61. 其他</a></li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/others/%E5%88%A4%E5%88%AB%E5%BC%8F%E6%A8%A1%E5%9E%8Bvs%E7%94%9F%E6%88%90%E5%BC%8F%E6%A8%A1%E5%9E%8B.html">2.1.62. 判别式模型vs生成式模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/%E5%88%A4%E5%88%AB%E5%BC%8F%E6%A8%A1%E5%9E%8Bvs%E7%94%9F%E6%88%90%E5%BC%8F%E6%A8%A1%E5%9E%8B.html#id2">判别式模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/%E5%88%A4%E5%88%AB%E5%BC%8F%E6%A8%A1%E5%9E%8Bvs%E7%94%9F%E6%88%90%E5%BC%8F%E6%A8%A1%E5%9E%8B.html#id3">数学公式</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/%E5%88%A4%E5%88%AB%E5%BC%8F%E6%A8%A1%E5%9E%8Bvs%E7%94%9F%E6%88%90%E5%BC%8F%E6%A8%A1%E5%9E%8B.html#id4">生成式模型</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/%E5%88%A4%E5%88%AB%E5%BC%8F%E6%A8%A1%E5%9E%8Bvs%E7%94%9F%E6%88%90%E5%BC%8F%E6%A8%A1%E5%9E%8B.html#id5">数学公式</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/others/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%A9%BA%E9%97%B4.html">2.1.63. 欧几里得空间(Euclidean space)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%A9%BA%E9%97%B4.html#id1">✅ 欧几里得空间</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%A9%BA%E9%97%B4.html#id2">1. 定义</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%A9%BA%E9%97%B4.html#id3">2. 主要特征</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%A9%BA%E9%97%B4.html#id4">3. 常见例子</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%A9%BA%E9%97%B4.html#id5">4. 与非欧几里得空间的对比</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%A9%BA%E9%97%B4.html#id6">✅ 非欧几里得空间</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%A9%BA%E9%97%B4.html#id7">1. 定义</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%A9%BA%E9%97%B4.html#id8">2. 主要特征</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%A9%BA%E9%97%B4.html#id9">3. 常见例子</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%A9%BA%E9%97%B4.html#id10">4. 与欧几里得空间对比</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%A9%BA%E9%97%B4.html#id11">5. 直观比喻</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%A9%BA%E9%97%B4.html#euclidean-data-structures">✅ 欧几里得数据结构（Euclidean Data Structures）</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%A9%BA%E9%97%B4.html#id12">典型特征：</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%A9%BA%E9%97%B4.html#id13">常见例子：</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%A9%BA%E9%97%B4.html#non-euclidean-data-structures">✅ 非欧几里得数据结构（Non-Euclidean Data Structures）</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%A9%BA%E9%97%B4.html#id14">典型特征：</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%A9%BA%E9%97%B4.html#id15">常见例子：</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%A9%BA%E9%97%B4.html#id16">对比</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%A9%BA%E9%97%B4.html#id17">应用示例：</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%A9%BA%E9%97%B4.html#hypersurface">超曲面（Hypersurface）</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%A9%BA%E9%97%B4.html#id18">形式化定义</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%A9%BA%E9%97%B4.html#id19">直观理解</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/keys/others/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%A9%BA%E9%97%B4.html#id20">例子</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/keys/others/%E7%9F%A2%E9%87%8F%E5%8C%96%E8%AE%A1%E7%AE%97.html">2.1.64. 矢量化计算(Vectorize calculations)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/%E7%9F%A2%E9%87%8F%E5%8C%96%E8%AE%A1%E7%AE%97.html#id2">核心思想</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/keys/others/%E7%9F%A2%E9%87%8F%E5%8C%96%E8%AE%A1%E7%AE%97.html#id3">例子</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="theories/tmp.html">2.2. 临时</a><ul>
<li class="toctree-l2"><a class="reference internal" href="theories/tmps/ReAct.html">2.2.1. ReAct框架</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/ReAct.html#id2">组成部分</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/ReAct.html#id3">工作流程</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/ReAct.html#id4">优势</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/ReAct.html#id5">示例</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/tmps/Reflection.html">2.2.2. Reflection反思</a></li>
<li class="toctree-l2"><a class="reference internal" href="theories/tmps/math.html">2.2.3. 数学</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/math.html#id3">线性拟合</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/math.html#id4">多项式拟合</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/math.html#id5">归一化</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/tmps/bag-of-words.html">2.2.4. bag-of-words</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/bag-of-words.html#id3">示例说明</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/bag-of-words.html#n-grams">N-Grams</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/tmps/word2vec.html">2.2.5. Word2Vec</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/word2vec.html#review-bag-of-words">Review: Bag-of-words</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/word2vec.html#id3">Word2Vec</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/word2vec.html#id4">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/tmps/doc2vec.html">2.2.6. Doc2Vec</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/doc2vec.html#review-word2vec-model">Review: Word2Vec Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/doc2vec.html#id3">Doc2Vec</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/doc2vec.html#gensim">Gensim</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/doc2vec.html#id4">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/tmps/FastText.html">2.2.7. FastText</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/FastText.html#id3">基本概念</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/FastText.html#id4">局限性</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/FastText.html#word2vec">与Word2Vec对比</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/FastText.html#training-models">Training models</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/FastText.html#id5">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/tmps/LDA.html">2.2.8. LDA-Latent Dirichlet Allocation(潜在狄利克雷分配)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/LDA.html#ensemble-lda">Ensemble LDA</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/LDA.html#lda-model">LDA Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/LDA.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/tmps/overfitting-underfitting.html">2.2.9. overfitting&amp;underfitting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/overfitting-underfitting.html#id2">以决策树为例讲解</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/overfitting-underfitting.html#id3">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/tmps/RAG.html">2.2.10. RAG</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/RAG.html#id2">简介</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/RAG.html#kg">知识图谱KG</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/RAG.html#pg">属性图谱PG</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/RAG.html#id3">RAG</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/RAG.html#graphrag">GraphRAG</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/RAG.html#adaptive-rag">Adaptive RAG</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/RAG.html#corrective-rag">Corrective RAG</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/RAG.html#id7">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/tmps/Agent.html">2.2.11. Agent</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/Agent.html#id2">优势</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/Agent.html#planning">Planning</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/Agent.html#relection-and-refinement">Relection and refinement</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/tmps/Agent.html#relfexion">Relfexion</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/tmps/Agent.html#react">ReAct</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/Agent.html#memory">Memory</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/tmps/Agent.html#sensory-memory">sensory memory</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/tmps/Agent.html#short-term-memory">short-term memory</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/tmps/Agent.html#long-term-memory">long-term memory</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/Agent.html#tools">Tools</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/tmps/Agent.html#tool-use">Tool Use框架</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/tmps/Agent.html#id3">Tool Use微调</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/Agent.html#id4">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/tmps/LLM.html">2.2.12. LLM</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/LLM.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/tmps/RL.html">2.2.13. RL-强化学习</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/RL.html#id2">RL算法</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/tmps/prompt_engineering.html">2.2.14. Prompt Engineering</a></li>
<li class="toctree-l2"><a class="reference internal" href="theories/tmps/finetune.html">2.2.15. LLM调优(finetune)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/finetune.html#pt-pre-training">PT (Pre-training)</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/finetune.html#sft-supervised-fine-tuning">SFT (Supervised Fine-Tuning)</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/finetune.html#rm-reward-modeling">RM (Reward Modeling)</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/finetune.html#ppo-proximal-policy-optimization">PPO (Proximal Policy Optimization)</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/finetune.html#dpo-direct-preference-optimization">DPO (Direct Preference Optimization)</a></li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/finetune.html#kto-knowledge-transfer-optimization">KTO (Knowledge Transfer Optimization)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="theories/tmps/Workflow.html">2.2.16. Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="theories/tmps/0normal.html">2.2.17. 通用</a><ul>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/0normal.html#llm-based-auto-annotators">LLM-based auto-annotators</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/tmps/0normal.html#id2">核心概念详解</a><ul>
<li class="toctree-l5"><a class="reference internal" href="theories/tmps/0normal.html#id3">1. 它要解决什么问题？</a></li>
<li class="toctree-l5"><a class="reference internal" href="theories/tmps/0normal.html#id4">2. 它是如何工作的？</a></li>
<li class="toctree-l5"><a class="reference internal" href="theories/tmps/0normal.html#id5">3. 为什么它如此重要？</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="theories/tmps/0normal.html#id6">存在的挑战与局限性（也就是这篇论文的背景）</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/tmps/0normal.html#id7">总结</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/0normal.html#counterfactual-prediction">反事实预测(Counterfactual Prediction)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/tmps/0normal.html#id8">1. “事实”是什么？</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/tmps/0normal.html#id9">2. “反事实”是什么？</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/tmps/0normal.html#id10">3. 论文如何实现这个“反事实预测”？</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/tmps/0normal.html#id11">一个简单的比喻</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/tmps/0normal.html#id12">总结为什么论文里用这个词：</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/0normal.html#elo">Elo 评分系统</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/tmps/0normal.html#id13">核心概念</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/tmps/0normal.html#id14">它是如何工作的？</a><ul>
<li class="toctree-l5"><a class="reference internal" href="theories/tmps/0normal.html#id15">1. 核心组件：</a></li>
<li class="toctree-l5"><a class="reference internal" href="theories/tmps/0normal.html#id16">2. 核心流程：</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="theories/tmps/0normal.html#id17">一个简单的例子</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/tmps/0normal.html#llm-lmsys-chatbot-arena">在LLM评估中的应用（如LMSYS Chatbot Arena）</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="theories/tmps/0normal.html#inverse-reinforcement-learning">逆强化学习（Inverse Reinforcement Learning）</a><ul>
<li class="toctree-l4"><a class="reference internal" href="theories/tmps/0normal.html#id18">核心思想一句话概括</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/tmps/0normal.html#irl">为什么需要IRL？—— 动机</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/tmps/0normal.html#id19">IRL的基本假设</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/tmps/0normal.html#id20">IRL的核心问题与挑战</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/tmps/0normal.html#id21">IRL的一般流程</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/tmps/0normal.html#id22">经典算法举例</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/tmps/0normal.html#irl-vs-imitation-learning">IRL vs 模仿学习（Imitation Learning）</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/tmps/0normal.html#id23">应用领域</a></li>
<li class="toctree-l4"><a class="reference internal" href="theories/tmps/0normal.html#id24">总结</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference external" href="/index.html">主页</a></p></td>
<td><p><a class="reference internal" href="genindex.html"><span class="std std-ref">索引</span></a></p></td>
<td><p><a class="reference internal" href="py-modindex.html"><span class="std std-ref">模块索引</span></a></p></td>
<td><p><a class="reference internal" href="search.html"><span class="std std-ref">搜索页面</span></a></p></td>
</tr>
</tbody>
</table>
</section>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="theories/key.html" class="btn btn-neutral float-right" title="2.1. 关键定义" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="normals/%E6%9C%BA%E5%99%A8%E4%BA%BA.html" class="btn btn-neutral" title="1.10. 机器人领域" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>
  
  <div id="gitalk-container"></div>
  <div role="contentinfo">
    <p>
        &copy; Copyright 2010-2025, 新溪-gordon.

    </p>
  </div>
  <div>备案号 <a href="http://www.beian.miit.gov.cn">京ICP备16018553号</a></div><div>Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a></div>. 


</footer>

<script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?042289284b8eb33866001347a3e0b129";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
</script>     
        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'V2025.10',
            LANGUAGE:'zh-CN',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/documentation_options.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="_static/sphinx_highlight.js"></script>
      <script type="text/javascript" src="_static/clipboard.min.js"></script>
      <script type="text/javascript" src="_static/copybutton.js"></script>
      <script type="text/javascript" src="_static/translations.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>

  

  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });


      // var gitalk = new Gitalk({
      //         clientID: '565177626b5d46427009',
      //         clientSecret: 'b2a36e67e1d2a73e43667f46d571c2624f8e1026',
      //         repo: 'knowledge',
      //         owner: 'zhaoweiguo',
      //         admin: ['zhaoweiguo'],
      //         id: location.pathname,      // Ensure uniqueness and length less than 50
      //         distractionFreeMode: false  // Facebook-like distraction free mode
      //       })
      // gitalk.render('gitalk-container')

  </script>


<script type="text/javascript" src="_static/js/table-of-contents-sidebar.js"></script>
<!-- <script type="text/javascript" src="https://table-of-contents-sidebar.github.io/table-of-contents-sidebar-lib/table-of-contents-sidebar.js"></script> -->
<script type="text/javascript">
    window.onload = function(e){
        TableOfContents.init({
            basePath: "https://table-of-contents-sidebar.github.io/table-of-contents-sidebar-lib/",
            querySelector: "body" // or other css querySelector
        });
    }
</script> 

</body>
</html>