

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="zh-CN" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="zh-CN" > <!--<![endif]-->
<head>


<!-- start added 2025-04-14   增加对markdown中公式的支持 -->
<script>
window.MathJax = {
    tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true
    },
    options: {
        ignoreHtmlClass: "tex2jax_ignore|mathjax_ignore",
        processHtmlClass: "tex2jax_process|mathjax_process|math|output_area"
    }
};
</script>
<script defer="defer" src="https://fastly.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<!-- end added 2025-04-14   增加对markdown中公式的支持 -->


<!-- start added 2025-08-06   增加对mermaid图的支持 -->
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', function() {
    mermaid.initialize({
        startOnLoad: true,
        theme: 'default',
        flowchart: { useMaxWidth: true }
    });
});
</script>
<!--  end added 2025-08-06   增加对mermaid图的支持 -->




  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>2.2.16. 通用 &mdash; 新溪-gordon V2025.11 文档</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="搜索" href="../../search.html" />
    <link rel="next" title="3. 大模型" href="../../LLM.html" />
    <link rel="prev" title="2.2.15. Workflow" href="Workflow.html" /> 

  
  <script src="../../_static/js/modernizr.min.js"></script>
  <script src="../../_static/js/jquery.min.js"></script>


<!-- 评论插件 gittalk start -->
<!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script> -->
<!-- 评论插件 gittalk end -->


</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> 新溪-gordon
          

          
          </a>

          
            
            
              <div class="version">
                V2025.11
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">AI</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../normal.html">1. 常用</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../normals/normal.html">1.1. 常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../normals/AIGC.html">1.2. AIGC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../normals/ml.html">1.3. 机器学习machine learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../normals/bi.html">1.4. BI(Business Intelligence)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../normals/deep_learning.html">1.5. 深度学习</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../normals/deep_learnings/normal.html">1.5.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../normals/deep_learnings/history.html">1.5.2. 历史</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../normals/monitor.html">1.6. monitor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../normals/algorithm.html">1.7. 相关算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../normals/tool.html">1.8. 工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../normals/question.html">1.9. 常见问题</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../normals/%E6%9C%BA%E5%99%A8%E4%BA%BA.html">1.10. 机器人领域</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../../theory.html">2. 理论</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../key.html">2.1. 关键定义</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../keys/Recommenders/CF%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4.html">2.1.1. 协同过滤（Collaborative Filtering, CF）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/Recommenders/MF%E6%A6%82%E7%8E%87%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3.html">2.1.2. MF(Matrix Factorization，矩阵分解)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/Recommenders/PMF%E6%A6%82%E7%8E%87%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3.html">2.1.3. PMF（Probabilistic Matrix Factorization，概率矩阵分解）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/Recommenders/Two-TowerModels%E5%8F%8C%E5%A1%94%E6%A8%A1%E5%9E%8B.html">2.1.4. Two-Tower Models（双塔模型）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/Parallelism/normal.html">2.1.5. 通用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/Parallelism/PipelineParallelism.html">2.1.6. Pipeline Parallelism</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/Parallelism/TensorParallesim.html">2.1.7. Tensor Parallesim</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/func_activations/activation_Sigmoid.html">2.1.8. 激活函数-Sigmoid</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/func_activations/activation_RELU.html">2.1.9. 激活函数-ReLU</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/func_activations/activation_Leaky-ReLU.html">2.1.10. 激活函数-Leaky ReLU</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/func_activations/activation_Tanh.html">2.1.11. 激活函数-Tanh</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/func_activations/activation_GELU.html">2.1.12. 激活函数-GELU</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/func_activations/normalization_L1.html">2.1.13. 归一化-L1</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/func_activations/normalization_L2.html">2.1.14. 归一化-L2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/func_activations/probabilistic_Softmax.html">2.1.15. 概率分布-Softmax</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/func_activations/probabilistic_logSoftmax.html">2.1.16. 概率分布-logsoftmax</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/func_activations/probabilistic_Sparsemax.html">2.1.17. 概率分布-Sparsemax</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/func_loss/classify_cross_entropy.html">2.1.18. 损失函数-分类-cross-entropy(交叉熵)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/func_loss/classify_NLL.html">2.1.19. 损失函数-分类-负对数似然损失NLL Loss</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/func_loss/classify_log.html">2.1.20. 损失函数-分类-对数损失(Log Loss)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/func_loss/classify_kl.html">2.1.21. 损失函数-分类-KL 散度(KL Loss)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/func_loss/regression_MSE.html">2.1.22. 损失函数-回归-均方误差(MSE)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/func_loss/regression_MAE.html">2.1.23. 损失函数-回归-平均绝对误差(MAE)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/func_loss/regression_Huber.html">2.1.24. 损失函数-回归-Huber 损失</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/func_loss/regression_log_cosh.html">2.1.25. 损失函数-回归-对数余弦损失(Log-Cosh Loss)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/func_loss/%E6%9D%83%E9%87%8D%E8%A1%B0%E5%87%8F-L2%E6%AD%A3%E5%88%99%E5%8C%96.html">2.1.26. 权重衰减(L2正则化)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/func_optims/GD.html">2.1.27. GD(梯度下降)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/func_optims/SGD.html">2.1.28. SGD随机梯度下降</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/func_optims/RMSprop.html">2.1.29. RMSprop</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/func_optims/Adam.html">2.1.30. Adam</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/func_optims/AdamW.html">2.1.31. AdamW</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/func_optims/Momentum.html">2.1.32. Momentum</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/ners/HMM-%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B.html">2.1.33. HMM-隐马尔可夫模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/ners/WWM-%E5%85%A8%E8%AF%8DMask.html">2.1.34. WWM-Whole Word Masking</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/ners/CRF-%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA.html">2.1.35. CRF-条件随机场</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/dls/ANN.html">2.1.36. ANN(NN)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/dls/DNN-%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html">2.1.37. 深度神经网络(Deep Neural Network, DNN)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/dls/CNN-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html">2.1.38. 卷积神经网络(Convolutional Neural Network, CNN)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/dls/RNN-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91.html">2.1.39. RNN: 循环神经网(Recurrent Neural Network, RNN)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/dls/LSTM-%E9%95%BF%E7%9F%AD%E6%97%B6%E8%AE%B0%E5%BF%86.html">2.1.40. LSTM: 长短时记忆(Long Short Term Memory, LSTM)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/dl_theorys/propagation.html">2.1.41. 前向/反向传播</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/dl_theorys/LinearLayer.html">2.1.42. Linear Layer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/dl_theorys/FFN.html">2.1.43. Feedforward Network-前馈网络</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/dl_theorys/LayerNorm.html">2.1.44. LayerNorm(层归一化)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/dl_theorys/WeightTying.html">2.1.45. Weight Tying</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/dl_theorys/GreedyDecoding.html">2.1.46. Greedy Decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/dl_theorys/ImageGrounding.html">2.1.47. Image Grounding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/dl_theorys/Perplexity.html">2.1.48. Perplexity(PPL)困惑度</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/3Ds/ManhattanWorld%E6%9B%BC%E5%93%88%E9%A1%BF%E4%B8%96%E7%95%8C.html">2.1.49. Manhattan World(曼哈顿世界)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/3Ds/HoughTransform%E9%9C%8D%E5%A4%AB%E5%8F%98%E6%8D%A2.html">2.1.50. Hough Transform（霍夫变换）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/3Ds/PolarCoordinateSystem%E6%9E%81%E5%9D%90%E6%A0%87%E8%A1%A8%E7%A4%BA%E6%B3%95.html">2.1.51. 极坐标表示法(Polar Coordinate System)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/3Ds/GaussianSphere%E9%AB%98%E6%96%AF%E7%90%83.html">2.1.52. Gaussian Sphere（高斯球）</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/3Ds/edge_direction%E8%BE%B9%E7%BC%98%E6%96%B9%E5%90%91.html">2.1.53. 边缘方向 Edge Direction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/3Ds/NormalVector%E6%B3%95%E5%90%91%E9%87%8F.html">2.1.54. NormalVector法向量</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/others/AllReduce.html">2.1.55. AllReduce</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/others/BPE.html">2.1.56. BPE</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/others/Embedding%E6%A8%A1%E5%9E%8B.html">2.1.57. Embedding 模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/others/K-Means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95.html">2.1.58. K-Means聚类算法</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/others/LLM.html">2.1.59. LLM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/others/deeplearning.html">2.1.60. 深度学习相关</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/others/other.html">2.1.61. 其他</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/others/%E5%88%A4%E5%88%AB%E5%BC%8F%E6%A8%A1%E5%9E%8Bvs%E7%94%9F%E6%88%90%E5%BC%8F%E6%A8%A1%E5%9E%8B.html">2.1.62. 判别式模型vs生成式模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/others/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E7%A9%BA%E9%97%B4.html">2.1.63. 欧几里得空间(Euclidean space)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../keys/others/%E7%9F%A2%E9%87%8F%E5%8C%96%E8%AE%A1%E7%AE%97.html">2.1.64. 矢量化计算(Vectorize calculations)</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="../tmp.html">2.2. 临时</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="ReAct.html">2.2.1. ReAct框架</a></li>
<li class="toctree-l3"><a class="reference internal" href="Reflection.html">2.2.2. Reflection反思</a></li>
<li class="toctree-l3"><a class="reference internal" href="math.html">2.2.3. 数学</a></li>
<li class="toctree-l3"><a class="reference internal" href="bag-of-words.html">2.2.4. bag-of-words</a></li>
<li class="toctree-l3"><a class="reference internal" href="word2vec.html">2.2.5. Word2Vec</a></li>
<li class="toctree-l3"><a class="reference internal" href="doc2vec.html">2.2.6. Doc2Vec</a></li>
<li class="toctree-l3"><a class="reference internal" href="FastText.html">2.2.7. FastText</a></li>
<li class="toctree-l3"><a class="reference internal" href="LDA.html">2.2.8. LDA-Latent Dirichlet Allocation(潜在狄利克雷分配)</a></li>
<li class="toctree-l3"><a class="reference internal" href="overfitting-underfitting.html">2.2.9. overfitting&amp;underfitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="RAG.html">2.2.10. RAG</a></li>
<li class="toctree-l3"><a class="reference internal" href="Agent.html">2.2.11. Agent</a></li>
<li class="toctree-l3"><a class="reference internal" href="LLM.html">2.2.12. LLM</a></li>
<li class="toctree-l3"><a class="reference internal" href="prompt_engineering.html">2.2.13. Prompt Engineering</a></li>
<li class="toctree-l3"><a class="reference internal" href="finetune.html">2.2.14. LLM调优(finetune)</a></li>
<li class="toctree-l3"><a class="reference internal" href="Workflow.html">2.2.15. Workflow</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">2.2.16. 通用</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM.html">3. 大模型</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../LLMs/normal.html">3.1. 常用</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/normals/normal.html">3.1.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/normals/package.html">3.1.2. 依赖安装</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/normals/encoder.html">3.1.3. 编码-解码器</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/normals/usage.html">3.1.4. 使用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/normals/tmp.html">3.1.5. 临时</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLMs/model.html">3.2. 著名模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/models/Qwen3.html">3.2.1. Qwen3</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/models/DeepSeek.html">3.2.2. DeepSeek-R1-推理模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/models/LLaMA.html">3.2.3. LLaMA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/models/ChatGLM.html">3.2.4. ChatGLM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/models/BERT.html">3.2.5. BERT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/models/OpenAI.html">3.2.6. OpenAI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/models/BART.html">3.2.7. BART</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/models/T5.html">3.2.8. T5</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/models/ChatRWKV.html">3.2.9. ChatRWKV</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/models/Open-Assistant.html">3.2.10. Open-Assistant</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/models/OpenGVLab.html">3.2.11. OpenGVLab</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLMs/finetune.html">3.3. 调优</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../LLMs/Quantization%E9%87%8F%E5%8C%96.html">3.4. 模型量化(Quantization)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/Quantizations/normal.html">3.4.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/Quantizations/GGUF.html">3.4.2. GGUF 文件</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLMs/fileformat.html">3.5. 文件格式</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/fileformats/normal.html">3.5.1. 通用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/fileformats/GGML.html">3.5.2. GGML系列文件格式</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/fileformats/ONNX.html">3.5.3. ONNX</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/fileformats/ONNXs/normal.html">常用</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/fileformats/ONNXs/ONNX.html">ONNX</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/fileformats/ONNXs/onnxruntime.html">onnxruntime</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/fileformats/ONNXs/skl2onnx.html">skl2onnx</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/fileformats/NCNN.html">3.5.4. NCNN</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLMs/openai.html">3.6. 商业项目</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/openais/normal.html">3.6.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/openais/openai.html">3.6.2. OpenAI</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLMs/prompt.html">3.7. Prompt 提示词</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/prompts/demo_chinese.html">3.7.1. 中文</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/prompts/demo_english.html">3.7.2. English</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/prompts/skill.html">3.7.3. 示例</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLMs/Android.html">3.8. Android版LLM相关</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/Androids/normal.html">3.8.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/Androids/Android%E7%89%88%E9%83%A8%E7%BD%B2.html">3.8.2. Android版部署</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/Androids/GPU.html">3.8.3. GPU</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../RAG.html">4. RAG相关</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../NLP.html">5. NLP</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../NLPs/normal.html">5.1. 常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../NLPs/preprocess.html">5.2. 预处理</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../NLPs/preprocesses/normal.html">5.2.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../NLPs/preprocesses/%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E5%8F%96.html">5.2.2. 关键词提取</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../NLPs/preprocesses/%E5%88%86%E8%AF%8D.html">5.2.3. 分词</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../NLPs/preprocesses/%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90.html">5.2.4. 情感分析</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../NLPs/preprocesses/%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA.html">5.2.5. 文本表示</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../NLPs/preprocesses/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6.html">5.2.6. 注意力机制</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../NLPs/preprocesses/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B.html">5.2.7. 语言模型</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../NLPs/NER.html">5.3. NER-命名实体识别</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../NLPs/NERs/normal.html">5.3.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../NLPs/NERs/seq-label.html">5.3.2. 序列标注</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../NLPs/NERs/BiLSTM%2BCRF.html">5.3.3. BiLSTM+CRF</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../NLPs/NERs/history.html">5.3.4. 历史</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../NLPs/summary.html">5.4. 总结-摘要</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../NLPs/summarys/normal.html">5.4.1. 通用</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../library.html">6. 函数库</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/normal.html">6.1. 常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/Image.html">6.2. Image图像处理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/Video.html">6.3. Video视频</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/IPython.html">6.4. IPython</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/IPythons/normal.html">6.4.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/IPythons/magic.html">6.4.2. 魔法命令 </a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/IPythons/display.html">6.4.3. display函数</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/Jupyter.html">6.5. Jupyter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/NumPy.html">6.6. NumPy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/NumPys/normal.html">6.6.1. 通用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/NumPys/Ndarray.html">6.6.2. Ndarray 对象</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/NumPys/function.html">6.6.3. 通用函数</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/Pandas.html">6.7. Pandas</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Pandas/normal.html">6.7.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Pandas/example_subset.html">6.7.2. 实例-subset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Pandas/example_analysis.html">6.7.3. 实例-统计分析</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Pandas/example_sql.html">6.7.4. 利用pandas实现SQL操作</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Pandas/example_default_value.html">6.7.5. 实例-缺失值的处理</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Pandas/example_multi_index.html">6.7.6. 多层索引的使用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Pandas/practice.html">6.7.7. 实践</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../libraries/Pandas/practices/practice_2012ObamaElect.html">实践-2012年奥巴马总统连任选举</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Pandas/api_input_output.html">6.7.8. API-输入输出</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Pandas/api_General.html">6.7.9. API-General functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Pandas/api_Series.html">6.7.10. API-Series</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Pandas/api_DataFrame.html">6.7.11. API-DataFrame</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Pandas/api_Index.html">6.7.12. API-index</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/Matplotlib.html">6.8. Matplotlib</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Matplotlibs/normal.html">6.8.1. 基本</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Matplotlibs/install.html">6.8.2. 安装</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Matplotlibs/pyplot.html">6.8.3. pyplot </a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Matplotlibs/matplotlib.patches.html">6.8.4. matplotlib.patches</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Matplotlibs/example.html">6.8.5. 实例</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../libraries/Matplotlibs/examples/plot.html">折线图plot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libraries/Matplotlibs/examples/bar.html">条形图bar</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libraries/Matplotlibs/examples/hist.html">直方图hist</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libraries/Matplotlibs/examples/scatter.html">散点图scatter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libraries/Matplotlibs/examples/stackplot.html">面积图stackplot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libraries/Matplotlibs/examples/pie.html">饼图pie</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libraries/Matplotlibs/examples/box.html">箱型图box</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../libraries/Matplotlibs/examples/multi.html">多图合并multi</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Matplotlibs/pylab.html">6.8.6. pylab子包</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/SciPy.html">6.9. SciPy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/SciPys/normal.html">6.9.1. 常用</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/sklearn.html">6.10. sklearn</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/sklearns/normal.html">6.10.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/sklearns/supervised.html">6.10.2. 监督学习</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../libraries/sklearns/superviseds/glm.html">广义线性模型</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/sklearns/unsupervised.html">6.10.3. 无监督学习</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/statsmodels.html">6.11. statsmodels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/OpenCV.html">6.12. OpenCV</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/OpenCVs/normal.html">6.12.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/OpenCVs/example.html">6.12.2. 实例</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/OpenCVs/struct.html">6.12.3. 代码类结构</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/Seaborn.html">6.13. Seaborn</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/Seaborns/normal.html">6.13.1. 常用</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/jieba.html">6.14. jieba中文分词</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/gensim.html">6.15. gensim: 文本主题建模和相似性分析</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/gensims/normal.html">6.15.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/gensims/Core_Tutorials.html">6.15.2. Core Tutorials</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/gensims/Tutorials.html">6.15.3. Tutorials: Learning Oriented Lessons</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../libraries/gensims/How-to_Guides.html">6.15.4. How-to Guides: Solve a Problem</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../libraries/LAC.html">6.16. LAC-百度词法分析工具</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../framework.html">7. 学习框架</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../frameworks/normal.html">7.1. 常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../frameworks/pytorch.html">7.2. PyTorch</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../frameworks/pytorchs/normal.html">7.2.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../frameworks/pytorchs/nn.html">7.2.2. nn模块</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../frameworks/pytorchs/PyTorch.html">7.2.3. PyTorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../frameworks/pytorchs/ExecuTorch.html">7.2.4. ExecuTorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../frameworks/pytorchs/torchrun.html">7.2.5. torchrun (Elastic Launch)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../frameworks/huggingface.html">7.3. huggingface</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../frameworks/huggingfaces/normal.html">7.3.1. 常用</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../frameworks/huggingfaces/normals/huggingface_hub.html">Hugging Face Hub</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../frameworks/huggingfaces/normals/lib_python.html">Hub Python Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../frameworks/huggingfaces/normals/Datasets.html">Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../frameworks/huggingfaces/normals/Text_Generation_Inference_main.html">TGI: Text Generation Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../frameworks/huggingfaces/normals/Evaluate.html">Evaluate</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../frameworks/huggingfaces/Transformers.html">7.3.2. Transformers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../frameworks/huggingfaces/Transformers/Transformers.html">Transformers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../frameworks/huggingfaces/Transformers/Transformers_V4.45.2.html">Transformers 4.45.2</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../frameworks/huggingfaces/Tokenizers_V0.13.3.html">7.3.3. Tokenizers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../frameworks/huggingfaces/PEFT.html">7.3.4. PEFT</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../frameworks/huggingfaces/PEFT/PEFT.html">PEFT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../frameworks/huggingfaces/PEFT/PEFT_V0.13.0.html">PEFT 0.13.0</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../frameworks/huggingfaces/Accelerate.html">7.3.5. Accelerate</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../frameworks/huggingfaces/TRL.html">7.3.6. TRL - Transformer Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../frameworks/huggingfaces/collect.html">7.3.7. 收集</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../frameworks/huggingfaces/collects/resources.html">resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../frameworks/huggingfaces/collects/model.html">model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../frameworks/huggingfaces/collects/blog_decoding-methods.html">博文: decoding methods of LLM with transformers</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../frameworks/vLLM.html">7.4. vLLM</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../frameworks/vLLMs/normal.html">7.4.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../frameworks/vLLMs/vLLM_doc.html">7.4.2. vLLM官方文档</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../frameworks/llama.cpp.html">7.5. llama.cpp框架</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../frameworks/llama.cpps/normal.html">7.5.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../frameworks/llama.cpps/llama-cpp-python.html">7.5.2. Python bindings for llama.cpp</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../frameworks/DeepSpeed.html">7.6. DeepSpeed</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../frameworks/DeepSpeeds/huggingface.html">7.6.1. huggingface</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../frameworks/DeepSpeeds/ZeRO.html">7.6.2. Zero Redundancy Optimizer (ZeRO)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../frameworks/DeepSpeeds/deepspeed_doc.html">7.6.3. DeepSpeed</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../frameworks/mxnet.html">7.7. mxnet库</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../frameworks/mxnets/ndarray.html">7.7.1. nd模块</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../frameworks/mxnets/ndarrays/ndarray.html">ndarray</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../frameworks/mxnets/ndarrays/ndarray.random.html">ndarray.random</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../frameworks/mxnets/gluon.html">7.7.2. gluon模块</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../frameworks/mxnets/autograd.html">7.7.3. autograd模块</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../frameworks/tensorflow.html">7.8. tensorflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../frameworks/Keras.html">7.9. Keras</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../frameworks/Keras/normal.html">7.9.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../frameworks/Keras/demo.html">7.9.2. 实例</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../frameworks/Keras/demos/binary_classification.html">二分类问题</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../frameworks/Keras/demos/multiclass_classification.html">多分类问题</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../frameworks/Keras/demos/regression.html">回归问题</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../frameworks/other.html">7.10. 其他</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../website.html">8. 关键网站</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../websites/Papers%20with%20Code.html">8.1. Papers with Code</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../websites/Kaggle.html">8.2. Kaggle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../websites/ArXiv.html">8.3. ArXiv 学术论文预印本平台</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../websites/video.html">8.4. 视频相关</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../websites/normal.html">8.5. 通用</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../practice.html">9. 实践</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../practices/OCR.html">9.1. OCR</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../practices/OCRs/normal.html">9.1.1. 常用</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../practices/AIML.html">9.2. AIML</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../practices/AIMLs/normal.html">9.2.1. 常用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../practices/AIMLs/spec.html">9.2.2. AIML 2.1 Documentation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../opensource.html">10. 开源项目</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../opensources/Agent.html">10.1. Agent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../opensources/RAG.html">10.2. RAG</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../opensources/normal.html">10.3. 常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../opensources/ui.html">10.4. UI界面</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../opensources/finetune.html">10.5. 调优</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../opensources/search.html">10.6. 搜索</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../opensources/LLM-Inference-Engine.html">10.7. LLM Inference Engines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../opensources/LLM-Inference-Tool.html">10.8. 模型推理平台</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../opensources/LLM-inference-accelerate.html">10.9. LLM推理加速</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../opensources/Evaluate.html">10.10. LLM评估</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../opensources/platform.html">10.11. AI平台</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../dataset.html">11. 数据集</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../datasets/normal.html">11.1. 常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../datasets/chinese.html">11.2. 中文数据集</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../datasets/chinese_image.html">11.3. 中文图片相关数据集</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../datasets/huggingface.html">11.4. dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../datasets/website.html">11.5. 数据集相关网站</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../model.html">12. 常见模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cuda.html">13. 图形&amp;计算加速技术</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../cudas/normal.html">13.1. 常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../cudas/cuda.html">13.2. cuda</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../Evaluate.html">14. Evaluate评测</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Evaluates/normal.html">14.1. 通用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Evaluates/TruLens.html">14.2. TruLens</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Evaluates/Ragas.html">14.3. Ragas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Evaluates/DeepEval.html">14.4. DeepEval</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Evaluates/UpTrain.html">14.5. UpTrain</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Evaluates/huggingface.html">14.6. evaluate</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../%E4%BC%A0%E7%BB%9FAI.html">15. 传统AI</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">新溪-gordon</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../theory.html"><span class="section-number">2. </span>理论</a> &raquo;</li>
        
          <li><a href="../tmp.html"><span class="section-number">2.2. </span>临时</a> &raquo;</li>
        
      <li><span class="section-number">2.2.16. </span>通用</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/theories/tmps/0normal.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            <nav id="local-table-of-contents" role="navigation" aria-labelledby="local-table-of-contents-title">
              <h4 id="local-table-of-contents-title">On This Page</h4>
              <ul>
<li><a class="reference internal" href="#">2.2.16. 通用</a><ul>
<li><a class="reference internal" href="#llm-based-auto-annotators">LLM-based auto-annotators</a><ul>
<li><a class="reference internal" href="#id2">核心概念详解</a><ul>
<li><a class="reference internal" href="#id3">1. 它要解决什么问题？</a></li>
<li><a class="reference internal" href="#id4">2. 它是如何工作的？</a></li>
<li><a class="reference internal" href="#id5">3. 为什么它如此重要？</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id6">存在的挑战与局限性（也就是这篇论文的背景）</a></li>
<li><a class="reference internal" href="#id7">总结</a></li>
</ul>
</li>
<li><a class="reference internal" href="#counterfactual-prediction">反事实预测(Counterfactual Prediction)</a><ul>
<li><a class="reference internal" href="#id8">1. “事实”是什么？</a></li>
<li><a class="reference internal" href="#id9">2. “反事实”是什么？</a></li>
<li><a class="reference internal" href="#id10">3. 论文如何实现这个“反事实预测”？</a></li>
<li><a class="reference internal" href="#id11">一个简单的比喻</a></li>
<li><a class="reference internal" href="#id12">总结为什么论文里用这个词：</a></li>
</ul>
</li>
<li><a class="reference internal" href="#elo">Elo 评分系统</a><ul>
<li><a class="reference internal" href="#id13">核心概念</a></li>
<li><a class="reference internal" href="#id14">它是如何工作的？</a><ul>
<li><a class="reference internal" href="#id15">1. 核心组件：</a></li>
<li><a class="reference internal" href="#id16">2. 核心流程：</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id17">一个简单的例子</a></li>
<li><a class="reference internal" href="#llm-lmsys-chatbot-arena">在LLM评估中的应用（如LMSYS Chatbot Arena）</a></li>
</ul>
</li>
<li><a class="reference internal" href="#inverse-reinforcement-learning">逆强化学习（Inverse Reinforcement Learning）</a><ul>
<li><a class="reference internal" href="#id18">核心思想一句话概括</a></li>
<li><a class="reference internal" href="#irl">为什么需要IRL？—— 动机</a></li>
<li><a class="reference internal" href="#id19">IRL的基本假设</a></li>
<li><a class="reference internal" href="#id20">IRL的核心问题与挑战</a></li>
<li><a class="reference internal" href="#id21">IRL的一般流程</a></li>
<li><a class="reference internal" href="#id22">经典算法举例</a></li>
<li><a class="reference internal" href="#irl-vs-imitation-learning">IRL vs 模仿学习（Imitation Learning）</a></li>
<li><a class="reference internal" href="#id23">应用领域</a></li>
<li><a class="reference internal" href="#id24">总结</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
  <section class="tex2jax_ignore mathjax_ignore" id="id1">
<h1><span class="section-number">2.2.16. </span>通用<a class="headerlink" href="#id1" title="此标题的永久链接">¶</a></h1>
<section id="llm-based-auto-annotators">
<h2>LLM-based auto-annotators<a class="headerlink" href="#llm-based-auto-annotators" title="此标题的永久链接">¶</a></h2>
<p><strong>LLM-based auto-annotators（基于大语言模型的自动标注器）</strong> 指的是使用一个大型语言模型（通常是强大、先进的模型，如 GPT-4）来自动化地评估或判断另一个被测试模型（通常称为“目标模型”）生成的文本输出质量的过程。</p>
<p>您可以把它想象成 <strong>“用AI来给AI打分”</strong>。</p>
<hr class="docutils" />
<section id="id2">
<h3>核心概念详解<a class="headerlink" href="#id2" title="此标题的永久链接">¶</a></h3>
<section id="id3">
<h4>1. 它要解决什么问题？<a class="headerlink" href="#id3" title="此标题的永久链接">¶</a></h4>
<p>在LLM的发展过程中，研究人员和工程师需要不断评估新模型的性能。传统上，这个工作需要依靠<strong>人类评估者</strong>来完成。人类评估者会阅读模型对一系列提示（Prompts）的回复，并根据一些标准（如 helpfulness 有帮助性、harmlessness 无害性、fluency 流畅度等）进行评分或比较。</p>
<p>然而，人类评估存在几个巨大缺点：</p>
<ul class="simple">
<li><p><strong>成本高昂</strong>：需要支付大量评估人员的工资。</p></li>
<li><p><strong>速度缓慢</strong>：人工评估无法跟上模型迭代的速度。</p></li>
<li><p><strong>难以规模化</strong>：当需要测试成千上万个提示时，组织人力评估变得不切实际。</p></li>
<li><p><strong>一致性难题</strong>：不同评估者的标准可能有细微差别，难以保证完全一致。</p></li>
</ul>
</section>
<section id="id4">
<h4>2. 它是如何工作的？<a class="headerlink" href="#id4" title="此标题的永久链接">¶</a></h4>
<p>LLM-based auto-annotators 的出现就是为了解决上述问题。其工作流程通常如下：</p>
<ol class="arabic simple">
<li><p><strong>输入</strong>：给定一个<strong>提示（Prompt）</strong> 和两个（或多个）不同模型针对该提示生成的<strong>回复（Response）</strong>。</p></li>
<li><p><strong>调用评判模型</strong>：将一个更强大的LLM（如 GPT-4）作为“裁判”，向其发送一个精心设计的<strong>评判指令（Judgment Prompt）</strong>。这个指令会要求裁判模型根据特定标准（例如：“哪个回复更有帮助、更准确？”）来比较两个回复。</p></li>
<li><p><strong>输出</strong>：裁判模型（auto-annotator）会输出它的判断结果。结果形式通常是：</p>
<ul class="simple">
<li><p><strong>偏好选择</strong>：选择模型A获胜、模型B获胜或平局。</p></li>
<li><p><strong>评分</strong>：给每个回复打一个分数（例如，1-10分）。</p></li>
</ul>
</li>
<li><p><strong>统计汇总</strong>：在所有测试提示上运行此过程后，统计每个模型的胜率或平均分，从而得出一个模型相对于其他模型的整体性能排名。</p></li>
</ol>
<p><strong>一个简化示例：</strong></p>
<ul class="simple">
<li><p><strong>提示</strong>：“向我解释一下量子计算的基本原理。”</p></li>
<li><p><strong>模型A的回复</strong>：（一个简洁、准确的解释）</p></li>
<li><p><strong>模型B的回复</strong>：（一个冗长、包含无关信息的解释）</p></li>
<li><p><strong>给GPT-4（auto-annotator）的指令</strong>： “你是一个有帮助且公正的助手。请比较以下两个对用户问题的回复，哪个更有帮助、更相关？只输出‘A’或‘B’或‘Tie’。”</p></li>
<li><p><strong>GPT-4的输出</strong>： “A”</p></li>
</ul>
</section>
<section id="id5">
<h4>3. 为什么它如此重要？<a class="headerlink" href="#id5" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p><strong>成本效益</strong>：使用AI裁判的成本远低于雇佣人类。</p></li>
<li><p><strong>高速与可扩展性</strong>：可以在几分钟内自动评估数千个样本，极大加速了模型开发和迭代周期。</p></li>
<li><p><strong>一致性</strong>：AI裁判的标准是统一的，避免了人类主观性带来的偏差。</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="id6">
<h3>存在的挑战与局限性（也就是这篇论文的背景）<a class="headerlink" href="#id6" title="此标题的永久链接">¶</a></h3>
<p>尽管LLM-based auto-annotators优势巨大，但它们也存在一个根本性问题：</p>
<p><strong>它们并不是完美的“中立裁判”，自身也存在各种偏见（Bias）。</strong></p>
<p>论文中提到的<strong>长度偏好（Length Bias）</strong> 就是一个经典例子：自动标注器（如AlpacaEval中使用的GPT-4）会系统性倾向于给更长的回复打高分，即使更短的回复实际上更精炼、质量更高。这是因为更长回复通常包含更多细节，看起来更“努力”，从而触发了裁判模型的内在偏好。</p>
<p>其他可能偏见还包括：</p>
<ul class="simple">
<li><p><strong>风格偏好</strong>：喜欢特定格式（如分点论述）、特定语气或风格的回复。</p></li>
<li><p><strong>事实性谬误</strong>：可能无法准确判断回复中的事实错误。</p></li>
<li><p><strong>被自身能力限制</strong>：裁判模型自身的能力上限决定了它无法评估比它更聪明的模型。</p></li>
</ul>
</section>
<section id="id7">
<h3>总结<a class="headerlink" href="#id7" title="此标题的永久链接">¶</a></h3>
<p><strong>LLM-based auto-annotators</strong> 是利用一个强大的LLM作为“裁判”来自动评估其他模型输出质量的工具。它是LLM研发基础设施中的关键组成部分，实现了<strong>低成本、高速度、可规模化</strong>的评估。然而，它并非完美无瑕，其自身引入的<strong>偏见</strong>（如长度偏好）是当前研究需要重点关注和解决的问题。本文提出的“Length-Controlled”方法正是为了修正这种偏见而设计的。</p>
</section>
</section>
<section id="counterfactual-prediction">
<h2>反事实预测(Counterfactual Prediction)<a class="headerlink" href="#counterfactual-prediction" title="此标题的永久链接">¶</a></h2>
<p>因为它回答了一个 <strong>“如果……将会怎样？”（What if…?）</strong> 的问题，而这个问题的场景是<strong>与事实相反的、假设性的</strong>。</p>
<p>让我们来拆解一下：</p>
<section id="id8">
<h3>1. “事实”是什么？<a class="headerlink" href="#id8" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p><strong>事实</strong>是：在评估过程中，模型A生成了一个长度为 <code class="docutils literal notranslate"><span class="pre">L_A</span></code> 的回复，模型B（基线模型）生成了一个长度为 <code class="docutils literal notranslate"><span class="pre">L_B</span></code> 的回复。它们长度不同（<code class="docutils literal notranslate"><span class="pre">L_A</span> <span class="pre">≠</span> <span class="pre">L_B</span></code>）。</p></li>
<li><p>基于这个事实，自动评估器（如AlpacaEval）观察到了长度差异，并给出了一个偏好判断（例如，它认为模型A更好）。</p></li>
</ul>
</section>
<section id="id9">
<h3>2. “反事实”是什么？<a class="headerlink" href="#id9" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p><strong>反事实</strong>是：我们<strong>在脑海中构建了一个假设的、未曾发生过的世界</strong>。在这个世界里，模型A和模型B的回复<strong>长度完全相同</strong>（<code class="docutils literal notranslate"><span class="pre">L_A</span> <span class="pre">=</span> <span class="pre">L_B</span></code>）。</p></li>
<li><p>然后我们问：<strong>在这个假设的世界里，自动评估器会做出怎样的判断？</strong></p></li>
</ul>
</section>
<section id="id10">
<h3>3. 论文如何实现这个“反事实预测”？<a class="headerlink" href="#id10" title="此标题的永久链接">¶</a></h3>
<p>论文中的方法完美地模拟了这个思想实验：</p>
<ol class="arabic simple">
<li><p><strong>建立因果模型</strong>：他们使用历史数据拟合了一个公式（广义线性模型），这个公式描述了“长度差异”如何影响“评估器偏好”。这个模型捕捉了评估器的偏见——它有多偏爱更长的回复。</p></li>
<li><p><strong>干预</strong>：当我们要对一个新的模型比较进行“去偏”时，我们<strong>干预</strong>这个公式。我们强行将公式中的“长度差异”这个变量设置为我们想要的值——<strong>0</strong>（即长度相同）。</p></li>
<li><p><strong>预测</strong>：然后，我们用这个被干预过的公式重新计算预测值。这个新的预测值<strong>不是在预测实际发生的事</strong>（因为实际长度确实不同），而是在预测 <strong>“如果长度差为0，会发生什么”</strong>。</p></li>
</ol>
</section>
<section id="id11">
<h3>一个简单的比喻<a class="headerlink" href="#id11" title="此标题的永久链接">¶</a></h3>
<p>想象一下你在给学生打分，但你心里有一个无意识的偏见：<strong>更高的身高会让你下意识地给学生打更高的分</strong>（身高偏见）。</p>
<ul class="simple">
<li><p><strong>事实</strong>：学生A身高180cm，考了85分；学生B身高170cm，考了87分。你最终给了学生A更高的评价。</p></li>
<li><p><strong>反事实问题</strong>：“<strong>如果</strong>这两个学生身高一模一样，<strong>那么</strong>根据他们85分和87分的真实水平，你会如何评价？”</p></li>
<li><p><strong>如何实现</strong>：我通过数据分析发现，你的评分 = 真实分数 + (身高-175)*0.5。那么对于学生A，你的偏见加分是 <code class="docutils literal notranslate"><span class="pre">(180-175)*0.5</span> <span class="pre">=</span> <span class="pre">+2.5</span></code>；学生B是 <code class="docutils literal notranslate"><span class="pre">(170-175)*0.5</span> <span class="pre">=</span> <span class="pre">-2.5</span></code>。</p></li>
<li><p><strong>反事实预测</strong>：我现在<strong>干预</strong>这个公式，<strong>强行设定两人的身高都为175cm</strong>（即消除身高差异）。那么学生A的预测得分是 <code class="docutils literal notranslate"><span class="pre">85</span> <span class="pre">+</span> <span class="pre">0</span> <span class="pre">=</span> <span class="pre">85</span></code>，学生B是 <code class="docutils literal notranslate"><span class="pre">87</span> <span class="pre">+</span> <span class="pre">0</span> <span class="pre">=</span> <span class="pre">87</span></code>。</p></li>
<li><p><strong>结论</strong>：在消除了身高偏见（反事实条件）后，应该是学生B（87分）表现得更好。这个结论就是“反事实预测”。</p></li>
</ul>
</section>
<section id="id12">
<h3>总结为什么论文里用这个词：<a class="headerlink" href="#id12" title="此标题的永久链接">¶</a></h3>
<p>论文中的“反事实预测”指的正是：
<strong>通过统计模型，模拟在一个假设的、长度偏见被消除（即长度相等）的世界里，评估器会做出的判断。</strong> 这个判断与<strong>实际发生的事实（长度不等）</strong> 相反，故称为“反事实”。</p>
<p>这种方法的核心目的是<strong>剥离掉混淆因素（如长度）的影响</strong>，从而更清晰地揭示出输出<strong>内容质量</strong>本身的优劣，使得评估结果更加公平和可靠。</p>
</section>
</section>
<section id="elo">
<h2>Elo 评分系统<a class="headerlink" href="#elo" title="此标题的永久链接">¶</a></h2>
<p>这是一个非常重要且广泛应用的概念，尤其在竞争性排名中。</p>
<section id="id13">
<h3>核心概念<a class="headerlink" href="#id13" title="此标题的永久链接">¶</a></h3>
<p>Elo评分系统（Elo Rating System）最初由物理学家阿帕德·埃洛（Arpad Elo）为国际象棋设计，用于<strong>计算棋手相对技能水平</strong>的数值。它的核心思想非常简单：</p>
<blockquote>
<div><p><strong>通过选手之间的比赛结果，动态更新他们的分数，从而反映出他们当前的相对实力水平。</strong></p>
</div></blockquote>
</section>
<section id="id14">
<h3>它是如何工作的？<a class="headerlink" href="#id14" title="此标题的永久链接">¶</a></h3>
<p>Elo系统基于一个简单的“预期”和“结果”比较。</p>
<section id="id15">
<h4>1. 核心组件：<a class="headerlink" href="#id15" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p><strong>评分（Rating）</strong>：每个参与者都有一个数字分数，代表其预估的实力水平。分数越高，实力越强。</p></li>
<li><p><strong>K因子（K-factor）</strong>：一个常数，决定了每次比赛后分数调整的幅度。K值越大，分数变化越剧烈（新手通常用更大的K值，高手用更小的K值，以稳定评级）。</p></li>
</ul>
</section>
<section id="id16">
<h4>2. 核心流程：<a class="headerlink" href="#id16" title="此标题的永久链接">¶</a></h4>
<p>假设有两位选手/模型/实体：<strong>选手A</strong>（评分 <code class="docutils literal notranslate"><span class="pre">R_A</span></code>) 和 <strong>选手B</strong>（评分 <code class="docutils literal notranslate"><span class="pre">R_B</span></code>)。</p>
<ol class="arabic">
<li><p><strong>计算预期胜率（Expected Score）</strong>：</p>
<ul class="simple">
<li><p>在比赛前，系统会根据两人的分数差计算出每个人的预期胜率。</p></li>
<li><p>公式为：选手A的预期胜率 <img src="https://latex.codecogs.com/svg.png?E_A&space;=&space;\frac{1}{1&space;+&space;10^{(R_B&space;-&space;R_A)/400}}" title="E_A = \frac{1}{1 + 10^{(R_B - R_A)/400}}" /></p></li>
<li><p>选手B的预期胜率自然就是 <img src="https://latex.codecogs.com/svg.png?E_B&space;=&space;1&space;-&space;E_A" title="E_B = 1 - E_A" /></p></li>
<li><p><strong>解读</strong>：如果A的分数比B高很多（<code class="docutils literal notranslate"><span class="pre">R_A</span> <span class="pre">&gt;&gt;</span> <span class="pre">R_B</span></code>），那么 <code class="docutils literal notranslate"><span class="pre">E_A</span></code> 会接近1，表示A被预期几乎肯定会赢。如果两人分数相同，则预期胜率都是0.5。</p></li>
</ul>
</li>
<li><p><strong>进行比赛并观察结果（Actual Score）</strong>：</p>
<ul class="simple">
<li><p>比赛结束后，结果用一个值来表示：</p>
<ul>
<li><p><strong>赢 = 1</strong></p></li>
<li><p><strong>平 = 0.5</strong></p></li>
<li><p><strong>输 = 0</strong></p></li>
</ul>
</li>
<li><p>我们记选手A的实际得分为 <code class="docutils literal notranslate"><span class="pre">S_A</span></code>（赢就是1，输就是0，平就是0.5）。</p></li>
</ul>
</li>
<li><p><strong>更新评分（Update Rating）</strong>：</p>
<ul class="simple">
<li><p>将<strong>实际结果</strong>与<strong>预期结果</strong>进行比较。</p></li>
<li><p>选手A的新评分 <img src="https://latex.codecogs.com/svg.png?R_A'&space;=&space;R_A&space;+&space;K&space;\times&space;(S_A&space;-&space;E_A)" title="R_A' = R_A + K \times (S_A - E_A)" /></p></li>
<li><p><strong>解读</strong>：</p>
<ul>
<li><p>如果A赢了（<code class="docutils literal notranslate"><span class="pre">S_A</span> <span class="pre">=</span> <span class="pre">1</span></code>），但大家本来就觉得TA会赢（<code class="docutils literal notranslate"><span class="pre">E_A</span> <span class="pre">≈</span> <span class="pre">0.8</span></code>），那么 <code class="docutils literal notranslate"><span class="pre">(1</span> <span class="pre">-</span> <span class="pre">0.8)</span> <span class="pre">=</span> <span class="pre">0.2</span></code>，TA的分数只会小幅上涨 <code class="docutils literal notranslate"><span class="pre">K</span> <span class="pre">*</span> <span class="pre">0.2</span></code>。</p></li>
<li><p>如果A赢了（<code class="docutils literal notranslate"><span class="pre">S_A</span> <span class="pre">=</span> <span class="pre">1</span></code>），但TA是爆冷门（<code class="docutils literal notranslate"><span class="pre">E_A</span> <span class="pre">≈</span> <span class="pre">0.2</span></code>），那么 <code class="docutils literal notranslate"><span class="pre">(1</span> <span class="pre">-</span> <span class="pre">0.2)</span> <span class="pre">=</span> <span class="pre">0.8</span></code>，TA的分数会大幅上涨 <code class="docutils literal notranslate"><span class="pre">K</span> <span class="pre">*</span> <span class="pre">0.8</span></code>。</p></li>
<li><p>如果A输了（<code class="docutils literal notranslate"><span class="pre">S_A</span> <span class="pre">=</span> <span class="pre">0</span></code>），但大家本来就觉得TA会输（<code class="docutils literal notranslate"><span class="pre">E_A</span> <span class="pre">≈</span> <span class="pre">0.2</span></code>），那么 <code class="docutils literal notranslate"><span class="pre">(0</span> <span class="pre">-</span> <span class="pre">0.2)</span> <span class="pre">=</span> <span class="pre">-0.2</span></code>，TA的分数只会小幅下跌 <code class="docutils literal notranslate"><span class="pre">K</span> <span class="pre">*</span> <span class="pre">-0.2</span></code>。</p></li>
<li><p><strong>如果A的表现符合预期（<code class="docutils literal notranslate"><span class="pre">S_A</span> <span class="pre">≈</span> <span class="pre">E_A</span></code>），那么分数基本不变。</strong></p></li>
</ul>
</li>
</ul>
<p>选手B的评分更新方式完全相同。</p>
</li>
</ol>
</section>
</section>
<hr class="docutils" />
<section id="id17">
<h3>一个简单的例子<a class="headerlink" href="#id17" title="此标题的永久链接">¶</a></h3>
<p>假设：</p>
<ul class="simple">
<li><p>选手A：评分 1200</p></li>
<li><p>选手B：评分 1000</p></li>
<li><p>K因子：32</p></li>
</ul>
<ol class="arabic simple">
<li><p><strong>计算预期</strong>：</p>
<ul class="simple">
<li><p>A对B的预期胜率 <img src="https://latex.codecogs.com/svg.png?E_A&space;=&space;\frac{1}{1&space;+&space;10^{(1000-1200)/400}}&space;=&space;\frac{1}{1&space;+&space;10^{-0.5}}&space;\approx&space;\frac{1}{1&space;+&space;0.316}&space;\approx&space;0.76" title="E_A = \frac{1}{1 + 10^{(1000-1200)/400}} = \frac{1}{1 + 10^{-0.5}} \approx \frac{1}{1 + 0.316} \approx 0.76" /></p></li>
<li><p>B对A的预期胜率 <img src="https://latex.codecogs.com/svg.png?E_B&space;=&space;1&space;-&space;0.76&space;=&space;0.24" title="E_B = 1 - 0.76 = 0.24" /></p></li>
</ul>
</li>
<li><p><strong>进行比赛</strong>：</p>
<ul class="simple">
<li><p>** Scenario 1: A赢了（符合预期）**</p>
<ul>
<li><p>A的新评分 = <code class="docutils literal notranslate"><span class="pre">1200</span> <span class="pre">+</span> <span class="pre">32</span> <span class="pre">*</span> <span class="pre">(1</span> <span class="pre">-</span> <span class="pre">0.76)</span> <span class="pre">=</span> <span class="pre">1200</span> <span class="pre">+</span> <span class="pre">32</span> <span class="pre">*</span> <span class="pre">0.24</span> <span class="pre">=</span> <span class="pre">1200</span> <span class="pre">+</span> <span class="pre">7.68</span> <span class="pre">≈</span> <span class="pre">1208</span></code></p></li>
<li><p>B的新评分 = <code class="docutils literal notranslate"><span class="pre">1000</span> <span class="pre">+</span> <span class="pre">32</span> <span class="pre">*</span> <span class="pre">(0</span> <span class="pre">-</span> <span class="pre">0.24)</span> <span class="pre">=</span> <span class="pre">1000</span> <span class="pre">-</span> <span class="pre">7.68</span> <span class="pre">≈</span> <span class="pre">992</span></code></p></li>
</ul>
</li>
<li><p>** Scenario 2: B赢了（爆出冷门）**</p>
<ul>
<li><p>A的新评分 = <code class="docutils literal notranslate"><span class="pre">1200</span> <span class="pre">+</span> <span class="pre">32</span> <span class="pre">*</span> <span class="pre">(0</span> <span class="pre">-</span> <span class="pre">0.76)</span> <span class="pre">=</span> <span class="pre">1200</span> <span class="pre">-</span> <span class="pre">24.32</span> <span class="pre">≈</span> <span class="pre">1176</span></code></p></li>
<li><p>B的新评分 = <code class="docutils literal notranslate"><span class="pre">1000</span> <span class="pre">+</span> <span class="pre">32</span> <span class="pre">*</span> <span class="pre">(1</span> <span class="pre">-</span> <span class="pre">0.24)</span> <span class="pre">=</span> <span class="pre">1000</span> <span class="pre">+</span> <span class="pre">32</span> <span class="pre">*</span> <span class="pre">0.76</span> <span class="pre">=</span> <span class="pre">1000</span> <span class="pre">+</span> <span class="pre">24.32</span> <span class="pre">≈</span> <span class="pre">1024</span></code></p></li>
</ul>
</li>
</ul>
</li>
</ol>
<p>可以看到，爆冷门（以弱胜强）会导致分数发生巨大变化。</p>
</section>
<hr class="docutils" />
<section id="llm-lmsys-chatbot-arena">
<h3>在LLM评估中的应用（如LMSYS Chatbot Arena）<a class="headerlink" href="#llm-lmsys-chatbot-arena" title="此标题的永久链接">¶</a></h3>
<p>在像Chatbot Arena这样的平台上，Elo系统是完美的选择：</p>
<ol class="arabic simple">
<li><p><strong>匿名对决</strong>：用户同时看到两个不同模型（如GPT-4和Claude）对同一个问题的回复，但不知道哪个回复来自哪个模型。</p></li>
<li><p><strong>人类投票</strong>：用户投票选择哪个回复更好（或平局）。</p></li>
<li><p><strong>视为比赛</strong>：每一次人类投票都被视为一场“比赛”。</p></li>
<li><p><strong>更新Elo分数</strong>：系统根据投票结果（即比赛结果）更新这两个模型的Elo分数。</p>
<ul class="simple">
<li><p>如果一个弱模型意外地战胜了一个强模型，它会获得很多分数，而强模型会失去很多分数。</p></li>
<li><p>如果强模型轻松击败弱模型，它们的分数只会微调。</p></li>
</ul>
</li>
</ol>
<p>经过数十万次这样的“比赛”后，所有模型的Elo分数就会稳定下来，形成一个<strong>非常可靠的相对排名榜</strong>。这就是为什么论文中说他们的新指标与Chatbot Arena的<strong>相关性更高</strong>是一件大事——因为Chatbot Arena的排名被视为基于人类偏好的“黄金标准”。</p>
</section>
</section>
<section id="inverse-reinforcement-learning">
<h2>逆强化学习（Inverse Reinforcement Learning）<a class="headerlink" href="#inverse-reinforcement-learning" title="此标题的永久链接">¶</a></h2>
<section id="id18">
<h3>核心思想一句话概括<a class="headerlink" href="#id18" title="此标题的永久链接">¶</a></h3>
<p><strong>逆强化学习（IRL）</strong> 与传统的强化学习（RL）相反：</p>
<ul class="simple">
<li><p><strong>强化学习 (RL)</strong>：在已知<strong>奖励函数（什么行为是好的）</strong> 的前提下，学习一个<strong>最优策略（如何行动）</strong>。</p></li>
<li><p><strong>逆强化学习 (IRL)</strong>：通过观察专家的<strong>最优策略（如何行动）</strong>，反过来推导出其背后隐含的<strong>奖励函数（什么行为是好的）</strong>。</p></li>
</ul>
<p>想象一下，你看到一个大师在下棋并赢得了比赛。</p>
<ul class="simple">
<li><p><strong>RL</strong> 要解决的问题是：“我知道赢棋是最终奖励，现在我该如何学习下棋才能最大化这个奖励？”</p></li>
<li><p><strong>IRL</strong> 要解决的问题是：“我看完了大师所有的下法，但我不知道他为什么这么下。他追求的奖励到底是什么？是控制中心、保护王、还是吃掉更多棋子？我要从他的一系列动作中推断出他内心深处的‘奖励标准’。”</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="irl">
<h3>为什么需要IRL？—— 动机<a class="headerlink" href="#irl" title="此标题的永久链接">¶</a></h3>
<p>直接设计一个有效的奖励函数通常非常困难，甚至不现实。</p>
<ol class="arabic simple">
<li><p><strong>奖励函数的复杂性</strong>：对于很多复杂任务（如自动驾驶、机器人行走），我们很难用简单的规则来定义奖励。比如，如何为“驾驶得像一个人类”这个任务编写奖励函数？要考虑到舒适度、安全性、交通法规、社交礼仪等无数因素，几乎不可能手动编码。</p></li>
<li><p><strong>“奖励黑客”（Reward Hacking）</strong>：如果奖励函数设计得不够周全，智能体可能会找到一些意想不到的、甚至危险的方式来最大化奖励，而不是真正完成我们期望的任务。例如，一个旨在“快速到达终点”的扫地机器人可能会选择撞翻垃圾桶而不是绕行，因为这“更快”。</p></li>
<li><p><strong>从专家行为中学习</strong>：人类专家（如资深司机、外科医生）的行为中蕴含了大量隐性的、难以言传的知识。IRL提供了一种方法，可以从他们的示范（Demonstration）中提取这些知识，并将其形式化为一个奖励函数。</p></li>
</ol>
<p><strong>因此，IRL的核心动机是：与其费尽心思地手动设计一个不完美的奖励函数，不如直接从专家的优秀行为中学习和推断这个奖励函数。</strong></p>
</section>
<hr class="docutils" />
<section id="id19">
<h3>IRL的基本假设<a class="headerlink" href="#id19" title="此标题的永久链接">¶</a></h3>
<p>IRL基于一个重要的假设：<strong>被观察的专家行为是近乎最优的</strong>。也就是说，专家的行为是在某个（我们未知的）真实奖励函数下，通过优化得到的（或接近最优的）策略。我们的任务就是找到这个能解释专家行为的奖励函数。</p>
</section>
<hr class="docutils" />
<section id="id20">
<h3>IRL的核心问题与挑战<a class="headerlink" href="#id20" title="此标题的永久链接">¶</a></h3>
<p>IRL本质上是一个<strong>病态逆问题（Ill-posed Inverse Problem）</strong>。这意味着：</p>
<ul class="simple">
<li><p><strong>多个解（奖励函数）可以解释同样的行为</strong>。例如，专家选择走一条路，可能是因为这条路最短，也可能是因为这条路风景最好。仅从“选择这条路”这个行为，我们无法唯一确定奖励函数。</p></li>
<li><p><strong>Trivial Solution（平凡解）</strong>：一个最简单的错误解是，给专家走过的每一个状态（或状态-动作对）都分配一个高奖励，而其他状态分配零奖励或负奖励。这样的奖励函数虽然能完美“解释”专家数据，但它毫无泛化能力，无法指导智能体在未见过的新情况下做出决策。这通常被称为**“Reward Shaping”** 陷阱。</p></li>
</ul>
</section>
<section id="id21">
<h3>IRL的一般流程<a class="headerlink" href="#id21" title="此标题的永久链接">¶</a></h3>
<ol class="arabic simple">
<li><p><strong>输入</strong>：专家示范（Demonstrations）。这可以是一系列轨迹（Trajectories，即状态-动作序列），或者专家在特定状态下选择的动作。</p></li>
<li><p><strong>建模</strong>：假设奖励函数是某些特征（Features）的线性组合。例如，在自动驾驶中，特征可以是“车速”、“与车道中心的距离”、“与前车的距离”等。那么奖励函数可以表示为：<code class="docutils literal notranslate"><span class="pre">R(s)</span> <span class="pre">=</span> <span class="pre">w1</span> <span class="pre">*</span> <span class="pre">f1(s)</span> <span class="pre">+</span> <span class="pre">w2</span> <span class="pre">*</span> <span class="pre">f2(s)</span> <span class="pre">+</span> <span class="pre">...</span> <span class="pre">+</span> <span class="pre">wn</span> <span class="pre">*</span> <span class="pre">fn(s)</span></code>，其中 <code class="docutils literal notranslate"><span class="pre">w</span></code> 是权重，表示每个特征的重要性。</p></li>
<li><p><strong>求解</strong>：IRL算法的目标是找到一组权重 <code class="docutils literal notranslate"><span class="pre">w</span></code>，使得<strong>专家策略的性能（累计奖励）显著高于所有其他可能策略的性能</strong>。换句话说，专家的策略应该是在这个奖励函数下最优的策略。</p></li>
<li><p><strong>输出</strong>：推导出的奖励函数 <code class="docutils literal notranslate"><span class="pre">R(s)</span></code>。</p></li>
</ol>
</section>
<hr class="docutils" />
<section id="id22">
<h3>经典算法举例<a class="headerlink" href="#id22" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p><strong>学徒学习（Apprenticeship Learning）</strong>：通过迭代的过程，不断调整权重 <code class="docutils literal notranslate"><span class="pre">w</span></code>，使得基于当前奖励函数得到的最优策略与专家策略的差距越来越小，直到差距小于某个阈值。</p></li>
<li><p><strong>最大熵逆强化学习（Maximum Entropy IRL）</strong>：这是IRL领域一个里程碑式的方法。它解决“多个解”的问题的原则是：<strong>在所有能解释专家行为的奖励函数中，选择那个对应策略分布最均匀（熵最大）的</strong>。简单说，它不偏爱任何除了能解释数据之外的其他假设，避免了武断的结论，效果通常更好。许多现代算法（如Guided Cost Learning）都基于此发展而来。</p></li>
<li><p><strong>生成对抗模仿学习（GAIL）</strong>：这种方法甚至绕过了显式地求解奖励函数这一步。它使用生成对抗网络（GAN）的框架，直接让智能体的策略学习模仿专家的策略分布。可以将其理解为一种隐式的IRL。</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="irl-vs-imitation-learning">
<h3>IRL vs 模仿学习（Imitation Learning）<a class="headerlink" href="#irl-vs-imitation-learning" title="此标题的永久链接">¶</a></h3>
<p>两者密切相关，都使用专家示范，但目标不同：</p>
<ul class="simple">
<li><p><strong>模仿学习（如行为克隆）</strong>：目标是<strong>直接学习一个策略</strong>，使其复现专家的动作。它不关心专家为什么这么做。</p></li>
<li><p><strong>逆强化学习（IRL）</strong>：目标是<strong>学习一个奖励函数</strong>。之后，通常还需要再用RL方法基于这个奖励函数去学习一个策略。</p></li>
</ul>
<p>所以，IRL + RL = 一种更强大、泛化能力更强的模仿学习。模仿学习是“知其然”，而IRL是“知其所以然”。</p>
</section>
<section id="id23">
<h3>应用领域<a class="headerlink" href="#id23" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p><strong>机器人</strong>：让机器人通过观察人类来学习任务（如摆放餐具、拧瓶盖）。</p></li>
<li><p><strong>自动驾驶</strong>：从人类驾驶数据中学习驾驶风格和决策逻辑。</p></li>
<li><p><strong>游戏AI</strong>：模仿高玩玩家的风格，并理解其背后的策略。</p></li>
<li><p><strong>数据分析</strong>：通过分析用户的行为（如购物路径、视频观看习惯）来推断用户的偏好和意图。</p></li>
</ul>
</section>
<section id="id24">
<h3>总结<a class="headerlink" href="#id24" title="此标题的永久链接">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-left"><p>特性</p></th>
<th class="head text-left"><p>强化学习 (RL)</p></th>
<th class="head text-left"><p>逆强化学习 (IRL)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><strong>输入</strong></p></td>
<td class="text-left"><p>状态、动作、<strong>奖励函数</strong></p></td>
<td class="text-left"><p><strong>专家示范</strong>、状态、动作</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>目标</strong></p></td>
<td class="text-left"><p>找到<strong>最优策略</strong> <code class="docutils literal notranslate"><span class="pre">π*</span></code></p></td>
<td class="text-left"><p>找到<strong>奖励函数</strong> <code class="docutils literal notranslate"><span class="pre">R</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>问题</strong></p></td>
<td class="text-left"><p>“如何根据奖励行动？”</p></td>
<td class="text-left"><p>“专家行为的动机是什么？”</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>类比</strong></p></td>
<td class="text-left"><p>学生根据评分标准（奖励）学习</p></td>
<td class="text-left"><p>老师通过观察学霸（专家）的答题思路来反推评分标准</p></td>
</tr>
</tbody>
</table>
<p>逆强化学习是连接“行为”与“意图”的桥梁，它使我们能够从观察中学习更深层的价值标准，是让AI智能体变得更智能、更人性化的重要技术之一。</p>
</section>
</section>
</section>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../../LLM.html" class="btn btn-neutral float-right" title="3. 大模型" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="Workflow.html" class="btn btn-neutral" title="2.2.15. Workflow" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>
  
  <div id="gitalk-container"></div>
  <div role="contentinfo">
    <p>
        &copy; Copyright 2010-2025, 新溪-gordon.

    </p>
  </div>
  <div>备案号 <a href="http://www.beian.miit.gov.cn">京ICP备16018553号</a></div><div>Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a></div>. 


</footer>

<script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?042289284b8eb33866001347a3e0b129";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
</script>     
        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'V2025.11',
            LANGUAGE:'zh-CN',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="../../_static/sphinx_highlight.js"></script>
      <script type="text/javascript" src="../../_static/clipboard.min.js"></script>
      <script type="text/javascript" src="../../_static/copybutton.js"></script>
      <script type="text/javascript" src="../../_static/translations.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>

  

  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });


      // var gitalk = new Gitalk({
      //         clientID: '565177626b5d46427009',
      //         clientSecret: 'b2a36e67e1d2a73e43667f46d571c2624f8e1026',
      //         repo: 'knowledge',
      //         owner: 'zhaoweiguo',
      //         admin: ['zhaoweiguo'],
      //         id: location.pathname,      // Ensure uniqueness and length less than 50
      //         distractionFreeMode: false  // Facebook-like distraction free mode
      //       })
      // gitalk.render('gitalk-container')

  </script>


<script type="text/javascript" src="../../_static/js/table-of-contents-sidebar.js"></script>
<!-- <script type="text/javascript" src="https://table-of-contents-sidebar.github.io/table-of-contents-sidebar-lib/table-of-contents-sidebar.js"></script> -->
<script type="text/javascript">
    window.onload = function(e){
        TableOfContents.init({
            basePath: "https://table-of-contents-sidebar.github.io/table-of-contents-sidebar-lib/",
            querySelector: "body" // or other css querySelector
        });
    }
</script> 

</body>
</html>