Embedding 模型
##############

* Embedding 模型在自然语言处理（NLP）和机器学习中的作用主要是将高维度、稀疏的离散数据（如单词、短语或其他类别）转换为低维度、稠密的实数向量。这些实数向量（embedding）能够捕捉到数据之间的语义关系和模式，从而使得计算和分析更加高效和有效。




常见的Embedding模型包括::

    Word2Vec：将单词表示为向量，通过上下文窗口进行训练。
    GloVe：基于全局词共现矩阵进行训练，生成词向量。
    FastText：扩展了Word2Vec，通过考虑子词信息提高表示能力。
    BERT：基于Transformer架构的预训练模型，可以捕捉上下文依赖关系。


























