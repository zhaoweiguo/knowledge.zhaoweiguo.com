LAC-百度词法分析工具
####################

* https://pypi.org/project/LAC/
* GitHub: https://github.com/baidu/lac
* 论文(Chinese Lexical Analysis with Deep Bi-GRU-CRF Network): https://arxiv.org/abs/1807.01882


简介
====

* LAC 全称 Lexical Analysis of Chinese，是百度自然语言处理部研发的一款联合的词法分析工具，实现中文分词、词性标注、专名识别等功能。
* 该工具具有以下特点与优势::

    1. 效果好
        通过深度学习模型联合学习分词、词性标注、专名识别任务，词语重要性
        整体效果 F1 值超过 0.91，词性标注 F1 值超过 0.94，专名识别 F1 值超过 0.85，效果业内领先
    2. 效率高
        精简模型参数，结合 Paddle 预测库的性能优化，CPU 单线程性能达 800QPS，效率业内领先。
    3. 可定制
        实现简单可控的干预机制，精准匹配用户词典对模型进行干预。词典支持长片段形式，使得干预更为精准。
    4. 调用便捷
        支持一键安装，同时提供了 Python、Java 和 C++ 调用接口与调用示例，实现快速调用和集成。
    5. 支持移动端
         定制超轻量级模型，体积仅为 2M，主流千元手机单线程性能达 200QPS，满足大多数移动端应用的需求，同等体积量级效果业内领先。



安装::

    全自动安装: 
        pip install lac
    国内网络可使用百度源安装，安装速率更快：
        pip install lac -i https://mirror.baidu.com/pypi/simple


    半自动下载：
    先下载 http://pypi.python.org/pypi/lac/，
    解压后运行 python setup.py install


安装验证::

    lac 或 lac --segonly,lac --rank

分词
====

示例::

    from LAC import LAC

    # 装载分词模型
    lac = LAC(mode='seg')

    # 单个样本输入，输入为Unicode编码的字符串
    text = u"LAC是个优秀的分词工具"
    seg_result = lac.run(text)
    # 【单样本】
    # seg_result = [LAC, 是, 个, 优秀, 的, 分词, 工具]

    # 批量样本输入, 输入为多个句子组成的list，平均速率会更快
    texts = [u"LAC是个优秀的分词工具", u"百度是一家高科技公司"]
    seg_result = lac.run(texts)
    # 【批量样本】
    # seg_result = [[LAC, 是, 个, 优秀, 的, 分词, 工具], [百度, 是, 一家, 高科技, 公司]]



词性
====

说明::

    标签    含义
    n   普通名词
    f   方位名词
    s   处所名词
    nw  作品名
    nz  其他专名

    v   普通动词
    vd  动副词
    vn  名动词
    
    a   形容词
    ad  副形词
    an  名形词

    d   副词
    m   数量词
    q   量词
    r   代词
    p   介词
    c   连词
    u   助词
    xc  其他虚词
    w   标点符号
    
    PER   人名
    LOC   地名
    ORG   机构名
    TIME  时间


+----------+-----------+-----------------+----------+------+-----------+--------+----------+
| 标签     | 含义      | 标签            | 含义     | 标签 | 含义      | 标签   | 含义     |
+==========+===========+=================+==========+======+===========+========+==========+
| n        | 普通名词  | f               | 方位名词 | s    | 处所名词  | nw     | 作品名   |
+----------+-----------+-----------------+----------+------+-----------+--------+----------+
| nz       | 其他专名  | v               | 普通动词 | vd   | 动副词 vn | 名动词 |          |
+----------+-----------+-----------------+----------+------+-----------+--------+----------+
| a        | 形容词 ad | 副形词 an       | 名形词 d | 副词 |           |        |          |
+----------+-----------+-----------------+----------+------+-----------+--------+----------+
| m        | 数量词 q  | 量词            | r        | 代词 | p         | 介词   |          |
+----------+-----------+-----------------+----------+------+-----------+--------+----------+
| c        | 连词      | u               | 助词     | xc   | 其他虚词  | w      | 标点符号 |
+----------+-----------+-----------------+----------+------+-----------+--------+----------+
| PER 人名 | LOC 地名  | ORG 机构名 TIME | 时间     |      |           |        |          |
+----------+-----------+-----------------+----------+------+-----------+--------+----------+

示例-词性标注与实体识别::

    from LAC import LAC

    # 装载LAC模型
    lac = LAC(mode='lac')

    # 单个样本输入，输入为Unicode编码的字符串
    text = u"LAC是个优秀的分词工具"
    lac_result = lac.run(text)
    # 【单样本】
    # lac_result = ([百度, 是, 一家, 高科技, 公司], [ORG, v, m, n, n])


    # 批量样本输入, 输入为多个句子组成的list，平均速率更快
    texts = [u"LAC是个优秀的分词工具", u"百度是一家高科技公司"]
    lac_result = lac.run(texts)
    # 【批量样本】
    # lac_result = [
    #     ([百度, 是, 一家, 高科技, 公司], [ORG, v, m, n, n]),
    #     ([LAC, 是, 个, 优秀, 的, 分词, 工具], [nz, v, q, a, u, n, n])
    # ]


词语重要性
==========

示例::

    from LAC import LAC

    # 装载词语重要性模型
    lac = LAC(mode='rank')

    # 单个样本输入，输入为Unicode编码的字符串
    text = u"LAC是个优秀的分词工具"
    rank_result = lac.run(text)
    # 【单样本】：rank_result = [['LAC', '是', '个', '优秀', '的', '分词', '工具'], 
                        [nz, v, q, a, u, n, n],[3, 0, 0, 2, 0, 3, 1]]



    # 批量样本输入, 输入为多个句子组成的list，平均速率会更快
    texts = [u"LAC是个优秀的分词工具", u"百度是一家高科技公司"]
    rank_result = lac.run(texts)
    # 【批量样本】
    # rank_result = [
    #    (['LAC', '是', '个', '优秀', '的', '分词', '工具'], 
    #     [nz, v, q, a, u, n, n], [3, 0, 0, 2, 0, 3, 1]), 
    #    (['百度', '是', '一家', '高科技', '公司'], 
    #     [ORG, v, m, n, n], [3, 0, 2, 3, 1])
    # ]

词语重要性程度各类别标签集合如下表，我们使用 4-Level 梯度进行分类::

    标签  含义                  常见于词性
    0   query 中表述的冗余词     p, w, xc ...
    1   query 中限定较弱的词     r, c, u ...
    2   query 中强限定的词       n, s, v ...
    3   query 中的核心词         nz, nw, LOC ...


+------+----------------------------------+--------------+
| 标签 | 含义                             | 常见于词性   |
+======+==================================+==============+
| 0    | query 中表述的冗余词             | p, w, xc ... |
+------+----------------------------------+--------------+
| 1    | query 中限定较弱的词             | r, c, u ...  |
+------+----------------------------------+--------------+
| 2    | query 中强限定的词               | n, s, v ...  |
+------+----------------------------------+--------------+
| 3    | query 中的核心词 nz, nw, LOC ... |              |
+------+----------------------------------+--------------+


定制化功能
==========

* 在模型输出的基础上，LAC 还支持用户配置定制化的切分结果和专名类型输出。当模型预测匹配到词典的中的 item 时，会用定制化的结果替代原有结果。为了实现更加精确的匹配，我们支持以由多个单词组成的长片段作为一个 item。
* 我们通过装载词典文件的形式实现该功能，词典文件每行表示一个定制化的 item，由一个单词或多个连续的单词组成，每个单词后使用 '/' 表示标签，如果没有 '/' 标签则会使用模型默认的标签。每个 item 单词数越多，干预效果会越精准。

词典文件示例::

    春天/SEASON
    花/n 开/v
    秋天的风
    落 阳

代码示例::

    from LAC import LAC
    lac = LAC()

    # 装载干预词典, sep参数表示词典文件采用的分隔符，为None时默认使用空格或制表符'\t'
    lac.load_customization('custom.txt', sep=None)

    # 干预后结果
    custom_result = lac.run(u"春天的花开秋天的风以及冬天的落阳")

    # 原本输出结果:
    # 春天/TIME 的/u 花开/v 秋天/TIME 的/u 风/n 以及/c 冬天/TIME 的/u 落阳/n

    # 添加示例中的词典文件后的结果为:
    # 春天/SEASON 的/u 花/n 开/v 秋天的风/n 以及/c 冬天/TIME 的/u 落/n 阳/n


增量训练
========

* 我们也提供了增量训练的接口，用户可以使用自己的数据，进行增量训练，首先需要将数据转换为模型输入的格式，并且所有数据文件均为 "UTF-8" 编码：

1. 分词训练
-----------

数据样例(与大多数开源分词数据集格式一致，使用空格作为单词切分标记)::

    LAC 是 个 优秀 的 分词 工具 。
    百度 是 一家 高科技 公司 。
    春天 的 花开 秋天 的 风 以及 冬天 的 落阳 。

代码示例::

    from LAC import LAC

    # 选择使用分词模型
    lac = LAC(mode = 'seg')

    # 训练和测试数据集，格式一致
    train_file = "./data/seg_train.tsv"
    test_file = "./data/seg_test.tsv"
    lac.train(model_save_dir='./my_seg_model/',train_data=train_file, test_data=test_file)

    # 使用自己训练好的模型
    my_lac = LAC(model_path='my_seg_model')


2. 词法分析训练
---------------

数据样例(在分词数据的基础上，每个单词以 “/type” 的形式标记其词性或实体类别)::

    LAC/nz 是/v 个/q 优秀/a 的/u 分词/n 工具/n 。/w
    百度/ORG 是/v 一家/m 高科技/n 公司/n 。/w
    春天/TIME 的/u 花开/v 秋天/TIME 的/u 风/n 以及/c 冬天/TIME 的/u 落阳/n 。/w



代码示例::

    from LAC import LAC

    # 选择使用默认的词法分析模型
    lac = LAC()

    # 训练和测试数据集，格式一致
    train_file = "./data/lac_train.tsv"
    test_file = "./data/lac_test.tsv"
    lac.train(model_save_dir='./my_lac_model/',train_data=train_file, test_data=test_file)

    # 使用自己训练好的模型
    my_lac = LAC(model_path='my_lac_model')



































