传统AI
######






检索&推荐
=========

* 在推荐或搜索系统中，通过结合 Lucene 关键词检索 与 Embedding 向量检索（Hybrid Search），可以更好地实现 多种类型的召回方式，如基于商品（item）、用户（user）、搜索词（query）等角度，扩大召回范围，提高召回质量。




多路召回
--------

* item2item：基于用户当前或历史浏览/点击的商品，召回相似商品（类似“看了又看”）。

* query2item：基于用户搜索词召回商品，属于传统的搜索逻辑。
    - 用户输入 搜索词（Query），系统根据该 Query 召回一批 相关的商品（Item）
    - 比如用户搜索 “蓝牙耳机”，系统召回相关的耳机商品

* user2item：基于用户的整体兴趣画像、历史行为召回感兴趣的商品（协同过滤或画像匹配）。



检索
----


* Term-based 检索（关键词检索）

    - 使用如 Lucene / BM25 / Elasticsearch 的技术
    - 基于 倒排索引，依赖词面匹配（如 Query 包含 “蓝牙”，Item 文本也得包含这个词）
    - 精确、快速，但语义理解弱
    - 示例：
        - “蓝牙耳机” → 匹配商品标题中有 “蓝牙” 和 “耳机” 的商品


* Embedding-based 检索（语义向量检索）
    - 使用深度模型（如 BERT）将 Query 和 Item 编码成向量
    - 通过 向量相似度（如余弦距离） 检索语义相似的内容
    - 能处理同义词、上下文含义、语义近似等
    - 示例：
        - “无线耳机” → 可召回含“蓝牙耳机”的商品（虽然词不一样）

* Term-Embedding 混合模型（Hybrid）
    - Hybrid 模型结合两种方式的优点：
        - Term 检索 保证精确性、覆盖经典用户意图
        - Embedding 检索 提高语义理解能力，扩展召回范围
    - 结合方式可能包括：
        - 双塔融合召回
        - 多路召回合并
        - Lucene 先筛选 + 向量 rerank
        - FAISS/ANN 向量召回 + BM25 rerank




机器学习
========



XGBoost
-------

* XGBoost（Extreme Gradient Boosting） 是一种高效的、可扩展的 梯度提升树（Gradient Boosted Trees） 实现，是目前机器学习中最常用的集成学习方法之一，广泛应用于分类、回归、排序等任务。
* 核心思想：通过不断叠加“弱分类器”（如决策树），每一步训练一个新的树模型来修正上一步模型的错误预测。
* 模型类型：一种 Boosting 框架，以梯度下降思想优化损失函数。


* 应用场景
    * Kaggle / 天池 竞赛获奖常客
    * 推荐系统
    * 广告点击率预测
    * 信用评分 / 风控模型
    * 疾病预测 / 医疗建模
    * 搜索排序


* 与其他方法的对比

+----------+-------------------------------------------------------+
| 方法     | 说明                                                  |
+----------+-------------------------------------------------------+
| GBDT     | 基础版本，XGBoost 是其优化实现                        |
+----------+-------------------------------------------------------+
| LightGBM | 更快更省内存，适合超大规模数据                        |
+----------+-------------------------------------------------------+
| CatBoost | 处理类别特征更好（免 one-hot）                        |
+----------+-------------------------------------------------------+
| 随机森林 | 并行训练多个树（Bagging），而 XGBoost 是串行 Boosting |
+----------+-------------------------------------------------------+



LR(Logistic Regression)模型
---------------------------

* 在很多工业级推荐系统、广告系统、风控系统中，会采用 **多模型融合** 架构，常见组合之一就是：
    * **XGBoost**：用于挖掘复杂非线性关系、高阶交叉特征
    * **Logistic Regression（LR）**：用于建模线性关系、解释性强、部署轻量



* 常见应用形式:

+-----------------------------+---------------------------------------------------------------+
| 场景                        | 描述                                                          |
+=============================+===============================================================+
| **串联推理**                | 先用 XGBoost 召回候选项，再用 LR 进行排序或打分（或者反过来） |
+-----------------------------+---------------------------------------------------------------+
| **特征融合**                | 用 XGBoost 输出的结果作为特征，喂给 LR                        |
+-----------------------------+---------------------------------------------------------------+
| **集成预测**                | 将 XGBoost 和 LR 的输出加权平均作为最终预测                   |
+-----------------------------+---------------------------------------------------------------+
| **AB 测试系统支持两者模型** | 系统支持用不同模型部署做实验对比                              |
+-----------------------------+---------------------------------------------------------------+
| **线上推理系统支持双模型**  | 统一框架中既可调用 XGBoost，也能快速上线/热切换为 LR          |
+-----------------------------+---------------------------------------------------------------+


* 为什么要同时支持 XGBoost 和 LR？

+-------------+--------------------------+------------------------------+
| 模型        | 优点                     | 缺点                         |
+=============+==========================+==============================+
| **XGBoost** | 精度高、适合处理复杂特征 | 模型大，推理速度慢           |
+-------------+--------------------------+------------------------------+
| **LR**      | 简单、高效、易部署       | 表达能力有限，只建模线性关系 |
+-------------+--------------------------+------------------------------+






















