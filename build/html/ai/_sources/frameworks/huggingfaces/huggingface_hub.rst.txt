Hugging Face Hub
################


* Hugging Face Hub æ˜¯ä¸€ä¸ªæ‹¥æœ‰è¶…è¿‡ 120k æ¨¡å‹ã€20k æ•°æ®é›†å’Œ 50k æ¼”ç¤ºåº”ç”¨ç¨‹åº ï¼ˆSpacesï¼‰ çš„å¹³å°


Repositories
============

* Models, Spaces, and Datasets are hosted on the Hugging Face Hub as Git repositories, which means that version control and collaboration are core elements of the Hub.

Cloning repositories å…‹éš†å­˜å‚¨åº“::

	git clone https://huggingface.co/<your-username>/<your-model-name>
	git clone git@hf.co:<your-username>/<your-model-name>


Models
======

å¸¸è§çš„æœºå™¨å­¦ä¹ æ–‡æ¡£å·¥å…·åŒ…æ‹¬::

	- æ¨¡å‹å¡(Model Cards):è‡ªåŠ¨ç”Ÿæˆæè¿°æ¨¡å‹æ€§èƒ½ã€ç”¨é€”ã€å±€é™æ€§ç­‰ä¿¡æ¯çš„æ ‡å‡†æ–‡æ¡£ã€‚
	- æ•°æ®è¡¨(Data Sheets):è‡ªåŠ¨ç”Ÿæˆæ•°æ®é›†çš„å…ƒæ•°æ®ã€ç»„æˆã€æ”¶é›†æ–¹æ³•ç­‰ä¿¡æ¯çš„æ ‡å‡†æ–‡æ¡£ã€‚
	- æŠ¥å‘Šç”Ÿæˆå™¨(Reporting):æ ¹æ®æ¨¡å‹è¯•éªŒç»“æœè‡ªåŠ¨ç”Ÿæˆè¯•éªŒæŠ¥å‘Šã€‚
	- æ–‡æ¡£extractors:ä»ä»£ç æ³¨é‡Šã€å‡½æ•°ç­¾åç­‰è‡ªåŠ¨æå–æ–‡æ¡£ã€‚
	- å¯è§†åŒ–å·¥å…·(Visualization):é€šè¿‡å…³ç³»å›¾ã€æµç¨‹å›¾ç­‰å¯è§†åŒ–å±•ç¤ºç³»ç»Ÿç»“æ„ã€‚
	- ç¬”è®°æœ¬å·¥å…·(Notebooks):åƒJupyterç­‰ç¬”è®°æœ¬å¯ä»¥åµŒå…¥æ–‡æ¡£ã€ä»£ç ã€ç»“æœå±•ç¤ºã€‚

Integrated Libraries
--------------------

HuggingFace Supported Libraries::

	+----------------------------+---------------+---------+-------------------+-------------+
	| Library                    | Inference API | Widgets | Download from Hub | Push to Hub |
	+============================+===============+=========+===================+=============+
	| ğŸ¤— Transformers            | âœ…            | âœ…      | âœ…                | âœ…          |
	+----------------------------+---------------+---------+-------------------+-------------+
	| ğŸ¤— Diffusers               | âŒ            | âŒ      | âœ…                | âœ…          |
	+----------------------------+---------------+---------+-------------------+-------------+
	| Adapter Transformers       | âŒ            | âŒ      | âœ…                | âœ…          |
	+----------------------------+---------------+---------+-------------------+-------------+
	| AllenNLP                   | âœ…            | âœ…      | âœ…                | âŒ          |
	+----------------------------+---------------+---------+-------------------+-------------+
	| Asteroid                   | âœ…            | âœ…      | âœ…                | âŒ          |
	+----------------------------+---------------+---------+-------------------+-------------+
	| BERTopic                   | âœ…            | âœ…      | âœ…                | âœ…          |
	+----------------------------+---------------+---------+-------------------+-------------+
	| docTR                      | âœ…            | âœ…      | âœ…                | âŒ          |
	+----------------------------+---------------+---------+-------------------+-------------+
	| ESPnet                     | âœ…            | âœ…      | âœ…                | âŒ          |
	+----------------------------+---------------+---------+-------------------+-------------+
	| fastai                     | âœ…            | âœ…      | âœ…                | âœ…          |
	+----------------------------+---------------+---------+-------------------+-------------+
	| Keras                      | âŒ            | âŒ      | âœ…                | âœ…          |
	+----------------------------+---------------+---------+-------------------+-------------+
	| Flair                      | âœ…            | âœ…      | âœ…                | âŒ          |
	+----------------------------+---------------+---------+-------------------+-------------+
	| MBRL-Lib                   | âŒ            | âŒ      | âœ…                | âœ…          |
	+----------------------------+---------------+---------+-------------------+-------------+
	| ML-Agents                  | âŒ            | âŒ      | âœ…                | âœ…          |
	+----------------------------+---------------+---------+-------------------+-------------+
	| NeMo                       | âœ…            | âœ…      | âœ…                | âŒ          |
	+----------------------------+---------------+---------+-------------------+-------------+
	| PaddleNLP                  | âœ…            | âœ…      | âœ…                | âœ…          |
	+----------------------------+---------------+---------+-------------------+-------------+
	| Pyannote                   | âŒ            | âŒ      | âœ…                | âŒ          |
	+----------------------------+---------------+---------+-------------------+-------------+
	| PyCTCDecode                | âŒ            | âŒ      | âœ…                | âŒ          |
	+----------------------------+---------------+---------+-------------------+-------------+
	| Pythae                     | âŒ            | âŒ      | âœ…                | âœ…          |
	+----------------------------+---------------+---------+-------------------+-------------+
	| RL-Baselines3-Zoo          | âŒ            | âœ…      | âœ…                | âœ…          |
	+----------------------------+---------------+---------+-------------------+-------------+
	| Sample Factory             | âŒ            | âœ…      | âœ…                | âœ…          |
	+----------------------------+---------------+---------+-------------------+-------------+
	| Sentence Transformers      | âœ…            | âœ…      | âœ…                | âœ…          |
	+----------------------------+---------------+---------+-------------------+-------------+
	| spaCy                      | âœ…            | âœ…      | âœ…                | âœ…          |
	+----------------------------+---------------+---------+-------------------+-------------+
	| SpanMarker                 | âœ…            | âœ…      | âœ…                | âœ…          |
	+----------------------------+---------------+---------+-------------------+-------------+
	| Scikit Learn (using skops) | âœ…            | âœ…      | âœ…                | âœ…          |
	+----------------------------+---------------+---------+-------------------+-------------+
	| Speechbrain                | âœ…            | âœ…      | âœ…                | âŒ          |
	+----------------------------+---------------+---------+-------------------+-------------+
	| Stable-Baselines3          | âŒ            | âœ…      | âœ…                | âœ…          |
	+----------------------------+---------------+---------+-------------------+-------------+
	| TensorFlowTTS              | âŒ            | âŒ      | âœ…                | âŒ          |
	+----------------------------+---------------+---------+-------------------+-------------+
	| Timm                       | âœ…            | âœ…      | âœ…                | âœ…          |
	+----------------------------+---------------+---------+-------------------+-------------+
	| Transformers.js            | âŒ            | âŒ      | âœ…                | âŒ          |
	+----------------------------+---------------+---------+-------------------+-------------+

HuggingFace Supported Libraries Description `å„libåº“å…·ä½“é“¾æ¥å‚è§ <https://huggingface.co/docs/hub/models-libraries>`_ ::

	Library                  Description
	ğŸ¤— Transformers          State-of-the-art Natural Language Processing for Pytorch, TensorFlow, and JAX
	ğŸ¤— Diffusers             A modular toolbox for inference and training of diffusion models
	Adapter Transformers     Extends ğŸ¤—Transformers with Adapters.
	AllenNLP                 An open-source NLP research library, built on PyTorch.
	Asteroid                 Pytorch-based audio source separation toolkit
	BERTopic                 BERTopic is a topic modeling library for text and images
	docTR                    Models and datasets for OCR-related tasks in PyTorch & TensorFlow  
	ESPnet                   End-to-end speech processing toolkit (e.g. TTS)
	fastai                   Library to train fast and accurate models with state-of-the-art outputs.
	Keras                    Library that uses a consistent and simple API to build models leveraging TensorFlow and its ecosystem.
	Flair                    Very simple framework for state-of-the-art NLP.
	MBRL-Lib                 PyTorch implementations of MBRL Algorithms.
	ML-Agents                Enables games and simulations made with Unity to serve as environments for training intelligent agents.
	NeMo                     Conversational AI toolkit built for researchers
	PaddleNLP                Easy-to-use and powerful NLP library built on PaddlePaddle
	Pyannote                 Neural building blocks for speaker diarization.
	PyCTCDecode              Language model supported CTC decoding for speech recognition
	Pythae                   Unifyed framework for Generative Autoencoders in Python
	RL-Baselines3-Zoo        Training framework for Reinforcement Learning, using Stable Baselines3.
	Sample Factory           Codebase for high throughput asynchronous reinforcement learning.
	Sentence Transformers    Compute dense vector representations for sentences, paragraphs, and images.
	spaCy                    Advanced Natural Language Processing in Python and Cython.
	SpanMarker               Familiar, simple and state-of-the-art Named Entity Recognition.
	ScikitLearn(using skops) Machine Learning in Python.
	Speechbrain              A PyTorch Powered Speech Toolkit.
	Stable-Baselines3        Set of reliable implementations of deep reinforcement learning algorithms in PyTorch
	TensorFlowTTS            Real-time state-of-the-art speech synthesis architectures.
	Timm                     Collection of image models, scripts, pretrained weights, etc.
	Transformers.js          State-of-the-art Machine Learning for the web. Run ğŸ¤— Transformers directly in your browser, with no need for a server!


Transformers
^^^^^^^^^^^^

* transformers is a library with state-of-the-art Machine Learning for Pytorch, TensorFlow and JAX. It provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.

You can find models for many different tasks::

	01. Extracting the answer from a context (question-answering).
	02. Creating summaries from a large text (summarization).
	03. Classify text (e.g. as spam or not spam, text-classification).
	04. Generate a new text with models such as GPT (text-generation).
	05. Identify parts of speech (verb, subject, etc.) 
		or entities (country, organization, etc.) in a sentence (token-classification).
	06. Transcribe audio files to text (automatic-speech-recognition).
	07. Classify the speaker or language in an audio file (audio-classification).
	08. Detect objects in an image (object-detection).
	09. Segment an image (image-segmentation).
	10. Do Reinforcement Learning (reinforcement-learning)


Using existing models::

	# With pipeline, just specify the task and the model id from the Hub.
	from transformers import pipeline
	pipe = pipeline("text-generation", model="distilgpt2")

	# If you want more control, you will need to define the tokenizer and model.
	from transformers import AutoTokenizer, AutoModelForCausalLM
	tokenizer = AutoTokenizer.from_pretrained("distilgpt2")
	model = AutoModelForCausalLM.from_pretrained("distilgpt2")


* å…¶ä»–èµ„æº
* Transformers library: https://github.com/huggingface/transformers
* Transformers docs: https://huggingface.co/docs/transformers/index
* Share a model guide: https://huggingface.co/docs/transformers/model_sharing



Adapter Transformers
^^^^^^^^^^^^^^^^^^^^

å®‰è£…::

	pip install -U adapter-transformers

* ``adapter-transformers`` is a library that extends ğŸ¤— transformers by allowing to integrate, train and use Adapters and other efficient fine-tuning methods. The library is fully compatible with ğŸ¤— transformers. Adapters are small learnt layers inserted within each layer of a pre-trained model. You can learn more about this in the `original paper <https://arxiv.org/abs/2007.07779>`_.


* Adapter Hub repository: https://github.com/adapter-hub/hub
* AdapterHub: https://adapterhub.ml/explore/
* official guide: https://docs.adapterhub.ml/index.html
* Adapter Transformers library: https://github.com/adapter-hub/adapter-transformers
* Integration with Hub docs: https://docs.adapterhub.ml/huggingface_hub.html

ç¤ºä¾‹::

	from transformers import AutoModelWithHeads

	model = AutoModelWithHeads.from_pretrained("bert-base-uncased")
	adapter_name = model.load_adapter("AdapterHub/bert-base-uncased-pf-emotion", source="hf")
	model.active_adapters = adapter_name


find all Adapter Models programmatically::

	from transformers import list_adapters
	# source can be "ah" (AdapterHub), "hf" (hf.co) or None (for both, default)
	adapter_infos = list_adapters(source="hf", model_name="bert-base-uncased")


AllenNLP
^^^^^^^^

* allennlp is a NLP library for developing state-of-the-art models on different linguistic tasks. It provides high-level abstractions and APIs for common components and models in modern NLP. It also provides an extensible framework that makes it easy to run and manage NLP experiments.


.. image:: https://img.zhaoweiguo.com/uPic/2023/07/cWfYz0.jpg
   :width: 50%
   :height: 300px


* AllenNLP website: https://allenai.org/allennlp
* AllenNLP repository: https://github.com/allenai/allennlp



ç¤ºä¾‹::

	import allennlp_models
	from allennlp.predictors.predictor import Predictor

	predictor = Predictor.from_path("hf://allenai/bidaf-elmo")
	predictor_input = {
	    "passage": "My name is Wolfgang and I live in Berlin", 
	    "question": "Where do I live?"
	}
	predictions = predictor.predict_json(predictor_input)


Asteroid
^^^^^^^^

* asteroid is a Pytorch toolkit for audio source separation. It enables fast experimentation on common datasets with support for a large range of datasets and recipes to reproduce papers.
* models page: https://huggingface.co/models?filter=asteroid

.. figure:: https://img.zhaoweiguo.com/uPic/2023/07/V6D7ii.jpg
   :width: 400px


* Asteroid website: https://asteroid-team.github.io/
* Asteroid library: https://github.com/asteroid-team/asteroid
* Integration docs: https://github.com/asteroid-team/asteroid/blob/master/docs/source/readmes/pretrained_models.md



ç¤ºä¾‹::

	from asteroid.models import ConvTasNet
	model = ConvTasNet.from_pretrained('mpariente/ConvTasNet_WHAM_sepclean')


ESPnet
^^^^^^

* espnet is an end-to-end toolkit for speech processing, including automatic speech recognition, text to speech, speech enhancement, dirarization and other tasks.

.. figure:: https://img.zhaoweiguo.com/uPic/2023/07/EPEBlv.jpg
   :width: 400px

* ESPnet model zoo repository: https://github.com/espnet/espnet_model_zoo
* ESPnet docs: https://espnet.github.io/espnet/index.html
* Integration docs: https://github.com/asteroid-team/asteroid/blob/master/docs/source/readmes/pretrained_models.md

ç¤ºä¾‹::

	import soundfile
	from espnet2.bin.tts_inference import Text2Speech

	text2speech = Text2Speech.from_pretrained("model_name")
	speech = text2speech("foobar")["wav"]
	soundfile.write("out.wav", speech.numpy(), text2speech.fs, "PCM_16")




fastai
^^^^^^

* fastai is an open-source Deep Learning library that leverages PyTorch and Python to provide high-level components to train fast and accurate neural networks with state-of-the-art outputs on text, vision, and tabular data.
* models page: https://huggingface.co/models?library=fastai&sort=downloads

å®‰è£…::

	pip install huggingface_hub["fastai"]


* fastai course: https://course.fast.ai/
* fastai website: https://www.fast.ai/
* Integration with Hub docs: https://docs.fast.ai/huggingface.html
* Integration with Hub announcement: https://huggingface.co/blog/fastai


ç¤ºä¾‹::

	from huggingface_hub import from_pretrained_fastai

	learner = from_pretrained_fastai("espejelomar/identify-my-cat")

	_,_,probs = learner.predict(img)
	print(f"Probability it's a cat: {100*probs[1].item():.2f}%")

	# Probability it's a cat: 100.00%

Keras
^^^^^

* keras is an open-source machine learning library that uses a consistent and simple API to build models leveraging TensorFlow and its ecosystem.


* Keras Developer Guides: https://keras.io/guides/
* Keras examples: https://keras.io/examples/
* Keras examples on ğŸ¤— Hub: https://huggingface.co/keras-io
* Keras learning resources: https://keras.io/getting_started/learning_resources/#moocs



ç¤ºä¾‹::

	from huggingface_hub import from_pretrained_keras

	model = from_pretrained_keras("keras-io/mobile-vit-xxs")
	prediction = model.predict(image)
	prediction = tf.squeeze(tf.round(prediction))
	print(f'The image is a {classes[(np.argmax(prediction))]}!')

	# The image is a sunflower!


ML-Agents
^^^^^^^^^

* ml-agents is an open-source toolkit that enables games and simulations made with Unity to serve as environments for training intelligent agents.

å®‰è£…::

	# Clone the repository
	git clone https://github.com/Unity-Technologies/ml-agents

	# Go inside the repository and install the package
	cd ml-agents
	pip3 install -e ./ml-agents-envs
	pip3 install -e ./ml-agents

* ML-Agents documentation: https://github.com/Unity-Technologies/ml-agents/blob/develop/docs/Hugging-Face-Integration.md
* Official Unity ML-Agents Spaces demos: https://huggingface.co/unity

ç¤ºä¾‹::

	mlagents-load-from-hf --repo-id="Art-phys/poca-SoccerTwos_500M" --local-dir="./downloads"


PaddleNLP
^^^^^^^^^

* Leveraging the PaddlePaddle framework, PaddleNLP is an easy-to-use and powerful NLP library with awesome pre-trained model zoo, supporting wide-range of NLP tasks from research to industrial applications.

å®‰è£…::

	pip install -U paddlenlp


ç¤ºä¾‹::

	from paddlenlp.transformers import AutoTokenizer, AutoModelForMaskedLM

	tokenizer = AutoTokenizer.from_pretrained("PaddlePaddle/ernie-1.0-base-zh", from_hf_hub=True)
	model = AutoModelForMaskedLM.from_pretrained("PaddlePaddle/ernie-1.0-base-zh", from_hf_hub=True)

	tokenizer.save_to_hf_hub(repo_id="<my_org_name>/<my_repo_name>")
	model.save_to_hf_hub(repo_id="<my_org_name>/<my_repo_name>")

RL-Baselines3-Zoo
^^^^^^^^^^^^^^^^^

* rl-baselines3-zoo is a training framework for Reinforcement Learning using Stable Baselines3.



* RL-Baselines3-Zoo official trained models: https://huggingface.co/sb3
* RL-Baselines3-Zoo documentation: https://github.com/DLR-RM/rl-baselines3-zoo


ç¤ºä¾‹::

	# Download ppo SpaceInvadersNoFrameskip-v4 model and save it into the logs/ folder
	python -m rl_zoo3.load_from_hub --algo dqn --env SpaceInvadersNoFrameskip-v4 -f logs/ -orga sb3
	python enjoy.py --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/

Sample Factory
^^^^^^^^^^^^^^

* sample-factory is a codebase for high throughput asynchronous reinforcement learning. It has integrations with the Hugging Face Hub to share models with evaluation results and training metrics.
* Repository: https://github.com/alex-petrenko/sample-factory

å®‰è£…::

	pip install sample-factory

ç¤ºä¾‹::

	python -m sample_factory.huggingface.load_from_hub -r <HuggingFace_repo_id> -d <train_dir_path>



Sentence Transformers
^^^^^^^^^^^^^^^^^^^^^

* sentence-transformers is a library that provides easy methods to compute embeddings (dense vector representations) for sentences, paragraphs and images. Texts are embedded in a vector space such that similar text is close, which enables applications such as semantic search, clustering, and retrieval.

.. figure:: https://img.zhaoweiguo.com/uPic/2023/07/WkkFtA.jpg
   :width: 400px

* Sentence Transformers library: https://github.com/UKPLab/sentence-transformers
* Sentence Transformers docs: https://www.sbert.net/
* Integration with Hub announcement: https://huggingface.co/blog/sentence-transformers-in-the-hub

ç¤ºä¾‹::

	from sentence_transformers import SentenceTransformer, util
	model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')

	query_embedding = model.encode('How big is London')
	passage_embedding = model.encode(['London has 9,787,426 inhabitants at the 2011 census',
	                                  'London is known for its finacial district'])

	print("Similarity:", util.dot_score(query_embedding, passage_embedding))

spaCy
^^^^^

* spaCy is a popular library for advanced Natural Language Processing used widely across industry. spaCy makes it easy to use and train pipelines for tasks like named entity recognition, text classification, part of speech tagging and more, and lets you build powerful applications to process and analyze large volumes of text.

å®‰è£…::

	pip install spacy-huggingface-hub

ç¤ºä¾‹::

	# Using spacy.load().
	import spacy
	nlp = spacy.load("en_core_web_sm")

	# Importing as module.
	import en_core_web_sm
	nlp = en_core_web_sm.load()


SpanMarker
^^^^^^^^^^

* SpanMarker is a framework for training powerful Named Entity Recognition models using familiar encoders such as BERT, RoBERTa and DeBERTa. Tightly implemented on top of the ğŸ¤— Transformers library, SpanMarker can take good advantage of it. As a result, SpanMarker will be intuitive to use for anyone familiar with Transformers.

å®‰è£…::

	pip install -U span_marker

* SpanMarker repository: https://github.com/tomaarsen/SpanMarkerNER
* SpanMarker docs: https://tomaarsen.github.io/SpanMarkerNER


ç¤ºä¾‹::

	from span_marker import SpanMarkerModel

	model = SpanMarkerModel.from_pretrained("tomaarsen/span-marker-bert-base-fewnerd-fine-super")


SpeechBrain
^^^^^^^^^^^

* speechbrain is an open-source and all-in-one conversational toolkit for audio/speech. The goal is to create a single, flexible, and user-friendly toolkit that can be used to easily develop state-of-the-art speech technologies, including systems for speech recognition, speaker recognition, speech enhancement, speech separation, language identification, multi-microphone signal processing, and many others.

ç¤ºä¾‹::

	import torchaudio
	from speechbrain.pretrained import EncoderClassifier

	classifier = EncoderClassifier.from_hparams(
	    source="speechbrain/urbansound8k_ecapa"
	)
	out_prob, score, index, text_lab = classifier.classify_file('speechbrain/urbansound8k_ecapa/dog_bark.wav')


* SpeechBrain website: https://speechbrain.github.io/
* SpeechBrain docs: https://speechbrain.readthedocs.io/en/latest/index.html




Stable-Baselines3
^^^^^^^^^^^^^^^^^

* stable-baselines3 is a set of reliable implementations of reinforcement learning algorithms in PyTorch.

å®‰è£…::

	pip install stable-baselines3
	pip install huggingface-sb3


* Hugging Face Stable-Baselines3 documentation: https://github.com/huggingface/huggingface_sb3#hugging-face--x-stable-baselines3-v20
* Stable-Baselines3 documentation: https://stable-baselines3.readthedocs.io/en/master/




Stanza
^^^^^^

* stanza is a collection of accurate and efficient tools for the linguistic analysis of many human languages. Starting from raw text to syntactic analysis and entity recognition, Stanza brings state-of-the-art NLP models to languages of your choosing.


* stanza docs: https://stanfordnlp.github.io/stanza/

ç¤ºä¾‹::

	import stanza

	nlp = stanza.Pipeline('en') # download th English model and initialize an English neural pipeline
	doc = nlp("Barack Obama was born in Hawaii.") # run annotation over a sentence


TensorBoard
^^^^^^^^^^^

* TensorBoard provides tooling for tracking and visualizing metrics as well as visualizing models. All repositories that contain TensorBoard traces have an automatic tab with a hosted TensorBoard instance for anyone to check it out without any additional effort!


* TensorBoard documentation: https://www.tensorflow.org/tensorboard

timm
^^^^

* timm, also known as pytorch-image-models, is an open-source collection of state-of-the-art PyTorch image models, pretrained weights, and utility scripts for training, inference, and validation.

.. figure:: https://img.zhaoweiguo.com/uPic/2023/07/neP2Ex.jpg
   :width: 400px

ç¤ºä¾‹::

	import timm

	# Loading https://huggingface.co/timm/eca_nfnet_l0
	model = timm.create_model("hf-hub:timm/eca_nfnet_l0", pretrained=True)


* timm (pytorch-image-models) GitHub Repo: https://github.com/rwightman/pytorch-image-models
* timm documentation: https://huggingface.co/docs/timm

Transformers.js
^^^^^^^^^^^^^^^

* Transformers.js is a JavaScript library for running ğŸ¤— Transformers directly in your browser, with no need for a server! It is designed to be functionally equivalent to the original Python library, meaning you can run the same pretrained models using a very similar API.

å®‰è£…::

	npm i @xenova/transformers

* Transformers.js repository: https://github.com/xenova/transformers.js
* Transformers.js docs: https://huggingface.co/docs/transformers.js
* Transformers.js demo: https://xenova.github.io/transformers.js/

ç¤ºä¾‹::

	// Use a different model for sentiment-analysis
	let pipe = await pipeline('sentiment-analysis', 'nlptown/bert-base-multilingual-uncased-sentiment');



Widgets éƒ¨ä»¶
------------

Widgets examples
^^^^^^^^^^^^^^^^

* `Named Entity Recognition <https://huggingface.co/spacy/en_core_web_sm?text=My+name+is+Sarah+and+I+live+in+London>`_ using `spaCy <https://spacy.io/>`_.
* `Image Classification <https://huggingface.co/google/vit-base-patch16-224>`_ using `ğŸ¤—Transformers <https://github.com/huggingface/transformers>`_
* `Text to Speech <https://huggingface.co/julien-c/ljspeech_tts_train_tacotron2_raw_phn_tacotron_g2p_en_no_space_train>`_ using `ESPnet <https://github.com/espnet/espnet>`_.
* `Sentence Similarity <https://huggingface.co/osanseviero/full-sentence-distillroberta3>`_ using `Sentence Transformers <https://github.com/UKPLab/sentence-transformers>`_.

* è¯¦ç»†å†…å®¹: https://huggingface.co/docs/hub/models-widgets#whats-a-widget

some links to examples
^^^^^^^^^^^^^^^^^^^^^^

* text-classification, for instance `roberta-large-mnli <https://huggingface.co/roberta-large-mnli>`_
* token-classification, for instance `dbmdz/bert-large-cased-finetuned-conll03-english <https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english>`_
* question-answering, for instance `distilbert-base-uncased-distilled-squad <https://huggingface.co/distilbert-base-uncased-distilled-squad>`_
* translation, for instance `t5-base <https://huggingface.co/t5-base>`_
* summarization, for instance `facebook/bart-large-cnn <https://huggingface.co/facebook/bart-large-cnn>`_
* conversational, for instance `facebook/blenderbot-400M-distill <https://huggingface.co/facebook/blenderbot-400M-distill>`_
* text-generation, for instance `gpt2 <https://huggingface.co/gpt2>`_
* fill-mask, for instance `distilroberta-base <https://huggingface.co/distilroberta-base>`_
* zero-shot-classification (implemented on top of a nli text-classification model), for instance `facebook/bart-large-mnli <https://huggingface.co/facebook/bart-large-mnli>`_
* table-question-answering, for instance `google/tapas-base-finetuned-wtq <https://huggingface.co/google/tapas-base-finetuned-wtq>`_
* sentence-similarity, for instance `osanseviero/full-sentence-distillroberta2 <https://huggingface.co/osanseviero/full-sentence-distillroberta2>`_

* è¯¦ç»†å†…å®¹: https://huggingface.co/docs/hub/models-widgets#what-are-all-the-possible-taskwidget-types



Datasets
========

* ğŸ¤— Datasets documentation: https://huggingface.co/docs/datasets/index
* dataset card: https://huggingface.co/docs/hub/datasets-cards
* main datasets page: https://huggingface.co/datasets

.. note:: æ‰“å¼€æŒ‡å®šæ•°æ®é›†æ—¶ï¼Œå¯ä»¥ç‚¹å‡»æŒ‰é’®``Use in dataset library``æŸ¥çœ‹ä½¿ç”¨æ–¹æ³•

Using Datasets
--------------


* Some datasets on the Hub contain a loading script, which allows you to easily load the dataset when you need it.
* Many datasets however do not need to include a loading script, for instance when their data is stored directly in the repository in formats such as CSV, JSON and Parquet. ğŸ¤— Datasets can load those kinds of datasets automatically without a loading script.
* tutorials: https://huggingface.co/docs/datasets/tutorial
* how-to guides: https://huggingface.co/docs/datasets/how_to
* æ›´å¤šè¯¦æƒ…å‚è§: Datasets documentation

Adding new datasets
-------------------

* ä¸‰ç§æ–¹æ³•:
* Add files manually to the repository through the UI
* Push files with the ``push_to_hub`` method from ğŸ¤— Datasets
* Use Git to commit and push your dataset files




Spaces
======

* Hugging Face Spaces: https://huggingface.co/spaces





















