æœºå™¨å­¦ä¹ machine learning
########################

Kinds of Machine Learning
=========================

Supervised learning
-------------------

Regression::

    â€œHow many hours will this surgery take?â€: regression
    â€œHow many dogs are in this photo?â€: regression.

    L1 loss where
    ğ‘™(ğ‘¦,ğ‘¦â€²)=âˆ‘ğ‘–|ğ‘¦ğ‘–âˆ’ğ‘¦â€²ğ‘–|
 
    L2 loss, where
    ğ‘™(ğ‘¦,ğ‘¦â€²)=âˆ‘ğ‘–(ğ‘¦ğ‘–âˆ’ğ‘¦â€²ğ‘–)2

Classification::

    optical character recognition (OCR)
    It is treated with a different set of algorithms than those used for regression.
    In classification, we want our model to look at a feature vector
      (e.g., the pixel values in an image)
      and then predict which category (formally called classes), 
      among some (discrete) set of options, an example belongs.
    The simplest form of classification is when there are only two classes, 
      a problem which we call binary classification. 


Tagging::

    The problem of learning to predict classes that are not mutually exclusive 
      is called multi-label classification.
    ä¸€ä¸ªå›¾ç‰‡ä¸­å³æœ‰ç‹—ä¹Ÿæœ‰çŒ«æ—¶ï¼Œä¸èƒ½ä½¿ç”¨ä¸Šé¢Classificationä¸­çš„æ–¹æ³•æ¥åˆ¤æ–­æ˜¯å¦æœ‰ç‹—æˆ–çŒ«
    A typical article might have 5-10 tags applied because these concepts are correlated.
    ä¸€ä¸ªæŠ€æœ¯blogä¸­å¯èƒ½æœ‰å¤šä¸ªtag, ç›¸äº’é—´æ˜¯æœ‰å…³è”å…³ç³»ã€‚

Search and ranking::

    Googleæœç´¢, ä¸€ä¸ªå…³é”®è¯å¯¹åº”çš„æœç´¢ç»“æœ

Recommender systems::

    æ¨èç³»ç»Ÿ, æ ¹æ®ä½ çš„å–œå¥½ç»™ä½ æ¨èå†…å®¹: å¤´æ¡æ¨èä½ å–œæ¬¢çš„å†…å®¹

Sequence Learning::

    1. Automatic Speech Recognition
    2. Text to Speech.
    3. Machine Translation.

Unsupervised learning
---------------------

::

    1. clustering
    2. subspace estimation problems. 
       principal component analysis(If the dependence is linear)
    3. representation learning(e.g. Rome  âˆ’  Italy  +  France  =  Paris.)
    4. causality and probabilistic graphical models
    5. advent of generative adversarial networks




Interacting with an Environment
-------------------------------

offline learning::

    å‰è®²çš„éƒ½æ˜¯ç¦»çº¿å­¦ä¹ . å³:
    éœ€è¦é¢„å…ˆè·å–å¤§é‡æ•°æ®ï¼Œç„¶åä½¿æ¨¡å¼è¯†åˆ«æœºå™¨å¤„äºè¿è¡ŒçŠ¶æ€ï¼Œä¹‹åæ— éœ€å†æ¬¡ä¸ç¯å¢ƒäº¤äº’ã€‚

    Asimovâ€™s Robot Series
    That means we need to think about choosing actions, not just making predictions. 
    Moreover, unlike predictions, actions actually impact the environment.
    çœŸæ­£çš„æœºå™¨äººåšçš„æ“ä½œä¼šå¯¹ç¯å¢ƒæœ‰å½±å“(ä¸ä»…é¢„æµ‹æ¯”)

Reinforcement learning
----------------------

2ä¸ªå®ä¾‹::

    deep Q-network that beat humans at Atari games using only the visual input
    the AlphaGo program that dethroned the world champion at the board game Go

* The goal of reinforcement learning is to produce a good policy.
* we can cast any supervised learning problem as an RL problem.

MDPs, bandits, and friends
--------------------------

* When the environment is fully observed, we call the RL problem a 
      ã€ŒMarkov Decision Process (MDP)ã€. 
* When the state does not depend on the previous actions, we call the problem a
      ã€Œcontextual bandit problemã€
* When there is no state, just a set of available actions with initially unknown rewards, 
      this problem is the classic ã€Œmulti-armed bandit problemã€.


å®ä¾‹
====

::

    è‡ªåŠ¨é©¾é©¶: autopilot
    NLP: 
    å›¾åƒè¯†åˆ«ã€è¯­éŸ³è¯†åˆ«: visual/speech recognition
    é«˜é¢‘äº¤æ˜“: high frequency trading
    CV: 





