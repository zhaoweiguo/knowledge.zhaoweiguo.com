常见模型
########








视觉语言大模型
==============

* Paligemma
* https://huggingface.co/google/paligemma2-10b-mix-448





* https://huggingface.co/microsoft/Florence-2-base
* Florence-2模型是一种高效的视觉基础模型，可以用于多种视觉任务。该模型的性能评估结果表明，它在多种视觉任务中都取得了良好的结果。
* 代码参考
    * https://github.com/microsoft/OmniParser/blob/master/util/utils.py
        * https://www.aivi.fyi/llms/deploy-omniparser2.0



* 阶跃星辰
* Step-Video-T2V
* https://github.com/stepfun-ai/Step-Video-T2V
* 一个最新的文本生成视频的预训练模型，拥有30亿个参数，能够生成最长204帧的视频。它通过视频VAE（变分自编码器）和3D全注意力的DiT模型进行训练，同时结合直接偏好优化（DPO）来提升视频的视觉质量。通过这种技术，模型可以更高效地生成更真实、流畅的视频效果。





语音大模型
==========


* 阶跃星辰
* Step-Audio
* https://github.com/stepfun-ai/Step-Audio
* 是一个开源的智能语音交互框架，集成了语音理解和生成能力，支持多语言对话（如中文、英文、日语），并能处理情感语调（如快乐、悲伤）和地方方言（如粤语、四川话）。
* 其主要特点和技术创新包括：
    * 130B 参数多模态模型：一个统一的模型，集成语音识别、语义理解、对话、语音克隆和语音合成能力，并且有 Step-Audio-Chat 变体开放源代码。
    * 生成数据引擎：通过该模型生成高质量音频，避免传统语音合成依赖手动数据采集，且有 Step-Audio-TTS-3B 模型具备更强的指令跟随能力。
    * 语音控制精准调节：通过指令调节支持情感（如愤怒、快乐、悲伤）、方言（如粤语、四川话）和音色风格（如说唱）等。
    * 增强的智能：通过集成 ToolCall 机制和角色扮演增强模型在复杂任务中的表现。

































