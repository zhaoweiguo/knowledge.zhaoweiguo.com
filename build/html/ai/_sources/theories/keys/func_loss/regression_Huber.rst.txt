æŸå¤±å‡½æ•°-å›å½’-Huber æŸå¤±
########################


* å¹³æ»‘å¹³å‡ç»å¯¹è¯¯å·®
* å…¬å¼:

.. math::

    \begin{array}{l}
    L_{\delta}(\alpha) = \left\{\begin{matrix}
      \frac{1}{2}\alpha^2ï¼Œ &  for |\alpha| \le \delta ,\\
      \delta \cdot (|\alpha| - \frac{1}{2}\delta ) & for |\alpha| > \delta 
    \end{matrix}\right. \\
    \end{array}

å‚æ•° a é€šå¸¸è¡¨ç¤º residualsï¼Œå†™ä½œ yâˆ’f(x)ï¼Œå½“ a = yâˆ’f(x) æ—¶ï¼ŒHuber loss å®šä¹‰ä¸º

.. math::

    \begin{array}{l}
    L_{\delta}(y, f(x)) = \left\{\begin{matrix}
      \frac{1}{2}(y-f(x))^2ï¼Œ &  for |y-f(x)| \le \delta ,\\
      \delta \cdot (|y-f(x)| - \frac{1}{2}\delta ) & for |y-f(x)| > \delta 
    \end{matrix}\right. \\
    \end{array}

è¯´æ˜::

   Î´ æ˜¯ HuberLoss çš„å‚æ•°ï¼Œ\\
   yæ˜¯çœŸå®å€¼ï¼Œ \\
   f(x)æ˜¯æ¨¡å‹çš„é¢„æµ‹å€¼


.. note:: è¿™å„¿ç”¨ ``f(x)`` è€Œä¸ç”¨ :math:`\hat{y}` ä¸»è¦æ˜¯ä¸ºäº†è¡¨æ˜è¿™æ˜¯ä»æ¨¡å‹çš„å‡½æ•°å½¢å¼å‡ºå‘æ¨å¯¼çš„ã€‚ ``f(x)`` ï¼šè¡¨ç¤ºæ¨¡å‹çš„å‡½æ•°è¡¨è¾¾å¼ï¼Œæ˜¯ä»è¾“å…¥ç‰¹å¾ ğ‘¥ åˆ°è¾“å‡ºé¢„æµ‹å€¼çš„æ˜ å°„ã€‚ :math:`\hat{y}` è¡¨ç¤ºå…·ä½“çš„é¢„æµ‹å€¼ï¼Œæ˜¯æ¨¡å‹ ğ‘“(ğ‘¥) åœ¨ç»™å®šè¾“å…¥ ğ‘¥ åçš„è¾“å‡ºã€‚



* å½“é¢„æµ‹åå·®å°äº Î´ æ—¶ï¼Œå®ƒé‡‡ç”¨å¹³æ–¹è¯¯å·®,
* å½“é¢„æµ‹åå·®å¤§äº Î´ æ—¶ï¼Œé‡‡ç”¨çš„çº¿æ€§è¯¯å·®ã€‚



* ä¼˜ç‚¹ï¼šç»“åˆäº† MSE å’Œ MAE çš„ä¼˜ç‚¹ï¼Œå¯¹å¼‚å¸¸å€¼æ›´é²æ£’ã€‚
* åº”ç”¨åœºæ™¯ï¼šé€‚ç”¨äºæ•°æ®ä¸­å­˜åœ¨å°‘é‡å¼‚å¸¸å€¼çš„å›å½’ä»»åŠ¡ã€‚




.. figure:: https://img.zhaoweiguo.com/uPic/2024/11/52YcJP.png

    Huber Loss åœ¨ ``|yâˆ’f(x)| > Î´`` æ—¶ï¼Œæ¢¯åº¦ä¸€ç›´è¿‘ä¼¼ä¸º Î´ï¼Œèƒ½å¤Ÿä¿è¯æ¨¡å‹ä»¥ä¸€ä¸ªè¾ƒå¿«çš„é€Ÿåº¦æ›´æ–°å‚æ•°ã€‚å½“ ``|yâˆ’f(x)| â‰¤ Î´`` æ—¶ï¼Œæ¢¯åº¦é€æ¸å‡å°ï¼Œèƒ½å¤Ÿä¿è¯æ¨¡å‹æ›´ç²¾ç¡®åœ°å¾—åˆ°å…¨å±€æœ€ä¼˜å€¼ã€‚å› æ­¤ï¼ŒHuber Loss åŒæ—¶å…·å¤‡äº†å‰ä¸¤ç§æŸå¤±å‡½æ•°çš„ä¼˜ç‚¹ã€‚


.. figure:: https://img.zhaoweiguo.com/uPic/2024/11/huber-loss.gif


.. code-block:: python

    x = np.linspace(1, 20, 40)
    X = np.vstack((np.ones_like(x),x))    # å¼•å…¥å¸¸æ•°é¡¹ 1
    m = X.shape[1]
    # å‚æ•°åˆå§‹åŒ–
    W = np.zeros((1,2))
     
    # è¿­ä»£è®­ç»ƒ 
    num_iter = 20
    lr = 0.01
    delta = 2
    J = []
    for i in range(num_iter):
       y_pred = W.dot(X)
       loss = 1/m * np.sum(np.abs(y-y_pred))
       J.append(loss)
       mask = (y-y_pred).copy()
       mask[y-y_pred > delta] = delta
       mask[mask < -delta] = -delta
       W = W + lr * 1/m * mask.dot(X.T)
     
    # ä½œå›¾
    y1 = W[0,0] + W[0,1]*1
    y2 = W[0,0] + W[0,1]*20
    plt.scatter(x, y)
    plt.plot([1,20],[y1,y2],'r--')
    plt.xlabel('x')
    plt.ylabel('y')
    plt.title('Huber')
    plt.show()







.. figure:: https://img.zhaoweiguo.com/uPic/2024/11/RsmbZb.png

    MSEã€MAEã€Huber Loss: MSE çš„ Loss ä¸‹é™å¾—æœ€å¿«ï¼ŒMAE çš„ Loss ä¸‹é™å¾—æœ€æ…¢ï¼ŒHuber Loss ä¸‹é™é€Ÿåº¦ä»‹äº MSE å’Œ MAE ä¹‹é—´ã€‚

































