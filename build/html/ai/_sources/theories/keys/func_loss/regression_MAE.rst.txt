损失函数-回归-平均绝对误差(MAE)
###############################


* Mean Absolute Error
* 公式:

.. math:: 

    \begin{array}{l}
    L = \frac{1}{N} \sum_{i=1}^N{|y_i - \hat{y}_i|}
    \\
    说明: \\
    \hat(y): 模型预测值，通常称为预测输出
    \end{array}


* 优点：对异常值更鲁棒。
* 缺点：在优化时梯度不连续，可能导致收敛速度较慢。



.. figure:: https://img.zhaoweiguo.com/uPic/2024/11/Fu7wdQ.png

    MAE 的曲线呈 V 字型，连续但在 y-f(x)=0 处不可导，计算机求解导数比较困难。而且 MAE 大部分情况下梯度都是相等的，这意味着即使对于小的损失值，其梯度也是大的。这不利于函数的收敛和模型的学习。


* 值得一提的是，MAE 相比 MSE 有个优点就是 MAE 对离群点不那么敏感，更有包容性。因为 MAE 计算的是误差 y-f(x) 的绝对值，无论是 y-f(x)>1 还是 y-f(x)<1，没有平方项的作用，惩罚力度都是一样的，所占权重一样。


.. code-block:: python

    X = np.vstack((np.ones_like(x),x))    # 引入常数项 1
    m = X.shape[1]
    # 参数初始化
    W = np.zeros((1,2))
     
    # 迭代训练 
    num_iter = 20
    lr = 0.01
    J = []
    for i in range(num_iter):
       y_pred = W.dot(X)
       loss = 1/m * np.sum(np.abs(y-y_pred))
       J.append(loss)
       mask = (y-y_pred).copy()
       mask[y-y_pred > 0] = 1
       mask[mask <= 0] = -1
       W = W + lr * 1/m * mask.dot(X.T)
     
    # 作图
    y1 = W[0,0] + W[0,1]*1
    y2 = W[0,0] + W[0,1]*20
    plt.scatter(x, y)
    plt.plot([1,20],[y1,y2],'r--')
    plt.xlabel('x')
    plt.ylabel('y')
    plt.title('MAE')
    plt.show()





















