激活函数-Leaky ReLU
###################

* 特点：与 ReLU 类似，但在负数部分引入了一个小的斜率（通常为 0.01），有助于解决 ReLU 的神经元死亡问题。
* 公式：

.. math::

    \text{LeakyReLU}(x) = 
        \begin{cases} 
            x, & \text{if } x > 0 \\ 
            \alpha x, & \text{otherwise} 
        \end{cases}

















