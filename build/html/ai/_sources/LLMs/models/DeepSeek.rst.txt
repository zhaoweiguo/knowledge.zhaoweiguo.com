DeepSeek-R1-æ¨ç†æ¨¡å‹
####################



çƒ­ç‚¹è¯
======

* Test/Inference-Time scaling lawï¼Œé€šè¿‡å¢åŠ æ¨ç†é˜¶æ®µçš„ç®—åŠ›æå‡æ¨¡å‹çš„æ¨ç†èƒ½åŠ›
* Post Trainingï¼Œé€šè¿‡åè®­ç»ƒæå‡æ¨¡å‹çš„æ¨ç†èƒ½åŠ›
* PRM/ORMï¼šåŸºäºè¿‡ç¨‹/ç»“æœçš„å¥–åŠ±æ¨¡å‹
* CoTï¼šæ€ç»´é“¾
* å¼ºåŒ–å­¦ä¹ ã€self-playï¼ˆè‡ªæˆ‘åšå¼ˆï¼‰ä¸MCTSï¼ˆä½¿ç”¨è’™ç‰¹å¡æ´›æœç´¢æ ‘å¯»æ‰¾æœ€ä½³ç­”æ¡ˆï¼‰


å…¶ä»–å…³é”®è¯
----------

* pretrain-time scaling law



post-training
=============

* "Post-training"è¿™ä¸ªæœ¯è¯­é€šå¸¸å‡ºç°åœ¨æœºå™¨å­¦ä¹ å’Œäººå·¥æ™ºèƒ½é¢†åŸŸï¼Œç‰¹åˆ«æ˜¯åœ¨æ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ä¸­ã€‚å®ƒæŒ‡çš„æ˜¯åœ¨åˆå§‹è®­ç»ƒå®Œæˆä¹‹åè¿›è¡Œçš„ä¸€ç³»åˆ—æ“ä½œæˆ–æ­¥éª¤ï¼Œç›®çš„æ˜¯ä¸ºäº†è¿›ä¸€æ­¥æ”¹è¿›æ¨¡å‹çš„æ€§èƒ½ã€é€‚åº”æ–°çš„æ•°æ®æˆ–è€…ä»»åŠ¡ï¼Œè€Œä¸éœ€è¦ä»å¤´å¼€å§‹å®Œæ•´çš„è®­ç»ƒè¿‡ç¨‹ã€‚
* è¿™äº›æ“ä½œå¯èƒ½åŒ…æ‹¬ä½†ä¸é™äºï¼š
    * å¾®è°ƒï¼ˆFine-tuningï¼‰ï¼šä½¿ç”¨æ–°çš„æ•°æ®é›†å¯¹å·²è®­ç»ƒæ¨¡å‹è¿›è¡Œé¢å¤–çš„è®­ç»ƒï¼Œä»¥ä¾¿è®©æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”ç‰¹å®šçš„ä»»åŠ¡æˆ–æ•°æ®åˆ†å¸ƒã€‚è¿™é€šå¸¸æ¶‰åŠåˆ°è¾ƒä½çš„å­¦ä¹ ç‡ï¼Œä»¥é¿å…å¤§å¹…åº¦æ”¹å˜å·²ç»è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡ã€‚
    * é‡åŒ–ï¼ˆQuantizationï¼‰ï¼šå°†æ¨¡å‹ä¸­çš„å‚æ•°ä»æµ®ç‚¹æ•°è½¬æ¢ä¸ºä½ç²¾åº¦çš„æ•´æ•°è¡¨ç¤ºå½¢å¼ï¼Œä»¥æ­¤æ¥å‡å°‘æ¨¡å‹çš„å¤§å°å¹¶åŠ é€Ÿæ¨ç†è¿‡ç¨‹ï¼ŒåŒæ—¶å°½é‡ä¿æŒæ¨¡å‹çš„å‡†ç¡®åº¦ã€‚
    * å‰ªæï¼ˆPruningï¼‰ï¼šå»é™¤æ¨¡å‹ä¸­ä¸é‡è¦çš„æƒé‡æˆ–ç¥ç»å…ƒï¼Œä»¥å‡å°‘è®¡ç®—å¤æ‚åº¦å’Œæ¨¡å‹å¤§å°ï¼Œä½¿æ¨¡å‹æ›´é«˜æ•ˆã€‚
    * çŸ¥è¯†è’¸é¦ï¼ˆKnowledge Distillationï¼‰ï¼šé€šè¿‡è®­ç»ƒä¸€ä¸ªè¾ƒå°çš„â€œå­¦ç”Ÿâ€ç½‘ç»œæ¥æ¨¡ä»¿ä¸€ä¸ªè¾ƒå¤§çš„â€œæ•™å¸ˆâ€ç½‘ç»œçš„è¡Œä¸ºï¼Œä»è€Œè·å¾—æ›´å°ã€æ›´å¿«ä½†ä¾ç„¶ä¿æŒè¾ƒé«˜å‡†ç¡®æ€§çš„æ¨¡å‹ã€‚
    * åŸŸé€‚åº”ï¼ˆDomain Adaptationï¼‰ï¼šè°ƒæ•´æ¨¡å‹ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨ä¸€ä¸ªä¸è®­ç»ƒæ—¶ä¸åŒçš„ä½†ç›¸å…³çš„é¢†åŸŸå†…å·¥ä½œå¾—æ›´å¥½ã€‚



Test/Inference-time Scaling Law
===============================

* æœ‰ä¸€ä¸ªåŸºç¡€æ¨¡å‹ï¼ˆæˆ‘ä»¬ç§°å…¶ä¸ºgeneratorï¼‰ï¼Œä½†æ˜¯è¿™ä¸ªæ¨¡å‹çš„é€»è¾‘æ¨ç†èƒ½åŠ›ï¼ˆæ¯”å¦‚è§£æ•°å­¦é¢˜çš„èƒ½åŠ›ï¼‰è¾ƒå·®æ—¶ï¼Œæˆ‘ä»¬è¯¥æ€ä¹ˆæ”¹è¿›å®ƒï¼Ÿå†è¯´çš„å…·ä½“ç‚¹ï¼Œä¸è€ƒè™‘æ•°æ®é›†ç›¸å…³çš„æˆæœ¬ï¼Œå‡è®¾æˆ‘æ‰‹å¤´çš„gpuç®—åŠ›ï¼ˆFLOPsï¼‰æ˜¯æœ‰é™çš„ï¼Œæˆ‘è¯¥æ€ä¹ˆåˆ©ç”¨å®ƒï¼Œèƒ½è®©æˆ‘çš„æ¨¡å‹æœ€ç»ˆèƒ½æ¨ç†å‡ºæ›´å¥½çš„ç»“æœï¼Ÿ
* ä¸€ä¸ªæ¯”è¾ƒç›´æ¥çš„æƒ³æ³•æ˜¯ï¼šæŠŠç®—åŠ›èŠ±åœ¨å®ƒçš„pretainé˜¶æ®µï¼Œç»™æ¨¡å‹æ³¨å…¥æ›´å¤šæ•°ç†é€»è¾‘çš„é¢„è®­ç»ƒçŸ¥è¯†ã€‚
    * ä¾‹å¦‚ç”¨æ›´å¥½ã€æ›´å¤šçš„ä»£ç æ•°å­¦ç­‰æ•°æ®ï¼Œæˆ–è€…æ‰©å±•æ¨¡å‹çš„å‚æ•°è§„æ¨¡ã€‚è¿™ä¸ªåšæ³•å¯å‘è‡ªå¤§å®¶éƒ½å¾ˆç†Ÿæ‚‰çš„scaling lawï¼ˆæ›´å…·ä½“åœ°è¯´æ˜¯pretrain-time scaling lawï¼‰ã€‚
    * æ›¾ç»ï¼Œä¸ºäº†æå‡æ¨¡å‹çš„é€»è¾‘æ¨ç†èƒ½åŠ›ï¼Œæˆ‘ä»¬æŠŠç®—åŠ›éƒ½èŠ±åœ¨pretrainé˜¶æ®µï¼Œç”±æ­¤è¯ç”Ÿäº†pretrain scaling law
    * ç°åœ¨ï¼Œå·²ç»æœ‰ç°æˆçš„äº§å“è¯æ˜ï¼Œç®—åŠ›å¦‚æœèŠ±åœ¨post trainingå’Œinferenceä¸Šï¼Œæ¨¡å‹çš„æ¨ç†èƒ½åŠ›å°†å¾—åˆ°æ›´å¤§æå‡ï¼Œä¹Ÿå°±æ˜¯å­˜åœ¨ä¸€ä¸ªTest/Inferece scaling law

* openai o1 æŠŠè¿™ä¸ªç®—åŠ›æ›´å¤šåœ°ç”¨åœ¨äº†2ä¸ªåœ°æ–¹ï¼š
    * ç”¨åœ¨äº†rlhfçš„è®­ç»ƒä¸Šï¼ˆpost trainingï¼‰
    * ç”¨åœ¨äº†æ¨¡å‹çš„æ¨ç†é˜¶æ®µä¸Šï¼ˆTest/Infereceï¼‰

* Test/Inferece scaling law
    * pretrain scaling lawå—åˆ°æ¨¡å‹å‚æ•°å’Œè®­ç»ƒæ•°æ®çš„å½±å“ä¸€æ ·
    * Test/Inferece scaling law


* æŠŠç®—åŠ›ç”¨åœ¨inferenceé˜¶æ®µï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨ä¸å˜åŠ¨pretrainé˜¶æ®µçš„æƒ…å†µä¸‹ï¼Œåªé€šè¿‡æ¨ç†ç­‰å±‚é¢çš„ä¼˜åŒ–ï¼Œæ¥æå‡æ¨¡å‹æœ€åçš„ç”Ÿæˆæ•ˆæœã€‚
    * è¿™é‡Œåˆåˆ†æˆä¸¤ç§æƒ…å†µã€‚
        * ä¼˜åŒ–æ¨ç†è¾“å…¥ï¼šprompt(CoT)
            * æŠŠç®—åŠ›èŠ±åœ¨æ¨ç†é˜¶æ®µä¸Šå¯ä»¥æå‡æ¨¡å‹æ•ˆæœ
                * promptç»™çš„è¶Šç»†èŠ‚ï¼Œä½ çš„å¤šè½®å¼•å¯¼ç»™çš„è¶Šå¤šï¼Œæ¨¡å‹æˆ–è®¸å°±èƒ½äº§å‡ºæ›´å¥½çš„ç»“æœã€‚
                * è€Œæ›´å¤šçš„tokenæ„å‘³ç€æ¨ç†é˜¶æ®µéœ€è¦èŠ±è´¹æ›´å¤šçš„ç®—åŠ›ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬æ‰€è¯´çš„ã€æŠŠç®—åŠ›èŠ±åœ¨æ¨ç†é˜¶æ®µä¸Šå¯ä»¥æå‡æ¨¡å‹æ•ˆæœã€‘çš„å…·ä½“å†…å®¹ä¹‹ä¸€
        * ä¼˜åŒ–æ¨ç†è¾“å‡ºï¼šrevise output distribution
            * è®©æ¨¡å‹åƒä¸‹ä¸€ä¸ªé—®é¢˜åï¼Œè‡ªåŠ¨åŒ–åœ°å»åšCoTçš„è¿‡ç¨‹
                * å¦‚ï¼šå¸Œæœ›æ¨¡å‹åœ¨åƒä¸‹ä¸€ä¸ªé—®é¢˜åï¼Œèƒ½è‡ªä¸»äº§ç”Ÿä»¥ä¸‹è¾“å‡ºï¼šattempt1 -> attempt2 -> attempt3 -> ...-> attempti -> answer
                * å…¶ä¸­ï¼Œæ¯ä¸ªattemptåŒ…å«â€œå¤šä¸ªä¸­é—´æ­¥éª¤steps + æœ€ç»ˆç­”æ¡ˆâ€ï¼Œä¹Ÿå°±æ˜¯å®ƒåœ¨æ¨¡æ‹Ÿäººç±»çš„æ€è€ƒè¿‡ç¨‹ï¼šå…ˆåšä¸€æ¬¡attemptï¼Œç„¶åå‘ç°é—®é¢˜ï¼Œåœ¨æ­¤åŸºç¡€ä¸Šåœ¨åšåˆ«çš„attemptï¼Œç›´åˆ°æ‰¾åˆ°æœ€ç»ˆç­”æ¡ˆã€‚
            * æ–¹æ¡ˆ
                * ä¸€ä¸ªç›´è§‚çš„æ–¹æ³•å°±æ˜¯ï¼Œå¦‚æœæˆ‘æœ‰ï¼š problem -> attempt1 -> ... -> attempti -> answer è¿™ç§å¸¦æ ‡ç­¾çš„æ•°æ®
                * è§£æ³•1ï¼šæˆ‘ç›´æ¥åšsftï¼ŒæŠŠæœ€æ­£ç¡®çš„attemptæ”¾åœ¨è¾“å…¥åºåˆ—æœ€åï¼Œå½“ä½œlabelè¿›è¡Œè®­ç»ƒå³å¯
                * è§£æ³•2ï¼šæˆ‘ç”¨ç±»ä¼¼rlhfçš„æ–¹æ³•ï¼Œå…ˆæœ‰ä¸€ä¸ªå¥–åŠ±æ¨¡å‹ï¼Œå®ƒèƒ½å¯¹æ¯ä¸€ä¸ªæ€è€ƒæ­¥éª¤åšè¯„ä¼°ï¼Œç„¶ååˆ©ç”¨è¿™ä¸ªè¯„ä¼°ç»“æœï¼ŒæŒ‡å¼•æ¨¡å‹æ­¥æ­¥æœç´¢ï¼Œæ¯ä¸€æ­¥éƒ½æ‰¾åˆ°æœ€ä½³çš„æ€è€ƒæ­¥éª¤ï¼Œæœ€ç»ˆèƒ½æ‰¾åˆ°ç­”æ¡ˆ
                * ä»…ä»è®­ç»ƒæ–¹æ³•ä¸Šæ¥è¯´ï¼Œéƒ½å¯ä»¥ç®—æˆæ˜¯post-training


* å¦‚ä½•ä¿è¯ä¸­é—´ç»“æœå’Œç­”æ¡ˆä¸€å®šæ˜¯æœ€å¥½
    * ä¸€æ–¹é¢ï¼Œæˆ‘ä»¬å¯ä»¥è€ƒè™‘ä¼˜åŒ–æ¨ç†é˜¶æ®µï¼Œå³ä½¿ç”¨ä¸€ä¸ªèƒ½å¤Ÿè¯„ä¼°ä¸­é—´æ­¥éª¤çš„verifierï¼Œåœ¨æ¨ç†æ—¶æŒ‡å¼•æ¨¡å‹æœç´¢å‡ºæœ€ä½³ç­”æ¡ˆã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯¹ä¸€ä¸ªé—®é¢˜é‡‡æ ·å¤šä¸ªattemptsé“¾ï¼Œä»ä¸­æ‰¾æœ€å¥½çš„ã€‚æˆ–è€…åœ¨å•ä¸ªattemptsä¸­æ‰¾åˆ°æœ€å¥½çš„attempt
    * å¦ä¸€æ–¹é¢ï¼Œæˆ‘ä»¬å¯ä»¥è€ƒè™‘åœ¨post-trainingé˜¶æ®µï¼Œä½¿ç”¨è¿™ä¸ªverifieræ¥æŒ‡å¯¼æ¨¡å‹è‡ªåŠ¨åŒ–ç”Ÿäº§é«˜è´¨é‡çš„æ•°æ®ï¼ˆè¿™æ˜¯ä¸ªinferenceæ­¥éª¤ï¼‰ï¼ŒåŸºäºè¿™äº›æ•°æ®æˆ‘ä»¬å†åšå¯¹é½ã€‚å¦‚æœè¿™ä¸ªæµç¨‹åšå¾—å¥½ï¼Œæˆ‘ä»¬ç”šè‡³å¯ä»¥ç›´æ¥ä¿¡ä»»post-trainingåæ¨¡å‹çš„ç»“æœ
    * æ‰€ä»¥ï¼Œã€ä¼˜åŒ–æ¨ç†è¾“å‡ºã€‘è¿™ä¸€éƒ¨åˆ†ï¼Œä½ å¯ä»¥æŠŠç®—åŠ›å…¨éƒ¨èŠ±åœ¨post-trainingä¸Šï¼Œä¹Ÿå¯ä»¥èŠ±åœ¨post-training+inferenceä¸Šï¼Œä»o1çš„æŠ€æœ¯æŠ¥å‘Šä¸Šçœ‹ï¼Œå®ƒåº”è¯¥é€‰æ‹©äº†åè€…ï¼ŒåŒæ—¶post-trainingé€‰æ‹©äº†æŸç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•


* å…·ä½“å‚è§ç›¸å…³è®ºæ–‡
    * Let's Verify Step by Step ï¼ˆopenaiï¼‰
    * Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters(deepmind)


OpenAI
======

.. figure:: https://img.zhaoweiguo.com/uPic/2025/02/mDrZoo.png

    a multi-step conversation between a user and an assistant. Input and output tokens from each step are carried over, while reasoning tokens are discarded.



* from: https://platform.openai.com/docs/guides/reasoning





å‚è€ƒ
====

* https://mp.weixin.qq.com/s/pSR8RyvvQPUEuHBtUFh8Og
* æ”¶é›†äº†å†…å¤–ç½‘å¯èƒ½å’Œo1èƒŒåçš„ç®—æ³•æœ‰å…³çš„å„ç§èµ„æ–™ï¼ŒåŒ…æ‹¬ç›¸å…³è®ºæ–‡ã€ä»£ç å’Œtwitter postç­‰ç­‰: https://github.com/hijkzzz/Awesome-LLM-Strawberry
* Let's Verify Step by Step ï¼ˆopenaiï¼‰: https://arxiv.org/abs/2305.20050
* Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters (google deepmind): https://arxiv.org/abs/2408.03314
* A collection of LLM papers, blogs, and projects, with a focus on OpenAI o1 ğŸ“ and reasoning techniques: https://github.com/hijkzzz/Awesome-LLM-Strawberry































