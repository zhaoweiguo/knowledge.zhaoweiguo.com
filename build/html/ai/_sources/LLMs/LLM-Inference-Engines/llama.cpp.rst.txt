llama.cpp
#########


* llama.cpp 是一个轻量级的 C++ 项目，用于在 CPU 上运行 Meta 的 LLaMA（Large Language Model Meta AI）语言模型。该项目旨在将 LLaMA 模型在资源有限的环境中运行，并在 CPU 上实现相对高效的推理。
* https://github.com/ggerganov/llama.cpp


* Georgi Gerganov 是一位使用 C/C++ 语言编写神经网络代码的开发者中的佼佼者。Georgi Gerganov 是资深的开源社区开发者，曾为 OpenAI 的 Whisper 自动语音识别模型开发 whisper.cpp。
* 2023 年 3 月 Georgi Gerganov 又构建了开源项目 llama.cpp，llama.cpp 让开发者在没有 GPU 的条件下也能运行 Meta 的 LLaMA 模型。
* 2023 年 6 月 Georgi Gerganov 宣布创立一家新公司 ggml.ai，旨在支持 ggml 的开发。ggml 是 Georgi Gerganov 使用 C/C++ 构建了机器学习张量库，能够帮助开发者在消费级硬件上实现大模型，并提升模型性能。





主要特点
========

* 轻量级和简洁：llama.cpp 设计简洁，代码库较小，非常轻量，适合在资源受限的环境中运行。
* 无 GPU 依赖：不同于许多深度学习模型，llama.cpp 旨在在 CPU 上运行。这使得它在没有高性能 GPU 的设备上也可以使用。
* 本地推理：因为在 CPU 上运行，llama.cpp 可以在本地环境中使用，无需依赖云计算。这对于隐私和离线应用非常有帮助。
* 多平台支持：llama.cpp 可以在各种操作系统上运行，包括 Linux、Windows 和 macOS。
* 适用范围广：尽管 llama.cpp 针对 LLaMA 语言模型，但它的设计理念可以适用于其他大规模语言模型，扩展性强。

















































