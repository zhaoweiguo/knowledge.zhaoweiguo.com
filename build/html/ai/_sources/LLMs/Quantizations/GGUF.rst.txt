GGUF 文件
#########

示例::

    mmproj-model-f16.ggufGGUF:  有图像输入，是图文多模态模型的必要组件
    Model-7.6B-F16.ggufGGUF:    想保留模型全部精度，有高性能 GPU
    Model-7.6B-Q4_0.ggufGGUF
    Model-7.6B-Q4_1.ggufGGUF
    Model-7.6B-Q4_K_M.ggufGGUF
    Model-7.6B-Q4_K_S.ggufGGUF
    Model-7.6B-Q5_0.ggufGGUF
    Model-7.6B-Q5_1.ggufGGUF
    Model-7.6B-Q5_K_M.ggufGGUF
    Model-7.6B-Q6_K.ggufGGUF
    Model-7.6B-Q8_0.ggufGGUF


命名模式::

    Model-[参数规模]-[量化策略].gguf


+--------------------------------+--------+-------------------------------------------------------------+
| 文件名示例                     | 精度   | 含义解释                                                    |
+================================+========+=============================================================+
| `F16`                          | 全精度 | 使用 float16，几乎无信息损失，但体积大，资源需求高          |
+--------------------------------+--------+-------------------------------------------------------------+
| `Q8_0`                         | 8-bit  | 较高精度，较大的体积，推理速度快，适合性能机器              |
+--------------------------------+--------+-------------------------------------------------------------+
| `Q6_K`                         | 6-bit  | 较好的质量和性能权衡，推荐中等配置机器使用                  |
+--------------------------------+--------+-------------------------------------------------------------+
| `Q5_1` / `Q5_0`                | 5-bit  | 更小体积，更快推理，但略有精度损失                          |
+--------------------------------+--------+-------------------------------------------------------------+
| `Q4_1` / `Q4_0`                | 4-bit  | 体积小，推理非常快，适合低端机器或移动端使用                |
+--------------------------------+--------+-------------------------------------------------------------+
| `Q4_K_M` / `Q4_K_S` / `Q5_K_M` | K-bit  | llama.cpp新量化格式，用 groupwise 或 blockwise 技术增强效果 |
+--------------------------------+--------+-------------------------------------------------------------+

* `K_M` 表示 `K-bit Mixed`，`K_S` 表示 `K-bit Symmetric`。
* 这通常是某些特别调优过的量化方式，在保留较多模型性能的同时进一步减少体积。





