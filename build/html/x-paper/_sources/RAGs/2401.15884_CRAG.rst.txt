2401.15884_CRAG: Corrective Retrieval Augmented Generation
##########################################################

* https://arxiv.org/html/2401.15884
* 作者：严世奇, 顾嘉晨、朱云 , 凌振华 
* 组织：国家语音语言信息处理工程研究中心，中国科技大学(合肥)，加州大学洛杉矶分校，Google Research
* 大型语言模型（ LLMs ）不可避免地会出现幻觉，因为生成文本的准确性不能仅通过它们封装的参数知识来保证。 尽管检索增强生成（RAG）是LLMs的实用补充，但它在很大程度上依赖于检索到的文档的相关性，这引发了人们对检索出错时模型如何表现的担忧。 为此，我们提出了纠正检索增强生成（ CRAG ）来提高生成的鲁棒性。 具体来说，轻量级检索评估器被设计为评估查询检索到的文档的整体质量，返回一个置信度，基于该置信度可以触发不同的知识检索动作。 由于从静态和有限的语料库中检索只能返回次优文档，因此大规模网络搜索被用作增强检索结果的扩展。 此外，针对检索到的文档设计了分解然后重组算法，有选择地关注关键信息并过滤掉其中的不相关信息。 CRAG是即插即用的，可以与各种基于 RAG 的方法无缝耦合。 在涵盖短格式和长格式生成任务的四个数据集上进行的实验表明， CRAG可以显着提高基于 RAG 的方法的性能。
* Large language models (LLMs) inevitably exhibit hallucinations since the accuracy of generated texts cannot be secured solely by the parametric knowledge they encapsulate. Although retrieval-augmented generation (RAG) is a practicable complement to LLMs, it relies heavily on the relevance of retrieved documents, raising concerns about how the model behaves if retrieval goes wrong. To this end, we propose the Corrective Retrieval Augmented Generation (CRAG) to improve the robustness of generation. Specifically, a lightweight retrieval evaluator is designed to assess the overall quality of retrieved documents for a query, returning a confidence degree based on which different knowledge retrieval actions can be triggered. Since retrieval from static and limited corpora can only return sub-optimal documents, large-scale web searches are utilized as an extension for augmenting the retrieval results. Besides, a decompose-then-recompose algorithm is designed for retrieved documents to selectively focus on key information and filter out irrelevant information in them. CRAG is plug-and-play and can be seamlessly coupled with various RAG-based approaches. Experiments on four datasets covering short- and long-form generation tasks show that CRAG can significantly improve the performance of RAG-based approaches.


.. note:: 将具有特定功能的SLM引入RAG中，并根据RAG系统的结果进行微调。训练一个轻量级检索评估器来评估查询检索到的文档的整体质量，并根据置信度触发不同的知识检索动作。


.. figure:: https://img.zhaoweiguo.com/uPic/2024/09/qkDbPP.png

    图 1：示例表明，低质量的检索器很容易引入大量不相关的信息，阻碍生成器获取准确的知识，并可能误导它们。


鉴于上述问题，本文专门研究了检索器返回不准确结果的场景。提出了一种名为纠正检索-增强生成（ CRAG ）的方法来自我校正检索器的结果并提高增强生成文档的利用率。轻量级检索评估器旨在评估查询检索到的文档的整体质量。这是 RAG 的重要组成部分，通过审查和评估检索到的文档的相关性和可靠性来生成信息。量化置信度，基于该置信度可以触发{正确、不正确、模糊}的不同知识检索动作。对于后两个动作，因为从静态和有限的语料库中检索只能返回范围和多样性方面次优的文档，需要拓宽检索信息的范围，利用网络的扩展性和动态性来补充和丰富最初获得的文档。此外，为了消除检索到的文档中包含的对 RAG 无益的冗余上下文，在整个检索和利用过程中精心设计了分解然后重组算法。 该算法确保检索信息的细化，优化关键见解的提取并最大限度地减少非必要元素的包含，从而提高检索数据的利用率。


.. figure:: https://img.zhaoweiguo.com/uPic/2024/09/fCNJB6.png

    图 2：An overview of CRAG at inference. 构建检索评估器来评估检索到的文档与输入的相关性，并估计置信度，基于该置信度可以触发不同的知识检索动作{正确，不正确，模糊}。




































