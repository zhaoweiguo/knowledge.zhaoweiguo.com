# 2410.02355_AlphaEdit: Null-Space Constrained Knowledge Editing for Language Models

* 首页: <https://arxiv.org/abs/2410.02355>
* PDF: <https://arxiv.org/pdf/2410.02355>
* 引用: 73(2025-08-19)
* 组织: 
    * 1University of Science and Technology of China
    * 2National University of Singapore
* GitHub: <https://github.com/jianghoucheng/AlphaEdit>


## 总结

**AlphaEdit**
* 非微调的知识编辑方法
    * 实现对模型内部知识的精确更新
* 核心思想：非微调、零空间扰动
    * 核心思想是在将扰动应用到模型参数之前，将扰动投影到保留知识的零空间（null space），从而确保扰动不会影响保留知识的输出
    * 作者从理论上证明，这种方法可以保证在查询保留知识时，模型的输出不会发生变化，从而有效缓解知识破坏问题。

**知识编辑**
* 主要分为两类：
    * 参数修改方法(parameter-modifying methods): 直接调整一小部分参数(本文属于此类🌼)
    * 参数保留方法(parameter-preserving methods): 在不改变原始参数的情况下集成其他模块
* 先定位后编辑（locating-then-editing）范式
    * 该方法首先定位对特定知识有影响的参数，然后通过引入 **扰动（perturbation）** 对这些参数进行编辑
        * 定位：通过因果追踪（causal tracing）找到对目标知识有影响的参数（如矩阵 𝐖）。
        * 编辑：通过引入扰动 Δ 来调整参数，目标是减少对目标知识的输出误差 e₁。
        * 为了确保保留原有知识，通常也会将保留知识的输出误差 e₀ 作为目标函数的一部分
    * 这种扰动在执行过程中不可避免地会破坏模型中原本保留的其他知识，尤其是在 **连续编辑（sequential editing）** 的场景下，这种问题尤为明显


**核心概念：**
* Null Space（零空间）
    * 零空间是本方法的理论基础。
    * 对于两个矩阵 $\mathbf{A}$ 和 $\mathbf{B}$，如果 $\mathbf{B}\mathbf{A} = \mathbf{0}$，则称 $\mathbf{B}$ 在 $\mathbf{A}$ 的左零空间（简称为零空间）中。
* Null Space Projecting（零空间投影）
* Null-Space Constrained Model Editing（零空间约束下的模型编辑）



**贡献**
* 提出了一种新的、更可控的知识编辑范式。
* 零空间约束是实现高精度编辑的关键。
* 为未来的研究提供了新的思路。


**From Deepseek**
* 方法创新点：
    * 通过将扰动投影到“保留知识”的零空间（null space）中，实现对模型参数的编辑，从而在更新知识的同时保持原有知识不变。
    * 该方法理论上证明了编辑后模型在查询保留知识时输出不变，有效缓解了模型遗忘和崩溃问题。
* 现实意义：
    * 提出一种高效且非侵入式的知识编辑方法，用于在不破坏已有知识的前提下更新大语言模型（LLMs）中的知识，对模型维护和持续学习具有重要工业价值。



## Abstract

**研究背景**：
大型语言模型（LLMs）在生成内容时经常出现“幻觉”问题，即生成错误或过时的知识。为了解决这一问题，研究者提出了**模型编辑方法**，用于对模型中的知识进行**有针对性的更新**。当前主流的方法是**先定位后编辑**（locating-then-editing）范式，该方法首先定位对特定知识有影响的参数，然后通过引入**扰动（perturbation）**对这些参数进行编辑。

**存在问题**：尽管该方法在一定程度上有效，但已有研究表明，这种扰动在执行过程中**不可避免地会破坏模型中原本保留的其他知识**，尤其是在**连续编辑（sequential editing）**的场景下，这种问题尤为明显。

**本文贡献**：为了解决上述问题，作者提出了**AlphaEdit**，一种新的模型编辑方法。其核心思想是在将扰动应用到模型参数之前，**将扰动投影到保留知识的零空间（null space）**，从而确保扰动**不会影响保留知识的输出**。作者**从理论上证明**，这种方法可以保证在查询保留知识时，模型的输出不会发生变化，从而有效**缓解知识破坏问题**。

**实验验证**：作者在多个大型语言模型（如LLaMA3、GPT2-XL、GPT-J）上进行了广泛的实验。结果表明，**AlphaEdit显著提升了大多数“先定位后编辑”方法的性能**，平均提升了**36.7%**，且只需**添加一行投影代码**即可实现。该方法具有**高效、易实现、高性能**的特点。



## 1 Introduction


本文主要探讨了**大型语言模型（LLMs）**的**模型编辑方法**，尤其是**参数修改类方法**（parameter-modifying methods）。这类方法的核心思想是通过**定位关键参数**，并对其进行**扰动调整**，从而实现对模型中特定知识的更新，同时保留其他知识。

### 1.1 当前方法的局限性

- **参数修改方法**通常遵循“定位-编辑”范式（locate-then-edit paradigm）：
  - **定位**：通过因果追踪（causal tracing）找到对目标知识有影响的参数（如矩阵 𝐖）。
  - **编辑**：通过引入扰动 Δ 来调整参数，目标是减少对目标知识的输出误差 e₁。
  - 为了确保保留原有知识，通常也会将保留知识的输出误差 e₀ 作为目标函数的一部分。

- **关键问题**：当前方法在 **e₁（更新知识的误差）** 和 **e₀（保留知识的误差）** 之间难以取得平衡。
  - 现有方法通常更重视 **e₁ 的最小化**，而对 **e₀ 控制不足**。
  - 这容易导致模型**过拟合**于更新后的知识，从而引发**隐藏层表示分布的偏移**（hidden representation shift）。
  - 在**连续编辑**（sequential editing）场景下，这种过拟合会逐渐累积，造成**模型遗忘**（model forgetting）甚至**模型崩溃**（model collapse）。

### 1.2 本文提出的方法：AlphaEdit

为了解决上述问题，本文提出了一种新的模型编辑方法 **AlphaEdit**，其核心创新点如下：

- **不再将 e₀（保留知识的误差）纳入目标函数**，让模型专注于最小化 e₁，避免在二者之间进行权衡。
- **引入矩阵投影与零空间（null space）约束**：
  - 在应用 Δ 之前，将扰动 Δ 投影到 **保留知识的零空间**，从而确保编辑不会影响原有知识。
  - 通过数学性质（如投影和零空间）保证：**隐藏层表示在编辑后保持不变**（invariant），从而防止模型过拟合和分布偏移。

- **实验结果**：
  - AlphaEdit 在多个主流模型（如 GPT-2 XL、LLaMA-3）上进行了测试。
  - 相比基线方法（如 MEMIT），AlphaEdit 的性能平均提升超过 **36.7%**。
  - 此方法只需在现有模型编辑方法中添加一行代码即可实现，是一种**即插即用的增强方案**，可广泛应用于各类模型编辑框架。

### 1.3 结论与意义

- AlphaEdit 是一种**简单、高效且通用的模型编辑方法**，通过引入**零空间约束**，解决了当前方法在知识更新与保留之间难以平衡的问题。
- 该方法不仅在性能上显著优于现有方法，还具备良好的兼容性，适用于多种模型编辑场景。
- 为语言模型的**高效知识更新**提供了新的思路，有助于推动模型编辑技术的进一步发展与实际应用。


## 2 Preliminary


### 2.1 Autoregressive Language Model（自回归语言模型）

本节介绍了自回归大型语言模型（LLM）的基本结构，强调其如何通过已有的词元序列预测下一个词元。在每一层中，模型的隐藏状态 $ \mathbf{h}^l $ 可表示为：

$$
\mathbf{h}^l = \mathbf{h}^{l-1} + \mathbf{a}^l + \mathbf{m}^l
$$

其中：
- $ \mathbf{a}^l $ 是注意力块的输出；
- $ \mathbf{m}^l $ 是前馈网络（FFN）层的输出，其结构为：

$$
\mathbf{m}^l = \mathbf{W}_{\text{out}}^{l} \sigma(\mathbf{W}_{\text{in}}^{l} \gamma(\mathbf{h}^{l-1} + \mathbf{a}^l))
$$

- $ \mathbf{W}_{\text{in}}^l $ 和 $ \mathbf{W}_{\text{out}}^l $ 是 FFN 层的权重矩阵；
- $ \sigma $ 是非线性激活函数；
- $ \gamma $ 是层归一化操作。

**重点讲解**：作者指出，FFN 层中的 $ \mathbf{W}_{\text{out}}^l $ 可被解释为一种“线性关联记忆”机制，它可以将输入键 $ \mathbf{k} $（编码了 (s, r)）与对应的值 $ \mathbf{v} $（编码了 o）关联起来，从而实现类似知识库的功能。这一理解是当前许多**模型编辑方法**（如 Li et al. 2024, Hu et al. 2024）的核心基础。

---

### 2.2 Model Editing in LLMs（LLM 中的模型编辑）

模型编辑的目标是**更新 LLM 中存储的知识**，通常通过“定位-编辑”范式，即在模型参数上添加扰动 $ {\Delta} $。每个编辑操作旨在更新 $ u $ 条知识（以三元组形式 (s, r, o) 表示），从而引入新的 (key, value) 对。

**重点讲解**：模型编辑的目标函数通常采用最小化重构误差的方式，即：

$$
{\Delta} = \arg\min_{{\tilde{\Delta}}} \| (\mathbf{W} + {\tilde{\Delta}})\mathbf{K}_1 - \mathbf{V}_1 \|^2
$$

其中：
- $ \mathbf{K}_1 $ 和 $ \mathbf{V}_1 $ 是要更新的知识对应的 key 和 value 矩阵；
- $ \mathbf{K}_0 $ 和 $ \mathbf{V}_0 $ 是保留知识的 key 和 value 矩阵，需要在编辑过程中被保护。

为了同时保留已有知识，目标函数扩展为：

$$
{\Delta} = \arg\min_{{\tilde{\Delta}}} \left( \| (\mathbf{W} + {\tilde{\Delta}})\mathbf{K}_1 - \mathbf{V}_1 \|^2 + \| (\mathbf{W} + {\tilde{\Delta}})\mathbf{K}_0 - \mathbf{V}_0 \|^2 \right)
$$

由于 $ \mathbf{W}\mathbf{K}_0 = \mathbf{V}_0 $，可利用正规方程（Normal Equation）求解该优化问题的闭式解：

$$
{\Delta} = (\mathbf{V}_1 - \mathbf{W}\mathbf{K}_1)\mathbf{K}_1^T(\mathbf{K}_0\mathbf{K}_0^T + \mathbf{K}_1\mathbf{K}_1^T)^{-1}
$$

**次要说明**：虽然 $ \mathbf{K}_0 $ 无法直接获取，但可以通过大量文本（如维基百科的 10 万个三元组）来估计。实践中，$ \mathbf{K}_0 \in \mathbb{R}^{d_0 \times 100,000} $，是一个高维矩阵。详细实现步骤可参考附录 B.1。

---

### 总结

- **2.1 节** 介绍了自回归语言模型的结构，重点讨论了 FFN 层在知识存储中的作用，将其解释为一种“线性关联记忆”机制。
- **2.2 节** 提出了模型编辑的数学框架，通过在 FFN 的权重矩阵上添加扰动来更新 LLM 中的知识，同时保留原有知识。
- **关键贡献**：建立了一个基于 key-value 存储与编辑的理论模型，为后续基于编辑的模型更新方法奠定了基础。

## 3 Method


### 3.1 Null Space（零空间）

**核心概念：**

零空间是本方法的理论基础。对于两个矩阵 $\mathbf{A}$ 和 $\mathbf{B}$，如果 $\mathbf{B}\mathbf{A} = \mathbf{0}$，则称 $\mathbf{B}$ 在 $\mathbf{A}$ 的左零空间（简称为零空间）中。

**在模型编辑中的应用：**

在模型编辑过程中，假设我们要对参数矩阵 $\mathbf{W}$ 引入扰动 $\Delta$。为了确保这个扰动不会影响模型中需要保留的知识（记为 $\mathbf{K}_0$ 和 $\mathbf{V}_0$），我们需要将 $\Delta$ 投影到 $\mathbf{K}_0$ 的零空间中，即保证 $\Delta'\mathbf{K}_0 = \mathbf{0}$。

这样，模型更新后仍然满足：

$$
(\mathbf{W} + \Delta')\mathbf{K}_0 = \mathbf{W}\mathbf{K}_0 = \mathbf{V}_0
$$

即保留了原有知识的键值映射关系。

**重点：** 投影到零空间是确保编辑不影响已有知识的核心机制。

---

### 3.2 Null Space Projecting（零空间投影）

**动机与问题：**

由于 $\mathbf{K}_0$ 的维度很高（例如 $d_0 \times 100,000$），直接对其应用零空间投影在计算和存储上效率较低。因此，作者选择对 $\mathbf{K}_0\mathbf{K}_0^T$ 进行奇异值分解（SVD），然后基于其零空间构建投影矩阵 $\mathbf{P}$。

**具体步骤：**

1. 对 $\mathbf{K}_0\mathbf{K}_0^T$ 进行 SVD 分解：   $$
   \mathbf{U}, \Lambda, \mathbf{U}^T = \text{SVD}(\mathbf{K}_0\mathbf{K}_0^T)
   $$
2. 保留 $\mathbf{U}$ 中对应于小（接近零）特征值的列向量，构建子矩阵 $\hat{\mathbf{U}}$。
3. 构造投影矩阵 $\mathbf{P} = \hat{\mathbf{U}}\hat{\mathbf{U}}^T$，使得扰动 $\Delta$ 满足：
   $$
   \Delta \mathbf{P} \cdot \mathbf{K}_0 = \mathbf{0}
   $$

**结论：**

通过将扰动 $\Delta$ 乘以 $\mathbf{P}$，可以确保其落在零空间中，不会破坏 $\mathbf{K}_0$ 对应的知识结构。

---

### 3.3 Null-Space Constrained Model Editing（零空间约束下的模型编辑）

**目标：**

在已知零空间投影方法的基础上，重新设计模型编辑的目标函数，使其更加高效且不影响已有知识。

**优化步骤：**

1. **投影扰动：** 将原扰动 $\Delta$ 替换为 $\Delta \mathbf{P}$；
2. **去除冗余项：** 由于零空间投影已经保护了原有知识，可以去除关于 $\mathbf{K}_0$ 的保护项；
3. **添加正则项：** 添加 $\|\Delta \mathbf{P}\|^2$，以提升训练稳定性。

**最终优化目标函数：**

$$
\Delta = \arg\min_{\tilde{\Delta}} \left( \|(\mathbf{W} + \tilde{\Delta}\mathbf{P})\mathbf{K}_1 - \mathbf{V}_1\|^2 + \|\tilde{\Delta}\mathbf{P}\|^2 \right)
$$

其中 $\mathbf{K}_1, \mathbf{V}_1$ 是当前编辑任务中需要更新的知识。

**序列编辑场景下的扩展：**

在多轮编辑中，还需保护之前编辑的知识 $\mathbf{K}_p$，目标函数增加一项：

$$
\|\tilde{\Delta}\mathbf{P}\mathbf{K}_p\|^2
$$

得到最终目标函数：

$$
\Delta = \arg\min_{\tilde{\Delta}} \left( \|(\mathbf{W} + \tilde{\Delta}\mathbf{P})\mathbf{K}_1 - \mathbf{V}_1\|^2 + \|\tilde{\Delta}\mathbf{P}\|^2 + \|\tilde{\Delta}\mathbf{P}\mathbf{K}_p\|^2 \right)
$$

**解析解：**

通过最小二乘法，求得扰动 $\Delta_{\text{AlphaEdit}}$ 的解析形式为：

$$
\Delta_{\text{AlphaEdit}} = \mathbf{R} \mathbf{K}_1^T \mathbf{P} \left( \mathbf{K}_p \mathbf{K}_p^T \mathbf{P} + \mathbf{K}_1 \mathbf{K}_1^T \mathbf{P} + \mathbf{I} \right)^{-1}
$$

其中 $\mathbf{R} = \mathbf{V}_1 - \mathbf{W} \mathbf{K}_1$ 是残差向量。

**与现有方法的对比：**

作者还给出了与 MEMIT 方法的比较公式（见 Eqn. 15），指出 AlphaEdit 仅需对现有方法进行微小修改（加入投影矩阵 $\mathbf{P}$）即可显著提升效果。

---

### 总结

AlphaEdit 方法通过引入零空间投影机制，使得模型参数的扰动不会破坏已有知识，从而提升了模型编辑任务的准确性和稳定性。该方法在计算上高效，仅需一次投影矩阵运算即可复用于多个下游任务，适用于单次或多次编辑场景。


## 4 Experiment


本节通过实验回答四个研究问题（RQ1-RQ4），旨在验证AlphaEdit在知识编辑任务中的表现、通用能力保持、表征分布稳定性以及对基线方法的增强效果。

---

### **4.1 Experimental Setup**

**实验设置**：

- **基础模型与基线方法**：
  - 使用三种大语言模型（LLMs）：GPT2-XL（1.5B）、GPT-J（6B）和LLaMA3（8B）。
  - 对比的基线方法包括：Fine-Tuning (FT)、MEND、InstructEdit、ROME、MEMIT、PRUNE、RECT，以及额外的基于记忆的编辑方法（如SERAC、GRACE、MELO）。

- **数据集与评估指标**：
  - 使用Counterfact和ZsRE两个数据集进行评估。
  - 评估指标包括：Efficacy（有效性）、Generalization（泛化能力）、Specificity（特异性）、Fluency（流畅性）和Consistency（一致性）。
  - 进一步在KnowEdit、LEME和MQUAKE等数据集上进行了扩展实验。

---

### **4.2 Performance on Knowledge Update and Preservation (RQ1)**

**重点内容**：

- AlphaEdit在知识更新和保留方面表现优异，显著优于所有基线方法，特别是在Efficacy和Generalization两个关键指标上。
  - 平均提升：Efficacy提升12.54%，Generalization提升16.78%。
  - 在LLaMA3上表现尤为突出，Efficacy提升32.85%，Generalization提升30.60%。
- AlphaEdit通过**null-space投影**缓解了知识更新与保留之间的冲突，从而提升了整体性能。
- 同时，AlphaEdit在文本生成流畅性方面也有显著提升（如在GPT2-XL上提升18.33%），表明其不仅更新知识，还能保留语言模型的生成能力。

---

### **4.3 General Capability Tests (RQ2)**

**重点内容**：

- 在通用能力评估中（使用GLUE基准下的6个任务：SST、MRPC、CoLA、RTE、MMLU、NLI），AlphaEdit在多次编辑（如3000次）后仍能保持模型的原始性能。
- 相较之下，其他基线方法在编辑2000次后性能急剧下降，几乎所有指标趋近于零。
- 这表明AlphaEdit的**null-space投影**不仅保护了特定知识，还保留了模型从原始知识中学习到的通用能力。

---

### **4.4 Hidden Representations Analysis (RQ3)**

**重点内容**：

- AlphaEdit在编辑过程中**避免了隐藏表示分布的显著偏移**，而大多数基线方法（如RECT）在编辑后出现了明显的分布变化，甚至在某些模型中分布趋势完全反转。
- 通过t-SNE可视化和分布偏移量化分析，验证了AlphaEdit在防止过拟合和保持表征稳定性方面的有效性。
- 这进一步解释了AlphaEdit在知识保留与泛化能力上的优越性。

---

### **4.5 Performance Improvements of Baseline Methods (RQ4)**

**重点内容**：

- AlphaEdit的投影策略可以**无缝集成到其他基线方法中**，显著提升其性能。
  - 例如，MEMIT、PRUNE和RECT在添加一行为投影代码后，编辑能力平均提升28.24%，通用能力提升42.65%。
- 说明**null-space投影**不仅对AlphaEdit本身有效，还能广泛应用于提升现有模型编辑方法的性能。

---

### **总结**

实验部分系统评估了AlphaEdit在多个维度上的表现，结果显示：

- **AlphaEdit显著优于所有基线方法**，特别是在知识更新与保留之间的平衡、通用能力保持、以及隐藏表示稳定性方面。
- **null-space投影**是AlphaEdit的核心机制，有效防止了模型遗忘、模型崩溃和分布偏移问题。
- 该方法**具有高度通用性**，不仅能作为独立方法使用，还能增强其他模型编辑策略。

通过这些实验结果，论文验证了AlphaEdit在语言模型知识编辑任务中的优越性能和广泛适用性。


## 5 Related Work


### Parameter-modifying Model Editing（参数修改型模型编辑）

该方法主要采用**元学习**或**定位-编辑**策略进行模型编辑。

- **元学习**方法通过超网络（hypernetwork）调整模型参数，具有代表性的方法包括 KE（Cao et al., 2021）和 MEND（Mitchell et al., 2022a）。InstructEdit（Zhang et al., 2024b）在 MEND 的基础上扩展，设计了用于不同任务的训练指令。
- **定位-编辑**策略优先定位知识的存储位置，再进行针对性编辑。代表性方法有 ROME（Meng et al., 2022）和 MEMIT（Meng et al., 2023）。GLAME（Zhang et al., 2024a）在此基础上引入知识图谱以增强相关知识的编辑能力。
- 最新工作 AnyEdit（Jiang et al., 2025）提出了递归方法，可以编辑 LLM 中任意长度和格式的知识，是一个重要的进展。

**重点内容：** AnyEdit 的递归方法、GLAME 利用知识图谱增强编辑能力、ROME 和 MEMIT 的定位编辑策略。

---

### Parameter-preserving Model Editing（参数保留型模型编辑）

这类方法不修改模型原有参数，而是通过添加模块来存储待更新的知识。这些模块可以是代码本（codebook）、神经元或辅助模型。

- 代表性方法包括 SERAC（Mitchell et al., 2022b）、T-Patcher（Huang et al., 2023）、GRACE（Hartvigsen et al., 2023）和 MELO（Yu et al., 2024）。
- 另外，MemPrompt（Madaan et al., 2022）和 IKE（Zheng et al., 2023）通过将待更新知识融入输入提示中实现编辑。

- 最近 WISE（Wang et al., 2025）创新性地引入了**双记忆机制**和**无冲突的知识分片（conflict-free knowledge sharding）**，有效解决了可靠性与泛化能力之间的权衡问题。

**重点内容：** WISE 的双记忆与冲突无关分片机制、模块化编辑方法、参数保留的设计优势。

---

### Evaluating Knowledge Editing（知识编辑评估）

近年来，研究者提出了多种**基准数据集**，用于评估编辑方法的效果。

- **KnowEdit**（Zhang et al., 2024d）提供了一个统一的数据集，涵盖知识插入、修改和删除任务。
- **LEME**（Rosati et al., 2024）关注长文本知识编辑；
- **CKnowEdit**（Fang et al., 2025）侧重多语言知识编辑；
- **MQuAKE**（Zhong et al., 2023）则专注于多跳知识编辑。

这些数据集共同推动了知识编辑方法的**全面评估**，提升了研究的系统性与客观性。

**重点内容：** KnowEdit 的统一性、MQuAKE 的多跳任务、LEME 和 CKnowEdit 的针对性扩展。


## 6 Limitations & Future Discussion



本节主要讨论了 AlphaEdit 方法的局限性以及未来的潜在研究方向。

**1. 适用范围有限**尽管 AlphaEdit 在编辑知识的同时保持了模型性能的相对稳定，但其在**多模态大语言模型（multi-modal LLMs）** 以及**大规模推理模型（large reasoning models）** 中的应用尚未被验证。因此，未来的研究可以聚焦于如何将 AlphaEdit 扩展到更广泛的 LLM 类型，以提升其通用性。

**2. null-space 投影的潜力**AlphaEdit 中使用**null-space 投影**（零空间投影）在平衡“知识更新”与“知识保留”方面表现出色。这一方法在其它场景中也具有应用潜力，尤其可以用于提升 LLM 在**特定领域（如安全性、数学或生物化学）** 的能力，而不会影响模型在其他方面的表现。

**3. 未来研究方向**作者指出，这些研究方向（扩展模型适用范围、探索 null-space 投影的应用潜力）为提升 AlphaEdit 方法的**实用性（applicability）** 和**可扩展性（scalability）** 提供了令人期待的前景。

总结来说，本节强调了当前方法的局限性，并提出了两个重点未来研究方向：一是扩展模型的适用范围，二是利用 null-space 投影提升特定能力。这些方向对于推动 AlphaEdit 的发展具有重要意义。


## 7 Conclusion

本文介绍了 **AlphaEdit**，这是一种新颖的模型编辑方法，旨在解决当前方法中一个关键挑战——在**知识更新**与**知识保留**之间的权衡。通过**仅一行代码**即可实现，AlphaEdit 显著简化了模型编辑的流程。

### 核心思想

AlphaEdit 的关键在于**最小化对保留知识的干扰**。它通过将参数扰动**投影到其关键矩阵的零空间**（null space）中，有效地实现了这一点。这样，模型在更新知识时，不会影响到已经学到的重要信息，从而更加专注于**知识更新**本身。

### 实验结果（重点内容）

作者在多个基础大型语言模型（LLMs）上进行了广泛的实验，包括 **LLaMA3**、**GPT-2 XL** 和 **GPT-J**。实验结果表明，AlphaEdit 显著提升了现有模型编辑方法的性能，平均提升了 **36.7%** 的编辑能力。这一提升具有重要意义，证明了 AlphaEdit 在模型编辑任务中的优越性和广泛适用性。

### 小结

综上所述，AlphaEdit 提出了一种高效、简洁的模型编辑方法，在实现知识更新的同时，有效保留了原有知识。其实验验证了其在多种主流模型上的出色表现，为未来模型编辑任务提供了新的解决方案。


## Ethics Statement



本文的AlphaEdit方法显著提升了顺序模型编辑的性能，使其在现实世界应用中更新和管理知识时具有重要价值。尽管可以直接修改存储的知识，这也带来了潜在风险，例如可能引入**错误或有害的信息**。对此，作者**强烈呼吁研究人员实施严格的验证和监督机制**，以确保这些技术的**伦理使用**。

尽管存在上述风险，模型编辑的**初衷是积极的**，旨在**未来实现大型模型的高效更新**。因此，作者鼓励研究人员**负责任且谨慎地使用这一技术**。


## Reproducibility


本节重点介绍如何确保研究结果的可复现性。

为了确保我们研究结果的可复现性，作者提供了 AlphaEdit 的详细实现说明，这些说明可以在附录 A 中找到（附录标题为 "Experimental Setup"，详见 [arxiv链接](https://arxiv.org/html/2410.02355v4#A1 "Appendix A Experimental Setup ‣ AlphaEdit: Null-Space Constrained Knowledge Editing for Language Models")）。此外，AlphaEdit 的源代码已公开在 GitHub 上，网址为 [https://github.com/jianghoucheng/AlphaEdit](https://github.com/jianghoucheng/AlphaEdit)。这些措施旨在方便领域内的其他研究人员验证和复现我们的实验结果。

**重点内容总结：**
- 提供了详细的实现说明（附录 A）。
- 源代码已公开，便于复现。
- 目标是提高研究的透明度和可验证性。


## Acknowledgement



本研究得到了国家科技重大专项（2023ZD0121102）、国家自然科学基金（92270114）以及国家自然科学基金（U24B20180）的支持。同时，感谢 EasyEdit 平台提供的支持（<https://github.com/zjunlp/EasyEdit>）。


## Appendix A Experimental Setup



### A.1 数据集

本节对本文中使用的数据集进行了详细介绍：

- **Counterfact**：这是一个更具挑战性的数据集，用于对比反事实与事实陈述。该数据集通过替换主题实体并保持相同谓词来构建超出范围的数据。它与 ZsRE 具有类似的评估指标，用于评估编辑效果、泛化性和特异性。此外，Counterfact 包含多个具有相同语义的生成提示，用于测试生成文本的质量，特别是流畅性和一致性。

- **ZsRE**：这是一个问答数据集，使用回译生成等价邻居问题。它使用自然问题作为超出范围的数据以评估局部性。每个样本包含一个主题字符串和一个答案作为编辑目标，同时包含重新表述的问题用于泛化评估，以及用于评估特异性的局部性问题。

- **KnowEdit**：这是一个全面的基准数据集，旨在系统性地评估知识编辑方法。它将现有方法分为依赖外部知识、内在知识更新或将新知识合并到模型中的类别。KnowEdit 不仅测量编辑对特定领域的影响，还强调在多任务上的整体性能保持，提供统一的框架以评估编辑效率与影响。本文使用 KnowEdit 中的 `wiki_recent` 和 `wikibio` 进行实验。

- **LEME**：这是一个以长文本生成输出为主要评估对象的扩展评估范式，揭示了事实漂移、内部一致性以及词汇连贯性等独特挑战。该协议指出，短文本指标与长文本生成结果之间的相关性较低，揭示了编辑评估中未被探索的维度。

- **MQuAKE**：通过引入多跳推理问题，填补了当前评估中的一个关键空白，测试事实更新的涟漪效应。与单事实召回基准不同，MQuAKE 测量了编辑后信念的一致性，揭示了现有方法在处理复杂关系依赖方面的局限性。

---

### A.2 评估指标

本节分别介绍了用于 ZsRE 和 Counterfact 数据集的评估指标。

#### A.2.1 ZsRE 指标

- **有效性（Efficacy）**：衡量编辑样本上 top-1 准确率的平均值，表示模型是否成功实现了目标编辑。

- **泛化性（Generalization）**：评估模型在等价提示（例如重述问题）上的性能，即模型是否能推广到语义相同但表达方式不同的输入。

- **特异性（Specificity）**：确保编辑不会影响与编辑无关的样本。通过衡量未被编辑的样本预测结果是否保持不变来评估。

#### A.2.2 Counterfact 指标

- **有效性（有效性成功）**：表示编辑输出比原始输出更有概率的样本比例。

- **泛化性（重述成功）**：与 ZsRE 类似，评估模型在重述提示上的性能。

- **特异性（邻域成功）**：评估在语义相关但不同主题的提示下，模型是否能保持对正确事实的高概率输出。

- **流畅性（生成熵）**：通过 n-gram 分布的熵值衡量模型输出中的重复程度，值越高表示重复越少。

- **一致性（参考分数）**：通过计算模型生成文本与参考 Wikipedia 文本的 TF-IDF 向量之间的余弦相似度来评估输出的一致性。

---

### A.3 实现细节

本文对 AlphaEdit 使用 GPT-2 XL 和 GPT-J 模型的实现遵循 MEMIT 的配置：

- **GPT-2 XL**：编辑关键层 [13,14,15,16,17]，超参数 λ 设置为 20,000，优化步骤为 20，学习率为 0.5。
- **GPT-J**：编辑关键层 [3,4,5,6,7,8]，λ 设置为 15,000，优化步骤为 25，学习率为 0.5。

- **Llama3 (8B)**：编辑关键层 [4,5,6,7,8]，λ 设置为 15,000，优化步骤为 25，学习率为 0.1。

所有实验在单块 A40（48GB）GPU 上进行，模型使用 HuggingFace Transformers 加载。

---

### A.4 基线方法

本节介绍了本文中使用的五种基线模型：

- **MEND**：通过小辅助网络进行高效编辑，避免完整的微调，具有高效且局部的参数调整。

- **InstructEdit**：基于 MEND 的元学习方法，通过设计不同任务的指令进行训练，实现多任务编辑能力。

- **ROME**：直接编辑中间层的前馈模块，修改权重以更改事实关联，强调中间层在记忆事实知识中的关键作用。

- **MEMIT**：扩展 ROME 方法，可在多个层插入新的事实记忆，实现大规模编辑。

- **PRUNE**：通过限制编辑矩阵的条件数防止模型性能下降，保持模型整体能力。

- **RECT**：通过正则化权重更新，减少编辑对模型通用能力的负面影响。

- **SERAC**：使用检索增强的半参数编辑框架，支持编辑范围定义和顺序更新，适用于问答、事实核查和对话生成。

- **MELO**：使用动态激活的 LoRA 块进行高效编辑，在分类、问答和幻觉纠正任务上表现优异。

- **GRACE**：提出长期编辑框架，通过潜空间的局部代码本处理大量顺序编辑，保留模型泛化能力。

---

**总结**：本节详细列出了实验中使用的主要数据集、评估指标、模型实现细节及基线方法，为后续实验分析提供了完整的设置背景。


## Appendix B Implementation Details of Current Model Editing & Related Proofs


### B.1 模型编辑

**目标**：模型编辑旨在通过一次或多次“编辑”操作对预训练模型进行微调。每次编辑将知识三元组 (s, r, o) 替换为新知识 (s, r, o∗)。目标是使模型在给定自然语言提示 p(s, r)（例如“美国总统是”）时能够回忆出新对象 o∗（Yang et al., 2024b；Li et al., 2025；Zhang et al., 2024c）。

**实现步骤**：

1. **定位关键层（Locating Influential Layers）**：
   - 使用“因果追踪”方法定位模型中对当前知识更新有显著影响的FFN层（Meng et al., 2022）。
   - 方法是向隐藏层注入高斯噪声，逐步恢复原始状态，观察哪些层对输出有较大影响，从而确定需要编辑的层。

2. **提取期望输出（Acquiring the Expected Output）**：
   - 通过“键值理论”，将输入关系 (s, r) 编码为向量 **k**，再通过输出权重 **W_out** 得到原始输出值 **v**。
   - 通过梯度下降法对 **v** 进行优化，最大化模型输出新对象 o∗ 的概率（Meng et al., 2023）。
   - 优化目标为：
     $$
     {{v}}^{\ast} = {{v}} + \arg\min_{\mathbf{{\delta}}^{l}} (-\log \mathbb{P}_{f_{W_{\text{out}}^l}(m^l + \mathbf{{\delta}}^l)}[o^{\ast} | (s, r)])
     $$

3. **更新输出权重（Updating W_out）**：
   - 使用最小二乘法更新输出权重 **W_out**，在保留原有知识 **K₀, V₀** 的前提下，加入新的知识对 **K₁, V₁**。
   - 定义目标函数为：
     $$
     \tilde{{{W}}}_{\text{out}}^{l} = \arg\min_{\hat{{{W}}}} \left( \sum_{i=1}^{n} \|\hat{{{W}}}{{k}}_{i} - {{v}}_{i} \|^2 + \sum_{i=n+1}^{n+u} \|\hat{{{W}}}{{k}}_{i} - {{v}}^{\ast}_{i} \|^2 \right)
     $$
   - 通过正则方程求解其闭式解，最终得到新的权重 **W_out**。

---

### B.2 K₀ 和 K₀K₀ᵀ 的公共零空间证明

**定理**：设 **K₀** 是一个 m×n 矩阵，则 **K₀** 与其自乘 **K₀K₀ᵀ** 具有相同的左零空间。

**证明思路**：
- 左零空间定义为满足 **xᵀK₀ = 0** 的向量 **x**。
- 证明 **x ∈ 左零空间(K₀) ⇒ x ∈ 左零空间(K₀K₀ᵀ)**。
- 反之，若 **x ∈ 左零空间(K₀K₀ᵀ)**，由非负性可推得 **x ∈ 左零空间(K₀)**。
- 因此，两者的左零空间重合，体现了 **K₀** 与其自乘矩阵在结构上的对称性和依赖关系。

---

### B.3 ΔP K₀K₀ᵀ = 0 的证明

**背景**：通过 **K₀K₀ᵀ** 的奇异值分解（SVD），可以得到其正交基 **U₁, U₂** 和对应特征值 **Λ₁, Λ₂**。
- **U₂** 对应所有零特征值，构成 **K₀K₀ᵀ** 的零空间。

**结论**：投影矩阵 **P = U₂U₂ᵀ** 满足：
$$
\Delta P K_0 (K_0)^T = 0
$$
- 表明 **ΔP** 的变化不会影响 **K₀K₀ᵀ** 的非零空间部分，从而保证了模型在编辑过程中不破坏原始知识。

---

### B.4 AlphaEdit 干扰项推导

**目标函数**为：
$$
J = \| ({{W}} + {\tilde{\Delta}}{{P}}){{K}}_1 - {{V}}_1 \|^2 + \| {\tilde{\Delta}}{{P}} \|^2 + \| {\tilde{\Delta}}{{P}}{{K}}_p \|^2
$$
- 通过对目标函数求导并令导数为零，可得闭式解：
$$
{\Delta}_{\text{AlphaEdit}} = {{R}}{{K}}_1^{\top}{{P}} ( {{K}}_p{{K}}_p^{\top}{{P}} + {{K}}_1{{K}}_1^{\top}{{P}} + {{I}} )^{-1}
$$
- 该解约束于 **P** 的列空间，确保更新仅作用于零空间，避免破坏原始知识。

---

### B.5 矩阵 (KpKpᵀP + K₁K₁ᵀP + αI) 可逆性证明

**关键点**：
- **KpKpᵀ** 和 **K₁K₁ᵀ** 是对称半正定矩阵。
- **P** 是投影矩阵，也是对称半正定的。
- 加上正数 α 乘以单位矩阵 **I**，使得整个矩阵变为正定矩阵。
- 因此，矩阵：
$$
{{K}}_p{{K}}_p^T{{P}} + {{K}}_1{{K}}_1^T{{P}} + \alpha{{I}}
$$
是可逆的，保证了解的存在性和唯一性。

---

### 总结

本节详细介绍了模型编辑的实现步骤，包括关键层的定位、输出权重的更新方法，并通过数学证明确保了编辑操作的安全性与有效性。特别是通过零空间约束（如 AlphaEdit 方法）和矩阵可逆性分析，表明了模型在更新知识的同时，能够保留原有知识，具有良好的稳定性和鲁棒性。


## Appendix C More Experimental Results



### C.1 Case Study（案例研究）

本节通过**案例研究**，分析了模型在顺序编辑后的生成效果。选择了**Counterfact**和**ZsRE**数据集中的样本，对多种编辑方法（MEMIT、PRUNE、RECT、AlphaEdit）进行了比较。

- **MEMIT、PRUNE、RECT**等基线方法在编辑后，要么**无法正确引入目标输出**，要么生成的文本**不连贯、不可读**，说明模型知识保留和生成能力大幅下降。
- **AlphaEdit**则**成功执行了编辑任务**，同时保持了生成文本的**高质量和连贯性**，在多个案例中表现优越。

#### C.1.1 Case 1（GPT2-XL模型）

- MEMIT输出的内容**重复、混乱**，PRUNE和RECT则生成了大量**无意义的重复字符串或语义无关的句子**。
- **AlphaEdit**输出了**结构合理、内容连贯**的文本，如推荐住宿地点、酒店位置等。

#### C.1.2 Case 2（GPT-J模型）

- MEMIT生成内容**不合逻辑**，语义跳跃严重。
- PRUNE输出的文本**包含大量无意义的拼写错误和不相关词汇**。
- **AlphaEdit**生成的内容**逻辑清晰、信息准确**，如描述从布加勒斯特出发的交通方式和时间。

#### C.1.3 Case 3（LLaMA3-8B模型）

- MEMIT和PRUNE输出的文本**重复、语义模糊**。
- RECT虽然语义稍好，但仍存在**重复和冗余**。
- **AlphaEdit**生成的内容**条理清晰、信息丰富**，如介绍布加勒斯特的机场和交通方式。

---

### C.2 General Capability Tests（通用能力测试）

- 本节测试了模型在**减少编辑批次数量**的情况下，通用任务性能的变化。
- 基线方法在顺序编辑后**快速退化**，而**AlphaEdit始终维持高水平表现**。
- 图8展示了在**SST、MRPC、CoLA、RTE、MMLU、NLI**六大任务上的**F1得分**，表明AlphaEdit具有更强的**鲁棒性**和**知识保留能力**。

---

### C.3 Quantification of Distribution Shift（分布偏移量化）

- 本节分析了编辑前后模型**隐藏表示的分布偏移程度**。
- 引入了**三个指标**进行评估：
  - **D1、D2**：衡量编辑前后分布的**重叠程度**。
  - **Hausdorff距离**：衡量两个分布之间的**最大距离**。
- 通过这些指标可以看出，**AlphaEdit优化的方法在编辑过程中分布偏移最小**，表明其在保留原始知识方面表现突出。

---

### C.4 Editing Facts involving Various Semantics（涉及多种语义的编辑）

- 本节评估了AlphaEdit在**不同语义类别**（如语言、地理、人物等）下的编辑效果。
- AlphaEdit在**多种语义类别中表现出色**，如语言相关的编辑达到**98%成功率**。
- 图10显示，AlphaEdit在**大部分语义类别上均显著优于基线方法**，即使在难编辑的语义类别中，AlphaEdit加入投影机制后仍能保持**超过90%的准确率**。

---

### C.5 Comparison between AlphaEdit and Memory-based Editing Methods（AlphaEdit与基于记忆的编辑方法对比）

- 对比了AlphaEdit与**SERAC、GRACE、MELO**等基于记忆的方法。
- **AlphaEdit在Efficacy（有效性）和Generalization（泛化能力）上显著领先**。
  - 例如，在GPT-J上，AlphaEdit在Counterfact任务中Efficacy达到**99.75**，远超SERAC和MELO。
- 在**Specificity（特异性）和Fluency（流畅性）**上，AlphaEdit虽略逊于某些基于记忆的方法，但整体表现平衡，具有更强的**通用性和稳定性**。
- 表2汇总了各模型在多个指标上的对比，突出了AlphaEdit的**综合优势**。

---

### C.6 Evaluation on Additional Base LLMs: Gemma and phi-1.5（在Gemma和phi-1.5模型上的评估）

- 本节将试验扩展到**Gemma**（目标为更小、更高效的模型）和**phi-1.5**。
- AlphaEdit在这些模型上依然表现出色：
  - 在Gemma上，AlphaEdit在**Fluency（398.96）**和**Consistency（32.91）**上表现最佳。
  - 在phi-1.5上，AlphaEdit在**Efficacy（70.79）**和**Fluency（399.47）**上表现突出。
- 表3展示了AlphaEdit在不同模型架构上的**适应性**和**稳定性**。

---

### C.7 Evaluation on Expanding Benchmark: KnowEdit, LEME and MQUAKE（在扩展基准上的评估）

- 本节在**KnowEdit（wiki_recent、wikibio）、LEME和MQUAKE**三个基准上评估AlphaEdit。
- AlphaEdit在**编辑成功率（Edit Success）**、**Portability（可移植性）**、**Locality（局部性）**和**Fluency**等指标上显著优于其他方法。
- 在**LEME**的长文本生成任务中，AlphaEdit在GPT-J和GPT2-XL上均表现出极高的**结构性和一致性**。
- 在**MQUAKE**的多跳推理任务中，AlphaEdit在**Multi-hop**和**Multi-hop (CoT)**任务中均大幅领先，表明其在**复杂推理和逻辑一致性**方面具有优势。

- 表4和表5详细展示了AlphaEdit在不同任务上的**数据对比**，进一步验证其**高效、稳定、泛化性强**的特点。


#### 总结

本附录通过多个角度评估了AlphaEdit的性能，包括**案例研究、通用能力测试、分布偏移分析、语义编辑能力、与记忆方法对比、模型扩展测试**等。结果一致表明，**AlphaEdit**在**准确性、稳定性、泛化能力、复杂推理任务处理能力**等方面全面优于现有方法，是一种**鲁棒性强、应用广泛的知识编辑方法**。


### C.8 Impact of Dataset Size on AlphaEdit’s Performance


本节研究了用于计算矩阵 **K₀** 的数据集大小对 AlphaEdit 性能的影响。实验通过逐步减少训练数据集的比例（从 100% 降到 10%），评估 AlphaEdit 在以下三个关键指标上的表现：

- **Efficacy（效果）**：模型对目标知识的修改效果
- **Generalization（泛化能力）**：模型在未见过的数据上的表现
- **Specificity（特异性）**：模型修改特定知识而不影响邻近知识的能力

**重点结论如下**：

1. **Efficacy 和 Generalization 表现稳定**：
   - 即使数据集减少到原大小的 10%，这两个指标的性能下降仍然很小（小于 5%），说明 AlphaEdit 在数据量减少时仍能保持高效和泛化能力。

2. **Specificity 明显下降**：
   - Specificity 在数据集减少到 10% 时下降了 11.76%，表明模型的“邻接知识存储能力”高度依赖于数据集的大小。

3. **实验模型与数据**：
   - 实验在多个基础模型（LLaMA3、GPT2-XL、GPT-J）和不同数据集（Counterfact、ZsRE）上进行。
   - 表格（Table 6）和图表（Figure 11）展示了详细的性能变化趋势，特别是在 LLaMA3 上的结果可视化。

4. **总体结论**：
   - AlphaEdit 在 Efficacy 和 Generalization 上具有良好的鲁棒性，但在 Specificity 方面较为敏感，需依赖足够大的数据集。

---

### C.9 AlphaEdit 的运行时评估

本节评估了 AlphaEdit 的计算效率，关注其运行时间与模型规模和知识库大小的关系。

**重点内容如下**：

1. **计算复杂度分析**：
   - AlphaEdit 的核心操作是 **null-space projection（零空间投影）**，其计算复杂度仅与模型的隐藏层维度 **d₀** 相关，而与模型层数、模型大小或知识库大小无关。
   - 这意味着 AlphaEdit 的计算效率高，不随模型规模扩大而显著增加。

2. **运行时间对比实验**：
   - 与 MEMIT 方法进行对比，在三种不同规模的模型（LLaMA3、GPT-J、GPT2-XL）上评估了执行 100 次编辑任务的平均耗时。
   - 实验结果显示，AlphaEdit 与 MEMIT 的运行时间几乎相同，表明 AlphaEdit 没有引入额外的开销。

3. **结论**：
   - AlphaEdit 在保持高性能的同时，具备良好的可扩展性，适用于大规模语言模型的知识编辑任务。

---

### 总结

- **C.8** 节明确指出 AlphaEdit 在 Efficacy 和 Generalization 上对数据集大小的依赖性较低，但 Specificity 对数据量敏感。
- **C.9** 节验证了 AlphaEdit 的高效性和可扩展性，证明其适用于不同规模的语言模型和知识编辑任务。
- 综上所述，AlphaEdit 是一种在性能和效率上都表现优异的知识编辑方法。


## Appendix D Visualizing the Counterfact and ZSRE Datasets Through Examples



### 重点内容讲解：

- **Counterfact 数据集**（图12）：
  - 该数据集用于对语言模型中已有的**事实性知识进行纠正或更新**。
  - 通过图12的示例，读者可以直观看到模型中哪些信息被修改了，以及修改后的结果是什么。
  - 示例强调了模型编辑任务的核心：**如何在不破坏原有知识的前提下，准确地更新错误或过时的知识**。

- **ZSRE 数据集**（图13）：
  - ZSRE（Zero-Shot Relation Extraction）是一个用于零样本关系抽取的数据集。
  - 示例展示了在该数据集中，模型需要根据**上下文推断实体之间的关系**，而不仅仅是记忆已有的事实。
  - 该数据集在编辑任务中用于测试模型的**泛化能力和关系推理能力**。

### 总结：

本附录通过图示方式，直观展示了 **Counterfact** 和 **ZSRE** 数据集在模型编辑任务中的应用。其重点在于帮助读者理解数据集中所包含的**事实性修改**和**关系推断**任务。这些示例对理解后续模型编辑方法的实验和评估具有重要意义。
