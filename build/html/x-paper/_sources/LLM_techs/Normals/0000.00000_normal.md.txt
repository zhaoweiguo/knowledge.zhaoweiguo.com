# 🏀常用

## 余弦退火


**余弦退火（Cosine Annealing）** 是一种**学习率调度策略**，核心思想是**让学习率随训练轮次以余弦函数的形式周期性衰减**，结合“重启（Restart）”机制跳出局部最优，广泛应用于深度学习和强化学习（如DQN、PPO等算法的学习率调整）。

它解决了传统固定学习率或线性衰减学习率的缺陷：固定学习率易在训练后期震荡不收敛，线性衰减学习率则可能过早进入局部最优。

---

### 一、核心原理
#### 1. 余弦学习率衰减公式
余弦退火的学习率更新规则基于**余弦函数的半周期**，公式为：
\[
\eta_t = \eta_{\text{min}} + \frac{1}{2} (\eta_{\text{max}} - \eta_{\text{min}}) \left( 1 + \cos\left( \frac{T_{\text{cur}}}{T_{\text{max}}} \pi \right) \right)
\]
其中：
- \( \eta_t \)：第 \( t \) 轮的学习率；
- \( \eta_{\text{max}} \)：学习率的最大值（初始学习率）；
- \( \eta_{\text{min}} \)：学习率的最小值（通常为 \( 0 \) 或一个很小的正数，如 \( 1e-6 \)）；
- \( T_{\text{cur}} \)：当前周期内的训练轮次（从 \( 0 \) 到 \( T_{\text{max}} \)）；
- \( T_{\text{max}} \)：单个周期的总训练轮次（即学习率从 \( \eta_{\text{max}} \) 衰减到 \( \eta_{\text{min}} \) 所需的轮次）。

#### 2. 公式直观理解
- 当 \( T_{\text{cur}} = 0 \) 时，\( \cos(0) = 1 \)，\( \eta_t = \eta_{\text{max}} \)（学习率最大）；
- 当 \( T_{\text{cur}} = T_{\text{max}} \) 时，\( \cos(\pi) = -1 \)，\( \eta_t = \eta_{\text{min}} \)（学习率最小）；
- 学习率的衰减曲线是**余弦函数的上半部分**，从最大值平滑下降到最小值，而非线性衰减的直线。

#### 3. 重启机制（Cosine Annealing with Restarts）
标准余弦退火的学习率衰减到最小值后会保持不变，而**带重启的余弦退火**（也叫SGDR，Stochastic Gradient Descent with Warm Restarts）会在学习率达到最小值时，**将学习率重置为 \( \eta_{\text{max}} \)，并开始新的周期**。

重启机制的作用：
- 学习率的突然重置相当于给模型“加热”，使其有机会跳出训练后期陷入的局部最优解；
- 后续周期的 \( T_{\text{max}} \) 可以设置为逐渐增大（如每次重启后乘以一个系数 \( T_{\text{mult}} > 1 \)），让模型在后期的训练中更稳定。

---

### 二、余弦退火的优势
1. **平滑衰减**：余弦函数的平滑性避免了学习率突变对模型训练的冲击，训练过程更稳定。
2. **跳出局部最优**：带重启的机制通过学习率的周期性重置，让模型在训练后期仍有能力探索更优的参数空间。
3. **自适应调整**：相比线性衰减，余弦退火在训练前期学习率下降较慢（保证快速收敛），后期下降较快（精细调整参数），更符合模型训练的规律。

---

### 三、与其他学习率调度策略的对比
| 策略类型       | 核心特点                     | 优势                     | 缺陷                     |
|----------------|------------------------------|--------------------------|--------------------------|
| **固定学习率** | 学习率始终不变               | 实现简单                 | 后期易震荡，难以收敛     |
| **线性衰减**   | 学习率随轮次线性下降         | 训练后期更稳定           | 衰减过快，易陷入局部最优 |
| **余弦退火**   | 学习率余弦平滑衰减，可重启   | 训练稳定，能跳出局部最优 | 需调参 \( T_{\text{max}} \) 和重启策略 |

---

### 四、在强化学习中的应用
余弦退火在强化学习中主要用于调整**策略网络/价值网络的学习率**，例如：
1. **DQN及其变种**：调整Q网络的学习率，避免训练后期Q值更新震荡，提高收敛速度。
2. **PPO（近端策略优化）**：调整策略网络和价值网络的学习率，通过重启机制让策略在后期仍有机会探索更优的动作选择。
3. **Q-Learning的学习率 \( \alpha \)**：传统Q-Learning的学习率 \( \alpha \) 通常固定或线性衰减，使用余弦退火可以让 \( \alpha \) 平滑衰减，提高Q表的收敛稳定性。

#### 示例：强化学习中的余弦退火学习率调度
假设训练总轮次为 \( 1000 \)，单个周期 \( T_{\text{max}} = 200 \)，\( \eta_{\text{max}} = 0.001 \)，\( \eta_{\text{min}} = 1e-6 \)，重启系数 \( T_{\text{mult}} = 2 \)：
- 第1个周期（轮次0-199）：学习率从0.001余弦衰减到1e-6；
- 第2个周期（轮次200-599）：\( T_{\text{max}} = 400 \)，学习率重置为0.001，再衰减到1e-6；
- 后续周期以此类推，直到训练结束。


### 核心总结
余弦退火是一种**高效的学习率调度策略**，通过**余弦函数的平滑衰减**保证训练稳定性，结合**重启机制**帮助模型跳出局部最优。它在深度学习和强化学习中均有广泛应用，是提升模型训练效果的重要技巧之一。




























