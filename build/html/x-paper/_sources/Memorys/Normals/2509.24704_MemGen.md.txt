(2509.24704)=
# 2509.24704_MemGen: Weaving Generative Latent Memory for Self-Evolving Agents



* 首页: <https://arxiv.org/abs/2509.24704>
* PDF: <https://arxiv.org/pdf/2509.24704>
* 引用: 3(2025-12-26)
* 组织:
    * National University of Singapore
* GitHub: <https://github.com/KANABOON1/MemGen>



## 总结


![](https://img.zhaoweiguo.com/uPic/2025/12/zGvFOk.jpg)

Figure 1 The comparison among parametric memory, retrieval-based memory and MemGen. 

![](https://img.zhaoweiguo.com/uPic/2025/12/t2iTSO.jpg)

Figure 2 The overview of our proposed MemGen.






## From Moonlight


### 三句摘要

1. 💡 MemGen提出了一种动态生成式latent memory框架，通过将记忆与推理过程紧密交织，以克服现有LLM agent memory系统在灵活性和整合性上的局限。
2. ⚙️ 该框架包含一个经RL训练的memory trigger，用于智能地判断何时触发记忆调用，以及一个memory weaver，负责生成machine-native的latent token sequence以丰富agent的实时推理状态。
3. 📈 MemGen在八个benchmark上实现了显著的性能提升，展现出强大的跨领域泛化能力和持续学习能力，并自发演化出类似人类的planning memory、procedural memory和working memory等记忆功能。


### 关键词

- MemGen: 是一种动态生成式记忆框架，旨在为大型语言模型（LLM）驱动的智能体提供一种更具人类特征的认知能力。它通过一个由强化学习训练的“记忆触发器”和一个“记忆编织器”协同工作，使得智能体能够在推理过程中按需生成和融入机器原生的潜在记忆（latent memory），从而实现推理与记忆的流畅交织和智能体能力的自我演进。
- Parametric Memory: 指的是一种将经验直接内化到智能体模型参数中的记忆范式。这种方法通过直接更新模型参数来存储和利用过去的经验，但可能导致灾难性遗忘（catastrophic forgetting），即在新知识的学习过程中，模型会丢失旧的知识。
- Retrieval-based Memory: 指的是一种将过去经验外部化并存储在结构化数据库中的记忆范式。智能体通过查询数据库来检索相关信息，然后将检索到的上下文信息提供给模型。这种方法避免了参数更新带来的灾难性遗忘，但其有效性依赖于复杂的上下文工程，并且通常缺乏与推理过程的流畅集成。
- Latent Memory: 指的是一种利用潜在状态（latent states）作为机器原生、高密度载体的记忆形式。它通过在模型的潜在空间中编码和表示经验，提供了一种比传统参数记忆或检索记忆更具柔性、更高效的记忆机制。MemGen 框架的核心就是利用这种潜在记忆。
- Memory Trigger: 是 MemGen 框架的组件之一，它充当一个元认知监视器，负责监测智能体推理过程中的认知状态。当识别到关键的思考时刻或需要记忆辅助时，它会决定是否调用记忆编织器来生成或检索记忆。其目标是在保持效率的同时，确保在关键节点进行记忆调用。
- Memory Weaver: 是 MemGen 框架的另一个核心组件，它负责根据智能体的当前状态（特别是触发器捕获的认知状态）来合成（synthesize）机器原生的潜在记忆（latent memory）。这个过程可能融合了智能体自身的参数化知识或外部检索的信息，并将这些信息整合成一个紧凑的、易于模型利用的潜在token序列。
- Reasoning: 指的是智能体进行思考、分析、推理以解决问题或做出决策的过程。MemGen 的关键创新在于实现了推理与记忆的“无缝交织”，即记忆的生成与融入是动态发生的，并与推理过程相互促进，形成一个循环。
- Cognition: 指的是智能体执行心智活动（如思考、学习、记忆、推理）的总体能力。MemGen 旨在赋予智能体一种更接近人类的“类人认知”（human-esque cognitive faculty），通过其动态的记忆生成和整合机制，模拟人类大脑中记忆与认知之间相互塑造的过程。
- Catastrophic Forgetting: 指的是在神经网络学习新任务或新数据时，遗忘之前学到的知识的现象。这是传统参数记忆方法（如微调）的一个主要缺点。MemGen 通过将新经验内化到记忆编织器而非核心推理器（reasoner）的参数中，旨在减轻或避免此问题。
- Cross-domain Generalization: 指的是智能体在不同类型或领域的任务上都能表现良好的能力。MemGen 在实验中被证明具有很强的跨领域泛化能力，即在某个领域的训练可以提升在其他领域的表现，或者即使在不同领域的数据上进行训练，其记忆机制也能有效地适应。
- Continual Learning: 指的是智能体在持续学习新任务或新数据时，能够保持对先前任务的性能，避免知识的遗忘。MemGen 通过其机制，如将知识存储在独立的记忆组件而非核心模型参数中，表现出更稳定的持续学习能力，减轻了灾难性遗忘。
- Planning Memory: 是 MemGen 在无显式监督的情况下，自发演化出的一种人类特有的记忆功能。它专门支持智能体进行高级任务规划和策略性推理，帮助模型分解复杂任务并序列化其推理步骤。
- Procedural Memory: 是 MemGen 自发演化出的另一种记忆功能。它负责存储和调用任务特定的操作性知识，例如工具的使用、API的调用、以及答案的格式化等具体执行技能，支持智能体高效地执行具体动作。
- Working Memory: 是 MemGen 自发演化出的记忆功能之一，它负责在当前任务会话中维持和有效利用先前的上下文信息，以保持推理的一致性和连贯性。它帮助智能体在较长的交互过程中不丢失关键信息。
- Latent Computation: 指的是一种利用潜在状态（latent states）来干预或重塑大型语言模型推理过程的计算范式。MemGen 将潜在记忆作为一种形式的潜在计算，用以增强推理能力。
- Reinforcement Learning (RL): 是一种机器学习方法，智能体通过与环境互动，根据收到的奖励信号来学习最优策略。MemGen 使用 RL 来训练其“记忆触发器”，使其学会何时最有效地调用记忆。


### 摘要

MemGen提出了一种名为MemGen的动态生成式记忆框架，旨在为大型语言模型（LLM）驱动的智能体（agent）提供类似人类的认知能力。它通过将推理与记忆合成紧密交织，克服了现有参数化记忆（parametric memory）和检索式记忆（retrieval-based memory）的局限性。

**问题背景与动机：**
现有智能体记忆范式存在显著缺陷：
1.  **参数化记忆**：直接修改模型参数，易导致灾难性遗忘（catastrophic forgetting）。
2.  **检索式记忆**：将经验存储于外部数据库，虽然避免了灾难性遗忘，但其效果受限于上下文工程，且无法实现记忆与推理的流畅、无缝集成。
3.  **现有隐式记忆（latent memory）**：主要关注长上下文处理或通过LLM参数更新存储经验，缺乏推理与记忆的无缝交织，且本质上仍是检索而非生成式的。
MemGen旨在解决“如何将智能体记忆设计为一种动态认知能力，使其能够与推理无缝地进行流动和重构”这一核心问题。

**核心方法（Methodology）：**
MemGen由两个协同组件构成：
1.  **记忆触发器（Memory Trigger，$T_{\text{trigger}}$）**：
    *   **功能**：作为元认知监控器，连续监测智能体的推理状态，判断何时需要显式调用记忆（即进行“反思”）。它决定在哪个时间点（token generation step）进行记忆插入。
    *   **实例化**： $T_{\text{trigger}}$被实现为一个轻量级的LoRA适配器（LoRA adapter），附着在冻结的推理核心LLM $\pi_\theta$上。
    *   **激活策略**：为避免过度的计算开销，采用句子粒度激活策略，即只在分界符（如逗号、句号）处考虑触发。
    *   **决策过程**：给定推理核心的当前隐藏状态序列 $H_{t,<j} = (h_{t,1}, \dots, h_{t,j-1})$，$T_{\text{trigger}}$ 计算调用概率 $p_j = \sigma(T_{\text{trigger}}(H_{t,<j}))$。然后，从中采样一个二元决策 $d_j \sim \text{Bernoulli}(p_j) \in \{\text{INVOKE, SKIP}\}$。
    *   **训练**：通过强化学习（RL）训练，具体采用了一种奖励自适应惩罚机制的rule-based RL，旨在鼓励稀疏而关键的记忆调用。目标函数最大化奖励 $R(\tau_i)$ 并惩罚不必要的激活：
        $\max_\phi \mathbb{E}_{\tau_i \sim \pi_\theta, \tilde{d} \sim T_\phi^{\text{trigger}}} \left[R(\tau_i) - \lambda \sum_{i,j} \max(0, \tilde{d}_{i,j} - \bar{p})\right]$
        其中，$\bar{p}$ 是高奖励轨迹中平均激活概率。

2.  **记忆编织器（Memory Weaver，$W_{\text{weaver}}$）**：
    *   **功能**：当$T_{\text{trigger}}$决定调用记忆时，$W_{\text{weaver}}$被唤醒。它以当前认知状态 $H_{t,<j}$ 作为刺激，生成一段简洁的、机器原生的隐式token序列 $M_t = [m_{t,1}, m_{t,2}, \dots, m_{t,K}]$ 作为记忆。这个过程是生成式的，类似人类大脑整合回忆片段。
    *   **实例化**： $W_{\text{weaver}}$也被实现为附着在 $\pi_\theta$ 上的另一个LoRA适配器。
    *   **生成过程**： $M_t := W_{\theta'}^{\text{weaver}}(H_{t,<j}) \in \mathbb{R}^{K \times d_{\text{model}}}$，其中$K$是固定长度，$\theta'$是可训练的LoRA参数。
    *   **记忆插入**：生成的隐式记忆 $M_t$ 被预置（prepended）到推理核心的当前隐藏状态 $H_{t,<j}$ 中。推理核心随后在该增强的上下文上恢复token生成：$z_{t,j} \sim \pi_\theta(\cdot | s_t, z_{t,<j}, M_t)$。
    *   **训练**：$W_{\text{weaver}}$的训练将经验知识内化到其参数 $\theta'$ 中，而冻结核心推理器 $\pi_\theta$。这确保了 $\pi_\theta$ 的通用能力不受影响，并有效缓解了灾难性遗忘。训练目标是最大化智能体在任务上的下游奖励。
        $\max_{\theta^{\text{lora}}} \mathbb{E}_{(x_i,\tau_i) \sim H} \mathbb{E}_{\tau \sim \Pi_{W_{\theta'},T_\theta}(\cdot|x_i)}[R(x_i, \tau)]$
        MemGen与多种优化策略兼容，如监督微调（SFT）或基于RL的方法（如GRPO）。在SFT场景下，优化目标是最大化专家轨迹的条件对数似然；在GRPO场景下， weaver通过组内相对奖励（group-relative reward）来更新。
    *   **与检索式记忆集成**：$W_{\text{weaver}}$ 可以结合外部检索到的文本记忆（textual memory）。检索到的信息会被编码为嵌入 $E_t$，并与当前隐藏状态 $H_{t,<j}$ 一起输入到 $W_{\text{weaver}}$ 中，即 $M_t = W_{\text{weaver}}([H_{t,<j}; E_t])$，从而提供更丰富的记忆支持。

**优势与发现：**
1.  **性能提升**：在八个基准测试中，MemGen显著超越了领先的外部记忆系统（如ExpeL、AWM）和强化学习方法（如GRPO）。
2.  **跨领域泛化**：MemGen学习到的记忆在不同任务领域之间表现出强大的泛化能力，例如在数学领域训练后，科学推理和代码生成性能也得到提升。这是因为记忆触发器能够智能地判断何时何地插入记忆，从而减少了领域冲突。
3.  **持续学习能力**：MemGen能够有效缓解灾难性遗忘，即使在多个新领域上进行微调后，也能保持在先前训练领域上的稳定性能。
4.  **涌现的人类记忆分层**：在没有显式监督的情况下，MemGen自发地演化出类似人类的记忆能力：
    *   **规划记忆（Planning Memory）**：支持高层任务规划和战略推理。
    *   **程序记忆（Procedural Memory）**：促进工具使用和答案格式化等任务特定操作技能的召回。
    *   **工作记忆（Working Memory）**：帮助智能体在长上下文环境中维持一致性和理解。
这些功能专业化表明MemGen赋予了智能体精确且功能独特的记忆。

**效率分析**：
MemGen的记忆插入过程不会引入显著的推理开销。尽管实现了高达57.66%的性能提升，但每次查询的推理延迟仍保持在原始LLM延迟的24%至94%之间。

**结论**：
MemGen通过强化学习驱动的记忆触发器和生成式记忆编织器，实现了推理与记忆合成的紧密交织。它超越了现有记忆范式的局限性，展现出显著的性能提升、强大的跨领域泛化和持续学习能力，并自发形成了类似人类的记忆分层结构，为自演化LLM智能体迈向更自然形式的机器认知提供了有前景的路径。



## From Deepseek&OpenAI

### 一、研究背景与动机

当前LLM智能体在记忆机制上存在两类主流方法：
1. **参数化记忆**：通过微调更新模型参数，易导致**灾难性遗忘**。
2. **检索式记忆**：将经验存储在外部数据库中，但缺乏与推理过程的深度融合。

现有方法未能实现**推理与记忆的动态交织**，而这正是人类认知的关键特征。


### 二、MemGen 核心思想

```note
MemGen 把“记忆”从「事前准备 / 事后检索」变成了「推理过程中随时生成、随时介入的潜在结构」。记忆不是被“取出来”的，而是在当前思考状态下被“重新生成”的。

核心哲学：
人类的认知不是“先检索全部记忆，再推理”，而是“推理与记忆在过程中不断相互塑造”。MemGen 的核心目标就是让机器模拟这种交织（Interleaving）过程。

```

MemGen 模拟人类认知中的“推理-记忆”动态交互过程，通过两个核心组件实现：

**1. 记忆触发器（Memory Trigger）**
- 基于强化学习训练，监控智能体的推理状态。
- 在关键时刻决定是否调用记忆，实现**选择性记忆激活**。
- 仅在语义边界（如句号、逗号）处触发，保持效率。

**2. 记忆编织器（Memory Weaver）**
- 接收当前推理状态作为输入，**生成潜记忆序列**。
- 记忆以**潜在嵌入向量**形式存在，是机器原生、人类不可读的。
- 支持与外部检索系统结合，融合内部参数知识与外部信息。
- 输入：
    - 当前 hidden states（思考状态）
    - 可选 外部检索内容
- 输出：
    - 一个固定长度的 latent token 序列
    - 直接插进模型内部计算图(拼接 / 融合进当前 hidden state，继续送入后续 Transformer 层)


```note
确类比海马体：海马体在回忆时不是“播放录像”，而是根据当前语境重建记忆。
Weaver 不是在存“内容”，而是在学习 功能性结构。
```

和记忆检索最大的结构差异
```
RAG / MemoryBank：
query → embedding → similarity → text → prompt

Memory Weaver：
hidden state → latent generator → latent memory → hidden state
```



### 三、MemGen 核心优势

| 优势 | 说明 |
|------|------|
| **性能提升显著** | 在多个基准测试中超越现有方法，如 ALFWorld 提升 31.7% |
| **跨领域泛化强** | 在一个领域训练后，在其他领域仍能提升性能（如数学训练提升科学推理6.06%） |
| **持续学习能力强** | 有效缓解灾难性遗忘，保持对旧任务的表现 |
| **记忆功能自组织** | 无监督地演化出类人的记忆层次结构（计划记忆、程序记忆、工作记忆） |


### 四、实验验证

✅ **主要实验设置**
- **模型**：Qwen2.5-1.5B、SmoLLM3-3B、Qwen3-8B
- **基准数据集**：ALFWorld、TriviaQA、GSM8K、KodCode、MATH 等 9 个数据集
- **对比方法**：包括参数化记忆、检索式记忆、潜在计算等多种基线

✅ **关键发现**
1. **MemGen 在所有任务中均优于基线**，尤其在推理密集型任务中表现突出。
2. **记忆触发器能智能判断何时调用记忆**，在不同任务中调用频率不同。
3. **潜在记忆序列具有结构化聚类特征**，不同聚类对应不同功能（计划、程序、工作记忆）。

---

### 五、记忆功能分析

通过干预研究发现，MemGen 自发演化出三种类人记忆：

| 记忆类型 | 功能 | 实验表现 |
|----------|------|----------|
| **计划记忆** | 支持高层任务规划和策略推理 | 移除后规划错误显著增加 |
| **程序记忆** | 存储任务相关操作知识（如工具使用） | 移除后工具调用和格式错误增加 |
| **工作记忆** | 维持上下文一致性和理解 | 移除后任务理解和行为一致性下降 |


### 六、效率分析

MemGen 在显著提升性能的同时，**未引入显著推理延迟**，推理时间仍低于或接近基线模型。


### 七、总结与意义

MemGen 提出了一种**生成式、动态交织的记忆机制**，推动LLM智能体向更自然、更自适应的认知系统演进。其核心贡献包括：

- ✅ 提出**生成式潜记忆框架**，实现推理与记忆的动态融合
- ✅ 通过**记忆触发器与编织器**实现智能记忆调用与生成
- ✅ 展示**跨领域泛化与持续学习能力**
- ✅ 揭示**记忆功能的自组织演化现象**


### 八、可进一步思考的问题

1. **记忆的可解释性**：如何让潜在记忆更透明、更可解释？
2. **多模态记忆扩展**：是否可扩展到视觉、语音等模态？
3. **记忆压缩与长期存储**：如何更高效地存储和管理长期记忆？
4. **记忆与情感/动机的结合**：如何让记忆系统更具“人性化”？























