# 2511.00xxx_MemMachine

* 首页: <https://memmachine.ai/>
* GitHub: <https://github.com/MemMachine/MemMachine>




## 主要内容

### 记忆类型

* 情景记忆 (Episodic Memory)​	
    * 记录具体的交互事件和对话历史（如“用户昨天询问了天气”），带有时间戳，保证对话的连续性。	
    * 就像你的日记本，记录了“某时某地发生了某事”。
* 语义记忆 (Semantic Memory)​	
    * 存储从交互中提炼出的结构化知识和事实（如“用户是软件工程师，擅长Python”），形成知识图谱。	
    * 就像你的个人百科，存储了关于你和世界的客观事实。
* 档案记忆 (Archival Memory)​	
    * 构建持续的用户画像，存储个人偏好、习惯和身份等长期信息（如“用户偏好简洁回答，喜欢在早上喝咖啡”）。	
    * 就像你的个性名片，定义了你的喜好、习惯和身份。
* 程序记忆 (Procedural Memory)​	
    * 保存智能体可重复使用的操作步骤、技能和方法（如解决问题的标准化流程），提高效率。	
    * 就像你的技能手册，记录了“如何完成某项任务”的固定流程。


### 记忆检索

1. 混合检索​	
    * 广泛“撒网”，初步召回相关记忆。	
    * 向量检索 + 关键词检索​ 并行工作。	
    * 兼顾语义理解与精确匹配，避免单一检索的盲区。
2. 分数归一化​	
    * 统一不同检索方式的结果评分标准。	
    * Min-Max归一化​ 等算法。	
    * 使来自不同算法的分数具有可比性，为融合做准备。如：将向量检索和关键词检索得到的分数统一映射到0到1之间的可比较范围内。
3. 加权融合​	
    * 将初步结果智能合并成一个列表。	
    * 可配置权重​ (如向量70%，关键词30%)。	
    * 根据场景调整侧重点，形成更优的综合排序。
    * 计算每个记忆片段的最终综合得分。这个权重可以根据场景调整，比如在需要高度精确匹配的领域，可以调高关键词检索的权重。
4. 智能重排序​	
    * 对融合结果进行最终微调，提升顶部精度。	
    * 交叉编码器、BM25、RRF​ 等算法。	
    * 进行更精细的上下文理解，将最相关结果推到最前。
        * BM25​	基于关键词的统计概率模型，计算查询中每个词项与记忆内容的相关性得分。	充当“精准匹配专家”，确保包含明确关键词的记忆获得基础高分。
        * 交叉编码器​	深度神经网络模型，将查询和记忆片段一同分析，直接输出相关性概率分数。	充当“语义理解裁判”，深度理解上下文，精准判断真实相关性。
        * RRF（互惠排名融合）​	一种混合排序算法，将多个排名列表智能地融合成一个更优的最终列表。	充当“智慧决策者”，平衡不同方法的优势，提升结果的鲁棒性。


#### 重排序

**重排序的必要性**
* MemMachine首先通过混合检索策略，从海量记忆中初步筛选出可能相关的记忆。然而，这个初步列表可能存在两个问题：首先，列表可能仍然很长；其次，排名靠前的记忆未必是最相关的。比如，一些只是频繁提到关键词但实际帮助不大的记忆可能排名靠前。因此，重排序的作用就像一个智能过滤器，对初步结果进行精细调整，优先选择最有可能帮助AI生成准确及相关响应的上下文。


**MemMachine采用了多种重排序方法**
* BM25：
    - 关键词匹配的基石BM25是一种经典的信息检索算法。
    - 它主要计算查询中的关键词与记忆文本之间的匹配程度，但它比简单计数更智能，会考虑词频、逆文档频率等因素，自动给予区分度高的关键词更高权重。
    - 作用：为包含确切关键词的记忆提供较高的基础分数，保证基础的检索精度。
    - 特点：速度快，适合处理大规模数据，但对同义词和语义变化不敏感。
* 交叉编码器：
    - 深度语义的裁判为了解决BM25在语义理解上的局限，MemMachine引入了基于Transformer的交叉编码器。
    - 与BM25的“快速评判”不同，交叉编码器进行的是“深度分析”。
    - 工作原理：
        - 它将用户的查询和一个记忆片段同时输入模型，让模型分析两者之间的交互特征，直接输出一个代表相关性的概率分数（例如0.85表示高度相关）。
        - 这种方式能理解语言的细微差别。
    - 特点：精度极高，能深刻理解语义，但计算成本高、速度慢，通常只对Top K（如前20或50条）的初步结果进行重排序。
* RRF
    - 采用RRF这类算法将BM25和交叉编码器等不同方法产生的排名列表智能地融合起来。
    - 工作原理：
        - RRF为每个记忆片段在每个列表中的排名分配一个分数（例如，排名第一的得1/（1+1）=0.5，排名第二的得1/（1+2）≈0.33，以此类推），
        - 然后将每个记忆在所有列表中的得分相加，最后按总分进行重新排名。
    - 优势：
        - 这种机制确保了即使某个方法判断失误，另一个方法也可以进行纠正。
        - 例如，一个记忆在BM25列表中排名靠后，但被交叉编码器判为高度相关，它的RRF总分依然可能跃升到前列，从而提高了结果的鲁棒性和准确性。


**工作流程**

1. 初步检索：通过混合检索获得一个较长的相关记忆列表。
2. 精细重排：使用交叉编码器对这个列表的Top K结果进行深度语义分析并重排。
3. 结果融合：利用RRF等算法将BM25的初始得分与交叉编码器的新得分融合，产生最终排名。
4. 最终筛选：系统会根据最终排名，选择最顶部的若干条记忆（如Top 3或Top 5）注入到AI的上下文窗口中。














