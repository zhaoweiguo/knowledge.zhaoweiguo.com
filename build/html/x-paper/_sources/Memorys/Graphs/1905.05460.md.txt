# 1905.05460_Cognitive Graph for Multi-Hop Reading Comprehension at Scale

* 首页: <https://arxiv.org/abs/1905.05460>
* PDF: <https://arxiv.org/pdf/1905.05460>



## Abstract

本章节提出了一个名为 **CogQA** 的新框架，用于在**大规模网页文档**中进行**多跳问答**（multi-hop question answering）。该框架基于**认知科学中的双过程理论**（dual process theory），通过协调两个模块——**隐式抽取模块**（System 1，对应直觉式快速思考）和**显式推理模块**（System 2，对应逻辑性慢思考）——在**迭代过程中逐步构建认知图谱**（cognitive graph）。

该框架的亮点在于：
- **可解释性强**：不仅能给出准确答案，还能提供**可解释的推理路径**。
- **高效处理大规模数据**：基于 BERT 和图神经网络（GNN）实现，能够处理 **HotpotQA fullwiki 数据集**中的**数百万文档**。
- **性能领先**：在 HotpotQA 排行榜上取得了 **34.9 的联合 F1 分数**，远超最佳竞品的 23.6。

总结：CogQA 是一个结合认知科学理论与深度学习技术的新颖多跳问答框架，具备高准确率、强解释性，并能高效处理大规模文档。


## 1 Introduction

本节介绍了当前深度学习在机器阅读理解领域的发展现状及面临的三大挑战，并提出了基于人类认知过程的解决方案——CogQA框架。

---

### 1.1 当前进展

- 深度学习模型在机器阅读理解方面取得了显著进展，甚至在单段落问答任务（如SQuAD）上表现超过人类。

---

### 1.2 三大挑战（重点）

#### 1）推理能力（Reasoning Ability）

- **问题**：现有单段落问答模型在对抗测试中表现出依赖问题与句子的表面匹配，缺乏复杂推理能力。
- **趋势**：多跳问答（multi-hop QA）成为下一个关键挑战，要求模型在多个信息片段之间进行推理。

#### 2）可解释性（Explainability）

- **现状**：如HotpotQA数据集要求模型提供支持句子，属于无序、句子级别的解释。
- **人类对比**：人类能通过逐步推理解释答案，体现为有序、实体级别的解释。
- **目标**：构建具有实体级、有序解释能力的系统。

#### 3）可扩展性（Scalability）

- **当前方法**：多数系统采用“检索-抽取”框架（如DrQA），通过预检索缩小信息源范围。
- **局限性**：这种框架是单段落问答与大规模信息检索之间的折中方案。
- **人类对比**：人类能在大规模知识库中快速推理，系统需提升扩展性以接近这一能力。

---

### 1.3 灵感来源：人类认知过程（重点）

- **双过程理论（Dual Process Theory）**：
  - **系统1（System 1）**：快速、直觉、无意识，用于初步检索相关信息。
  - **系统2（System 2）**：慢速、有意识、可控，用于深度推理。
  - **协作机制**：两个系统交替工作，实现“快慢思维”结合。

---

### 1.4 提出的解决方案：CogQA框架（重点）

- **核心思想**：模仿人类双系统认知机制。
  - **系统1**：从段落中提取与问题相关的实体和答案候选，并编码语义信息。
  - **系统2**：在构建的“认知图谱（Cognitive Graph）”上进行推理，引导系统1提取下一步实体。
- **迭代机制**：不断更新图谱，直到找到所有可能答案，最终由系统2确定答案。
- **实现方式**：基于BERT和图神经网络（GNN）实现。

---

### 1.5 主要贡献（重点）

1. 提出**CogQA框架**，用于大规模多跳阅读理解任务，模拟人类认知过程。
2. 引入**认知图谱结构**，提供有序、实体级别的解释能力，适合关系推理。
3. 实验表明，该方法在多个指标上显著优于现有方法。

---

### 图1说明（简要）

- 展示了一个多跳问答中的认知图谱示例。
- 图中节点代表实体及其介绍段落，边表示实体之间的推理联系。
- 正确推理路径用实线表示，模拟人类逐步推理过程。


## 2 Cognitive Graph QA Framework

### 标题不变：**2 Cognitive Graph QA Framework**

---

### 概述

本节介绍了一个基于**认知图谱**（Cognitive Graph）的多跳问答（Multi-hop QA）框架，称为 **CogQA**。该框架模拟人类的双系统认知机制：

- **System 1**：快速提取信息（如实体、答案候选、跳转节点）；
- **System 2**：基于图结构进行深度推理，更新节点表示。

整个过程通过构建一个显式的图结构（即认知图谱），逐步扩展并更新节点的语义表示，最终通过预测器 ℱ 选出最佳答案。

---

### 算法流程（Algorithm 1）

#### 输入：
- System 1 模型 𝒮₁
- System 2 模型 𝒮₂
- 问题 Q
- 预测器 ℱ
- 维基数据库 𝒲

#### 输出：
- 最佳答案节点（通过 ℱ 在图中选择得分最高的答案节点）

---

### 核心步骤详解：

#### **1. 初始化认知图谱 𝒢**
- 从问题 Q 中提取提到的实体作为初始节点；
- 将这些节点标记为“前沿节点”（frontier nodes），即下一步要处理的节点。

#### **2. 图谱扩展与推理迭代**
- **循环处理前沿节点 x**，直到没有前沿节点或图谱足够大。

##### **步骤详解：**

- **3-4**：取出一个前沿节点 x，并从其前驱节点中收集线索 clues[x, 𝒢]（如包含 x 的句子）。
- **5**：在数据库 𝒲 中查找 x 对应的段落 para[x]。
- **6**：使用 System 1 模型 𝒮₁ 生成 x 的初始语义表示 sem[x, Q, clues]。
- **7-21**：如果 x 是跳转节点（hop node）：
  - **8**：使用 𝒮₁ 从 para[x] 中提取跳转实体和答案候选。
  - **9-16**：遍历跳转实体 y：
    - **10-11**：若 y 不在图中但存在于数据库中，创建新跳转节点；
    - **12-14**：若 y 在图中但与 x 无边，则添加边并标记 y 为前沿节点。
  - **17-19**：遍历答案实体 y，添加答案节点和边 (x, y)。
- **22**：使用 System 2 模型 𝒮₂ 更新图中节点的隐藏表示 𝐗。
- **23**：循环终止条件：图中无前沿节点或图谱已足够大。

#### **最终输出：**
- 使用预测器 ℱ 对所有答案节点打分，返回得分最高的答案节点。

---

### 框架特点（重点讲解）

#### ✅ **1. 可解释性（Explainability）**
- 认知图谱 𝒢 显式记录了推理路径，包括：
  - 简单路径（simple paths）
  - 联合路径（joint reasoning）
  - 循环路径（loopy reasoning）
- “线索”（clues）是来自前驱节点的信息，用于指导 System 1 更好地提取实体和跳转节点。
- 所有新增节点或新增入边的节点都会被重新访问，以利用新线索。

#### ✅ **2. 可扩展性（Scalability）**
- 时间复杂度不随段落数量显著增长；
- 仅需通过标题索引访问特定段落，而非遍历所有段落；
- 相比传统检索-抽取框架，CogQA 能发现语义相关但关键词无关的远距离段落，避免信息遗漏。

---

### 实现示意图（Figure 2）

图中展示了 CogQA 的整体流程：

- **System 1**：
  - 接收线索 clues[x, 𝒢] 和问题 Q；
  - 从 para[x] 中提取跳转节点和答案节点；
  - 生成初始语义表示 sem[x, Q, clues]。

- **System 2**：
  - 基于图结构 𝒢 更新节点表示 𝐗；
  - 为后续节点提供新的线索 clues[y, 𝒢]。

---

### 总结

CogQA 框架通过构建**认知图谱**，结合快速提取（System 1）与深度推理（System 2），实现了**多跳问答**任务中的高效、可解释、可扩展的推理过程。其核心优势在于：

- **显式图结构**支持复杂推理路径；
- **双系统机制**分离提取与推理；
- **迭代扩展机制**确保信息不遗漏；
- **可解释性强**，便于分析推理过程；
- **可扩展性好**，适用于大规模语料库。

该框架为多跳阅读理解任务提供了一个结构清晰、逻辑严谨的建模思路。


## 3 Implementation

本章主要介绍 **CogQA 框架的具体实现方式**，包括 System 1 和 System 2 的模型选择、clues 的形式，以及训练策略。

---

### 3.1 System 1

**System 1 的核心功能是提取信息以构建认知图**，因此需要一个强大的模型。作者选择 **BERT** 作为 System 1。

- **输入结构**：  
  BERT 的输入由三部分组成：
  - [CLS] + 问题（Question）
  - [SEP] + clues（来自前驱节点的句子）
  - [SEP] + 当前节点对应的段落（Para[x]）

  > 其中，clues 是原始句子，而非隐藏状态，这样可以解耦不同迭代步骤的训练，提高效率。

- **输出与表示**：  
  BERT 输出的向量记为 𝐓 ∈ ℝ^{L×H}，其中 L 是输入长度，H 是隐藏层维度。

- **Span Extraction（关键部分）**：
  - 使用“pointer vectors”（可学习参数）来预测答案和下一跳实体的起始和结束位置。
  - 通过 softmax 计算每个 token 作为起始/结束位置的概率。
  - 对于答案 span，只保留 top-K 的起始位置，并在一定范围内寻找最佳结束位置。
  - 使用 [CLS] 的输出作为负样本阈值，过滤掉低概率的 span。

- **Semantics Generation（语义生成）**：
  - 虽然 [CLS] 的输出可以用于语义表示，但实验发现使用倒数第三层的 [CLS] 输出效果最好。

---

### 3.2 System 2

**System 2 的功能是处理认知图结构，更新节点表示**，采用 **GNN（图神经网络）** 实现。

- **Clues 的生成**：
  - clues[x, 𝒢] 是当前节点 x 的前驱节点中提到 x 的原始句子。

- **GNN 的设计**：
  - 初始节点表示 𝐗[x] 来自 System 1 的语义向量。
  - 使用一种 GNN 变体进行传播更新，公式如下：
    - Δ = σ((AD⁻¹)ᵀ σ(𝐗W₁))
    - 𝐗′ = σ(𝐗W₂ + Δ)
  - A 是图的邻接矩阵，D 是度矩阵，AD⁻¹ 是列归一化的邻接矩阵。
  - 这种设计借鉴了图卷积网络的局部谱滤波思想。

- **更新方式**：
  - 实验中采用异步更新（每次访问节点时更新），但发现与最终统一更新效果相当，因此采用更高效的统一更新方式。

---

### 3.3 Predictor

**预测模块根据问题类型设计不同的下游任务**：

- **Special Question（特殊问题）**：
  - 需要从段落中提取答案 span。
  - 使用两层全连接网络（FCN）预测答案节点。

- **Alternative & General Question（选择与一般问题）**：
  - 需要比较两个实体的属性。
  - 输入为两个节点表示的差值 𝐗[x] - 𝐗[y]，使用两个相同的 FCN 分别处理。

---

### 3.4 Training

**训练采用监督学习方式，包含两个主要任务**：

#### 3.4.1 Task #1: Span Extraction

- **目标**：训练 System 1 提取答案和下一跳实体的 span。
- **数据构建**：
  - 每个段落对应一个 span 列表 𝒟[x, Q]，包含实体名和起止位置。
- **损失函数**：
  - 使用交叉熵损失 ℒ_ans^start/end 和 ℒ_hop^start/end。
  - 对于负样本，使用 [CLS] 的输出作为负阈值，其起始位置概率为 1。

#### 3.4.2 Task #2: Answer Node Prediction

- **目标**：训练模型从认知图中识别正确答案节点。
- **训练样本构建**：
  - 每个问题构建一个“黄金图”（包含所有正确推理路径）和若干负样本节点。
- **损失函数**：
  - 对 special question 使用 softmax + 交叉熵。
  - 对 alternative 和 general question 使用二分类交叉熵。
- **反向传播**：
  - 损失不仅优化预测器和 System 2，还通过语义向量 fine-tune System 1。

---

### 总结

本章详细介绍了 CogQA 框架的实现细节：

- **System 1 使用 BERT 提取 span 和语义表示**，强调了 span 提取的指针机制和负样本处理。
- **System 2 使用 GNN 更新图节点表示**，通过图结构进行语义传播。
- **预测模块根据问题类型设计不同任务**，包括 span 提取、实体比较等。
- **训练采用多任务监督学习**，包含 span 提取和答案节点预测两个任务，且损失反向传播至整个模型。

整体实现强调了 **模块化设计、图结构建模、高效训练策略**，是实现多跳阅读理解的关键。


## 4 Experiment


### 4.1 数据集
本研究使用了HotpotQA的full-wiki设置进行实验。该数据集包含112,779个问题，其中84%需要多跳推理。数据集被划分为训练集（90,564个问题）、开发集（7,405个问题）和测试集（7,405个问题）。开发集和测试集中的问题均为多跳推理难题。

在训练集中，每个问题提供一个答案以及两个黄金实体的段落，并标注了多个支持事实（即包含关键信息的句子）。此外，还有8个无用的负段落用于训练。在评估阶段，仅提供问题，同时要求模型输出答案和支持事实。

为了构建认知图谱，研究通过模糊匹配（基于Levenshtein距离）从支持事实中推断出图中的边。如果某个支持事实中包含的实体或答案与某个黄金实体模糊匹配，则添加一条边。

---

### 4.2 实验细节
系统1中使用了预训练的BERT-base模型（Devlin et al., 2018），隐藏层大小为768，GNN和预测器中也保持不变。模型中所有激活函数为gelu。训练分为两个阶段：第一阶段仅训练任务#1，第二阶段联合训练任务#1和#2。训练中的超参数如下：

| 模型 | 任务 | 批量大小 | 学习率 | 权重衰减 |
| --- | --- | --- | --- | --- |
| BERT | #1, #2 | 10 | 1e-4, 4e-5 | 0.01 |
| GNN | #2 | 图 | 1e-4 | 0 |

BERT和GNN分别使用不同的Adam优化器（β1=0.9, β2=0.999），预测器与GNN共享优化器。BERT的学习率在前10%的训练步骤中线性预热，之后线性衰减至0。

支持事实的选取基于图中节点的clues中的句子。在图初始化时，1-hop实体通过模糊匹配从训练集中提取。研究还将1-hop实体的提取独立为一个BERT模型，以便在其他模型中复用。

---

### 4.3 基线模型
实验对比了多个模型，分为两类：**已有模型** 和 **消融实验模型**。

#### 已有模型
- **Yang et al. (2018)**：HotpotQA原始论文提出的强基线模型，基于DrQA的检索-抽取框架，结合了自注意力、字符级模型、双向注意力等技术。
- **GRN, QFE, DecompRC, MultiQA**：HotpotQA排行榜上的其他未发表模型。
- **BERT**：单跳QA的SOTA模型。由于BERT输入限制为单段落，研究通过认知图谱扩展段落内容。
- **Yang et al. (2018)-IR**：改进检索的版本，通过加入1-hop实体，将支持事实覆盖率从56%提升至72%。

#### 消融实验模型
- **CogQA-onlyR**：使用与Yang et al. (2018)相同的1-hop实体初始化图，用于公平比较。
- **CogQA-onlyQ**：仅使用问题中的1-hop实体初始化图，不依赖检索。
- **CogQA-sys1**：仅保留系统1，缺乏系统2的级联推理。

---

### 4.4 实验结果

#### 总体性能
CogQA在所有指标上显著优于其他基线模型（见表1）。其优势主要来自于认知图谱框架优于传统检索-抽取方法。传统方法在面对多跳推理时，因缺乏推理线索而难以找到相关段落，而CogQA通过逐步发现相关实体进行推理。

#### 逻辑严谨性
通过计算“JointEM / AnsEM”比例，评估模型推理的逻辑严谨性。CogQA的比例达到33.4%，远高于Yang et al. (2018)的7.9%和QFE的30.3%。

#### 多跳推理
图3展示了CogQA在8种不同跳数问题上的表现。随着跳数增加，Yang et al. (2018)和Yang et al. (2018)-IR性能显著下降，而CogQA表现稳健。但在某些问题（如选择题和一般问题）上无明显提升，因为缺乏监督信号。

#### 消融实验
- **CogQA-onlyR**：即使使用相同的初始实体，仍显著优于Yang et al. (2018)，说明CogQA框架本身具有优势。
- **CogQA-onlyQ**：不依赖检索，仅使用问题中的实体，仍优于所有基线模型，说明CogQA框架优于传统检索-抽取方法。
- **BERT**：虽然BERT是必要组件，但单独使用时表现与Yang et al. (2018)相当或略差，说明提升主要来自框架而非BERT本身。
- **CogQA-sys1**：仅使用系统1，性能下降约50%，说明系统2的GNN推理能力对结果至关重要。

#### 案例分析
图4展示了CogQA在不同问题中的推理过程：
- **案例1**：通过“Senate”与“upper house”的语义相似性正确选择答案。
- **案例2**：通过并行推理路径增强答案的鲁棒性。
- **案例3**：在无实体提及的语义检索问题中，CogQA结合信息检索找到答案“Marijus Adomaitis”，尽管标注答案为“Ten Walls”，但模型通过认知图谱回溯发现“Ten Walls”的真实姓名，说明其推理过程具有可解释性。

---

总结：CogQA通过认知图谱框架在多跳阅读理解任务中表现出色，尤其在逻辑严谨性和多跳推理方面显著优于传统方法。


## 5 Related work


### 机器阅读理解（Machine Reading Comprehension）
本节指出，机器阅读理解（MRC）的研究重点已从早期的完形填空式任务（如 Hermann 等，2015；Hill 等，2015）逐渐转向更复杂的问答任务（如 Rajpurkar 等，2016）。与传统的计算语言学流程相比，神经网络模型（如 BiDAF 和 R-net）在文本中提取答案方面表现出更强的能力。近年来，基于 BERT 的预训练模型在大规模语料上训练后，在单段落的 MRC-QA 任务上几乎达到了超越人类水平的表现，这促使研究者将注意力转向**多跳推理**（multi-hop reasoning）这一更具挑战性的方向。

> **重点内容**：BERT 等模型在单段落任务中已接近“解决”，推动研究转向更复杂的多跳推理任务。

---

### 多跳问答（Multi-Hop QA）
早期的多跳问答数据集要么基于有限的知识图谱结构（如 Talmor 和 Berant，2018），要么是多选题形式（如 Welbl 等，2018），这些数据集存在噪声问题，限制了该领域的发展。直到高质量的 HotpotQA 数据集（Yang 等，2018）发布，才为多跳推理研究提供了更坚实的基础。

此外，"多步推理" 的理念也催生了单段落问答中的**多轮方法**（multi-turn methods），如 Kumar 等（2016）、Seo 等（2017b）、Shen 等（2017）提出的方法，这些方法通过多次阅读文本，试图让模型隐式地捕捉更深层次的信息。

> **重点内容**：HotpotQA 是推动多跳问答发展的关键数据集；多轮方法尝试模拟多跳推理过程。

---

### 开放域问答（Open-Domain QA）
开放域问答（Open-Domain QA）指的是支持证据的搜索空间非常大的问答任务。段落级别的答案提取方法在信息检索领域已有长期研究，最早可追溯至 1990 年代（如 Belkin，1993；Voorhees 等，1999；Moldovan 等，2000）。

近年来，DrQA（Chen 等，2017）结合神经网络模型与检索机制，提出了“检索-抽取”框架（retrieval-extraction framework），极大推动了这一传统研究方向的发展。后续研究通过启发式采样（Clark 和 Gardner，2018）或强化学习（Hu 等，2018；Wang 等，2018a）来提升检索效果。然而，对于复杂推理任务，该框架的改进仍显不足。

> **重点内容**：“检索-抽取”框架是当前开放域问答的核心方法；复杂推理任务仍需框架层面的创新。

--- 

### 总结结构对照：
| 原标题 | 内容简述 | 是否重点 |
|--------|----------|----------|
| Machine Reading Comprehension | MRC 从完形填空转向 QA，BERT 推动发展 | ✅ 是 |
| Multi-Hop QA | 多跳 QA 数据集演进与多轮方法 | ✅ 是 |
| Open-Domain QA | 开放域问答的发展与检索-抽取框架 | ✅ 是 |


## 6 Discussion and Conclusion


**CogQA框架的贡献与成果：**  
作者提出了一种新的多跳机器阅读理解框架CogQA，其推理过程以“认知图谱”的形式组织，实现了前所未有的**实体级可解释性**。基于BERT和GNN的实现，在HotpotQA数据集上取得了**最先进的结果**，验证了该框架的有效性。

**未来研究方向：**  
1. **提升System 2的可靠性**：由于认知图谱具有明确的结构，System 2可以借助**神经逻辑技术**（neural logic techniques）来增强推理的稳定性和可解释性。
2. **优化System 1的能力**：未来的架构若能结合**注意力机制与循环机制**，有望显著提升System 1的表现，并优化两个系统之间的交互。
3. **拓展应用领域**：作者认为CogQA框架具有良好的泛化能力，可应用于其他认知任务，如**对话式AI**和**序列推荐系统**等。

### 小结：
本节强调了CogQA在多跳推理任务中的创新性和有效性，并从结构优化、模型设计和应用扩展三个方面提出了有前景的未来研究方向。重点在于其**可解释性**和**系统协同机制**的提升潜力。
