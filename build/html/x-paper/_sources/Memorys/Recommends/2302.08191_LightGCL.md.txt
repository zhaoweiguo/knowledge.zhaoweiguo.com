# 2302.08191_LightGCL: Simple Yet Effective Graph Contrastive Learning for Recommendation

* 首页: <https://arxiv.org/abs/2302.08191>
* PDF: <https://arxiv.org/pdf/2302.08191>
* 引入: 428(2025-09-12)
* 组织:
    * University of Hong Kong
* GitHub: <https://github.com/HKUDS/LightGCL>


## 总结


**研究背景**

1. **图神经网络在推荐系统中的成功**：
    * 将用户-物品交互数据视为一个二分图，利用GNN来聚合邻居信息，可以有效地学习用户和物品的嵌入表示，从而进行精准推荐。
2. **对比学习的引入**：
    * 为了缓解数据稀疏性问题（即大多数用户只有很少的交互记录），对比学习被引入到GNN中。
    * 其核心思想是通过对图进行随机扰动（如随机丢弃边或节点）来创建同一个图的多个“视图”，然后训练模型让同一个节点在不同视图中的表示尽量相似，不同节点的表示尽量不同。这能增强模型的鲁棒性。
3. **现有方法的缺陷**：
    * **计算瓶颈**：大多数方法（如SimGCL, SGL）需要为每个训练批次构建两个完整的增强视图，并进行对比学习，这带来了巨大的计算和内存开销。
    * **不可控的噪声**：随机丢弃边或节点可能会破坏图中重要的连接（例如，一个用户只交互过几次，丢弃其中一条边就会损失大量信息），引入有害的噪声，影响模型性能。

**核心思想**
* LightGCL 提出了一个非常巧妙的解决方案：
    * 与其通过随机扰动这种“不可控”的方式来创建对比视图，不如直接创建一个“平滑且全局”的对比视图，这个视图能从全局结构中提取最有益的信息。
* 具体来说，它利用**奇异值分解（SVD）** 来生成一个高质量的对比视图。
    * SVD可以从原始交互图中提取出最重要的全局结构模式，这个生成的视图既保留了图的核心信息，又自然地对噪声进行了平滑处理。


**关键技术方法**
1. 总体架构
   * LightGCL 的架构图通常包含三个部分：
   * **原始视图**：基于原始用户-物品交互图，使用轻量化的GNN（如LightGCN，只进行邻居聚合，没有复杂的变换和非线性激活）来生成一组嵌入。
   * **SVD增强视图**：对归一化的交互矩阵进行**低秩奇异值分解**，生成一个“平滑”的图结构，并在此基础上进行图卷积，生成另一组嵌入。
   * **对比学习**：在每个视图内部（例如，原始视图的用户嵌入和SVD视图的用户嵌入之间）进行对比学习。

2. 核心创新点：基于SVD的图增强
   * **Step 1: 构建归一化邻接矩阵**
       将用户-物品交互矩阵 `R` 转化为一个大的邻接矩阵 `A`。

   * **Step 2: 对邻接矩阵进行奇异值分解**
       对矩阵 `A` 进行SVD： `A = U Σ V^T`
       * `U` 和 `V` 是酉矩阵，包含了用户和物品的特征向量。
       * `Σ` 是一个对角矩阵，对角线上的奇异值从大到小排列，代表了不同成分的重要性。

   * **Step 3: 低秩重构（关键步骤）**
       只保留前 `k` 个最大的奇异值及其对应的特征向量，用它们来重构一个新的、平滑的邻接矩阵 `Â`：
       `Â = U_{：， ：k} Σ_{：k， ：k} V_{：， ：k}^T`
       * **为什么有效？**：最大的奇异值对应的成分捕获了图中最显著、最全局的关联模式（例如，大众流行的趋势）。而较小的奇异值通常对应于噪声或非常局部的细节。通过保留最重要的成分，`Â` 就像一个“去噪”和“平滑”版本的原始图，它强调了全局一致性结构。

   * **Step 4: 在平滑图上进行传播**
       将这个重构的矩阵 `Â` 作为增强视图的邻接矩阵，进行图卷积操作，得到用户和物品在增强视图下的嵌入。

**高效性体现**

* **不需要完全SVD**：
    * 完全SVD的计算成本是 `O(n^3)`，对于大规模推荐系统是不可行的。
    * 但LightGCL不需要计算完整的SVD，它只需要前 `k` 个最大的奇异值和向量。
    * 这可以通过高效的**随机SVD算法**来实现，其复杂度是线性的，远低于完全SVD。
* **一次性计算**：
    * 与每个训练周期都要进行随机增强的方法不同，SVD增强视图的矩阵 `Â` 是**离线计算**的。
    * 一旦算好，在整个训练过程中都可以重复使用，极大地降低了训练时的开销。

**对比学习目标**
* 模型结合了两个损失函数：
    * **主任务损失（Bayesian Personalized Ranking Loss）**：用于衡量推荐的主要目标，即用户对正样本物品（交互过的）的预测分数应高于负样本物品（未交互过的）。
    * **对比学习损失（InfoNCE Loss）**：让同一个用户在原始视图和SVD视图中的表示相互靠近，而与不同用户的表示相互远离。对物品也进行同样的操作。

**实验结论与优势**
1. **性能领先**：LightGCL 的性能显著优于传统的GNN模型（如NGCF, LightGCN）和当时的对比学习模型（如SGL, SimGCL）。
2. **效率极高**：由于SVD的离线计算和轻量化的GNN主干，LightGCL 的训练速度比SimGCL等模型快得多，同时内存消耗也更低。
3. **鲁棒性强**：特别是在数据稀疏的场景下，由于SVD视图提供了可靠的全局信息，LightGCL 表现出了更强的鲁棒性。
4. **超参数简单**：模型对超参数（如对比损失权重）不敏感，更容易调优。最重要的超参数是SVD的秩 `k`，论文发现 `k` 不需要很大就能取得很好效果。

**总结**
* LightGCL 的核心贡献在于，它用一种“优雅”且“高效”的数学工具（SVD）替代了“粗暴”且“昂贵”的随机增强策略，为图对比学习提供了高质量的信息来源。
    * **Simple**：它的思想直接——用SVD获取全局结构作为增强视图。
    * **Effective**：它不仅在性能上取得了突破，还解决了计算效率的瓶颈。
    * **Elegant**：它将线性代数中的经典方法巧妙地应用于解决现代深度学习中的问题。
* 因此，这篇论文被认为是图对比学习推荐领域的一个里程碑式的工作，为后续研究提供了新的思路。



## Abstract



**Graph neural network (GNN)** 是一种用于基于图的推荐系统的强大学习方法。近年来，结合对比学习（contrastive learning, CL）的GNN在推荐任务中表现出色，其关键在于通过**数据增强方案**来应对高度稀疏的数据问题。

尽管取得了一定成功，大多数现有的图对比学习方法要么在用户-项目交互图上执行**随机增强**（如节点/边扰动），要么依赖于**基于启发式的方法**（如用户聚类）来生成对比视图。作者认为，这些方法无法很好地保留图的**内在语义结构**，并且容易受到**噪声扰动**的影响。

为了解决这些问题，本文提出了一种简单而有效的图对比学习范式 **LightGCL**，旨在提升基于CL的推荐系统的**普遍性**和**鲁棒性**。该模型**唯一使用奇异值分解（SVD）**进行对比增强，从而实现了在**全局协作关系建模**下的**不受约束的结构优化**。

实验在多个基准数据集上进行，结果表明，LightGCL 在性能上显著优于现有最先进的方法。进一步的分析表明，LightGCL 在应对**数据稀疏性**和**流行度偏差**方面具有优越的鲁棒性。



## 1 Introduction



本节主要介绍了图神经网络（GNN）在基于图的推荐系统中的有效性，并指出现有图对比学习（GCL）方法在实际应用中面临的关键挑战，同时提出了本文的解决方案——LightGCL。

---

### 1.1 GNN 在推荐系统中的应用

图神经网络通过在用户-物品交互图上进行**嵌入传播**，能够提取**局部协同信号**来学习用户和物品的表示。通常，GNN 推荐系统通过堆叠多个**消息传递层**，探索高阶连接性来增强表示效果。然而，这类方法通常依赖于**大量高质量的标注数据**，而现实中的推荐场景常面临**数据稀疏性问题**，限制了模型性能的提升。

为了解决**标注数据稀缺**的问题，近年来**对比学习**（Contrastive Learning）被引入推荐系统，通过**数据增强**生成不同的视图（views），并利用**正负样本对的对比**来增强表示学习。其核心目标是让模型在多个视图之间学习一致的用户和物品表示。

---

### 1.2 现有图对比学习方法的局限性

尽管对比学习在图推荐中表现良好，但现有方法仍存在以下**关键问题**：

1. **图增强依赖随机扰动**，如节点删除、边扰动等，容易导致**有用结构信息的丢失**，进而影响表示质量。
2. **视图生成依赖启发式策略**（如随机噪声扰动），限制了模型的**泛化能力**，且对**用户行为中的噪声敏感**。
3. **GNN 对比推荐系统面临过平滑问题**（over-smoothing），导致节点表示变得难以区分。

---

### 1.3 本文的解决方案：LightGCL

为了解决上述问题，本文提出了一种**轻量且稳健的图对比学习方法 LightGCL**，其主要创新包括：

- **图增强由 SVD 引导**，不仅保留用户-物品交互中的**有用信息**，还引入**全局协同关系**，增强对比学习中的表示对齐。
- **无需手动设计两个增强视图**，通过鲁棒的对比学习范式，保留用户项交互的关键语义，使得表示能够反映**用户特定偏好**与**跨用户全局依赖**。

---

### 1.4 本文贡献

本文的主要贡献包括：

1. 提出一个**轻量且稳健的图对比学习框架**，有效应对数据稀疏性和图增强不稳定的问题。
2. 提出 LightGCL 方法，通过注入**全局协同关系**，缓解对比信号不准确的问题。
3. **训练效率更高**，优于现有基于 GCL 的方法。
4. 在多个真实数据集上的**广泛实验验证**表明，LightGCL 在性能上具有优势，**深入分析**也证明了其合理性和鲁棒性。

---

总结而言，本节指出当前图对比推荐方法的不足，并提出 LightGCL 作为改进方案，强调其在**鲁棒性、效率和性能**上的优势。


## 2 Related Work



### Graph Contrastive Learning for Recommendation（图对比学习在推荐中的应用）

近年来，有研究将对比学习（Contrastive Learning, CL）引入基于图的推荐系统，以利用自监督信号来缓解标签稀疏的问题。其中，SGL（Wu 等，2021）和 SimGCL（Yu 等，2022a）通过在图结构和嵌入上随机丢弃节点或边来进行数据增强。然而，这种随机增强方式可能会丢失关键信息，尤其对于不活跃用户（即交互数据本就稀疏的用户）来说，可能使稀疏问题更严重。

此外，一些新的基于对比学习的推荐方法，如 HCCF（Xia 等，2022b）和 NCL（Lin 等，2022），尝试通过启发式策略来构造对比视图（contrastive views）。尽管这些方法在实验中表现良好，但它们的成功高度依赖于所设计的启发式规则（例如超边数量或用户聚类数），而这些规则难以适应不同的推荐任务，泛化性较差。

### Self-Supervised Learning on Graphs（图上的自监督学习）

近年来，自监督学习（Self-Supervised Learning, SSL）通过从无标签的图数据中学习节点表示，推动了图学习的发展。例如，AutoSSL（Jin 等，2022）通过自动组合多个预训练任务来增强图表示学习的效果。

在基于图结构的对比式自监督学习方面，研究人员提出了多种方法。例如，SimGRACE（Xia 等，2022a）通过扰动 GNN 编码器来生成对比视图。AutoGCL（Yin 等，2022）则设计了与图编码器端到端联合训练的图视图生成器。此外，GCA（Zhu 等，2021b）从拓扑层和属性层同时进行数据增强，能够识别出重要的边和特征用于自适应增强。GraphCL（You 等，2020）则使用多种增强策略（如节点/边扰动和属性掩码）来生成相关性强的图表示视图。

**重点总结**：

- 图对比学习被广泛用于缓解推荐系统中的数据稀疏问题。
- 随机增强（如节点/边丢弃）可能导致重要信息丢失，尤其是对不活跃用户。
- 启发式方法（如 HCCF、NCL）虽然有效，但缺乏灵活性和适应性。
- 自监督学习在图结构中的应用（如 AutoSSL、SimGRACE、GCA、GraphCL）通过多种增强策略提升表示学习效果，其中 GCA 和 GraphCL 在自适应增强和多策略融合方面有一定优势。


## 3 Methodology

![](https://img.zhaoweiguo.com/uPic/2025/09/YzP91i.jpg)

Figure 1: Overall structure of LightGCL.


在这一部分，我们详细描述了我们提出的 **LightGCL** 框架。LightGCL 是一种轻量的图对比学习方法，如图 1 所示。该框架通过 GCN（图卷积网络）提取局部图依赖关系，同时通过 SVD（奇异值分解）引导的增强方法进行全局协作关系分析，从而学习有效的用户和物品表示。

---

### 3.1 局部图依赖建模

作为协同过滤的常用做法，我们为每个用户 $ u_i $ 和物品 $ v_j $ 分配嵌入向量 $ {\mathbf{e}}_{i}^{(u)}, {\mathbf{e}}_{j}^{(v)} \in \mathbb{R}^d $，其中 $ d $ 是嵌入维度。所有用户和物品嵌入的集合分别表示为 $ {\mathbf{E}}^{(u)} \in \mathbb{R}^{I \times d} $ 和 $ {\mathbf{E}}^{(v)} \in \mathbb{R}^{J \times d} $，其中 $ I $ 和 $ J $ 分别是用户和物品的数量。

我们采用两层 GCN 来聚合每个节点的邻居信息。在第 $ l $ 层，聚合过程如下：

$$
{\mathbf{z}}_{i,l}^{(u)} = \sigma(p(\tilde{\mathcal{A}}_{i,:}) \cdot {\mathbf{E}}_{l-1}^{(v)}), \quad
{\mathbf{z}}_{j,l}^{(v)} = \sigma(p(\tilde{\mathcal{A}}_{:,j}) \cdot {\mathbf{E}}_{l-1}^{(u)})
$$

- $ {\mathbf{z}}_{i,l}^{(u)} $、 $ {\mathbf{z}}_{j,l}^{(v)} $：表示第 $ l $ 层对用户和物品的嵌入聚合；
- $ \sigma(\cdot) $ 是激活函数（此处为恒等函数）；
- $ \tilde{\mathcal{A}} $ 是归一化的邻接矩阵，使用 $ p(\cdot) $ 进行边丢弃，以缓解过拟合问题。

最终嵌入是所有层的嵌入之和。用户 $ u_i $ 与物品 $ v_j $ 之间的内积预测 $ u_i $ 对 $ v_j $ 的偏好：

$$
{\mathbf{e}}_{i}^{(u)} = \sum_{l=0}^{L} {\mathbf{z}}_{i,l}^{(u)}, \quad
{\mathbf{e}}_{j}^{(v)} = \sum_{l=0}^{L} {\mathbf{z}}_{j,l}^{(v)}, \quad
\hat{y}_{i,j} = ({\mathbf{e}}_{i}^{(u)})^{\top} {\mathbf{e}}_{j}^{(v)}
$$

---

### 3.2 高效的全局协作关系学习

为了增强推荐的图对比学习能力，我们引入 SVD 方法（Rajwade et al., 2012; Rangarajan, 2001）来高效提取全局协作关系的关键信号。具体来说，我们对归一化的邻接矩阵 $ \tilde{\mathcal{A}} $ 进行 SVD：

$$
\tilde{\mathcal{A}} = {\mathbf{U}} {\mathbf{S}} {\mathbf{V}}^{\top}
$$

我们保留前 $ q $ 个最大的奇异值，以低秩方式重构邻接矩阵 $ \hat{\mathcal{A}} = {\mathbf{U}}_q {\mathbf{S}}_q {\mathbf{V}}_q^{\top} $。该方法的优势在于：

- 识别重要且可靠的用户-物品交互；
- 保留所有用户-物品对的全局协作信号。

由于精确的 SVD 在大规模矩阵上效率低下，我们采用 Halko 等人提出的随机 SVD 算法，先用低秩正交矩阵近似输入矩阵的范围，再计算 SVD。用近似矩阵进行消息传播：

$$
{\mathbf{g}}_{i,l}^{(u)} = \sigma(\hat{\mathcal{A}}_{i,:} \cdot {\mathbf{E}}_{l-1}^{(v)}), \quad
{\mathbf{g}}_{j,l}^{(v)} = \sigma(\hat{\mathcal{A}}_{:,j} \cdot {\mathbf{E}}_{l-1}^{(u)})
$$

通过预计算 $ ({\mathbf{U}}_q {\mathbf{S}}_q) $ 和 $ ({\mathbf{V}}_q {\mathbf{S}}_q) $，可以显著提高模型效率。

---

### 3.3 简化的局部-全局对比学习

传统图对比学习方法（如 SGL、SimGCL）通常使用三个视图进行对比，而我们的方法由于使用了基于 SVD 的增强图结构，能够直接对比原始图（主视图）嵌入与增强视图嵌入，避免了繁琐的多视图范式。

我们在 InfoNCE 损失函数中对比 SVD 增强视图嵌入 $ {\mathbf{g}}_{i,l}^{(u)} $ 与主视图嵌入 $ {\mathbf{z}}_{i,l}^{(u)} $：

$$
\mathcal{L}_{s}^{(u)} = \sum_{i=0}^{I} \sum_{l=0}^{L} -\log \frac{\exp(s({\mathbf{z}}_{i,l}^{(u)}, {\mathbf{g}}_{i,l}^{(u)}/\tau))}{\sum_{i'=0}^{I} \exp(s({\mathbf{z}}_{i,l}^{(u)}, {\mathbf{g}}_{i',l}^{(u)}/\tau))}
$$

- $ s(\cdot) $ 是余弦相似度；
- $ \tau $ 是温度参数；
- 对物品也采用相同的损失函数。

为了防止过拟合，我们在每批次中实现随机节点丢弃。最终的损失函数结合了推荐任务的主目标函数和对比损失：

$$
\mathcal{L} = \mathcal{L}_{r} + \lambda_1 \cdot (\mathcal{L}_{s}^{(u)} + \mathcal{L}_{s}^{(v)}) + \lambda_2 \cdot \|\Theta\|_2^2
$$

其中，$ \mathcal{L}_r $ 是推荐任务的目标函数：

$$
\mathcal{L}_r = \sum_{i=0}^{I} \sum_{s=1}^{S} \max(0, 1 - \hat{y}_{i,p_s} + \hat{y}_{i,n_s})
$$

- $ \hat{y}_{i,p_s} $、$ \hat{y}_{i,n_s} $：用户 $ i $ 对正样本和负样本的预测评分。

---

### 总结重点

- **LightGCL 的核心思想**：通过轻量的图对比学习，融合局部 GCN 与全局 SVD，提升推荐效果。
- **关键技术**：
  - **GCN**：提取局部图依赖；
  - **SVD**：提取全局协作关系；
  - **InfoNCE 对比损失**：简化多视图对比学习，提高模型效率。
- **优化策略**：使用随机 SVD、节点丢弃等技术，防止过拟合并提升模型性能。


## 4 Evaluation



本节通过广泛的实验验证了 **LightGCL** 方法的优越性和有效性，旨在回答以下五个研究问题：

---

### **RQ1：LightGCL 在不同数据集上的表现如何？**

通过在五个实际数据集（Yelp、Gowalla、ML-10M、Amazon-book、Tmall）上与16种最先进的基线方法进行比较，评估 LightGCL 的推荐性能。使用 **Recall@20/40** 和 **NDCG@20/40** 作为评估指标。实验结果显示：

- **对比学习方法（Contrastive Learning, CL）整体表现优于传统方法**，如 LightGCN、HyRec 等。
- **LightGCL 在所有基准中表现最好**，尤其在数据稀疏性和流行度偏倚方面表现出色。
- LightGCL 的性能提升来源于其**全局协作上下文信号的有效增强**，避免了传统自监督学习方法中常见的噪声干扰。

---

### **RQ2：轻量级图对比学习如何提升模型效率？**

LightGCL 通过**简化对比学习结构**和**低秩 SVD 图重构**，大幅降低了计算复杂度。主要结论如下：

- **预处理阶段的 SVD 计算成本较低**，且只需进行一次。
- **LightGCL 的训练复杂度低于现有高效模型（如 SimGCL）**，因为其只构造两个对比视图，而其他方法通常构造三个。
- LightGCL 的训练时间复杂度为 **O[2q(I+J)Ld]**，其中 q 为 SVD 的低秩，通常远小于原始边数 E。

---

### **RQ3：模型如何应对数据稀疏性和流行度偏倚？**

通过分析用户交互次数的不同稀疏度组，以及长尾项目的推荐表现，评估模型在极端稀疏和流行度偏差下的鲁棒性。

- **LightGCL 在稀疏用户组表现优异**，Recall@20 比整体性能下降较小，甚至在某些数据集（如 Gowalla）上表现更好。
- **LightGCL 在缓解流行度偏差方面优于 HCCF 和 SimGCL**，能够为长尾物品提供更公平的推荐。
- **LightGCL 的嵌入分布平衡了“过平滑”和“过均匀”问题**，在 t-SNE 可视化和 MAD 指标上表现良好。

---

### **RQ4：局部-全局对比学习如何贡献模型性能？**

通过消融实验，验证 LightGCL 中 SVD 图增强的有效性。实验设计包括：

- **CL-MF**：使用预训练的矩阵分解（MF）生成对比视图；
- **CL-SVD++**：使用 SVD++ 方法生成视图。

结果表明：

- **SVD 重构的图结构效果最好**，优于 MF 和 SVD++，说明 LightGCL 的 SVD 图增强设计是有效的。
- **LightGCL 的灵活性较高**，能够适应不同的图结构增强方法。

---

### **RQ5：不同参数设置如何影响模型性能？**

对关键超参数进行分析，包括：

- **λ₁（InfoNCE 损失的正则化权重）**：在 10⁻⁷ 时性能最佳，10⁻⁶~10⁻⁸ 范围内也表现良好。
- **τ（温度参数）**：对性能影响较小，最佳值因数据集而异。
- **q（SVD 的秩）**：q=5 已能保留图结构的关键信息，较小的 q 就足以取得良好效果。

---

### **案例研究（Case Study）**

通过 Yelp 数据集中一个用户的实际推荐案例，可视化展示 LightGCL 的图重构能力。结果显示：

- **模型能识别用户在不同地区的兴趣社区**（如居住地 Cleveland 和旅行地 Arizona）。
- **SVD 重构图能为未观测到的潜在兴趣项（如 #2647、#658）赋予高权重**，从而推荐那些被主流兴趣掩盖的小众项目。
- **模型对噪声交互不敏感**，能有效过滤不合理的推荐（如租租车点多次访问）。

---

### 总结

LightGCL 通过引入**高效且轻量的图对比学习框架**，在多个实际数据集上展现出卓越的推荐性能。相比传统方法和现有 CL 方法，它在以下方面具有显著优势：

- **性能优势**：在 Recall 和 NDCG 等指标上优于所有基线。
- **效率优势**：通过 SVD 图重构和结构简化，降低了训练成本。
- **鲁棒性优势**：在数据稀疏性和流行度偏差下仍能保持高推荐质量。
- **灵活性优势**：支持多种图结构增强方法，具备良好的可扩展性。

该方法为图神经网络在推荐系统中的高效应用提供了新的思路。


## 5 Conclusion


在本文中，作者提出了一种**简单且有效的图对比学习框架增强方法**，用于推荐系统。该方法的核心思想是**通过增强图结构来提升推荐效果**，特别是通过**奇异值分解（SVD）**来增强用户-项目交互图的结构。这是文章的重点内容，说明了作者在图结构增强方面的创新点。

**关键发现**表明，提出的图增强方案在**应对数据稀疏性和流行度偏差问题上表现出色**，这是推荐系统中常见的挑战。这也突出了该方法的实用价值和有效性。

**大量实验结果**表明，所提出的模型在多个公开评估数据集上**取得了最先进的性能**，这是本文的核心成果之一，也证明了方法的有效性。

在**未来的工作**中，作者计划探索将**因果分析**引入当前的轻量级图对比学习模型中，以进一步增强推荐系统的效果，尤其是在**缓解数据增强中的混杂效应**方面。这是文章的延伸方向，但相对于核心贡献来说，属于次要内容。


## Appendix A Details of the Baselines



该部分介绍了本文实验中所比较的多种推荐系统基线方法，主要分为以下几类：**基于MLP的协同过滤、基于GNN的协同过滤、解耦图协同过滤、基于超图的协同过滤、以及自监督学习推荐系统**。以下是对每类方法及其代表模型的重点总结。

---

### **1. MLP-enhanced Collaborative Filtering（基于MLP的协同过滤）**

- **NCF**（Neural Collaborative Filtering）：
  - 使用神经网络来挖掘协同过滤中的非线性关系。
  - 在本实验中，使用了两个隐藏层进行评估。
  - **重点**：NCF 模型通过神经网络建模用户和物品之间的交互模式，是传统协同过滤的现代扩展。

---

### **2. GNN-based Collaborative Filtering（基于GNN的协同过滤）**

- **GCCF**（Graph Convolutional Collaborative Filtering）：
  - 在GNN基础上引入残差结构，以缓解信息传播过程中的退化问题。
  - 减少非线性变换，以提升模型稳定性。
  
- **LightGCN**：
  - 对GCN结构进行了简化，**不再使用嵌入权重矩阵和非线性投影**。
  - **重点**：LightGCN 通过纯粹的图邻接传播实现高效的用户-物品关系建模，是当前图协同过滤的代表性模型之一。

---

### **3. Disentangled Graph Collaborative Filtering（解耦图协同过滤）**

- **DGCF**（Disentangled Graph Collaborative Filtering）：
  - 将用户和物品的嵌入向量**拆分为多个潜在意图**，从而学习更复杂的表示。
  - **重点**：该方法关注用户和物品之间的多维度关系，提升推荐的细粒度和可解释性。

---

### **4. Hypergraph-based Collaborative Filtering（基于超图的协同过滤）**

- **HyRec**：
  - 使用**超图结构**来捕捉用户与物品之间高阶的交互信息。
  - **重点**：相比传统图结构，超图能够建模多对多的复杂关系，适用于高阶关系建模。

---

### **5. Self-Supervised Learning Recommender Systems（自监督学习推荐系统）**

该部分详细列出了多种基于图的自监督学习方法，它们通过不同方式生成对比视图，并利用对比学习优化图表示。

- **GraphCL**：
  - 通过**随机节点删除和边掩盖**生成两个对比视图。
  - **重点**：对比视图通过SSL损失函数对齐，增强图表示的鲁棒性。

- **GRACE**：
  - 通过**随机边丢弃和节点特征丢弃**破坏图结构，生成对比视图。
  - **重点**：通过不同方式破坏图结构，提升模型对图的结构和内容的感知能力。

- **GCA**（Graph Contrastive Augmentation）：
  - 根据节点中心性**自适应地丢弃节点和边**。
  - **重点**：通过重要性驱动的增强方式提升生成视图的代表性。

- **MHCN**（Multi-Head Contrastive Network）：
  - 使用**图信息最大化网络**生成自监督信号，用于图表示学习。

- **SAIL**：
  - 通过最大化**GNN生成的高阶特征与输入特征之间的预测概率**来提升表示能力。

- **AutoGCL**：
  - 使用GNN**自动学习如何遮蔽节点和边**。
  - **重点**：通过最小化增强图与原图之间的相似度，同时最大化其生成嵌入的相似度，从而挖掘图中关键信息。

- **SimGRACE**：
  - 通过**随机扰动GNN参数**生成对比视图。
  - **重点**：简化增强过程，提高计算效率。

- **SGL**（Simple Graph contrastive Learning）：
  - 通过**随机游走采样和边/节点丢弃**生成对比视图。
  - **实验中使用了SGL-ED变体**，即只进行边丢弃，表现最优。

- **HCCF**（Hypergraph Contrastive Collaborative Filtering）：
  - 使用**超图编码全局信息**，并与其局部GCN编码信息进行对比。
  - **实验中设置超边数量为128**。

- **SHT**（Self-attention Hypergraph Transformer）：
  - 采用**超图变换器框架**，挖掘全局协同关系。
  - **通过知识蒸馏生成跨视图的自监督信号**。
  - **实验中设置超边数量为128**。

- **SimGCL**：
  - 通过**直接在特征表示中注入随机噪声**简化对比学习的增强过程。
  - **重点**：相比复杂增强方法，更简单高效，适用于资源受限场景。

---

### **总结**

本附录系统地介绍了各类推荐系统基线方法，涵盖了从传统协同过滤（如NCF）到现代图神经网络（如LightGCN、GCCF），再到更复杂的自监督学习方法（如GraphCL、GCA、SGL、SHT等）。其中，**自监督学习方法在实验设置中占据了较大比例**，反映了当前研究趋势中对数据增强、对比学习和图表示学习的关注。**重点方法包括LightGCN、SGL、HCCF、SHT等**，它们在参数设置或增强策略上各有特点，适合不同场景下的对比实验。


## Appendix B Performance Comparison with Baselines (Continued)


本附录展示了由于空间限制未在表1中展示的模型性能，这些模型包括 NCF、GCCF、GraphCL、SAIL、GRACE 和 AutoGCL。结果总结在表5中。从表中可以看出，我们的模型 LightGCL 在所有测试数据集上表现均优于这些基线模型。

### 表 5：在五个数据集上与基线模型的性能比较（续）

表中列出了五个数据集（Yelp、Gowalla、ML-10M、Amazon、Tmall）的性能指标：R@20、N@20、R@40 和 N@40。每种模型的数值越接近 1 表示性能越好。从整体来看，LightGCL 在所有数据集上均取得了最佳表现，表明其在图对比学习推荐系统中的优越性。

**重点总结：**

- **LightGCL 的表现突出**：相比 NCF、GCCF、GraphCL、SAIL、GRACE 和 AutoGCL，LightGCL 在所有指标和数据集上的表现更优，体现了其简单而有效的方法设计。
- **数据集多样性**：测试覆盖了多个实际推荐系统常用的数据集，结果具有代表性。
- **指标全面**：使用了 R@20、N@20、R@40、N@40 等多种指标，全面评估了模型的推荐性能。

**次要内容简述：**

- 各个基线模型的数值在数据集之间存在差异，但整体上 LightGCL 的性能优势明显，说明其具有较好的泛化能力。
- 例如，在 ML-10M 数据集上，LightGCL 在 R@20 和 N@20 的表现分别为 0.2613 和 0.3106，远高于其他模型。


## Appendix C Theoretical Analysis



本节对本文提出的**局部-全局对比学习（Local-Global CL）**进行了理论分析，说明其如何通过**基于奇异值分解（SVD）的全局关系学习**来增强节点表示。重点在于如何通过梯度传播机制，将原本未直接连接的潜在相关节点的嵌入拉近，从而提升模型效果。

---

### 节点定义与对比学习的局限性

- 对于一个节点 $ v_j \in \mathcal{U} $，其中集合 $ \mathcal{U} = \{u_{i'} \mid \mathcal{A}_{i,i'} = 0, \hat{\mathcal{A}}_{i,i'} \neq 0\} $，表示的是那些与 $ u_i $ 原本无边连接，但在重建的图 $ \hat{\mathcal{A}} $ 中被预测为邻接的节点。
- 在传统的 InfoNCE 损失中，这些节点 $ v_j $ 由于不与 $ u_i $ 直接连接，因此**不会参与梯度更新**，即 $ s(\mathbf{z}_{i,l}, \mathbf{g}_{i,l}) $ 中不会对其嵌入产生影响。

---

### 本文方法的改进

- 不同于传统方法，**本文的局部-全局对比学习方法为这些未连接但潜在相关的节点 $ v_j $ 赋予了梯度更新**。
- 具体来说，通过以下梯度传播公式：

$$
\frac{\partial s(\mathbf{z}_{i,l}, \mathbf{g}_{i,l})}{\partial \mathbf{g}_{j,l-1}} = \frac{\mathbf{z}_{i,l}}{\|\mathbf{z}_{i,l}\|\|\mathbf{g}_{i,l}\|} \cdot \sigma'(\cdot) \cdot \alpha_{i,j}
$$

- 上式表明，**节点 $ v_j $ 的嵌入也会受到 $ s(\mathbf{z}_{i,l}, \mathbf{g}_{i,l}) $ 的梯度影响**，使得其与 $ u_i $ 的嵌入更加相似。
- 这里的 $ \alpha_{i,j} $ 是一个归一化权重，用于衡量 $ u_i $ 与 $ v_j $ 之间的潜在相关性。

---

### 核心理论贡献

- 通过**SVD 等全局结构信息**，本文将原本未连通的节点视为**潜在相关节点**，并将其纳入对比学习的梯度更新过程中。
- 这种机制有效注入了**全局关系信息到局部嵌入表示中**，从而提升了推荐模型的表达能力与泛化性能。
- 相较于传统方法，这种方式更加全面地利用了图结构信息，尤其是在稀疏图中具有显著优势。

---

### 总结

- **本文通过理论分析，证明了局部-全局对比学习在 SVD 基础上的有效性**。
- **关键点在于对非邻接但潜在相关的节点嵌入进行梯度更新**，从而实现更优的表示学习。
- 这种方法不仅保留了局部结构信息，还融合了全局关系，是推荐系统中图对比学习的重要改进。


## Appendix D Calculation of Complexity


### D.1 Adjacency Matrix Normalization（邻接矩阵归一化）

**重点讲解：**

- 对于存储在 **COO格式**（坐标格式）的稀疏用户-物品矩阵，归一化操作需要访问矩阵中的每一个非零元素。
- 因此，计算复杂度与边数成正比，即 **O(E)**，其中 E 表示图中的边数。
- 对于基线模型 **SGL**，在训练时需要归一化两个增强的图结构，每个结构包含 **ρE** 条边。
- 所以，SGL 每个 batch 的复杂度为 **O(2ρE)**。

---

### D.2 Approximate SVD Algorithm（近似SVD算法）

**精简讲解：**

- 本节仅简单提及近似 SVD 算法的复杂度分析，并引用了 Halko 等人 (2011) 的详细说明。
- 未提供具体复杂度公式或推导过程。

---

### D.3 Graph Convolution（图卷积）

**重点讲解：**

- 图卷积操作涉及对稀疏邻接矩阵与稠密嵌入矩阵的乘法。
- 对于一个稀疏邻接矩阵 𝒜（边数为 E）与一个稠密矩阵 𝑬（维度为 I×d 或 J×d），每次矩阵乘法的复杂度为 **O(Ed)**。
- 每次图卷积需要分别对用户和物品嵌入进行两次乘法，因此总复杂度为 **O(2Ed)**。
- 对于 L 层图卷积，总复杂度为 **O(2ELd)**。
- 对于传统的对比学习（CL）方法如 **SGL** 和 **SimCGL**，使用三视图结构，因此复杂度变为 **O(12ELd)**。其中 SGL 的复杂度还会因参数 ρ 略有变化。

---

#### 对于本模型的 SVD-view 结构：

**重点讲解：**

- 本模型采用 SVD-view，需进行如下操作：
  - **𝑽^qᵀ × 𝑬l−1(v)**：复杂度为 **O(qJd)**
  - **𝑼^qᵀ × 𝑬l−1(v)**：复杂度为 **O(qId)**
- 然后分别与预计算的矩阵（𝑼^q𝑺^q 和 𝑽^q𝑺^q）相乘，复杂度分别为 **O(qId)** 和 **O(qJd)**。
- 总体复杂度为 **O(2q(I + J)d)**，其中 q 是 SVD 的秩。

---

### D.4 BPR Loss（BPR 损失）

**简要讲解：**

- BPR 损失用于推荐系统中，对每个 batch 中的 B 个用户计算正样本和负样本的得分。
- 每个得分计算的复杂度为 **O(Bd)**，两个正负样本总计为 **O(2Bd)**。

---

### D.5 CL Loss（对比学习损失）

**重点讲解：**

- 在每个 batch 中，对于 B 个用户计算 **InfoNCE 损失**：
  - **分子部分**：O(Bd)
  - **分母部分**：O(BMd)，其中 M 是该 batch 中的节点总数。
- 由于模型使用 **每层计算一个 InfoNCE 损失**，因此需要乘以层数 L，总复杂度为 **O(BdL + BMdL)**。

---

### 总结

本附录主要分析了模型不同模块的计算复杂度：

- **邻接矩阵归一化**：与边数 E 相关，基线模型 SGL 更复杂。
- **图卷积**：核心操作，复杂度与边数、层数、嵌入维度线性相关。
- **SVD-view**：引入了近似 SVD，复杂度与 SVD 的秩 q 和节点数有关。
- **损失函数（BPR 和 CL）**：BPR 构建推荐得分，CL 用于对比学习，复杂度与用户数和节点数有关。

整体来看，模型复杂度在推荐系统规模下是可扩展的，尤其通过稀疏矩阵运算和近似 SVD 技术优化了计算效率。


## Appendix E Performance Results under the New Setting



### 实验设置的调整说明

在本文最初提交时，实验采用的是如下设置：在每个批次中，首先随机抽样出一部分用户，然后再为这些用户抽取固定数量的正样本和负样本项目。然而，后续的实验发现，这种方法可能导致次优性能，因为图中的交互信息并未被充分采样和训练。

因此，作者改为采用一种更广泛使用的设置，即**直接根据交互数据采样正负项目对**。这种新设置更全面地利用了图中的交互信息，从而可能带来性能的提升。

为了验证新设置下的性能，作者再次测试了 LightGCL 模型，并在表中展示了结果。同时，注意到在新设置下，SimGCL 这一最强基线模型也表现出显著的性能提升，因此作者同时也展示了 SimGCL 的结果。

### 数据集处理说明

在新设置下，**ML-10M 数据集由于交互数量太多，训练时间过长，因此被弃用。**

### 表 6：LightGCL 和 SimGCL 在新设置下的性能表现

#### 表格内容总结

| 数据集 | 评价指标 | SimGCL | LightGCL |
|--------|----------|--------|----------|
| Yelp | R@20 | 0.1050 | 0.0985 |
|      | N@20 | 0.0911 | 0.0842 |
|      | R@40 | 0.1714 | 0.1553 |
|      | N@40 | 0.1171 | 0.1051 |
| Gowalla | R@20 | 0.2216 | 0.2148 |
|         | N@20 | 0.1355 | 0.1250 |
|         | R@40 | 0.3056 | 0.2995 |
|         | N@40 | 0.1565 | 0.1468 |
| Amazon | R@20 | 0.1116 | 0.1161 |
|        | N@20 | 0.0873 | 0.0901 |
|        | R@40 | 0.1645 | 0.1705 |
|        | N@40 | 0.1046 | 0.1080 |
| Tmall | R@20 | 0.0832 | 0.0884 |
|       | N@20 | 0.0590 | 0.0629 |
|       | R@40 | 0.1299 | 0.1337 |
|       | N@40 | 0.0752 | 0.0786 |

#### 重点内容分析

- **SimGCL** 在所有数据集和所有指标上表现略优于 LightGCL，说明 SimGCL 仍为当前最强的基线模型。
- **LightGCL** 在新设置下表现较为稳定，但在大多数情况下略逊于 SimGCL，表明仍有改进空间。
- 在**Gowalla**数据集上，两个模型的性能都相对较高，可能是因为该数据集的交互结构较为清晰。
- **Amazon** 和 **Tmall** 的性能相对较低，可能因为这些数据集的交互更复杂或噪声较多。
- **Yelp** 的 R@20 与 N@20 指标表现良好，说明模型在该数据集上对 top-K 推荐有一定能力。

### 总结

本附录展示了在新采样设置下，LightGCL 与 SimGCL 的性能对比。结果显示 SimGCL 仍保持优势，而 LightGCL 在多数数据集上表现稳定。新设置的有效性得到了验证，但也表明当前方法仍有改进空间。
