# 2311.01343_CLLM4Rec: Collaborative Large Language Model for Recommender Systems

* 首页: <https://arxiv.org/abs/2311.01343>
* PDF: <https://arxiv.org/pdf/2311.01343>
* 引用: 112(2025-09-06)
* 组织:
    * University of Virginia
    * LinkedIn Inc.
* Conference: Proceedings of the ACM Web Conference 2024; May 13–17, 2024; Singapore, Singapore
* Booktitle: Proceedings of the ACM Web Conference 2024 (WWW ’24), May 13–17, 2024, Singapore, Singapore

## 总结

**总结**
* 引入 <user_i> 和 <item_j> 令牌，将推荐系统中的离散ID“翻译”成LLM能理解的“语言”
* 软+硬提示策略 (Soft+Hard Prompting)
    * 分别处理异构token（如ID嵌入和词汇token）
    * “硬”提示：指其中的词汇令牌，LLM已经理解其含义
    * “软”提示：指其中的用户/物品ID令牌，它们的嵌入是需要学习的
* 多项预测头：不再使用自动回归逐个预测，而是引入一个新的预测头 f_rec
    * 协同LLM指导内容LLM
        * z^l 从纯净的交互中学到的信号，会拉拽 z^c，让它只关注文本中与推荐相关的部分。
    * 内容LLM辅助协同LLM
        * z^c 从丰富的文本中学到的语义信息，会补充到 z^l 中，缓解数据稀疏问题，增强模型的表示能力。
    * 训练时，两个LLM的损失和这个正则化损失会交替优化（L-step和C-step）。

* 面向推荐的微调
    * **预训练**：通过语言建模任务（预测下一个token）来学习用户/物品的嵌入表示。
    * **微调**：将模型转变为高效的、直接进行多项推荐的模型。


**CLLM4Rec**
1.  **桥接符号与语义**：通过引入 `<user_i>` 和 `<item_j>` 令牌，将推荐系统中的离散ID“翻译”成LLM能理解的“语言”。
2.  **双嵌入设计**：用**协同嵌入**捕捉交互 patterns，用**内容嵌入**捕捉文本语义，并通过**互正则化**让二者互相增强、互相纠偏。
3.  **分阶段训练**：
    * **预训练**：通过语言建模任务（预测下一个token）来学习用户/物品的嵌入表示。
    * **微调**：将模型转变为高效的、直接进行多项推荐的模型。
4.  **保护与利用**：始终**固定预训练LLM的主干参数**，只训练新增的嵌入层和预测头，既充分利用了LLM的知识和推理能力，又避免了灾难性遗忘。

**核心贡献 (Claimed Innovation)**
* 作者宣称 **CLLM4Rec** 是第一个真正紧密耦合了推荐系统两大范式的方法：
    * **ID 范式 (ID Paradigm)**：指传统的协同过滤方法，其核心是直接学习用户和物品的ID嵌入（ latent factors），擅长捕捉纯粹的协同信号。
    * **LLM 范式 (LLM Paradigm)**：指利用大型语言模型处理文本内容（如评论、描述）来进行推荐，擅长理解和推理语义信息。
* 在此之前，很多工作可能只是简单地将文本特征喂给LLM，或者用LLM生成辅助信息，但未能将这两种范式的核心（即ID和语义）在模型底层进行深度融合。
    * CLLM4Rec 通过引入用户/物品ID令牌及其双嵌入设计，实现了这种“紧密耦合”。

**实现方法 (How It Achieves This)**
* 概括了实现这一贡献的两个关键阶段，这也是方法论中的精髓：
    * **互正则化预训练 (Mutually Regularized Pretraining)**：这是模型学习高质量表示的核心。
        * **软+硬提示策略 (Soft+Hard Prompting)**：是成功训练模型的技术手段，它让LLM能够有效处理混合了ID和自然语言的序列。
        * **通过语言建模捕获信息**：模型不是在直接学习“推荐”，而是在学习“预测下一个token”。
            * 通过完成“用户交互过哪些物品”和“用户写了什么评论”这两个任务，它间接地、非常有效地捕获了协同信息和内容信息。
    * **面向推荐的微调 (Recommendation-Oriented Finetuning)**：这是将模型能力转化为实际应用的关键一步。
        * 它将一个“语言模型”成功地微调成了一个高效、精准的“推荐模型”，解决了生成式模型直接用于推荐时可能存在的效率低下和“幻觉”问题。

**实验成果**
* **准确性**（如Recall, NDCG等指标）上超越了SOTA。
* **多功能性**（“多方面”）可能体现在：处理冷启动问题、提供可解释性（因为LLM能理解内容）、以及高效性等多个维度上的综合优势。


## Abstract

本文主要探讨了**基于预训练大语言模型（LLMs）的下一代推荐系统（Recommender Systems, RSs）**的发展趋势。尽管LLMs在语言理解方面表现出色，但其在推荐任务中仍面临**语义鸿沟**的问题，导致诸如**虚假相关用户/物品描述符、用户/物品数据上的语言建模效果不佳、基于自回归的推荐效率低**等问题。

为了解决这些问题，本文提出了**CLLM4Rec**，这是**首个将LLM范式与ID范式紧密结合的生成式推荐系统**。该系统旨在**同时解决上述多个挑战**。

### 核心方法

1. **词汇扩展**  
   首先，作者将预训练LLMs的词汇表扩展为**用户/物品ID标记**，以**忠实地建模用户/物品的协同和内容语义**。

2. **新颖的软+硬提示策略**  
   提出了一种新的**软+硬提示策略**，通过在推荐系统专用语料库上进行语言建模，**有效学习用户/物品的协同与内容嵌入**。  
   - 每个文档被划分为两部分：  
     - **提示部分**：包含异质的软（用户/物品）标记和硬（词汇）标记。  
     - **主体部分**：包含同质的物品标记或词汇标记，以**稳定且有效地进行语言建模**。

3. **互正则化策略**  
   引入了一种**互正则化策略**，旨在**鼓励模型从用户/物品的噪声内容中捕获与推荐相关的信息**。

4. **推荐导向的微调策略**  
   最后，提出了一个新的**推荐导向的微调策略**。  
   - 在预训练的CLLM4Rec主干模型上添加了一个**多项式似然预测头**，用于**基于被掩码的用户-物品交互历史生成推荐**。  
   - 该方法允许**高效生成多个推荐项而不产生幻觉内容**。

### 重点总结

- **CLLM4Rec** 结合了LLM与传统ID建模范式，是当前推荐系统领域的重要创新。
- **软+硬提示策略**与**互正则化策略**是解决语义建模和噪声问题的关键。
- **推荐导向的微调策略**提升了推荐的效率与准确性。
- 作者在GitHub上开源了代码，便于复现与验证。

总之，本文为基于大语言模型的推荐系统研究提供了新思路和新方法。


## 1. Introduction


随着网络内容的指数级增长，推荐系统（Recommender Systems, RS）已成为在线服务平台的重要组成部分。然而，传统的推荐系统长期依赖于基于ID的范式，即通过用户/物品唯一连续的ID嵌入（embeddings）表示其语义相似性。典型的基于ID的方法包括：**矩阵分解（如PMF）** 和 **双塔模型（如StarSpace）**，它们通常通过用户/物品的历史交互（协同过滤）或特征（内容方法）来初始化和学习ID嵌入。

近年来，**大语言模型（LLMs）**（如GPT、T5、LLaMA）因其在自然语言理解、知识和逻辑推理方面的强大能力而成为研究热点。这些模型在大规模语料上训练，具备生成能力，因此有望被用于构建下一代推荐系统。特别是在用户和物品具有大量文本特征（如描述、评论、简介等）的场景下，LLM可以更准确地理解和推理语义，从而提供更高质量的推荐。

已有初步研究探索了将LLM应用于推荐系统，一般分为两个步骤：

1. **将用户/物品信息转换为自然语言提示（prompt）**，包括交互历史、特征和候选物品。
2. **通过LLM处理该提示，从输出中提取推荐相关的信息进行推荐**。

该方法可以以**零样本（zero-shot）方式**运行，也可以在有标注数据的情况下**对LLM进行微调**，以获得更准确的推荐结果。

尽管已有积极进展，但**NLP与推荐系统之间仍存在根本差距**。主要挑战包括：

- **自然语言与用户/物品语义的不匹配**：现有方法通常使用伪ID或描述性文本表示用户/物品，但这些方式存在语义偏差或语义不准确的问题。
- **LLM的词表限制**：大多数LLM的词表规模有限（如GPT约50k，T5约30k），难以直接容纳大量用户/物品ID嵌入。
- **时序依赖引入噪声**：用户历史交互通常不具有时序依赖性，但语言模型对顺序敏感，可能引入虚假的时序关联。
    - 例如，“user_4332”转换为 [“user”， “_”， “43”， “32”]，
    - 其中可以对不相关的用户/项目引入虚假相关性（例如，“user_4332”与“user_43”和“user_32”）
- **内容建模噪声**：LLM未针对推荐任务设计，容易捕捉无关的文本特征。
    - 基于描述的方法使用语义上有意义的标记来索引用户/项目，例如项目标题或根据内容相似性分配给不同用户/物品的少量新引入的代币。 
    - 然而，基于描述的方法对用户-项目语义相似性引入了强烈的归纳偏差，这可能无法忠实地捕捉真实的语义。
- **生成效率问题**：LLM生成token的方式是自回归的，多物品推荐效率较低。
- **幻觉问题**：候选物品通常需要显式提供，否则可能生成不可靠结果。

---

为了解决上述问题，作者提出了**CLLM4Rec**，这是首个**将ID范式与LLM范式紧密结合的生成式推荐系统**。主要方法包括：

- **用户/物品ID嵌入扩展**：将用户/物品ID引入LLM的词表空间，使其能够真实地建模用户/物品的协同与内容语义。
- **两阶段嵌入学习策略**：通过**协同语言模型**和**内容语言模型**联合预训练，使用**“soft+hard”提示策略**，分别处理异构token（如ID嵌入和词汇token），提升模型的稳定性与效果。
- **随机物品重排序策略**：用于协同语言模型，避免顺序带来的虚假关联。
- **推荐导向的微调策略**：通过添加**多项式似然的物品预测头**，在掩码交互历史的提示下，高效生成多个物品推荐，避免幻觉。

---

## 本节贡献（Contribution）

1. **提出CLLM4Rec**：首个将ID范式与LLM范式结合的生成式推荐系统，通过引入与LLM词表空间对齐的ID嵌入，更好地捕捉用户兴趣和物品属性。
2. **提出“soft+hard”提示策略**：通过协同与内容信息的联合建模，实现对异构token的高效预训练。
3. **提出推荐导向的微调策略**：通过掩码交互历史建立提示，并使用预测头高效生成多个物品推荐，避免幻觉。

---

### 总结

本节介绍了推荐系统从基于ID范式向基于LLM范式演进的背景、挑战与初步尝试，指出现有方法的局限，并提出**CLLM4Rec**作为解决方案，通过结构创新与训练策略优化，解决了LLM在推荐系统中应用的关键问题。


## 2. Related Work



## 2. 相关工作

### 2.1. 大型语言模型（LLM）基础

大型语言模型（Large Language Models, LLMs）是基于 Transformer 架构的模型，经过大规模语料库的训练，展现出对自然语言的理解能力以及逻辑推理能力。根据所使用的 Transformer 架构部分，现有 LLM 可分为三类：

- **仅编码器型**：如 BERT；
- **编码器-解码器型**：如 T5；
- **仅解码器型**：如 GPT 和 LLaMA。

本文重点关注**仅解码器型 LLM**，因为它们在生成能力方面优于仅编码器模型。

LLM 的训练通常分为两个阶段：

1. **预训练阶段**：模型在大规模语料库上进行语言建模训练（如下一个/遮蔽词预测），通过堆叠的自注意力模块，有效地将知识编码到模型中；
2. **微调阶段**：通过示例提示-输出对或对多个生成答案的人类反馈进行微调，使模型能够根据提示进行逻辑推理并生成答案。

### 2.2. LLM 在推荐系统中的应用

近年来，基于 LLM 的推荐系统（LLM-based Recommender Systems, RS）展现了其在解决传统 ID 型推荐系统长期问题上的潜力，例如：

- 对用户/物品文本特征的理解较浅；
- 泛化能力差等。

Hou 等人提出，现有 LLM 能够作为**零样本排序器**（zero-shot ranker），根据用户历史行为和物品描述来排序物品的相关性。

进一步的研究集中在通过**微调**获得面向推荐任务的 LLM 模型，代表性工作包括：

- **P5**：在交互数据和用户/物品特征构建的语料上微调 T5，物品以伪 ID 表示；
- **M6**：在预训练阶段结合文本填充和自回归任务，伪 ID 被物品文本描述替代；
- **TALLRec**：同时使用伪 ID 和物品文本描述来表示物品。

然而，基于伪 ID 的表示可能引入**无关物品之间的虚假相关性**。为此，Hua 等人提出使用少量新 token 来描述物品，这些 token 由物品的内容和协同相似性决定。

尽管如此，使用共享 token 可能仍会引入**偏差**，且推荐过程需要**显式提供候选物品**并通过**低效的自回归生成**完成。总体而言，**自然语言处理（NLP）与推荐系统（RS）之间的割裂问题仍未得到良好解决**。



## 3. Methodology


### 核心目标

这段文字的核心目标是：**设计一个新的生成式推荐系统，通过引入用户和物品的ID令牌（Token），将预训练的大型语言模型（LLM）与推荐任务紧密耦合。** 这样既能准确建模用户/物品的语义（例如用户的兴趣），又能充分利用LLM中编码的知识和逻辑推理能力。

---

### 分步详解

#### 1. 问题定义 (3.1 Problem Formulation)

* **场景**：处理**隐式反馈**（如点击、购买，而不是明确的评分）的推荐系统。
* **符号**：
    * `I` 个用户，`J` 个物品。
    * `r_i`：一个二进制的向量，表示用户 `i` 与所有 `J` 个物品是否有过交互（1表示有，0表示无）。
    * `x_i^u`, `x_j^v`：与用户 `i` 或物品 `j` 相关的**文本特征**（如用户传记、物品描述）。
    * `x_ij^uv`：同时与用户 `i` 和物品 `j` 相关的文本特征（如用户对物品的**评论**）。
* **LLM的角色**：文中使用了一个预训练的LLM，将其视为一个概率模型 `p_llm`，可以根据上文 `x_1:k` 来预测下一个令牌 `x_k+1` 的概率。LLM通过多层自注意力模块将输入序列转换为隐藏表示 `h_1:k`，并基于其预训练的知识进行逻辑推理。

#### 2. 扩展用户/物品令牌 (3.2 Extension of User/Item Tokens)

为了把推荐系统和自然语言“连接”起来，作者做了关键操作：

* **词汇表扩展 (Vocab Expansion)**：在LLM原有的词汇表（包含约3万-5万个单词/令牌）基础上，**新增两种特殊的令牌**：
    * `<user_i>`：代表第 `i` 个用户。
    * `<item_j>`：代表第 `j` 个物品。
    这些新令牌不会被拆分成更小的单元（如字母），它们拥有自己独立的ID。
* **令牌嵌入 (Token Embeddings)**：为了让LLM能“理解”这些新令牌，需要为它们创建数值向量（嵌入）。作者设计了**两种嵌入**来分别捕捉**协同过滤信号**和**内容信息**：
    1.  **协同嵌入 (Collaborative Embeddings - `z^l`)**: 从高斯分布中随机初始化。这些嵌入的目标是学习用户和物品之间纯粹的交互模式（类似于传统推荐模型中的潜在因子）。
    2.  **内容嵌入 (Content Embeddings - `z^c`)**: 从以协同嵌入为中心的高斯分布中初始化（`z^c ~ N(z^l, ...)`）。这迫使内容嵌入不能偏离协同嵌入太远，确保从文本中学到的是与推荐**相关**的信息。
* **CLLM4Rec 基础模型**：构建了一个基础模型 `llm_hat`，它使用扩展后的词汇表。**关键点是：在预训练阶段，只训练新添加的用户和物品的嵌入 (`z^l`, `z^c`)，而预训练LLM的原始参数和原始词汇的嵌入都被固定不动**。这样可以保护LLM已有的知识不被破坏。

#### 3. 互正则化预训练 (3.3 Mutually-Regularized Pretraining)

这是本文最核心、最创新的部分，目的是利用文本数据来学习好的用户/物品嵌入。

* **构建推荐语料库**：将原始的交互数据 `r_i` 和文本数据 `x^u, x^v, x^uv` 转换成LLM可以理解的文本序列（文档）。例如：
    * “`<user_57>` has interacted with `<item_46>` `<item_123>` ...”
    * “`<user_57>` writes the review for `<item_46>`: This lipstick color is great but it dries my lips.”
* **软+硬提示 (Soft+Hard Prompting)**：作者发现上面的文档可以分成两部分：
    1.  **提示 (Prompt)**：包含**异构**令牌（用户ID、物品ID和**词汇令牌**，如 “has interacted with”）。这部分作为上下文。
    2.  **主体文本 (Main Text)**：包含**同构**令牌（要么全是物品ID，要么全是词汇令牌）。这部分是模型要生成的目标。
    * **“硬”提示**：指其中的词汇令牌（如 “interacted with”），LLM已经理解其含义。
    * **“软”提示**：指其中的用户/物品ID令牌，它们的嵌入是需要学习的。
    通过这种拆分，模型可以更专注地学习协同信息和内容信息。
* **两个LLM头**：
    * **协同LLM**：使用协同嵌入 `z^l`。它的任务是根据提示（如“用户A交互过”），**预测下一个物品ID**（自动回归地生成用户的历史交互序列）。这使模型学习用户和物品之间的协同关系。
    * **内容LLM**：使用内容嵌入 `z^c`。它的任务是根据提示（如“用户A评论物品B：”），**预测下一个词汇令牌**（生成评论内容）。这使LLM利用其知识理解文本内容（例如，从评论中推理出物品是口红，用户喜欢颜色但讨厌干燥），并将这些信息编码到内容嵌入中。
* **互正则化 (Mutual Regularization)**：这是防止两个任务各自缺陷的关键：
    * **问题1**：内容LLM可能会学到与推荐无关的文本噪声。
    * **问题2**：协同LLM可能因为数据稀疏（交互少）而过拟合。
    * **解决方案**：由于内容嵌入 `z^c` 的定义是基于协同嵌入 `z^l` 的（`z^c ~ N(z^l, ...)`），在训练目标中，这会转化为一个**正则化项**（MSE损失），强制要求 `z^c` 和 `z^l` 不能相差太远。
        * **协同LLM指导内容LLM**：`z^l` 从纯净的交互中学到的信号，会拉拽 `z^c`，让它只关注文本中与推荐相关的部分。
        * **内容LLM辅助协同LLM**：`z^c` 从丰富的文本中学到的语义信息，会补充到 `z^l` 中，缓解数据稀疏问题，增强模型的表示能力。
    训练时，两个LLM的损失和这个正则化损失会交替优化（L-step和C-step）。
* **随机物品重排序**：用户的历史交互物品本身没有顺序关系。为了避免LLM的位置嵌入干扰，在训练协同LLM时，会随机打乱用户历史物品序列的顺序。

#### 4. 面向推荐的微调 (3.4 Recommendation-Oriented Finetuning)

预训练后的模型还只是一个语言模型，不能直接高效地做推荐。

* **目的**：将预训练好的协同LLM**微调**成一个高效的推荐模型（称为 **RecLLM**）。
* **掩码提示**：为了构建训练样本，随机掩码用户的一部分历史交互物品（如mask掉20%）。
    * **输入（提示）**：使用未掩码的物品生成提示：“`<user_i>` has interacted with `<item_a>` `<item_b>` ... the user will interact with:”
    * **目标**：被掩码的那些物品（`hold-out items`）。
* **多项预测头**：不再使用自动回归逐个预测，而是引入一个**新的预测头 `f_rec`**。它基于提示的最终隐藏状态，**一次性预测所有物品的得分概率**（类似于传统的推荐模型），然后通过多项分布损失进行训练。这极大地提升了推荐效率。
* **继续保持正则化**：在微调阶段，仍然保持与内容LLM的互正则化，以利用文本信息。

#### 5. 使用CLLM4Rec进行预测 (3.5 Predictions)

* 最终，为一个用户做推荐时，将其**全部历史交互物品**转换为推荐提示（不含掩码）。
* 输入到微调好的 **RecLLM** 模型中。
* 模型通过**一次前向传播**，输出对所有物品的评分概率 `r_i_hat`。
* 选择用户未交互过的、得分最高的 `M` 个物品作为推荐结果。

---

### 核心思想总结

1.  **桥接符号与语义**：通过引入 `<user_i>` 和 `<item_j>` 令牌，将推荐系统中的离散ID“翻译”成LLM能理解的“语言”。
2.  **双嵌入设计**：用**协同嵌入**捕捉交互 patterns，用**内容嵌入**捕捉文本语义，并通过**互正则化**让二者互相增强、互相纠偏。
3.  **分阶段训练**：
    * **预训练**：通过语言建模任务（预测下一个token）来学习用户/物品的嵌入表示。
    * **微调**：将模型转变为高效的、直接进行多项推荐的模型。
4.  **保护与利用**：始终**固定预训练LLM的主干参数**，只训练新增的嵌入层和预测头，既充分利用了LLM的知识和推理能力，又避免了灾难性遗忘。

简单来说，**CLLM4Rec 把推荐任务巧妙地转换成了LLM擅长的“完形填空”和“文本生成”任务，从而让强大的LLM为推荐系统服务。**


## 4. Empirical Study

本节通过在四个公开数据集和一个 LinkedIn 职业推荐数据集上的实验，探讨以下三个研究问题（RQ）：

- **RQ1**：CLLM4Rec（首个将基于 ID 的范式与基于 LLM 的范式紧密耦合的推荐系统）在性能上如何与最先进的基于 ID 和基于 LLM 的推荐系统（RS）进行比较？
- **RQ2**：CLLM4Rec 的预训练阶段（包括互正则化技巧和随机项目重排序策略）如何影响其性能？
- **RQ3**：CLLM4Rec 在微调阶段使用掩码提示（masked prompting）和多项式项目预测头（multinomial item prediction head）如何影响推荐的效率与效果？

本节主要讨论基于 GPT-2 的 CLLM4Rec 模型，该模型具有 768 维的 token 嵌入和 50,257 个 token。更多 LLM 模型的实验结果见附录 B。

---

### 4.1 实验设置（Experimental Setup）

#### 4.1.1 数据集（Datasets）

本节实验使用四个公开推荐数据集和一个 LinkedIn 职业推荐数据集：

- **公开数据集**：
  - Amazon Beauty、Toys、Sports 数据集（用户评分大于3的作为隐式反馈）
  - Yelp 数据集（同样进行二值化处理）
- **LinkedIn 数据集**：
  - 用户对职位广告的点击作为隐式反馈
  - 用户简介与职位描述作为文本特征

数据预处理包括：
- 确保每个用户至少有5个交互记录（5-core）
- 随机划分训练集（80%）、验证集（10%）和测试集（10%）

数据集统计信息汇总于附录表3。

---

### 4.2 与基线模型的比较（Comparison with Baselines）

#### 4.2.1 基线模型（Baselines）

为验证 CLLM4Rec 的综合性优势，实验与以下基线模型进行比较：

1. **基于 ID 的基线**：
   - **Multi-VAE**：基于变分自编码器的协同过滤模型
   - **MD-CVAE**：Multi-VAE 的改进版，引入文本特征的 VAE 进行正则化

2. **基于语言模型的基线**：
   - **BERT4Rec**：利用双向自注意力的掩码语言建模进行推荐
   - **S3^3Rec**：扩展 BERT4Rec，引入项目属性预测等任务进行自监督学习

3. **基于大语言模型的基线**：
   - **LLM-Scratch**：从头训练模型，不使用预训练权重
   - **LLM-CF**：仅保留协同 LLM 和 RecLLM，去除内容 LLM 和互正则化
   - **LLM-FtAll**：微调整个模型（包括预训练 LLM 的嵌入）
   - **LLM-FixOrd**：去除随机项目排序策略
   - **LLM-PreRec**：仅使用预训练阶段的输出进行推荐，不进行微调

#### 4.2.2 定性分析（Qualitative Analysis）

部分基于 LLM 的推荐方法（如 P5、TALLRec）依赖用户/项目描述生成推荐，但生成的 token 可能与推荐无关，需提供候选列表避免幻觉。CLLM4Rec 可直接从整个项目池中生成多个推荐，因此适用于更广泛场景。

---

#### 4.2.3 公开数据集结果（Results on Public Datasets）

实验结果如表 1 所示，CLLM4Rec 在所有数据集上均优于其他基线模型，尤其在以下方面表现显著：

- **ID 基线**：Multi-VAE 表现强大，但 CLLM4Rec 利用 LLM 的预训练知识，显著优于 MD-CVAE
- **LLM 基线**：
  - **LLM-Scratch** 性能最差，说明从头训练无法有效利用预训练信息
  - **LLM-FtAll** 性能较差，说明全量微调可能破坏预训练知识
  - **LLM-PreRec** 表现良好，说明预训练阶段的软+硬提示策略有效
  - **CLLM4Rec** 在 LLM-PreRec 的基础上通过微调进一步提升性能，证明了其推荐导向微调的有效性

---

#### 4.2.4 LinkedIn 数据集结果（Results on LinkedIn Dataset）

CLLM4Rec 与 LinkedIn 当前的双塔模型（TT）和 M6-Retrieval（基于 M6 Transformer 的推荐模型）进行比较，结果如表 2 所示：

- **CLLM4Rec 显著优于 TT 模型**
- **CLLM4Rec-Emb**：将 CLLM4Rec 学到的嵌入作为 TT 模型的输入，性能进一步提升，且优于 M6-Retrieval

尽管 CLLM4Rec 推理效率较高，但相比 TT 模型仍存在延迟问题，实际部署需权衡效率与性能。

---

### 4.3 参数敏感性分析（Parameter Sensitivity Analysis）

本节分析 CLLM4Rec 中的超参数 **λc**（控制互正则化强度）对性能的影响。

- **当 λc 较小时**：互正则化不足，内容 LLM 无法为协同 LLM 提供足够的信息，性能下降
- **当 λc 过大时**：互正则化损失占主导，抑制了语言建模的学习效果
- **λc = 1** 附近性能达到最优，是推荐实践的起点

图 4 展示了在四个数据集上的 λc 敏感性分析结果，验证了该结论的普遍性。

---

### 总结

本节通过系统实验验证了以下结论：

1. **CLLM4Rec 在多个数据集上均优于传统 ID 模型和 LLM 模型**
2. **预训练阶段的互正则化和随机重排序策略对性能提升至关重要**
3. **微调阶段采用掩码提示和多项式预测头可提升推荐效率和效果**
4. **参数 λc 的选择对模型性能有显著影响，1 是一个推荐的初始值**
5. **CLLM4Rec 在工业级 LinkedIn 数据集上表现出应用潜力，尤其在嵌入结合使用时**

整体来看，CLLM4Rec 在推荐系统中成功融合了 ID 模型与 LLM 模型的优势，是一种有潜力的推荐系统新范式。


## 5. Conclusion

本文提出了 **CLLM4Rec**，这是首个将 **ID范式**（用户/项目标识符）和 **LLM范式**（大型语言模型）紧密结合的推荐系统方法。该方法在忠实捕捉用户和项目语义的同时，也能充分利用预训练语言模型所蕴含的知识和逻辑推理能力。

**重点内容：**

- **CLLM4Rec 的创新点**：通过一种基于“软+硬”提示策略的**相互正则化的预训练方法**，CLLM4Rec 能够有效融合用户和项目的**协同信息与内容信息**，并借助语言建模来进行建模。
- **推荐导向的微调**：在预训练的基础上，CLLM4Rec 进行了**推荐导向的微调**，以充分挖掘并利用预训练中获得的知识，从而高效生成推荐结果。
- **实验验证**：广泛的实验表明，CLLM4Rec 在多个方面均展现出优于当前最先进的方法。这验证了其在推荐系统中的**多方面优势**。

**总结**：CLLM4Rec 通过创新性的预训练和微调策略，将传统推荐方法与预训练语言模型的优点深度融合，为推荐系统提供了一种新的、高效且强大的解决方案。






## Acknowledgment

本研究部分得到了国家科学基金会（National Science Foundation）的资助，资助编号包括：IIS-2006844、IIS-2144209、IIS-2223769、CNS2154962 和 BCS-2228534。此外，研究还得到了弗吉尼亚州网络倡议（Commonwealth Cyber Initiative Awards）的资助，资助编号为 VV-1Q23-007、HV2Q23-003 和 VV-1Q24-011。作者也获得了摩根大通（JP Morgan Chase）和思科（Cisco）的教师研究奖的支持。重点强调了多方资助的支持，体现了研究的多方合作与资源投入。


## Appendix A Technical Details

### A.1. Soft+Hard Prompting 的实现  
在实现**Soft+Hard Prompting**策略时（如3.3.2节所述），针对**仅解码器结构的LLM（如GPT）**，我们仅生成提示词中的“**keys”和“values**”，用于异构标记（如 𝐱<sub>𝑖</sub><sup>𝑟,𝑝</sup>，𝐱<sub>𝑖𝑗</sub><sup>𝑢𝑣,𝑝</sup>），并使用最后一个标记的“query”作为起点，生成主文本中的**同构标记**（如 𝐱<sub>𝑖</sub><sup>𝑟,𝑚</sup>，𝐱<sub>𝑖𝑗</sub><sup>𝑢𝑣,𝑚</sup>），用于语言建模任务。

对于**编解码器结构的LLM（如T5）**，一种自然的思路是：将提示词（如 𝐱<sub>𝑖</sub><sup>𝑟,𝑝</sup>，𝐱<sub>𝑖𝑗</sub><sup>𝑢𝑣,𝑝</sup>）作为**编码器输入**，再在**解码器中生成主文本**（如 𝐱<sub>𝑖</sub><sup>𝑟,𝑚</sup>，𝐱<sub>𝑖𝑗</sub><sup>𝑢𝑣,𝑚</sup>）。

---

### A.2. 推荐导向微调的互正则化目标  
在推荐导向的微调中，我们定义了一个**互正则化目标函数**，具体如下：

目标函数为：

$$
\mathcal{L}_{\text{rec\_step}}^{\text{MAP}}(\mathbf{z}^{l,u}_i, \mathbf{Z}^{l,v}_i; \theta) = \underbrace{-\sum_{k} r^{hold}_{ik} \ln \hat{r}^{hold}_{ik}}_{\text{Multinomial NLL Loss}} + \underbrace{\frac{\lambda_l}{2} \|\mathbf{z}^{l,u}_i\|_2^2 + \sum_k \frac{\lambda_l}{2} \|\mathbf{z}^{l,v}_{ik}\|_2^2}_{\text{Prior loss}} 
$$
$$
\underbrace{+\frac{\lambda_c}{2} \|\mathbf{z}^{l,u}_i - \hat{\mathbf{z}}^{c,u}_i\|_2^2 + \sum_k \frac{\lambda_c}{2} \|\mathbf{z}^{l,v}_{ik} - \hat{\mathbf{z}}^{c,v}_{ik}\|_2^2}_{\text{MR loss with content LLM}} + \mathcal{C}_{rec}
$$

其中关键点如下：

1. **Multinomial NLL Loss**（负对数似然损失）  
   用于衡量推荐预测头输出（如 𝐫<sub>𝑖</sub><sup>ℎ𝑜𝑙𝑑</sup>^）与真实标签之间的差距。  
   它鼓励模型输出的用户潜在变量（如 𝐡<sub>𝑙,𝑖,−1</sub><sup>𝑟𝑒𝑐</sup>）与用户历史交互商品的嵌入表示相似。

2. **Prior loss**（先验损失）  
   加入L2正则化项，防止模型参数过大，提高泛化能力。  
   用于对齐用户嵌入（𝐳<sub>𝑖</sub><sup>𝑙,𝑢</sup>）与物品嵌入（𝐳<sub>𝑖𝑘</sub><sup>𝑙,𝑣</sup>）的规范性。

3. **MR loss with content LLM**（内容LLM的互正则化损失）  
   通过引入内容LLM提供的嵌入（如 𝐳<sub>𝑖</sub><sup>𝑐,𝑢</sup>, 𝐳<sub>𝑖𝑘</sub><sup>𝑐,𝑣</sup>），正则化模型学习的嵌入与内容信息的一致性。  
   重点在于确保推荐模型（RecLLM）与内容模型（content LLM）之间的协同学习。

4. **常数项 𝒞<sub>rec</sub>**  
   优化过程中与目标函数无关的常数项，不影响最终求解。

---

### 总结  
本节重点介绍了**Soft+Hard Prompting的实现方式**以及**推荐模型微调中的互正则化目标函数**。对于不同的LLM结构（仅解码器 vs 编解码器结构），提示词的处理方式有所不同。而互正则化目标函数的核心在于：  
- 通过推荐预测头建模用户与物品间的交互分布；  
- 通过引入L2正则化和内容LLM的嵌入，实现模型间的协同学习与泛化能力提升。


## Appendix B Experiments

### B.1. 数据集统计
本节总结了论文中使用的公开数据集和LinkedIn推荐数据集的统计信息，详见表3，用于后续实验的分析与比较。

### B.2. 基于GPT-2的CLLM4Rec的实现细节
本节详细介绍了基于GPT-2的CLLM4Rec模型的实现细节。训练过程分为三个阶段：
1. **内容LLM预训练**：通过语言建模对用户/物品的内容嵌入进行10个epoch的预训练，以初始化模型。
2. **协同与内容LLM的联合预训练**：交替训练协同模型和内容模型，共进行100个epoch，目标函数参考方程7和8。
3. **推荐导向的微调阶段**：在此阶段进行150个epoch的微调，并通过Recall@20、Recall@40和NDCG@100指标在验证集上选择最优模型。

其中一个关键的超参数是**先验精度λc（λ_c）**，它控制协同与内容模型之间的相互正则化强度。论文中先通过网格搜索确定其最优值，并以此对比其他基线模型，随后分析其对模型性能的影响。

### B.3. 补充实验结果

#### B.3.1. 更多模型骨干的实现细节
本节展示了CLLM4Rec使用两种额外的大型语言模型（LLM）骨干进行的实验，以验证其泛化能力：
- **T5-base**：基于编码器-解码器结构，包含32,128个词汇标记，每个标记对应一个768维嵌入。
- **LLaMA-7B**：使用与T5相同的标记方式，每个标记对应一个4,096维嵌入。

对于非对称模型（即预测头与单词嵌入未绑定的模型），在预训练和微调阶段，模型的预测头权重会被随机初始化并与物品嵌入一起学习。训练过程与GPT-2模型类似，分为预训练、相互正则化和推荐导向微调三个阶段。

#### B.3.2. 更多基线模型
本节引入了两个强ID基模型：
- **EASE**：基于单层自编码器，具有无自重建约束，具有更低的方差和更强的归纳偏置，适用于稀疏评分数据。
- **BPR**：通过将用户/物品的词袋文本特征与协同嵌入结合，在优化排序目标时提高效果。

#### B.3.3. 结果与分析
实验结果总结在表4中，对比了不同LLM骨干下的CLLM4Rec模型与基线模型在三个Amazon Review数据集（AM-Beauty、AM-Toys、AM-Sports）上的性能。
- **CLLM4Rec-GPT2** 表现最佳，性能优于其他模型，包括CLLM4Rec-T5和CLLM4Rec-LLaMA。
- **CLLM4Rec-T5** 表现较差，原因可能包括：
  - T5模型参数初始化方差较大，导致训练不稳定。
  - T5的prompt设计与CLLM4Rec的目标存在不匹配。
- **CLLM4Rec-LLaMA** 在较大数据集（AM-Sports）上表现略优于GPT-2，但在较小数据集（AM-Beauty）上存在过拟合问题，说明模型大小与数据规模之间存在平衡关系。

### 总结
本附录通过实验验证了CLLM4Rec模型在不同LLM骨干下的泛化能力，并对比了多个基线模型。结果表明，GPT-2在稳定性和性能方面具有优势，而T5和LLaMA则在特定条件下（如数据规模较大）表现出一定的潜力。同时，模型设计中的关键超参数（如λc）对性能有显著影响，应谨慎调整。
