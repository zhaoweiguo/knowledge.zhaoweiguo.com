# 2507.07957_MIRIX: Multi-Agent Memory System for LLM-Based Agents


* 首页: <https://arxiv.org/abs/2507.07957>
* PDF: <https://arxiv.org/pdf/2507.07957>




## Abstract


虽然AI代理的记忆能力正受到越来越多关注，但目前的解决方案依然存在根本性限制。大多数方法依赖于平面化、狭隘范围的记忆组件，限制了它们在个性化、抽象化以及长期可靠回忆用户特定信息方面的能力。为此，本文提出 **MIRIX**——一种模块化、多代理的记忆系统，通过解决该领域最关键的挑战（使语言模型**真正**具备记忆能力）重新定义AI记忆的未来。与之前的方法不同，MIRIX 不仅限于文本，而是融合了丰富的视觉和多模态体验，使得记忆在现实场景中真正具有实用性。

MIRIX 包含六种结构化明确的记忆类型：**核心记忆（Core）**、**情景记忆（Episodic）**、**语义记忆（Semantic）**、**程序记忆（Procedural）**、**资源记忆（Resource Memory）** 和 **知识库（Knowledge Vault）**，并结合一个多代理框架，动态控制和协调记忆的更新与检索。这一设计使代理能够大规模地**持久化存储、推理和准确检索多样化的长期用户数据**。

### 验证实验

我们通过两个具有挑战性的设置验证了MIRIX的性能：

1. **在 ScreenshotVQA 上的验证**：该多模态基准包含近20,000张高分辨率计算机截图，要求深度的情境理解，且目前没有任何现有记忆系统可以应用。MIRIX 在准确率上比 RAG 基线高出 35%，并且将存储需求减少了 99.9%。
   
2. **在 LOCOMO 上的验证**：该长文本对话基准采用单模态文本输入，MIRIX 达到了 85.4% 的最先进性能，远超现有基线。

这些结果表明，MIRIX 为增强型大语言模型代理（LLM Agents）设定了新的性能标准。

### 应用体验

为了使用户能够体验我们的记忆系统，我们提供了一个由 MIRIX 驱动的打包应用程序。该应用能够**实时监控屏幕**、**构建个性化记忆库**，并提供**直观的可视化**和**本地安全存储**，确保用户隐私。

---

**重点总结**：
- MIRIX 是一种模块化、多代理的记忆系统，解决了当前AI记忆的核心问题。
- 它包含六种结构化记忆类型，结合动态代理机制，支持长期、多样化的记忆处理。
- 在 ScreenshotVQA 和 LOCOMO 上的实验验证了其卓越的性能与存储效率。
- 提供了实际应用版本，具备隐私保护和视觉化功能，方便用户体验。


## 1 Introduction



以下是对该论文 **第一章 Introduction** 的总结，按照原文结构进行梳理，并对重点内容进行强调讲解：

---

## 1 Introduction 总结

### 1.1 研究背景与动机

**重点内容：**
- 近年来，大型语言模型（LLM）代理的研究主要集中在**复杂任务执行能力**的提升，如代码调试、仓库管理、自主浏览网页等。
- **但记忆（memory）这一基础维度却鲜有研究**。记忆对于实现一致、个性化交互、学习反馈、避免重复提问等至关重要。
- 当前大多数LLM代理**状态不持久**，除了当前提示窗口外，无法保留长期记忆，除非用户显式提供上下文。这极大地限制了其在实际场景中的长期使用。

### 1.2 现有记忆系统的局限性

**重点内容：**
- 一些记忆增强系统被提出，如使用**知识图谱**（如 Zep、Cognee）或**扁平化记忆结构**（如 Letta、Mem0、ChatGPT）。
- **知识图谱**适合表示实体间结构化关系，但难以建模**事件序列、情感状态、长文档或多模态输入**（如图像）。
- **扁平化记忆系统**（如 Letta 和 Mem0）虽然有一定应用，但面临以下挑战：
  1. **缺乏组合记忆结构**：大多数系统将所有历史数据存储在一个扁平数据库中，缺乏**按记忆类型（如程序性、情景性、语义性）分类的结构**，导致检索效率和准确性下降。
  2. **多模态支持差**：文本为主的记忆机制无法处理大量**非语言输入**（如图像、界面布局、地图）。
  3. **可扩展性与抽象化问题**：存储原始输入（尤其是图像）会导致**存储需求过高**，缺乏有效的抽象层级来**总结并保留关键信息**。

### 1.3 本文提出的系统：MIRIX

**重点内容：**
- 本文提出**MIRIX**（Multi-Agent Memory System for LLM-Based Agents），这是一个**模块化、全面的记忆系统**，包含六种记忆组件（如图1）：
  - **Core Memory**：核心记忆，用于存储用户偏好等关键信息。
  - **Episodic Memory**：情景记忆，存储用户特定事件和经历。
  - **Semantic Memory**：语义记忆，捕捉概念和命名实体。
  - **Procedural Memory**：程序性记忆，记录任务执行步骤。
  - **Resource Memory**：资源记忆，存储用户提供的文档、文件等媒体。
  - **Knowledge Vault**：知识库，保存必须精确存储的重要信息（如地址、电话号码等敏感事实）。
- 每种记忆组件内部采用**层次化结构**，例如情景记忆包含摘要和细节字段，语义记忆按名称和描述组织信息。
- 由于管理这种**结构化且异构的记忆系统**对单个代理来说困难，本文采用**多代理架构**：
  - 为每种记忆组件设计一个**Memory Manager**（记忆管理器）。
  - 一个**Meta Memory Manager**（元记忆管理器）负责任务的路由。
  - 附加一个**Chat Agent**，用于演示如何访问和使用这些记忆。

**补充说明：**
- 提出了**主动检索机制**（Active Retrieval）：在回答问题或执行下一步前，代理必须生成一个*主题（topic）*，并将检索到的信息作为系统提示输入模型。
- 设计了多种**检索工具**，以便代理在不同情境中选择合适的工具。

### 1.4 实验与评估

**重点内容：**
- **实验一：多模态输入挑战**
  - 构建了一组**包含5,000到20,000张高分辨率截图的基准数据集**，来源于三位博士生一个月的电脑使用记录。
  - 每张截图分辨率为2K到4K，要求代理从这些视觉历史中提取信息并构建记忆。
  - 该任务对现有长上下文模型（如 Gemini）也构成挑战。
- **实验二：LOCOMO 数据集评估**
  - 在长对话数据集 LOCOMO 上进行评估（约26,000 token/对话）。
  - 限制 Chat Agent 只能使用**检索到的记忆**回答问题，不能访问原始对话文本。
  - 该设置用于测试系统是否能**有效提取和路由关键信息**。

**实验结果：**
- 相比RAG和长上下文基线，MIRIX分别提高了35%和410%，同时存储需求分别减少了99.9%和93.3%。
- 在 LOCOMO 上，MIRIX 达到85.38%的准确率，比现有最佳方法高出8.0%，接近长上下文模型的上限。

### 1.5 应用与贡献

**重点内容：**
- 为提高记忆系统的实用性，作者还开发了一个**由 MIRIX 驱动的个人助理应用**，在用户授权下捕捉屏幕内容，并持续构建记忆。
- 该应用允许用户通过记忆系统与助理进行更智能的互动，体现了系统的**现实可应用性**。

**贡献总结：**
1. **分析现有记忆系统的不足**，提出由六种记忆组件和八个代理组成的**新型记忆系统**。
2. **构建新型多模态内存建模基准**，要求代理从大量屏幕截图中理解用户行为。
3. **实验验证**：MIRIX 在新基准和 LOCOMO 上显著优于现有方法。
4. **构建并开源个人助理应用**，使用户能在实际场景中体验高级记忆功能。

---

该章系统性地介绍了 MIRIX 的研究背景、系统设计、实验方法和主要贡献，为后续章节的深入展开打下了坚实基础。


## 2 Application & Use Cases



### 2 应用与使用场景

#### 2.1 MIRIX 应用

为了展示记忆系统（Memory System）的完整功能，开发了一个跨平台的应用程序，前端基于 **React-Electron**，后端使用 **Uvicorn** 服务器。该应用支持直接安装，用户可通过 **ScreenShots** 选项卡激活屏幕监控功能。该功能使代理（agent）能够观察用户的屏幕活动，并动态更新其记忆，逐步构建对用户上下文的理解。代理可以根据积累的记忆回答相关问题。

##### **Memory Updates（记忆更新）**  
- 每 1.5 秒截取一张屏幕图像，去除视觉上重复的截图，保留 20 张唯一截图后启动记忆更新流程（约每 60 秒一次）。
- 为了降低延迟，采用 **流式上传**（streaming upload）策略：截图一旦生成即上传，而非等待整批处理。
- 利用 **Gemini API** 支持从 Google Cloud URL 加载图像的特性，实现高效的图像传输，显著减少端到端延迟（从大约 50 秒降低到 5 秒以下）。

##### **Chat Interface（聊天界面）**  
- 用户可通过聊天界面与代理交互，代理可访问所有累积的记忆，以提供更智能、个性化的回应。
- 图 2 示例展示了用户查询过去行为，代理基于记忆内容生成回答的场景。

##### **Memory Visualization（记忆可视化）**  
- 随着屏幕观察时间的延长，代理将知识组织为结构化记忆组件。  
- **语义记忆**（Semantic Memory）以树状结构组织（如图 3 所示），**程序性记忆**（Procedural Memory）则以列表形式呈现（如图 4 所示）。

---

#### 2.2 可穿戴设备上的记忆系统

可穿戴设备市场近年来迅速发展，智能个人助理类产品（如 AI 眼镜、AI 针等）已成为趋势。尽管这些设备支持语音、视觉捕捉和实时反馈，但普遍缺乏**长期记忆能力**，无法持续学习用户习惯和行为。

MIRIX 记忆系统非常适合集成到这类设备中：  
- 通过持续采集音频、视觉和用户查询，实现实时记忆构建。
- 示例应用包括：AI 眼镜可自动总结会议、记住常去地点、识别重复视觉模式，甚至回溯过去对话。
- 记忆系统包含**程序性**、**情景性**、**语义性**和**资源性**记忆模块，适合轻量级设备。
  - **程序性记忆**：学习用户习惯（如日常路线、会议结构）。
  - **语义记忆**：存储用户偏好、环境与日常模式。
  - **情景记忆**：记录时间戳事件（如“上周会议我看到了什么”）。
- 考虑硬件限制（计算与存储资源有限），系统支持**混合本地/云端存储**，关键信息本地存储，大规模记忆可按需云端调用。

**总结**：此记忆系统可作为可穿戴 AI 代理的“认知核心”，实现个性化、连续性与边缘智能。随着市场发展，具备持久结构化记忆将成为下一代 AI 助手的重要差异点。

---

#### 2.3 代理记忆市场（Agent Memory Marketplace）

我们设想未来，**个人记忆**将作为新的数字资产类别存在。AI 时代中，记忆不再是静态的事件记录，而是可共享、可个性化、可货币化的动态知识库。**Agent Memory Marketplace** 是一个去中心化的生态系统，支持 AI 代理之间记忆的交换、复用与共建。

##### 核心理念：
- **人类记忆将成为 AI 时代最有价值的资产**，因为它包含主观体验、偏好、互动和情境，既高度个人化，又可被 AI 系统复用。

##### 市场结构分为三层：

1. **AI 代理基础设施**
   - 支持长期、交互式的智能代理系统，包括：
     - 个人 AI 助手与伙伴（个性化、持续学习）
     - AI 可穿戴设备（如智能眼镜、AI 针）中扩展记忆采集
     - 多代理系统（共享记忆访问，实现协同智能）

2. **隐私保护记忆基础设施**
   - 为增强信任与用户接受度，系统包含：
     - **端到端加密**
     - **细粒度隐私控制**（用户可选择共享、交易或限制记忆）
     - **去中心化存储**（抗审查、分布式存储）

3. **记忆市场与社交功能**
   - 一个点对点的生态系统，用于**记忆共享、聚合与交易**，包括：
     - **记忆社交与交易**（如生产力技巧、小众工作流或生活建议）
     - **专业社区**（如金融、教育、宠物护理领域的共享记忆）
     - **粉丝经济与约会应用**（用户可订阅名人记忆的 AI 代理人，或通过 AI 代理人进行预约会互动）

**总结**：我们设想一个未来，个人记忆不再只是过去事件的记录，而是成为活跃的数字资产。通过结合长期 AI 代理、隐私保护基础设施与去中心化市场，我们构建了一个安全、有意义、协作性强的生态系统，使记忆不仅能被用户自身利用，还能赋能协作、个性化与经济价值。


## 3 Methodology



以下是对该论文“## 3 Methodology”章节内容的总结，按照原文结构进行整理，突出重点内容，精简次要信息：

---

## 3 Methodology

### 3.1 Memory Components

本节提出了一种模块化的记忆架构，包含六个不同的记忆组件：**Core Memory**、**Episodic Memory**、**Semantic Memory**、**Procedural Memory**、**Resource Memory** 和 **Knowledge Vault**。每个组件在结构和功能上都经过定制，用于捕捉用户交互和世界知识的不同方面，从而支持代理在时间与任务上的有效检索、推理与行动。

#### Core Memory（核心记忆）
- **功能**：存储高优先级、持久性信息，这些信息应始终对代理可见。
- **结构**：分为 `persona` 和 `human` 两个块。`persona` 描述代理的身份、语气和行为模式；`human` 存储用户的基本信息（如姓名、偏好等）。
- **容量管理**：当内存使用超过 90% 时，系统会触发有控制的重写机制，确保信息紧凑但不丢失关键内容。

#### Episodic Memory（情景记忆）
- **功能**：记录带时间戳的事件和用户互动，支持代理理解用户的日常行为、近期活动和上下文相关的后续响应。
- **结构**：每个条目包括 `event_type`（如用户消息、系统通知）、`summary`（简洁描述）、`details`（扩展信息）、`actor`（用户或代理）和 `timestamp`。
- **用途**：代理可以通过时间索引追踪变化，识别正在进行中的任务或待处理动作。

#### Semantic Memory（语义记忆）
- **功能**：保存抽象知识和事实性信息，与具体时间和事件无关。
- **结构**：包括 `name`（概念标识）、`summary`（定义）、`details`（背景信息）、`source`（来源，如用户提供或推断）。
- **用途**：支持代理进行常识、社会关系、地理等领域的推理。

#### Procedural Memory（程序记忆）
- **功能**：存储结构化的、目标导向的过程或操作指南，如“如何填写报销单”、“如何设置Zoom会议”。
- **结构**：每个条目包括 `entry_type`（如工作流、指南）、`goal`（目标描述）和 `steps`（步骤列表，可为JSON格式）。
- **用途**：用于任务拆解、自动化和执行复杂用户目标。

#### Resource Memory（资源记忆）
- **功能**：存储用户正在处理但不适合其他记忆类型的文档、多模态文件或长文本。
- **结构**：包括 `title`、`summary`（概述）、`resource_type`（如文档、图片）和 `content`（全文或摘录）。
- **用途**：支持长周期任务的上下文连续性。

#### Knowledge Vault（知识库）
- **功能**：安全存储敏感信息，如密码、地址、API密钥等。
- **结构**：包括 `entry_type`（如凭证、API密钥）、`source`（来源）、`sensitivity_level`（敏感等级）和 `secret_value`。
- **用途**：支持执行需要认证的任务，高敏感信息通过访问控制保护。

---

### 3.2 Active Retrieval and Retrieval Design（主动检索与检索设计）

许多记忆增强系统中，记忆检索需要显式触发，否则模型会依赖其参数知识，可能导致过时或错误的回答。

#### Active Retrieval（主动检索）
- **机制**：分为两个阶段：
  1. 代理根据输入上下文生成一个“当前话题”；
  2. 用该话题从六个记忆组件中检索相关内容，并将结果注入系统提示中。
- **示例**：用户询问“Twitter的CEO是谁？”时，代理自动检索记忆中对应的信息，并根据来源（如`<episodic_memory>`）标记内容，确保模型使用最新、个性化信息回应。

#### 检索方法
- 支持多种检索策略：`embedding_match`（嵌入匹配）、`bm25_match`（BM25匹配）、`string_match`（字符串匹配）等，未来将继续扩展。

---

### 3.3 Multi-Agent Workflow（多代理工作流）

为管理复杂且多样化的用户交互，系统采用模块化的多代理架构，由**Meta Memory Manager**（元记忆管理器）与六个**Memory Managers**（记忆管理器）协同工作。

#### Memory Update Workflow（记忆更新流程）
- **流程**：
  1. 接收用户输入后，系统首先在记忆库中进行搜索；
  2. 搜索结果与用户输入一起传递给**Meta Memory Manager**；
  3. **Meta Memory Manager** 分析内容，决定哪些记忆组件需要更新，并将输入路由给相应的**Memory Managers**；
  4. 各**Memory Managers** 并行更新各自的内存，避免重复信息；
  5. 更新完成后，向**Meta Memory Manager** 报告，完成更新确认。

#### Conversational Retrieval Workflow（对话检索流程）
- **流程**：
  1. **Chat Agent**（聊天代理）接收用户查询后，首先进行初步搜索，获取所有记忆组件的高阶摘要；
  2. 分析查询内容，确定需要更精确搜索的记忆组件，并选择合适的检索方法；
  3. 整合搜索结果并生成最终回应；
  4. 若用户查询涉及更新记忆（如提供新事实），Chat Agent 可直接与相关 Memory Manager 交互，进行精准更新。

---

### 图表说明
- **图5（Active Retrieval）**：展示了代理如何根据用户输入生成话题，并从各记忆组件中检索内容。
- **图6（Memory Update Workflow）**：展示了从用户输入到记忆更新的完整流程。
- **图7（Query Workflow）**：展示了代理如何根据用户查询执行检索并生成回应的过程。

---

### 总结
本章详细介绍了 MIRIX 系统的多模块记忆架构和多代理系统设计，每个记忆组件针对不同类型的用户信息做专门设计，通过“主动检索”和“多代理工作流”实现高效、准确、上下文感知的记忆管理与响应能力。系统强调自动化、模块化与安全性，适用于复杂任务和长期交互场景。


## 4 Experiments



## 4 实验 (Experiments)

本节详细介绍了 MIRIX 在两个数据集上的实验设置、评估指标和结果。通过与现有记忆系统和基线方法的对比，MIRIX 展示了其在多种任务上的优越性能和高效性。

---

### 4.1 实验设置 (Experimental Setup)

#### 4.1.1 数据集 (Datasets)

##### ScreenshotVQA
- **数据收集**：作者创建了一个新数据集，收集了三位计算机科学和物理专业的博士生的屏幕截图。
- **数据生成方式**：通过脚本每秒截图一次，若当前图像与上一帧相似度超过 0.99，则跳过。
- **数据量**：三位学生分别使用电脑的时间为1天、20天和1个月，生成了5886、18178和5349张图像。
- **问题生成**：每位学生手动创建一定数量的问题，并经双人验证确保可回答性，最终分别生成11、21和55个问题。

##### LOCOMO
- **来源**：沿用 Mem0 中的 LOCOMO 数据集，用于与 MIRIX 的横向比较。
- **数据结构**：包含10次对话，平均每次对话600轮、26000个token，200个问题。
- **问题类型**：包括单跳、多跳、时间顺序和开放域问题。
- **特别说明**：排除“对抗性”问题类别，以保证公平性。

---

#### 4.1.2 评估指标与实现细节 (Evaluation Metrics and Implementation Details)

##### 评估指标 (Evaluation Metrics)
- **主指标**：LLM-as-a-Judge，使用 GPT-4.1 作为裁判，评估生成的回答是否成功回答了问题。
- **重要性**：该指标是核心，用于量化不同方法的性能差异。

##### ScreenshotVQA 的实现细节
- **模型**：使用 Gemini-2.5-flash-preview-04-17。
- **原因**：Gemini 与 Google Cloud 集成良好，支持异步图像上传和检索，加快处理速度。
- **操作流程**：每步需要多次函数调用，包括主记忆管理器和其他记忆管理器。

##### LOCOMO 的实现细节
- **模型选择**：使用 gpt-4.1-mini，因其在函数调用上优于 gpt-4o-mini（数据来自 Berkeley 函数调用基准）。
- **基线方法**：在统一模型下复现了 LangMem、RAG-500、Mem0 和 Zep。
- **代码来源**：使用 Mem0 和 Zep 的官方代码库。
- **结果复现**：所有基线运行一次，MIRIX 和 Full-Context 运行三次并取平均。
- **代码与数据**：公开结果和代码可在 GitHub 上访问。

---

### 4.2 ScreenshotVQA 上的实验结果 (Experimental Results on ScreenshotVQA)

- **对比方法**：
  - **Gemini**：长上下文基线，直接输入所有截图，图片被压缩到 256×256，最多包含3600张。
  - **SigLIP**：检索增强基线，用 SigLIP 检索前50张相关图像，再由 Gemini 生成答案。

- **评估指标**：
  - **Accuracy**：通过 LLM-as-a-Judge 评估。
  - **Storage**：按像素大小计算存储开销（Gemini）或原始图像大小（SigLIP）或提取信息的大小（MIRIX）。

- **主要结论**：
  - MIRIX 在准确率上显著优于 Gemini 和 SigLIP，同时存储成本大大降低。
  - **Gemini**：由于图片压缩，存储开销仍较大。
  - **SigLIP**：存储开销极高（15GB+），但准确率略高于 Gemini。
  - **MIRIX**：存储极小（仅 15.89MB），准确率最高（59.50%），比 SigLIP 高35%，比 Gemini 高410%。

---

### 4.3 LOCOMO 上的实验结果 (Experimental Results on LOCOMO)

- **对比方法**：
  - A-Mem、LangMem、Zep、Mem0、Memobase（均基于 gpt-4.1-mini 实现）。
  - 另外报告了 Mem0 原论文中基于 gpt-4o-mini 的结果。

- **主要结论**：
  - **总体表现**：MIRIX 在所有类别中表现最优，平均得分 85.38，比最强开源方法（LangMem）高出 8 分以上。
  - **单跳与时间顺序**：MIRIX 表现优异，但略低于 Full-Context。部分问题因上下文歧义导致误差（如计划与实际事件混淆）。
  - **多跳推理**：MIRIX 表现最佳，比其他方法高出 24 分以上。原因在于其存储了整合事件，无需查询时拼接信息。
  - **开放域**：MIRIX 表现良好，但与 Full-Context 仍有差距。这是因为开放域问题需要更全局的理解，而 MIRIX 依赖 RAG 检索，存在瓶颈。

- **总结**：
  - MIRIX 在 LOCOMO 数据集上实现了 SOTA 性能，尤其在多跳推理方面表现突出。
  - 其模块化设计、智能路由机制和分层存储策略是性能提升的关键。

---

### 总结

本章通过对 **ScreenshotVQA** 和 **LOCOMO** 两个数据集的实验验证，全面评估了 MIRIX 在 **图像问答** 和 **对话记忆系统** 任务中的性能。实验结果表明：

- MIRIX 在存储效率和准确率方面远超现有基线（如 Gemini、SigLIP）。
- 在对话记忆任务中，MIRIX 在多跳推理上表现突出，显著优于 Mem0、LangMem 等主流系统。
- 虽然在某些任务（如开放域、单跳）上仍有改进空间，但整体表现已达到当前最优。


## 5 Related Work



## 5 相关工作总结

---

### **Memory-Augmented Large Language Models（内存增强的大语言模型）**

本节重点介绍了**在大语言模型中引入内存机制的模型架构研究**，这些模型通过扩展Transformer结构，引入了**多种形式的潜在空间（latent-space）内存组件**。这些内存组件包括但不限于：

- 模型参数
- 外部记忆矩阵
- 隐藏状态
- 软提示（soft prompts）
- 键值缓存（key-value caches）

尽管这些方法在性能上有显著提升，但大多数方法**需要重新训练模型**，这与GPT-4或DeepSeek-R1等**闭源模型不兼容**。此外，**基于键值缓存的方法**虽然能处理长上下文，但仅作为**长上下文方法**使用，**缺乏对抽象、整合和推理能力的支持**，因此不被视为真正的记忆系统。

---

### **Memory-Augmented LLM Agents（内存增强的LLM代理）**

当前，大多数LLM代理使用的是**基于token的记忆方法**，即将对话历史以**原始文本形式存储在外部数据库中**，典型系统包括Zep、Mem0和MemGPT等。这些代理在**长期对话基准测试**和**文档检索任务**中表现良好。

**然而，其内存架构较为简单**，主要问题包括：
- **缺乏模块化**，无法有效实现记忆路由；
- **检索和使用效率低下**。

因此，尽管这些系统在特定任务上表现优异，但在**真实应用场景中仍有不足**。

---

### **Various Memory Types（不同类型的记忆）**

从认知科学的角度来看，记忆通常被分为**短期记忆**（工作记忆）和**长期记忆**。在LLM的研究中，短期记忆通常对应**模型的上下文窗口**，而长期记忆则泛指**上下文之外的所有信息**。

为克服这种粗略的划分，近期研究提出了**更细致的记忆架构**，例如：

- **情节记忆**（episodic memory）：记录具体的事件和经历（如Pink等人强调其在LLM代理中的重要性）；
- **语义记忆**（semantic memory）：存储普遍知识，对**现实世界推理和抽象能力**至关重要；
- **程序记忆**（procedural memory）：负责学习技能和执行常规任务。

尽管已有研究识别出这些记忆类型的重要性，但目前的系统仍**停留在识别阶段**，**尚未形成系统化的记忆体系**。

---

### **Multi-Agent Systems（多智能体系统）**

不同于传统的单一智能体架构，近年来的研究转向**多智能体系统**，通过多个**功能专一的智能体协作**完成复杂任务。早期系统如AutoGPT和BabyAGI使用**共享记忆日志**的自动规划执行循环。

更近期的研究提出**角色专业化**的设计，例如：

- **MetaGPT**：模拟软件开发团队的结构；
- **AgentVerse**：为智能体分配特定角色（如规划、评估）。

认知科学也支持**模块化的记忆结构**，尤其强调**情节记忆与语义记忆的区分**。

受这些思想启发，**MIRIX系统部署了八个专门的智能体**，每个智能体负责管理一种特定的记忆类型（如情节记忆、语义记忆、程序记忆），并通过协作处理**多模态输入**，实现更高效的智能行为。

---

### 总结

本节全面回顾了当前**大语言模型中内存增强技术**的研究现状，涵盖：

1. **模型结构改进**（引入多种潜在空间记忆机制）；
2. **LLM代理系统的记忆方法**（以token为单位存储对话历史）；
3. **认知科学启发的记忆类型划分**（情节、语义、程序等）；
4. **多智能体系统的发展**（通过角色分工实现模块化协作）。

这些研究虽然在多个方面取得进展，但仍面临**模型兼容性差、记忆系统不完整、模块化不足**等挑战。**MIRIX系统正是在这些基础上，提出了一种更完整的、基于多智能体的记忆架构**。


## 6 Conclusion and Future Work



## 6 结论与未来工作

在本研究中，我们提出了 **MIRIX**，这是一种新型的**记忆架构**，旨在**提升基于大语言模型（LLM）的智能体**在**长期推理**和**个性化能力**方面的表现。与目前主要依赖**扁平存储**或**有限记忆类型**的现有记忆系统不同，MIRIX 采用了**结构化和组合式的方法**，集成了六个专门的记忆组件：**核心记忆（Core）**、**情景记忆（Episodic）**、**语义记忆（Semantic）**、**程序性记忆（Procedural）**、**资源记忆（Resource）** 和 **知识库（Knowledge Vault）**。这些组件由**各自的记忆管理器**管理，并在**元记忆管理器（Meta Memory Manager）**的协调下协同工作。

**重点内容**：  
我们设计了一项**具有挑战性的多模态基准测试**，该测试基于**真实用户活动的高清截图**，以严格评估 MIRIX 的性能。实验结果显示，与**检索增强生成**和**长上下文基线**相比，MIRIX 在**准确性和存储效率**方面都取得了显著提升。在 **LOCOMO 基准测试**中的实验进一步验证了 MIRIX 在**长对话场景**中达到了**当前最优的性能**。

此外，为了让更多用户能够实际体验 MIRIX 的能力，我们开发并发布了**一款由 MIRIX 驱动的个人助手应用**，使用户能够在**日常场景中获得一致且记忆增强的交互体验**。我们希望这项工作能够为构建更加**稳健、可扩展且类似人类的记忆系统**铺平道路。

**未来工作**：  
我们计划**构建更具挑战性的现实世界基准**，以全面评估 MIRIX 的性能。同时，我们将持续改进 MIRIX 及其相关的**个人助手应用**，以**为用户提供更优质的服务体验**。


## Appendix A Full Experimental Results with Different Runs



以下是对 **Appendix A Full Experimental Results with Different Runs** 的中文总结，按原文结构进行讲解，并对重点内容做了突出说明：

---

## Appendix A Full Experimental Results with Different Runs

本节报告了 **MIRIX** 和 **Full-Context** 方法在使用 **gpt-4.1-mini** 时的多次运行结果，完整结果见 **表3**。文中指出，尽管不同运行之间存在一些变化，但 **MIRIX** 在所有运行中都保持了 **最先进的性能**。

### 主要内容总结：

- **实验设计与数据来源**：
  - 使用 **gpt-4.1-mini** 作为基础模型。
  - 对 MIRIX 和 Full-Context 方法分别进行了 **三次独立运行**。
  - 全部预测结果与 LLM-Judge 评分数据存放于公开 GitHub 仓库中，地址为：
    > <https://github.com/Mirix-AI/MIRIX/tree/public_evaluation/public_evaluations/evaluation_metrics>
  
- **重点表格：Table 3**
  - 表中比较了不同方法在 **LOCOMO 数据集** 上的表现，按照问题类型分为：
    - **Single Hop**（单跳）
    - **Multi-Hop**（多跳）
    - **Open Domain**（开放领域）
    - **Temporal**（时间相关）
    - **Overall**（整体）
  - 每个指标的得分使用 **LLM 作为评估者**（LLM-Judge）进行打分，**百分比越高越好**。

- **表中重点方法表现对比**：
  - **MIRIX 的表现非常突出**：
    - 三次运行的平均得分为：
      - **Single Hop：85.0%**
      - **Multi-Hop：83.7%**
      - **Open Domain：65.6%**
      - **Temporal：88.3%**
      - **Overall：85.3%**
    - 在所有指标上均优于大多数基线方法，特别是在 **Multi-Hop** 和 **Temporal** 任务上表现尤其优异。
  - **Full-Context 的表现接近上限**：
    - 文中提到，由于 LOCOMO 数据集的平均长度仅为 9k token，**Full-Context**（即直接使用完整上下文）几乎可以看作是性能上限。
    - MIRIX 能够在大多数任务中接近甚至略超 Full-Context，表明其在记忆系统设计上的显著进步。
  - **其他方法表现**：
    - **Zep**：使用 gpt-4.1-mini 时仅得 49.09%，作者怀疑其实现可能存在问题，因此未报告。
    - **Memobase** 和 **Zep** 在 Temporal 任务上表现较好，但整体表现不如 MIRIX。
    - **LangMem**、**Mem0** 等方法的表现中等，低于 MIRIX。

- **结论**：
  - 尽管多次运行间存在轻微波动，**MIRIX 在所有运行中都保持了 SOTA 表现**。
  - 实验结果展示了 MIRIX 在多跳推理、时间任务和长文本处理等方面的优势。
  - 与 Full-Context 接近的性能表明，MIRIX 在有效记忆管理和上下文压缩方面取得了重要进展。

---

### 补充说明：
- **LLM-Judge 评分方式**：使用 LLM 作为评分器对生成结果进行判断，这种方式已成为当前评估 LLM 系统性能的常用方法。
- **公开数据与复现支持**：作者提供了完整的评估结果和预测输出，方便后续研究者进行复现与比较。

---

### 总结：
本附录通过多轮实验验证了 **MIRIX** 在多类型任务中的鲁棒性和优越性能，特别是在记忆管理和上下文压缩方面表现出色。与 Full-Context 接近的表现表明，MIRIX 已经接近当前 LLM 处理长文本任务的理论上限。
