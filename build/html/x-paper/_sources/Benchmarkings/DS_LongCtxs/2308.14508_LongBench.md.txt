# 2308.14508_LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding

* <https://arxiv.org/abs/2308.14508>
* PDF: <https://arxiv.org/pdf/2308.14508>
* 引用: 320(2025-08-15)
* 组织
    * 1Tsinghua University 
    * 2Zhipu.AI 
    * 3Institute of Automation, Chinese Academy of Sciences



## From Deepseek

提出了首个针对长文本理解的双语（中英文）、多任务基准测试框架——**LongBench**。该研究旨在解决当前大语言模型（LLMs）在长上下文理解能力评估上的不足，尽管现有模型在短文本任务中表现优异，但对书籍、报告、代码库等长序列输入的处理能力仍有限。  

### **核心贡献**  
1. **基准构建**：  
   - 包含**21个数据集**，覆盖**6类任务**（单文档问答、多文档问答、摘要、小样本学习、合成任务、代码补全），平均长度达6,711词（英文）和13,386字符（中文）。  
   - 支持中英双语，任务设计贴近实际长文本应用场景（如法律、学术、编程等）。  
   - 数据格式统一，便于自动化评估。  

2. **实验发现**：  
   - **商业模型（如GPT-3.5-Turbo-16k）**优于开源模型，但在更长上下文仍存在挑战。  
   - **技术改进**：扩展的位置编码（scaled position embedding）和长序列微调能显著提升长文本理解能力。  
   - **上下文压缩技术**（如检索增强）对弱长上下文模型有帮助，但效果仍不及原生强长上下文模型。  

### **意义**  
LongBench为长文本理解提供了标准化、多维度的评估工具，推动了模型在长上下文场景下的能力优化，并为未来研究（如位置编码、记忆机制）提供了方向。  












