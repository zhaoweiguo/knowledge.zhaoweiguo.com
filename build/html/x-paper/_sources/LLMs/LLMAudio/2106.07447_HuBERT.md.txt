# 2106.07447_HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units

* 首页: [https://arxiv.org/abs/2106.07447](https://arxiv.org/abs/2106.07447)
* PDF: [https://arxiv.org/pdf/2106.07447](https://arxiv.org/pdf/2106.07447)
* 组织: 无
* 引用: 3789(2025-07-26)


## 总结

* 简介
    * Hidden-Unit BERT (HuBERT) 
    * 目标
        * 通过自监督学习方式，从大量未标注的语音数据中学习到高质量的语音表示，从而提升语音处理任务（如语音识别、语音合成等）的性能
    * 方法
        * 通过掩码预测隐藏单元的机制
* 核心思想：预测隐藏单元
   - 掩码预测任务：受BERT在NLP中的启发，HuBERT对输入语音进行随机掩码（遮蔽部分时间段）。
   - 预测目标：模型需预测**被掩码区域**对应的**隐藏单元**（Hidden Units），而非原始音频或传统声学特征（如MFCC）。
   - 隐藏单元的本质：这些单元是**离线聚类算法**（如k-means）对MFCC或模型中间特征生成的**伪标签**，可视为数据驱动的“声学单元”。
* 两阶段训练流程
   - 第一阶段：用基础声学特征（MFCC）进行聚类，生成初始伪标签训练模型。
   - 第二阶段：用**第一版HuBERT模型提取的特征**重新聚类，生成更优质的伪标签，再训练最终模型。  
   - （迭代优化：伪标签质量随模型提升而改善）
* 关键创新：避免直接量化
   - 对比**wav2vec 2.0**（需学习量化模块将连续语音离散化），HuBERT直接使用聚类生成的**离线伪标签**作为预测目标：
     - **优势1**：规避量化模块的学习难度和潜在信息损失。
     - **优势2**：标签生成与模型训练解耦，简化优化过程。
* 模型架构
   - **特征编码器**：卷积神经网络（CNN），将原始音频转换为帧级特征。
   - **上下文编码器**：Transformer，学习长距离依赖关系。
   - **预测头**：在掩码位置预测对应隐藏单元的分布。
* **性能优势**
   - **低/高资源任务均领先**：在LibriSpeech（960小时）和Libri-light（6万小时）上训练后，HuBERT在ASR任务上超越同期模型（如wav2vec 2.0），尤其在小规模标注数据场景下泛化能力更强。
   - **多任务泛化性**：学到的表示可迁移到说话人识别、情感识别等任务。
* 核心贡献总结
   - **任务设计**：将语音自监督学习转化为**掩码区域伪标签预测**问题。
   - **标签策略**：通过**迭代聚类**生成渐进优化的伪标签，替代量化模块。
   - **效率与效果**：两阶段训练实现高性能，且规避了量化噪声。
* 意义
    * HuBERT证明了**基于聚类伪标签的掩码预测**是学习通用语音表征的有效范式，推动了自监督语音模型的发展，为后续模型（如WavLM）奠定了基础。
* 总结
    * HuBERT的核心是通过**预测掩码区域的聚类伪标签**学习语音表示，其创新在于利用**离线聚类生成目标**替代量化模块，并通过**两阶段迭代优化**提升表示质量，最终在多个语音任务上达到SOTA性能。




## LLM 总结

本文提出了一种名为 **HuBERT (Hidden Unit BERT)** 的自监督语音表示学习模型。该模型借鉴了自然语言处理中 BERT 的掩码预测机制，将其应用于语音信号的隐藏单元预测任务中，以实现对语音信号的自监督学习。以下是文章内容的总结：

### 概述
- **目标**：通过自监督学习方式，从大量未标注的语音数据中学习到高质量的语音表示，从而提升语音处理任务（如语音识别、语音合成等）的性能。
- **方法**：HuBERT 通过掩码部分的语音隐藏单元，并预测这些被掩码的单元，从而学习语音的上下文表示。

### 方法细节
1. **预训练框架**：
   - 使用一个标准的卷积神经网络（CNN）对输入语音信号进行编码，提取出语音的隐藏表示（hidden units）。
   - 将隐藏表示输入到一个基于 Transformer 的模型中，进行掩码预测任务。

2. **掩码机制**：
   - 在训练过程中，随机掩码一部分时间步的隐藏表示。
   - 使用 Transformer 模型基于未被掩码的上下文来预测被掩码的单元。

3. **聚类与伪标签**：
   - 在训练初期，使用聚类算法（如 K-means）对隐藏单元的表示进行聚类，生成伪标签。
   - 随着训练的进行，伪标签的粒度逐渐细化，从粗粒度的聚类标签过渡到更细粒度的单元预测，从而逐步提升模型的表达能力。

4. **自监督学习过程**：
   - 仅使用未标注的语音数据进行训练。
   - 模型通过预测被掩码的隐藏单元，学习到语音的上下文表示。

### 实验与结果
- 在多个语音识别任务中，HuBERT 的性能优于许多监督和自监督学习方法。
- 通过不同阶段的伪标签优化，模型能够逐步学习到更丰富的语音表示。
- 模型在少量标注数据的微调下，也能取得良好的性能，显示出较强的数据效率。

### 结论
- **HuBERT 是一种有效的自监督语音表示学习方法**，它通过掩码预测隐藏单元的机制，能够从大量未标注语音数据中提取出高质量的语音表示。
- 该方法具有良好的可扩展性和应用前景，可广泛用于语音识别、语音合成以及其他语音处理任务中。

这篇文章展示了自监督学习在语音处理领域的巨大潜力，并为后续研究提供了重要的方法参考。


## Abstract



本文提出了一种名为**Hidden-Unit BERT (HuBERT)** 的自监督语音表示学习方法，旨在解决语音表示学习中的三个独特挑战：  
1. 每个语音输入包含多个语音单位；  
2. 预训练阶段无语音单位的词典；  
3. 语音单位长度不一且无显式分割。

为解决这些问题，HuBERT采用了**离线聚类**方法，为类似于BERT的预测损失提供对齐的标签。其核心思想是**仅在被遮蔽的区域应用预测损失**，从而迫使模型学习连续输入中的**声学与语言联合表示**。该模型主要依赖于无监督聚类步骤的一致性，而非聚类标签本身的质量。

实验结果显示，尽管采用的是一个简单的100个聚类的k-means教师模型，并仅进行两次迭代聚类，HuBERT在Librispeech和Libri-light基准数据集上的表现**达到甚至超过了**当前最先进的wav2vec 2.0模型，且在不同训练时长（10分钟、1小时、10小时、100小时、960小时）下均表现优异。使用10亿参数模型时，HuBERT在更具挑战性的**dev-other**和**test-other**评估子集上分别实现了**19%和13%的相对词错误率（WER）减少**。

该研究展示了HuBERT在自监督语音表示学习中的强大性能和泛化能力。


## I Introduction

![](https://img.zhaoweiguo.com/uPic/2025/07/AE98cc.png)

Figure 1:The HuBERT approach predicts hidden cluster assignments of the masked frames (y2,y3,y4 in the figure) generated by one or more iterations of k-means clustering.

本章节主要介绍了**高保真语音表示学习**的背景、挑战以及当前的研究方法，重点提出了一种名为**HuBERT**的自监督学习模型，并展示了其在语音识别任务中的卓越表现。

### 内容总结如下：

1. **研究背景与目标**：
   - 语音表示学习的目标是模仿婴儿学习语言的过程，通过聆听和互动来学习高保真语音表示，包括内容信息和非词汇信息（如说话人身份、情绪、语调等）。
   - 理解完整情境还需要建模与语音信号交错的背景噪声（如笑声、咳嗽、环境音等）。

2. **自监督学习的必要性**：
   - 由于高质量标注数据获取困难，自监督学习逐渐成为主流，它通过设计预训练任务，从输入信号本身提取目标，无需依赖语言资源。
   - 自监督任务包括时序特征区分、音频特征预测、掩码音频特征预测等。

3. **伪标签方法（Pseudo-Labeling）**：
   - 该方法通过已有监督数据训练教师模型，然后对无标签数据生成伪标签，并用于训练学生模型。
   - 虽然有效，但其依赖教师模型的监督数据质量，且难以泛化到多个任务，存在局限性。

4. **自监督学习的优势**：
   - 自监督学习方法能更全面地建模输入信号的所有信息，学习到的表示更具通用性。
   - 在计算机视觉（CV）和自然语言处理（NLP）领域已取得显著成果，但在语音领域面临独特挑战（如连续信号建模、单元边界未知等）。

5. **HuBERT模型的提出**：
   - HuBERT是一种适用于语音信号的自监督学习模型，采用离线聚类生成噪声标签，进行类似BERT的预训练。
   - 通过掩码预测聚类标签，迫使模型学习有意义的连续潜在表示，同时建模语音的时序结构。
   - 启发自DeepCluster，但结合了语音序列的掩码预测机制。

6. **实验与结果**：
   - HuBERT在标准LibriSpeech 960h和Libri-Light 60k小时数据集上进行预训练，在多个微调数据子集（10分钟到960小时）中表现优于或匹敌当前最先进的 wav2vec 2.0 模型。
   - 提供了三种模型规模（Base, Large, X-Large），其中 X-Large 在 Libri-Light 数据集上相对 Large 模型在测试集上分别实现了 19% 和 13% 的相对词错误率（WER）提升。

### 总体观点：
该章节强调了自监督学习在语音表示学习中的重要性，尤其在减少对标注数据依赖方面具有显著优势。通过提出 HuBERT 模型，作者展示了如何在连续语音信号中有效结合聚类与掩码预测，从而实现高效、可扩展的语音表示学习。


## II Method



本章节主要介绍了 **HuBERT**（Hidden Unit BERT）的 **方法实现与训练机制**，从模型结构到训练策略进行了详细描述。以下是内容总结：

---

### **II-A：学习隐状态（Hidden Units）**
- HuBERT 通过 **自监督学习** 提取语音隐状态（Hidden Units），替代传统的基于文本和语音对的伪标签（伪音素标签）。
- 使用 **k-means** 或更复杂的模型来生成音频帧的隐状态，这类方法能够发现与语音基本单位（如音素）相关联的结构。
- 隐状态表示为 Z = [z₁, z₂, ..., zₜ]，其中 zₜ 是一个类别变量，表示第 t 帧的聚类结果。
- 图 1 展示了 HuBERT 的结构，模型预测被掩码的帧的聚类标签。

---

### **II-B：掩码预测进行表示学习**
- 受 SpanBERT 和 wav2vec 2.0 启发，HuBERT 使用 **掩码预测机制**：随机选择一部分帧进行掩码，模型需要从上下文中预测这些掩码帧的隐状态。
- **掩码策略**：使用连续的 span 进行掩码，模拟真实语音中缺失片段的情况。
- **损失函数设计**：
  - Lₘ：仅对掩码帧预测的损失；
  - Lᵤ：对未掩码帧预测的损失；
  - L = αLₘ + (1 - α)Lᵤ，通过 α 控制训练侧重。
- α = 0 时，类似传统声学建模；α = 1 时，类似语言建模，更关注上下文建模，对聚类质量不敏感。

---

### **II-C：使用聚类集成（Cluster Ensembles）**
- 为了提升隐状态的质量，HuBERT 采用多个聚类模型（如不同码本大小的 k-means）。
- 相当于 **多任务学习**，每个聚类模型提供不同粒度的隐状态标签。
- 还结合 **乘积量化（PQ）**，将高维特征分解为多个子空间，分别进行量化，提升量化效果。

---

### **II-D：迭代优化聚类分配**
- 在模型训练过程中，利用预训练模型输出的表示，迭代更新聚类模型，生成新的隐状态。
- 通过这种方式，逐步提升隐状态与语音单位的匹配度。

---

### **II-E：模型实现细节**
- **模型架构**：基于 wav2vec 2.0，包括卷积编码器、BERT 编码器、投影层和码本嵌入层。
- **三种配置**：Base、Large 和 X-Large，参数量分别为约 95M、317M 和 964M。
- **卷积编码器**：七层卷积，步长和卷积核大小固定，输入为 16kHz 声音数据，降采样因子为 320×，输出帧率为 20ms。
- **BERT 编码器**：多层 Transformer，不同配置层数不同（12 / 24 / 48 层）。
- **掩码与预测机制**：掩码后输入 BERT，输出使用投影矩阵和码本嵌入计算相似度，输出聚类分布。
- **微调阶段**：使用 CTC 损失进行语音识别（ASR）微调，仅优化 BERT 部分，冻结卷积编码器。

---

### 总结：
本章详细介绍了 HuBERT 的 **模型结构**、**训练目标**（掩码预测）、**聚类生成与优化策略**，以及 **实现细节**。通过自监督学习与掩码预测机制，HuBERT 能够在没有文本标注的情况下，从语音数据中学习高质量的语音表示，为后续语音识别等任务提供有力支持。


## III Related Work



该章节主要回顾了与自监督语音表征学习相关的研究工作，并按训练目标进行分类讨论：

1. **基于生成模型的方法**：早期研究通过构建带有潜在变量的生成模型来学习语音表示，假设这些潜在变量能够捕捉语音中的语音信息。模型训练的目标是最大化似然函数，而不同的潜在结构（如连续、离散或序列结构）被用来编码先验假设。

2. **基于预测的自监督学习方法**：近年来，该方向受到越来越多关注。模型任务包括预测未见区域的内容或通过对比目标帧与随机采样的帧。部分模型结合了预测损失和对比损失。这些目标通常可解释为互信息最大化。此外，也有一些目标不属于上述类别。

3. **与DiscreteBERT的比较**：本文工作与DiscreteBERT密切相关，两者都通过预测被掩码区域的离散目标进行训练。但HuBERT有几点关键不同：首先，HuBERT使用原始波形作为输入，而非量化单元，从而保留更多信息；其次，实验表明，使用简单的k-means目标即可获得优于DiscreteBERT所用vq-wav2vec量化单元的性能；此外，HuBERT还引入了多种提升教师模型质量的技术，而非使用固定教师模型。

4. **与wav2vec 2.0的比较**：虽然HuBERT与wav2vec 2.0相关，但后者依赖于复杂的对比损失设计、辅助多样性损失以及Gumbel-softmax温度退火机制。而HuBERT通过将声学单元发现与掩码预测学习分离，采用更直接的预测损失，实现了与或优于wav2vec 2.0的效果。

5. **与半监督ASR中的伪标签方法的关系**：HuBERT中迭代改进目标标签的思路，类似于半监督ASR中的迭代伪标签方法，但将其扩展至自监督学习框架，并结合掩码预测损失。

总结来说，该章节系统回顾了自监督语音表示学习的相关方法，分析了各类方法的优缺点，并指出HuBERT在多个方面进行了改进，从而实现了更优的性能。


## IV Experimental Details



本章节详细描述了论文中用于HuBERT模型实验的具体细节和评估方法，主要包括以下几个方面：

### 数据集
- **无监督预训练**：使用960小时的LibriSpeech音频或60,000小时的Libri-light音频，均来自LibriVox项目。
- **监督微调**：考虑了五个不同的划分：Libri-light的10分钟、1小时、10小时划分，以及LibriSpeech的100小时和960小时划分。其中，Libri-light划分是LibriSpeech的子集，每部分包含一半来自train-clean和另一半来自train-other的音频。

### 无监督单元发现
- 使用**K-means算法**进行声学单元发现，初始使用39维MFCC特征进行聚类（13个系数及其一阶和二阶导数）。
- 随后，使用HuBERT模型的中间Transformer层特征进行改进的聚类（500个簇），但由于HuBERT输出维度较高，仅使用10%的数据进行训练。
- 使用MiniBatchKMeans算法进行大规模聚类，设置批大小为10,000帧，并使用K-means++进行初始化。

### 预训练
- **Base模型**：使用960小时LibriSpeech音频，训练2轮，使用32个GPU，每轮训练250k步和400k步。
- **Large和X-Large模型**：使用60,000小时Libri-light音频，分别使用128和256个GPU训练400k步。
- 所有模型使用Adam优化器，学习率从0线性增长到峰值，再线性衰减回0。Base/Large/X-Large的峰值学习率分别为5e-4/1.5e-3/3e-3。

### 监督微调与解码
- 每个模型在8个GPU上微调，训练批次大小根据模型大小不同（200/80/40秒/GPU）。
- 使用**wav2letter++**和**Fairseq**的解码器，融合语言模型进行解码，优化目标包括CTC概率和语言模型分数。
- 使用Ax工具进行超参数搜索，包括学习率、训练步数、冻结步数等。

### 目标质量评估
- 通过**强制对齐的音素标签**与K-means聚类结果之间的关联性，评估聚类质量。
- 定义三个评估指标：
  1. **音素纯度（Phone Purity）**：衡量每个聚类类中最可能音素的准确率。
  2. **簇纯度（Cluster Purity）**：衡量每个音素中最可能聚类类的准确率。
  3. **归一化互信息（PNMI）**：衡量聚类标签对音素标签信息的保留程度。

### 实验结果
- 表格总结了不同模型在不同标注数据量下的表现，包括10分钟、1小时、10小时、100小时和960小时的标注数据。
- HuBERT模型在多个设定下表现优于其他模型，尤其是Large和X-Large模型在高资源设定下接近SOTA水平。

### 总结
本章详细描述了实验中使用的数据、训练流程、聚类方法、微调策略以及模型评估方式，通过不同模型和设定的比较，证明了HuBERT在自监督语音表示学习中的优越性。


## V Results



这篇论文的“V 结果”部分主要围绕HuBERT模型的实验结果和分析展开，包括低资源和高资源设置下的性能比较、聚类稳定性、不同层和迭代的聚类质量、训练目标的影响、超参数调整等方面的探讨。以下是本章内容的总结：

---

### **V-A 主要结果：低资源与高资源设置**

在低资源设置中，HuBERT模型在仅使用10分钟、1小时、10小时或100小时标注数据的情况下，通过微调取得了优异的性能表现。相比半监督和自监督方法（如IPL、wav2vec 2.0等），HuBERT在低资源下表现更优。例如，在仅使用10分钟标注数据的极端低资源设置中，HuBERT Large模型在test-clean和test-other上的词错误率（WER）分别为4.7%和7.6%，优于当前最先进的wav2vec 2.0模型。随着模型规模增加至1B参数，HuBERT X-Large模型进一步将WER降低到4.6%和6.8%。

在高资源设置中，HuBERT在微调960小时LibriSpeech数据时，性能与基于wav2vec 2.0的对比学习模型相当，但略逊于结合预训练和自训练方法的模型。然而，已有研究表明，结合自训练可显著提升HuBERT的性能，因此作者预期其在自训练优化后将表现更佳。

---

### **V-B 分析：K-Means聚类稳定性**

研究了K-Means聚类在不同聚类数量和不同训练数据量下的稳定性。结果显示：
- 聚类稳定性较好（标准差小）。
- 使用HuBERT特征进行聚类比MFCC特征表现更优，尤其是在500个聚类的情况下，PNMI（电话归一化互信息）显著提高。
- 聚类质量的提升验证了迭代优化的必要性。

---

### **V-C 分析：不同层和迭代的聚类质量**

分析了HuBERT模型在不同层和不同迭代中用于聚类的效果。结果表明：
- 所有层中，HuBERT的聚类质量明显优于MFCC。
- Base-it2（第二轮迭代）模型的聚类质量在多数指标上优于Base-it1，尤其是在电话纯度（phone purity）和PNMI方面。
- Base-it1模型在中间层（如第6层）表现最佳，但末尾层质量下降，可能与其训练目标质量较差有关。

---

### **V-D 消融实验：预测掩码帧的重要性**

通过设置不同的训练目标：
- 仅预测掩码帧（α=1.0）优于预测所有帧（α=0.5）或仅预测未掩码帧（α=0.0）。
- 当使用高质量聚类（如Base-it1的第6层）时，掩码帧的损失对性能提升帮助最大。
- 在使用低质量聚类时，仅预测掩码帧可显著减少词错误率。

---

### **V-E 消融实验：聚类集成的影响**

研究了使用多个K-Means模型进行聚类集成的效果：
- 使用多个不同聚类数的K-Means模型（如50、100、500）或使用拼接特征和乘积量化（Product K-means）方法，能够提高整体性能。
- 聚类集成方法的WER优于单一K-Means模型。

---

### **V-F 消融实验：超参数影响**

分析了不同超参数（如掩码比例、批量大小、训练步数）对HuBERT性能的影响：
- 最优掩码比例为6.5%；
- 增加批量大小（通过更多GPU）可提升性能；
- 延长训练步数有助于模型性能提升，特别是对于低聚类数（如C=100）效果更明显；
- 在400k步训练时，HuBERT在test-other上的WER达到11.68%。

---

### **总结**

本章通过一系列实验验证了HuBERT模型在不同资源设置下的有效性与鲁棒性。关键结论包括：
- HuBERT在低资源环境下表现优异，优于现有自监督和半监督方法；
- 使用高质量特征（如HuBERT中间层）和迭代优化的聚类方法显著提升模型效果；
- 仅预测掩码帧、使用聚类集成和合理设置超参数是提升性能的关键因素；
- 尽管在某些高资源设置下略逊于结合自训练的方法，但HuBERT具备通过进一步优化实现更好性能的潜力。

这些实验结果为HuBERT模型的改进和实际应用提供了重要依据。


## VI Conclusion



本文总结如下：

本论文提出了HuBERT，一种基于预测连续输入中被遮蔽片段的K-means聚类分配的语音表征学习方法。在Librispeech 960小时和Libri-light 60,000小时的预训练设置下，HuBERT在所有微调子集（10分钟、1小时、10小时、100小时和960小时）上均达到或超过了当前最先进的系统表现。此外，通过迭代优化K-means聚类分配并使用前一迭代的潜在表征，模型的表征质量显著提升。HuBERT还能够扩展到10亿参数的Transformer模型，在test-other数据集上相对词错误率（WER）最多降低了13%。未来的工作方向包括改进HuBERT的训练过程，使其仅需单阶段训练；同时，由于其表征质量优异，研究团队计划将HuBERT应用于语音识别（ASR）以外的多种下游识别和生成任务中。
