# 2005.08100_Conformer: Convolution-augmented Transformer for Speech Recognition

* 首页: [https://arxiv.org/abs/2005.08100](https://arxiv.org/abs/2005.08100)
* PDF: [https://arxiv.org/pdf/2005.08100](https://arxiv.org/pdf/2005.08100)
* 引用: 4060(2025-07-23)


## LLM总结

本文提出了一种新的模型架构 **Conformer**，用于语音识别任务。Conformer 结合了 **Transformer** 和 **卷积神经网络（CNN）** 的优点：在传统的 Transformer 架构中引入了 CNN 模块，以增强模型在局部特征提取和建模时序信息方面的能力。

### 主要贡献包括：

1. **架构设计**：
   - Conformer 基于 Transformer 的编码器结构，但在每个编码器层中加入了一个 **多层感知机（MLP）卷积模块**，该模块通过深度可分离卷积（depthwise separable convolution）来提取局部特征。
   - 每个编码器层包含：多头自注意力（MHSA）、卷积模块、前馈网络（FFN）以及残差连接和层归一化。

2. **实验验证**：
   - 在多个语音识别基准数据集（如 LibriSpeech）上进行了实验，结果表明 Conformer 在词错误率（WER）方面优于传统的 Transformer 和 CNN 模型。
   - Conformer 在不同规模的数据集上均表现出良好的性能，尤其在大规模数据集上优势更为明显。

3. **可扩展性与灵活性**：
   - Conformer 的模块化设计使其易于调整和扩展，适用于不同语音识别场景。
   - 通过调整卷积核大小、通道数等参数，可以灵活控制模型的感知范围和复杂度。

### 总结：

Conformer 通过将 CNN 与 Transformer 有效结合，提升了语音识别模型在建模局部特征和长距离依赖关系上的能力。实验结果表明，Conformer 在多个语音识别任务中均取得优于现有方法的性能，具有很好的实用价值和研究前景。


## Abstract



该研究摘要主要总结了以下内容：

近年来，基于Transformer和卷积神经网络（CNN）的模型在自动语音识别（ASR）任务中表现出优于循环神经网络（RNN）的潜力。Transformer擅长捕捉音频序列中的全局内容交互，而CNN在提取局部特征方面效果显著。

本研究旨在结合Transformer与CNN的优势，以参数高效的方式同时建模音频序列的局部和全局依赖关系。为此，作者提出了一种用于语音识别的**卷积增强型Transformer模型（Conformer）**，该模型在性能上显著优于之前的Transformer和CNN模型，并达到了当前最先进的准确率。

在广泛使用的LibriSpeech基准测试中，该模型在不使用语言模型的情况下，达到测试集和测试其他集的词错误率（WER）分别为2.1%和4.3%，而在使用外部语言模型时，该指标进一步提升至1.9%和3.9%。此外，作者还训练了一个仅含1000万参数的小型模型，其表现也具有竞争力（WER为2.7%/6.3%）。

关键词包括：语音识别、注意力机制、卷积神经网络、Transformer、端到端模型。


## 1 Introduction



本文综述了近年来基于神经网络的端到端语音识别（ASR）系统的进展，重点探讨了如何将自注意力机制（如Transformer）与卷积神经网络（CNN）有效结合，以提升模型性能并提高参数效率。

文章首先回顾了传统RNN在建模音频时序依赖方面的优势，随后指出Transformer由于其捕捉长距离依赖和高效训练能力已成为主流。另一方面，CNN虽然擅长提取局部特征，但在捕捉全局信息方面存在限制。为了解决这一问题，现有工作如ContextNet引入了挤压激励模块来增强局部卷积的感受野，但其全局上下文建模能力仍然有限。

随后，作者指出结合自注意力和卷积机制可以取长补短：自注意力捕捉全局内容交互，而卷积提取局部特征。已有研究如多分支架构表明，这种组合在任务如机器翻译中具有优势。受此启发，作者提出了一种名为**Conformer**的新模型架构，将自注意力模块和卷积模块有机融合，并夹在两个前馈网络之间，形成“沙拉三明治”结构。

Conformer的具体实现包含：
- 通过点卷积、GLU激活、1D深度卷积和Swish激活组成卷积模块，以高效捕捉局部上下文；
- 利用多头自注意力机制建模全局依赖；
- 整体结构兼具局部特征提取与全局信息整合的优势。

实验证明，Conformer在LibriSpeech数据集上达到了SOTA性能。不同参数规模的模型（10M、30M、118M）均表现出优于现有模型的表现，例如30M参数的Conformer模型性能已超过使用139M参数的Transformer Transducer模型。此外，作者还系统研究了注意力头数、卷积核大小、激活函数、前馈网络位置等超参数对模型性能的影响，揭示了各组件对准确率提升的贡献。


## 2 Conformer Encoder



本章主要介绍 **Conformer Encoder** 的结构，它是 Conformer 模型的核心部分。相比于传统的 Transformer 模型，Conformer 的创新在于将 **Transformer Block 替换为 Conformer Block**，并在其中引入了 **卷积模块（Convolution Module）**，以增强模型对局部特征的提取能力。

### 主要内容总结：

#### 1. **Conformer Encoder 的整体结构**
- 输入首先经过一个 **卷积下采样层（convolution subsampling layer）**，将输入的音频信号进行压缩。
- 然后输入到多个 **Conformer Block** 中进行处理。
- 每个 Conformer Block 由四个模块组成，按顺序分别为：  
  - **第一个 Feed Forward 模块（FFN）**  
  - **多头自注意力模块（Multi-Headed Self-Attention, MHSA）**  
  - **卷积模块（Convolution Module）**  
  - **第二个 Feed Forward 模块（FFN）**

#### 2. **Conformer Block 的关键组成模块**
- **多头自注意力模块（MHSA）**
  - 引入了 **相对位置编码（relative positional encoding）**，增强模型对不同长度输入的泛化能力。
  - 采用 **pre-norm 残差结构（pre-norm residual unit）** 和 **Dropout**，有助于训练更深的模型并进行正则化。
  
- **卷积模块（Convolution Module）**
  - 受启发于 [17]，结构包括：  
    - **逐点卷积 + GLU（Gated Linear Unit）** 作为门控机制  
    - **1D 深度可分离卷积（depthwise convolution）**  
    - **BatchNorm** 用于帮助深层网络训练
  - 卷积模块在 Conformer Block 中紧随自注意力模块之后，被证明在语音识别任务中效果最好。

- **前馈网络（Feed Forward Module, FFN）**
  - 结构为两层线性变换夹中间的非线性激活函数（Swish）。
  - 采用 **pre-norm 残差结构**，分别在输入和 FFN 内部进行 LayerNorm。
  - 第一层使用 **4 倍扩展因子**，最后一层将维度还原。

#### 3. **Conformer Block 的结构设计**
- Conformer Block 的结构借鉴了 **Macaron-Net** 的思想，将原有的单个 FFN 拆分为两个“半步 FFN”，分别在自注意力和卷积模块前后。
- 数学公式中展示了 Conformer Block 的输入输出过程，其结构为：  
  **FFN → MHSA → Conv → FFN**，并最终进行 LayerNorm。
- 实验表明，这种 **“夹心结构”显著优于传统的单 FFN Transformer Block**，尤其是在语音识别任务中。

#### 4. **模块组合与实验验证**
- 文中还探讨了多种 **卷积与自注意力模块的组合方式**，并通过消融实验验证了不同结构对模型性能的影响。
- 最终结论是：**将卷积模块放在自注意力模块之后效果最佳**。

---

### 总结：
本章详细介绍了 Conformer Encoder 的设计，重点在于 **Conformer Block** 的结构创新，包括引入卷积模块、采用相对位置编码和 Macaron-style 的 FFN 结构。这些设计使模型在保留 Transformer 强大建模能力的同时，增强了对局部结构的感知，提升了语音识别任务的性能。


## 3 Experiments



本章节主要介绍了Conformer模型在语音识别任务中的实验设置、模型架构、参数配置以及各类消融实验的结果分析，具体总结如下：

---

### **3.1 数据集**
实验使用 **LibriSpeech** 数据集，包含970小时的带标注语音数据和8亿词的文本语料库。特征提取使用80通道的滤波器组（filterbanks），窗口长度为25ms，滑动步长为10ms。采用 **SpecAugment** 进行数据增强，参数设置为 F=27，时间为10个时间掩码，最大时间掩码比例为0.05。

---

### **3.2 Conformer Transducer 模型**
构建了三种不同规模的模型：小（10.3M参数）、中（30.7M参数）、大（118.8M参数），通过调整网络深度、模型维度、注意力头数量选择最优模型。模型均使用单层LSTM解码器。正则化手段包括：
- 残差块的Dropout（0.1）
- Variational Noise
- ℓ2 正则化（权重系数为1e-6）
- Adam优化器（β1=0.9, β2=0.98, ϵ=1e-9）
- Transformer学习率调度（10k warm-up 步长，峰值学习率为 0.05/√d）

语言模型（LM）为3层LSTM，宽度4096，使用LibriSpeech语料训练，词级困惑度（perplexity）为63.9。所有模型使用 **Lingvo 工具包** 实现。

---

### **3.3 LibriSpeech 实验结果**
对三种模型在LibriSpeech数据集上的 **test-clean** 和 **test-other** 任务进行了评估，结果表明：
- 在无语言模型情况下，Conformer Medium模型（30.7M参数）在test-clean/test-other上达到2.3/5.0的WER，优于同规模Transformer和LSTM模型。
- 在有语言模型融合后，Conformer模型在所有模型中取得了最低的WER，例如Conformer Large模型达到1.9/3.9的WER，优于ContextNet等模型。
- 表明结合Transformer和卷积结构的Conformer模型在语音识别任务中具有显著优势。

---

### **3.4 消融实验（Ablation Studies）**

#### **3.4.1 Conformer Block vs. Transformer Block**
通过逐步去除Conformer Block中的独特组件（如卷积模块、Macaron风格FFN对、SWISH激活等），发现：
- **卷积模块是性能提升最关键的部分**。
- **Macaron风格的FFN比单个FFN更有效**。
- **SWISH激活函数有助于模型更快收敛**。

#### **3.4.2 卷积与Transformer模块的组合方式**
测试了不同模块组合方式对性能的影响，结果表明：
- **将卷积模块放在自注意力模块之后，效果最佳**。
- 使用轻量卷积替代深度卷积或使用并行结构均导致性能下降。

#### **3.4.3 Macaron Feed-Forward 模块**
分析了使用两个FFN（Macaron结构）与单一FFN模块的差异，发现：
- **Macaron结构略优于单一FFN结构**。
- 使用全步残差（full-step residual）对结果影响不大。

#### **3.4.4 注意力头的数量**
实验表明：
- 增加注意力头数量可提升效果，**16个头时效果最佳**。
- 超过16个头后性能提升不明显，甚至略有下降。

#### **3.4.5 卷积核大小**
测试了不同卷积核大小（3、7、17、32、65）对模型的影响，发现：
- **32大小的卷积核效果最佳**。
- 卷积核过大（如65）反而会降低性能。

---

### **总结**
本章通过在LibriSpeech数据集上对Conformer模型的全面实验和消融研究，验证了该模型在不同参数规模下均优于当前最先进的语音识别模型。Conformer结合了Transformer的注意力机制和卷积模型的局部建模能力，具有更高的准确性和稳定的性能表现。实验还揭示了模型中关键组件（如卷积模块、FFN结构、注意力头数量等）对性能的影响，为模型设计和优化提供了重要依据。


## 4 Conclusion



本章总结如下：

本文提出了Conformer模型，该模型将卷积神经网络（CNN）和Transformer的组件结合，用于端到端的语音识别。研究分析了各组件的重要性，证明了卷积模块对Conformer性能的关键作用。实验表明，与之前的工作相比，Conformer在LibriSpeech数据集上以更少的参数实现了更高的准确率，并在测试集和test-other上取得了新的最先进成绩，分别为1.9%和3.9%。
