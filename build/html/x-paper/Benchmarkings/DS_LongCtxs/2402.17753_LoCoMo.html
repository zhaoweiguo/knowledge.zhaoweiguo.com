

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="zh-CN" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="zh-CN" > <!--<![endif]-->
<head>


<!-- start added 2025-04-14   å¢åŠ å¯¹markdownä¸­å…¬å¼çš„æ”¯æŒ -->
<script>
window.MathJax = {
    tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true
    },
    options: {
        ignoreHtmlClass: "tex2jax_ignore|mathjax_ignore",
        processHtmlClass: "tex2jax_process|mathjax_process|math|output_area"
    }
};
</script>
<script defer="defer" src="https://fastly.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<!-- end added 2025-04-14   å¢åŠ å¯¹markdownä¸­å…¬å¼çš„æ”¯æŒ -->


  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>2402.17753_LoCoMo: Evaluating Very Long-Term Conversational Memory of LLM Agents &mdash; æ–°æºª-gordon V2025.07 æ–‡æ¡£</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
    <link rel="index" title="ç´¢å¼•" href="../../genindex.html" />
    <link rel="search" title="æœç´¢" href="../../search.html" />
    <link rel="next" title="2404.06654_RULER: Whatâ€™s the Real Context Size of Your Long-Context Language Models?" href="2404.06654_RULER.html" />
    <link rel="prev" title="2402.05136_LV-Eval: A Balanced Long-Context Benchmark with 5 Length Levels Up to 256K" href="2402.05136_LV-Eval.html" /> 

  
  <script src="../../_static/js/modernizr.min.js"></script>
  <script src="../../_static/js/jquery.min.js"></script>


<!-- è¯„è®ºæ’ä»¶ gittalk start -->
<!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script> -->
<!-- è¯„è®ºæ’ä»¶ gittalk end -->


</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> æ–°æºª-gordon
          

          
          </a>

          
            
            
              <div class="version">
                V2025.07
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../0normal.html">é€šç”¨</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../0normals/normal.html">é€šç”¨</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../0normals/normal.html#id3">å¦‚ä½•çœ‹ä¸€ä¸ªè®ºæ–‡æ˜¯ä¸æ˜¯é‡è¦</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../0normals/website.html">å­¦æœ¯ç½‘ç«™</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../0normals/website.html#id2">æ•´ä½“åˆ†æ</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../0normals/website.html#id3">1. å­¦æœ¯æœç´¢å¹³å°ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼šæ£€ç´¢ä¸å‘ç°æ–‡çŒ®ï¼‰</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../0normals/website.html#google-scholar">Google Scholar</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../0normals/website.html#semantic-scholar">Semantic Scholar</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../0normals/website.html#web-of-science">Web of Science</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../0normals/website.html#id4">ç™¾åº¦å­¦æœ¯</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../0normals/website.html#id5">2. èµ„æºå…±äº«å¹³å°ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼šå…è´¹è·å–ä»˜è´¹æ–‡çŒ®ï¼‰</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../0normals/website.html#sci-hub">Sci-Hub</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../0normals/website.html#library-genesis-libgen">Library Genesis (LibGen)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../0normals/website.html#unpaywall">Unpaywall</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../0normals/website.html#id6">è®ºæ–‡æ•°æ®åº“ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼šå­˜å‚¨ä¸æä¾›æ–‡çŒ®åŸæ–‡ï¼‰</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../0normals/website.html#acl-anthology">ACL Anthology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../0normals/website.html#arxiv">ArXiv</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../0normals/website.html#cnki">çŸ¥ç½‘ CNKI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../0normals/website.html#id10">ä¸‡æ–¹æ•°æ®åº“</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../../Benchmarking.html">è¯„æµ‹åŸºå‡†</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#id3">è¯„æµ‹åŸºå‡†</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../Standards/02xx.xxxxx_BLEU.html">02xx.xxxxx_BLEU: a Method for Automatic Evaluation of Machine Translation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Standards/02xx.xxxxx_BLEU.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/02xx.xxxxx_BLEU.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/02xx.xxxxx_BLEU.html#id8">ç¤ºä¾‹è®²è§£</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/02xx.xxxxx_BLEU.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/02xx.xxxxx_BLEU.html#the-baseline-bleu-metric">2.The Baseline BLEU Metric</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/02xx.xxxxx_BLEU.html#the-bleu-evaluation">3.The BLEU Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/02xx.xxxxx_BLEU.html#the-human-evaluation">4.The Human Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/02xx.xxxxx_BLEU.html#bleu-vs-the-human-evaluation">5.BLEU vs The Human Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/02xx.xxxxx_BLEU.html#conclusion">6.Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Standards/0401.xxxxx_ROUGE.html">0401.xxxxx_ROUGE: A Package for Automatic Evaluation of Summaries</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Standards/0401.xxxxx_ROUGE.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/0401.xxxxx_ROUGE.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/0401.xxxxx_ROUGE.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/0401.xxxxx_ROUGE.html#rouge-n-n-gram-co-occurrence-statistics">2.ROUGE-N: N-gram Co-Occurrence Statistics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/0401.xxxxx_ROUGE.html#rouge-l-longest-common-subsequence">3.ROUGE-L: Longest Common Subsequence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/0401.xxxxx_ROUGE.html#rouge-w-weighted-longest-common-subsequence">4 ROUGE-W: Weighted Longest Common Subsequence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/0401.xxxxx_ROUGE.html#rouge-s-skip-bigram-co-occurrence-statistics">5.ROUGE-S: Skip-Bigram Co-Occurrence Statistics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/0401.xxxxx_ROUGE.html#evaluations-of-rouge">6 Evaluations of ROUGE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/0401.xxxxx_ROUGE.html#conclusions">7 Conclusions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Standards/1803.01937_ROUGE2.html">1803.01937_ROUGE2.0: Updated and Improved Measures for Evaluation of Summarization Tasks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Standards/1803.01937_ROUGE2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/1803.01937_ROUGE2.html#problems-with-the-current-rouge-measures">1. Problems with the current ROUGE measures</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/1803.01937_ROUGE2.html#rouge-2-0">2. ROUGE 2.0</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Standards/1804.08771_SacreBLEU.html">1804.08771_SacreBLEU: A Call for Clarity in Reporting BLEU Scores</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Standards/1804.08771_SacreBLEU.html#bleu">BLEU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/1804.08771_SacreBLEU.html#id3">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/1804.08771_SacreBLEU.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/1804.08771_SacreBLEU.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/1804.08771_SacreBLEU.html#problem-description">2 Problem Description</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/1804.08771_SacreBLEU.html#a-way-forward">3 A way forward</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/1804.08771_SacreBLEU.html#summary">4 Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Standards/2306.05685_LLM-as-a-Judge.html">2306.05685_Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Standards/2306.05685_LLM-as-a-Judge.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/2306.05685_LLM-as-a-Judge.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/2306.05685_LLM-as-a-Judge.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/2306.05685_LLM-as-a-Judge.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/2306.05685_LLM-as-a-Judge.html#mt-bench-and-chatbot-arena">2 MT-Bench and Chatbot Arena</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/2306.05685_LLM-as-a-Judge.html#llm-as-a-judge">3 LLM as a Judge</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/2306.05685_LLM-as-a-Judge.html#agreement-evaluation">4 Agreement Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/2306.05685_LLM-as-a-Judge.html#human-preference-benchmark-and-standardized-benchmark">5 Human Preference Benchmark and Standardized Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/2306.05685_LLM-as-a-Judge.html#discussion">6 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/2306.05685_LLM-as-a-Judge.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/2306.05685_LLM-as-a-Judge.html#appendix-a-prompt-templates">Appendix A Prompt templates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/2306.05685_LLM-as-a-Judge.html#appendix-b-case-study">Appendix B Case Study</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/2306.05685_LLM-as-a-Judge.html#appendix-c-data-collection">Appendix C Data Collection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/2306.05685_LLM-as-a-Judge.html#appendix-d-additional-experimental-results">Appendix D Additional Experimental Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/2306.05685_LLM-as-a-Judge.html#appendix-e-training-details-of-vicuna-models">Appendix E Training Details of Vicuna Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Standards/2306.05685_LLM-as-a-Judge.html#appendix-f-exploring-vicuna-as-a-judge">Appendix F Exploring Vicuna as a judge</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#agent">æ•°æ®é›†-Agent</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../DS_Agents/2312.14033_T-Eval.html">2312.14033_T-Eval: Evaluating the Tool Utilization Capability of Large Language Models Step by Step</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2312.14033_T-Eval.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2312.14033_T-Eval.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2312.14033_T-Eval.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2312.14033_T-Eval.html#t-eval">2 T-Eval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2312.14033_T-Eval.html#experiments">3 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2312.14033_T-Eval.html#discussion">4 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2312.14033_T-Eval.html#related-work">5 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2312.14033_T-Eval.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2312.14033_T-Eval.html#appendix-a-t-eval-benchmark-details">Appendix A T-EvalÂ Benchmark Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2312.14033_T-Eval.html#appendix-b-implementation-details">Appendix B Implementation Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2312.14033_T-Eval.html#appendix-c-detailed-evaluation-metrics">Appendix C Detailed Evaluation Metrics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2312.14033_T-Eval.html#appendix-d-api-documentation">Appendix D API Documentation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../DS_Agents/2406.12045_%CF%84-bench.html">2406.12045_Ï„-bench: A Benchmark for Tool-Agent-User</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2406.12045_%CF%84-bench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2406.12045_%CF%84-bench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2406.12045_%CF%84-bench.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2406.12045_%CF%84-bench.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2406.12045_%CF%84-bench.html#bench-a-benchmark-for-t-ool-a-gent-u-ser-interaction">3.Ï„-bench: A benchmark for T ool-A gent-U ser Interaction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2406.12045_%CF%84-bench.html#benchmark-construction">4. Benchmark Construction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2406.12045_%CF%84-bench.html#experiments">5.Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2406.12045_%CF%84-bench.html#disscussion">6.Disscussion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html">2506.07982_ğœÂ²-Bench: Evaluating Conversational Agents in a Dual-Control Environment</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#tau-2-bench-evaluating-agents-in-a-dual-control-environment">3 <span class="math notranslate nohighlight">\(\tau^{2}\)</span>-bench: Evaluating Agents in a Dual-Control Environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#broader-impact">Broader Impact</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#appendix-a-telecom-domain">Appendix A Telecom Domain</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#appendix-b-verifying-original-tau-2-bench">Appendix B Verifying Original <span class="math notranslate nohighlight">\(\tau^{2}\)</span>-bench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#appendix-c-prompts">Appendix C Prompts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#appendix-d-domain-policies">Appendix D Domain Policies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#appendix-e-user-simulator-quality">Appendix E User Simulator Quality</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#qa">æ•°æ®é›†-QA</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../DS_QAs/1809.09600_HotpotQA.html">1809.09600_HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/1809.09600_HotpotQA.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/1809.09600_HotpotQA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/1809.09600_HotpotQA.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/1809.09600_HotpotQA.html#data-collection">2 Data Collection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/1809.09600_HotpotQA.html#processing-and-benchmark-settings">3 Processing and Benchmark Settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/1809.09600_HotpotQA.html#dataset-analysis">4 Dataset Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/1809.09600_HotpotQA.html#experiments">5 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/1809.09600_HotpotQA.html#related-work">6 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/1809.09600_HotpotQA.html#conclusions">7 Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/1809.09600_HotpotQA.html#appendix-a-data-collection-details">Appendix A Data Collection Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/1809.09600_HotpotQA.html#a">é™„å½•A æ•°æ®æ”¶é›†ç»†èŠ‚</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/1809.09600_HotpotQA.html#appendix-b-further-data-analysis">Appendix B Further Data Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/1809.09600_HotpotQA.html#appendix-c-full-wiki-setting-details">Appendix C Full Wiki Setting Details</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../DS_QAs/2109.07958_TruthfulQA.html">2109.07958_TruthfulQA: Measuring How Models Mimic Human Falsehoods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2109.07958_TruthfulQA.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2109.07958_TruthfulQA.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2109.07958_TruthfulQA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2109.07958_TruthfulQA.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2109.07958_TruthfulQA.html#the-truthfulqa-benchmark">2 The TruthfulQA Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2109.07958_TruthfulQA.html#experiments">3 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2109.07958_TruthfulQA.html#results">4 Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2109.07958_TruthfulQA.html#discussion">5 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2109.07958_TruthfulQA.html#related-work">6 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2109.07958_TruthfulQA.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2109.07958_TruthfulQA.html#ethics-and-impact">8 Ethics and Impact</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2109.07958_TruthfulQA.html#appendix-a-additional-examples-from-truthfulqa">Appendix A Additional examples from TruthfulQA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2109.07958_TruthfulQA.html#appendix-b-additional-results">Appendix B Additional results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2109.07958_TruthfulQA.html#appendix-c-dataset-construction">Appendix C Dataset construction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2109.07958_TruthfulQA.html#appendix-d-human-evaluations">Appendix D Human evaluations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2109.07958_TruthfulQA.html#appendix-e-prompts">Appendix E Prompts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2109.07958_TruthfulQA.html#appendix-f-checking-for-data-quality-and-disagreement">Appendix F Checking for data quality and disagreement</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../DS_QAs/2311.12022_GPQA.html">2311.12022_GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2311.12022_GPQA.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2311.12022_GPQA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2311.12022_GPQA.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2311.12022_GPQA.html#data-collection">2.Data Collection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2311.12022_GPQA.html#dataset-analysis">3.Dataset Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2311.12022_GPQA.html#baseline">4.Baseline</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2311.12022_GPQA.html#related-work">5.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2311.12022_GPQA.html#limitations">6.Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2311.12022_GPQA.html#conclusion">7.Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../DS_QAs/2411.04368_SimpleQA.html">2411.04368_SimpleQA: Measuring short-form factuality in large language models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2411.04368_SimpleQA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2411.04368_SimpleQA.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2411.04368_SimpleQA.html#data-collection-and-verification">2.Data Collection and Verification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2411.04368_SimpleQA.html#measuring-calibration">4.Measuring calibration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_QAs/2411.04368_SimpleQA.html#appendix-b-guessing-strategy-and-f-score">Appendix B Guessing strategy and F-score</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#id4">æ•°æ®é›†-ç¼–ç¨‹</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../DS_Codes/2107.03374_HumanEval.html">2107.03374_HumanEval: Evaluating Large Language Models Trained on Code</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2107.03374_HumanEval.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2107.03374_HumanEval.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2107.03374_HumanEval.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2107.03374_HumanEval.html#evaluation-framework">2.Evaluation Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2107.03374_HumanEval.html#code-fine-tuning">3.Code Fine-Tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2107.03374_HumanEval.html#supervised-fine-tuning">4.Supervised Fine-Tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2107.03374_HumanEval.html#docstring-generation">5.Docstring Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2107.03374_HumanEval.html#limitations">6.Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2107.03374_HumanEval.html#broader-impacts-and-hazard-analysis">7.Broader Impacts and Hazard Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2107.03374_HumanEval.html#related-work">8.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2107.03374_HumanEval.html#conclusions">9.Conclusions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../DS_Codes/2108.07732_MBPP.html">2108.07732_MBPP: Program Synthesis with Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2108.07732_MBPP.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2108.07732_MBPP.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2108.07732_MBPP.html#datasets">2 Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2108.07732_MBPP.html#model-and-methods">3 Model and Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2108.07732_MBPP.html#mbpp-synthesis-results">4 MBPP Synthesis Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2108.07732_MBPP.html#human-model-collaboration-results">5 Human-Model Collaboration Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2108.07732_MBPP.html#program-execution-results">6 Program Execution Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2108.07732_MBPP.html#mathqa-results">7 MathQA Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2108.07732_MBPP.html#related-work">8 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2108.07732_MBPP.html#risks-and-limitations">9 Risks and Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2108.07732_MBPP.html#conclusion">10 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2108.07732_MBPP.html#appendix-a-appendix">Appendix A Appendix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../DS_Codes/2310.06770_SWE-bench.html">2310.06770_SWE-bench: Can Language Models Resolve Real-World GitHub Issues?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2310.06770_SWE-bench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2310.06770_SWE-bench.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2310.06770_SWE-bench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2310.06770_SWE-bench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2310.06770_SWE-bench.html#id7">2 SWE-bench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2310.06770_SWE-bench.html#swe-llama-fine-tuning-codellama-for-swe-bench">3 SWE-Llama: Fine-tuning CodeLlama for SWE-bench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2310.06770_SWE-bench.html#experimental-setup">4 Experimental Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2310.06770_SWE-bench.html#results">5 Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2310.06770_SWE-bench.html#related-work">6 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2310.06770_SWE-bench.html#discussion">7 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2310.06770_SWE-bench.html#ethics-statement">8 Ethics Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2310.06770_SWE-bench.html#reproducibility-statement">9 Reproducibility Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2310.06770_SWE-bench.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2310.06770_SWE-bench.html#appendix-a-benchmark-details">Appendix A Benchmark Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2310.06770_SWE-bench.html#appendix-b-additional-details-on-training-swe-llama">Appendix B Additional Details on Training SWE-Llama</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2310.06770_SWE-bench.html#appendix-c-additional-results">Appendix C Additional Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2310.06770_SWE-bench.html#appendix-d-additional-experimental-details">Appendix D Additional Experimental Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2310.06770_SWE-bench.html#appendix-e-societal-impact">Appendix E Societal Impact</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2310.06770_SWE-bench.html#appendix-f-in-depth-analysis-of-swe-llama-generations">Appendix F In-depth Analysis of SWE-Llama Generations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../DS_Codes/2402.16694_HumanEval-XL.html">2402.16694_HumanEval-XL: A Multilingual Code Generation Benchmark for Cross-lingual Natural Language Generalization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2402.16694_HumanEval-XL.html#a-multilingual-code-generation-benchmark-for-cross-lingual-natural-language-generalization">A Multilingual Code Generation Benchmark for Cross-lingual Natural Language Generalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2402.16694_HumanEval-XL.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2402.16694_HumanEval-XL.html#introduction">1.Â Â Â Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2402.16694_HumanEval-XL.html#related-work">2.Â Â Â Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2402.16694_HumanEval-XL.html#humaneval-xl">3.Â Â Â HumanEval-XL</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2402.16694_HumanEval-XL.html#experiments">4.Â Â Â Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2402.16694_HumanEval-XL.html#conclusion">5.Â Â Â Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2402.16694_HumanEval-XL.html#acknowledgments">Acknowledgments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2402.16694_HumanEval-XL.html#appendix-a-experiment-settings">Appendix A Experiment Settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2402.16694_HumanEval-XL.html#appendix-b-comprehensive-experiment-results">Appendix B Comprehensive Experiment Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../DS_Codes/2403.07974_LiveCodeBench.html">2403.07974_LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2403.07974_LiveCodeBench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2403.07974_LiveCodeBench.html#llm">LLMæ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2403.07974_LiveCodeBench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2403.07974_LiveCodeBench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2403.07974_LiveCodeBench.html#holistic-evaluation">2 Holistic Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2403.07974_LiveCodeBench.html#benchmark-curation">3 Benchmark Curation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2403.07974_LiveCodeBench.html#experiment-setup">4 Experiment Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2403.07974_LiveCodeBench.html#results">5 Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2403.07974_LiveCodeBench.html#related-work">6 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2403.07974_LiveCodeBench.html#limitations">7 Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2403.07974_LiveCodeBench.html#conclusion">8 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2403.07974_LiveCodeBench.html#appendix-a-dataset">Appendix A Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2403.07974_LiveCodeBench.html#appendix-b-ui">Appendix B UI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2403.07974_LiveCodeBench.html#appendix-c-experimental-setup">Appendix C Experimental Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2403.07974_LiveCodeBench.html#appendix-d-results">Appendix D Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2403.07974_LiveCodeBench.html#appendix-e-qualitative-examples">Appendix E Qualitative Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../DS_Codes/2407.10499_CIBench.html">2407.10499_CIBench: Evaluating Your LLMs with a Code Interpreter Plugin</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2407.10499_CIBench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2407.10499_CIBench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2407.10499_CIBench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2407.10499_CIBench.html#related-works">2 Related Works</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2407.10499_CIBench.html#cibench">3 CIBench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2407.10499_CIBench.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2407.10499_CIBench.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2407.10499_CIBench.html#appendix-a-dataset-details">Appendix A Dataset Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2407.10499_CIBench.html#appendix-b-construction-prompts-and-rules">Appendix B Construction Prompts and Rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2407.10499_CIBench.html#appendix-c-experiment-example-demo">Appendix C Experiment Example Demo</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2407.10499_CIBench.html#appendix-d-subjective-visualization-evaluation">Appendix D Subjective Visualization Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2407.10499_CIBench.html#appendix-e-dataset-error-analysis">Appendix E Dataset Error Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2407.10499_CIBench.html#appendix-f-human-annotator">Appendix F Human Annotator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2407.10499_CIBench.html#appendix-g-ethical-consideration">Appendix G Ethical Consideration</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../DS_Codes/2410.03859_SWE-bench-Multimodal.html">2410.03859_SWE-bench-Multimodal: Do AI Systems Generalize to Visual Software Domains?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2410.03859_SWE-bench-Multimodal.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2410.03859_SWE-bench-Multimodal.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2410.03859_SWE-bench-Multimodal.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2410.03859_SWE-bench-Multimodal.html#swe-bench-multimodal">2 SWE-bench Multimodal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2410.03859_SWE-bench-Multimodal.html#evaluating-on-swe-bench-m">3 Evaluating on SWE-bench M</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2410.03859_SWE-bench-Multimodal.html#results">4 Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2410.03859_SWE-bench-Multimodal.html#related-work">5 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2410.03859_SWE-bench-Multimodal.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2410.03859_SWE-bench-Multimodal.html#appendix-a-dataset">Appendix A Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2410.03859_SWE-bench-Multimodal.html#appendix-b-collection">Appendix B Collection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2410.03859_SWE-bench-Multimodal.html#appendix-c-experiments">Appendix C Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2410.03859_SWE-bench-Multimodal.html#appendix-d-human-validation">Appendix D Human Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2410.03859_SWE-bench-Multimodal.html#appendix-e-limitations">Appendix E Limitations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../DS_Codes/2410.06992_SWE-Bench%2B.html">2410.06992_SWE-Bench+: Enhanced Coding Benchmark for LLMs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2410.06992_SWE-Bench%2B.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2410.06992_SWE-Bench%2B.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2410.06992_SWE-Bench%2B.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2410.06992_SWE-Bench%2B.html#robustness-analysis-of-swe-bench">2 Robustness Analysis of SWE-Bench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2410.06992_SWE-Bench%2B.html#building-swe-bench">3 Building SWE-Bench+</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2410.06992_SWE-Bench%2B.html#robustness-of-swe-bench">4 Robustness of SWE-Bench+</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2410.06992_SWE-Bench%2B.html#effectiveness-aware-evaluation">5 Effectiveness-aware Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2410.06992_SWE-Bench%2B.html#related-work">6 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2410.06992_SWE-Bench%2B.html#conclusion">7 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../DS_Codes/2501.01257_CodeForces.html">2501.01257_CodeForces: Benchmarking Competition-level Code Generation of LLMs on CodeForces</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2501.01257_CodeForces.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2501.01257_CodeForces.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2501.01257_CodeForces.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2501.01257_CodeForces.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2501.01257_CodeForces.html#codeforces-benchmark">3 CodeForces Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2501.01257_CodeForces.html#evaluation-on-existing-llms">4 Evaluation on Existing LLMs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2501.01257_CodeForces.html#analysis-experiments">5 Analysis Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2501.01257_CodeForces.html#discussion">6 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2501.01257_CodeForces.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2501.01257_CodeForces.html#ethical-statement">8 Ethical Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2501.01257_CodeForces.html#appendix-a-model-cards">Appendix A Model Cards</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2501.01257_CodeForces.html#appendix-b-decoding-hyperparameters">Appendix B Decoding Hyperparameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2501.01257_CodeForces.html#appendix-c-analysis-of-our-elo-rating-calculation-system">Appendix C Analysis of Our Elo Rating Calculation System</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2501.01257_CodeForces.html#appendix-d-human-comparable-elo-rating">Appendix D Human-comparable Elo Rating</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2501.01257_CodeForces.html#appendix-e-problem-demonstration">Appendix E Problem Demonstration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Codes/2501.01257_CodeForces.html#appendix-f-special-judge">Appendix F Special Judge</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="../../Benchmarking.html#id5">æ•°æ®é›†-é•¿æ–‡æœ¬</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="2402.05136_LV-Eval.html">2402.05136_LV-Eval: A Balanced Long-Context Benchmark with 5 Length Levels Up to 256K</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2402.05136_LV-Eval.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2402.05136_LV-Eval.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2402.05136_LV-Eval.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2402.05136_LV-Eval.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2402.05136_LV-Eval.html#lv-eval-benchmark">3 LV-Eval Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="2402.05136_LV-Eval.html#evaluation">4 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="2402.05136_LV-Eval.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="2402.05136_LV-Eval.html#appendix-c-detailed-evaluation-results">Appendix C Detailed Evaluation Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="2402.05136_LV-Eval.html#appendix-d-detailed-ablation-results">Appendix D Detailed Ablation Results</a></li>
</ul>
</li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">2402.17753_LoCoMo: Evaluating Very Long-Term Conversational Memory of LLM Agents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="#generative-pipeline-for-locomo">3 Generative Pipeline for LoCoMo</a></li>
<li class="toctree-l4"><a class="reference internal" href="#locomo-evaluation-benchmark">4 LoCoMo Evaluation Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="#experimental-setup">5 Experimental Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="#experimental-results">6 Experimental Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="#limitations">8 Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#broader-impacts">9 Broader Impacts</a></li>
<li class="toctree-l4"><a class="reference internal" href="#appendix-overview">Appendix Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="#appendix-a-generative-pipeline-for-locomo">Appendix A Generative Pipeline for LoCoMo</a></li>
<li class="toctree-l4"><a class="reference internal" href="#appendix-b-dataset">Appendix B Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="#appendix-c-experimental-setup">Appendix C Experimental Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="#appendix-d-results">Appendix D Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2404.06654_RULER.html">2404.06654_RULER: Whatâ€™s the Real Context Size of Your Long-Context Language Models?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2404.06654_RULER.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.06654_RULER.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.06654_RULER.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.06654_RULER.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.06654_RULER.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.06654_RULER.html#the-ruler-benchmark">3 The RulerÂ Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.06654_RULER.html#experiments-results">4 Experiments &amp; Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.06654_RULER.html#task-error-analysis">5 Task Error Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.06654_RULER.html#model-analysis">6 Model Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.06654_RULER.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.06654_RULER.html#limitations">8 Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.06654_RULER.html#appendix-a-models">Appendix A Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.06654_RULER.html#appendix-b-task-configurations">Appendix B Task Configurations</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.06654_RULER.html#appendix-c-task-correlation-analysis">Appendix C Task Correlation Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.06654_RULER.html#appendix-d-prompt-templates">Appendix D Prompt Templates</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.06654_RULER.html#appendix-e-passkey-retrieval-and-vanilla-niah-results">Appendix E Passkey Retrieval and Vanilla NIAH Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.06654_RULER.html#appendix-f-additional-results">Appendix F Additional Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2407.11963_NeedleBench.html">2407.11963_NeedleBench: Can LLMs Do Retrieval and Reasoning in Information-Dense Context</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2407.11963_NeedleBench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.11963_NeedleBench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.11963_NeedleBench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.11963_NeedleBench.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.11963_NeedleBench.html#tasks-and-datasets">3 Tasks and Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.11963_NeedleBench.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.11963_NeedleBench.html#impact-of-language-which-model-performs-better-under-the-bilingual-scenario">4.1.5 Impact of Language_ Which Model Performs Better under the Bilingual Scenario_</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.11963_NeedleBench.html#conclusion-and-future-work">5 Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.11963_NeedleBench.html#appendix-a-evaluated-models">Appendix A Evaluated Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.11963_NeedleBench.html#appendix-b-needlebench-prompt-examples">Appendix B NeedleBenchÂ Prompt Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.11963_NeedleBench.html#appendix-c-error-analysis-examples">Appendix C Error Analysis Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#id6">æ•°æ®é›†-æ•°å­¦</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../DS_Maths/2103.03874_MATH.html">2103.03874_MATH: Measuring Mathematical Problem Solving With the MATH Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../DS_Maths/2110.14168_GSM8K.html">2110.14168_GSM8K: Training Verifiers to Solve Math Word Problems</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DS_Maths/2110.14168_GSM8K.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Maths/2110.14168_GSM8K.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Maths/2110.14168_GSM8K.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Maths/2110.14168_GSM8K.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Maths/2110.14168_GSM8K.html#dataset">2 Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Maths/2110.14168_GSM8K.html#related-work">3 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Maths/2110.14168_GSM8K.html#methods">4 Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Maths/2110.14168_GSM8K.html#additional-experiments">5 Additional Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Maths/2110.14168_GSM8K.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Maths/2110.14168_GSM8K.html#appendix-a-dataset-details">Appendix A Dataset Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Maths/2110.14168_GSM8K.html#appendix-b-hyperparameters">Appendix B Hyperparameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Maths/2110.14168_GSM8K.html#appendix-c-calculator-annotations">Appendix C Calculator Annotations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Maths/2110.14168_GSM8K.html#appendix-d-example-model-solutions">Appendix D Example Model Solutions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Maths/2110.14168_GSM8K.html#appendix-e-verifier-details">Appendix E Verifier Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Maths/2110.14168_GSM8K.html#appendix-f-verifier-visualization">Appendix F Verifier Visualization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../DS_Maths/2405.12209_MathBench.html">2405.12209_MathBench: Evaluating the Theory and Application Proficiency of LLMs with a Hierarchical Mathematics Benchmark</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DS_Maths/2405.12209_MathBench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Maths/2405.12209_MathBench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Maths/2405.12209_MathBench.html#methodology">2 Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Maths/2405.12209_MathBench.html#experiments-and-analysis">3 Experiments and Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Maths/2405.12209_MathBench.html#discussion">4 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Maths/2405.12209_MathBench.html#related-work">5 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Maths/2405.12209_MathBench.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Maths/2405.12209_MathBench.html#limitations">7 Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Maths/2405.12209_MathBench.html#ethical-considerations">8 Ethical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Maths/2405.12209_MathBench.html#appendix-a-mathbench-statistics">Appendix A MathBench Statistics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Maths/2405.12209_MathBench.html#appendix-b-detailed-experimental-results">Appendix B Detailed Experimental Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Maths/2405.12209_MathBench.html#appendix-c-extra-analysis">Appendix C Extra Analysis</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#id7">æ•°æ®é›†-å›¾ç‰‡</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../DS_Images/2306.13394_MME.html">2306.13394_MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2306.13394_MME.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2306.13394_MME.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2306.13394_MME.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2306.13394_MME.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2306.13394_MME.html#mme-evaluation-suite">2 MME Evaluation Suite</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2306.13394_MME.html#experiments">3 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2306.13394_MME.html#analysis">4 Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2306.13394_MME.html#conclusion">5 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../DS_Images/2307.06281_MMBench.html">2307.06281_MMBench: Is Your Multi-modal Model an All-around Player?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2307.06281_MMBench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2307.06281_MMBench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2307.06281_MMBench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2307.06281_MMBench.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2307.06281_MMBench.html#the-construction-of-mmbench">3 The construction of MMBench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2307.06281_MMBench.html#evaluation-strategy">4 Evaluation Strategy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2307.06281_MMBench.html#evaluation-results">5 Evaluation Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2307.06281_MMBench.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2307.06281_MMBench.html#appendix-a-more-details-about-the-data">Appendix A More Details about the Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2307.06281_MMBench.html#appendix-b-more-details-on-mmbench-construction">Appendix B More Details on MMBench Construction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2307.06281_MMBench.html#appendix-c-more-details-on-llm-based-choice-extraction">Appendix C More Details on LLM-based Choice Extraction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2307.06281_MMBench.html#appendix-d-evaluation-settings-and-results">Appendix D Evaluation Settings and Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../DS_Images/2307.16125_SEED-Bench.html">2307.16125_SEED-Bench: Benchmarking Multimodal LLMs with Generative Comprehension</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2307.16125_SEED-Bench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2307.16125_SEED-Bench.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2307.16125_SEED-Bench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2307.16125_SEED-Bench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2307.16125_SEED-Bench.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2307.16125_SEED-Bench.html#id7">3 SEED-Bench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2307.16125_SEED-Bench.html#evaluation-results">4 Evaluation Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2307.16125_SEED-Bench.html#conclusion">5 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../DS_Images/2311.12793_ShareGPT4V.html">2311.12793_ShareGPT4V: Improving Large Multi-Modal Models with Better Captions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2311.12793_ShareGPT4V.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2311.12793_ShareGPT4V.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2311.12793_ShareGPT4V.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2311.12793_ShareGPT4V.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2311.12793_ShareGPT4V.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2311.12793_ShareGPT4V.html#sharegpt4v-dataset">3 ShareGPT4V Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2311.12793_ShareGPT4V.html#sharegpt4v-7b-model">4 ShareGPT4V-7B Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2311.12793_ShareGPT4V.html#id11"><strong>4.1 æ¨¡å‹æ¶æ„</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2311.12793_ShareGPT4V.html#id12"><strong>4.2 é¢„è®­ç»ƒ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2311.12793_ShareGPT4V.html#sft"><strong>4.3 ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2311.12793_ShareGPT4V.html#id13"><strong>æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2311.12793_ShareGPT4V.html#experiments">5 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2311.12793_ShareGPT4V.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2311.12793_ShareGPT4V.html#appendix-a-data-sources">Appendix A Data Sources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2311.12793_ShareGPT4V.html#appendix-b-caption-analysis">Appendix B Caption Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2311.12793_ShareGPT4V.html#appendix-c-prompts">Appendix C Prompts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2311.12793_ShareGPT4V.html#appendix-d-examples">Appendix D Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../DS_Images/2506.18095_ShareGPT-4o-Image.html">2506.18095_ShareGPT-4o-Image: Aligning Multimodal Models with GPT-4o-Level Image Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2506.18095_ShareGPT-4o-Image.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2506.18095_ShareGPT-4o-Image.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2506.18095_ShareGPT-4o-Image.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2506.18095_ShareGPT-4o-Image.html#sharegpt-4o-image">2 ShareGPT-4o-Image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2506.18095_ShareGPT-4o-Image.html#janus-4o-fine-tuning-with-sharegpt-4o-image">3 Janus-4o: Fine-Tuning with ShareGPT-4o-Image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2506.18095_ShareGPT-4o-Image.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2506.18095_ShareGPT-4o-Image.html#conclusion">5 conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2506.18095_ShareGPT-4o-Image.html#appendix-a-related-work">Appendix A Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2506.18095_ShareGPT-4o-Image.html#appendix-b-image-generation-categories">Appendix B Image Generation Categories</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2506.18095_ShareGPT-4o-Image.html#appendix-c-prompts-for-generation">Appendix C Prompts for Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2506.18095_ShareGPT-4o-Image.html#appendix-d-document-pipeline">Appendix D Document Pipeline</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DS_Images/2506.18095_ShareGPT-4o-Image.html#appendix-e-ethical-considerations-and-societal-impact">Appendix E Ethical Considerations and Societal Impact</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#id8">æ•°æ®é›†</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../Datasets/0normal.html">é€šç”¨</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/0normal.html#id2">è¯„æµ‹æ ‡å‡†</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/0normal.html#accuracy">å‡†ç¡®ç‡(Accuracy)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/0normal.html#precision">ç²¾ç¡®ç‡(Precision, ç²¾å‡†ç‡)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/0normal.html#recall">å¬å›ç‡(Recall)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/0normal.html#f1-score">F1 Score</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/0normal.html#id3">å¯è§†åŒ–ç²¾åº¦å’Œå¬å›ç‡</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Datasets/2009.03300_MMLU.html">2009.03300_MMLU: Measuring Massive Multitask Language Understanding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2009.03300_MMLU.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2009.03300_MMLU.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2009.03300_MMLU.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2009.03300_MMLU.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2009.03300_MMLU.html#a-multitask-test">3.A Multitask Test</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2009.03300_MMLU.html#experiments">4.Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2009.03300_MMLU.html#discussion">5.Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2009.03300_MMLU.html#conclusion">6.Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Datasets/2305.08322_C-Eval.html">2305.08322_C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2305.08322_C-Eval.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2305.08322_C-Eval.html#id2">C-Eval_ A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2305.08322_C-Eval.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2305.08322_C-Eval.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2305.08322_C-Eval.html#the-c-eval-evaluation-suite">2 The C-EvalÂ Evaluation Suite</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2305.08322_C-Eval.html#experiment">3 Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2305.08322_C-Eval.html#related-work">4 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2305.08322_C-Eval.html#discussion">5 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2305.08322_C-Eval.html#acknowledgement">Acknowledgement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2305.08322_C-Eval.html#appendix-a-author-contributions">Appendix A Author Contributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2305.08322_C-Eval.html#appendix-b-detailed-stats-of-c-eval">Appendix B Detailed Stats of C-Eval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2305.08322_C-Eval.html#appendix-c-explanation-data-generation">Appendix C Explanation Data Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2305.08322_C-Eval.html#appendix-d-evaluation-prompts">Appendix D Evaluation Prompts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2305.08322_C-Eval.html#appendix-e-details-of-the-models-being-evaluated">Appendix E Details of the models being evaluated</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2305.08322_C-Eval.html#appendix-f-breakdown-of-model-performance">Appendix F Breakdown of Model Performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2305.08322_C-Eval.html#appendix-g-option-bias">Appendix G Option Bias</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2305.08322_C-Eval.html#appendix-h-compute-and-resources-used-for-evaluation">Appendix H Compute and Resources Used for Evaluation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Datasets/2306.09212_CMMLU.html">2306.09212_CMMLU: Measuring massive multitask language understanding in Chinese</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2306.09212_CMMLU.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2306.09212_CMMLU.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2306.09212_CMMLU.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2306.09212_CMMLU.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2306.09212_CMMLU.html#cmmlu">3 CMMLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2306.09212_CMMLU.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2306.09212_CMMLU.html#impact-of-model-size-on-performance">Impact of model size on performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2306.09212_CMMLU.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2306.09212_CMMLU.html#appendix-a-comparison-to-concurrent-benchmarks">Appendix A Comparison to concurrent benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2306.09212_CMMLU.html#appendix-b-cmmlu-subjects">Appendix B CMMLU Subjects</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2306.09212_CMMLU.html#appendix-c-cmmlu-examples">Appendix C CMMLU Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2306.09212_CMMLU.html#appendix-d-cmmlu-difficulty-distribution">Appendix D CMMLU Difficulty Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2306.09212_CMMLU.html#appendix-e-emergent-ability-shown-in-cmmlu-subjects">Appendix E Emergent Ability shown in CMMLU subjects</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2306.09212_CMMLU.html#appendix-f-models-being-evaluated">Appendix F Models being Evaluated</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2306.09212_CMMLU.html#appendix-g-strategies-for-estimating-model-choices">Appendix G Strategies for Estimating Model Choices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2306.09212_CMMLU.html#appendix-h-regular-expressions-matching-algorithmsl">Appendix H Regular expressions matching algorithmsl</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2306.09212_CMMLU.html#appendix-i-correlation-to-other-benchmarks">Appendix I Correlation to other Benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2306.09212_CMMLU.html#appendix-j-breakdown-of-model-performance">Appendix J Breakdown of Model Performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2306.09212_CMMLU.html#j-3-the-effect-of-chain-of-thought-prompt">J.3 The effect of chain-of-thought prompt</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Datasets/2307.15020_SuperCLUE.html">2307.15020_SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2307.15020_SuperCLUE.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2307.15020_SuperCLUE.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2307.15020_SuperCLUE.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2307.15020_SuperCLUE.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2307.15020_SuperCLUE.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2307.15020_SuperCLUE.html#superclue-benchmark">3 SuperCLUE Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2307.15020_SuperCLUE.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2307.15020_SuperCLUE.html#additional-analysis">5 Additional Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2307.15020_SuperCLUE.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2307.15020_SuperCLUE.html#appendix-a-evaluation-process">Appendix A Evaluation Process</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2307.15020_SuperCLUE.html#appendix-b-capability-categories">Appendix B Capability Categories</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Datasets/2311.12983_GAIA.html">2311.12983_GAIA: a benchmark for General AI Assistants</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2311.12983_GAIA.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2311.12983_GAIA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2311.12983_GAIA.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2311.12983_GAIA.html#related-work">2.Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2311.12983_GAIA.html#id4">3.GAIA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2311.12983_GAIA.html#llms-results-on-gaia">4.LLMs results on GAIA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2311.12983_GAIA.html#discussion">5.Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2311.12983_GAIA.html#limitations">6.Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2311.12983_GAIA.html#appendix-a-extended-related-work">Appendix A Extended related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2311.12983_GAIA.html#appendix-c-extended-description-of-gaia">Appendix C Extended description of GAIA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2311.12983_GAIA.html#appendix-d-extended-description-of-our-question-design-framework">Appendix D Extended description of our question design framework</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Datasets/2404.07972_OSWorld.html">2404.07972_OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2404.07972_OSWorld.html#id2">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2404.07972_OSWorld.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2404.07972_OSWorld.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2404.07972_OSWorld.html#osworld-environment">2. OSWORLD Environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2404.07972_OSWorld.html#osworld-benchmark">3. OSWORLD Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2404.07972_OSWorld.html#benchmarking-llm-and-vlm-agent-baselines">4. Benchmarking LLM and VLM Agent Baselines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2404.07972_OSWorld.html#analysis">5. Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2404.07972_OSWorld.html#related-work">6. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2404.07972_OSWorld.html#conclusion-and-future-work">7. Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2404.07972_OSWorld.html#a-details-of-osworld-environment">A. Details of OSWORLD Environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2404.07972_OSWorld.html#c-details-of-baseline-methods">C. Details of Baseline Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2404.07972_OSWorld.html#d-examples-of-qualitative-analysis">D. Examples of Qualitative Analysis</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Datasets/2501.14249_HLE.html">2501.14249_HLE: Humanityâ€™s Last Exam</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2501.14249_HLE.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2501.14249_HLE.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2501.14249_HLE.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2501.14249_HLE.html#dataset">3.Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2501.14249_HLE.html#evaluation">4.Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Datasets/2501.14249_HLE.html#discussion">5.Discussion</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM.html">LLM æ¨¡å‹</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../LLM.html#nlp">NLP æ¨¡å‹</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/1810.04805_BERT.html">1810.04805_BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/1810.04805_BERT.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/1810.04805_BERT.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/1810.04805_BERT.html#bert">3 BERT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/1810.04805_BERT.html#appendix-a-additional-details-for-bert">Appendix A Additional Details for BERT</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html">18xx_GPT1: Improving Language Understanding by Generative Pre-Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#framework">3. Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#analysis">5 Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#id3">å¼•æ–‡å£ç¢‘</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#id4">è¦ç‚¹è§£è¯»</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/19_GPT2.html">19xx_GPT2: Language Models are Unsupervised Multitask Learners</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/19_GPT2.html#the-illustrated-gpt-2">The Illustrated GPT-2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/19_GPT2.html#id2">å‚è€ƒ</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2012.00413_CPM.html">2012.00413_CPM: A Large-scale Generative Chinese Pre-trained Language Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2302.13971_LLaMA.html">2302.13971_LLaMA: Open and Efficient Foundation Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2307.09288_Llama2.html">2307.09288_Llama 2: Open Foundation and Fine-Tuned Chat Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html">2309.16609_Qwen Technical Report</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#pretraining">2. Pretraining</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#alignment">3. Alignment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#code-qwen-specialized-model-for-coding">4. CODE-QWEN: SPECIALIZED MODEL FOR CODING</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#math-qwen-specialized-model-for-mathematics-reasoning">5. MATH-QWEN: SPECIALIZED MODEL FOR MATHEMATICS REASONING</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#related-work">6. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#conclusion">7. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#a-1-more-training-details">A.1 MORE TRAINING DETAILS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#a-2-evaluation">A.2 EVALUATION</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html">2310.19341_Skywork: A More Open Bilingual Foundation Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#methodology">2 Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#pre-training">3 Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#evaluation">4 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#discussion">5 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#limitation">6 Limitation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#appendix-a-details-on-gpt-7b-vs-llama-7b-experiment">Appendix A Details on GPT-7B vs. LLaMA-7B Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#appendix-b-preliminary-experiments-on-distributed-training">Appendix B Preliminary Experiments on Distributed Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#appendix-c-more-benchmark-results">Appendix C More Benchmark Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#appendix-d-details-on-lm-test-sets">Appendix D Details on LM Test Sets</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2401.14196_DeepSeek-Coder.html">2401.14196_DeepSeek-Coder: When the Large Language Model Meets Programming â€“ The Rise of Code Intelligence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2404.06395_MiniCPM.html">2404.06395_MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2404.06395_MiniCPM.html#two-stage-pre-training-strategy">5. Two Stage Pre-training Strategy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2404.06395_MiniCPM.html#model">6. Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2404.06395_MiniCPM.html#minicpm-family">7 MiniCPM Family</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2405.04434_DeepSeek-V2.html">2405.04434_DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2406.12793_ChatGLM.html">2406.12793_ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html">2407.10671_Qwen2 Technical Report</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html#tokenizer-model">2. Tokenizer &amp; Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html#pre-training">3. Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html#post-training">4. Post-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html">2412.15115_Qwen2.5</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html#architecture-and-tokenizer">2. Architecture and Tokenizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html#pre-training">3. Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html#post-training">4. Post-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2505.09388_Qwen3.html">2505.09388_Qwen3</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2505.09388_Qwen3.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2505.09388_Qwen3.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2505.09388_Qwen3.html#architecture">2. Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2505.09388_Qwen3.html#pre-training">3. Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2505.09388_Qwen3.html#post-training">4. Post-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2505.09388_Qwen3.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM.html#id2">å¤šæ¨¡æ€æ¨¡å‹</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html">2112.15093_CTR: Benchmarking Chinese Text Recognition: Datasets, Baselines, and an Empirical Study</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#preliminaries">2. Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#datasets">3. Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#baselines">4. Baselines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#an-empirical-study">5. An Empirical Study</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#conclusions">6. Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#appendix-a-details-of-prab">Appendix A Details of PRAB</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#appendix-c-visualization-of-failure-cases">Appendix C Visualization of Failure Cases.</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html">2304.08485_LLaVA: Visual Instruction Tuning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html#gpt-assisted-visual-instruction-data-generation">3. GPT-assisted Visual Instruction Data Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html#visual-instruction-tuning">4. Visual Instruction Tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2308.12966_Qwen-VL.html">2308.12966_Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2308.12966_Qwen-VL.html#methodology">Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2308.12966_Qwen-VL.html#training">Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2308.12966_Qwen-VL.html#evaluation">Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2308.12966_Qwen-VL.html#b-data-format-details-of-training">B. Data Format Details of Training</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html">2310.03744_LLaVA2: Improved Baselines with Visual Instruction Tuning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#approach">3. Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#empirical-evaluation">4. Empirical Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#open-problems-in-lmms">5. Open Problems in LMMs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#a-implementation-details">A. Implementation Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#b-qualitative-results">B. Qualitative Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html">2312.07533_VILA: On Pre-training for Visual Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html#on-pre-training-for-visual-language-models">3. On Pre-training for Visual Language Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2403.05525_DeepSeek-VL.html">2403.05525_DeepSeek-VL: Towards Real-World Vision-Language Understanding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2403.05525_DeepSeek-VL.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html">2408.01800_MiniCPM-V: A GPT-4V Level MLLM on Your Phone</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#model-architecture">3. Model Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#training">4. Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#end-side-deployment">5. End-side Deployment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#experiments">6. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#conclusion">7. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html">2409.17146_Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Vision-Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#architecture">2. Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#data">3. Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#training">4. Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#ablations">6. Ablations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-a-model-details">Appendix A: Model Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-b-training-details">Appendix B: Training Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-c-evaluation-results">Appendix C: Evaluation Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-d-result-details">Appendix D: Result Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-e-ablations-details">Appendix E Ablations Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-f-data-details">Appendix F Data Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-g-dataset-examples">Appendix G Dataset Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-h-related-work">Appendix H Related Work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html">2410.13848_Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#llm">LLMæ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#janus-a-simple-unified-and-flexible-multimodal-framework">3 Janus: A Simple, Unified and Flexible Multimodal Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#appendix-a-details-of-semantic-tokenizer-mentioned-in-ablation-study">Appendix A Details of Semantic Tokenizer Mentioned in Ablation Study</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#appendix-b-additional-qualitative-results">Appendix B Additional Qualitative Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2411.00774_Freeze-Omni.html">2411.00774_Freeze-Omni: A Smart and Low Latency Speech-to-speech Dialogue Model with Frozen LLM</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2411.00774_Freeze-Omni.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2411.00774_Freeze-Omni.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2411.00774_Freeze-Omni.html#model">2. Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2411.00774_Freeze-Omni.html#experience">3. Experience</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2411.00774_Freeze-Omni.html#conclusion-and-future-work">4. Conclusion and Future Work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html">2412.04468_NVILA: Efficient Frontier Visual Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html#approach">2. Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html#more-capabilities">4. More Capabilities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2502.13923_Qwen2.5-VL.html">2502.13923_Qwen2.5-VL</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2502.13923_Qwen2.5-VL.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2502.13923_Qwen2.5-VL.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2502.13923_Qwen2.5-VL.html#approach">2. Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2502.13923_Qwen2.5-VL.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2502.13923_Qwen2.5-VL.html#conclusion">4. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html">2503.20215_Qwen2.5-Omni Technical Report</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#archtecture">2. Archtecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#id2">3 é¢„è®­ç»ƒ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#post-training">4 åè®­ç»ƒï¼ˆPost-trainingï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html">2506.13642_Stream-Omni: Simultaneous Multimodal Interactions with Large Language-Vision-Speech Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#id4">3. Stream-Omni</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#results-and-analyses">5. Results and Analyses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#appendix-a-construction-of-instructomni">Appendix A Construction of InstructOmni</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#appendix-b-construction-of-spokenvisit">Appendix B Construction of SpokenVisIT</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html">2506.13642_Stream-Omni: Simultaneous Multimodal Interactions with Large Language-Vision-Speech Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#id9">3 Stream-Omni</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#data-construction">3.2.1 Data Construction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#results-and-analyses">5 Results and Analyses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#limitations">Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#appendix-a-construction-of-instructomni">Appendix A Construction of InstructOmni</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#appendix-b-construction-of-spokenvisit">Appendix B Construction of SpokenVisIT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#appendix-c-case-study">Appendix C Case Study</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM.html#id3">LLM éŸ³é¢‘</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2005.08100_Conformer.html">2005.08100_Conformer: Convolution-augmented Transformer for Speech Recognition</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2005.08100_Conformer.html#llm">LLMæ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2005.08100_Conformer.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2005.08100_Conformer.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2005.08100_Conformer.html#conformer-encoder">2 Conformer Encoder</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2005.08100_Conformer.html#experiments">3 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2005.08100_Conformer.html#conclusion">4 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html">2106.07447_HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#i-introduction">I Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#ii-method">II Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#iii-related-work">III Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#iv-experimental-details">IV Experimental Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#v-results">V Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#vi-conclusion">VI Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html">2112.02418_YourTTS: Towards Zero-Shot Multi-Speaker TTS and Zero-Shot Voice Conversion for everyone</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#id1">å…³é”®æ¦‚å¿µ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#yourtts-model">2. YourTTS Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#results-and-discussion">4. Results and Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#zero-shot-voice-conversion">5. Zero-Shot Voice Conversion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#speaker-adaptation">6. Speaker Adaptation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#conclusions-limitations-and-future-work">7. Conclusions, limitations and future work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html">2212.04356_whisper: Robust Speech Recognition via Large-Scale Weak Supervision</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#approach">2. Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#analysis-and-ablations">4. Analysis and Ablations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#limitations-and-future-work">6. Limitations and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#conclusions">7. Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#a-evaluation-datasets">A. Evaluation Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#b-compared-models">B Compared Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#c-text-standardization">C. Text Standardization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html">2301.02111_Vall-E: Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html#background-speech-quantization">3. Background: Speech Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html#id9">4. VALL-E</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html#conclusion-limitations-and-future-work">6. Conclusion, Limitations, and Future Work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html">2303.03926_VALL-E_X: Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural Codec Language Modeling</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#cross-lingual-codec-language-model">3 Cross-Lingual Codec Language Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#vall-e-x-application">4. VALL-E X Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#a-appendix">A. Appendix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2406.05370_VALL-E2.html">2406.05370_VALL-E2: Neural Codec Language Models are Human Parity Zero-Shot Text to Speech Synthesizers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2406.05370_VALL-E2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2406.05370_VALL-E2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2406.05370_VALL-E2.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2406.05370_VALL-E2.html#id5">3. VALL-E 2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2406.05370_VALL-E2.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2406.05370_VALL-E2.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2407.05407_CosyVoice.html">2407.05407_CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.05407_CosyVoice.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.05407_CosyVoice.html#instructions">1. Instructions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.05407_CosyVoice.html#cosyvoice-a-scalable-tts-model-using-supervised-semantic-tokens">2. CosyVoice: A Scalable TTS model using Supervised Semantic Tokens</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.05407_CosyVoice.html#dataset">3. Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.05407_CosyVoice.html#experimental-settings">4. Experimental Settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.05407_CosyVoice.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2407.10759_Qwen2-Audio.html">2407.10759_Qwen2-Audio Technical Report</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.10759_Qwen2-Audio.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.10759_Qwen2-Audio.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.10759_Qwen2-Audio.html#methodology">2. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.10759_Qwen2-Audio.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.10759_Qwen2-Audio.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html">2410.00037_Moshi: a speech-text foundation model for real-time dialogue</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#model">3.Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#datasets-and-training">4. Datasets and Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#safety">6.Safety</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#conclusion">7.Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2412.10117_CosyVoice2.html">2412.10117_CosyVoice2: Scalable Streaming Speech Synthesis with Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2412.10117_CosyVoice2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2412.10117_CosyVoice2.html#instroduction">1. Instroduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2412.10117_CosyVoice2.html#id5">2. CosyVoice 2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2412.10117_CosyVoice2.html#experimental-settings">3. Experimental Settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2412.10117_CosyVoice2.html#experimental-results">4. Experimental Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2412.10117_CosyVoice2.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html">2501.06282_MinMo: A Multimodal Large Language Model for Seamless Voice Interaction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#instruction">1.Instruction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#id9">3.MinMo</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#experiments">4.Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#conclusion">5.Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#limitations">6.Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#a-prompts-for-voice-understanding-tasks">A. Prompts for Voice Understanding Tasks</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2505.02707_Voila.html">2505.02707_Voila: Voice-Language Foundation Models for Real-Time Autonomous Interaction and Voice Role-Play</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.02707_Voila.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.02707_Voila.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.02707_Voila.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.02707_Voila.html#voila-voice-language-foundation-models">3. Voila: Voice-Language Foundation Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.02707_Voila.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.02707_Voila.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html">2505.17589_CosyVoice3: Towards In-the-wild Speech Generation via Scaling-up and Post-training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#id3">2.CosyVoice 3</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#the-multilingual-data-pipeline">3.The Multilingual Data Pipeline</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#experimental-settings">4.Experimental Settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#experimental-results">5.Experimental Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#conclusion">6.Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#limitations">7.Limitations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM.html#id4">LLM è§†é¢‘</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html">2301.12597_BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#bootstrapping-language-image-pre-training-with-frozen-image-encoders-and-large-language-models">Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#method">3 Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#experiment">4 Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#limitation">5 Limitation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#conclusion">6 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html">2308.01390_OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#id1">OpenFlamingo_ An Open-Source Framework for Training Large Autoregressive Vision-Language Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#related-work">2 Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#approach">3 Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#results">4 Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#discussion">5 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#appendix-a-extended-results">Appendix A Extended results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#appendix-b-additional-notes-on-filtering-mmc4">Appendix B Additional notes on filtering MMC4</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#appendix-c-synthetic-data-prompt">Appendix C Synthetic data prompt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#appendix-d-image-credits">Appendix D Image credits</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM.html#llm-moe">LLM MoE</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMoEs/2408.15664_AUXILIARY-LOSS-FREE_LB.html">2408.15664_AUXILIARY-LOSS-FREE LOAD BALANCING STRATEGY FOR MIXTURE-OF-EXPERTS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMoEs/2410.07490_MoDEM.html">2410.07490_MoDEM: Mixture of Domain Expert Models</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM.html#id5">å•†ä¸šæ¨¡å‹</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2303.08774_GPT4.html">2303.08774_GPT-4 Technical Report</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html">2312.11805_Gemini: A Family of Highly Capable Multimodal Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#model-architecture">2. Model Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#training-infrastructure">3. Training Infrastructure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#post-training-models">6. Post-Training Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#responsible-deployment">7. Responsible Deployment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#discussion-and-conclusion">8. Discussion and Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2403.05530_Gemini1.5.html">2403.05530_Gemini1.5: Unlocking multimodal understanding across millions of tokens of context</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html">2406.02430_Seed-TTS: A Family of High-Quality Versatile Speech Generation Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#method">2 Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#experiments">3 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#model-extensions">4 Model extensions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#model-applications-limitations-and-safety">5 Model applications, limitations, and safety</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#authors-alphabetical-order">6 Authors (alphabetical order)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#acknowledgement">7 Acknowledgement</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html">2407.04675_Seed-ASR: Understanding Diverse Speech and Contexts with LLM-based Speech Recognition</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html#motivation">2 Motivation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html#methods">3 Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html#model-and-evaluation">4 Model and Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html#appendix-a-appendix">Appendix A Appendix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2503.20020_Gemini2.html">2503.20020_Gemini2: Gemini Robotics: Bringing AI into the Physical World</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2504.xxxxx_Seed-Thinking-v1.5.html">2504.xxxxx_Seed-Thinking-v1.5: Advancing Superb Reasoning Models with Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html">2505.07062_Seed1.5-VL Technical Report</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#id1">Seed1.5-VL Technical Report</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#architecture">2 Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#pre-training">3 Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#training-recipe">3.2 Training Recipe</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#post-training">4 Post-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#hybrid-reinforcement-learning">4.4 Hybrid Reinforcement Learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#training-infrastructure">5 Training Infrastructure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#evaluation">6 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#video-task-evaluation">6.1.3 Video Task Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#comparison-with-state-of-the-arts">6.3.2 Comparison with State-of-the-arts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#conclusion-and-next-steps">7 Conclusion and Next Steps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#contributions-and-acknowledgments">8 Contributions and Acknowledgments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#qualitative-examples">9 Qualitative examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#visual-reasoning-visual-pattern-recognition">9.7 Visual Reasoning_ Visual Pattern Recognition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#failure-cases-combinatorial-search-i">9.19 Failure Cases_ Combinatorial Search I</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#evaluation-details">10 Evaluation Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#dream-1k">DREAM-1K</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM_tech.html">LLM å‘¨è¾¹æŠ€æœ¯</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#framework">Framework</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html">1712.05889_Ray: A Distributed Framework for Emerging AI Applications</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#motivation-and-requirements">2. Motivation and Requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#programming-and-computation-model">3. Programming and Computation Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#architecture">4. Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#related-work">6 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#discussion-and-experiences">7 Discussion and Experiences</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#conclusion">8. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html">1910.02054_DeepSpeed_ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#extended-introduction">1. Extended Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#where-did-all-the-memory-go">3 Where Did All the Memory Go?</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#zero-insights-and-overview">4 ZeRO: Insights and Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#deep-dive-into-zero-dp">5 Deep Dive into ZeRO-DP</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#deep-dive-into-zero-r">6 Deep Dive into ZeRO-R</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#communication-analysis-of-zero-dp">7 Communication Analysis of ZeRO-DP</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#communication-analysis-of-zero-r">8. Communication Analysis of ZeRO-R</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#step-towards-1-trillion-parameters">9. Step Towards 1 Trillion Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#implementation-and-evaluation">10. Implementation and Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#concluding-remarks">11. Concluding Remarks</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Frameworks/19XX_PyTorch.html">PyTorch: An Imperative Style, High-Performance Deep Learning Library</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Frameworks/20XX_Transformers.html">Transformers: State-of-the-Art Natural Language Processing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html">2210.XX_Ray v2 Architecture</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#architecture-overview">Architecture Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#object-management">Object Management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#task-management">Task Management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#resource-management-and-scheduling">Resource Management and Scheduling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#actor-management">Actor management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#global-control-service">Global Control Service</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#cluster-management">Cluster Management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#appendix">Appendix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html">2309.06180_vLLM: Efficient Memory Management for Large Language Model Serving with PagedAttention</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#id2">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#memory-challenges-in-llm-serving">3. Memory Challenges in LLM Serving</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#method">4. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#implementation">5. Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#evaluation">6. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#ablation-studies">7. Ablation Studies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#conclusion">10. Conclusion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#id2">å¤§æ¨¡å‹è°ƒä¼˜</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2101.00190_Prefix-Tuning.html">2101.00190_Prefix-Tuning: Optimizing Continuous Prompts for Generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2103.10385_p-tuning.html">2103.10385_p-tuning: GPT Understands, Too</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2104.08691_Prompt_Tuning.html">2104.08691_Prompt Tuning: The Power of Scale for Parameter-Efficient Prompt Tuning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2106.09685_LoRA.html">2106.09685_LoRA: Low-Rank Adaptation of Large Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2401.01335_Self-Play.html">2401.01335_Self-Play: Fine-Tuning Converts Weak Language Models to Strong Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2402.09353_DoRA.html">2402.09353_DoRA: Weight-Decomposed Low-Rank Adaptation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2402.12354_LoRA%2B.html">2402.12354_LoRA+: Efficient Low Rank Adaptation of Large Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2403.03507_GaLore.html">2403.03507_GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2403.13372_LlamaFactory.html">2403.13372_LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/FineTunes/2403.13372_LlamaFactory.html#id2">ç«äº‰æ¡†æ¶</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/FineTunes/2403.13372_LlamaFactory.html#efficient-fine-tuning-techniques">3. Efficient Fine-Tuning Techniques</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/FineTunes/2403.13372_LlamaFactory.html#llamafactory-framework">4 LlamaFactory Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/FineTunes/2403.13372_LlamaFactory.html#conclusion-and-future-work">6 Conclusion and Future Work</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#id3">åˆ†å¸ƒå¼æ¨¡å‹</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/1701.06538_MoE.html">1701.06538_MoE: Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/1806.03377_PipeDream.html">1806.03377_PipeDream: Fast and Efficient Pipeline Parallel DNN Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1806.03377_PipeDream.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1806.03377_PipeDream.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1806.03377_PipeDream.html#background-related-work">2. Background &amp; Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1806.03377_PipeDream.html#parallel-training-in-pipedream">3. Parallel Training in PipeDream</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1806.03377_PipeDream.html#implementation">4. Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1806.03377_PipeDream.html#evaluation">5. Evaluation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html">1811.06965_GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html#id2">æ”¶é›†</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html#the-gpipe-library">2. The GPipe Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html#performance-analyses">3. Performance Analyses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html#image-classification">4. Image Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html#massive-massively-multilingual-machine-translation">5. Massive Massively Multilingual Machine Translation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html#design-features-and-trade-offs">6. Design Features and Trade-Offs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/1909.08053_Megatron-LM.html">1909.08053_Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1909.08053_Megatron-LM.html#id2">æ”¶é›†</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1909.08053_Megatron-LM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1909.08053_Megatron-LM.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1909.08053_Megatron-LM.html#background-and-challenges">2. Background and Challenges</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1909.08053_Megatron-LM.html#model-parallel-transformers">3. Model Parallel Transformers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html">19xx_PipeDream: Generalized Pipeline Parallelism for DNN Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html#id2">æ”¶é›†</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html#abstract">ABSTRACT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html#background-and-related-work">2. BACKGROUND AND RELATED WORK</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html#pipeline-parallelism">3. æµæ°´çº¿å¹¶è¡Œ(PIPELINE PARALLELISM)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html#id5">4. å®ç°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html#id6">6. ç»“è®º</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/2006.09503_PipeDream-2BW.html">2006.09503_PipeDream-2BW: Memory-Efficient Pipeline-Parallel DNN Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2006.09503_PipeDream-2BW.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/2006.15704DataParallel.html">2006.15704_PyTorch Distributed: Experiences on Accelerating Data Parallel Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/2006.16668_GShard.html">2006.16668_GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/2104.04473_Megatron-LM2.html">2104.04473_Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2104.04473_Megatron-LM2.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html">2205.14135_FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#background">2 Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#flashattention-algorithm-analysis-and-extensions">3. FLASHATTENTION: Algorithm, Analysis, and Extensions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#limitations-and-future-directions">5. Limitations and Future Directions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#appendix-a-related-work">Appendix A Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#appendix-b-algorithm-details">Appendix B Algorithm Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#appendix-c-proofs">Appendix C Proofs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#appendix-d-extension-details">Appendix D Extension Details</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/2307.08691_FlashAttention2.html">2307.08691_FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2307.08691_FlashAttention2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2307.08691_FlashAttention2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2307.08691_FlashAttention2.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2307.08691_FlashAttention2.html#flashattention-2-algorithm-parallelism-and-work-partitioning">3. FlashAttention-2: Algorithm, Parallelism, and Work Partitioning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2307.08691_FlashAttention2.html#empirical-validation">4. Empirical Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2307.08691_FlashAttention2.html#discussion-and-future-directions">5. Discussion and Future Directions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/normal.html">é€šç”¨</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#id4">LLM é‡åŒ–</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/0normal.html">é€šç”¨</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/0normal.html#id2">æ··åˆç²¾åº¦</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/0normal.html#id3">æµ®ç‚¹æ•°æ ¼å¼</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/0normal.html#weight-only-quantization">weight-only quantization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2110.02861_bitsandbytes.html">2110.02861_bitsandbytes: 8-bit Optimizers via Block-wise Quantization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2110.02861_bitsandbytes.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2110.02861_bitsandbytes.html#background">1. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2110.02861_bitsandbytes.html#bit-optimizers">2. 8-bit Optimizers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2110.02861_bitsandbytes.html#bit-vs-32-bit-optimizer-performance-for-common-benchmarks">3. 8-bit vs 32-bit Optimizer Performance for common Benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2110.02861_bitsandbytes.html#analysis">4. Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2110.02861_bitsandbytes.html#related-work">5. Related Work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html">2206.01861_ZeroQuant: Efficient and Affordable Post-Training Quantization for Large-Scale Transformers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#relative-work">2. Relative Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#background-and-challenges">3. Background and Challenges</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#methodology">4. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#results">5. Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#conclusions">6. Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#appendix-a-background">Appendix A Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#appendix-d-details-about-system-optimization">Appendix D Details about System Optimization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html">2206.09557_LUT-GEMM: Quantized Matrix Multiplication based on LUTs for Efficient Inference in Large-Scale Generative Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#instructions">1. Instructions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#design-methodology-of-lut-gemm">3. Design Methodology of LUT-GEMM</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#experimental-results">4. Experimental results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#accelerating-quantized-opt-175b">5. Accelerating Quantized OPT-175B</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#appendix-a-llm-inference-latency-breakdown">Appendix A LLM Inference Latency Breakdown</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#appendix-b-detailed-implementation">Appendix B Detailed Implementation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html">2208.07339_LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#id1">ç›¸å…³å‚è€ƒ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#int8-matrix-multiplication-at-scale">3. Int8 Matrix Multiplication at Scale</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#emergent-large-magnitude-features-in-transformers-at-scale">4. Emergent Large Magnitude Features in Transformers at Scale</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#discussion-and-limitations">6. Discussion and Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#broader-impacts">7. Broader Impacts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#id17">å…¶ä»–</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html">2209.05433_FP8: FP8 Formats For Deep Learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html#aspects-of-fp8-usage-in-deep-learning">2. Aspects of FP8 Usage in Deep Learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html#fp8-binary-interchange-format">3. FP8 Binary Interchange Format</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html#id3">ç¤ºä¾‹è®²è§£</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html#empirical-results">4. Empirical Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html#conclusions">5. Conclusions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html">2210.17323_GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html#background">3. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html#the-gptq-algorithm">4. The GPTQ Algorithm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html#experimental-validation">5. Experimental Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html#summary-and-limitations">6. Summary and Limitations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html">2211.10438_SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#preliminaries">2. Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#review-of-quantization-difficulty">3. Review of Quantization Difficulty</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#id9">4. SmoothQuant</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#related-work">6. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#conclusion">7. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#appendix-a-discussion-on-weight-only-quantization">Appendix A. Discussion on Weight-Only Quantization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html">2305.14314_QLoRA: Efficient Finetuning of Quantized LLMs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#id1">å…³é”®è¯</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#qlora-finetuning">3. QLoRA Finetuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#qlora-vs-standard-finetuning">4. QLoRA vs. Standard Finetuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#pushing-the-chatbot-state-of-the-art-with-qlora">5. Pushing the Chatbot State-of-the-art with QLoRA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#qualitative-analysis">6. Qualitative Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#related-work">7. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#limitations-and-discussion">8. Limitations and Discussion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html">2306.00978_AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html#awq-activation-aware-weight-quantization">3. AWQ: Activation-aware Weight Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html#tinychat-mapping-awq-onto-edge-platforms">4. TinyChat: Mapping AWQ onto Edge Platforms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2309.05516_AutoRound.html">2309.05516_AutoRound: Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2309.05516_AutoRound.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2309.05516_AutoRound.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2309.05516_AutoRound.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2309.05516_AutoRound.html#methodology">3. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2309.05516_AutoRound.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2309.05516_AutoRound.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#id5">LLM å®‰å…¨</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Securitys/2312.06674_Llama_Guard.html">2312.06674_Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#id6">LLMå¼ºåŒ–å­¦ä¹ </a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/RLs/1703.03864_EvolutionStrategies.html">1703.03864_Evolution Strategies: as a Scalable Alternative to Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html">2504.02495_DeepSeek-GRM: Inference-Time Scaling for Generalist Reward Modeling</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#preliminaries">2. Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#self-principled-critique-tuning-spct">3. Self-Principled Critique Tuning (SPCT)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#inference-time-scaling-with-spct">4. Inference-Time Scaling with SPCT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#results-on-reward-modeling-benchmarks">5. Results on Reward Modeling Benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#related-work">6. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#conclusion-and-future-work">7. Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#a-additional-related-work">A. Additional Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#b-limitations-and-future-directions">B. Limitations and Future Directions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#g-prompt-templates">G. Prompt Templates</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/RLs/2504.13958_ToolRL.html">2504.13958_ToolRL: Reward is All Tool Learning Needs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#id7">å…¶ä»–</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html">2203.02155_Training language models to follow instructions with human feedback(InstructGPT)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#related-work">2. Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#methods-and-experimental-details">3. Methods and experimental details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#results">4. Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#discussion">5. Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#appendix-a-additional-prompt-data-details">Appendix A Additional prompt data details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#appendix-b-additional-human-data-collection-details">Appendix B Additional human data collection details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#appendix-c-additional-model-details">Appendix C Additional model details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#appendix-d-automatic-evaluation-details">Appendix D Automatic evaluation details</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/others/2305.20050_LetsVerifyStepbyStep.html">2305.20050_Letâ€™s Verify Step by Step</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2305.20050_LetsVerifyStepbyStep.html#id2">1. ç ”ç©¶èƒŒæ™¯</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2305.20050_LetsVerifyStepbyStep.html#id3">2. ç›‘ç£æ–¹æ³•å¯¹æ¯”</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2305.20050_LetsVerifyStepbyStep.html#id4">3. æ ¸å¿ƒå‘ç°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2305.20050_LetsVerifyStepbyStep.html#id5">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/others/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html">2408.03314_Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html#how-to-scale-test-time-computation-optimally">3. How to Scale Test-Time Computation Optimally</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html#scaling-test-time-compute-via-verifiers">5. Scaling Test-Time Compute via Verifiers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html#refining-the-proposal-distribution">6. Refining the Proposal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html#id7">å…¶ä»–</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html">2412.14135_Scaling of Search and Learning: A Roadmap to Reproduce o1 from Reinforcement Learning Perspective</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#fromgpt">FromGPT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#id2">3. Policy Initialization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#id3">4. Reward Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#id5">5. Search</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#id8">6. Learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#open-source-o1-project">7 Open-source o1 Project</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#future-directions">8. Future Directions</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../ML.html">æœºå™¨å­¦ä¹ </a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../ML.html#ml-vision">ML Vision</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/1506.02640_YOLO.html">1506.02640_You Only Look Once: Unified, Real-Time Object Detection</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/1506.02640_YOLO.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/1612.08242_YOLO9000.html">1612.08242_YOLO9000: Better, Faster, Stronger</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/1612.08242_YOLO9000.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/1804.02767_YOLOv3.html">1804.02767_YOLOv3</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2004.10934_YOLOv4.html">2004.10934_YOLOv4: Optimal Speed and Accuracy of Object Detection</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2004.10934_YOLOv4.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2205.00159_SVTR.html">2205.00159_SVTR: Scene Text Recognition with a Single Visual Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2205.00159_SVTR.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2205.00159_SVTR.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2205.00159_SVTR.html#method">2. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2205.00159_SVTR.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2205.00159_SVTR.html#conclusion">4. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2207.02696_YOLOv7.html">2207.02696_YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2207.02696_YOLOv7.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2303.05499_GroundingDINO.html">Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2304.08485_VisualInstructionTuning.html">2304.08485_Visual Instruction Tuning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2402.13616_YOLOv9.html">2402.13616_YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2402.13616_YOLOv9.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2405.14458_YOLOv10.html">2405.14458_YOLOv10: Real-Time End-to-End Object Detection</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2405.14458_YOLOv10.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html">2411.15858_SVTRv2: CTC Beats Encoder-Decoder Models in Scene Text Recognition</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#id1">å®šä¹‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#methods">3. Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#conclusion">5. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#more-detail-of-real-world-datasets">8. More detail of real-world datasets</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../ML.html#ml">ML</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2112.09332_WebGPT.html">2112.09332_WebGPT: Browser-assisted question-answering with human feedback</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2203.11147_GopherCite.html">2203.11147_GopherCite: Teaching language models to support answers with verified quotes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2304.09848_Generative_Search.html">2304.09848_Generative_Search: Evaluating Verifiability in Generative Search Engines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2305.14251_FActScore.html">2305.14251_FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2305.14627_ALCE.html">2305.14627_ALCE: Enabling Large Language Models to Generate Text with Citations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ML_normals/2305.14627_ALCE.html#nli">NLI åœ¨å¼•ç”¨è´¨é‡è¯„ä¼°ä¸­çš„åº”ç”¨</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ML_normals/2305.14627_ALCE.html#prompt">è®ºæ–‡ä¸­ç”¨çš„prompt</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2307.02185_Citation.html">2307.02185_Citation: A Key to Building Responsible and Accountable Large Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2307.16883_HAGRID.html">2307.16883_HAGRID: A Human-LLM Collaborative Dataset for Generative Information-Seeking with Attribution</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../Agent.html">AI Agent</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Agent.html#agent">é€šç”¨ Agent</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2210.03629_ReAct.html">2210.03629_ReAct</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2303.08268_Chat-with-the-Environment.html">2303.08268_Chat-with-the-Environment</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2303.08268_Chat-with-the-Environment.html#id2">æ­£æ–‡</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2303.11366_Reflexion.html">2303.11366_Reflexion: Language Agents with Verbal Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2303.16434_TaskMatrix.AI.html">2303.16434_TaskMatrix.AI</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2303.16434_TaskMatrix.AI.html#id2">å¤§è„‘</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2303.16434_TaskMatrix.AI.html#id3">æ¥å£å¹³å°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2303.16434_TaskMatrix.AI.html#api">API é€‰æ‹©å™¨</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2304.03442_Generative-Agents.html">2304.03442_Generative-Agents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2304.03442_Generative-Agents.html#generative-agent-architecture">Generative Agent Architecture</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2307.07924_ChatDev.html">2307.07924_ChatDev: Communicative Agents for Software Development</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2308.00352_MetaGPT.html">2308.00352_MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2308.04026_AgentSims.html">2308.04026_AgentSims: An Open-Source Sandbox for Large Language Model Evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2308.08155_AutoGen.html">2308.08155_AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2308.10848_AgentVerse.html">2308.10848_AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2308.10848_AgentVerse.html#id2">ç†å¿µ</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2310.06117_Step-Back.html">2310.06117_Step-Back: Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2402.18679_MetaGPT_DI.html">2402.18679_MetaGPT_DI: Data Interpreter: An LLM Agent For Data Science</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2402.18679_MetaGPT_DI.html#introduction">INTRODUCTION</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2407.07061_IoA.html">2407.07061_IoA: Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2407.07061_IoA.html#overview-of-ioa">2.1 OVERVIEW OF IOA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2407.07061_IoA.html#architecture-of-ioa">2.2 ARCHITECTURE OF IOA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2407.07061_IoA.html#key-mechanisms">2.3 KEY MECHANISMS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2407.07061_IoA.html#putting-it-all-together">2.5 Putting It All Together</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2408.08435_ADAS.html">2408.08435_ADAS: Automated Design of Agentic Systems</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2408.08435_ADAS.html#prompt">Prompt</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2410.10762_AFlow.html">2408.08435_ADAS: Automating Agentic Workflow Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2410.10762_AFlow.html#introduce">Introduce</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2410.10762_AFlow.html#preliminary">PRELIMINARY</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2410.17238_SELA.html">2410.17238_SELA: Tree-Search Enhanced LLM Agents for Automated Machine Learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2410.17238_SELA.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2410.17238_SELA.html#related-works">2 Related Works</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2410.17238_SELA.html#method">3 Method</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2410.21012_FACT.html">2410.21012_FACT: Examining the Effectiveness of Iterative Context Rewriting for Multi-fact Retrieval</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2410.21012_FACT.html#introduce">Introduce</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2504.01990_foundation-agents.html">2504.01990_Advances and Challenges in Foundation Agents</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2506.12508_AgentOrchestra.html">2506.12508_AgentOrchestra: A Hierarchical Multi-Agent Framework for General-Purpose Task Solving</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2506.12508_AgentOrchestra.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2506.12508_AgentOrchestra.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2506.12508_AgentOrchestra.html#agentorchestra">3.AgentOrchestra</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2506.12508_AgentOrchestra.html#experiments">4.Experiments</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Agent.html#agent-aios">è§†è§‰ Agent&amp;AIOS</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2108.03353_Screen2Words.html">2108.03353_ Screen2Words: Automatic Mobile UI Summarization with Multimodal Learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2108.03353_Screen2Words.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2108.03353_Screen2Words.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2108.03353_Screen2Words.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2108.03353_Screen2Words.html#dataset-creation">3. Dataset Creation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2108.03353_Screen2Words.html#model-design">4. Model Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2108.03353_Screen2Words.html#id3">å…¶å®ƒ</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html">2209.08199_ScreenQA: Large-Scale Question-Answer Pairs over Mobile App Screenshots</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#problem-setting-tasks-and-metrics">3. Problem Setting: Tasks and Metrics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#data-annotation">4. Data Annotation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#dataset-analysis">5. Dataset Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#experiments-and-baselines">6. Experiments and Baselines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#conclusion">7. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#limitations">8. Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#ethical-considerations">9. Ethical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#a-data-annotation-details">A. Data Annotation Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#b-data-examples">B. Data Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html">2212.06817_RT-1: ROBOTICS TRANSFORMER FOR REAL-WORLD CONTROL AT SCALE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#abstract">ABSTRACT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#preliminaries">3. Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#system-overview">4. System Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#rt-1-robotics-transformer">5. RT-1: ROBOTICS TRANSFORMER</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#experiments">6. EXPERIMENTS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#conclusions-limitations-and-future-work">7. CONCLUSIONS, LIMITATIONS AND FUTURE WORK</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#b-model-card">B. MODEL CARD</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#c-model-and-data">C. MODEL AND DATA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#d-experiments">D. EXPERIMENTS</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2312.13771_AppAgent.html">2312.13771_AppAgent: Multimodal Agents as Smartphone Users</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2312.13771_AppAgent.html#environment-and-action-space">3.1 Environment and Action Space</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2312.13771_AppAgent.html#exploration-phase">3.2 Exploration Phase</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2312.13771_AppAgent.html#deployment-phase">3.3 Deployment Phase</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html">2401.10935_SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#related-work">2. Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#approach">3. Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#screenspot-a-grounding-benchmark">4. ScreenSpot: A Grounding Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#limitations">Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#ethical-considerations">Ethical considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#a-details-of-seeclick-pre-training">A. Details of SeeClick Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#b-screenspot-annotation-evaluation">B ScreenSpot Annotation &amp; Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#c-downstream-agent-tasks">C. Downstream Agent Tasks</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html">2402.04615_ScreenAI: A Vision-Language Model for UI and Infographics Understanding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#methodology">2. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#automatic-data-generation">3. Automatic data generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#data-mixtures">4. Data Mixtures</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#experiments-and-results">5. Experiments and Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#conclusions">6. Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#a-definitions-of-metrics">A Definitions of Metrics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#b-screen-schema-examples">B. Screen Schema Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#c-prompts-for-llm-generated-content">C. Prompts For LLM Generated Content</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#d-screen-navigation-generated-examples">D. Screen Navigation Generated Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#f-screenqa-short-answers-generation">F. ScreenQA Short Answers Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#g-complex-question-answering-datasets">G. Complex Question Answering Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#h-new-benchmarks-repositories">H. New Benchmarks Repositories</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html">2402.07939_UFO: A UI-Focused Agent for Windows OS Interaction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html#the-design-of-ufo">3.The Design of UFO</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html#experiment">4.Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html#limitations-lessons-learned">5.Limitations &amp; Lessons Learned</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html#conclusion">6.Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2403.16971_AIOS.html">2403.16971_AIOS: LLM Agent Operating System</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2403.16971_AIOS.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2403.16971_AIOS.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2403.16971_AIOS.html#the-architecture-of-aios">2. The Architecture of AIOS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2403.16971_AIOS.html#aios-kernel">3. AIOS Kernel</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2403.16971_AIOS.html#evaluation">4 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2403.16971_AIOS.html#appendix-e-discussion">Appendix E Discussion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2406.01014_Mobile-Agent-v2.html">2406.01014_Mobile-Agent-v2: Mobile Device Operation Assistant with Effective Navigation via Multi-Agent Collaboration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2411.02059_TableGPT2.html">2411.02059_TableGPT2: A Large Multimodal Model with Tabular Data Integration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2411.02059_TableGPT2.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html">2501.11733_Mobile-Agent-E: Self-Evolving Mobile Assistant for Complex Tasks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#mobile-agent-e">2. Mobile-Agent-E</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#results">4. Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#conclusion-and-future-work">6. Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-a-full-trajectory-comparison-example-with-previous-sota">Appendix A Full Trajectory Comparison Example with Previous SOTA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-b-error-recovery-with-escalation-to-manager">Appendix B Error Recovery with Escalation to Manager</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-c-remaining-limitations">Appendix C Remaining Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-d-all-tasks-in-mobile-eval-e-benchmark">Appendix D All Tasks in Mobile-Eval-E Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-e-atomic-operation-space">Appendix E Atomic Operation Space</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-f-full-list-of-self-evolved-shortcuts">Appendix F Full list of Self-Evolved Shortcuts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-g-full-list-of-self-evolved-tips">Appendix G Full list of Self-Evolved Tips</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html">2501.12326_UI-TARS: Pioneering Automated GUI Interaction with Native Agents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html#evolution-path-of-gui-agents">2. Evolution Path of GUI Agents</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html#core-capabilities-of-native-agent-model">3. Core Capabilities of Native Agent Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html#ui-tars">4. UI-TARS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html#experiment">5. Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2502.14282_PC-Agent.html">2502.14282_PC-Agent: A Hierarchical Multi-Agent Collaboration Framework for Complex Task Automation on PC</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2502.14282_PC-Agent.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2502.14282_PC-Agent.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2502.14282_PC-Agent.html#pc-agent">2. PC-Agent</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2502.14282_PC-Agent.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2502.14282_PC-Agent.html#related-work">4. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2502.14282_PC-Agent.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html">2504.14603_UFO2: The Desktop AgentOS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#background">2.Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#system-design-of-ufo2">3.System Design of UFO2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#picture-in-picture-interface">4.Picture-in-Picture Interface</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#implementation-and-specialized-engineering-design">5.Implementation and Specialized Engineering Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#evaluation">6.Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#discussion-future-work">7.Discussion &amp; Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#related-work">8.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#conclusion">9.Conclusion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Agent.html#id2">è®°å¿†</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Memorys/2505.22101_MemOS.html">2505.22101_MemOS: An Operating System for Memory-Augmented Generation (MAG) in LLM (Short Version)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Memorys/2505.22101_MemOS.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Memorys/2505.22101_MemOS.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Memorys/2505.22101_MemOS.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Memorys/2505.22101_MemOS.html#memory-in-large-language-models">2 Memory in Large Language Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Memorys/2505.22101_MemOS.html#memos-design-philosophy">3 MemOS Design Philosophy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Memorys/2505.22101_MemOS.html#memos">4 MemOS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Memorys/2505.22101_MemOS.html#id2"><strong>4.1 MemOS ä¸­çš„è®°å¿†ç±»å‹</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Memorys/2505.22101_MemOS.html#memcube"><strong>4.2 è®°å¿†ç«‹æ–¹ä½“ï¼ˆMemCubeï¼‰ï¼šæ ¸å¿ƒèµ„æº</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Memorys/2505.22101_MemOS.html#id3"><strong>4.3 MemOS æ¶æ„</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Memorys/2505.22101_MemOS.html#id4"><strong>4.4 ç³»ç»Ÿæ‰§è¡Œæµç¨‹</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Memorys/2505.22101_MemOS.html#id5"><strong>æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Memorys/2505.22101_MemOS.html#conclusion">5 Conclusion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Agent.html#tools">Tools</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Tools/2205.00445_MRKL.html">2205.00445_MRKL</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Tools/2302.04761_Toolformer.html">2302.04761_Toolformer: Language Models Can Teach Themselves to Use Tools</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Tools/2303.17580_HuggingGPT.html">2303.17580_HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html">2307.16789_ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#llm">LLMæ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#dataset-construction">2 Dataset Construction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#experiments">3 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#related-work">4 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#appendix-a-implementation-details">Appendix A Implementation Details</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Agent.html#agi">AGI</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/AGIs/1905.10985_AI-GA.html">1905.10985_AI-GA: AI-generating algorithms, an alternate paradigm for producing general artificial intelligence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/AGIs/2408.06292_AI-Scientist.html">2408.06292_The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../RAG.html">RAG</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2005.11401_RAG_for_KI_NLP_task.html">2005.11401_Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html">2312.10997_Retrieval-Augmented Generation for Large Language Models: A Survey</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#ii-overview-of-rag">II. Overview of RAG</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#ii-a-naive-rag">II-A Naive RAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#ii-b-advanced-rag">II-B Advanced RAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#ii-c-modular-rag">II-C Modular RAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#ii-d-rag-vs-fine-tuning">II-D RAG vs Fine-tuning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iii-retrieval">III. Retrieval</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iii-a-retrieval-source">III-A Retrieval Source</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iii-b-indexing-optimization">III-B Indexing Optimization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iii-c-query-optimization">III-C Query Optimization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iii-d-embedding">III-D Embedding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iii-e-adapter">III-E Adapter</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iv-generation">IV. Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iv-a-context-curation">IV-A Context Curation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iv-b-llm-fine-tuning">IV-B LLM Fine-tuning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#v-augmentation-process-in-rag">V. Augmentation process in RAG</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#v-a-iterative-retrieval">V-A Iterative Retrieval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#v-b-recursive-retrieval">V-B Recursive Retrieval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#v-c-adaptive-retrieval">V-C Adaptive Retrieval</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vi-task-and-evaluation">VI. Task and Evaluation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vi-a-downstream-task">VI-A Downstream Task</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vi-b-evaluation-target">VI-B Evaluation Target</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vi-c-evaluation-aspects">VI-C Evaluation Aspects</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vi-d-evaluation-benchmarks-and-tools">VI-D Evaluation Benchmarks and Tools</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vii-discussion-and-future-prospects">VII. Discussion and Future Prospects</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vii-a-rag-vs-long-context">VII-A RAG vs Long Context</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vii-b-rag-robustness">VII-B RAG Robustness</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vii-c-hybrid-approaches">VII-C Hybrid Approaches</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vii-d-scaling-laws-of-rag">VII-D Scaling laws of RAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vii-e-production-ready-rag">VII-E Production-Ready RAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vii-f-multi-modal-rag">VII-F Multi-modal RAG</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2401.15884_CRAG.html">2401.15884_CRAG: Corrective Retrieval Augmented Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2403.14403_Adaptive-RAG.html">2403.14403_Adaptive-RAG</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html">2404.16130_GraphRAG: From Local to Global: A GraphRAG Approach to Query-Focused Summarization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id1">æ€»ç»“</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#introduction">1 Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#background">2 Background</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#rag">2.1 RAGæ–¹æ³•ä¸ç³»ç»Ÿ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#llmrag">2.2 çŸ¥è¯†å›¾è°±åœ¨LLMä¸RAGä¸­çš„åº”ç”¨</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id2">2.3 è‡ªé€‚åº”åŸºå‡†æµ‹è¯•</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id3">2.4 RAGè¯„ä¼°æ ‡å‡†</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#methods">3 Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#graphrag"><strong>3.1 GraphRAG å·¥ä½œæµç¨‹</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id4"><strong>3.2 å…¨å±€ç†è§£é—®é¢˜ç”Ÿæˆ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id5"><strong>3.3 å…¨å±€ç†è§£è¯„ä¼°æ ‡å‡†</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id6"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#analysis">4 Analysis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id7">4.1 å®éªŒ1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id11">4.2 å®éªŒ2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id14">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#results">5 Results</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id15">5.1 å®éªŒä¸€ï¼šä¸åŒæ–¹æ³•åœ¨æ‘˜è¦ä»»åŠ¡ä¸­çš„è¡¨ç°æ¯”è¾ƒ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id18">5.2 å®éªŒäºŒï¼šåŸºäºå£°æ˜çš„æŒ‡æ ‡è¯„ä¼°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id20">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#discussion">6 Discussion</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id21">6.1 è¯„ä¼°æ–¹æ³•çš„å±€é™æ€§</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id22">6.2 æœªæ¥å·¥ä½œ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id23">æ›´å¹¿æ³›çš„å½±å“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#appendix-a-entity-and-relationship-extraction-approach">Appendix A Entity and Relationship Extraction Approach</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id24"><strong>1. å®ä½“ä¸å…³ç³»æŠ½å–æ–¹æ³•</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#self-reflection"><strong>2. è‡ªæˆ‘åæ€ï¼ˆSelf-Reflectionï¼‰æŠ€æœ¯</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id25"><strong>3. åˆ†å—å¤§å°ä¸æŠ½å–æ•ˆæœçš„å…³ç³»</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id26"><strong>4. å®éªŒç»“æœï¼ˆå›¾3ï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id27"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#appendix-b-example-community-detection">Appendix B Example Community Detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#appendix-c-context-window-selection">Appendix C Context Window Selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#appendix-d-example-answer-comparison">Appendix D Example Answer Comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#appendix-e-system-prompts">Appendix E System Prompts</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#e-1-element-instance-generation"><strong>E.1 å®ä½“å®ä¾‹ç”Ÿæˆï¼ˆElement Instance Generationï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#e-2-community-summary-generation"><strong>E.2 ç¤¾åŒºæ‘˜è¦ç”Ÿæˆï¼ˆCommunity Summary Generationï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#e-3-community-answer-generation"><strong>E.3 ç¤¾åŒºé—®é¢˜å›ç­”ç”Ÿæˆï¼ˆCommunity Answer Generationï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#e-4-global-answer-generation"><strong>E.4 å…¨å±€é—®é¢˜å›ç­”ç”Ÿæˆï¼ˆGlobal Answer Generationï¼‰</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#appendix-f-evaluation-prompts">Appendix F Evaluation Prompts</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#f-1-relative-assessment-prompt">F.1 Relative Assessment Prompt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#f-2-relative-assessment-metrics">F.2 Relative Assessment Metrics</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#appendix-g-statistical-analysis">Appendix G Statistical Analysis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id38">ç»Ÿè®¡æ–¹æ³•ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id39">ä¸»è¦ç»“æœæ€»ç»“ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id40">æ€»ä½“è¶‹åŠ¿ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id41">é‡è¦ç»“è®ºï¼š</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html">2405.16506_GRAG: Graph Retrieval-Augmented Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2406.13213_Multi-Meta-RAG.html">2406.13213_Multi-Meta-RAG: Improving RAG for Multi-Hop Queries using Database Filtering with LLM-Extracted Metadata</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html">2410.05779_LightRAG: Simple and Fast Retrieval-Augmented Generation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#id1">æ€»ç»“</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#introduction">1 Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#retrieval-augmented-generation">2 Retrieval-Augmented Generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#the-lightrag-architecture">3 The LightRAGÂ Architecture</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#lightrag">ä¸€ã€LightRAGæ¶æ„æ¦‚è¿°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#graph-based-text-indexing">äºŒã€åŸºäºå›¾çš„æ–‡æœ¬ç´¢å¼•ï¼ˆGraph-based Text Indexingï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#dual-level-retrieval-paradigm">ä¸‰ã€åŒå±‚æ£€ç´¢èŒƒå¼ï¼ˆDual-level Retrieval Paradigmï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#retrieval-augmented-answer-generation">å››ã€æ£€ç´¢å¢å¼ºçš„ç­”æ¡ˆç”Ÿæˆï¼ˆRetrieval-Augmented Answer Generationï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#id2">äº”ã€å¤æ‚åº¦åˆ†æ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#id3">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#evaluation">4 Evaluation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#experimental-settings"><strong>1. å®éªŒè®¾ç½®ï¼ˆ4.1 Experimental Settingsï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#lightrag-rag-4-2-rq1"><strong>2. LightRAG ä¸ç°æœ‰ RAG æ–¹æ³•çš„å¯¹æ¯”ï¼ˆ4.2 RQ1ï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#rq2"><strong>3. æ¶ˆèå®éªŒï¼ˆ4.3 RQ2ï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#id8"><strong>æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#case-study-rq3">4.4 Case Study (RQ3)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#rq3">4.4 æ¡ˆä¾‹ç ”ç©¶ï¼ˆRQ3ï¼‰æ€»ç»“ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#rq4">4.5 æ¨¡å‹æˆæœ¬ä¸é€‚åº”æ€§åˆ†æï¼ˆRQ4ï¼‰æ€»ç»“ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#id9">æ€»ä½“ç»“è®ºï¼š</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#related-work">5 Related Work</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#id10">ç¬¬5ç«  ç›¸å…³å·¥ä½œï¼ˆæ€»ç»“ï¼‰</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#appendix">7 Appendix</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html">2410.10450_KBLaM: Knowledge Base augmented Language Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#introduction">1. Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#related-work">2. Related work</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#background">3. Background</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#self-attention-layer">Self-attention layer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#augmenting-llm-with-the-kb">4. Augmenting LLM with the KB</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#knowledge-tokens">Knowledge tokens</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#rectangular-attention-injecting-knowledge-token-into-prompt-tokens">Rectangular Attention: Injecting knowledge token into prompt tokens</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#kb-length-generalization-through-attention-score-scaling">KB length generalization through attention score scaling</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#kb-instruction-tuning">5. KB instruction tuning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#experiments">6. EXPERIMENTS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#experiment-setting">6.1 EXPERIMENT SETTING</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#experiment-results">6.2 EXPERIMENT RESULTS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#id2">æ€»ç»“äº®ç‚¹</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#conclusion">7. CONCLUSION</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#limitations-and-future-work">8. LIMITATIONS AND FUTURE WORK</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#appendix-a-extended-related-work">Appendix A Extended related work</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#appendix-b-ablation-study">Appendix B Ablation study</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#appendix-c-sample-kb">Appendix C Sample KB</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#sample-q-a">SAMPLE Q&amp;A</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#prompt">PROMPT</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#prompt-for-synthetic-kb-generation">PROMPT FOR SYNTHETIC KB GENERATION</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#prompt-for-open-ended-q-a-generation">Prompt for open-ended Q&amp;A generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#prompt-for-gpt-evaluation-of-open-ended-q-a">PROMPT FOR GPT EVALUATION OF OPEN-ENDED Q&amp;A</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#prompt-for-llama-evaluation">PROMPT FOR LLAMA EVALUATION</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#question-template">QUESTION TEMPLATE</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#sample-output">SAMPLE OUTPUT</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#synthetic-kb">SYNTHETIC KB</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#enron">ENRON</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html">2504.03137_LightPROF: A Lightweight Reasoning Framework for Large Language Model on Knowledge Graph</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#related-work">Related Work</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#llm-prompt-engineering">LLM Prompt Engineering</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#kg-based-llm-reasoning">KG-based LLM Reasoning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#preliminaries">Preliminaries</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#knowledge-graph-kg">1. Knowledge Graph (KG)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#anchor-entities">2. Anchor Entities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#relation-link">3. Relation Link</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#reasoning-path">4. Reasoning Path</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#methodology">Methodology</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#stage1-reasoning-graph-retrieval">Stage1: Reasoning Graph Retrieval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#stage2-knowledge-embedding">Stage2: Knowledge Embedding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#stage3-knowledge-prompts-mixed-reasoning">Stage3: Knowledge Prompts Mixed Reasoning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#experiments">Experiments</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/graphrag.html">GraphRAG å®˜æ–¹æ–‡æ¡£</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/graphrag.html#indexing">Indexing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/graphrag.html#indexing-architecture">&gt; Indexing Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/graphrag.html#indexing-dataflow">&gt; Indexing Dataflow</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/graphrag.html#prompt-tuning">&gt; Prompt Tuning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/graphrag.html#query">Query</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../paper_pool.html">è®ºæ–‡æ± </a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html">2305.16300_Random-Access Infinite Context Length for Transformers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#llm">LLM æ€»ç»“</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id1"><strong>ç ”ç©¶èƒŒæ™¯ä¸åŠ¨æœº</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id2"><strong>æ ¸å¿ƒé—®é¢˜</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id3"><strong>ä¸»è¦è´¡çŒ®</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id4"><strong>å…³é”®æŠ€æœ¯ç‚¹</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id5"><strong>å®éªŒç»“æœ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id6"><strong>æ„ä¹‰ä¸åº”ç”¨å‰æ™¯</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id7"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#introduction">1 Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#related-work">2 Related Work</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#methodology">3 Methodology</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id8"><strong>æ€»ä½“æ€è·¯</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id9"><strong>æ–¹æ³•è¯¦è§£</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id11"><strong>ä½ç½®ç¼–ç å¤„ç†</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id12"><strong>ä¸å…¶ä»–æ–¹æ³•çš„å¯¹æ¯”</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id13"><strong>æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#memory-computation">3.3 Memory &amp; Computation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#experiments">4 Experiments</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id14"><strong>4.1 è¯­è¨€å»ºæ¨¡å®éªŒ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id18"><strong>4.2 å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id22"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#future-work">5 Future Work</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#acknowledgment">Acknowledgment</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#appendix-a-grouped-softmax-example">Appendix A Grouped Softmax Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#appendix-b-dataset-description">Appendix B Dataset Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#appendix-c-number-of-unique-retrieved-blocks">Appendix C Number of Unique Retrieved Blocks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#appendix-d-context-miss-token">Appendix D Context Miss Token</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#appendix-e-positional-augmentation">Appendix E Positional Augmentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#appendix-f-additional-extensions-and-details">Appendix F Additional Extensions and Details</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#masked-language-modeling">1. <strong>æ©ç è¯­è¨€å»ºæ¨¡ï¼ˆMasked Language Modelingï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#flash-attention">2. <strong>ä¸ Flash Attention çš„ç»“åˆ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id23">3. <strong>æ£€ç´¢å—æ•°é‡ä¸å—å¤§å°çš„æƒè¡¡</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id24">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#appendix-g-offloading-kv-cache-to-cpu">Appendix G Offloading KV Cache to CPU</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html">2311.18743_AlignBench: Benchmarking Chinese Alignment of Large Language Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#id1">ä¸»è¦å†…å®¹æ€»ç»“ï¼š</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#id2">æ€»ç»“ï¼š</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#introduction">1 Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#id3"><strong>1. èƒŒæ™¯ä¸æŒ‘æˆ˜</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#alignbench"><strong>2. AlignBenchçš„è®¾è®¡ç›®æ ‡</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#id4"><strong>3. AlignBenchçš„ä¸»è¦ç‰¹ç‚¹</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#id5"><strong>4. AlignBenchçš„åº”ç”¨ä¸æˆæœ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#id6"><strong>5. æ€»ä½“è´¡çŒ®</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#id7"><strong>6. è¡¨æ ¼å¯¹æ¯”</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#dataset">2 Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#methods">3 Methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#human-evaluation-on-alignbench">4 Human Evaluation on AlignBench</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#agreement-evaluation">ä¸€ã€ä¸€è‡´æ€§è¯„ä¼°ï¼ˆAgreement Evaluationï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#quality-evaluation">äºŒã€è§£é‡Šè´¨é‡è¯„ä¼°ï¼ˆQuality Evaluationï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#id8">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#alignbench-benchmarking-results">5 AlignBench: Benchmarking Results</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#related-work">6 Related Work</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#appendix-a-appendix">Appendix A Appendix</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#a-2-prompts-and-details-of-methods">A.2 Prompts and Details of Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#a-2">A.2 æç¤ºæ¨¡æ¿ä¸æ–¹æ³•ç»†èŠ‚</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#a-3">A.3 å„ç»´åº¦è¡¨ç°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#a-4">A.4 æ¡ˆä¾‹åˆ†æ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#id10">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#id11">ä¸€ã€æ ¸å¿ƒé—®é¢˜ï¼šå‚è€ƒææ–™ç¼ºå¤±å¯¼è‡´è¯„ä¼°å›°éš¾</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#id12">äºŒã€æ•°å­¦ç§¯åˆ†é—®é¢˜å¯¹æ¯”åˆ†æ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#id13">ä¸‰ã€æ€»ç»“</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html">2401.15391_MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#id1"><strong>èƒŒæ™¯ä¸åŠ¨æœº</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#id2"><strong>è´¡çŒ®</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#id3"><strong>æ–¹æ³•æ¦‚è§ˆ</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#id4"><strong>å®éªŒç»“æœ</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#id5"><strong>æ€»ç»“</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#introduction">1 Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#id6">ä¸»è¦å†…å®¹æ€»ç»“å¦‚ä¸‹ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#id7">æ€»ç»“ï¼š</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#rag-with-multi-hop-queries">2 RAG with multi-Hop queries</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#rag">2.1 RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æ¦‚è¿°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#multi-hop-queries">2.2 å¤šè·³æŸ¥è¯¢ï¼ˆMulti-Hop Queriesï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#id8">2.3 è¯„ä¼°æŒ‡æ ‡</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#id9">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#a-benchmarking-dataset-multihop-rag">3 A Benchmarking Dataset: MultiHop-RAG</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#multihop-rag">ä¸€ã€MultiHop-RAG æ•°æ®é›†æ„å»ºæµç¨‹</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#id10">äºŒã€MultiHop-RAG æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#id11">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#benchmarking-rag-system-using-multihop-rag">4 Benchmarking RAG system using MultiHop-RAG</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#retrieval-related-task">ä¸€ã€æ£€ç´¢ç›¸å…³ä»»åŠ¡ï¼ˆRetrieval-related Taskï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#generation-related-task">äºŒã€ç”Ÿæˆç›¸å…³ä»»åŠ¡ï¼ˆGeneration-related Taskï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#other-use-cases">ä¸‰ã€å…¶ä»–æ½œåœ¨æ”¹è¿›æ–¹å‘ï¼ˆOther Use Casesï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#id12">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#related-work">5 Related Work</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#limitations">Limitations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#appendix-a-appendix-a-gpt-4-prompts-used-for-data-generation">Appendix A Appendix A: GPT-4 Prompts Used for Data Generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#appendix-b-appendix-b-dataset-examples">Appendix B Appendix B: Dataset Examples</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html">2405.16506_GRAG: Graph Retrieval-Augmented Generation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#introduction">1 Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#related-work">2 Related Work</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#prompt-tuning">2.1 Prompt Tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#llms">2.2 LLMsåœ¨å›¾ç›¸å…³ä»»åŠ¡ä¸­çš„åº”ç”¨</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#id1">2.3 å›¾ä¸Šçš„æ£€ç´¢æ–¹æ³•</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#problem-formalization">3 Problem Formalization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#methodology">4 Methodology</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#id2">æ¦‚è¿°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#id3">4.1 æ–‡æœ¬å­å›¾æ£€ç´¢</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#indexing">æ–‡æœ¬å­å›¾ç´¢å¼•ï¼ˆIndexingï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#ranking">æ–‡æœ¬å­å›¾æ’åºï¼ˆRankingï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#soft-pruning">æ–‡æœ¬å­å›¾è½¯å‰ªæï¼ˆSoft Pruningï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#id4">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#textual-graph-augmented-generation">4.2 Textual Graph Augmented Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#text-view-of-textual-graphs">1. æ–‡æœ¬è§†å›¾ï¼ˆText View of Textual Graphsï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#graph-view-of-textual-graphs">2. å›¾è§†å›¾ï¼ˆGraph View of Textual Graphsï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#generation-phase">3. ç”Ÿæˆé˜¶æ®µï¼ˆGeneration Phaseï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#id5">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#experiments">5 Experiments</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#id6">æ€»ç»“ï¼šç¬¬äº”ç«  å®éªŒéƒ¨åˆ†</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#limitations">7 Limitations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#acknowledgments">Acknowledgments</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#appendix-a-appendix">Appendix A Appendix</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#a"><strong>é™„å½•A æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#id12"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html">2407.01178_Memory3: Language Modeling with Explicit Memory</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#language-modeling-with-explicit-memory">Language Modeling with Explicit Memory</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id1">ç ”ç©¶èƒŒæ™¯ä¸åŠ¨æœºï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id2">ä¸»è¦å†…å®¹ä¸æ–¹æ³•ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id3">å®éªŒä¸ç»“æœï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id4">æ€»ç»“ï¼š</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#abstract">Abstract</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id5">æ ¸å¿ƒæ€æƒ³</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#memory3">Memory3 æ¨¡å‹ç‰¹ç‚¹</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id6">å®éªŒç»“æœ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id7">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#introduction">1â€‚_â€‚Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#retrieval-augmented-training">1.1.1â€‚_â€‚Retrieval-augmented Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id8">1.1.1 | åŸºäºæ£€ç´¢çš„è®­ç»ƒï¼ˆRetrieval-augmented Trainingï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#sparse-computation">1.1.2 | ç¨€ç–è®¡ç®—ï¼ˆSparse Computationï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#parameter-as-memory">1.1.3 | å‚æ•°å³è®°å¿†ï¼ˆParameter as Memoryï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id9">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#memory-circuitry-theory">2â€‚_â€‚Memory Circuitry Theory</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id10">æ ¸å¿ƒæ¦‚å¿µæ€»ç»“ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id11">æ€»ä½“è´¡çŒ®ï¼š</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#definition-2">Definition 2.</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id12">1. <strong>å®šä¹‰ä¸æ ¸å¿ƒæ¦‚å¿µï¼šè®¡ç®—å›¾ã€åŒæ„ä¸çŸ¥è¯†ï¼ˆç”µè·¯ï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id13">2. <strong>çŸ¥è¯†çš„å®ä¾‹</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id14">3. <strong>çŸ¥è¯†çš„å¤–éƒ¨åŒ–ä¸è®°å¿†</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id15">4. <strong>ç»“è®ºä¸æ–­è¨€</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id16">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#remark-1">Remark 1.</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id17">1. <strong>ç”µè·¯æ„é€ çš„å…³é”®æ€§è´¨</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#llm">2. <strong>è®°å¿†å¢å¼º LLM çš„å½¢å¼åŒ–å®šä¹‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id18">3. <strong>å†™å…¥ä»£ä»·ä¸è¯»å–ä»£ä»·çš„æƒè¡¡ï¼ˆè®°å¿†å±‚æ¬¡ç»“æ„ï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id19">4. <strong>çŸ¥è¯†ä½¿ç”¨é¢‘ç‡ä¸è®°å¿†åˆ†é…</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id20">5. <strong>å›¾ç¤ºä¸ç»“è®º</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id21">å°ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#design">3â€‚_â€‚Design</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id22"><strong>3 | Design</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id25"><strong>3.1 | æ¨ç†è¿‡ç¨‹</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id27"><strong>3.2 | å†™å…¥ä¸è¯»å–è®°å¿†</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id28"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#memory-sparsification-and-storage">3.3â€‚_â€‚Memory Sparsification and Storage</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id29">ä¸€ã€æ˜¾å¼è®°å¿†çš„å­˜å‚¨æŒ‘æˆ˜</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id30">äºŒã€å„ç»´åº¦çš„ç¨€ç–åŒ–ç­–ç•¥</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id31">ä¸‰ã€å‹ç¼©æ•ˆæœ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id32">å››ã€éƒ¨ç½²æ–¹å¼</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id33">äº”ã€è¡¥å……è¯´æ˜ä¸å»ºè®®</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id36">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#model-shape">3.4â€‚_â€‚Model Shape</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id37">3.4 | æ¨¡å‹ç»“æ„ï¼ˆModel Shapeï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#training-designs">3.5 | è®­ç»ƒè®¾è®¡ï¼ˆTraining Designsï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id38">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#two-stage-pretrain">3.6â€‚_â€‚Two-stage Pretrain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id39">ä¸€ã€é¢„è®­ç»ƒçš„ä¸¤ä¸ªé˜¶æ®µ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#continual-train">äºŒã€å¯¹ continual train çš„ä¼˜åŒ–</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id40">ä¸‰ã€é˜²æ­¢ä¿¡æ¯æ³„éœ²</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id41">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#pretraining-data">4â€‚_â€‚Pretraining Data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#data-collection"><strong>4.1 æ•°æ®æ”¶é›†ï¼ˆData Collectionï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#filtering"><strong>4.2 æ•°æ®è¿‡æ»¤ï¼ˆFilteringï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#tokenizer"><strong>4.3 åˆ†è¯å™¨ï¼ˆTokenizerï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#knowledge-base"><strong>4.4 çŸ¥è¯†åº“ï¼ˆKnowledge Baseï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id42"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#pretrain">5â€‚_â€‚Pretrain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id43">1. é¢„è®­ç»ƒæ€»ä½“è®¾è®¡</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#set-up">2. è®­ç»ƒè®¾ç½®ï¼ˆSet-upï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#warmup-stage">3. é¢„çƒ­é˜¶æ®µï¼ˆWarmup Stageï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#continual-train-stage">4. æŒç»­è®­ç»ƒé˜¶æ®µï¼ˆContinual Train Stageï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id44">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#fine-tuning-and-alignment">6â€‚_â€‚Fine-tuning and Alignment</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#supervised-finetuning-sft">6.1 ç›‘ç£å¾®è°ƒï¼ˆSupervised Finetuning, SFTï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#direct-preference-optimization-dpo">6.2 ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDirect Preference Optimization, DPOï¼‰</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#evaluation">7â€‚_â€‚Evaluation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id45">7.1 é€šç”¨èƒ½åŠ›è¯„ä¼°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id46">7.2 å¯¹è¯èƒ½åŠ›è¯„ä¼°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id47">7.3 å¹»è§‰ä¸äº‹å®æ€§è¯„ä¼°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id48">7.4 ä¸“ä¸šä»»åŠ¡è¯„ä¼°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id49">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#inference-speed">7.5â€‚_â€‚Inference Speed</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id50">ä¸»è¦å†…å®¹æ€»ç»“å¦‚ä¸‹ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id51">æ€»ç»“ï¼š</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#conclusion">8â€‚_â€‚Conclusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#acknowledgement">Acknowledgement</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#appendix-a-cost-estimation">Appendix A Cost Estimation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id52">æ¨¡å‹å‚æ•°è®¾å®š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#implicit-memory">éšå¼è®°å¿†ï¼ˆImplicit Memoryï¼‰æˆæœ¬</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#explicit-memory">æ˜¾å¼è®°å¿†ï¼ˆExplicit Memoryï¼‰æˆæœ¬</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#external-information-rag">å¤–éƒ¨ä¿¡æ¯ï¼ˆExternal Informationï¼Œå¦‚ RAGï¼‰æˆæœ¬</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id53">ç»¼åˆæ¯”è¾ƒ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id54">æ‹“å±•è®¨è®º</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#appendix-b-vector-compression">Appendix B Vector Compression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#appendix-c-supplementary-evaluation-results">Appendix C Supplementary Evaluation Results</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html">2505.14683_Emerging Properties in Unified Multimodal Pretraining</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#introduction">1 Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id1">æ ¸å¿ƒå†…å®¹æ€»ç»“ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id2">æ€»ç»“ï¼š</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#model">2 Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id3">1. æ¨¡å‹æ¶æ„æ¦‚è§ˆ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id4">2. ç”Ÿæˆç­–ç•¥</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id5">3. æ¨¡å‹ç»†èŠ‚</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#generalized-causal-attention">4. å¹¿ä¹‰å› æœæ³¨æ„åŠ›ï¼ˆGeneralized Causal Attentionï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#transformer">5. Transformerç»“æ„é€‰æ‹©ä¸å®éªŒ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id6">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#data">3 Data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id7">æ•°æ®ç‰¹ç‚¹ä¸ç›®æ ‡</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id8">æ•°æ®æ¥æºä¸ç»Ÿè®¡</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id9">æ•°æ®æ„å»ºæ–¹æ³•</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id16">æ•°æ®è®­ç»ƒç­–ç•¥</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id17">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#training">4 Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id18">1. å¤šé˜¶æ®µè®­ç»ƒç­–ç•¥</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id19">2. å…³é”®è¶…å‚æ•°è°ƒæ•´</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id22">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#evaluation">5 Evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#emerging-properties">6 Emerging Properties</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id23">1. <strong>æ–°å…´å±æ€§çš„å®šä¹‰ä¸ç ”ç©¶èƒŒæ™¯</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id24">2. <strong>ä»»åŠ¡è¡¨ç°ä¸è®­ç»ƒé˜¶æ®µçš„å…³ç³»</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id25">3. <strong>å¤šæ¨¡æ€ç‰¹å¾çš„é‡è¦æ€§</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id26">4. <strong>å®šæ€§åˆ†æä¸ç”Ÿæˆè´¨é‡æå‡</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id27">5. <strong>æ ¸å¿ƒå‘ç°ä¸ç»“è®º</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id28">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#main-results">7 Main Results</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id29">7.1 å›¾åƒç†è§£</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id30">7.2 å›¾åƒç”Ÿæˆ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id31">7.3 å›¾åƒç¼–è¾‘</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id32">7.4 å¸¦æœ‰æ¨ç†çš„ç”Ÿæˆ/ç¼–è¾‘</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id33">7.5 ä¸–ç•Œå»ºæ¨¡</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id34">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#more-qualitative-results">7.6 More Qualitative Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#conclusion">8 Conclusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#acknowledgement">9 Acknowledgement</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html">MemOS: A Memory OS for AI System</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#llm">LLM æ€»ç»“ï¼š</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#introduction">1 Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id1"><strong>1. èƒŒæ™¯ä¸åŠ¨æœº</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id2"><strong>2. ç°æœ‰æ–¹æ³•çš„ä¸è¶³</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id3"><strong>3. å››å¤§å…¸å‹æŒ‘æˆ˜</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#memos"><strong>4. MemOSçš„æå‡ºä¸æ ¸å¿ƒç†å¿µ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id4"><strong>5. æ€»ç»“ä¸æ„ä¹‰</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#memory-in-large-language-models">2 Memory in Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id5">æ€»ç»“å¦‚ä¸‹ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id6"><strong>ä¸€ã€è®°å¿†ç ”ç©¶çš„å››ä¸ªé˜¶æ®µ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id7"><strong>äºŒã€ç¬¬ä¸€é˜¶æ®µï¼šè®°å¿†å®šä¹‰ä¸æ¢ç´¢</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id14"><strong>ä¸‰ã€MemOS çš„åˆæ­¥æ„æƒ³</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id15"><strong>å››ã€æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#stage-1"><strong>2.1 æ˜¾å¼é•¿æœŸè®°å¿†çš„å»ºç«‹ï¼ˆStage 1ï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#stage-2"><strong>2.2 äººè„‘å¼è®°å¿†æœºåˆ¶çš„å¼•å…¥ï¼ˆStage 2ï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#stage-3"><strong>2.3 åŸºäºå·¥å…·çš„è®°å¿†ç®¡ç†ï¼ˆStage 3ï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#stage-4"><strong>2.4 ç³»ç»ŸåŒ–è®°å¿†æ²»ç†ï¼ˆStage 4ï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id16"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#memos-design-philosophy">3 MemOS Design Philosophy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#memos-3-1-vision-of-memos">ä¸€ã€MemOS çš„æ„¿æ™¯ï¼ˆ3.1 Vision of MemOSï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#from-computer-os-to-memory-os">äºŒã€ä»ä¼ ç»Ÿæ“ä½œç³»ç»Ÿåˆ°è®°å¿†æ“ä½œç³»ç»Ÿï¼ˆ3.2 From Computer OS to Memory OSï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id17">ä¸‰ã€æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#memory-modeling-in-memos">4 Memory Modeling in MemOS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id18"><strong>4.1 å†…å­˜ç±»å‹ä¸è¯­ä¹‰æ¼”åŒ–è·¯å¾„</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#memory-cube-memcube"><strong>4.2 Memory Cubeï¼ˆMemCubeï¼‰ï¼šå†…å­˜çš„æ ¸å¿ƒèµ„æºå•å…ƒ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id19"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#architecture-of-memos">5 Architecture of MemOS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id20">æ€»ç»“ï¼šMemOS æ¶æ„ä¸æ‰§è¡Œæµç¨‹</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id24">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id25">5.5.1 MemGovernanceï¼ˆå†…å­˜æ²»ç†æ¨¡å—ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#memvault">5.5.2 MemVaultï¼ˆå†…å­˜å­˜å‚¨ä¸è·¯ç”±åŸºç¡€è®¾æ–½ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#memloader-memdumper">5.5.3 MemLoader ä¸ MemDumperï¼ˆå†…å­˜åŠ è½½ä¸å¯¼å‡ºæ¨¡å—ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#memstore">5.5.4 MemStoreï¼ˆå†…å­˜å­˜å‚¨ä¸åˆ†å‘æ¥å£ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id26">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#evaluation">6 Evaluation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#end-to-end-evaluation-on-locomo"><strong>1. æ•´ä½“ç³»ç»Ÿè¯„ä¼°ï¼ˆEnd-to-End Evaluation on LOCOMOï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#evaluation-of-memory-retrieval"><strong>2. å†…å­˜æ£€ç´¢è¯„ä¼°ï¼ˆEvaluation of Memory Retrievalï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#kv-evaluation-of-kv-based-memory-acceleration"><strong>3. KVç¼“å­˜åŠ é€Ÿè¯„ä¼°ï¼ˆEvaluation of KV-Based Memory Accelerationï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id27"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#memos-for-architecture-innovation-and-applications">7 MemOS for Architecture Innovation and Applications</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id28">ä¸€ã€MemOSæ¨åŠ¨çš„æ¶æ„åˆ›æ–°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id29">äºŒã€MemOSçš„åº”ç”¨åœºæ™¯</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id30">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#conclusion">8 Conclusion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../other.html">å…¶ä»–</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../other.html#id3">æ•°æ®é›†&amp;æ•°æ®è’¸é¦</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../others/DataSets/1811.10959v3_Dataset_Distillation.html">1811.10959v3_Dataset Distillation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../others/DataSets/1811.10959v3_Dataset_Distillation.html#abstract">ABSTRACT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/DataSets/1811.10959v3_Dataset_Distillation.html#llm">LLMæ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/DataSets/1811.10959v3_Dataset_Distillation.html#introduction">1. INTRODUCTION</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/DataSets/1811.10959v3_Dataset_Distillation.html#approach">3. APPROACH</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../others/DataSets/2502.20653_Dataset_Distillation.html">2502.20653_Dataset Distillation with Neural Characteristic Function: A Minmax Perspective</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../others/DataSets/2502.20653_Dataset_Distillation.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/DataSets/2502.20653_Dataset_Distillation.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/DataSets/2502.20653_Dataset_Distillation.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/DataSets/2502.20653_Dataset_Distillation.html#conclusion">7. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../others/DataSets/normal.html">é€šç”¨</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../others/DataSets/normal.html#dataset-distillation">Dataset distillation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../other.html#d">3D</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../others/3D/2003.08934_NeRF.html">2003.08934_NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2003.08934_NeRF.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2003.08934_NeRF.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2003.08934_NeRF.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2003.08934_NeRF.html#neural-radiance-field-scene-representation">3. Neural Radiance Field Scene Representation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2003.08934_NeRF.html#volume-rendering-with-radiance-fields">4. Volume Rendering with Radiance Fields</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2003.08934_NeRF.html#optimizing-a-neural-radiance-field">5. Optimizing a Neural Radiance Field</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2003.08934_NeRF.html#result">6. Result</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2003.08934_NeRF.html#conclusion">7. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../others/3D/2203.08586_VanishingPointEstimation.html">2203.08586: Deep vanishing point detection: Geometric priors make dataset variations vanish</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2203.08586_VanishingPointEstimation.html#id1">æ¦‚å¿µ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2203.08586_VanishingPointEstimation.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2203.08586_VanishingPointEstimation.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2203.08586_VanishingPointEstimation.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2203.08586_VanishingPointEstimation.html#geometric-priors-for-vp-detection">3. Geometric priors for VP detection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2203.08586_VanishingPointEstimation.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2203.08586_VanishingPointEstimation.html#conclusion-and-limitations">5. Conclusion and limitations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html">2312.14132_DUSt3R: Geometric 3D Vision Made Easy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html#id1">å…³é”®è¯</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html#id2">ç›¸å…³æ¦‚å¿µ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html#method">3. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html#experiments-with-dust3r">4. Experiments with DUSt3R</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html#conclusion">5. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html#appendix-a">Appendix A <strong>é™„å½•æ¦‚è§ˆ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html#appendix-b-qualitative-results">Appendix B.  Qualitative results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html#appendix-c-extended-related-work">Appendix C. Extended Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html#appendix-d-multi-view-pose-estimation">Appendix D. å¤šè§†è§’å§¿æ€ä¼°è®¡ï¼ˆMulti-view Pose Estimationï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html#appendix-e-visual-localization">Appendix E. è§†è§‰å®šä½ï¼ˆVisual Localizationï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html#appendix-f-training-details">Appendix F. Training details</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html">2406.09756_MASt3R: Grounding Image Matching in 3D with MASt3R</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html#id1">å‰è¨€</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html#id2">ğŸ§  æ€ç»´å¯¼å›¾å¼æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html#related-works">2. Related works</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html#id3">ğŸ§  æ€»ç»“æ€ç»´å¯¼å›¾</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html#method">3. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html#experimental-results">4. Experimental results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html#conclusion">5. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html#appendix-a-additional-qualitative-results">Appendix A Additional Qualitative Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html#b-fast-reciprocal-matching">B. Fast Reciprocal Matching</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html#c-coarse-to-fine">C. Coarse-to-Fine</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html#d-detailed-experimental-settings">D. Detailed experimental settings</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../others/3D/2412.09401_SLAM3R.html">2412.09401_SLAM3R: Real-Time Dense Scene Reconstruction from Monocular RGB Videos</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.09401_SLAM3R.html#id1">æœ¯è¯­</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.09401_SLAM3R.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.09401_SLAM3R.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.09401_SLAM3R.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.09401_SLAM3R.html#method">3. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.09401_SLAM3R.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.09401_SLAM3R.html#conclusion">5. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.09401_SLAM3R.html#id14">6. è‡´è°¢</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.09401_SLAM3R.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.09401_SLAM3R.html#appendix-a-implementation-details">Appendix A Implementation details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.09401_SLAM3R.html#appendix-b-details-for-experimental-settings">Appendix B Details for experimental settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.09401_SLAM3R.html#appendix-c-additional-comparisons-and-analyses">Appendix C Additional comparisons and analyses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.09401_SLAM3R.html#d-more-visual-results">D. More visual results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html">2412.12392_MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html#gpt">GPT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html#id1">å…ˆéªŒçŸ¥è¯†</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html#method">3. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html#results">4. Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html#limitations-and-future-work">5. Limitations and Future Workï¼ˆå±€é™ä¸æœªæ¥å·¥ä½œï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html#conclusion">ğŸ§¾ 6. Conclusionï¼ˆæ€»ç»“ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html#id32">ğŸ§  æ€»ç»“ä¸€å¥è¯ç‰ˆï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html#initialisation">8. Initialisationï¼ˆåˆå§‹åŒ–ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html#runtime-breakdown">9. Runtime Breakdownï¼ˆè¿è¡Œæ—¶åˆ†æï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html#evaluation-setup">10. Evaluation Setupï¼ˆè¯„ä¼°è®¾ç½®ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html#id35">11. EuRoC ç»“æœæ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../others/3D/2503.11651_VGGT.html">2503.11651_VGGT: Visual Geometry Grounded Transformer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2503.11651_VGGT.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2503.11651_VGGT.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2503.11651_VGGT.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2503.11651_VGGT.html#method">3. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2503.11651_VGGT.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2503.11651_VGGT.html#discussions">5. Discussions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2503.11651_VGGT.html#conclusions">6. Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2503.11651_VGGT.html#appendix-a-formal-definitions">Appendix A Formal Definitions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2503.11651_VGGT.html#appendix-b-implementation-details">Appendix B Implementation Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2503.11651_VGGT.html#appendix-c-additional-experiments">Appendix C Additional Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2503.11651_VGGT.html#appendix-d-qualitative-examples">Appendix D Qualitative Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2503.11651_VGGT.html#appendix-e-related-work">Appendix E Related Work</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../other.html#id4">å…¶ä»–</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../others/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html">A PAINLESS GUIDE TO CRC ERROR DETECTION ALGORITHMS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#the-basic-idea-behind-crc-algorithms">The Basic Idea Behind CRC Algorithms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#polynomical-arithmetic">Polynomical Arithmetic</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#binary-arithmetic-with-no-carries">Binary Arithmetic with No Carries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#id2">ä¸€ä¸ªå¯ç”¨çš„å®ä¾‹</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#choosing-a-poly">Choosing A Poly</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#a-straightforward-crc-implementation">A Straightforward CRC Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#a-table-driven-implementation">A Table-Driven Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#a-slightly-mangled-table-driven-implementation">A Slightly Mangled Table-Driven Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#id3">å‚è€ƒ</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../others/others/Distributed%20Representations%20of%20Sentences%20and%20Documents.html">Distributed Representations of Sentences and Documents</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">æ–°æºª-gordon</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../Benchmarking.html">è¯„æµ‹åŸºå‡†</a> &raquo;</li>
        
      <li>2402.17753_LoCoMo: Evaluating Very Long-Term Conversational Memory of LLM Agents</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/Benchmarkings/DS_LongCtxs/2402.17753_LoCoMo.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            <nav id="local-table-of-contents" role="navigation" aria-labelledby="local-table-of-contents-title">
              <h4 id="local-table-of-contents-title">On This Page</h4>
              <ul>
<li><a class="reference internal" href="#">2402.17753_LoCoMo: Evaluating Very Long-Term Conversational Memory of LLM Agents</a><ul>
<li><a class="reference internal" href="#id1">æ€»ç»“</a></li>
<li><a class="reference internal" href="#abstract">Abstract</a></li>
<li><a class="reference internal" href="#introduction">1 Introduction</a></li>
<li><a class="reference internal" href="#related-work">2 Related Work</a></li>
<li><a class="reference internal" href="#generative-pipeline-for-locomo">3 Generative Pipeline for LoCoMo</a><ul>
<li><a class="reference internal" href="#locomo"><strong>3. LoCoMo çš„ç”Ÿæˆç®¡é“æ¦‚è¿°</strong></a></li>
<li><a class="reference internal" href="#persona"><strong>3.1 è§’è‰²è®¾å®šï¼ˆPersonaï¼‰</strong></a></li>
<li><a class="reference internal" href="#temporal-event-graph"><strong>3.2 æ—¶é—´äº‹ä»¶å›¾ï¼ˆTemporal Event Graphï¼‰</strong></a></li>
<li><a class="reference internal" href="#id2"><strong>3.3 è™šæ‹Ÿä»£ç†æ¶æ„</strong></a><ul>
<li><a class="reference internal" href="#reflect-respond"><strong>1. åæ€ä¸å›åº”ï¼ˆReflect &amp; Respondï¼‰</strong></a></li>
<li><a class="reference internal" href="#image-sharing-image-reaction"><strong>2. å›¾åƒåˆ†äº«ä¸å›¾åƒååº”ï¼ˆImage Sharing &amp; Image Reactionï¼‰</strong></a></li>
</ul>
</li>
<li><a class="reference internal" href="#human-verification-editing"><strong>3.4 äººç±»éªŒè¯ä¸ç¼–è¾‘ï¼ˆHuman Verification &amp; Editingï¼‰</strong></a></li>
<li><a class="reference internal" href="#id3"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
<li><a class="reference internal" href="#locomo-evaluation-benchmark">4 LoCoMo Evaluation Benchmark</a><ul>
<li><a class="reference internal" href="#question-answering-task">1. é—®ç­”ä»»åŠ¡ï¼ˆQuestion Answering Taskï¼‰</a></li>
<li><a class="reference internal" href="#event-summarization-task">2. äº‹ä»¶æ€»ç»“ä»»åŠ¡ï¼ˆEvent Summarization Taskï¼‰</a></li>
<li><a class="reference internal" href="#multi-modal-dialogue-generation-task">3. å¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆä»»åŠ¡ï¼ˆMulti-Modal Dialogue Generation Taskï¼‰</a></li>
<li><a class="reference internal" href="#id4">æ€»ç»“</a></li>
</ul>
</li>
<li><a class="reference internal" href="#experimental-setup">5 Experimental Setup</a><ul>
<li><a class="reference internal" href="#id5"><strong>1. å®éªŒè®¾ç½®æ¦‚è¿°</strong></a></li>
<li><a class="reference internal" href="#question-answering"><strong>2. é—®ç­”ä»»åŠ¡ï¼ˆQuestion Answeringï¼‰</strong></a></li>
<li><a class="reference internal" href="#event-summarization"><strong>3. äº‹ä»¶æ‘˜è¦ç”Ÿæˆä»»åŠ¡ï¼ˆEvent Summarizationï¼‰</strong></a></li>
<li><a class="reference internal" href="#multi-modal-dialogue-generation"><strong>4. å¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆä»»åŠ¡ï¼ˆMulti-modal Dialogue Generationï¼‰</strong></a></li>
<li><a class="reference internal" href="#id6"><strong>5. æ€»ç»“</strong></a></li>
</ul>
</li>
<li><a class="reference internal" href="#experimental-results">6 Experimental Results</a><ul>
<li><a class="reference internal" href="#id7">6.1 é—®ç­”ä»»åŠ¡ï¼ˆQuestion Answering Taskï¼‰</a></li>
<li><a class="reference internal" href="#id8">6.2 äº‹ä»¶å›¾æ€»ç»“ä»»åŠ¡ï¼ˆEvent Summarization Taskï¼‰</a></li>
<li><a class="reference internal" href="#multi-modal-dialog-generation-task">6.3 å¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆä»»åŠ¡ï¼ˆMulti-Modal Dialog Generation Taskï¼‰</a></li>
<li><a class="reference internal" href="#id9">æ€»ä½“ç»“è®º</a></li>
</ul>
</li>
<li><a class="reference internal" href="#conclusion">7 Conclusion</a></li>
<li><a class="reference internal" href="#limitations">8 Limitations</a></li>
<li><a class="reference internal" href="#broader-impacts">9 Broader Impacts</a></li>
<li><a class="reference internal" href="#appendix-overview">Appendix Overview</a></li>
<li><a class="reference internal" href="#appendix-a-generative-pipeline-for-locomo">Appendix A Generative Pipeline for LoCoMo</a></li>
<li><a class="reference internal" href="#appendix-b-dataset">Appendix B Dataset</a><ul>
<li><a class="reference internal" href="#b"><strong>é™„å½•Bï¼šæ•°æ®é›†</strong></a><ul>
<li><a class="reference internal" href="#b-1"><strong>B.1 æ•°æ®é›†ç»Ÿè®¡</strong></a></li>
<li><a class="reference internal" href="#b-2"><strong>B.2 æ•°æ®é›†æˆæƒ</strong></a></li>
<li><a class="reference internal" href="#b-3"><strong>B.3 æ ‡æ³¨äººå‘˜ä¿¡æ¯</strong></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#appendix-c-experimental-setup">Appendix C Experimental Setup</a><ul>
<li><a class="reference internal" href="#baselines">1. åŸºçº¿æ–¹æ³•ï¼ˆBaselinesï¼‰</a><ul>
<li><a class="reference internal" href="#id10">1.1 é—®ç­”ä»»åŠ¡</a></li>
<li><a class="reference internal" href="#id11">1.2 äº‹ä»¶æ‘˜è¦ä»»åŠ¡</a></li>
<li><a class="reference internal" href="#id12">1.3 å¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆ</a></li>
</ul>
</li>
<li><a class="reference internal" href="#implementation-details">2. å®ç°ç»†èŠ‚ï¼ˆImplementation Detailsï¼‰</a></li>
<li><a class="reference internal" href="#id13">æ€»ç»“</a></li>
</ul>
</li>
<li><a class="reference internal" href="#appendix-d-results">Appendix D Results</a><ul>
<li><a class="reference internal" href="#id14">æ€»ç»“å†…å®¹å¦‚ä¸‹ï¼š</a><ul>
<li><a class="reference internal" href="#minigpt-5">1. <strong>è¡¨6ï¼šMiniGPT-5å¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆæ€§èƒ½æ¯”è¾ƒ</strong></a></li>
<li><a class="reference internal" href="#d-1-event-summarization-task">2. <strong>D.1 äº‹ä»¶æ€»ç»“ä»»åŠ¡ï¼ˆEvent Summarization Taskï¼‰</strong></a></li>
<li><a class="reference internal" href="#d-2-multimodal-dialog-generation-task">3. <strong>D.2 å¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆä»»åŠ¡ï¼ˆMultimodal Dialog Generation Taskï¼‰</strong></a></li>
</ul>
</li>
<li><a class="reference internal" href="#id15">æ€»ä½“æ€»ç»“ï¼š</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
  <section class="tex2jax_ignore mathjax_ignore" id="locomo-evaluating-very-long-term-conversational-memory-of-llm-agents">
<h1>2402.17753_LoCoMo: Evaluating Very Long-Term Conversational Memory of LLM Agents<a class="headerlink" href="#locomo-evaluating-very-long-term-conversational-memory-of-llm-agents" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h1>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/2402.17753">https://arxiv.org/abs/2402.17753</a></p></li>
<li><p>ç»„ç»‡: University of North Carolina, Chapel Hill; University of Southern California; Snap Inc</p></li>
<li><p>å®˜ç½‘: https://snap-research.github.io/locomo/</p></li>
<li><p>gitHub: <a class="reference external" href="https://github.com/snap-research/LoCoMo">https://github.com/snap-research/LoCoMo</a></p></li>
<li><p>å¼•ç”¨: 82(2025-07-13)</p></li>
</ul>
<section id="id1">
<h2>æ€»ç»“<a class="headerlink" href="#id1" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<ul class="simple">
<li><p>ç®€ä»‹</p>
<ul>
<li><p>è‹±æ–‡æ•°æ®é›†</p></li>
<li><p>é•¿æœŸå¯¹è¯æ•°æ®é›†</p>
<ul>
<li><p>æ¯ä¸ªå¯¹è¯åŒ…å«å¹³å‡300è½®ã€9,000ä¸ªtokenï¼Œæœ€é•¿å¯è¾¾35ä¸ªä¼šè¯ã€‚</p></li>
<li><p>å¹³å‡æ¯æ®µå¯¹è¯åŒ…å«300è½®ã€9209ä¸ªtokenï¼Œè·¨è¶Š19.3ä¸ªä¼šè¯ï¼Œè¦†ç›–æ•°æœˆæ—¶é—´</p></li>
</ul>
</li>
<li><p>ç›®æ ‡ï¼šä»¥å…¨é¢è¡¡é‡æ¨¡å‹åœ¨é•¿æœŸå¯¹è¯ä¸­çš„è®°å¿†èƒ½åŠ›</p></li>
<li><p>ä¸‰ç§ä»»åŠ¡:</p>
<ul>
<li><p>é—®ç­”ä»»åŠ¡</p>
<ul>
<li><p>æµ‹è¯•æ¨¡å‹æ˜¯å¦èƒ½â€œå›å¿†â€è¿‡å»çš„å¯¹è¯å†…å®¹ï¼Œ</p></li>
<li><p>åˆ†ä¸ºå•è·³ã€å¤šè·³ã€æ—¶é—´æ¨ç†ã€å¸¸è¯†/ä¸–ç•ŒçŸ¥è¯†å’Œå¯¹æŠ—æ€§é—®é¢˜ç­‰ç±»å‹</p></li>
</ul>
</li>
<li><p>äº‹ä»¶æ€»ç»“</p>
<ul>
<li><p>è¯„ä¼°æ¨¡å‹æ˜¯å¦èƒ½ç†è§£å¹¶æ€»ç»“å¯¹è¯ä¸­äº‹ä»¶ä¹‹é—´çš„å› æœå’Œæ—¶é—´å…³ç³»</p></li>
</ul>
</li>
<li><p>å¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆ</p>
<ul>
<li><p>è¯„ä¼°æ¨¡å‹æ˜¯å¦èƒ½ç”Ÿæˆä¸å¯¹è¯å†å²ä¸€è‡´çš„å›åº”ï¼ŒåŒ…æ‹¬å¯¹å›¾åƒçš„ååº”</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="abstract">
<h2>Abstract<a class="headerlink" href="#abstract" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p>æœ¬ç¯‡è®ºæ–‡æ—¨åœ¨ç ”ç©¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨<strong>éå¸¸é•¿æœŸå¯¹è¯</strong>ä¸­çš„<strong>é•¿æœŸè®°å¿†èƒ½åŠ›</strong>ã€‚ç°æœ‰ç ”ç©¶å¤šèšç„¦äºä¸è¶…è¿‡äº”ä¸ªå¯¹è¯è½®æ¬¡ï¼ˆsessionï¼‰çš„å¯¹è¯è¯„ä¼°ï¼Œè€Œå¯¹æ›´é•¿æ—¶é—´èŒƒå›´ï¼ˆå¦‚å‡ åä¸ªä¼šè¯ï¼‰çš„ç ”ç©¶ä»å±ç©ºç™½ã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç ”ç©¶ç¼ºå£ï¼Œä½œè€…æå‡ºäº†ä¸€å¥—<strong>äººæœºååŒçš„å¯¹è¯ç”Ÿæˆç®¡é“</strong>ï¼Œç”¨äºç”Ÿæˆé«˜è´¨é‡ã€é•¿æœŸçš„å¯¹è¯æ•°æ®ã€‚è¯¥æ–¹æ³•åŸºäº<strong>LLMæ™ºèƒ½ä½“æ¶æ„</strong>ï¼Œå¹¶ç»“åˆ<strong>è§’è‰²è®¾å®š</strong>å’Œ<strong>æ—¶é—´äº‹ä»¶å›¾</strong>ï¼Œä½¿å¯¹è¯å†…å®¹å…·æœ‰è¿è´¯æ€§å’Œäº‹ä»¶åŸºç¡€ã€‚æ­¤å¤–ï¼Œæ™ºèƒ½ä½“è¿˜è¢«èµ‹äºˆ<strong>å›¾åƒç”Ÿæˆä¸äº¤äº’èƒ½åŠ›</strong>ï¼Œä»¥æå‡å¯¹è¯çš„å¤šæ¨¡æ€æ€§ã€‚ç”Ÿæˆçš„å¯¹è¯ä¼šç”±äººç±»æ ‡æ³¨è€…è¿›è¡Œ<strong>é•¿æœŸä¸€è‡´æ€§æ£€æŸ¥</strong>å’Œ<strong>äº‹ä»¶å›¾åŒ¹é…éªŒè¯</strong>ã€‚</p>
<p>åŸºäºæ­¤ç®¡é“ï¼Œä½œè€…æ„å»ºäº†ä¸€ä¸ªåä¸º<strong>LoCoMo</strong>çš„é•¿æœŸå¯¹è¯æ•°æ®é›†ã€‚æ¯ä¸ªå¯¹è¯åŒ…å«å¹³å‡<strong>300è½®ã€9,000ä¸ªtoken</strong>ï¼Œæœ€é•¿å¯è¾¾<strong>35ä¸ªä¼šè¯</strong>ã€‚åŸºäºè¯¥æ•°æ®é›†ï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ª<strong>ç»¼åˆè¯„ä¼°åŸºå‡†</strong>ï¼Œæ¶µç›–<strong>é—®ç­”ä»»åŠ¡</strong>ã€<strong>äº‹ä»¶æ€»ç»“</strong>å’Œ<strong>å¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆ</strong>ï¼Œä»¥å…¨é¢è¡¡é‡æ¨¡å‹åœ¨é•¿æœŸå¯¹è¯ä¸­çš„è®°å¿†èƒ½åŠ›ã€‚</p>
<p>å®éªŒç»“æœè¡¨æ˜ï¼Œå°½ç®¡ä½¿ç”¨äº†<strong>é•¿ä¸Šä¸‹æ–‡å¤„ç†</strong>å’Œ<strong>RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰<strong>ç­‰æŠ€æœ¯ï¼Œå½“å‰LLMåœ¨ç†è§£å’Œå»ºæ¨¡é•¿æœŸå¯¹è¯ä¸­çš„</strong>æ—¶é—´å› æœåŠ¨æ€</strong>æ–¹é¢ä»ç„¶å­˜åœ¨æ˜æ˜¾æŒ‘æˆ˜ï¼Œè¿œä¸åŠäººç±»è¡¨ç°ã€‚è®ºæ–‡æœ€åæä¾›äº†ä»£ç å’Œæ•°æ®èµ„æºï¼Œä»¥ä¿ƒè¿›åç»­ç ”ç©¶ã€‚</p>
</section>
<section id="introduction">
<h2>1 Introduction<a class="headerlink" href="#introduction" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/07/l69wOX.jpg" /></p>
<p>Figure 1: An example in LOCOMO.</p>
<p>æœ¬èŠ‚ä¸»è¦ä»‹ç»äº†LoCoMoè¿™ä¸€å…¨æ–°çš„é•¿æ—¶ã€å¼€æ”¾åŸŸã€å¤šæ¨¡æ€å¯¹è¯æ•°æ®é›†ï¼Œå¹¶æå‡ºäº†ç”¨äºè¯„ä¼°LLMä»£ç†åœ¨é•¿å¯¹è¯ä¸­è®°å¿†èƒ½åŠ›çš„ç»¼åˆè¯„ä¼°æ¡†æ¶ã€‚</p>
<p>é¦–å…ˆï¼Œä½œè€…æŒ‡å‡ºå½“å‰å°½ç®¡åœ¨åŸºäºLLMçš„å¯¹è¯æ¨¡å‹å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯æ–¹é¢å–å¾—äº†ä¸€äº›è¿›å±•ï¼Œä½†é’ˆå¯¹<strong>éå¸¸é•¿çš„å¯¹è¯</strong>ï¼ˆä¾‹å¦‚è·¨è¶Šæ•°æœˆã€æ•°ç™¾è½®æ¬¡ï¼‰çš„ç³»ç»Ÿæ€§è¯„ä¼°ä»ç„¶ä¸è¶³ã€‚å·²æœ‰å¯¹è¯æ•°æ®é›†çš„å¹³å‡å¯¹è¯é•¿åº¦è¾ƒçŸ­ï¼Œç¼ºä¹å¯¹é•¿æœŸè®°å¿†èƒ½åŠ›çš„æœ‰æ•ˆæµ‹è¯•ï¼Œè€ŒLoCoMoå¡«è¡¥äº†è¿™ä¸€ç©ºç™½ã€‚</p>
<p><strong>LoCoMoæ•°æ®é›†çš„ç‰¹ç‚¹</strong>åŒ…æ‹¬ï¼š</p>
<ul class="simple">
<li><p>å¹³å‡æ¯æ®µå¯¹è¯åŒ…å«300è½®ã€9209ä¸ªtokenï¼Œè·¨è¶Š19.3ä¸ªä¼šè¯ï¼Œè¦†ç›–æ•°æœˆæ—¶é—´ï¼›</p></li>
<li><p>æ”¯æŒ<strong>å¤šæ¨¡æ€å¯¹è¯</strong>ï¼ŒåŒ…æ‹¬å›¾åƒçš„åˆ†äº«å’Œå›åº”ï¼›</p></li>
<li><p>é€šè¿‡LLMç”Ÿæˆå¯¹è¯åˆç¨¿ï¼Œå†ç”±äººå·¥æ ¡å¯¹ä»¥ä¿®æ­£é•¿æœŸä¸ä¸€è‡´æ€§å’Œå¢å¼ºå¯¹è¯è¿è´¯æ€§ï¼›</p></li>
<li><p>å¯¹è¯å†…å®¹å›´ç»•è§’è‰²çš„<strong>ä¸ªæ€§ç‰¹å¾</strong>ã€<strong>ç”Ÿæ´»äº‹ä»¶çš„æ—¶é—´çº¿</strong>ä»¥åŠ<strong>å†å²å¯¹è¯çš„åæ€å’Œå›åº”æœºåˆ¶</strong>æ„å»ºã€‚</p></li>
</ul>
<p><strong>è¯„ä¼°æ¡†æ¶</strong>æ–¹é¢ï¼Œä½œè€…æå‡ºäº†ä¸‰ç§ä»»åŠ¡æ¥å…¨é¢è¯„ä¼°æ¨¡å‹åœ¨é•¿å¯¹è¯ä¸­çš„è¡¨ç°ï¼š</p>
<ol class="arabic simple">
<li><p><strong>é—®ç­”ä»»åŠ¡ï¼ˆQAï¼‰</strong>ï¼šæµ‹è¯•æ¨¡å‹æ˜¯å¦èƒ½â€œå›å¿†â€è¿‡å»çš„å¯¹è¯å†…å®¹ï¼Œåˆ†ä¸ºå•è·³ã€å¤šè·³ã€æ—¶é—´æ¨ç†ã€å¸¸è¯†/ä¸–ç•ŒçŸ¥è¯†å’Œå¯¹æŠ—æ€§é—®é¢˜ç­‰ç±»å‹ï¼›</p></li>
<li><p><strong>äº‹ä»¶å›¾æ€»ç»“ä»»åŠ¡</strong>ï¼šè¯„ä¼°æ¨¡å‹æ˜¯å¦èƒ½ç†è§£å¹¶æ€»ç»“å¯¹è¯ä¸­äº‹ä»¶ä¹‹é—´çš„å› æœå’Œæ—¶é—´å…³ç³»ï¼›</p></li>
<li><p><strong>å¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆä»»åŠ¡</strong>ï¼šè¯„ä¼°æ¨¡å‹æ˜¯å¦èƒ½ç”Ÿæˆä¸å¯¹è¯å†å²ä¸€è‡´çš„å›åº”ï¼ŒåŒ…æ‹¬å¯¹å›¾åƒçš„ååº”ã€‚</p></li>
</ol>
<p><strong>å®éªŒç»“æœ</strong>è¡¨æ˜ï¼š</p>
<ol class="arabic simple">
<li><p><strong>é•¿ä¸Šä¸‹æ–‡LLMå’ŒRAG</strong>åœ¨QAä»»åŠ¡ä¸­æå‡æ˜¾è‘—ï¼ˆ22-66%ï¼‰ï¼Œä½†ä¸äººç±»è¡¨ç°ä»æœ‰è¾ƒå¤§å·®è·ï¼ˆä½56%ï¼‰ï¼Œç‰¹åˆ«æ˜¯åœ¨æ—¶é—´æ¨ç†æ–¹é¢å·®è·è¾¾73%ï¼›</p></li>
<li><p><strong>é•¿ä¸Šä¸‹æ–‡LLMåœ¨å¯¹æŠ—æ€§é—®é¢˜å’Œäº‹ä»¶å›¾æ€»ç»“ä»»åŠ¡ä¸­è¡¨ç°è¾ƒå·®</strong>ï¼Œå®¹æ˜“å°†å¯¹è¯æˆ–äº‹ä»¶é”™è¯¯åœ°åˆ†é…ç»™é”™è¯¯çš„è§’è‰²ï¼›</p></li>
<li><p><strong>RAGåœ¨è´¨é‡å’Œä¸Šä¸‹æ–‡ç†è§£ä¹‹é—´å–å¾—å¹³è¡¡</strong>ï¼Œç‰¹åˆ«å½“å¯¹è¯è¢«è½¬åŒ–ä¸ºè§’è‰²ç”Ÿæ´»çš„æ•°æ®åº“å½¢å¼æ—¶ï¼Œè¡¨ç°æ›´ä¼˜ã€‚</p></li>
</ol>
<p>ç»¼ä¸Šï¼Œæœ¬èŠ‚å¼ºè°ƒäº†LoCoMoåœ¨çœŸå®é•¿å¯¹è¯æ¨¡æ‹Ÿã€å¤šæ¨¡æ€äº¤äº’å’Œé•¿æœŸè®°å¿†è¯„ä¼°æ–¹é¢çš„åˆ›æ–°æ€§ï¼Œå¹¶æå‡ºäº†æ–°çš„è¯„ä¼°ä»»åŠ¡ï¼Œä¸ºæœªæ¥å¯¹è¯ç³»ç»Ÿçš„å¼€å‘å’Œè¯„ä¼°æä¾›äº†é‡è¦åŸºç¡€ã€‚</p>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/07/dgKY56.jpg" /></p>
<p>Figure 2: Overview of our evaluation framework. We propose three tasks: question answering, event summarization and multimodal dialog generation to evaluate modelsâ€™ comprehension in very long-term dialogues.</p>
</section>
<section id="related-work">
<h2>2 Related Work<a class="headerlink" href="#related-work" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p>æœ¬ç« ç»¼è¿°äº†ä¸é•¿æœŸå¯¹è¯ã€å¤šæ¨¡æ€å¯¹è¯å’Œåˆæˆè¯„ä¼°åŸºå‡†ç›¸å…³çš„ç ”ç©¶å·¥ä½œã€‚</p>
<p>åœ¨<strong>é•¿æœŸå¯¹è¯</strong>æ–¹é¢ï¼Œç°æœ‰ç ”ç©¶ä¸»è¦ä¾èµ–äºä»å†å²å¯¹è¯ä¸­æ£€ç´¢ä¸Šä¸‹æ–‡ï¼Œå¹¶æŒ‰ç…§æ—¶é—´é¡ºåºè¿›è¡Œæ¨ç†ï¼Œæˆ–ä½¿ç”¨äº‹ä»¶æ¥æ„å»ºå¯¹è¯å†…å®¹ä»¥ä¿æŒä¸€è‡´æ€§ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å­˜åœ¨ä¸€äº›å±€é™ï¼šï¼ˆ1ï¼‰æ£€ç´¢å‡†ç¡®æ€§å—é™ï¼Œå› ä¸ºæ£€ç´¢æ¨¡å‹é€šå¸¸åŸºäºè¯­ä¹‰ç›¸ä¼¼æ€§è®­ç»ƒï¼Œè€Œéé’ˆå¯¹å¯¹è¯ä»»åŠ¡ï¼›ï¼ˆ2ï¼‰æ¨¡å‹åœ¨ä»æ£€ç´¢ç»“æœä¸­è¯†åˆ«æ­£ç¡®ä¸Šä¸‹æ–‡æ—¶å­˜åœ¨æ¨ç†å›°éš¾ï¼›ï¼ˆ3ï¼‰æ—¶é—´é—´éš”çš„å¤„ç†ä¹Ÿå¸¦æ¥æŒ‘æˆ˜ï¼Œä¾‹å¦‚ç³»ç»Ÿå¯¹è¿‡å»äº‹ä»¶çš„å›åº”å¯èƒ½å› å¯¹è¯æ—¶é—´é—´éš”ä¸åŒè€Œå˜åŒ–ã€‚å› æ­¤ï¼Œä½œè€…å¼ºè°ƒéœ€è¦é•¿å¯¹è¯æ•°æ®å’Œç³»ç»Ÿçš„è¯„ä¼°æ¡†æ¶ã€‚ä¸ºæ­¤ï¼Œä»–ä»¬è®¾è®¡äº†ä¸€ä¸ªåŸºäºæ£€ç´¢å¢å¼ºå’Œäº‹ä»¶å›¾çš„é•¿æœŸå¯¹è¯ç”Ÿæˆæµç¨‹ï¼Œå¹¶æå‡ºäº†è¯„ä¼°é•¿æœŸå¯¹è¯ä»£ç†çš„æ¡†æ¶ã€‚</p>
<p>åœ¨<strong>å¤šæ¨¡æ€å¯¹è¯</strong>æ–¹é¢ï¼Œç ”ç©¶ä¸»è¦åˆ†ä¸ºä¸¤ç±»ä»»åŠ¡ï¼šåŸºäºå›¾åƒçš„å¯¹è¯å’Œå›¾åƒå…±äº«å¯¹è¯ã€‚å‰è€…ä»¥å›¾åƒä¸ºä¸Šä¸‹æ–‡è¿›è¡Œé—®é¢˜å›ç­”æˆ–ç”Ÿæˆè‡ªç„¶å¯¹è¯ï¼›åè€…åˆ™æ˜¯æ ¹æ®å¯¹è¯å†…å®¹é€‰æ‹©åˆé€‚çš„å›¾åƒã€‚ä½œè€…ç»“åˆäº†å›¾åƒå…±äº«ä»»åŠ¡çš„æ–¹æ³•ï¼Œç”Ÿæˆå¤šæ¨¡æ€å¯¹è¯ï¼Œå¹¶å°†å…¶ä½œä¸ºåŸºäºå›¾åƒçš„å¯¹è¯ä»»åŠ¡è¿›è¡Œè¯„ä¼°ã€‚</p>
<p>åœ¨<strong>åˆæˆè¯„ä¼°åŸºå‡†</strong>æ–¹é¢ï¼Œç”±äºç¼ºä¹å¤§é‡äººå·¥ç”Ÿæˆçš„æ•°æ®ï¼Œä¸”å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆè´¨é‡æ¥è¿‘äººç±»æ°´å¹³ï¼Œç ”ç©¶è€…å¼€å§‹é‡‡ç”¨LLMè¿›è¡Œæ•°æ®åˆæˆã€‚å·²æœ‰å·¥ä½œåˆ©ç”¨LLMç”Ÿæˆå¤§è§„æ¨¡å¯¹è¯æ•°æ®ï¼Œç”¨äºè¯„ä¼°æ—¥å¸¸ç¤¾äº¤äº’åŠ¨ã€å¤šæ¨¡æ€ç¯å¢ƒä¸‹çš„å›åº”ä»¥åŠç¬¦åˆç‰¹å®šäººç‰©è®¾å®šçš„å›åº”ã€‚ä½œè€…ä¹Ÿé‡‡ç”¨LLMç”Ÿæˆæ•°æ®ï¼Œä½†é€šè¿‡äººå·¥éªŒè¯å’Œç¼–è¾‘æ¥ç¡®ä¿æ•°æ®çš„é«˜è´¨é‡ã€‚</p>
<p>æ€»ä¹‹ï¼Œæœ¬ç« æ€»ç»“äº†ç°æœ‰ç ”ç©¶åœ¨é•¿æœŸå¯¹è¯ã€å¤šæ¨¡æ€å¯¹è¯å’Œåˆæˆè¯„ä¼°æ–¹é¢çš„è¿›å±•ä¸ä¸è¶³ï¼Œå¹¶ä¸ºåç»­ç ”ç©¶æä¾›äº†æ–¹æ³•åŸºç¡€å’Œè¯„ä¼°æ€è·¯ã€‚</p>
</section>
<section id="generative-pipeline-for-locomo">
<h2>3 Generative Pipeline for LoCoMo<a class="headerlink" href="#generative-pipeline-for-locomo" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p>è¿™ä¸€ç« èŠ‚ä»‹ç»äº† LoCoMo çš„ç”Ÿæˆç®¡é“ï¼ˆgenerative pipelineï¼‰ï¼Œæ—¨åœ¨æ„å»ºå…·æœ‰é•¿æœŸå¯¹è¯è®°å¿†çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è™šæ‹Ÿä»£ç†ã€‚ä¸»è¦å†…å®¹æ€»ç»“å¦‚ä¸‹ï¼š</p>
<hr class="docutils" />
<section id="locomo">
<h3><strong>3. LoCoMo çš„ç”Ÿæˆç®¡é“æ¦‚è¿°</strong><a class="headerlink" href="#locomo" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>LoCoMo çš„ç”Ÿæˆç®¡é“ç”±ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ç»„æˆï¼š<strong>è™šæ‹Ÿä»£ç†çš„æ¶æ„</strong>å’Œ<strong>äººç±»éªŒè¯ä¸ç¼–è¾‘</strong>ã€‚æ•´ä¸ªæµç¨‹çš„ç›®æ ‡æ˜¯ç”Ÿæˆå…·æœ‰é•¿æœŸä¸€è‡´æ€§ã€å¤šæ¨¡æ€äº¤äº’èƒ½åŠ›çš„è™šæ‹Ÿå¯¹è¯å†…å®¹ã€‚å…·ä½“åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š</p>
<ol class="arabic simple">
<li><p><strong>è™šæ‹Ÿä»£ç†çš„æ„å»º</strong>ï¼šä¸ºä¸¤ä¸ªä»£ç†ï¼ˆâ„’â‚ å’Œ â„’â‚‚ï¼‰åˆ†é…ç‹¬ç‰¹çš„è§’è‰²ï¼ˆpersonaï¼‰å’Œæ—¶é—´äº‹ä»¶å›¾ï¼ˆtemporal event graphï¼‰ï¼Œå¹¶èµ‹äºˆè®°å¿†ä¸åæ€æ¨¡å—ï¼Œä»¥æ”¯æŒé•¿æœŸå¯¹è¯è®°å¿†å’Œå¤šæ¨¡æ€äº¤äº’ï¼ˆå¦‚å›¾åƒåˆ†äº«ä¸ååº”ï¼‰ã€‚</p></li>
<li><p><strong>å¯¹è¯ç”Ÿæˆä¸ç¼–è¾‘</strong>ï¼šé€šè¿‡äººç±»æ ‡æ³¨è€…å¯¹ç”Ÿæˆçš„å¯¹è¯è¿›è¡Œç­›é€‰å’Œä¿®æ”¹ï¼Œä»¥ç¡®ä¿é•¿æœŸä¸€è‡´æ€§å’Œå†…å®¹è´¨é‡ã€‚</p></li>
</ol>
</section>
<hr class="docutils" />
<section id="persona">
<h3><strong>3.1 è§’è‰²è®¾å®šï¼ˆPersonaï¼‰</strong><a class="headerlink" href="#persona" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p>æ¯ä¸ªä»£ç†è¢«èµ‹äºˆä¸€ä¸ªè¯¦ç»†çš„<strong>è§’è‰²è®¾å®š</strong>ï¼ŒåŒ…æ‹¬ç›®æ ‡ã€ç»å†ã€æ—¥å¸¸ä¹ æƒ¯ã€äººé™…å…³ç³»ç­‰ä¿¡æ¯ã€‚</p></li>
<li><p>åˆå§‹è§’è‰²è®¾å®šä» MSC æ•°æ®é›†ä¸­é€‰å–ï¼Œéšåé€šè¿‡ GPT-3.5 æ‰©å±•ä¸ºå®Œæ•´çš„è§’è‰²èƒŒæ™¯ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="temporal-event-graph">
<h3><strong>3.2 æ—¶é—´äº‹ä»¶å›¾ï¼ˆTemporal Event Graphï¼‰</strong><a class="headerlink" href="#temporal-event-graph" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p>ä¸ºæ¯ä¸ªä»£ç†æ„å»ºä¸€ä¸ª<strong>æ—¶é—´äº‹ä»¶å›¾ ğ’¢</strong>ï¼Œåæ˜ å…¶ç°å®ç”Ÿæ´»ä¸­çš„å› æœäº‹ä»¶åºåˆ—ã€‚</p></li>
<li><p>äº‹ä»¶ä¹‹é—´å…·æœ‰å› æœå…³ç³»ï¼Œå¹¶åˆ†å¸ƒåœ¨ 6 åˆ° 12 ä¸ªæœˆçš„æ—¶é—´è·¨åº¦å†…ã€‚</p></li>
<li><p>äº‹ä»¶ç”Ÿæˆé‡‡ç”¨åˆ†æ‰¹æ¬¡è¿­ä»£æ–¹å¼ï¼Œä»¥å¹³è¡¡æ¨ç†æ•ˆç‡å’Œäº‹ä»¶è¿è´¯æ€§ã€‚</p></li>
<li><p>æ¯ä¸ªä»£ç†çš„æ—¶é—´å›¾åŒ…å«æœ€å¤š 25 ä¸ªäº‹ä»¶ï¼Œç¡®ä¿å¯¹è¯ä¸­èƒ½è‡ªç„¶å¼•å…¥é•¿æœŸè®°å¿†ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="id2">
<h3><strong>3.3 è™šæ‹Ÿä»£ç†æ¶æ„</strong><a class="headerlink" href="#id2" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>è™šæ‹Ÿä»£ç†åŸºäº Park ç­‰äººï¼ˆ2023ï¼‰æå‡ºçš„æ¶æ„ï¼ŒåŒ…å«ä»¥ä¸‹ä¸¤ä¸ªä¸»è¦åŠŸèƒ½æ¨¡å—ï¼š</p>
<section id="reflect-respond">
<h4><strong>1. åæ€ä¸å›åº”ï¼ˆReflect &amp; Respondï¼‰</strong><a class="headerlink" href="#reflect-respond" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p>ä»£ç†ç»“åˆ<strong>çŸ­æœŸè®°å¿†</strong>ï¼ˆä¼šè®®æ‘˜è¦ï¼‰å’Œ<strong>é•¿æœŸè®°å¿†</strong>ï¼ˆè¿‡å¾€å¯¹è¯è§‚å¯Ÿï¼‰æ¥ç”Ÿæˆå›åº”ã€‚</p></li>
<li><p>æ¯æ¬¡ä¼šè®®åç”Ÿæˆæ‘˜è¦ï¼Œå­˜å‚¨åœ¨çŸ­æœŸè®°å¿†ä¸­ï¼Œç”¨äºåç»­å¯¹è¯å‚è€ƒã€‚</p></li>
<li><p>æ¯ä¸ªå¯¹è¯å›åˆè¢«è®°å½•ä¸ºé•¿æœŸè®°å¿†ä¸­çš„è§‚å¯Ÿï¼Œç”¨äºæœªæ¥å¯¹è¯çš„åæ€ã€‚</p></li>
<li><p>ä»£ç†åœ¨ç”Ÿæˆå›åº”æ—¶ï¼Œè¿˜ä¼šè€ƒè™‘æ—¶é—´äº‹ä»¶å›¾ä¸­å‘ç”Ÿåœ¨ä¸Šä¸€æ¬¡ä¼šè®®å’Œå½“å‰ä¼šè®®ä¹‹é—´çš„äº‹ä»¶ã€‚</p></li>
</ul>
</section>
<section id="image-sharing-image-reaction">
<h4><strong>2. å›¾åƒåˆ†äº«ä¸å›¾åƒååº”ï¼ˆImage Sharing &amp; Image Reactionï¼‰</strong><a class="headerlink" href="#image-sharing-image-reaction" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p>ä»£ç†æ”¯æŒ<strong>å›¾åƒåˆ†äº«</strong>å’Œ<strong>å›¾åƒååº”</strong>ï¼Œå¢å¼ºå¯¹è¯çš„å¤šæ¨¡æ€æ€§ã€‚</p></li>
<li><p><strong>å›¾åƒåˆ†äº«</strong>æµç¨‹åŒ…æ‹¬ï¼šç”Ÿæˆå›¾åƒæè¿° â†’ æå–å…³é”®è¯ â†’ é€šè¿‡å…³é”®è¯æœç´¢å›¾åƒ â†’ åˆ†äº«å›¾åƒã€‚</p></li>
<li><p><strong>å›¾åƒååº”</strong>æµç¨‹åŒ…æ‹¬ï¼šç”Ÿæˆå›¾åƒæè¿° â†’ å¯¹å›¾åƒç”Ÿæˆå›åº”ã€‚</p></li>
<li><p>å›¾åƒåŠæè¿°ä¹Ÿä¼šè¢«å­˜å‚¨åˆ°é•¿æœŸè®°å¿†ä¸­ï¼Œä¾›æœªæ¥å¯¹è¯ä½¿ç”¨ã€‚</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="human-verification-editing">
<h3><strong>3.4 äººç±»éªŒè¯ä¸ç¼–è¾‘ï¼ˆHuman Verification &amp; Editingï¼‰</strong><a class="headerlink" href="#human-verification-editing" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p>äººç±»æ ‡æ³¨è€…å¯¹ç”Ÿæˆçš„å¯¹è¯è¿›è¡ŒåæœŸå¤„ç†ï¼ŒåŒ…æ‹¬ï¼š</p>
<ol class="arabic simple">
<li><p>ä¿®æ­£å¯¹è¯ä¸­çš„é•¿æœŸä¸ä¸€è‡´é—®é¢˜ï¼›</p></li>
<li><p>åˆ é™¤æˆ–æ›¿æ¢ä¸ç›¸å…³çš„å›¾åƒï¼›</p></li>
<li><p>æ£€æŸ¥å¯¹è¯å†…å®¹ä¸æ—¶é—´äº‹ä»¶å›¾ä¹‹é—´çš„å¯¹é½æ€§ã€‚</p></li>
</ol>
</li>
<li><p>æ ‡æ³¨è€…å¹³å‡ç¼–è¾‘äº†çº¦ 15% çš„å¯¹è¯å›åˆï¼Œå¹¶æ›¿æ¢äº†çº¦ 19% çš„å›¾åƒã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="id3">
<h3><strong>æ€»ç»“</strong><a class="headerlink" href="#id3" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>æœ¬ç« èŠ‚è¯¦ç»†ä»‹ç»äº† LoCoMo ç³»ç»Ÿçš„ç”Ÿæˆæµç¨‹ï¼Œé€šè¿‡ç»“åˆè§’è‰²è®¾å®šã€æ—¶é—´äº‹ä»¶å›¾ã€å¤šæ¨¡æ€äº¤äº’å’Œäººç±»ç¼–è¾‘ï¼Œæ„å»ºäº†ä¸€ä¸ªèƒ½å¤Ÿè¿›è¡Œé•¿æœŸè¿è´¯å¯¹è¯çš„è™šæ‹Ÿä»£ç†ç³»ç»Ÿã€‚è¯¥æµç¨‹ä¸ä»…æå‡äº†å¯¹è¯çš„è‡ªç„¶æ€§å’Œä¸€è‡´æ€§ï¼Œè¿˜å¼•å…¥äº†å›¾åƒäº¤äº’ï¼Œä½¿ç³»ç»Ÿæ›´åŠ è´´è¿‘çœŸå®çš„äººé™…äº¤æµä½“éªŒã€‚</p>
</section>
</section>
<section id="locomo-evaluation-benchmark">
<h2>4 LoCoMo Evaluation Benchmark<a class="headerlink" href="#locomo-evaluation-benchmark" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p>æœ¬ç« èŠ‚ä»‹ç»äº† <strong>LoCoMo è¯„ä¼°åŸºå‡†ï¼ˆLoCoMo Evaluation Benchmarkï¼‰</strong>ï¼Œæ—¨åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨<strong>é•¿æœŸå¯¹è¯è®°å¿†</strong>æ–¹é¢çš„è¡¨ç°ã€‚è¯¥åŸºå‡†åŒ…å«ä¸‰ä¸ªä¸»è¦ä»»åŠ¡ï¼Œåˆ†åˆ«ä»ä¸åŒè§’åº¦æµ‹è¯•å¯¹è¯ä»£ç†åœ¨é•¿æœŸå¯¹è¯ä¸­çš„è®°å¿†èƒ½åŠ›ä¸ä¿¡æ¯å¤„ç†èƒ½åŠ›ï¼š</p>
<hr class="docutils" />
<section id="question-answering-task">
<h3>1. é—®ç­”ä»»åŠ¡ï¼ˆQuestion Answering Taskï¼‰<a class="headerlink" href="#question-answering-task" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>è¯¥ä»»åŠ¡è¯„ä¼°ä»£ç†èƒ½å¦ä»<strong>é•¿æœŸå†å²å¯¹è¯ä¸­æå–ä¿¡æ¯</strong>æ¥å›ç­”é—®é¢˜ã€‚ä»»åŠ¡åˆ†ä¸ºäº”ç±»ï¼š</p>
<ul class="simple">
<li><p><strong>å•è·³é—®é¢˜ï¼ˆSingle-hopï¼‰</strong>ï¼šç­”æ¡ˆä»…ä¾èµ–å•ä¸ªå¯¹è¯ä¼šè¯ï¼›</p></li>
<li><p><strong>å¤šè·³é—®é¢˜ï¼ˆMulti-hopï¼‰</strong>ï¼šéœ€è¦ç»¼åˆå¤šä¸ªä¼šè¯çš„ä¿¡æ¯ï¼›</p></li>
<li><p><strong>æ—¶åºæ¨ç†é—®é¢˜ï¼ˆTemporal reasoningï¼‰</strong>ï¼šéœ€è¦ç†è§£æ—¶é—´é¡ºåºå’Œæ—¶é—´çº¿ç´¢ï¼›</p></li>
<li><p><strong>å¼€æ”¾é¢†åŸŸçŸ¥è¯†é—®é¢˜ï¼ˆOpen-domain knowledgeï¼‰</strong>ï¼šç»“åˆå¯¹è¯ä¿¡æ¯ä¸å¸¸è¯†/ä¸–ç•ŒçŸ¥è¯†ï¼›</p></li>
<li><p><strong>å¯¹æŠ—æ€§é—®é¢˜ï¼ˆAdversarial questionsï¼‰</strong>ï¼šæµ‹è¯•ä»£ç†è¯†åˆ«æ— æ³•å›ç­”çš„é—®é¢˜çš„èƒ½åŠ›ã€‚</p></li>
</ul>
<p>è¯„ä¼°æ–¹å¼ä¸ºä½¿ç”¨ <strong>F1 éƒ¨åˆ†åŒ¹é…</strong>ï¼Œå¹¶å°½é‡ç¡®ä¿ç­”æ¡ˆç›´æ¥æ¥è‡ªå¯¹è¯ï¼Œä»¥ç®€åŒ–è¯„ä¼°ã€‚åŒæ—¶æ ‡æ³¨ç­”æ¡ˆæ‰€åœ¨çš„å¯¹è¯è½®æ¬¡ IDï¼Œå¹¶è¯„ä¼° RAG æ¨¡å‹çš„ä¸Šä¸‹æ–‡æ£€ç´¢å‡†ç¡®æ€§ã€‚</p>
</section>
<hr class="docutils" />
<section id="event-summarization-task">
<h3>2. äº‹ä»¶æ€»ç»“ä»»åŠ¡ï¼ˆEvent Summarization Taskï¼‰<a class="headerlink" href="#event-summarization-task" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>è¯¥ä»»åŠ¡æµ‹è¯•ä»£ç†å¯¹<strong>äº‹ä»¶åºåˆ—åŠå…¶å› æœå…³ç³»çš„ç†è§£èƒ½åŠ›</strong>ã€‚å¯¹è¯æ„å»ºåŸºäºä¸€ä¸ªæ—¶é—´äº‹ä»¶å›¾è°± ğ’¢ï¼Œä»£ç†éœ€æ ¹æ®æ‰€ç»™æ—¶é—´èŒƒå›´å¯¹äº‹ä»¶è¿›è¡Œæ€»ç»“ï¼Œå¹¶ä¸å›¾è°±ä¸­çš„äº‹ä»¶å¯¹æ¯”ã€‚</p>
<p>ç”±äºå¯¹è¯ä¸­å­˜åœ¨æ—¶é—´ä¸å› æœçš„å¼•ç”¨å…³ç³»ï¼Œäº‹ä»¶æ€»ç»“æ¯”ä¼ ç»Ÿæ–‡æœ¬æ›´å¤æ‚ã€‚è¯„ä¼°ä½¿ç”¨ <strong>FactScore æŒ‡æ ‡</strong>ï¼Œå°†æ€»ç»“å†…å®¹ä¸å‚è€ƒäº‹ä»¶å›¾è°±åˆ†è§£ä¸ºåŸå­äº‹å®ï¼Œè¯„ä¼°ï¼š</p>
<ul class="simple">
<li><p><strong>ç²¾ç¡®ç‡ï¼ˆPrecisionï¼‰</strong>ï¼šæ€»ç»“ä¸­çš„äº‹å®ä¸å‚è€ƒäº‹å®çš„åŒ¹é…æ•°é‡ï¼›</p></li>
<li><p><strong>å¬å›ç‡ï¼ˆRecallï¼‰</strong>ï¼šå‚è€ƒäº‹å®åœ¨æ€»ç»“ä¸­çš„è¦†ç›–ç‡ï¼›</p></li>
<li><p><strong>F1 åˆ†æ•°</strong>ï¼šç»¼åˆç²¾ç¡®ç‡å’Œå¬å›ç‡ã€‚</p></li>
</ul>
<p>è¿™ä¸å…¶ä»–ä¼ ç»Ÿæ‘˜è¦è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚ BLEUã€ROUGEï¼‰ä¸åŒï¼Œæ›´åŠ å…³æ³¨<strong>äº‹å®å‡†ç¡®æ€§</strong>ã€‚</p>
</section>
<hr class="docutils" />
<section id="multi-modal-dialogue-generation-task">
<h3>3. å¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆä»»åŠ¡ï¼ˆMulti-Modal Dialogue Generation Taskï¼‰<a class="headerlink" href="#multi-modal-dialogue-generation-task" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>è¯¥ä»»åŠ¡è¯„ä¼°ä»£ç†èƒ½å¦åœ¨é•¿æœŸå¯¹è¯ä¸­<strong>ä¿æŒè§’è‰²ä¸€è‡´æ€§</strong>ä¸<strong>æƒ…èŠ‚è¿è´¯æ€§</strong>ã€‚å¯¹è¯è¯é¢˜éšæ—¶é—´æ¨è¿›ï¼Œæ¶‰åŠè§’è‰²çš„äº‹ä»¶å˜åŒ–ï¼ˆå¦‚å—ä¼¤ååº·å¤ç­‰ï¼‰ï¼Œä»£ç†éœ€åœ¨ç”Ÿæˆå¯¹è¯æ—¶ä¸è®¾å®šçš„äº‹ä»¶å›¾è°±å’Œè§’è‰²è®¾å®šä¿æŒä¸€è‡´ã€‚</p>
<p>è¯„ä¼°æ–¹å¼åŒ…æ‹¬ï¼š</p>
<ul class="simple">
<li><p><strong>MMRelevance</strong>ï¼šè¡¡é‡ç”Ÿæˆå¯¹è¯ä¸çœŸå®å¯¹è¯çš„å¤šæ¨¡æ€ç›¸å…³æ€§ï¼›</p></li>
<li><p>å…¶ä»–è‡ªç„¶è¯­è¨€ç”Ÿæˆï¼ˆNLGï¼‰æŒ‡æ ‡ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="id4">
<h3>æ€»ç»“<a class="headerlink" href="#id4" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>LoCoMo è¯„ä¼°åŸºå‡†é€šè¿‡ä¸‰ä¸ªä»»åŠ¡ï¼ˆé—®ç­”ã€äº‹ä»¶æ€»ç»“ã€å¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆï¼‰å…¨é¢æµ‹è¯•äº† LLM ä»£ç†åœ¨é•¿æœŸå¯¹è¯ä¸­å¯¹è®°å¿†çš„å­˜å‚¨ã€æ£€ç´¢ã€æ¨ç†ä¸ç”Ÿæˆèƒ½åŠ›ã€‚è¯„ä¼°è®¾è®¡æ³¨é‡<strong>äº‹å®å‡†ç¡®æ€§</strong>ä¸<strong>é•¿æœŸä¸€è‡´æ€§</strong>ï¼Œå¹¶ç»“åˆå¤šç§è¯„ä¼°æŒ‡æ ‡ï¼ŒåŠ›æ±‚å®¢è§‚è¡¡é‡ä»£ç†çš„é•¿æœŸè®°å¿†è¡¨ç°ã€‚</p>
</section>
</section>
<section id="experimental-setup">
<h2>5 Experimental Setup<a class="headerlink" href="#experimental-setup" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p>æœ¬ç« èŠ‚ä¸»è¦ä»‹ç»å®éªŒè®¾ç½®å’Œä¸åŒæ¨¡å‹åœ¨é—®ç­”ã€äº‹ä»¶æ‘˜è¦å’Œå¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå…·ä½“æ€»ç»“å¦‚ä¸‹ï¼š</p>
<hr class="docutils" />
<section id="id5">
<h3><strong>1. å®éªŒè®¾ç½®æ¦‚è¿°</strong><a class="headerlink" href="#id5" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p><strong>ä»»åŠ¡ç±»å‹</strong>ï¼šå®éªŒåŒ…å«ä¸‰ä¸ªä»»åŠ¡ï¼š<strong>é—®ç­”</strong>ï¼ˆQuestion Answeringï¼‰ã€<strong>äº‹ä»¶æ‘˜è¦ç”Ÿæˆ</strong>ï¼ˆEvent Summarizationï¼‰å’Œ<strong>å¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆ</strong>ï¼ˆMulti-modal Dialogue Generationï¼‰ã€‚</p></li>
<li><p><strong>å›¾åƒå¤„ç†æ–¹å¼</strong>ï¼š</p>
<ul>
<li><p>åœ¨é—®ç­”å’Œäº‹ä»¶æ‘˜è¦ä»»åŠ¡ä¸­ï¼Œå›¾åƒè¢«æ›¿æ¢ä¸ºå…¶<strong>æè¿°æ–‡å­—ï¼ˆcaptionsï¼‰</strong>ï¼Œæ¨¡å‹ä»…åŸºäº<strong>çº¯æ–‡æœ¬å¯¹è¯</strong>è¿›è¡Œæ¨ç†ã€‚</p></li>
<li><p><strong>å¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆä»»åŠ¡</strong>ä¸­<strong>ç›´æ¥ä½¿ç”¨å›¾åƒ</strong>è¾“å…¥ã€‚</p></li>
</ul>
</li>
<li><p><strong>æ¨¡å‹ç±»å‹</strong>ï¼š</p>
<ul>
<li><p>è¯„ä¼°äº†ä¸‰ç§æ¨¡å‹ç±»å‹ï¼š</p>
<ol class="arabic simple">
<li><p><strong>åŸºç¡€æ¨¡å‹</strong>ï¼ˆBase LLMsï¼‰ï¼šå¦‚ Mistral-7Bã€Llama-70B-chatã€GPT-3.5-turbo å’Œ GPT-4-turboã€‚</p></li>
<li><p><strong>é•¿ä¸Šä¸‹æ–‡æ¨¡å‹</strong>ï¼ˆLong-context LLMsï¼‰ï¼šå¦‚ GPT-3.5-turbo-16kã€‚</p></li>
<li><p><strong>æ£€ç´¢å¢å¼ºç”Ÿæˆæ¨¡å‹</strong>ï¼ˆRAGï¼‰ï¼šç»“åˆ DRAGON æ£€ç´¢å™¨å’Œ GPT-3.5-turbo-16k ä½œä¸ºé˜…è¯»å™¨ï¼Œä»å¯¹è¯å†å²æˆ–æ‘˜è¦ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ã€‚</p></li>
</ol>
</li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="question-answering">
<h3><strong>2. é—®ç­”ä»»åŠ¡ï¼ˆQuestion Answeringï¼‰</strong><a class="headerlink" href="#question-answering" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p><strong>æ¨¡å‹ç±»å‹</strong>ï¼š</p>
<ul>
<li><p><strong>åŸºç¡€æ¨¡å‹</strong>ï¼šåœ¨é—®ç­”è¡¨ç°ä¸Šè¡¨ç°ä¸€èˆ¬ï¼ŒF1 åˆ†æ•°è¾ƒä½ã€‚</p></li>
<li><p><strong>é•¿ä¸Šä¸‹æ–‡æ¨¡å‹</strong>ï¼šéšç€ä¸Šä¸‹æ–‡é•¿åº¦çš„å¢åŠ ï¼ˆä» 4K åˆ° 16Kï¼‰ï¼Œæ€§èƒ½æ˜¾è‘—æå‡ã€‚ä¾‹å¦‚ï¼ŒGPT-3.5-turbo-16k åœ¨ 16K ä¸Šä¸‹æ–‡æ—¶ï¼Œæ•´ä½“ F1 åˆ†æ•°è¾¾åˆ° <strong>37.8</strong>ã€‚</p></li>
<li><p><strong>RAG æ¨¡å‹</strong>ï¼šé€šè¿‡æ£€ç´¢å¯¹è¯å†å²ã€è§‚å¯Ÿä¿¡æ¯æˆ–æ‘˜è¦æ¥å¢å¼ºä¸Šä¸‹æ–‡ï¼Œä¸åŒæ£€ç´¢å•ä½ï¼ˆdialogã€observationã€summaryï¼‰å’Œ top-k å€¼å¯¹ç»“æœæœ‰å½±å“ã€‚å…¶ä¸­ï¼Œâ€œ<strong>observation</strong>â€åœ¨ä¸åŒ top-k å€¼ä¸‹çš„è¡¨ç°è¾ƒä¼˜ï¼Œæœ€é«˜æ•´ä½“ F1 åˆ†æ•°ä¸º <strong>41.4</strong>ã€‚</p></li>
</ul>
</li>
<li><p><strong>æ€§èƒ½æŒ‡æ ‡</strong>ï¼šä½¿ç”¨ <strong>F1-score</strong> å’Œ <strong>Recall&#64;k</strong>ï¼ˆk ä¸ºæ£€ç´¢æ•°é‡ï¼‰è¯„ä¼°æ¨¡å‹è¡¨ç°ï¼Œ<strong>åˆ†æ•°è¶Šé«˜è¶Šå¥½</strong>ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="event-summarization">
<h3><strong>3. äº‹ä»¶æ‘˜è¦ç”Ÿæˆä»»åŠ¡ï¼ˆEvent Summarizationï¼‰</strong><a class="headerlink" href="#event-summarization" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p><strong>æ¨¡å‹è®¾ç½®</strong>ï¼šä½¿ç”¨é—®ç­”ä»»åŠ¡ä¸­çš„ <strong>åŸºç¡€æ¨¡å‹</strong> å’Œ <strong>é•¿ä¸Šä¸‹æ–‡æ¨¡å‹</strong>ï¼Œä½†<strong>ä¸ä½¿ç”¨ RAG</strong>ï¼Œå› ä¸ºæ‘˜è¦éœ€è¦å¯¹æ•´ä¸ªå¯¹è¯æœ‰å…¨é¢ç†è§£ã€‚</p></li>
<li><p><strong>å®ç°æ–¹å¼</strong>ï¼š</p>
<ul>
<li><p>ä½¿ç”¨ <strong>å¢é‡æ‘˜è¦</strong>ï¼ˆincremental summarizationï¼‰ï¼šæ¯æ¬¡å¯¹å‰ä¸€é˜¶æ®µçš„å¯¹è¯ç”Ÿæˆæ‘˜è¦ï¼Œç„¶åå°†è¯¥æ‘˜è¦ç”¨äºä¸‹ä¸€é˜¶æ®µçš„æ‘˜è¦ç”Ÿæˆã€‚</p></li>
<li><p>å¼•ç”¨æ–‡çŒ®ï¼šChang et al. (2023) çš„æ–¹æ³•ã€‚</p></li>
</ul>
</li>
<li><p><strong>æœªå±•ç¤ºå…·ä½“æŒ‡æ ‡</strong>ï¼Œä½†å¼ºè°ƒäº†æ‘˜è¦ä»»åŠ¡çš„æŒ‘æˆ˜æ€§åœ¨äºéœ€è¦å¯¹é•¿å¯¹è¯æ•´ä½“è¿›è¡Œç†è§£ï¼Œè€Œéå±€éƒ¨æ£€ç´¢ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="multi-modal-dialogue-generation">
<h3><strong>4. å¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆä»»åŠ¡ï¼ˆMulti-modal Dialogue Generationï¼‰</strong><a class="headerlink" href="#multi-modal-dialogue-generation" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p><strong>æ•°æ®ç”Ÿæˆ</strong>ï¼š</p>
<ul>
<li><p>é€šè¿‡è‡ªåŠ¨åŒ–æµç¨‹ç”Ÿæˆ <strong>50 æ¬¡å¯¹è¯</strong>ï¼Œç”¨äºè®­ç»ƒæ•°æ®ï¼ˆæœªè¿›è¡Œäººå·¥ç­›é€‰ï¼‰ã€‚</p></li>
</ul>
</li>
<li><p><strong>æ¨¡å‹è®­ç»ƒ</strong>ï¼š</p>
<ul>
<li><p>ä½¿ç”¨ <strong>MiniGPT-5</strong> è¿›è¡Œè®­ç»ƒï¼Œå…±è®­ç»ƒä¸‰ç§ç‰ˆæœ¬ï¼š</p>
<ol class="arabic simple">
<li><p><strong>Base</strong>ï¼šä»…åŸºäºå…ˆå‰å¯¹è¯ã€‚</p></li>
<li><p><strong>+ summary</strong>ï¼šç»“åˆå…ˆå‰å¯¹è¯å’Œå…¨å±€æ‘˜è¦ã€‚</p></li>
<li><p><strong>+ observation</strong>ï¼šç»“åˆå…ˆå‰å¯¹è¯å’Œä»å¯¹è¯å†å²ä¸­æ£€ç´¢åˆ°çš„è§‚å¯Ÿä¿¡æ¯ã€‚</p></li>
</ol>
</li>
</ul>
</li>
<li><p><strong>åˆå§‹åŒ–æ–¹å¼</strong>ï¼š</p>
<ul>
<li><p>ä½¿ç”¨åœ¨ <strong>MMDialog</strong> ä¸Šå¾®è°ƒçš„ MiniGPT-5 æ£€æŸ¥ç‚¹è¿›è¡Œåˆå§‹åŒ–ã€‚</p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="id6">
<h3><strong>5. æ€»ç»“</strong><a class="headerlink" href="#id6" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p>æœ¬å®éªŒæ¯”è¾ƒäº†å¤šç§æ¨¡å‹åœ¨é•¿å¯¹è¯ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼š</p>
<ul>
<li><p><strong>åŸºç¡€æ¨¡å‹</strong>å—é™äºä¸Šä¸‹æ–‡é•¿åº¦ï¼Œæ€§èƒ½è¾ƒä½ã€‚</p></li>
<li><p><strong>é•¿ä¸Šä¸‹æ–‡æ¨¡å‹</strong>éšç€ä¸Šä¸‹æ–‡å¢åŠ ï¼Œè¡¨ç°æ˜¾è‘—æå‡ã€‚</p></li>
<li><p><strong>RAG æ¨¡å‹</strong>é€šè¿‡å¼•å…¥æ£€ç´¢æœºåˆ¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡é—®ç­”æ€§èƒ½ã€‚</p></li>
</ul>
</li>
<li><p><strong>äº‹ä»¶æ‘˜è¦</strong>éœ€è¦æ¨¡å‹å¯¹æ•´ä½“å¯¹è¯æœ‰å…¨é¢ç†è§£ï¼Œå› æ­¤æœªä½¿ç”¨ RAGï¼Œè€Œæ˜¯é‡‡ç”¨å¢é‡æ‘˜è¦æ–¹æ³•ã€‚</p></li>
<li><p><strong>å¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆ</strong>ä½¿ç”¨å›¾åƒå’Œæ–‡æœ¬ç»“åˆï¼Œè®­ç»ƒæ—¶å¼•å…¥æ‘˜è¦å’Œè§‚å¯Ÿä¿¡æ¯ï¼Œä»¥æå‡æ¨¡å‹å¯¹ä¸Šä¸‹æ–‡çš„ç†è§£èƒ½åŠ›ã€‚</p></li>
</ul>
</section>
</section>
<section id="experimental-results">
<h2>6 Experimental Results<a class="headerlink" href="#experimental-results" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p>æœ¬ç« æ€»ç»“äº†å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨<strong>é•¿å¯¹è¯è®°å¿†è¯„ä¼°ä»»åŠ¡</strong>ä¸­çš„å®éªŒç»“æœï¼Œæ¶µç›–<strong>é—®ç­”ä»»åŠ¡</strong>ã€<strong>äº‹ä»¶å›¾æ€»ç»“ä»»åŠ¡</strong>å’Œ<strong>å¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆä»»åŠ¡</strong>ã€‚ä»¥ä¸‹æ˜¯å¯¹å„éƒ¨åˆ†çš„æ€»ç»“ï¼š</p>
<hr class="docutils" />
<section id="id7">
<h3>6.1 é—®ç­”ä»»åŠ¡ï¼ˆQuestion Answering Taskï¼‰<a class="headerlink" href="#id7" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p><strong>ä¸»è¦å‘ç°</strong>ï¼š</p>
<ol class="arabic simple">
<li><p><strong>ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶å½±å“æ¨¡å‹è¡¨ç°</strong>ï¼š</p>
<ul class="simple">
<li><p>æ‹¥æœ‰æœ‰é™ä¸Šä¸‹æ–‡çª—å£çš„LLMï¼ˆå¦‚GPT-4-turboï¼‰åœ¨å¤„ç†æé•¿å¯¹è¯æ—¶è¡¨ç°ä¸ä½³ï¼Œå°½ç®¡å®ƒæ˜¯è¡¨ç°æœ€å¥½çš„æ¨¡å‹ï¼ˆå¾—åˆ†32.4ï¼‰ï¼Œä½†ä»è¿œä½äºäººç±»åŸºå‡†ï¼ˆ87.9ï¼‰ã€‚</p></li>
</ul>
</li>
<li><p><strong>é•¿ä¸Šä¸‹æ–‡æ¨¡å‹å®¹æ˜“äº§ç”Ÿå¹»è§‰ï¼ˆHallucinationsï¼‰</strong>ï¼š</p>
<ul class="simple">
<li><p>GPT-3.5-turbo-16Kï¼ˆ16Kä¸Šä¸‹æ–‡ï¼‰åœ¨å¯¹æŠ—æ€§é—®é¢˜ä¸Šçš„å‡†ç¡®ç‡ä½è‡³2.1%ï¼Œè¿œä½äºLlama-2-Chatï¼ˆ22.1%ï¼‰å’ŒGPT-4-turboï¼ˆ70.2%ï¼‰ï¼Œè¡¨æ˜é•¿ä¸Šä¸‹æ–‡æ¨¡å‹å®¹æ˜“å—è¯¯å¯¼ç”Ÿæˆé”™è¯¯ä¿¡æ¯ã€‚</p></li>
</ul>
</li>
<li><p><strong>RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰çš„æœ‰æ•ˆæ€§ä¸æŒ‘æˆ˜</strong>ï¼š</p>
<ul class="simple">
<li><p>å°†å¯¹è¯ä½œä¸ºè§‚å¯Ÿè®°å½•å¹¶è¿›è¡Œæ£€ç´¢ï¼Œèƒ½æé«˜æ¨¡å‹è¡¨ç°ï¼ˆå¦‚GPT-3.5-turboä½¿ç”¨Top 5è§‚å¯Ÿè®°å½•æ—¶æå‡5%ï¼‰ã€‚</p></li>
<li><p>ä½†æ£€ç´¢å†…å®¹è¿‡å¤šæˆ–å™ªéŸ³è¿‡é«˜ä¼šé™ä½æ•ˆæœã€‚</p></li>
<li><p>ä½¿ç”¨ä¼šè¯æ‘˜è¦ä½œä¸ºä¸Šä¸‹æ–‡æœªèƒ½æ˜¾è‘—æå‡æ€§èƒ½ï¼Œå¯èƒ½æ˜¯å› ä¸ºä¿¡æ¯ä¸¢å¤±ã€‚</p></li>
</ul>
</li>
</ol>
<p><strong>éš¾ç‚¹åˆ†æ</strong>ï¼š</p>
<ul class="simple">
<li><p><strong>æ—¶é—´æ¨ç†é—®é¢˜</strong>ï¼šLLMéš¾ä»¥æ­£ç¡®ç†è§£å¯¹è¯ä¸­çš„æ—¶é—´æ¦‚å¿µï¼Œç±»ä¼¼é—®é¢˜ä¹Ÿå­˜åœ¨äºå…¶ä»–æ—¶é—´æ¨ç†åŸºå‡†ä¸­ã€‚</p></li>
<li><p><strong>å¼€æ”¾åŸŸçŸ¥è¯†é—®é¢˜</strong>ï¼šLLMåœ¨å¼€æ”¾åŸŸçŸ¥è¯†ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œå¼•å…¥ä¸å‡†ç¡®çš„æ£€ç´¢å†…å®¹åè€Œä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="id8">
<h3>6.2 äº‹ä»¶å›¾æ€»ç»“ä»»åŠ¡ï¼ˆEvent Summarization Taskï¼‰<a class="headerlink" href="#id8" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p><strong>ä¸»è¦å‘ç°</strong>ï¼š</p>
<ol class="arabic simple">
<li><p><strong>å¢é‡æ€»ç»“è¡¨ç°æœ€ä½³</strong>ï¼š</p>
<ul class="simple">
<li><p>GPT-3.5-turboåœ¨å¬å›ç‡å’ŒF1åˆ†æ•°ä¸Šè¡¨ç°æœ€å¥½ï¼Œå°½ç®¡GPT-4-turboåœ¨ç²¾ç¡®åº¦ä¸Šæœ‰5.3%çš„æå‡ï¼Œä½†å¬å›ç‡è¾ƒä½ã€‚</p></li>
<li><p>è¯¥ä»»åŠ¡éœ€è¦æ¨¡å‹ç†è§£äº‹ä»¶é—´çš„<strong>æ—¶é—´ä¾èµ–</strong>å’Œ<strong>å› æœå…³ç³»</strong>ï¼ˆè§å›¾7ï¼‰ã€‚</p></li>
</ul>
</li>
<li><p><strong>é•¿ä¸Šä¸‹æ–‡æ¨¡å‹æœªå¿…æ›´ä¼˜</strong>ï¼š</p>
<ul class="simple">
<li><p>GPT-3.5-turbo-16Kï¼ˆ16Kä¸Šä¸‹æ–‡ï¼‰åœ¨ç²¾ç¡®åº¦å’Œå¬å›ç‡ä¸Šå‡ä½äºGPT-3.5-turboï¼ˆ4Kä¸Šä¸‹æ–‡ï¼‰ï¼Œè¡¨æ˜é•¿ä¸Šä¸‹æ–‡æ¨¡å‹æœªå¿…èƒ½æ›´å¥½åœ°åˆ©ç”¨å…¶ä¸Šä¸‹æ–‡ã€‚</p></li>
<li><p>è¿™ä¸é—®ç­”ä»»åŠ¡ä¸­çš„å‘ç°ä¸€è‡´ï¼Œè¯´æ˜æ¨¡å‹å¯èƒ½å¹¶æœªæœ‰æ•ˆåˆ©ç”¨æ›´é•¿çš„ä¸Šä¸‹æ–‡ã€‚</p></li>
</ul>
</li>
<li><p><strong>å•†ä¸šæ¨¡å‹ä¼˜åŠ¿æ˜æ˜¾</strong>ï¼š</p>
<ul class="simple">
<li><p>GPT-4-turboå’ŒGPT-3.5-turboåœ¨ROUGEå’ŒFactScoreæŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºå¼€æºæ¨¡å‹ï¼ˆå¦‚Llama-2-Chatï¼‰ã€‚</p></li>
</ul>
</li>
</ol>
<p><strong>å¸¸è§é”™è¯¯ç±»å‹</strong>ï¼ˆæ‰‹åŠ¨åˆ†æï¼‰ï¼š</p>
<ul class="simple">
<li><p>ç¼ºå¤±å…³é”®ä¿¡æ¯ï¼›</p></li>
<li><p>ç”Ÿæˆä¸å‡†ç¡®æˆ–æ— å…³çš„ç»†èŠ‚ï¼ˆå¹»è§‰ï¼‰ï¼›</p></li>
<li><p>è¯¯è§£å¯¹è¯ä¸­çš„å¹½é»˜æˆ–è®½åˆºï¼›</p></li>
<li><p>è¯´è¯äººå½’å±é”™è¯¯ï¼›</p></li>
<li><p>å°†ä¸é‡è¦çš„å¯¹è¯è¯¯è®¤ä¸ºé‡è¦äº‹ä»¶ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="multi-modal-dialog-generation-task">
<h3>6.3 å¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆä»»åŠ¡ï¼ˆMulti-Modal Dialog Generation Taskï¼‰<a class="headerlink" href="#multi-modal-dialog-generation-task" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p><strong>ä¸»è¦å‘ç°</strong>ï¼š</p>
<ol class="arabic simple">
<li><p><strong>ä¸Šä¸‹æ–‡å¼•å…¥æå‡æ€§èƒ½</strong>ï¼š</p>
<ul class="simple">
<li><p>åœ¨è®­ç»ƒä¸­åŠ å…¥ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¦‚è§‚å¯Ÿè®°å½•ï¼‰èƒ½æ˜¾è‘—æå‡å¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆæ•ˆæœã€‚ä¾‹å¦‚ï¼Œå¼•å…¥è§‚å¯Ÿè®°å½•ä¸­çš„è§†é¢‘æ¸¸æˆæ¯”èµ›ä½“éªŒä¿¡æ¯ï¼Œä½¿ç”Ÿæˆçš„å¯¹è¯å’Œå›¾åƒæ›´è´´åˆè¯´è¯äººçš„äººè®¾ã€‚</p></li>
</ul>
</li>
<li><p><strong>MM-Relevanceåˆ†æ•°éšå¯¹è¯å†å²å¢é•¿è€Œä¸‹é™</strong>ï¼š</p>
<ul class="simple">
<li><p>å¯¹è¯å†å²è¶Šé•¿ï¼ŒMM-Relevanceåˆ†æ•°è¶Šä½ï¼ˆè§å›¾4Bï¼‰ï¼Œè¡¨æ˜æ¨¡å‹éš¾ä»¥å¤„ç†é•¿å¯¹è¯ä¸­çš„å¤šæ¨¡æ€ä¿¡æ¯ã€‚</p></li>
</ul>
</li>
<li><p><strong>RAGç¼“è§£æ€§èƒ½ä¸‹é™</strong>ï¼š</p>
<ul class="simple">
<li><p>æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ–¹æ³•èƒ½åœ¨ä¸€å®šç¨‹åº¦ä¸Šç¼“è§£MM-Relevanceåˆ†æ•°çš„ä¸‹é™è¶‹åŠ¿ï¼Œè¡¨æ˜ç»“åˆæ£€ç´¢ä¿¡æ¯æœ‰åŠ©äºæ¨¡å‹ç”Ÿæˆæ›´ç›¸å…³çš„å†…å®¹ã€‚</p></li>
</ul>
</li>
</ol>
</section>
<hr class="docutils" />
<section id="id9">
<h3>æ€»ä½“ç»“è®º<a class="headerlink" href="#id9" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>æœ¬ç« é€šè¿‡å¯¹ä¸‰ç§ä»»åŠ¡çš„å…¨é¢å®éªŒï¼Œæ­ç¤ºäº†LLMåœ¨<strong>é•¿å¯¹è¯è®°å¿†ä»»åŠ¡</strong>ä¸­çš„å…³é”®æŒ‘æˆ˜ä¸è¡¨ç°å·®å¼‚ï¼š</p>
<ul class="simple">
<li><p><strong>ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶ä¸å¹»è§‰é—®é¢˜</strong>å½±å“æ¨¡å‹åœ¨é—®ç­”å’Œäº‹ä»¶æ€»ç»“ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼›</p></li>
<li><p><strong>RAGæ–¹æ³•</strong>åœ¨ç‰¹å®šè®¾ç½®ä¸‹æœ‰æ•ˆï¼Œä½†å­˜åœ¨å™ªéŸ³å’Œä¿¡æ¯ä¸¢å¤±é—®é¢˜ï¼›</p></li>
<li><p><strong>å¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆ</strong>ä¸­ï¼Œä¸Šä¸‹æ–‡å¼•å…¥å’ŒRAGæ–¹æ³•æœ‰åŠ©äºæå‡ç”Ÿæˆè´¨é‡ï¼›</p></li>
<li><p><strong>æ—¶é—´æ¨ç†</strong>ã€<strong>å¼€æ”¾åŸŸçŸ¥è¯†</strong>å’Œ<strong>å¯¹è¯ç†è§£</strong>ï¼ˆå¹½é»˜ã€è®½åˆºç­‰ï¼‰æ˜¯å½“å‰LLMéš¾ä»¥å…‹æœçš„éš¾ç‚¹ã€‚</p></li>
</ul>
<p>è¿™äº›å‘ç°ä¸ºæ”¹è¿›LLMåœ¨é•¿å¯¹è¯åœºæ™¯ä¸­çš„è¡¨ç°æä¾›äº†æ˜ç¡®æ–¹å‘ã€‚</p>
</section>
</section>
<section id="conclusion">
<h2>7 Conclusion<a class="headerlink" href="#conclusion" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p>æœ¬ç« æ€»ç»“äº†ç ”ç©¶çš„ä¸»è¦æˆæœä¸å‘ç°ã€‚ä½œè€…æ„å»ºäº†ä¸€ä¸ªåä¸ºLoCoMoçš„äººæœºåä½œæ•°æ®é›†ï¼ŒåŒ…å«50æ®µé«˜è´¨é‡çš„è¶…é•¿å¯¹è¯ï¼Œæ¯æ®µå¹³å‡åŒ…å«300è½®å¯¹è¯ã€çº¦9000ä¸ªtokenï¼Œè·¨è¶Šæœ€å¤š35æ¬¡ä¼šè¯ã€‚åŒæ—¶ï¼Œæå‡ºäº†ä¸€å¥—åŒ…å«ä¸‰é¡¹ä»»åŠ¡çš„è¯„ä¼°æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹åœ¨é•¿å¯¹è¯ä¸­çš„è¡¨ç°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå°½ç®¡æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œåœ¨å¤„ç†é•¿å¯¹è¯ä¸­çš„é•¿æœŸå™äº‹ç†è§£ä»¥åŠå¯¹è¯äº‹ä»¶ä¹‹é—´çš„æ—¶é—´å’Œå› æœå…³ç³»æ–¹é¢ä»å­˜åœ¨æ˜¾è‘—å›°éš¾ã€‚</p>
</section>
<section id="limitations">
<h2>8 Limitations<a class="headerlink" href="#limitations" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p>è¯¥ç« èŠ‚æ€»ç»“äº†ç ”ç©¶ä¸­å­˜åœ¨çš„ä¸€äº›<strong>å±€é™æ€§</strong>ï¼Œä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ç‚¹ï¼š</p>
<ol class="arabic simple">
<li><p><strong>æ··åˆäººæœºç”Ÿæˆæ•°æ®</strong>ï¼šæ•°æ®é›†ä¸»è¦æ¥æºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆçš„æ–‡æœ¬ï¼Œå°½ç®¡æœ‰äººç±»æ ‡æ³¨è€…å‚ä¸éªŒè¯å’Œç¼–è¾‘ä»¥å¢å¼ºçœŸå®æ€§ï¼Œä½†è¯¥æ•°æ®é›†å¯èƒ½ä»æ— æ³•å®Œå…¨åæ˜ çœŸå®çš„åœ¨çº¿å¯¹è¯çš„ç»†å¾®å·®å¼‚ã€‚</p></li>
<li><p><strong>å¤šæ¨¡æ€è¡Œä¸ºçš„æ¢ç´¢æœ‰é™</strong>ï¼šæ•°æ®é›†ä¸­çš„å›¾ç‰‡æ¥è‡ªç½‘ç»œï¼Œç¼ºä¹ä¸ªäººç…§ç‰‡ä¸­å¸¸è§çš„è§†è§‰ä¸€è‡´æ€§ï¼ˆå¦‚å¤–è¡¨ã€å®¶åº­ç¯å¢ƒã€å® ç‰©ç­‰ï¼‰ï¼Œå› æ­¤åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œå›¾ç‰‡å¯ä»¥è¢«å…¶æ–‡å­—æè¿°æ›¿ä»£ï¼Œåªæœ‰åœ¨éœ€è¦OCRï¼ˆå…‰å­¦å­—ç¬¦è¯†åˆ«ï¼‰çš„åœºæ™¯ä¸‹æ‰ä¾‹å¤–ã€‚</p></li>
<li><p><strong>è¯­è¨€é™åˆ¶</strong>ï¼šç›®å‰çš„ç”Ÿæˆå¯¹è¯æµç¨‹ä»…æ”¯æŒè‹±è¯­ï¼Œä½†ç†è®ºä¸Šå¯ä»¥é€šè¿‡ä½¿ç”¨æŒæ¡å…¶ä»–è¯­è¨€çš„LLMå’Œç›¸åº”ç¿»è¯‘æ¥æ‰©å±•è¯­è¨€æ”¯æŒã€‚</p></li>
<li><p><strong>ä¾èµ–é—­æºLLM</strong>ï¼šåœ¨ç”Ÿæˆå¯¹è¯æ•°æ®æ—¶ä½¿ç”¨äº†æœ€å…ˆè¿›çš„å•†ä¸šé—­æºLLMï¼Œè™½ç„¶èƒ½å¤Ÿç”Ÿæˆæ›´çœŸå®çš„å¯¹è¯ï¼Œä½†è¿™ä¹Ÿé™åˆ¶äº†å¯å¤ç°æ€§å’Œå¼€æºæ€§ã€‚ç ”ç©¶è€…è®¡åˆ’å…¬å¼€ä»£ç ï¼Œä»¥ä¾¿æœªæ¥ä¸å¼€æºLLMç»“åˆä½¿ç”¨ã€‚</p></li>
<li><p><strong>é•¿æ–‡æœ¬ç”Ÿæˆçš„è¯„ä¼°æŒ‘æˆ˜</strong>ï¼šLLMå€¾å‘äºç”Ÿæˆå†—é•¿çš„å›å¤ï¼Œå³ä½¿æç¤ºè¦æ±‚ç®€çŸ­å›ç­”ï¼Œè¿™ä½¿å¾—è¯„ä¼°å…¶å›ç­”çš„å‡†ç¡®æ€§å˜å¾—å›°éš¾ã€‚è¯¥ç ”ç©¶çš„è¯„ä¼°æ¡†æ¶ä¹Ÿé¢ä¸´åŒæ ·çš„é—®é¢˜ã€‚</p></li>
</ol>
<p>æ•´ä½“è€Œè¨€ï¼Œä½œè€…è¯šå®åœ°æŒ‡å‡ºäº†ç ”ç©¶ä¸­ç”±äºæŠ€æœ¯ã€èµ„æºå’Œæ–¹æ³•å¸¦æ¥çš„é™åˆ¶ï¼Œå¹¶æå‡ºäº†ç›¸åº”çš„æ”¹è¿›æ–¹å‘ã€‚</p>
</section>
<section id="broader-impacts">
<h2>9 Broader Impacts<a class="headerlink" href="#broader-impacts" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p>è¯¥ç« èŠ‚â€œ9 Broader Impactsâ€ä¸»è¦æ¢è®¨äº†è®ºæ–‡æ‰€æå‡ºçš„ç”Ÿæˆä»£ç†æ¡†æ¶åœ¨ä¼¦ç†å’Œå®é™…åº”ç”¨ä¸­å¯èƒ½å¸¦æ¥çš„å¹¿æ³›å½±å“ï¼Œæ€»ç»“å¦‚ä¸‹ï¼š</p>
<ol class="arabic simple">
<li><p><strong>ç”Ÿæˆä»£ç†çš„ä¼¦ç†é£é™©</strong>ï¼šä½œè€…å€Ÿé‰´å¹¶æ”¹è¿›äº†Parkç­‰äººæå‡ºçš„ç”Ÿæˆä»£ç†æ¡†æ¶ï¼Œè‡´åŠ›äºç”Ÿæˆé«˜åº¦çœŸå®æ„Ÿçš„é•¿æœŸå¯¹è¯ã€‚ç„¶è€Œï¼Œè¿™ç§çœŸå®æ„Ÿå¯èƒ½å¯¼è‡´ç”¨æˆ·ä¸ä»£ç†ä¹‹é—´å½¢æˆâ€œå¯„ç”Ÿå¼ç¤¾ä¼šå…³ç³»â€ï¼Œä»è€Œå¯¹ç”¨æˆ·çš„ç°å®ç”Ÿæ´»äº§ç”Ÿè´Ÿé¢å½±å“ã€‚å› æ­¤ï¼Œä½œè€…å»ºè®®åœ¨å®é™…éƒ¨ç½²æ—¶åº”æ˜ç¡®å£°æ˜å¯¹è¯æ¥è‡ªç”Ÿæˆæ¨¡å‹ï¼Œä»¥é¿å…è¯¯å¯¼ç”¨æˆ·ã€‚</p></li>
<li><p><strong>å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„é£é™©</strong>ï¼šæ–‡ä¸­ä½¿ç”¨çš„å¤šæ¨¡æ€å¤§æ¨¡å‹å¯ä»¥æ ¹æ®å¯¹è¯å†…å®¹ç”Ÿæˆå›¾åƒï¼Œè¿™ç§èƒ½åŠ›å¯èƒ½è¢«æ»¥ç”¨ï¼Œå¯¼è‡´è™šå‡ä¿¡æ¯å’Œç¤¾äº¤åè§çš„ä¼ æ’­ã€‚ç‰¹åˆ«æ˜¯å½“ä»£ç†è¢«è¯±å¯¼é‡å¤é”™è¯¯ä¿¡æ¯æˆ–å±é™©è§‚ç‚¹æ—¶ï¼Œé£é™©æ›´å¤§ã€‚</p></li>
<li><p><strong>ä»£ç†æ›¿ä»£äººç±»çš„æ½œåœ¨é—®é¢˜</strong>ï¼šç”Ÿæˆä»£ç†å¯èƒ½è¢«ç”¨äºæ›¿ä»£çœŸå®äººç±»å‚ä¸æŸäº›ç ”ç©¶æˆ–è¿‡ç¨‹ï¼Œå°¤å…¶æ˜¯åœ¨éš¾ä»¥æ”¶é›†é•¿æœŸäººç±»äº’åŠ¨æ•°æ®çš„æƒ…å†µä¸‹ã€‚ä½†ä½œè€…å¼ºè°ƒï¼Œè‹¥ç ”ç©¶ç»“æœå¯èƒ½å½±å“ç°å®å†³ç­–ï¼Œè¿™ç§æ›¿ä»£åº”è°¨æ…å¯¹å¾…ï¼Œä»¥å…å¯¹äººç±»é€ æˆå®é™…å½±å“ã€‚æœ¬æ–‡ä»…æ˜¯å…³äºé•¿æœŸå¯¹è¯ä¸­æ¨¡å‹ç†è§£èƒ½åŠ›çš„ç ”ç©¶ï¼Œä¸æ¶‰åŠç°å®æ”¿ç­–å»ºè®®ï¼Œä½œè€…ä¹Ÿå»ºè®®å…¶ä»–ç ”ç©¶è€…é¿å…æ®æ­¤æå‡ºæ”¿ç­–æ€§å»ºè®®ã€‚</p></li>
</ol>
<p>æ€»ä½“è€Œè¨€ï¼Œè¯¥ç« èŠ‚å¼ºè°ƒäº†ç”Ÿæˆä»£ç†æŠ€æœ¯åœ¨æ¨åŠ¨å¯¹è¯ç ”ç©¶çš„åŒæ—¶ï¼Œæ‰€æ¶‰åŠçš„ä¼¦ç†é£é™©å’Œç¤¾ä¼šè´£ä»»ï¼Œå¹¶æå‡ºäº†ä¸€äº›åº”å¯¹æªæ–½å’Œä½¿ç”¨å»ºè®®ã€‚</p>
</section>
<section id="appendix-overview">
<h2>Appendix Overview<a class="headerlink" href="#appendix-overview" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p>è¯¥æ®µè½ä¸»è¦æ¦‚è¿°äº†é™„å½•çš„ç»“æ„å’Œå†…å®¹ï¼Œå¹¶é…åˆä¸€ä¸ªå›¾è¡¨è¯´æ˜LoCoMoæ•°æ®é›†ä¸­äººç‰©è®¾å®šç”Ÿæˆç›¸å…³çš„ä¿¡æ¯ã€‚ä»¥ä¸‹æ˜¯å†…å®¹æ€»ç»“ï¼š</p>
<ol class="arabic simple">
<li><p><strong>é™„å½•ç»“æ„</strong>ï¼š</p>
<ul class="simple">
<li><p><strong>é™„å½•A</strong>ï¼šä»‹ç»äº†LoCoMoæ•°æ®é›†ä¸­ç”Ÿæˆå¼æµç¨‹çš„ç»†èŠ‚ã€‚</p></li>
<li><p><strong>é™„å½•B</strong>ï¼šæä¾›äº†LoCoMoæ•°æ®é›†çš„ç»Ÿè®¡æ•°æ®ã€æ•°æ®å‘å¸ƒçš„è®¸å¯è¯ä»¥åŠæ ‡æ³¨äººå‘˜çš„è¯¦ç»†ä¿¡æ¯ã€‚</p></li>
<li><p><strong>é™„å½•C</strong>ï¼šæè¿°äº†å®éªŒè®¾ç½®å’Œå®ç°ç»†èŠ‚ã€‚</p></li>
<li><p><strong>é™„å½•D</strong>ï¼šå±•ç¤ºäº†åœ¨LoCoMoåŸºå‡†ä¸Šè¯„ä¼°çš„é¢å¤–ç»“æœã€‚</p></li>
</ul>
</li>
<li><p><strong>å›¾5è¯´æ˜</strong>ï¼š</p>
<ul class="simple">
<li><p>å›¾5å±•ç¤ºäº†ä¸€ä¸ªç”¨äºä»åˆå§‹äººç‰©è®¾å®šï¼ˆpcï¼‰ç”Ÿæˆæ‰©å±•äººç‰©é™ˆè¿°ï¼ˆpï¼‰çš„æç¤ºè¯­ï¼ˆpromptï¼‰ã€‚</p></li>
<li><p>åŒæ—¶æä¾›äº†LoCoMoæ•°æ®é›†ä¸­äººç‰©é™ˆè¿°çš„ç¤ºä¾‹ï¼Œç”¨äºè¯´æ˜è™šæ‹Ÿä»£ç†åœ¨å¯¹è¯ç”Ÿæˆæµç¨‹ä¸­çš„äººç‰©è®¾å®šç”Ÿæˆæ–¹å¼ã€‚</p></li>
</ul>
</li>
</ol>
<p>æ€»ç»“ï¼šè¯¥æ®µè½å’Œå›¾è¡¨ä¸ºè®ºæ–‡çš„é™„å½•éƒ¨åˆ†æä¾›äº†ç»“æ„è¯´æ˜ï¼Œå¹¶å…·ä½“è§£é‡Šäº†LoCoMoæ•°æ®é›†ä¸­äººç‰©è®¾å®šç”Ÿæˆçš„æ–¹æ³•å’Œç¤ºä¾‹ï¼Œå¢å¼ºäº†è®ºæ–‡çš„æŠ€æœ¯ç»†èŠ‚å’Œæ•°æ®èƒŒæ™¯çš„å¯ç†è§£æ€§ã€‚</p>
</section>
<section id="appendix-a-generative-pipeline-for-locomo">
<h2>Appendix A Generative Pipeline for LoCoMo<a class="headerlink" href="#appendix-a-generative-pipeline-for-locomo" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p>æœ¬é™„å½•æè¿°äº†LoCoMoæ•°æ®é›†ç”Ÿæˆæµç¨‹çš„ä¸»è¦ç»„æˆéƒ¨åˆ†ï¼ŒåŒ…æ‹¬è§’è‰²è®¾å®šï¼ˆPersonaï¼‰ã€æ—¶é—´äº‹ä»¶å›¾ï¼ˆTemporal Event Graphï¼‰å’Œäººç±»è¿‡æ»¤ï¼ˆHuman Filteringï¼‰ä¸‰ä¸ªéƒ¨åˆ†ï¼š</p>
<ol class="arabic simple">
<li><p><strong>è§’è‰²è®¾å®šï¼ˆPersonaï¼‰</strong>ï¼š</p>
<ul class="simple">
<li><p>æ¯ä¸ªè™šæ‹Ÿä»£ç†ï¼ˆagentï¼‰è¢«èµ‹äºˆä¸€ä¸ªç‹¬ç‰¹çš„è§’è‰²è®¾å®šï¼ˆpersonaï¼‰ï¼Œè¯¥è®¾å®šé€šè¿‡ä»MSCæ•°æ®é›†ä¸­é€‰å–åˆå§‹è§’è‰²å±æ€§ï¼Œåˆ©ç”¨GPT-3.5-turboæ¨¡å‹æ‰©å±•ç”Ÿæˆå®Œæ•´çš„è§’è‰²æè¿°ã€‚</p></li>
<li><p>ç”Ÿæˆè¿‡ç¨‹ä½¿ç”¨äº†æç¤ºè¯ï¼ˆpromptï¼‰å’Œä¸Šä¸‹æ–‡ç¤ºä¾‹ï¼Œç¡®ä¿è§’è‰²è®¾å®šçš„å¤šæ ·æ€§å’Œåˆç†æ€§ã€‚</p></li>
<li><p>ç¤ºä¾‹å’Œæç¤ºè¯è§å›¾5å’Œå›¾6ã€‚</p></li>
</ul>
</li>
<li><p><strong>æ—¶é—´äº‹ä»¶å›¾ï¼ˆTemporal Event Graphï¼‰</strong>ï¼š</p>
<ul class="simple">
<li><p>åŸºäºè§’è‰²è®¾å®šï¼Œä½¿ç”¨è¿­ä»£æ–¹å¼ç”Ÿæˆäº‹ä»¶å›¾ï¼Œå›¾ä¸­åŒ…å«å› æœå…³è”çš„äº‹ä»¶ã€‚</p></li>
<li><p>åˆå§‹ç”Ÿæˆä¸‰ä¸ªä¸è§’è‰²ç›¸å…³çš„ç‹¬ç«‹äº‹ä»¶ï¼Œä¹‹åé€æ­¥ç”Ÿæˆç”±å·²æœ‰äº‹ä»¶å¼•å‘çš„æ–°äº‹ä»¶ï¼Œä»è€Œå½¢æˆå› æœé“¾ã€‚</p></li>
<li><p>è™šæ‹Ÿä»£ç†æ¶æ„åŒ…æ‹¬â€œåæ€ä¸å›åº”â€ï¼ˆReflect &amp; Respondï¼‰å’Œâ€œå›¾åƒåˆ†äº«ä¸å›åº”â€ï¼ˆImage Sharing &amp; Responseï¼‰ä¸¤ä¸ªæœºåˆ¶ã€‚</p>
<ul>
<li><p><strong>åæ€ä¸å›åº”</strong>ï¼šç»“åˆçŸ­æœŸè®°å¿†ï¼ˆå½“å‰ä¼šè¯æ‘˜è¦ï¼‰å’Œé•¿æœŸè®°å¿†ï¼ˆå…³äºè§’è‰²çš„è§‚å¯Ÿæ€§é™ˆè¿°ï¼‰ç”Ÿæˆå›å¤ã€‚</p></li>
<li><p><strong>å›¾åƒåˆ†äº«ä¸å›åº”</strong>ï¼šæ”¯æŒç”Ÿæˆå›¾åƒæè¿°å¹¶åŸºäºå›¾åƒè¿›è¡Œå¯¹è¯äº’åŠ¨ã€‚</p></li>
</ul>
</li>
<li><p>ç›¸å…³æç¤ºè¯å’Œç¤ºä¾‹è§å›¾7è‡³å›¾10ã€‚</p></li>
</ul>
</li>
<li><p><strong>äººç±»è¿‡æ»¤ï¼ˆHuman Filteringï¼‰</strong>ï¼š</p>
<ul class="simple">
<li><p>ç”Ÿæˆçš„å¯¹è¯å†…å®¹ç»è¿‡äººç±»æ ‡æ³¨è€…ç¼–è¾‘ï¼Œä»¥æé«˜æ•°æ®è´¨é‡å’Œä¸€è‡´æ€§ã€‚</p></li>
<li><p>ç¼–è¾‘ä»»åŠ¡åŒ…æ‹¬ï¼šåˆ é™¤æ— å…³å›¾åƒã€è¡¥å……å›¾åƒä¸Šä¸‹æ–‡ã€æ›¿æ¢ä¸åŒ¹é…å›¾åƒã€ä¿®æ­£å¯¹è¯ä¸€è‡´æ€§ã€ç¡®ä¿å¯¹è¯ä¸äº‹ä»¶å›¾ä¸€è‡´ã€åˆ é™¤æœªå‡ºç°åœ¨å¯¹è¯ä¸­çš„äº‹ä»¶ç­‰ã€‚</p></li>
<li><p>å›¾11å±•ç¤ºäº†ä¸€äº›ç¼–è¾‘ç¤ºä¾‹ã€‚</p></li>
</ul>
</li>
</ol>
<p>æ€»ç»“ï¼šLoCoMoæ•°æ®é›†çš„ç”Ÿæˆä¾èµ–äºè§’è‰²è®¾å®šã€æ—¶é—´äº‹ä»¶å»ºæ¨¡å’Œå¤šè½®å¯¹è¯ç”Ÿæˆï¼ŒåŒæ—¶é€šè¿‡äººç±»æ ‡æ³¨è¿›è¡ŒåæœŸä¿®æ­£ï¼Œä»¥ç¡®ä¿æ•°æ®çš„è¿è´¯æ€§ã€åˆç†æ€§å’Œå¤šæ ·æ€§ï¼Œé€‚ç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é•¿æœŸå¯¹è¯ä¸­çš„è®°å¿†èƒ½åŠ›ã€‚</p>
</section>
<section id="appendix-b-dataset">
<h2>Appendix B Dataset<a class="headerlink" href="#appendix-b-dataset" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p>æœ¬ç« æ€»ç»“å¦‚ä¸‹ï¼š</p>
<hr class="docutils" />
<section id="b">
<h3><strong>é™„å½•Bï¼šæ•°æ®é›†</strong><a class="headerlink" href="#b" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<section id="b-1">
<h4><strong>B.1 æ•°æ®é›†ç»Ÿè®¡</strong><a class="headerlink" href="#b-1" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>æœ¬éƒ¨åˆ†ä»‹ç»äº†LoCoMoæ•°æ®é›†çš„ç»Ÿè®¡ä¿¡æ¯ï¼ŒåŒ…æ‹¬å¯¹è¯å’Œè¯„ä¼°åŸºå‡†çš„æ•°æ®è§„æ¨¡ä¸ç‰¹ç‚¹ã€‚</p>
<ul class="simple">
<li><p><strong>å¯¹è¯ç»Ÿè®¡</strong>ï¼š</p>
<ul>
<li><p>æ€»å¯¹è¯æ•°ï¼š50ä¸ªã€‚</p></li>
<li><p>å¹³å‡æ¯ä¸ªå¯¹è¯åŒ…å«19.3ä¸ªä¼šè¯ï¼ˆsessionï¼‰ã€‚</p></li>
<li><p>å¹³å‡æ¯ä¸ªä¼šè¯åŒ…å«15.8è½®å¯¹è¯ï¼ˆturnï¼‰ã€‚</p></li>
<li><p>å¹³å‡æ¯ä¸ªå¯¹è¯åŒ…å«çº¦9,209.2ä¸ªtokenã€‚</p></li>
<li><p>æ¯è½®å¯¹è¯çš„å¹³å‡tokenæ•°çº¦ä¸º30.2ä¸ªï¼ˆå¯¹è¯å†…å®¹ï¼‰å’Œ18.2ä¸ªï¼ˆè§‚å¯Ÿå†…å®¹ï¼‰ã€‚</p></li>
<li><p>æ¯ä¸ªä¼šè¯çš„æ€»ç»“å¹³å‡é•¿åº¦ä¸º127.4ä¸ªtokenã€‚</p></li>
</ul>
</li>
<li><p><strong>é—®ç­”è¯„ä¼°åŸºå‡†ç»Ÿè®¡</strong>ï¼š</p>
<ul>
<li><p>å•è·³æ£€ç´¢ï¼š2,705ä¸ªé—®é¢˜ï¼ˆå 36%ï¼‰ã€‚</p></li>
<li><p>å¤šè·³æ£€ç´¢ï¼š1,104ä¸ªé—®é¢˜ï¼ˆå 14.6%ï¼‰ã€‚</p></li>
<li><p>æ—¶é—´æ¨ç†ï¼š1,547ä¸ªé—®é¢˜ï¼ˆå 20.6%ï¼‰ã€‚</p></li>
<li><p>å¼€æ”¾åŸŸçŸ¥è¯†ï¼š285ä¸ªé—®é¢˜ï¼ˆå 3.9%ï¼‰ã€‚</p></li>
<li><p>å¯¹æŠ—æ€§é—®é¢˜ï¼š1,871ä¸ªé—®é¢˜ï¼ˆå 24.9%ï¼‰ã€‚</p></li>
<li><p>æ€»é—®é¢˜æ•°ï¼š7,512ä¸ªã€‚</p></li>
</ul>
</li>
<li><p><strong>äº‹ä»¶æ€»ç»“ç»Ÿè®¡</strong>ï¼š</p>
<ul>
<li><p>æ¯ä¸ªå¯¹è¯å¹³å‡åŒ…å«24.2ä¸ªäº‹ä»¶ã€‚</p></li>
<li><p>äº‹ä»¶æ€»ç»“çš„å¹³å‡é•¿åº¦ä¸º896.5ä¸ªtokenã€‚</p></li>
</ul>
</li>
<li><p><strong>å¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆç»Ÿè®¡</strong>ï¼š</p>
<ul>
<li><p>æ¯ä¸ªå¯¹è¯å¹³å‡åŒ…å«32.3å¼ å›¾ç‰‡ã€‚</p></li>
</ul>
</li>
</ul>
</section>
<section id="b-2">
<h4><strong>B.2 æ•°æ®é›†æˆæƒ</strong><a class="headerlink" href="#b-2" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>LoCoMoæ•°æ®é›†å°†é‡‡ç”¨ <strong>CC BY-NC 4.0 DEED</strong> è®¸å¯åè®®å‘å¸ƒï¼Œå…è®¸åœ¨éå•†ä¸šç”¨é€”ä¸‹ä½¿ç”¨ï¼Œå¹¶éœ€æ³¨æ˜å‡ºå¤„ã€‚</p>
</section>
<section id="b-3">
<h4><strong>B.3 æ ‡æ³¨äººå‘˜ä¿¡æ¯</strong><a class="headerlink" href="#b-3" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>æœ¬æ•°æ®é›†ç”±å†…éƒ¨æ ‡æ³¨äººå‘˜å®Œæˆæ ‡æ³¨ã€‚ç”±äºä¿¡æ¯ä¿å¯†åŸå› ï¼Œæ— æ³•æä¾›æ ‡æ³¨äººå‘˜çš„äººå£ç»Ÿè®¡ä¿¡æ¯ã€‚</p>
<hr class="docutils" />
<p><strong>æ€»ç»“</strong>ï¼š<br />
æœ¬ç« æä¾›äº†LoCoMoæ•°æ®é›†çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯ï¼Œæ¶µç›–å¯¹è¯ç»“æ„ã€è¯„ä¼°ä»»åŠ¡åˆ†å¸ƒã€äº‹ä»¶æ€»ç»“åŠå¤šæ¨¡æ€å†…å®¹ã€‚åŒæ—¶æ˜ç¡®äº†æ•°æ®é›†çš„æˆæƒæ–¹å¼ï¼Œå¹¶è¯´æ˜äº†æ ‡æ³¨äººå‘˜çš„ä¿¡æ¯ä¿å¯†æƒ…å†µã€‚è¿™äº›å†…å®¹ä¸ºç†è§£æ•°æ®è§„æ¨¡å’Œä½¿ç”¨é™åˆ¶æä¾›äº†é‡è¦å‚è€ƒã€‚</p>
</section>
</section>
</section>
<section id="appendix-c-experimental-setup">
<h2>Appendix C Experimental Setup<a class="headerlink" href="#appendix-c-experimental-setup" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p>æœ¬èŠ‚æ€»ç»“äº†è®ºæ–‡ä¸­å…³äºå®éªŒè®¾ç½®çš„é™„å½•å†…å®¹ï¼Œä¸»è¦åŒ…æ‹¬åŸºçº¿æ–¹æ³•ã€ä¸åŒä»»åŠ¡çš„å®éªŒé…ç½®ä»¥åŠå®ç°ç»†èŠ‚ã€‚</p>
<section id="baselines">
<h3>1. åŸºçº¿æ–¹æ³•ï¼ˆBaselinesï¼‰<a class="headerlink" href="#baselines" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>åœ¨LoCoMoæ•°æ®é›†ä¸Šï¼Œå¯¹è¯åŒ…å«è‡ªç„¶è¯­è¨€å’Œå›¾åƒï¼Œæ¶‰åŠé«˜é˜¶æ¨ç†å’Œå¤šæ¨¡æ€å…±æŒ‡æ¶ˆè§£ã€‚ç ”ç©¶å‘ç°ï¼Œä½¿ç”¨BLIP-2ç”Ÿæˆå›¾åƒæè¿°ï¼Œå¹¶ç»“åˆå…ˆè¿›å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡Œæ¨ç†ï¼Œå¯ä»¥æœ‰æ•ˆå¤„ç†å¤šæ¨¡æ€å…±æŒ‡é—®é¢˜ã€‚å› æ­¤ï¼Œé—®ç­”å’Œäº‹ä»¶æ‘˜è¦ä»»åŠ¡ä¸»è¦ä½¿ç”¨LLMsè¿›è¡Œï¼Œä»…åœ¨å¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆä»»åŠ¡ä¸­ç›´æ¥ä½¿ç”¨å›¾åƒã€‚</p>
<section id="id10">
<h4>1.1 é—®ç­”ä»»åŠ¡<a class="headerlink" href="#id10" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>å®éªŒé‡‡ç”¨ä¸‰ç§æ–¹æ³•ï¼š</p>
<ul class="simple">
<li><p><strong>Base</strong>ï¼šåœ¨å—é™ä¸Šä¸‹æ–‡çª—å£ä¸­ä½¿ç”¨LLMç›´æ¥å®Œæˆä»»åŠ¡ï¼Œæ—©æœŸå¯¹è¯ä¼šå› çª—å£é™åˆ¶è¢«çœç•¥ã€‚</p></li>
<li><p><strong>Long-context</strong>ï¼šä½¿ç”¨æ‹¥æœ‰æ›´å¤§ä¸Šä¸‹æ–‡çª—å£çš„LLMï¼Œå°½å¯èƒ½æš´éœ²æ›´å¤šå¯¹è¯å†…å®¹ã€‚</p></li>
<li><p><strong>RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰</strong>ï¼šä»å¯¹è¯å†å²ã€è§‚å¯Ÿæˆ–ä¼šè¯æ€»ç»“ä¸­æ£€ç´¢ç›¸å…³å†…å®¹ã€‚è§‚å¯ŸåŸºäºå¯¹è¯ä¸­æ¯ä¸ªè¯´è¯è€…çš„æ–­è¨€ï¼Œä¼šè¯æ€»ç»“åˆ™ä¸ºæ¯åœºå¯¹è¯çš„ç®€è¦æ€»ç»“ã€‚</p></li>
</ul>
<p>ä½¿ç”¨çš„æ¨¡å‹åŒ…æ‹¬ Mistral-7Bã€LLaMA-70Bã€gpt-3.5-turbo å’Œ gpt-4-turboï¼Œæ£€ç´¢æ¨¡å‹ä¸º DRAGONã€‚æœªæŠ¥å‘Šéƒ¨åˆ†å¼€æºæ¨¡å‹çš„æ€§èƒ½ï¼ŒåŸå› åœ¨äºå…¶åœ¨çŸ­ä¸Šä¸‹æ–‡ä¸­çš„è¡¨ç°å¯èƒ½å­˜åœ¨æ³¢åŠ¨ã€‚</p>
</section>
<section id="id11">
<h4>1.2 äº‹ä»¶æ‘˜è¦ä»»åŠ¡<a class="headerlink" href="#id11" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>åŒæ ·é‡‡ç”¨ <strong>Base</strong> å’Œ <strong>Long-context</strong> é…ç½®ï¼Œä½†ä¸ä½¿ç”¨ RAGã€‚ä¸é—®ç­”ä»»åŠ¡ä¸åŒï¼Œäº‹ä»¶æ‘˜è¦éœ€è¦å¯¹æ•´ä¸ªå¯¹è¯æœ‰å…¨é¢ç†è§£ã€‚ç ”ç©¶é‡‡ç”¨è¿­ä»£æ–¹å¼ï¼Œå…ˆä¸ºå‰ä¸€èŠ‚å¯¹è¯ç”Ÿæˆæ‘˜è¦ï¼Œå†åŸºäºè¯¥æ‘˜è¦ç”Ÿæˆä¸‹ä¸€èŠ‚çš„æ‘˜è¦ã€‚åŒæ—¶ï¼Œé€šè¿‡ä¸€ä¸ªç¤ºä¾‹è¾“å…¥å’Œè¾“å‡ºå¼•å¯¼æ¨¡å‹æå–é‡è¦äººç”Ÿäº‹ä»¶ã€‚</p>
</section>
<section id="id12">
<h4>1.3 å¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆ<a class="headerlink" href="#id12" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>ä½¿ç”¨ MiniGPT-5 æ¨¡å‹ï¼Œåœ¨50ä¸ªè‡ªåŠ¨ç”Ÿæˆçš„å¯¹è¯ä¸Šè¿›è¡Œè®­ç»ƒï¼Œæœªç»è¿‡äººå·¥ç­›é€‰ã€‚è®­ç»ƒæ•°æ®åŒ…æ‹¬ä»¥ä¸‹ä¸‰ç§å˜ä½“ï¼š</p>
<ul class="simple">
<li><p><strong>Base</strong>ï¼šä»…ä½¿ç”¨å‰æ–‡å¯¹è¯ã€‚</p></li>
<li><p><strong>+summary</strong>ï¼šä½¿ç”¨å‰æ–‡å¯¹è¯å’Œå…¨å±€å¯¹è¯æ‘˜è¦ã€‚</p></li>
<li><p><strong>+observation</strong>ï¼šä½¿ç”¨å‰æ–‡å¯¹è¯å’Œä»å†å²ä¸­æ£€ç´¢åˆ°çš„ç›¸å…³è§‚å¯Ÿã€‚
æ¨¡å‹å‡åŸºäº MiniGPT-5 åœ¨ MMDialog æ•°æ®é›†ä¸Šçš„é¢„è®­ç»ƒå‚æ•°ã€‚</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="implementation-details">
<h3>2. å®ç°ç»†èŠ‚ï¼ˆImplementation Detailsï¼‰<a class="headerlink" href="#implementation-details" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p>ä½¿ç”¨ <strong>OpenAI API</strong> å’Œ <strong>Huggingface</strong> å¹³å°è¿›è¡Œå®éªŒï¼Œæ¸©åº¦ï¼ˆtemperatureï¼‰è®¾ä¸º 0ï¼Œtop-p ä¸º 1ï¼Œä»¥ç¡®ä¿ç”Ÿæˆç»“æœçš„ç¡®å®šæ€§ã€‚</p></li>
<li><p>æ‰€æœ‰å®éªŒï¼ˆåŒ…æ‹¬ RAG æ¨¡å‹ã€MiniGPT-5 è®­ç»ƒå’Œæ¨ç†ï¼‰å‡åœ¨ <strong>NVIDIA A6000</strong> æœåŠ¡å™¨ä¸Šä½¿ç”¨ <strong>FP32</strong> ç²¾åº¦å®Œæˆã€‚</p></li>
<li><p>å¯¹äº MiniGPT-5ï¼Œæ¨¡å‹è®­ç»ƒäº† 10 ä¸ªå‘¨æœŸï¼Œè€—æ—¶çº¦ 30 å°æ—¶ï¼Œä½¿ç”¨åŸå§‹ä»£ç åº“æ¨èçš„è¶…å‚æ•°ã€‚</p></li>
<li><p>è¯„ä¼°ä¸­ä½¿ç”¨æ ‡å‡†çš„ Python åº“è®¡ç®—ä»¥ä¸‹æŒ‡æ ‡ï¼š</p>
<ul>
<li><p><strong>BLEU</strong></p></li>
<li><p><strong>ROUGE</strong></p></li>
<li><p><strong>BertScore</strong></p></li>
<li><p><strong>FactScore</strong></p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="id13">
<h3>æ€»ç»“<a class="headerlink" href="#id13" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>æœ¬èŠ‚è¯¦ç»†æè¿°äº†å®éªŒè®¾ç½®ï¼Œé’ˆå¯¹é—®ç­”ã€äº‹ä»¶æ‘˜è¦å’Œå¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆä»»åŠ¡åˆ†åˆ«è®¾è®¡äº†ä¸åŒçš„åŸºçº¿æ–¹æ³•å’Œæ¨¡å‹é…ç½®ï¼Œå¹¶æä¾›äº†å…·ä½“çš„å®ç°ç»†èŠ‚å’Œè¯„ä¼°æŒ‡æ ‡ï¼Œä¸ºå®éªŒç»“æœçš„å¯ä¿¡æ€§å’Œå¯å¤ç°æ€§æä¾›äº†ä¿éšœã€‚</p>
</section>
</section>
<section id="appendix-d-results">
<h2>Appendix D Results<a class="headerlink" href="#appendix-d-results" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<section id="id14">
<h3>æ€»ç»“å†…å®¹å¦‚ä¸‹ï¼š<a class="headerlink" href="#id14" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<section id="minigpt-5">
<h4>1. <strong>è¡¨6ï¼šMiniGPT-5å¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆæ€§èƒ½æ¯”è¾ƒ</strong><a class="headerlink" href="#minigpt-5" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>è¡¨6æ¯”è¾ƒäº†MiniGPT-5æ¨¡å‹åœ¨ä¸åŒè®­ç»ƒå˜ä½“ä¸‹çš„å¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆæ€§èƒ½ã€‚æ€§èƒ½è¯„ä¼°æŒ‡æ ‡åŒ…æ‹¬BLEU-1/2ã€Rouge-L å’Œ MM-Rã€‚ç»“æœæ˜¾ç¤ºï¼š</p>
<ul class="simple">
<li><p><strong>åŸºç¡€æ¨¡å‹ï¼ˆBaseï¼‰</strong> è¡¨ç°ä¸º BLEU-1/2 ä¸º 57.1/34.2ï¼ŒRouge-L ä¸º 12.4ï¼ŒMM-R ä¸º 56.1ã€‚</p></li>
<li><p>åœ¨åŸºç¡€ä¸ŠåŠ å…¥**æ‘˜è¦ï¼ˆ+ summaryï¼‰**æ—¶ï¼Œ<strong>top-k=1</strong>æ—¶æ€§èƒ½æœ€ä¼˜ï¼ŒBLEU-1/2 ä¸º 58.2/34.1ï¼ŒRouge-L ä¸º 12.8ï¼ŒMM-R ä¸º 56.9ã€‚</p></li>
<li><p>åŠ å…¥**è§‚å¯Ÿï¼ˆ+ observationï¼‰**æ—¶ï¼Œ<strong>top-k=5</strong> æ—¶æ€§èƒ½æœ€ä½³ï¼ŒBLEU-1/2 ä¸º 59.7/35.1ï¼ŒRouge-L ä¸º 13.6ï¼ŒMM-R ä¸º 57.8ã€‚</p></li>
</ul>
</section>
<section id="d-1-event-summarization-task">
<h4>2. <strong>D.1 äº‹ä»¶æ€»ç»“ä»»åŠ¡ï¼ˆEvent Summarization Taskï¼‰</strong><a class="headerlink" href="#d-1-event-summarization-task" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>è¯¥éƒ¨åˆ†é€šè¿‡è¡¨7å±•ç¤ºäº†LLMsåœ¨äº‹ä»¶æ€»ç»“ä»»åŠ¡ä¸­å¸¸è§çš„äº”ç±»é”™è¯¯ï¼š</p>
<ul class="simple">
<li><p><strong>ä¿¡æ¯ç¼ºå¤±ï¼ˆMissing informationï¼‰</strong>ï¼šå…³é”®äº‹ä»¶ç»†èŠ‚ç¼ºå¤±ï¼Œæ¨¡å‹æœªèƒ½å»ºç«‹å› æœå’Œæ—¶é—´è”ç³»ã€‚</p></li>
<li><p><strong>å¹»è§‰ï¼ˆHallucinationï¼‰</strong>ï¼šæ·»åŠ äº†ä¸å­˜åœ¨çš„æˆ–æ¥è‡ªå…¶ä»–äº‹ä»¶çš„ä¿¡æ¯ã€‚</p></li>
<li><p><strong>å¯¹è¯æç¤ºè¯¯è§£ï¼ˆMisunderstanding of dialog cuesï¼‰</strong>ï¼šå°†è½»æ¾è¯­å¥è¯¯è§£ä¸ºä¸¥è‚ƒé™ˆè¿°ã€‚</p></li>
<li><p><strong>è¯´è¯äººå½’å±é”™è¯¯ï¼ˆSpeaker attributionï¼‰</strong>ï¼šäº‹ä»¶è¢«é”™è¯¯åœ°å½’å› äºé”™è¯¯çš„è¯´è¯äººã€‚</p></li>
<li><p><strong>æ˜¾è‘—æ€§é”™è¯¯ï¼ˆSaliencyï¼‰</strong>ï¼šæ¨¡å‹å°†å¯¹è¯ä¸­ä¸é‡è¦çš„äº’åŠ¨è§†ä¸ºé‡è¦ã€‚</p></li>
</ul>
<p>è¿™äº›é”™è¯¯ç¤ºä¾‹åŸºäº gpt-3.5-turbo çš„é¢„æµ‹ç”Ÿæˆï¼Œåæ˜ äº†å½“å‰LLMsåœ¨é•¿å¯¹è¯äº‹ä»¶æ€»ç»“ä¸­çš„ä¸»è¦é—®é¢˜ã€‚</p>
</section>
<section id="d-2-multimodal-dialog-generation-task">
<h4>3. <strong>D.2 å¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆä»»åŠ¡ï¼ˆMultimodal Dialog Generation Taskï¼‰</strong><a class="headerlink" href="#d-2-multimodal-dialog-generation-task" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>éƒ¨åˆ†D.2ä»‹ç»äº†LoCoMoåŸºå‡†ä¸­MiniGPT-5æ¨¡å‹åœ¨<strong>å¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆä»»åŠ¡</strong>ä¸Šçš„è¯„ä¼°ç»“æœï¼Œå…¶æ€§èƒ½æ•°æ®è¯¦è§è¡¨6ã€‚</p>
</section>
</section>
<section id="id15">
<h3>æ€»ä½“æ€»ç»“ï¼š<a class="headerlink" href="#id15" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p>MiniGPT-5æ¨¡å‹åœ¨å¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œé€šè¿‡å¼•å…¥<strong>æ‘˜è¦</strong>å’Œ<strong>è§‚å¯Ÿ</strong>ä¿¡æ¯ï¼Œæå‡äº†ç”Ÿæˆæ€§èƒ½ã€‚</p></li>
<li><p><strong>top-k=5</strong> æ—¶çš„â€œ+ observationâ€å˜ä½“è¡¨ç°æœ€ä½³ã€‚</p></li>
<li><p>åœ¨äº‹ä»¶æ€»ç»“ä»»åŠ¡ä¸­ï¼ŒLLMsä¸»è¦å­˜åœ¨ä¿¡æ¯ç¼ºå¤±ã€å¹»è§‰ã€è¯¯è§£æç¤ºã€è¯´è¯äººå½’å±é”™è¯¯å’Œæ˜¾è‘—æ€§åˆ¤æ–­é”™è¯¯ç­‰é—®é¢˜ã€‚</p></li>
<li><p>æœ¬é™„å½•å†…å®¹æ—¨åœ¨è¯„ä¼°LLMsåœ¨é•¿å¯¹è¯åœºæ™¯ä¸­çš„è¡¨ç°ï¼Œæ­ç¤ºå…¶åœ¨å¤šæ¨¡æ€å¯¹è¯ç”Ÿæˆå’Œäº‹ä»¶æ€»ç»“ä»»åŠ¡ä¸­çš„ä¼˜åŠ£ç‚¹ã€‚</p></li>
</ul>
<p>ä»¥ä¸Šå†…å®¹æ˜¯å¯¹é™„å½•Dç« èŠ‚å†…å®¹çš„æ€»ç»“ã€‚</p>
</section>
</section>
</section>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="2404.06654_RULER.html" class="btn btn-neutral float-right" title="2404.06654_RULER: Whatâ€™s the Real Context Size of Your Long-Context Language Models?" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="2402.05136_LV-Eval.html" class="btn btn-neutral" title="2402.05136_LV-Eval: A Balanced Long-Context Benchmark with 5 Length Levels Up to 256K" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>
  
  <div id="gitalk-container"></div>
  <div role="contentinfo">
    <p>
        &copy; Copyright 2010-2025, æ–°æºª-gordon.

    </p>
  </div>
  <div>å¤‡æ¡ˆå· <a href="http://www.beian.miit.gov.cn">äº¬ICPå¤‡16018553å·</a></div><div>Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a></div>. 


</footer>

<script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?042289284b8eb33866001347a3e0b129";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
</script>     
        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'V2025.07',
            LANGUAGE:'zh-CN',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="../../_static/sphinx_highlight.js"></script>
      <script type="text/javascript" src="../../_static/clipboard.min.js"></script>
      <script type="text/javascript" src="../../_static/copybutton.js"></script>
      <script type="text/javascript" src="../../_static/translations.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>

  

  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });


      // var gitalk = new Gitalk({
      //         clientID: '565177626b5d46427009',
      //         clientSecret: 'b2a36e67e1d2a73e43667f46d571c2624f8e1026',
      //         repo: 'knowledge',
      //         owner: 'zhaoweiguo',
      //         admin: ['zhaoweiguo'],
      //         id: location.pathname,      // Ensure uniqueness and length less than 50
      //         distractionFreeMode: false  // Facebook-like distraction free mode
      //       })
      // gitalk.render('gitalk-container')

  </script>


<script type="text/javascript" src="../../_static/js/table-of-contents-sidebar.js"></script>
<!-- <script type="text/javascript" src="https://table-of-contents-sidebar.github.io/table-of-contents-sidebar-lib/table-of-contents-sidebar.js"></script> -->
<script type="text/javascript">
    window.onload = function(e){
        TableOfContents.init({
            basePath: "https://table-of-contents-sidebar.github.io/table-of-contents-sidebar-lib/",
            querySelector: "body" // or other css querySelector
        });
    }
</script> 

</body>
</html>