

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="zh-CN" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="zh-CN" > <!--<![endif]-->
<head>


<!-- start added 2025-04-14   å¢åŠ å¯¹markdownä¸­å…¬å¼çš„æ”¯æŒ -->
<script>
window.MathJax = {
    tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true
    },
    options: {
        ignoreHtmlClass: "tex2jax_ignore|mathjax_ignore",
        processHtmlClass: "tex2jax_process|mathjax_process|math|output_area"
    }
};
</script>
<script defer="defer" src="https://fastly.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<!-- end added 2025-04-14   å¢åŠ å¯¹markdownä¸­å…¬å¼çš„æ”¯æŒ -->


  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>2312.14132_DUSt3R: Geometric 3D Vision Made Easy &mdash; æ–°æºª-gordon V2025.07 æ–‡æ¡£</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
    <link rel="index" title="ç´¢å¼•" href="../../genindex.html" />
    <link rel="search" title="æœç´¢" href="../../search.html" />
    <link rel="next" title="2406.09756_MASt3R: Grounding Image Matching in 3D with MASt3R" href="2406.09756_MASt3R.html" />
    <link rel="prev" title="2203.08586: Deep vanishing point detection: Geometric priors make dataset variations vanish" href="2203.08586_VanishingPointEstimation.html" /> 

  
  <script src="../../_static/js/modernizr.min.js"></script>
  <script src="../../_static/js/jquery.min.js"></script>


<!-- è¯„è®ºæ’ä»¶ gittalk start -->
<!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script> -->
<!-- è¯„è®ºæ’ä»¶ gittalk end -->


</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> æ–°æºª-gordon
          

          
          </a>

          
            
            
              <div class="version">
                V2025.07
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../0normal.html">é€šç”¨</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../0normals/normal.html">é€šç”¨</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../0normals/normal.html#id3">å¦‚ä½•çœ‹ä¸€ä¸ªè®ºæ–‡æ˜¯ä¸æ˜¯é‡è¦</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../0normals/website.html">å­¦æœ¯ç½‘ç«™</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../0normals/website.html#id2">æ•´ä½“åˆ†æ</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../0normals/website.html#id3">1. å­¦æœ¯æœç´¢å¹³å°ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼šæ£€ç´¢ä¸å‘ç°æ–‡çŒ®ï¼‰</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../0normals/website.html#google-scholar">Google Scholar</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../0normals/website.html#semantic-scholar">Semantic Scholar</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../0normals/website.html#web-of-science">Web of Science</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../0normals/website.html#id4">ç™¾åº¦å­¦æœ¯</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../0normals/website.html#id5">2. èµ„æºå…±äº«å¹³å°ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼šå…è´¹è·å–ä»˜è´¹æ–‡çŒ®ï¼‰</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../0normals/website.html#sci-hub">Sci-Hub</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../0normals/website.html#library-genesis-libgen">Library Genesis (LibGen)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../0normals/website.html#unpaywall">Unpaywall</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../0normals/website.html#id6">è®ºæ–‡æ•°æ®åº“ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼šå­˜å‚¨ä¸æä¾›æ–‡çŒ®åŸæ–‡ï¼‰</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../0normals/website.html#acl-anthology">ACL Anthology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../0normals/website.html#arxiv">ArXiv</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../0normals/website.html#cnki">çŸ¥ç½‘ CNKI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../0normals/website.html#id10">ä¸‡æ–¹æ•°æ®åº“</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../Benchmarking.html">è¯„æµ‹åŸºå‡†</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#id3">è¯„æµ‹åŸºå‡†</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html">02xx.xxxxx_BLEU: a Method for Automatic Evaluation of Machine Translation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html#id8">ç¤ºä¾‹è®²è§£</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html#the-baseline-bleu-metric">2.The Baseline BLEU Metric</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html#the-bleu-evaluation">3.The BLEU Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html#the-human-evaluation">4.The Human Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html#bleu-vs-the-human-evaluation">5.BLEU vs The Human Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html#conclusion">6.Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html">0401.xxxxx_ROUGE: A Package for Automatic Evaluation of Summaries</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html#rouge-n-n-gram-co-occurrence-statistics">2.ROUGE-N: N-gram Co-Occurrence Statistics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html#rouge-l-longest-common-subsequence">3.ROUGE-L: Longest Common Subsequence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html#rouge-w-weighted-longest-common-subsequence">4 ROUGE-W: Weighted Longest Common Subsequence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html#rouge-s-skip-bigram-co-occurrence-statistics">5.ROUGE-S: Skip-Bigram Co-Occurrence Statistics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html#evaluations-of-rouge">6 Evaluations of ROUGE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html#conclusions">7 Conclusions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Standards/1803.01937_ROUGE2.html">1803.01937_ROUGE2.0: Updated and Improved Measures for Evaluation of Summarization Tasks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1803.01937_ROUGE2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1803.01937_ROUGE2.html#problems-with-the-current-rouge-measures">1. Problems with the current ROUGE measures</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1803.01937_ROUGE2.html#rouge-2-0">2. ROUGE 2.0</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Standards/1804.08771_SacreBLEU.html">1804.08771_SacreBLEU: A Call for Clarity in Reporting BLEU Scores</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1804.08771_SacreBLEU.html#bleu">BLEU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1804.08771_SacreBLEU.html#id3">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1804.08771_SacreBLEU.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1804.08771_SacreBLEU.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1804.08771_SacreBLEU.html#problem-description">2 Problem Description</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1804.08771_SacreBLEU.html#a-way-forward">3 A way forward</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1804.08771_SacreBLEU.html#summary">4 Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge.html">2306.05685_Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge.html#mt-bench-and-chatbot-arena">2 MT-Bench and Chatbot Arena</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge.html#llm-as-a-judge">3 LLM as a Judge</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge.html#agreement-evaluation">4 Agreement Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge.html#human-preference-benchmark-and-standardized-benchmark">5 Human Preference Benchmark and Standardized Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge.html#discussion">6 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge.html#appendix-a-prompt-templates">Appendix A Prompt templates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge.html#appendix-b-case-study">Appendix B Case Study</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge.html#appendix-c-data-collection">Appendix C Data Collection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge.html#appendix-d-additional-experimental-results">Appendix D Additional Experimental Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge.html#appendix-e-training-details-of-vicuna-models">Appendix E Training Details of Vicuna Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge.html#appendix-f-exploring-vicuna-as-a-judge">Appendix F Exploring Vicuna as a judge</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#agent">æ•°æ®é›†-Agent</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html">2312.14033_T-Eval: Evaluating the Tool Utilization Capability of Large Language Models Step by Step</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#t-eval">2 T-Eval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#experiments">3 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#discussion">4 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#related-work">5 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#appendix-a-t-eval-benchmark-details">Appendix A T-EvalÂ Benchmark Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#appendix-b-implementation-details">Appendix B Implementation Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#appendix-c-detailed-evaluation-metrics">Appendix C Detailed Evaluation Metrics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#appendix-d-api-documentation">Appendix D API Documentation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2406.12045_%CF%84-bench.html">2406.12045_Ï„-bench: A Benchmark for Tool-Agent-User</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2406.12045_%CF%84-bench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2406.12045_%CF%84-bench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2406.12045_%CF%84-bench.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2406.12045_%CF%84-bench.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2406.12045_%CF%84-bench.html#bench-a-benchmark-for-t-ool-a-gent-u-ser-interaction">3.Ï„-bench: A benchmark for T ool-A gent-U ser Interaction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2406.12045_%CF%84-bench.html#benchmark-construction">4. Benchmark Construction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2406.12045_%CF%84-bench.html#experiments">5.Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2406.12045_%CF%84-bench.html#disscussion">6.Disscussion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html">2506.07982_ğœÂ²-Bench: Evaluating Conversational Agents in a Dual-Control Environment</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#tau-2-bench-evaluating-agents-in-a-dual-control-environment">3 <span class="math notranslate nohighlight">\(\tau^{2}\)</span>-bench: Evaluating Agents in a Dual-Control Environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#broader-impact">Broader Impact</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#appendix-a-telecom-domain">Appendix A Telecom Domain</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#appendix-b-verifying-original-tau-2-bench">Appendix B Verifying Original <span class="math notranslate nohighlight">\(\tau^{2}\)</span>-bench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#appendix-c-prompts">Appendix C Prompts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#appendix-d-domain-policies">Appendix D Domain Policies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#appendix-e-user-simulator-quality">Appendix E User Simulator Quality</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#qa">æ•°æ®é›†-QA</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_QAs/1809.09600_HotpotQA.html">1809.09600_HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/1809.09600_HotpotQA.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/1809.09600_HotpotQA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/1809.09600_HotpotQA.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/1809.09600_HotpotQA.html#data-collection">2 Data Collection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/1809.09600_HotpotQA.html#processing-and-benchmark-settings">3 Processing and Benchmark Settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/1809.09600_HotpotQA.html#dataset-analysis">4 Dataset Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/1809.09600_HotpotQA.html#experiments">5 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/1809.09600_HotpotQA.html#related-work">6 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/1809.09600_HotpotQA.html#conclusions">7 Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/1809.09600_HotpotQA.html#appendix-a-data-collection-details">Appendix A Data Collection Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/1809.09600_HotpotQA.html#a">é™„å½•A æ•°æ®æ”¶é›†ç»†èŠ‚</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/1809.09600_HotpotQA.html#appendix-b-further-data-analysis">Appendix B Further Data Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/1809.09600_HotpotQA.html#appendix-c-full-wiki-setting-details">Appendix C Full Wiki Setting Details</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html">2109.07958_TruthfulQA: Measuring How Models Mimic Human Falsehoods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#the-truthfulqa-benchmark">2 The TruthfulQA Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#experiments">3 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#results">4 Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#discussion">5 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#related-work">6 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#ethics-and-impact">8 Ethics and Impact</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#appendix-a-additional-examples-from-truthfulqa">Appendix A Additional examples from TruthfulQA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#appendix-b-additional-results">Appendix B Additional results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#appendix-c-dataset-construction">Appendix C Dataset construction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#appendix-d-human-evaluations">Appendix D Human evaluations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#appendix-e-prompts">Appendix E Prompts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#appendix-f-checking-for-data-quality-and-disagreement">Appendix F Checking for data quality and disagreement</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html">2311.12022_GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html#data-collection">2.Data Collection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html#dataset-analysis">3.Dataset Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html#baseline">4.Baseline</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html#related-work">5.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html#limitations">6.Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html#conclusion">7.Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2411.04368_SimpleQA.html">2411.04368_SimpleQA: Measuring short-form factuality in large language models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2411.04368_SimpleQA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2411.04368_SimpleQA.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2411.04368_SimpleQA.html#data-collection-and-verification">2.Data Collection and Verification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2411.04368_SimpleQA.html#measuring-calibration">4.Measuring calibration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2411.04368_SimpleQA.html#appendix-b-guessing-strategy-and-f-score">Appendix B Guessing strategy and F-score</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#id4">æ•°æ®é›†-ç¼–ç¨‹</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html">2107.03374_HumanEval: Evaluating Large Language Models Trained on Code</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#evaluation-framework">2.Evaluation Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#code-fine-tuning">3.Code Fine-Tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#supervised-fine-tuning">4.Supervised Fine-Tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#docstring-generation">5.Docstring Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#limitations">6.Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#broader-impacts-and-hazard-analysis">7.Broader Impacts and Hazard Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#related-work">8.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#conclusions">9.Conclusions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html">2108.07732_MBPP: Program Synthesis with Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#datasets">2 Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#model-and-methods">3 Model and Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#mbpp-synthesis-results">4 MBPP Synthesis Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#human-model-collaboration-results">5 Human-Model Collaboration Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#program-execution-results">6 Program Execution Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#mathqa-results">7 MathQA Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#related-work">8 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#risks-and-limitations">9 Risks and Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#conclusion">10 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#appendix-a-appendix">Appendix A Appendix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html">2310.06770_SWE-bench: Can Language Models Resolve Real-World GitHub Issues?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#id7">2 SWE-bench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#swe-llama-fine-tuning-codellama-for-swe-bench">3 SWE-Llama: Fine-tuning CodeLlama for SWE-bench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#experimental-setup">4 Experimental Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#results">5 Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#related-work">6 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#discussion">7 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#ethics-statement">8 Ethics Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#reproducibility-statement">9 Reproducibility Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#appendix-a-benchmark-details">Appendix A Benchmark Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#appendix-b-additional-details-on-training-swe-llama">Appendix B Additional Details on Training SWE-Llama</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#appendix-c-additional-results">Appendix C Additional Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#appendix-d-additional-experimental-details">Appendix D Additional Experimental Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#appendix-e-societal-impact">Appendix E Societal Impact</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#appendix-f-in-depth-analysis-of-swe-llama-generations">Appendix F In-depth Analysis of SWE-Llama Generations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html">2402.16694_HumanEval-XL: A Multilingual Code Generation Benchmark for Cross-lingual Natural Language Generalization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#a-multilingual-code-generation-benchmark-for-cross-lingual-natural-language-generalization">A Multilingual Code Generation Benchmark for Cross-lingual Natural Language Generalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#introduction">1.Â Â Â Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#related-work">2.Â Â Â Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#humaneval-xl">3.Â Â Â HumanEval-XL</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#experiments">4.Â Â Â Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#conclusion">5.Â Â Â Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#acknowledgments">Acknowledgments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#appendix-a-experiment-settings">Appendix A Experiment Settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#appendix-b-comprehensive-experiment-results">Appendix B Comprehensive Experiment Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html">2403.07974_LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#llm">LLMæ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#holistic-evaluation">2 Holistic Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#benchmark-curation">3 Benchmark Curation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#experiment-setup">4 Experiment Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#results">5 Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#related-work">6 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#limitations">7 Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#conclusion">8 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#appendix-a-dataset">Appendix A Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#appendix-b-ui">Appendix B UI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#appendix-c-experimental-setup">Appendix C Experimental Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#appendix-d-results">Appendix D Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#appendix-e-qualitative-examples">Appendix E Qualitative Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html">2407.10499_CIBench: Evaluating Your LLMs with a Code Interpreter Plugin</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#related-works">2 Related Works</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#cibench">3 CIBench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#appendix-a-dataset-details">Appendix A Dataset Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#appendix-b-construction-prompts-and-rules">Appendix B Construction Prompts and Rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#appendix-c-experiment-example-demo">Appendix C Experiment Example Demo</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#appendix-d-subjective-visualization-evaluation">Appendix D Subjective Visualization Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#appendix-e-dataset-error-analysis">Appendix E Dataset Error Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#appendix-f-human-annotator">Appendix F Human Annotator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#appendix-g-ethical-consideration">Appendix G Ethical Consideration</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html">2410.03859_SWE-bench-Multimodal: Do AI Systems Generalize to Visual Software Domains?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#swe-bench-multimodal">2 SWE-bench Multimodal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#evaluating-on-swe-bench-m">3 Evaluating on SWE-bench M</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#results">4 Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#related-work">5 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#appendix-a-dataset">Appendix A Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#appendix-b-collection">Appendix B Collection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#appendix-c-experiments">Appendix C Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#appendix-d-human-validation">Appendix D Human Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#appendix-e-limitations">Appendix E Limitations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html">2410.06992_SWE-Bench+: Enhanced Coding Benchmark for LLMs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html#robustness-analysis-of-swe-bench">2 Robustness Analysis of SWE-Bench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html#building-swe-bench">3 Building SWE-Bench+</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html#robustness-of-swe-bench">4 Robustness of SWE-Bench+</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html#effectiveness-aware-evaluation">5 Effectiveness-aware Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html#related-work">6 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html#conclusion">7 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html">2501.01257_CodeForces: Benchmarking Competition-level Code Generation of LLMs on CodeForces</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#codeforces-benchmark">3 CodeForces Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#evaluation-on-existing-llms">4 Evaluation on Existing LLMs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#analysis-experiments">5 Analysis Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#discussion">6 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#ethical-statement">8 Ethical Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#appendix-a-model-cards">Appendix A Model Cards</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#appendix-b-decoding-hyperparameters">Appendix B Decoding Hyperparameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#appendix-c-analysis-of-our-elo-rating-calculation-system">Appendix C Analysis of Our Elo Rating Calculation System</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#appendix-d-human-comparable-elo-rating">Appendix D Human-comparable Elo Rating</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#appendix-e-problem-demonstration">Appendix E Problem Demonstration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#appendix-f-special-judge">Appendix F Special Judge</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#id5">æ•°æ®é›†-é•¿æ–‡æœ¬</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html">2402.05136_LV-Eval: A Balanced Long-Context Benchmark with 5 Length Levels Up to 256K</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html#lv-eval-benchmark">3 LV-Eval Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html#evaluation">4 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html#appendix-c-detailed-evaluation-results">Appendix C Detailed Evaluation Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html#appendix-d-detailed-ablation-results">Appendix D Detailed Ablation Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.17753_LoCoMo.html">2402.17753_LoCoMo: Evaluating Very Long-Term Conversational Memory of LLM Agents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.17753_LoCoMo.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.17753_LoCoMo.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.17753_LoCoMo.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.17753_LoCoMo.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.17753_LoCoMo.html#generative-pipeline-for-locomo">3 Generative Pipeline for LoCoMo</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.17753_LoCoMo.html#locomo-evaluation-benchmark">4 LoCoMo Evaluation Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.17753_LoCoMo.html#experimental-setup">5 Experimental Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.17753_LoCoMo.html#experimental-results">6 Experimental Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.17753_LoCoMo.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.17753_LoCoMo.html#limitations">8 Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.17753_LoCoMo.html#broader-impacts">9 Broader Impacts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.17753_LoCoMo.html#appendix-overview">Appendix Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.17753_LoCoMo.html#appendix-a-generative-pipeline-for-locomo">Appendix A Generative Pipeline for LoCoMo</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.17753_LoCoMo.html#appendix-b-dataset">Appendix B Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.17753_LoCoMo.html#appendix-c-experimental-setup">Appendix C Experimental Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.17753_LoCoMo.html#appendix-d-results">Appendix D Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html">2404.06654_RULER: Whatâ€™s the Real Context Size of Your Long-Context Language Models?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#the-ruler-benchmark">3 The RulerÂ Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#experiments-results">4 Experiments &amp; Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#task-error-analysis">5 Task Error Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#model-analysis">6 Model Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#limitations">8 Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#appendix-a-models">Appendix A Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#appendix-b-task-configurations">Appendix B Task Configurations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#appendix-c-task-correlation-analysis">Appendix C Task Correlation Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#appendix-d-prompt-templates">Appendix D Prompt Templates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#appendix-e-passkey-retrieval-and-vanilla-niah-results">Appendix E Passkey Retrieval and Vanilla NIAH Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#appendix-f-additional-results">Appendix F Additional Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html">2407.11963_NeedleBench: Can LLMs Do Retrieval and Reasoning in Information-Dense Context</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#tasks-and-datasets">3 Tasks and Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#impact-of-language-which-model-performs-better-under-the-bilingual-scenario">4.1.5 Impact of Language_ Which Model Performs Better under the Bilingual Scenario_</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#conclusion-and-future-work">5 Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#appendix-a-evaluated-models">Appendix A Evaluated Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#appendix-b-needlebench-prompt-examples">Appendix B NeedleBenchÂ Prompt Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#appendix-c-error-analysis-examples">Appendix C Error Analysis Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#id6">æ•°æ®é›†-æ•°å­¦</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2103.03874_MATH.html">2103.03874_MATH: Measuring Mathematical Problem Solving With the MATH Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html">2110.14168_GSM8K: Training Verifiers to Solve Math Word Problems</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#dataset">2 Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#related-work">3 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#methods">4 Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#additional-experiments">5 Additional Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#appendix-a-dataset-details">Appendix A Dataset Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#appendix-b-hyperparameters">Appendix B Hyperparameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#appendix-c-calculator-annotations">Appendix C Calculator Annotations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#appendix-d-example-model-solutions">Appendix D Example Model Solutions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#appendix-e-verifier-details">Appendix E Verifier Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#appendix-f-verifier-visualization">Appendix F Verifier Visualization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html">2405.12209_MathBench: Evaluating the Theory and Application Proficiency of LLMs with a Hierarchical Mathematics Benchmark</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#methodology">2 Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#experiments-and-analysis">3 Experiments and Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#discussion">4 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#related-work">5 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#limitations">7 Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#ethical-considerations">8 Ethical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#appendix-a-mathbench-statistics">Appendix A MathBench Statistics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#appendix-b-detailed-experimental-results">Appendix B Detailed Experimental Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#appendix-c-extra-analysis">Appendix C Extra Analysis</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#id7">æ•°æ®é›†-å›¾ç‰‡</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Images/2306.13394_MME.html">2306.13394_MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2306.13394_MME.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2306.13394_MME.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2306.13394_MME.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2306.13394_MME.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2306.13394_MME.html#mme-evaluation-suite">2 MME Evaluation Suite</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2306.13394_MME.html#experiments">3 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2306.13394_MME.html#analysis">4 Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2306.13394_MME.html#conclusion">5 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html">2307.06281_MMBench: Is Your Multi-modal Model an All-around Player?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#the-construction-of-mmbench">3 The construction of MMBench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#evaluation-strategy">4 Evaluation Strategy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#evaluation-results">5 Evaluation Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#appendix-a-more-details-about-the-data">Appendix A More Details about the Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#appendix-b-more-details-on-mmbench-construction">Appendix B More Details on MMBench Construction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#appendix-c-more-details-on-llm-based-choice-extraction">Appendix C More Details on LLM-based Choice Extraction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#appendix-d-evaluation-settings-and-results">Appendix D Evaluation Settings and Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.16125_SEED-Bench.html">2307.16125_SEED-Bench: Benchmarking Multimodal LLMs with Generative Comprehension</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.16125_SEED-Bench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.16125_SEED-Bench.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.16125_SEED-Bench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.16125_SEED-Bench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.16125_SEED-Bench.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.16125_SEED-Bench.html#id7">3 SEED-Bench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.16125_SEED-Bench.html#evaluation-results">4 Evaluation Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.16125_SEED-Bench.html#conclusion">5 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html">2311.12793_ShareGPT4V: Improving Large Multi-Modal Models with Better Captions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#sharegpt4v-dataset">3 ShareGPT4V Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#sharegpt4v-7b-model">4 ShareGPT4V-7B Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#id11"><strong>4.1 æ¨¡å‹æ¶æ„</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#id12"><strong>4.2 é¢„è®­ç»ƒ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#sft"><strong>4.3 ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#id13"><strong>æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#experiments">5 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#appendix-a-data-sources">Appendix A Data Sources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#appendix-b-caption-analysis">Appendix B Caption Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#appendix-c-prompts">Appendix C Prompts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#appendix-d-examples">Appendix D Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html">2506.18095_ShareGPT-4o-Image: Aligning Multimodal Models with GPT-4o-Level Image Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#sharegpt-4o-image">2 ShareGPT-4o-Image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#janus-4o-fine-tuning-with-sharegpt-4o-image">3 Janus-4o: Fine-Tuning with ShareGPT-4o-Image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#conclusion">5 conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#appendix-a-related-work">Appendix A Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#appendix-b-image-generation-categories">Appendix B Image Generation Categories</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#appendix-c-prompts-for-generation">Appendix C Prompts for Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#appendix-d-document-pipeline">Appendix D Document Pipeline</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#appendix-e-ethical-considerations-and-societal-impact">Appendix E Ethical Considerations and Societal Impact</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#id8">æ•°æ®é›†</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Datasets/0normal.html">é€šç”¨</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/0normal.html#id2">è¯„æµ‹æ ‡å‡†</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/0normal.html#accuracy">å‡†ç¡®ç‡(Accuracy)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/0normal.html#precision">ç²¾ç¡®ç‡(Precision, ç²¾å‡†ç‡)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/0normal.html#recall">å¬å›ç‡(Recall)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/0normal.html#f1-score">F1 Score</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/0normal.html#id3">å¯è§†åŒ–ç²¾åº¦å’Œå¬å›ç‡</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Datasets/2009.03300_MMLU.html">2009.03300_MMLU: Measuring Massive Multitask Language Understanding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2009.03300_MMLU.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2009.03300_MMLU.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2009.03300_MMLU.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2009.03300_MMLU.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2009.03300_MMLU.html#a-multitask-test">3.A Multitask Test</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2009.03300_MMLU.html#experiments">4.Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2009.03300_MMLU.html#discussion">5.Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2009.03300_MMLU.html#conclusion">6.Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html">2305.08322_C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#id2">C-Eval_ A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#the-c-eval-evaluation-suite">2 The C-EvalÂ Evaluation Suite</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#experiment">3 Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#related-work">4 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#discussion">5 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#acknowledgement">Acknowledgement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#appendix-a-author-contributions">Appendix A Author Contributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#appendix-b-detailed-stats-of-c-eval">Appendix B Detailed Stats of C-Eval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#appendix-c-explanation-data-generation">Appendix C Explanation Data Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#appendix-d-evaluation-prompts">Appendix D Evaluation Prompts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#appendix-e-details-of-the-models-being-evaluated">Appendix E Details of the models being evaluated</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#appendix-f-breakdown-of-model-performance">Appendix F Breakdown of Model Performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#appendix-g-option-bias">Appendix G Option Bias</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#appendix-h-compute-and-resources-used-for-evaluation">Appendix H Compute and Resources Used for Evaluation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html">2306.09212_CMMLU: Measuring massive multitask language understanding in Chinese</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#cmmlu">3 CMMLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#impact-of-model-size-on-performance">Impact of model size on performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-a-comparison-to-concurrent-benchmarks">Appendix A Comparison to concurrent benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-b-cmmlu-subjects">Appendix B CMMLU Subjects</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-c-cmmlu-examples">Appendix C CMMLU Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-d-cmmlu-difficulty-distribution">Appendix D CMMLU Difficulty Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-e-emergent-ability-shown-in-cmmlu-subjects">Appendix E Emergent Ability shown in CMMLU subjects</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-f-models-being-evaluated">Appendix F Models being Evaluated</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-g-strategies-for-estimating-model-choices">Appendix G Strategies for Estimating Model Choices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-h-regular-expressions-matching-algorithmsl">Appendix H Regular expressions matching algorithmsl</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-i-correlation-to-other-benchmarks">Appendix I Correlation to other Benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-j-breakdown-of-model-performance">Appendix J Breakdown of Model Performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#j-3-the-effect-of-chain-of-thought-prompt">J.3 The effect of chain-of-thought prompt</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html">2307.15020_SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#superclue-benchmark">3 SuperCLUE Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#additional-analysis">5 Additional Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#appendix-a-evaluation-process">Appendix A Evaluation Process</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#appendix-b-capability-categories">Appendix B Capability Categories</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html">2311.12983_GAIA: a benchmark for General AI Assistants</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#related-work">2.Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#id4">3.GAIA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#llms-results-on-gaia">4.LLMs results on GAIA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#discussion">5.Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#limitations">6.Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#appendix-a-extended-related-work">Appendix A Extended related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#appendix-c-extended-description-of-gaia">Appendix C Extended description of GAIA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#appendix-d-extended-description-of-our-question-design-framework">Appendix D Extended description of our question design framework</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html">2404.07972_OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#id2">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#osworld-environment">2. OSWORLD Environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#osworld-benchmark">3. OSWORLD Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#benchmarking-llm-and-vlm-agent-baselines">4. Benchmarking LLM and VLM Agent Baselines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#analysis">5. Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#related-work">6. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#conclusion-and-future-work">7. Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#a-details-of-osworld-environment">A. Details of OSWORLD Environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#c-details-of-baseline-methods">C. Details of Baseline Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#d-examples-of-qualitative-analysis">D. Examples of Qualitative Analysis</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Datasets/2501.14249_HLE.html">2501.14249_HLE: Humanityâ€™s Last Exam</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2501.14249_HLE.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2501.14249_HLE.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2501.14249_HLE.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2501.14249_HLE.html#dataset">3.Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2501.14249_HLE.html#evaluation">4.Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2501.14249_HLE.html#discussion">5.Discussion</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM.html">LLM æ¨¡å‹</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../LLM.html#nlp">NLP æ¨¡å‹</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/1810.04805_BERT.html">1810.04805_BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/1810.04805_BERT.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/1810.04805_BERT.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/1810.04805_BERT.html#bert">3 BERT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/1810.04805_BERT.html#appendix-a-additional-details-for-bert">Appendix A Additional Details for BERT</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html">18xx_GPT1: Improving Language Understanding by Generative Pre-Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#framework">3. Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#analysis">5 Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#id3">å¼•æ–‡å£ç¢‘</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#id4">è¦ç‚¹è§£è¯»</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/19_GPT2.html">19xx_GPT2: Language Models are Unsupervised Multitask Learners</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/19_GPT2.html#the-illustrated-gpt-2">The Illustrated GPT-2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/19_GPT2.html#id2">å‚è€ƒ</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2012.00413_CPM.html">2012.00413_CPM: A Large-scale Generative Chinese Pre-trained Language Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2302.13971_LLaMA.html">2302.13971_LLaMA: Open and Efficient Foundation Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2307.09288_Llama2.html">2307.09288_Llama 2: Open Foundation and Fine-Tuned Chat Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html">2309.16609_Qwen Technical Report</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#pretraining">2. Pretraining</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#alignment">3. Alignment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#code-qwen-specialized-model-for-coding">4. CODE-QWEN: SPECIALIZED MODEL FOR CODING</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#math-qwen-specialized-model-for-mathematics-reasoning">5. MATH-QWEN: SPECIALIZED MODEL FOR MATHEMATICS REASONING</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#related-work">6. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#conclusion">7. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#a-1-more-training-details">A.1 MORE TRAINING DETAILS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#a-2-evaluation">A.2 EVALUATION</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html">2310.19341_Skywork: A More Open Bilingual Foundation Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#methodology">2 Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#pre-training">3 Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#evaluation">4 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#discussion">5 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#limitation">6 Limitation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#appendix-a-details-on-gpt-7b-vs-llama-7b-experiment">Appendix A Details on GPT-7B vs. LLaMA-7B Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#appendix-b-preliminary-experiments-on-distributed-training">Appendix B Preliminary Experiments on Distributed Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#appendix-c-more-benchmark-results">Appendix C More Benchmark Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#appendix-d-details-on-lm-test-sets">Appendix D Details on LM Test Sets</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2401.14196_DeepSeek-Coder.html">2401.14196_DeepSeek-Coder: When the Large Language Model Meets Programming â€“ The Rise of Code Intelligence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2404.06395_MiniCPM.html">2404.06395_MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2404.06395_MiniCPM.html#two-stage-pre-training-strategy">5. Two Stage Pre-training Strategy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2404.06395_MiniCPM.html#model">6. Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2404.06395_MiniCPM.html#minicpm-family">7 MiniCPM Family</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2405.04434_DeepSeek-V2.html">2405.04434_DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2406.12793_ChatGLM.html">2406.12793_ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html">2407.10671_Qwen2 Technical Report</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html#tokenizer-model">2. Tokenizer &amp; Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html#pre-training">3. Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html#post-training">4. Post-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html">2412.15115_Qwen2.5</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html#architecture-and-tokenizer">2. Architecture and Tokenizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html#pre-training">3. Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html#post-training">4. Post-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2505.09388_Qwen3.html">2505.09388_Qwen3</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2505.09388_Qwen3.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2505.09388_Qwen3.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2505.09388_Qwen3.html#architecture">2. Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2505.09388_Qwen3.html#pre-training">3. Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2505.09388_Qwen3.html#post-training">4. Post-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2505.09388_Qwen3.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM.html#id2">å¤šæ¨¡æ€æ¨¡å‹</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html">2112.15093_CTR: Benchmarking Chinese Text Recognition: Datasets, Baselines, and an Empirical Study</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#preliminaries">2. Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#datasets">3. Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#baselines">4. Baselines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#an-empirical-study">5. An Empirical Study</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#conclusions">6. Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#appendix-a-details-of-prab">Appendix A Details of PRAB</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#appendix-c-visualization-of-failure-cases">Appendix C Visualization of Failure Cases.</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html">2304.08485_LLaVA: Visual Instruction Tuning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html#gpt-assisted-visual-instruction-data-generation">3. GPT-assisted Visual Instruction Data Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html#visual-instruction-tuning">4. Visual Instruction Tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2308.12966_Qwen-VL.html">2308.12966_Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2308.12966_Qwen-VL.html#methodology">Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2308.12966_Qwen-VL.html#training">Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2308.12966_Qwen-VL.html#evaluation">Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2308.12966_Qwen-VL.html#b-data-format-details-of-training">B. Data Format Details of Training</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html">2310.03744_LLaVA2: Improved Baselines with Visual Instruction Tuning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#approach">3. Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#empirical-evaluation">4. Empirical Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#open-problems-in-lmms">5. Open Problems in LMMs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#a-implementation-details">A. Implementation Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#b-qualitative-results">B. Qualitative Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html">2312.07533_VILA: On Pre-training for Visual Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html#on-pre-training-for-visual-language-models">3. On Pre-training for Visual Language Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2403.05525_DeepSeek-VL.html">2403.05525_DeepSeek-VL: Towards Real-World Vision-Language Understanding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2403.05525_DeepSeek-VL.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html">2408.01800_MiniCPM-V: A GPT-4V Level MLLM on Your Phone</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#model-architecture">3. Model Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#training">4. Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#end-side-deployment">5. End-side Deployment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#experiments">6. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#conclusion">7. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html">2409.17146_Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Vision-Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#architecture">2. Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#data">3. Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#training">4. Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#ablations">6. Ablations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-a-model-details">Appendix A: Model Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-b-training-details">Appendix B: Training Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-c-evaluation-results">Appendix C: Evaluation Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-d-result-details">Appendix D: Result Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-e-ablations-details">Appendix E Ablations Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-f-data-details">Appendix F Data Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-g-dataset-examples">Appendix G Dataset Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-h-related-work">Appendix H Related Work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html">2410.13848_Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#llm">LLMæ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#janus-a-simple-unified-and-flexible-multimodal-framework">3 Janus: A Simple, Unified and Flexible Multimodal Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#appendix-a-details-of-semantic-tokenizer-mentioned-in-ablation-study">Appendix A Details of Semantic Tokenizer Mentioned in Ablation Study</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#appendix-b-additional-qualitative-results">Appendix B Additional Qualitative Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2411.00774_Freeze-Omni.html">2411.00774_Freeze-Omni: A Smart and Low Latency Speech-to-speech Dialogue Model with Frozen LLM</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2411.00774_Freeze-Omni.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2411.00774_Freeze-Omni.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2411.00774_Freeze-Omni.html#model">2. Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2411.00774_Freeze-Omni.html#experience">3. Experience</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2411.00774_Freeze-Omni.html#conclusion-and-future-work">4. Conclusion and Future Work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html">2412.04468_NVILA: Efficient Frontier Visual Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html#approach">2. Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html#more-capabilities">4. More Capabilities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2502.13923_Qwen2.5-VL.html">2502.13923_Qwen2.5-VL</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2502.13923_Qwen2.5-VL.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2502.13923_Qwen2.5-VL.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2502.13923_Qwen2.5-VL.html#approach">2. Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2502.13923_Qwen2.5-VL.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2502.13923_Qwen2.5-VL.html#conclusion">4. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html">2503.20215_Qwen2.5-Omni Technical Report</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#archtecture">2. Archtecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#id2">3 é¢„è®­ç»ƒ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#post-training">4 åè®­ç»ƒï¼ˆPost-trainingï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html">2506.13642_Stream-Omni: Simultaneous Multimodal Interactions with Large Language-Vision-Speech Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#id4">3. Stream-Omni</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#results-and-analyses">5. Results and Analyses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#appendix-a-construction-of-instructomni">Appendix A Construction of InstructOmni</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#appendix-b-construction-of-spokenvisit">Appendix B Construction of SpokenVisIT</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html">2506.13642_Stream-Omni: Simultaneous Multimodal Interactions with Large Language-Vision-Speech Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#id9">3 Stream-Omni</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#data-construction">3.2.1 Data Construction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#results-and-analyses">5 Results and Analyses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#limitations">Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#appendix-a-construction-of-instructomni">Appendix A Construction of InstructOmni</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#appendix-b-construction-of-spokenvisit">Appendix B Construction of SpokenVisIT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#appendix-c-case-study">Appendix C Case Study</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM.html#id3">LLM éŸ³é¢‘</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2005.08100_Conformer.html">2005.08100_Conformer: Convolution-augmented Transformer for Speech Recognition</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2005.08100_Conformer.html#llm">LLMæ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2005.08100_Conformer.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2005.08100_Conformer.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2005.08100_Conformer.html#conformer-encoder">2 Conformer Encoder</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2005.08100_Conformer.html#experiments">3 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2005.08100_Conformer.html#conclusion">4 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html">2106.07447_HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#i-introduction">I Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#ii-method">II Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#iii-related-work">III Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#iv-experimental-details">IV Experimental Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#v-results">V Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#vi-conclusion">VI Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html">2112.02418_YourTTS: Towards Zero-Shot Multi-Speaker TTS and Zero-Shot Voice Conversion for everyone</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#id1">å…³é”®æ¦‚å¿µ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#yourtts-model">2. YourTTS Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#results-and-discussion">4. Results and Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#zero-shot-voice-conversion">5. Zero-Shot Voice Conversion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#speaker-adaptation">6. Speaker Adaptation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#conclusions-limitations-and-future-work">7. Conclusions, limitations and future work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html">2212.04356_whisper: Robust Speech Recognition via Large-Scale Weak Supervision</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#approach">2. Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#analysis-and-ablations">4. Analysis and Ablations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#limitations-and-future-work">6. Limitations and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#conclusions">7. Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#a-evaluation-datasets">A. Evaluation Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#b-compared-models">B Compared Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#c-text-standardization">C. Text Standardization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html">2301.02111_Vall-E: Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html#background-speech-quantization">3. Background: Speech Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html#id9">4. VALL-E</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html#conclusion-limitations-and-future-work">6. Conclusion, Limitations, and Future Work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html">2303.03926_VALL-E_X: Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural Codec Language Modeling</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#cross-lingual-codec-language-model">3 Cross-Lingual Codec Language Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#vall-e-x-application">4. VALL-E X Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#a-appendix">A. Appendix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2406.05370_VALL-E2.html">2406.05370_VALL-E2: Neural Codec Language Models are Human Parity Zero-Shot Text to Speech Synthesizers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2406.05370_VALL-E2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2406.05370_VALL-E2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2406.05370_VALL-E2.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2406.05370_VALL-E2.html#id5">3. VALL-E 2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2406.05370_VALL-E2.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2406.05370_VALL-E2.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2407.05407_CosyVoice.html">2407.05407_CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.05407_CosyVoice.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.05407_CosyVoice.html#instructions">1. Instructions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.05407_CosyVoice.html#cosyvoice-a-scalable-tts-model-using-supervised-semantic-tokens">2. CosyVoice: A Scalable TTS model using Supervised Semantic Tokens</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.05407_CosyVoice.html#dataset">3. Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.05407_CosyVoice.html#experimental-settings">4. Experimental Settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.05407_CosyVoice.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2407.10759_Qwen2-Audio.html">2407.10759_Qwen2-Audio Technical Report</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.10759_Qwen2-Audio.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.10759_Qwen2-Audio.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.10759_Qwen2-Audio.html#methodology">2. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.10759_Qwen2-Audio.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.10759_Qwen2-Audio.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html">2410.00037_Moshi: a speech-text foundation model for real-time dialogue</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#model">3.Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#datasets-and-training">4. Datasets and Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#safety">6.Safety</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#conclusion">7.Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2412.10117_CosyVoice2.html">2412.10117_CosyVoice2: Scalable Streaming Speech Synthesis with Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2412.10117_CosyVoice2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2412.10117_CosyVoice2.html#instroduction">1. Instroduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2412.10117_CosyVoice2.html#id5">2. CosyVoice 2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2412.10117_CosyVoice2.html#experimental-settings">3. Experimental Settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2412.10117_CosyVoice2.html#experimental-results">4. Experimental Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2412.10117_CosyVoice2.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html">2501.06282_MinMo: A Multimodal Large Language Model for Seamless Voice Interaction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#instruction">1.Instruction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#id9">3.MinMo</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#experiments">4.Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#conclusion">5.Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#limitations">6.Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#a-prompts-for-voice-understanding-tasks">A. Prompts for Voice Understanding Tasks</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2505.02707_Voila.html">2505.02707_Voila: Voice-Language Foundation Models for Real-Time Autonomous Interaction and Voice Role-Play</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.02707_Voila.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.02707_Voila.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.02707_Voila.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.02707_Voila.html#voila-voice-language-foundation-models">3. Voila: Voice-Language Foundation Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.02707_Voila.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.02707_Voila.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html">2505.17589_CosyVoice3: Towards In-the-wild Speech Generation via Scaling-up and Post-training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#id3">2.CosyVoice 3</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#the-multilingual-data-pipeline">3.The Multilingual Data Pipeline</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#experimental-settings">4.Experimental Settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#experimental-results">5.Experimental Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#conclusion">6.Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#limitations">7.Limitations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM.html#id4">LLM è§†é¢‘</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html">2301.12597_BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#bootstrapping-language-image-pre-training-with-frozen-image-encoders-and-large-language-models">Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#method">3 Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#experiment">4 Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#limitation">5 Limitation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#conclusion">6 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html">2308.01390_OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#id1">OpenFlamingo_ An Open-Source Framework for Training Large Autoregressive Vision-Language Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#related-work">2 Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#approach">3 Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#results">4 Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#discussion">5 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#appendix-a-extended-results">Appendix A Extended results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#appendix-b-additional-notes-on-filtering-mmc4">Appendix B Additional notes on filtering MMC4</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#appendix-c-synthetic-data-prompt">Appendix C Synthetic data prompt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#appendix-d-image-credits">Appendix D Image credits</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM.html#llm-moe">LLM MoE</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMoEs/2408.15664_AUXILIARY-LOSS-FREE_LB.html">2408.15664_AUXILIARY-LOSS-FREE LOAD BALANCING STRATEGY FOR MIXTURE-OF-EXPERTS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMoEs/2410.07490_MoDEM.html">2410.07490_MoDEM: Mixture of Domain Expert Models</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM.html#id5">å•†ä¸šæ¨¡å‹</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2303.08774_GPT4.html">2303.08774_GPT-4 Technical Report</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html">2312.11805_Gemini: A Family of Highly Capable Multimodal Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#model-architecture">2. Model Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#training-infrastructure">3. Training Infrastructure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#post-training-models">6. Post-Training Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#responsible-deployment">7. Responsible Deployment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#discussion-and-conclusion">8. Discussion and Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2403.05530_Gemini1.5.html">2403.05530_Gemini1.5: Unlocking multimodal understanding across millions of tokens of context</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html">2406.02430_Seed-TTS: A Family of High-Quality Versatile Speech Generation Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#method">2 Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#experiments">3 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#model-extensions">4 Model extensions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#model-applications-limitations-and-safety">5 Model applications, limitations, and safety</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#authors-alphabetical-order">6 Authors (alphabetical order)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#acknowledgement">7 Acknowledgement</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html">2407.04675_Seed-ASR: Understanding Diverse Speech and Contexts with LLM-based Speech Recognition</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html#motivation">2 Motivation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html#methods">3 Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html#model-and-evaluation">4 Model and Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html#appendix-a-appendix">Appendix A Appendix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2503.20020_Gemini2.html">2503.20020_Gemini2: Gemini Robotics: Bringing AI into the Physical World</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2504.xxxxx_Seed-Thinking-v1.5.html">2504.xxxxx_Seed-Thinking-v1.5: Advancing Superb Reasoning Models with Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html">2505.07062_Seed1.5-VL Technical Report</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#id1">Seed1.5-VL Technical Report</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#architecture">2 Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#pre-training">3 Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#training-recipe">3.2 Training Recipe</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#post-training">4 Post-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#hybrid-reinforcement-learning">4.4 Hybrid Reinforcement Learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#training-infrastructure">5 Training Infrastructure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#evaluation">6 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#video-task-evaluation">6.1.3 Video Task Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#comparison-with-state-of-the-arts">6.3.2 Comparison with State-of-the-arts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#conclusion-and-next-steps">7 Conclusion and Next Steps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#contributions-and-acknowledgments">8 Contributions and Acknowledgments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#qualitative-examples">9 Qualitative examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#visual-reasoning-visual-pattern-recognition">9.7 Visual Reasoning_ Visual Pattern Recognition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#failure-cases-combinatorial-search-i">9.19 Failure Cases_ Combinatorial Search I</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#evaluation-details">10 Evaluation Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#dream-1k">DREAM-1K</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM_tech.html">LLM å‘¨è¾¹æŠ€æœ¯</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#framework">Framework</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html">1712.05889_Ray: A Distributed Framework for Emerging AI Applications</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#motivation-and-requirements">2. Motivation and Requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#programming-and-computation-model">3. Programming and Computation Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#architecture">4. Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#related-work">6 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#discussion-and-experiences">7 Discussion and Experiences</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#conclusion">8. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html">1910.02054_DeepSpeed_ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#extended-introduction">1. Extended Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#where-did-all-the-memory-go">3 Where Did All the Memory Go?</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#zero-insights-and-overview">4 ZeRO: Insights and Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#deep-dive-into-zero-dp">5 Deep Dive into ZeRO-DP</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#deep-dive-into-zero-r">6 Deep Dive into ZeRO-R</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#communication-analysis-of-zero-dp">7 Communication Analysis of ZeRO-DP</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#communication-analysis-of-zero-r">8. Communication Analysis of ZeRO-R</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#step-towards-1-trillion-parameters">9. Step Towards 1 Trillion Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#implementation-and-evaluation">10. Implementation and Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#concluding-remarks">11. Concluding Remarks</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Frameworks/19XX_PyTorch.html">PyTorch: An Imperative Style, High-Performance Deep Learning Library</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Frameworks/20XX_Transformers.html">Transformers: State-of-the-Art Natural Language Processing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html">2210.XX_Ray v2 Architecture</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#architecture-overview">Architecture Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#object-management">Object Management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#task-management">Task Management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#resource-management-and-scheduling">Resource Management and Scheduling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#actor-management">Actor management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#global-control-service">Global Control Service</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#cluster-management">Cluster Management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#appendix">Appendix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html">2309.06180_vLLM: Efficient Memory Management for Large Language Model Serving with PagedAttention</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#id2">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#memory-challenges-in-llm-serving">3. Memory Challenges in LLM Serving</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#method">4. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#implementation">5. Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#evaluation">6. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#ablation-studies">7. Ablation Studies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#conclusion">10. Conclusion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#id2">å¤§æ¨¡å‹è°ƒä¼˜</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2101.00190_Prefix-Tuning.html">2101.00190_Prefix-Tuning: Optimizing Continuous Prompts for Generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2103.10385_p-tuning.html">2103.10385_p-tuning: GPT Understands, Too</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2104.08691_Prompt_Tuning.html">2104.08691_Prompt Tuning: The Power of Scale for Parameter-Efficient Prompt Tuning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2106.09685_LoRA.html">2106.09685_LoRA: Low-Rank Adaptation of Large Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2401.01335_Self-Play.html">2401.01335_Self-Play: Fine-Tuning Converts Weak Language Models to Strong Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2402.09353_DoRA.html">2402.09353_DoRA: Weight-Decomposed Low-Rank Adaptation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2402.12354_LoRA%2B.html">2402.12354_LoRA+: Efficient Low Rank Adaptation of Large Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2403.03507_GaLore.html">2403.03507_GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2403.13372_LlamaFactory.html">2403.13372_LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/FineTunes/2403.13372_LlamaFactory.html#id2">ç«äº‰æ¡†æ¶</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/FineTunes/2403.13372_LlamaFactory.html#efficient-fine-tuning-techniques">3. Efficient Fine-Tuning Techniques</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/FineTunes/2403.13372_LlamaFactory.html#llamafactory-framework">4 LlamaFactory Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/FineTunes/2403.13372_LlamaFactory.html#conclusion-and-future-work">6 Conclusion and Future Work</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#id3">åˆ†å¸ƒå¼æ¨¡å‹</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/1701.06538_MoE.html">1701.06538_MoE: Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/1806.03377_PipeDream.html">1806.03377_PipeDream: Fast and Efficient Pipeline Parallel DNN Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1806.03377_PipeDream.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1806.03377_PipeDream.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1806.03377_PipeDream.html#background-related-work">2. Background &amp; Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1806.03377_PipeDream.html#parallel-training-in-pipedream">3. Parallel Training in PipeDream</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1806.03377_PipeDream.html#implementation">4. Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1806.03377_PipeDream.html#evaluation">5. Evaluation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html">1811.06965_GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html#id2">æ”¶é›†</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html#the-gpipe-library">2. The GPipe Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html#performance-analyses">3. Performance Analyses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html#image-classification">4. Image Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html#massive-massively-multilingual-machine-translation">5. Massive Massively Multilingual Machine Translation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html#design-features-and-trade-offs">6. Design Features and Trade-Offs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/1909.08053_Megatron-LM.html">1909.08053_Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1909.08053_Megatron-LM.html#id2">æ”¶é›†</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1909.08053_Megatron-LM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1909.08053_Megatron-LM.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1909.08053_Megatron-LM.html#background-and-challenges">2. Background and Challenges</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1909.08053_Megatron-LM.html#model-parallel-transformers">3. Model Parallel Transformers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html">19xx_PipeDream: Generalized Pipeline Parallelism for DNN Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html#id2">æ”¶é›†</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html#abstract">ABSTRACT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html#background-and-related-work">2. BACKGROUND AND RELATED WORK</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html#pipeline-parallelism">3. æµæ°´çº¿å¹¶è¡Œ(PIPELINE PARALLELISM)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html#id5">4. å®ç°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html#id6">6. ç»“è®º</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/2006.09503_PipeDream-2BW.html">2006.09503_PipeDream-2BW: Memory-Efficient Pipeline-Parallel DNN Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2006.09503_PipeDream-2BW.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/2006.15704DataParallel.html">2006.15704_PyTorch Distributed: Experiences on Accelerating Data Parallel Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/2006.16668_GShard.html">2006.16668_GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/2104.04473_Megatron-LM2.html">2104.04473_Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2104.04473_Megatron-LM2.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html">2205.14135_FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#background">2 Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#flashattention-algorithm-analysis-and-extensions">3. FLASHATTENTION: Algorithm, Analysis, and Extensions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#limitations-and-future-directions">5. Limitations and Future Directions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#appendix-a-related-work">Appendix A Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#appendix-b-algorithm-details">Appendix B Algorithm Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#appendix-c-proofs">Appendix C Proofs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#appendix-d-extension-details">Appendix D Extension Details</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/2307.08691_FlashAttention2.html">2307.08691_FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2307.08691_FlashAttention2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2307.08691_FlashAttention2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2307.08691_FlashAttention2.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2307.08691_FlashAttention2.html#flashattention-2-algorithm-parallelism-and-work-partitioning">3. FlashAttention-2: Algorithm, Parallelism, and Work Partitioning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2307.08691_FlashAttention2.html#empirical-validation">4. Empirical Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2307.08691_FlashAttention2.html#discussion-and-future-directions">5. Discussion and Future Directions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/normal.html">é€šç”¨</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#id4">LLM é‡åŒ–</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/0normal.html">é€šç”¨</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/0normal.html#id2">æ··åˆç²¾åº¦</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/0normal.html#id3">æµ®ç‚¹æ•°æ ¼å¼</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/0normal.html#weight-only-quantization">weight-only quantization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2110.02861_bitsandbytes.html">2110.02861_bitsandbytes: 8-bit Optimizers via Block-wise Quantization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2110.02861_bitsandbytes.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2110.02861_bitsandbytes.html#background">1. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2110.02861_bitsandbytes.html#bit-optimizers">2. 8-bit Optimizers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2110.02861_bitsandbytes.html#bit-vs-32-bit-optimizer-performance-for-common-benchmarks">3. 8-bit vs 32-bit Optimizer Performance for common Benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2110.02861_bitsandbytes.html#analysis">4. Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2110.02861_bitsandbytes.html#related-work">5. Related Work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html">2206.01861_ZeroQuant: Efficient and Affordable Post-Training Quantization for Large-Scale Transformers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#relative-work">2. Relative Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#background-and-challenges">3. Background and Challenges</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#methodology">4. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#results">5. Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#conclusions">6. Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#appendix-a-background">Appendix A Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#appendix-d-details-about-system-optimization">Appendix D Details about System Optimization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html">2206.09557_LUT-GEMM: Quantized Matrix Multiplication based on LUTs for Efficient Inference in Large-Scale Generative Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#instructions">1. Instructions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#design-methodology-of-lut-gemm">3. Design Methodology of LUT-GEMM</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#experimental-results">4. Experimental results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#accelerating-quantized-opt-175b">5. Accelerating Quantized OPT-175B</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#appendix-a-llm-inference-latency-breakdown">Appendix A LLM Inference Latency Breakdown</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#appendix-b-detailed-implementation">Appendix B Detailed Implementation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html">2208.07339_LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#id1">ç›¸å…³å‚è€ƒ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#int8-matrix-multiplication-at-scale">3. Int8 Matrix Multiplication at Scale</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#emergent-large-magnitude-features-in-transformers-at-scale">4. Emergent Large Magnitude Features in Transformers at Scale</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#discussion-and-limitations">6. Discussion and Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#broader-impacts">7. Broader Impacts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#id17">å…¶ä»–</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html">2209.05433_FP8: FP8 Formats For Deep Learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html#aspects-of-fp8-usage-in-deep-learning">2. Aspects of FP8 Usage in Deep Learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html#fp8-binary-interchange-format">3. FP8 Binary Interchange Format</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html#id3">ç¤ºä¾‹è®²è§£</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html#empirical-results">4. Empirical Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html#conclusions">5. Conclusions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html">2210.17323_GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html#background">3. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html#the-gptq-algorithm">4. The GPTQ Algorithm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html#experimental-validation">5. Experimental Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html#summary-and-limitations">6. Summary and Limitations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html">2211.10438_SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#preliminaries">2. Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#review-of-quantization-difficulty">3. Review of Quantization Difficulty</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#id9">4. SmoothQuant</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#related-work">6. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#conclusion">7. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#appendix-a-discussion-on-weight-only-quantization">Appendix A. Discussion on Weight-Only Quantization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html">2305.14314_QLoRA: Efficient Finetuning of Quantized LLMs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#id1">å…³é”®è¯</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#qlora-finetuning">3. QLoRA Finetuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#qlora-vs-standard-finetuning">4. QLoRA vs. Standard Finetuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#pushing-the-chatbot-state-of-the-art-with-qlora">5. Pushing the Chatbot State-of-the-art with QLoRA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#qualitative-analysis">6. Qualitative Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#related-work">7. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#limitations-and-discussion">8. Limitations and Discussion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html">2306.00978_AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html#awq-activation-aware-weight-quantization">3. AWQ: Activation-aware Weight Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html#tinychat-mapping-awq-onto-edge-platforms">4. TinyChat: Mapping AWQ onto Edge Platforms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2309.05516_AutoRound.html">2309.05516_AutoRound: Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2309.05516_AutoRound.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2309.05516_AutoRound.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2309.05516_AutoRound.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2309.05516_AutoRound.html#methodology">3. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2309.05516_AutoRound.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2309.05516_AutoRound.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#id5">LLM å®‰å…¨</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Securitys/2312.06674_Llama_Guard.html">2312.06674_Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#id6">LLMå¼ºåŒ–å­¦ä¹ </a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/RLs/1703.03864_EvolutionStrategies.html">1703.03864_Evolution Strategies: as a Scalable Alternative to Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html">2504.02495_DeepSeek-GRM: Inference-Time Scaling for Generalist Reward Modeling</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#preliminaries">2. Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#self-principled-critique-tuning-spct">3. Self-Principled Critique Tuning (SPCT)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#inference-time-scaling-with-spct">4. Inference-Time Scaling with SPCT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#results-on-reward-modeling-benchmarks">5. Results on Reward Modeling Benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#related-work">6. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#conclusion-and-future-work">7. Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#a-additional-related-work">A. Additional Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#b-limitations-and-future-directions">B. Limitations and Future Directions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#g-prompt-templates">G. Prompt Templates</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/RLs/2504.13958_ToolRL.html">2504.13958_ToolRL: Reward is All Tool Learning Needs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#id7">å…¶ä»–</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html">2203.02155_Training language models to follow instructions with human feedback(InstructGPT)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#related-work">2. Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#methods-and-experimental-details">3. Methods and experimental details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#results">4. Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#discussion">5. Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#appendix-a-additional-prompt-data-details">Appendix A Additional prompt data details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#appendix-b-additional-human-data-collection-details">Appendix B Additional human data collection details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#appendix-c-additional-model-details">Appendix C Additional model details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#appendix-d-automatic-evaluation-details">Appendix D Automatic evaluation details</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/others/2305.20050_LetsVerifyStepbyStep.html">2305.20050_Letâ€™s Verify Step by Step</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2305.20050_LetsVerifyStepbyStep.html#id2">1. ç ”ç©¶èƒŒæ™¯</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2305.20050_LetsVerifyStepbyStep.html#id3">2. ç›‘ç£æ–¹æ³•å¯¹æ¯”</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2305.20050_LetsVerifyStepbyStep.html#id4">3. æ ¸å¿ƒå‘ç°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2305.20050_LetsVerifyStepbyStep.html#id5">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/others/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html">2408.03314_Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html#how-to-scale-test-time-computation-optimally">3. How to Scale Test-Time Computation Optimally</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html#scaling-test-time-compute-via-verifiers">5. Scaling Test-Time Compute via Verifiers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html#refining-the-proposal-distribution">6. Refining the Proposal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html#id7">å…¶ä»–</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html">2412.14135_Scaling of Search and Learning: A Roadmap to Reproduce o1 from Reinforcement Learning Perspective</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#fromgpt">FromGPT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#id2">3. Policy Initialization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#id3">4. Reward Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#id5">5. Search</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#id8">6. Learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#open-source-o1-project">7 Open-source o1 Project</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#future-directions">8. Future Directions</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../ML.html">æœºå™¨å­¦ä¹ </a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../ML.html#ml-vision">ML Vision</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/1506.02640_YOLO.html">1506.02640_You Only Look Once: Unified, Real-Time Object Detection</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/1506.02640_YOLO.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/1612.08242_YOLO9000.html">1612.08242_YOLO9000: Better, Faster, Stronger</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/1612.08242_YOLO9000.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/1804.02767_YOLOv3.html">1804.02767_YOLOv3</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2004.10934_YOLOv4.html">2004.10934_YOLOv4: Optimal Speed and Accuracy of Object Detection</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2004.10934_YOLOv4.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2205.00159_SVTR.html">2205.00159_SVTR: Scene Text Recognition with a Single Visual Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2205.00159_SVTR.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2205.00159_SVTR.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2205.00159_SVTR.html#method">2. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2205.00159_SVTR.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2205.00159_SVTR.html#conclusion">4. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2207.02696_YOLOv7.html">2207.02696_YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2207.02696_YOLOv7.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2303.05499_GroundingDINO.html">Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2304.08485_VisualInstructionTuning.html">2304.08485_Visual Instruction Tuning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2402.13616_YOLOv9.html">2402.13616_YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2402.13616_YOLOv9.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2405.14458_YOLOv10.html">2405.14458_YOLOv10: Real-Time End-to-End Object Detection</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2405.14458_YOLOv10.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html">2411.15858_SVTRv2: CTC Beats Encoder-Decoder Models in Scene Text Recognition</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#id1">å®šä¹‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#methods">3. Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#conclusion">5. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#more-detail-of-real-world-datasets">8. More detail of real-world datasets</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../ML.html#ml">ML</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2112.09332_WebGPT.html">2112.09332_WebGPT: Browser-assisted question-answering with human feedback</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2203.11147_GopherCite.html">2203.11147_GopherCite: Teaching language models to support answers with verified quotes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2304.09848_Generative_Search.html">2304.09848_Generative_Search: Evaluating Verifiability in Generative Search Engines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2305.14251_FActScore.html">2305.14251_FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2305.14627_ALCE.html">2305.14627_ALCE: Enabling Large Language Models to Generate Text with Citations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ML_normals/2305.14627_ALCE.html#nli">NLI åœ¨å¼•ç”¨è´¨é‡è¯„ä¼°ä¸­çš„åº”ç”¨</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ML_normals/2305.14627_ALCE.html#prompt">è®ºæ–‡ä¸­ç”¨çš„prompt</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2307.02185_Citation.html">2307.02185_Citation: A Key to Building Responsible and Accountable Large Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2307.16883_HAGRID.html">2307.16883_HAGRID: A Human-LLM Collaborative Dataset for Generative Information-Seeking with Attribution</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../Agent.html">AI Agent</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Agent.html#agent">é€šç”¨ Agent</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2210.03629_ReAct.html">2210.03629_ReAct</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2303.08268_Chat-with-the-Environment.html">2303.08268_Chat-with-the-Environment</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2303.08268_Chat-with-the-Environment.html#id2">æ­£æ–‡</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2303.11366_Reflexion.html">2303.11366_Reflexion: Language Agents with Verbal Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2303.16434_TaskMatrix.AI.html">2303.16434_TaskMatrix.AI</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2303.16434_TaskMatrix.AI.html#id2">å¤§è„‘</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2303.16434_TaskMatrix.AI.html#id3">æ¥å£å¹³å°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2303.16434_TaskMatrix.AI.html#api">API é€‰æ‹©å™¨</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2304.03442_Generative-Agents.html">2304.03442_Generative-Agents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2304.03442_Generative-Agents.html#generative-agent-architecture">Generative Agent Architecture</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2307.07924_ChatDev.html">2307.07924_ChatDev: Communicative Agents for Software Development</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2308.00352_MetaGPT.html">2308.00352_MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2308.04026_AgentSims.html">2308.04026_AgentSims: An Open-Source Sandbox for Large Language Model Evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2308.08155_AutoGen.html">2308.08155_AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2308.10848_AgentVerse.html">2308.10848_AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2308.10848_AgentVerse.html#id2">ç†å¿µ</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2310.06117_Step-Back.html">2310.06117_Step-Back: Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2402.18679_MetaGPT_DI.html">2402.18679_MetaGPT_DI: Data Interpreter: An LLM Agent For Data Science</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2402.18679_MetaGPT_DI.html#introduction">INTRODUCTION</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2407.07061_IoA.html">2407.07061_IoA: Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2407.07061_IoA.html#overview-of-ioa">2.1 OVERVIEW OF IOA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2407.07061_IoA.html#architecture-of-ioa">2.2 ARCHITECTURE OF IOA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2407.07061_IoA.html#key-mechanisms">2.3 KEY MECHANISMS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2407.07061_IoA.html#putting-it-all-together">2.5 Putting It All Together</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2408.08435_ADAS.html">2408.08435_ADAS: Automated Design of Agentic Systems</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2408.08435_ADAS.html#prompt">Prompt</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2410.10762_AFlow.html">2408.08435_ADAS: Automating Agentic Workflow Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2410.10762_AFlow.html#introduce">Introduce</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2410.10762_AFlow.html#preliminary">PRELIMINARY</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2410.17238_SELA.html">2410.17238_SELA: Tree-Search Enhanced LLM Agents for Automated Machine Learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2410.17238_SELA.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2410.17238_SELA.html#related-works">2 Related Works</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2410.17238_SELA.html#method">3 Method</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2410.21012_FACT.html">2410.21012_FACT: Examining the Effectiveness of Iterative Context Rewriting for Multi-fact Retrieval</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2410.21012_FACT.html#introduce">Introduce</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2504.01990_foundation-agents.html">2504.01990_Advances and Challenges in Foundation Agents</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2506.12508_AgentOrchestra.html">2506.12508_AgentOrchestra: A Hierarchical Multi-Agent Framework for General-Purpose Task Solving</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2506.12508_AgentOrchestra.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2506.12508_AgentOrchestra.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2506.12508_AgentOrchestra.html#agentorchestra">3.AgentOrchestra</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2506.12508_AgentOrchestra.html#experiments">4.Experiments</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Agent.html#agent-aios">è§†è§‰ Agent&amp;AIOS</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2108.03353_Screen2Words.html">2108.03353_ Screen2Words: Automatic Mobile UI Summarization with Multimodal Learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2108.03353_Screen2Words.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2108.03353_Screen2Words.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2108.03353_Screen2Words.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2108.03353_Screen2Words.html#dataset-creation">3. Dataset Creation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2108.03353_Screen2Words.html#model-design">4. Model Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2108.03353_Screen2Words.html#id3">å…¶å®ƒ</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html">2209.08199_ScreenQA: Large-Scale Question-Answer Pairs over Mobile App Screenshots</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#problem-setting-tasks-and-metrics">3. Problem Setting: Tasks and Metrics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#data-annotation">4. Data Annotation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#dataset-analysis">5. Dataset Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#experiments-and-baselines">6. Experiments and Baselines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#conclusion">7. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#limitations">8. Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#ethical-considerations">9. Ethical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#a-data-annotation-details">A. Data Annotation Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#b-data-examples">B. Data Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html">2212.06817_RT-1: ROBOTICS TRANSFORMER FOR REAL-WORLD CONTROL AT SCALE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#abstract">ABSTRACT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#preliminaries">3. Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#system-overview">4. System Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#rt-1-robotics-transformer">5. RT-1: ROBOTICS TRANSFORMER</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#experiments">6. EXPERIMENTS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#conclusions-limitations-and-future-work">7. CONCLUSIONS, LIMITATIONS AND FUTURE WORK</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#b-model-card">B. MODEL CARD</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#c-model-and-data">C. MODEL AND DATA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#d-experiments">D. EXPERIMENTS</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2312.13771_AppAgent.html">2312.13771_AppAgent: Multimodal Agents as Smartphone Users</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2312.13771_AppAgent.html#environment-and-action-space">3.1 Environment and Action Space</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2312.13771_AppAgent.html#exploration-phase">3.2 Exploration Phase</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2312.13771_AppAgent.html#deployment-phase">3.3 Deployment Phase</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html">2401.10935_SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#related-work">2. Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#approach">3. Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#screenspot-a-grounding-benchmark">4. ScreenSpot: A Grounding Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#limitations">Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#ethical-considerations">Ethical considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#a-details-of-seeclick-pre-training">A. Details of SeeClick Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#b-screenspot-annotation-evaluation">B ScreenSpot Annotation &amp; Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#c-downstream-agent-tasks">C. Downstream Agent Tasks</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html">2402.04615_ScreenAI: A Vision-Language Model for UI and Infographics Understanding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#methodology">2. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#automatic-data-generation">3. Automatic data generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#data-mixtures">4. Data Mixtures</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#experiments-and-results">5. Experiments and Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#conclusions">6. Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#a-definitions-of-metrics">A Definitions of Metrics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#b-screen-schema-examples">B. Screen Schema Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#c-prompts-for-llm-generated-content">C. Prompts For LLM Generated Content</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#d-screen-navigation-generated-examples">D. Screen Navigation Generated Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#f-screenqa-short-answers-generation">F. ScreenQA Short Answers Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#g-complex-question-answering-datasets">G. Complex Question Answering Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#h-new-benchmarks-repositories">H. New Benchmarks Repositories</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html">2402.07939_UFO: A UI-Focused Agent for Windows OS Interaction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html#the-design-of-ufo">3.The Design of UFO</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html#experiment">4.Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html#limitations-lessons-learned">5.Limitations &amp; Lessons Learned</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html#conclusion">6.Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2403.16971_AIOS.html">2403.16971_AIOS: LLM Agent Operating System</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2403.16971_AIOS.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2403.16971_AIOS.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2403.16971_AIOS.html#the-architecture-of-aios">2. The Architecture of AIOS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2403.16971_AIOS.html#aios-kernel">3. AIOS Kernel</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2403.16971_AIOS.html#evaluation">4 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2403.16971_AIOS.html#appendix-e-discussion">Appendix E Discussion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2406.01014_Mobile-Agent-v2.html">2406.01014_Mobile-Agent-v2: Mobile Device Operation Assistant with Effective Navigation via Multi-Agent Collaboration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2411.02059_TableGPT2.html">2411.02059_TableGPT2: A Large Multimodal Model with Tabular Data Integration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2411.02059_TableGPT2.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html">2501.11733_Mobile-Agent-E: Self-Evolving Mobile Assistant for Complex Tasks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#mobile-agent-e">2. Mobile-Agent-E</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#results">4. Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#conclusion-and-future-work">6. Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-a-full-trajectory-comparison-example-with-previous-sota">Appendix A Full Trajectory Comparison Example with Previous SOTA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-b-error-recovery-with-escalation-to-manager">Appendix B Error Recovery with Escalation to Manager</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-c-remaining-limitations">Appendix C Remaining Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-d-all-tasks-in-mobile-eval-e-benchmark">Appendix D All Tasks in Mobile-Eval-E Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-e-atomic-operation-space">Appendix E Atomic Operation Space</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-f-full-list-of-self-evolved-shortcuts">Appendix F Full list of Self-Evolved Shortcuts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-g-full-list-of-self-evolved-tips">Appendix G Full list of Self-Evolved Tips</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html">2501.12326_UI-TARS: Pioneering Automated GUI Interaction with Native Agents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html#evolution-path-of-gui-agents">2. Evolution Path of GUI Agents</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html#core-capabilities-of-native-agent-model">3. Core Capabilities of Native Agent Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html#ui-tars">4. UI-TARS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html#experiment">5. Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2502.14282_PC-Agent.html">2502.14282_PC-Agent: A Hierarchical Multi-Agent Collaboration Framework for Complex Task Automation on PC</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2502.14282_PC-Agent.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2502.14282_PC-Agent.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2502.14282_PC-Agent.html#pc-agent">2. PC-Agent</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2502.14282_PC-Agent.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2502.14282_PC-Agent.html#related-work">4. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2502.14282_PC-Agent.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html">2504.14603_UFO2: The Desktop AgentOS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#background">2.Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#system-design-of-ufo2">3.System Design of UFO2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#picture-in-picture-interface">4.Picture-in-Picture Interface</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#implementation-and-specialized-engineering-design">5.Implementation and Specialized Engineering Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#evaluation">6.Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#discussion-future-work">7.Discussion &amp; Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#related-work">8.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#conclusion">9.Conclusion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Agent.html#id2">è®°å¿†</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Memorys/2505.22101_MemOS.html">2505.22101_MemOS: An Operating System for Memory-Augmented Generation (MAG) in LLM (Short Version)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Memorys/2505.22101_MemOS.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Memorys/2505.22101_MemOS.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Memorys/2505.22101_MemOS.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Memorys/2505.22101_MemOS.html#memory-in-large-language-models">2 Memory in Large Language Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Memorys/2505.22101_MemOS.html#memos-design-philosophy">3 MemOS Design Philosophy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Memorys/2505.22101_MemOS.html#memos">4 MemOS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Memorys/2505.22101_MemOS.html#id2"><strong>4.1 MemOS ä¸­çš„è®°å¿†ç±»å‹</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Memorys/2505.22101_MemOS.html#memcube"><strong>4.2 è®°å¿†ç«‹æ–¹ä½“ï¼ˆMemCubeï¼‰ï¼šæ ¸å¿ƒèµ„æº</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Memorys/2505.22101_MemOS.html#id3"><strong>4.3 MemOS æ¶æ„</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Memorys/2505.22101_MemOS.html#id4"><strong>4.4 ç³»ç»Ÿæ‰§è¡Œæµç¨‹</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Memorys/2505.22101_MemOS.html#id5"><strong>æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Memorys/2505.22101_MemOS.html#conclusion">5 Conclusion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Agent.html#tools">Tools</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Tools/2205.00445_MRKL.html">2205.00445_MRKL</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Tools/2302.04761_Toolformer.html">2302.04761_Toolformer: Language Models Can Teach Themselves to Use Tools</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Tools/2303.17580_HuggingGPT.html">2303.17580_HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html">2307.16789_ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#llm">LLMæ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#dataset-construction">2 Dataset Construction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#experiments">3 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#related-work">4 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#appendix-a-implementation-details">Appendix A Implementation Details</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Agent.html#agi">AGI</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/AGIs/1905.10985_AI-GA.html">1905.10985_AI-GA: AI-generating algorithms, an alternate paradigm for producing general artificial intelligence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/AGIs/2408.06292_AI-Scientist.html">2408.06292_The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../RAG.html">RAG</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2005.11401_RAG_for_KI_NLP_task.html">2005.11401_Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html">2312.10997_Retrieval-Augmented Generation for Large Language Models: A Survey</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#ii-overview-of-rag">II. Overview of RAG</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#ii-a-naive-rag">II-A Naive RAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#ii-b-advanced-rag">II-B Advanced RAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#ii-c-modular-rag">II-C Modular RAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#ii-d-rag-vs-fine-tuning">II-D RAG vs Fine-tuning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iii-retrieval">III. Retrieval</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iii-a-retrieval-source">III-A Retrieval Source</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iii-b-indexing-optimization">III-B Indexing Optimization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iii-c-query-optimization">III-C Query Optimization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iii-d-embedding">III-D Embedding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iii-e-adapter">III-E Adapter</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iv-generation">IV. Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iv-a-context-curation">IV-A Context Curation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iv-b-llm-fine-tuning">IV-B LLM Fine-tuning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#v-augmentation-process-in-rag">V. Augmentation process in RAG</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#v-a-iterative-retrieval">V-A Iterative Retrieval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#v-b-recursive-retrieval">V-B Recursive Retrieval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#v-c-adaptive-retrieval">V-C Adaptive Retrieval</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vi-task-and-evaluation">VI. Task and Evaluation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vi-a-downstream-task">VI-A Downstream Task</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vi-b-evaluation-target">VI-B Evaluation Target</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vi-c-evaluation-aspects">VI-C Evaluation Aspects</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vi-d-evaluation-benchmarks-and-tools">VI-D Evaluation Benchmarks and Tools</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vii-discussion-and-future-prospects">VII. Discussion and Future Prospects</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vii-a-rag-vs-long-context">VII-A RAG vs Long Context</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vii-b-rag-robustness">VII-B RAG Robustness</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vii-c-hybrid-approaches">VII-C Hybrid Approaches</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vii-d-scaling-laws-of-rag">VII-D Scaling laws of RAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vii-e-production-ready-rag">VII-E Production-Ready RAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vii-f-multi-modal-rag">VII-F Multi-modal RAG</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2401.15884_CRAG.html">2401.15884_CRAG: Corrective Retrieval Augmented Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2403.14403_Adaptive-RAG.html">2403.14403_Adaptive-RAG</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html">2404.16130_GraphRAG: From Local to Global: A GraphRAG Approach to Query-Focused Summarization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id1">æ€»ç»“</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#introduction">1 Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#background">2 Background</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#rag">2.1 RAGæ–¹æ³•ä¸ç³»ç»Ÿ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#llmrag">2.2 çŸ¥è¯†å›¾è°±åœ¨LLMä¸RAGä¸­çš„åº”ç”¨</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id2">2.3 è‡ªé€‚åº”åŸºå‡†æµ‹è¯•</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id3">2.4 RAGè¯„ä¼°æ ‡å‡†</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#methods">3 Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#graphrag"><strong>3.1 GraphRAG å·¥ä½œæµç¨‹</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id4"><strong>3.2 å…¨å±€ç†è§£é—®é¢˜ç”Ÿæˆ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id5"><strong>3.3 å…¨å±€ç†è§£è¯„ä¼°æ ‡å‡†</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id6"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#analysis">4 Analysis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id7">4.1 å®éªŒ1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id11">4.2 å®éªŒ2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id14">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#results">5 Results</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id15">5.1 å®éªŒä¸€ï¼šä¸åŒæ–¹æ³•åœ¨æ‘˜è¦ä»»åŠ¡ä¸­çš„è¡¨ç°æ¯”è¾ƒ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id18">5.2 å®éªŒäºŒï¼šåŸºäºå£°æ˜çš„æŒ‡æ ‡è¯„ä¼°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id20">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#discussion">6 Discussion</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id21">6.1 è¯„ä¼°æ–¹æ³•çš„å±€é™æ€§</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id22">6.2 æœªæ¥å·¥ä½œ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id23">æ›´å¹¿æ³›çš„å½±å“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#appendix-a-entity-and-relationship-extraction-approach">Appendix A Entity and Relationship Extraction Approach</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id24"><strong>1. å®ä½“ä¸å…³ç³»æŠ½å–æ–¹æ³•</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#self-reflection"><strong>2. è‡ªæˆ‘åæ€ï¼ˆSelf-Reflectionï¼‰æŠ€æœ¯</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id25"><strong>3. åˆ†å—å¤§å°ä¸æŠ½å–æ•ˆæœçš„å…³ç³»</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id26"><strong>4. å®éªŒç»“æœï¼ˆå›¾3ï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id27"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#appendix-b-example-community-detection">Appendix B Example Community Detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#appendix-c-context-window-selection">Appendix C Context Window Selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#appendix-d-example-answer-comparison">Appendix D Example Answer Comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#appendix-e-system-prompts">Appendix E System Prompts</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#e-1-element-instance-generation"><strong>E.1 å®ä½“å®ä¾‹ç”Ÿæˆï¼ˆElement Instance Generationï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#e-2-community-summary-generation"><strong>E.2 ç¤¾åŒºæ‘˜è¦ç”Ÿæˆï¼ˆCommunity Summary Generationï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#e-3-community-answer-generation"><strong>E.3 ç¤¾åŒºé—®é¢˜å›ç­”ç”Ÿæˆï¼ˆCommunity Answer Generationï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#e-4-global-answer-generation"><strong>E.4 å…¨å±€é—®é¢˜å›ç­”ç”Ÿæˆï¼ˆGlobal Answer Generationï¼‰</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#appendix-f-evaluation-prompts">Appendix F Evaluation Prompts</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#f-1-relative-assessment-prompt">F.1 Relative Assessment Prompt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#f-2-relative-assessment-metrics">F.2 Relative Assessment Metrics</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#appendix-g-statistical-analysis">Appendix G Statistical Analysis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id38">ç»Ÿè®¡æ–¹æ³•ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id39">ä¸»è¦ç»“æœæ€»ç»“ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id40">æ€»ä½“è¶‹åŠ¿ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id41">é‡è¦ç»“è®ºï¼š</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html">2405.16506_GRAG: Graph Retrieval-Augmented Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2406.13213_Multi-Meta-RAG.html">2406.13213_Multi-Meta-RAG: Improving RAG for Multi-Hop Queries using Database Filtering with LLM-Extracted Metadata</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html">2410.05779_LightRAG: Simple and Fast Retrieval-Augmented Generation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#id1">æ€»ç»“</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#introduction">1 Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#retrieval-augmented-generation">2 Retrieval-Augmented Generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#the-lightrag-architecture">3 The LightRAGÂ Architecture</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#lightrag">ä¸€ã€LightRAGæ¶æ„æ¦‚è¿°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#graph-based-text-indexing">äºŒã€åŸºäºå›¾çš„æ–‡æœ¬ç´¢å¼•ï¼ˆGraph-based Text Indexingï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#dual-level-retrieval-paradigm">ä¸‰ã€åŒå±‚æ£€ç´¢èŒƒå¼ï¼ˆDual-level Retrieval Paradigmï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#retrieval-augmented-answer-generation">å››ã€æ£€ç´¢å¢å¼ºçš„ç­”æ¡ˆç”Ÿæˆï¼ˆRetrieval-Augmented Answer Generationï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#id2">äº”ã€å¤æ‚åº¦åˆ†æ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#id3">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#evaluation">4 Evaluation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#experimental-settings"><strong>1. å®éªŒè®¾ç½®ï¼ˆ4.1 Experimental Settingsï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#lightrag-rag-4-2-rq1"><strong>2. LightRAG ä¸ç°æœ‰ RAG æ–¹æ³•çš„å¯¹æ¯”ï¼ˆ4.2 RQ1ï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#rq2"><strong>3. æ¶ˆèå®éªŒï¼ˆ4.3 RQ2ï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#id8"><strong>æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#case-study-rq3">4.4 Case Study (RQ3)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#rq3">4.4 æ¡ˆä¾‹ç ”ç©¶ï¼ˆRQ3ï¼‰æ€»ç»“ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#rq4">4.5 æ¨¡å‹æˆæœ¬ä¸é€‚åº”æ€§åˆ†æï¼ˆRQ4ï¼‰æ€»ç»“ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#id9">æ€»ä½“ç»“è®ºï¼š</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#related-work">5 Related Work</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#id10">ç¬¬5ç«  ç›¸å…³å·¥ä½œï¼ˆæ€»ç»“ï¼‰</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#appendix">7 Appendix</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html">2410.10450_KBLaM: Knowledge Base augmented Language Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#introduction">1. Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#related-work">2. Related work</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#background">3. Background</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#self-attention-layer">Self-attention layer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#augmenting-llm-with-the-kb">4. Augmenting LLM with the KB</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#knowledge-tokens">Knowledge tokens</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#rectangular-attention-injecting-knowledge-token-into-prompt-tokens">Rectangular Attention: Injecting knowledge token into prompt tokens</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#kb-length-generalization-through-attention-score-scaling">KB length generalization through attention score scaling</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#kb-instruction-tuning">5. KB instruction tuning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#experiments">6. EXPERIMENTS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#experiment-setting">6.1 EXPERIMENT SETTING</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#experiment-results">6.2 EXPERIMENT RESULTS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#id2">æ€»ç»“äº®ç‚¹</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#conclusion">7. CONCLUSION</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#limitations-and-future-work">8. LIMITATIONS AND FUTURE WORK</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#appendix-a-extended-related-work">Appendix A Extended related work</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#appendix-b-ablation-study">Appendix B Ablation study</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#appendix-c-sample-kb">Appendix C Sample KB</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#sample-q-a">SAMPLE Q&amp;A</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#prompt">PROMPT</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#prompt-for-synthetic-kb-generation">PROMPT FOR SYNTHETIC KB GENERATION</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#prompt-for-open-ended-q-a-generation">Prompt for open-ended Q&amp;A generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#prompt-for-gpt-evaluation-of-open-ended-q-a">PROMPT FOR GPT EVALUATION OF OPEN-ENDED Q&amp;A</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#prompt-for-llama-evaluation">PROMPT FOR LLAMA EVALUATION</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#question-template">QUESTION TEMPLATE</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#sample-output">SAMPLE OUTPUT</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#synthetic-kb">SYNTHETIC KB</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#enron">ENRON</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html">2504.03137_LightPROF: A Lightweight Reasoning Framework for Large Language Model on Knowledge Graph</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#related-work">Related Work</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#llm-prompt-engineering">LLM Prompt Engineering</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#kg-based-llm-reasoning">KG-based LLM Reasoning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#preliminaries">Preliminaries</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#knowledge-graph-kg">1. Knowledge Graph (KG)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#anchor-entities">2. Anchor Entities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#relation-link">3. Relation Link</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#reasoning-path">4. Reasoning Path</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#methodology">Methodology</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#stage1-reasoning-graph-retrieval">Stage1: Reasoning Graph Retrieval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#stage2-knowledge-embedding">Stage2: Knowledge Embedding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#stage3-knowledge-prompts-mixed-reasoning">Stage3: Knowledge Prompts Mixed Reasoning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#experiments">Experiments</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/graphrag.html">GraphRAG å®˜æ–¹æ–‡æ¡£</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/graphrag.html#indexing">Indexing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/graphrag.html#indexing-architecture">&gt; Indexing Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/graphrag.html#indexing-dataflow">&gt; Indexing Dataflow</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/graphrag.html#prompt-tuning">&gt; Prompt Tuning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/graphrag.html#query">Query</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../paper_pool.html">è®ºæ–‡æ± </a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html">2305.16300_Random-Access Infinite Context Length for Transformers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#llm">LLM æ€»ç»“</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id1"><strong>ç ”ç©¶èƒŒæ™¯ä¸åŠ¨æœº</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id2"><strong>æ ¸å¿ƒé—®é¢˜</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id3"><strong>ä¸»è¦è´¡çŒ®</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id4"><strong>å…³é”®æŠ€æœ¯ç‚¹</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id5"><strong>å®éªŒç»“æœ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id6"><strong>æ„ä¹‰ä¸åº”ç”¨å‰æ™¯</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id7"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#introduction">1 Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#related-work">2 Related Work</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#methodology">3 Methodology</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id8"><strong>æ€»ä½“æ€è·¯</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id9"><strong>æ–¹æ³•è¯¦è§£</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id11"><strong>ä½ç½®ç¼–ç å¤„ç†</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id12"><strong>ä¸å…¶ä»–æ–¹æ³•çš„å¯¹æ¯”</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id13"><strong>æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#memory-computation">3.3 Memory &amp; Computation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#experiments">4 Experiments</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id14"><strong>4.1 è¯­è¨€å»ºæ¨¡å®éªŒ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id18"><strong>4.2 å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id22"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#future-work">5 Future Work</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#acknowledgment">Acknowledgment</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#appendix-a-grouped-softmax-example">Appendix A Grouped Softmax Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#appendix-b-dataset-description">Appendix B Dataset Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#appendix-c-number-of-unique-retrieved-blocks">Appendix C Number of Unique Retrieved Blocks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#appendix-d-context-miss-token">Appendix D Context Miss Token</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#appendix-e-positional-augmentation">Appendix E Positional Augmentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#appendix-f-additional-extensions-and-details">Appendix F Additional Extensions and Details</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#masked-language-modeling">1. <strong>æ©ç è¯­è¨€å»ºæ¨¡ï¼ˆMasked Language Modelingï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#flash-attention">2. <strong>ä¸ Flash Attention çš„ç»“åˆ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id23">3. <strong>æ£€ç´¢å—æ•°é‡ä¸å—å¤§å°çš„æƒè¡¡</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id24">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#appendix-g-offloading-kv-cache-to-cpu">Appendix G Offloading KV Cache to CPU</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html">2311.18743_AlignBench: Benchmarking Chinese Alignment of Large Language Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#id1">ä¸»è¦å†…å®¹æ€»ç»“ï¼š</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#id2">æ€»ç»“ï¼š</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#introduction">1 Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#id3"><strong>1. èƒŒæ™¯ä¸æŒ‘æˆ˜</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#alignbench"><strong>2. AlignBenchçš„è®¾è®¡ç›®æ ‡</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#id4"><strong>3. AlignBenchçš„ä¸»è¦ç‰¹ç‚¹</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#id5"><strong>4. AlignBenchçš„åº”ç”¨ä¸æˆæœ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#id6"><strong>5. æ€»ä½“è´¡çŒ®</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#id7"><strong>6. è¡¨æ ¼å¯¹æ¯”</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#dataset">2 Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#methods">3 Methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#human-evaluation-on-alignbench">4 Human Evaluation on AlignBench</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#agreement-evaluation">ä¸€ã€ä¸€è‡´æ€§è¯„ä¼°ï¼ˆAgreement Evaluationï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#quality-evaluation">äºŒã€è§£é‡Šè´¨é‡è¯„ä¼°ï¼ˆQuality Evaluationï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#id8">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#alignbench-benchmarking-results">5 AlignBench: Benchmarking Results</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#related-work">6 Related Work</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#appendix-a-appendix">Appendix A Appendix</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#a-2-prompts-and-details-of-methods">A.2 Prompts and Details of Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#a-2">A.2 æç¤ºæ¨¡æ¿ä¸æ–¹æ³•ç»†èŠ‚</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#a-3">A.3 å„ç»´åº¦è¡¨ç°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#a-4">A.4 æ¡ˆä¾‹åˆ†æ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#id10">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#id11">ä¸€ã€æ ¸å¿ƒé—®é¢˜ï¼šå‚è€ƒææ–™ç¼ºå¤±å¯¼è‡´è¯„ä¼°å›°éš¾</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#id12">äºŒã€æ•°å­¦ç§¯åˆ†é—®é¢˜å¯¹æ¯”åˆ†æ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2311.18743_AlignBench.html#id13">ä¸‰ã€æ€»ç»“</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html">2401.15391_MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#id1"><strong>èƒŒæ™¯ä¸åŠ¨æœº</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#id2"><strong>è´¡çŒ®</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#id3"><strong>æ–¹æ³•æ¦‚è§ˆ</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#id4"><strong>å®éªŒç»“æœ</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#id5"><strong>æ€»ç»“</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#introduction">1 Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#id6">ä¸»è¦å†…å®¹æ€»ç»“å¦‚ä¸‹ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#id7">æ€»ç»“ï¼š</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#rag-with-multi-hop-queries">2 RAG with multi-Hop queries</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#rag">2.1 RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æ¦‚è¿°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#multi-hop-queries">2.2 å¤šè·³æŸ¥è¯¢ï¼ˆMulti-Hop Queriesï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#id8">2.3 è¯„ä¼°æŒ‡æ ‡</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#id9">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#a-benchmarking-dataset-multihop-rag">3 A Benchmarking Dataset: MultiHop-RAG</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#multihop-rag">ä¸€ã€MultiHop-RAG æ•°æ®é›†æ„å»ºæµç¨‹</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#id10">äºŒã€MultiHop-RAG æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#id11">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#benchmarking-rag-system-using-multihop-rag">4 Benchmarking RAG system using MultiHop-RAG</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#retrieval-related-task">ä¸€ã€æ£€ç´¢ç›¸å…³ä»»åŠ¡ï¼ˆRetrieval-related Taskï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#generation-related-task">äºŒã€ç”Ÿæˆç›¸å…³ä»»åŠ¡ï¼ˆGeneration-related Taskï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#other-use-cases">ä¸‰ã€å…¶ä»–æ½œåœ¨æ”¹è¿›æ–¹å‘ï¼ˆOther Use Casesï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#id12">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#related-work">5 Related Work</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#limitations">Limitations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#appendix-a-appendix-a-gpt-4-prompts-used-for-data-generation">Appendix A Appendix A: GPT-4 Prompts Used for Data Generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2401.15391_MultiHop-RAG.html#appendix-b-appendix-b-dataset-examples">Appendix B Appendix B: Dataset Examples</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html">2405.16506_GRAG: Graph Retrieval-Augmented Generation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#introduction">1 Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#related-work">2 Related Work</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#prompt-tuning">2.1 Prompt Tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#llms">2.2 LLMsåœ¨å›¾ç›¸å…³ä»»åŠ¡ä¸­çš„åº”ç”¨</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#id1">2.3 å›¾ä¸Šçš„æ£€ç´¢æ–¹æ³•</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#problem-formalization">3 Problem Formalization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#methodology">4 Methodology</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#id2">æ¦‚è¿°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#id3">4.1 æ–‡æœ¬å­å›¾æ£€ç´¢</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#indexing">æ–‡æœ¬å­å›¾ç´¢å¼•ï¼ˆIndexingï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#ranking">æ–‡æœ¬å­å›¾æ’åºï¼ˆRankingï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#soft-pruning">æ–‡æœ¬å­å›¾è½¯å‰ªæï¼ˆSoft Pruningï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#id4">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#textual-graph-augmented-generation">4.2 Textual Graph Augmented Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#text-view-of-textual-graphs">1. æ–‡æœ¬è§†å›¾ï¼ˆText View of Textual Graphsï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#graph-view-of-textual-graphs">2. å›¾è§†å›¾ï¼ˆGraph View of Textual Graphsï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#generation-phase">3. ç”Ÿæˆé˜¶æ®µï¼ˆGeneration Phaseï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#id5">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#experiments">5 Experiments</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#id6">æ€»ç»“ï¼šç¬¬äº”ç«  å®éªŒéƒ¨åˆ†</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#limitations">7 Limitations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#acknowledgments">Acknowledgments</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#appendix-a-appendix">Appendix A Appendix</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#a"><strong>é™„å½•A æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2405.16506_GRAG.html#id12"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html">2407.01178_Memory3: Language Modeling with Explicit Memory</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#language-modeling-with-explicit-memory">Language Modeling with Explicit Memory</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id1">ç ”ç©¶èƒŒæ™¯ä¸åŠ¨æœºï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id2">ä¸»è¦å†…å®¹ä¸æ–¹æ³•ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id3">å®éªŒä¸ç»“æœï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id4">æ€»ç»“ï¼š</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#abstract">Abstract</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id5">æ ¸å¿ƒæ€æƒ³</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#memory3">Memory3 æ¨¡å‹ç‰¹ç‚¹</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id6">å®éªŒç»“æœ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id7">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#introduction">1â€‚_â€‚Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#retrieval-augmented-training">1.1.1â€‚_â€‚Retrieval-augmented Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id8">1.1.1 | åŸºäºæ£€ç´¢çš„è®­ç»ƒï¼ˆRetrieval-augmented Trainingï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#sparse-computation">1.1.2 | ç¨€ç–è®¡ç®—ï¼ˆSparse Computationï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#parameter-as-memory">1.1.3 | å‚æ•°å³è®°å¿†ï¼ˆParameter as Memoryï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id9">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#memory-circuitry-theory">2â€‚_â€‚Memory Circuitry Theory</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id10">æ ¸å¿ƒæ¦‚å¿µæ€»ç»“ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id11">æ€»ä½“è´¡çŒ®ï¼š</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#definition-2">Definition 2.</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id12">1. <strong>å®šä¹‰ä¸æ ¸å¿ƒæ¦‚å¿µï¼šè®¡ç®—å›¾ã€åŒæ„ä¸çŸ¥è¯†ï¼ˆç”µè·¯ï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id13">2. <strong>çŸ¥è¯†çš„å®ä¾‹</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id14">3. <strong>çŸ¥è¯†çš„å¤–éƒ¨åŒ–ä¸è®°å¿†</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id15">4. <strong>ç»“è®ºä¸æ–­è¨€</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id16">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#remark-1">Remark 1.</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id17">1. <strong>ç”µè·¯æ„é€ çš„å…³é”®æ€§è´¨</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#llm">2. <strong>è®°å¿†å¢å¼º LLM çš„å½¢å¼åŒ–å®šä¹‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id18">3. <strong>å†™å…¥ä»£ä»·ä¸è¯»å–ä»£ä»·çš„æƒè¡¡ï¼ˆè®°å¿†å±‚æ¬¡ç»“æ„ï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id19">4. <strong>çŸ¥è¯†ä½¿ç”¨é¢‘ç‡ä¸è®°å¿†åˆ†é…</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id20">5. <strong>å›¾ç¤ºä¸ç»“è®º</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id21">å°ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#design">3â€‚_â€‚Design</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id22"><strong>3 | Design</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id25"><strong>3.1 | æ¨ç†è¿‡ç¨‹</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id27"><strong>3.2 | å†™å…¥ä¸è¯»å–è®°å¿†</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id28"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#memory-sparsification-and-storage">3.3â€‚_â€‚Memory Sparsification and Storage</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id29">ä¸€ã€æ˜¾å¼è®°å¿†çš„å­˜å‚¨æŒ‘æˆ˜</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id30">äºŒã€å„ç»´åº¦çš„ç¨€ç–åŒ–ç­–ç•¥</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id31">ä¸‰ã€å‹ç¼©æ•ˆæœ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id32">å››ã€éƒ¨ç½²æ–¹å¼</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id33">äº”ã€è¡¥å……è¯´æ˜ä¸å»ºè®®</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id36">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#model-shape">3.4â€‚_â€‚Model Shape</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id37">3.4 | æ¨¡å‹ç»“æ„ï¼ˆModel Shapeï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#training-designs">3.5 | è®­ç»ƒè®¾è®¡ï¼ˆTraining Designsï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id38">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#two-stage-pretrain">3.6â€‚_â€‚Two-stage Pretrain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id39">ä¸€ã€é¢„è®­ç»ƒçš„ä¸¤ä¸ªé˜¶æ®µ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#continual-train">äºŒã€å¯¹ continual train çš„ä¼˜åŒ–</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id40">ä¸‰ã€é˜²æ­¢ä¿¡æ¯æ³„éœ²</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id41">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#pretraining-data">4â€‚_â€‚Pretraining Data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#data-collection"><strong>4.1 æ•°æ®æ”¶é›†ï¼ˆData Collectionï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#filtering"><strong>4.2 æ•°æ®è¿‡æ»¤ï¼ˆFilteringï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#tokenizer"><strong>4.3 åˆ†è¯å™¨ï¼ˆTokenizerï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#knowledge-base"><strong>4.4 çŸ¥è¯†åº“ï¼ˆKnowledge Baseï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id42"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#pretrain">5â€‚_â€‚Pretrain</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id43">1. é¢„è®­ç»ƒæ€»ä½“è®¾è®¡</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#set-up">2. è®­ç»ƒè®¾ç½®ï¼ˆSet-upï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#warmup-stage">3. é¢„çƒ­é˜¶æ®µï¼ˆWarmup Stageï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#continual-train-stage">4. æŒç»­è®­ç»ƒé˜¶æ®µï¼ˆContinual Train Stageï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id44">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#fine-tuning-and-alignment">6â€‚_â€‚Fine-tuning and Alignment</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#supervised-finetuning-sft">6.1 ç›‘ç£å¾®è°ƒï¼ˆSupervised Finetuning, SFTï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#direct-preference-optimization-dpo">6.2 ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDirect Preference Optimization, DPOï¼‰</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#evaluation">7â€‚_â€‚Evaluation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id45">7.1 é€šç”¨èƒ½åŠ›è¯„ä¼°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id46">7.2 å¯¹è¯èƒ½åŠ›è¯„ä¼°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id47">7.3 å¹»è§‰ä¸äº‹å®æ€§è¯„ä¼°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id48">7.4 ä¸“ä¸šä»»åŠ¡è¯„ä¼°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id49">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#inference-speed">7.5â€‚_â€‚Inference Speed</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id50">ä¸»è¦å†…å®¹æ€»ç»“å¦‚ä¸‹ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id51">æ€»ç»“ï¼š</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#conclusion">8â€‚_â€‚Conclusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#acknowledgement">Acknowledgement</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#appendix-a-cost-estimation">Appendix A Cost Estimation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id52">æ¨¡å‹å‚æ•°è®¾å®š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#implicit-memory">éšå¼è®°å¿†ï¼ˆImplicit Memoryï¼‰æˆæœ¬</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#explicit-memory">æ˜¾å¼è®°å¿†ï¼ˆExplicit Memoryï¼‰æˆæœ¬</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#external-information-rag">å¤–éƒ¨ä¿¡æ¯ï¼ˆExternal Informationï¼Œå¦‚ RAGï¼‰æˆæœ¬</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id53">ç»¼åˆæ¯”è¾ƒ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#id54">æ‹“å±•è®¨è®º</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#appendix-b-vector-compression">Appendix B Vector Compression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2407.01178_Memory3.html#appendix-c-supplementary-evaluation-results">Appendix C Supplementary Evaluation Results</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html">2505.14683_Emerging Properties in Unified Multimodal Pretraining</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#introduction">1 Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id1">æ ¸å¿ƒå†…å®¹æ€»ç»“ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id2">æ€»ç»“ï¼š</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#model">2 Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id3">1. æ¨¡å‹æ¶æ„æ¦‚è§ˆ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id4">2. ç”Ÿæˆç­–ç•¥</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id5">3. æ¨¡å‹ç»†èŠ‚</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#generalized-causal-attention">4. å¹¿ä¹‰å› æœæ³¨æ„åŠ›ï¼ˆGeneralized Causal Attentionï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#transformer">5. Transformerç»“æ„é€‰æ‹©ä¸å®éªŒ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id6">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#data">3 Data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id7">æ•°æ®ç‰¹ç‚¹ä¸ç›®æ ‡</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id8">æ•°æ®æ¥æºä¸ç»Ÿè®¡</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id9">æ•°æ®æ„å»ºæ–¹æ³•</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id16">æ•°æ®è®­ç»ƒç­–ç•¥</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id17">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#training">4 Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id18">1. å¤šé˜¶æ®µè®­ç»ƒç­–ç•¥</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id19">2. å…³é”®è¶…å‚æ•°è°ƒæ•´</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id22">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#evaluation">5 Evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#emerging-properties">6 Emerging Properties</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id23">1. <strong>æ–°å…´å±æ€§çš„å®šä¹‰ä¸ç ”ç©¶èƒŒæ™¯</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id24">2. <strong>ä»»åŠ¡è¡¨ç°ä¸è®­ç»ƒé˜¶æ®µçš„å…³ç³»</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id25">3. <strong>å¤šæ¨¡æ€ç‰¹å¾çš„é‡è¦æ€§</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id26">4. <strong>å®šæ€§åˆ†æä¸ç”Ÿæˆè´¨é‡æå‡</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id27">5. <strong>æ ¸å¿ƒå‘ç°ä¸ç»“è®º</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id28">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#main-results">7 Main Results</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id29">7.1 å›¾åƒç†è§£</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id30">7.2 å›¾åƒç”Ÿæˆ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id31">7.3 å›¾åƒç¼–è¾‘</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id32">7.4 å¸¦æœ‰æ¨ç†çš„ç”Ÿæˆ/ç¼–è¾‘</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id33">7.5 ä¸–ç•Œå»ºæ¨¡</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id34">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#more-qualitative-results">7.6 More Qualitative Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#conclusion">8 Conclusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#acknowledgement">9 Acknowledgement</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html">MemOS: A Memory OS for AI System</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#llm">LLM æ€»ç»“ï¼š</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#introduction">1 Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id1"><strong>1. èƒŒæ™¯ä¸åŠ¨æœº</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id2"><strong>2. ç°æœ‰æ–¹æ³•çš„ä¸è¶³</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id3"><strong>3. å››å¤§å…¸å‹æŒ‘æˆ˜</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#memos"><strong>4. MemOSçš„æå‡ºä¸æ ¸å¿ƒç†å¿µ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id4"><strong>5. æ€»ç»“ä¸æ„ä¹‰</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#memory-in-large-language-models">2 Memory in Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id5">æ€»ç»“å¦‚ä¸‹ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id6"><strong>ä¸€ã€è®°å¿†ç ”ç©¶çš„å››ä¸ªé˜¶æ®µ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id7"><strong>äºŒã€ç¬¬ä¸€é˜¶æ®µï¼šè®°å¿†å®šä¹‰ä¸æ¢ç´¢</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id14"><strong>ä¸‰ã€MemOS çš„åˆæ­¥æ„æƒ³</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id15"><strong>å››ã€æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#stage-1"><strong>2.1 æ˜¾å¼é•¿æœŸè®°å¿†çš„å»ºç«‹ï¼ˆStage 1ï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#stage-2"><strong>2.2 äººè„‘å¼è®°å¿†æœºåˆ¶çš„å¼•å…¥ï¼ˆStage 2ï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#stage-3"><strong>2.3 åŸºäºå·¥å…·çš„è®°å¿†ç®¡ç†ï¼ˆStage 3ï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#stage-4"><strong>2.4 ç³»ç»ŸåŒ–è®°å¿†æ²»ç†ï¼ˆStage 4ï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id16"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#memos-design-philosophy">3 MemOS Design Philosophy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#memos-3-1-vision-of-memos">ä¸€ã€MemOS çš„æ„¿æ™¯ï¼ˆ3.1 Vision of MemOSï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#from-computer-os-to-memory-os">äºŒã€ä»ä¼ ç»Ÿæ“ä½œç³»ç»Ÿåˆ°è®°å¿†æ“ä½œç³»ç»Ÿï¼ˆ3.2 From Computer OS to Memory OSï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id17">ä¸‰ã€æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#memory-modeling-in-memos">4 Memory Modeling in MemOS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id18"><strong>4.1 å†…å­˜ç±»å‹ä¸è¯­ä¹‰æ¼”åŒ–è·¯å¾„</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#memory-cube-memcube"><strong>4.2 Memory Cubeï¼ˆMemCubeï¼‰ï¼šå†…å­˜çš„æ ¸å¿ƒèµ„æºå•å…ƒ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id19"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#architecture-of-memos">5 Architecture of MemOS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id20">æ€»ç»“ï¼šMemOS æ¶æ„ä¸æ‰§è¡Œæµç¨‹</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id24">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id25">5.5.1 MemGovernanceï¼ˆå†…å­˜æ²»ç†æ¨¡å—ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#memvault">5.5.2 MemVaultï¼ˆå†…å­˜å­˜å‚¨ä¸è·¯ç”±åŸºç¡€è®¾æ–½ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#memloader-memdumper">5.5.3 MemLoader ä¸ MemDumperï¼ˆå†…å­˜åŠ è½½ä¸å¯¼å‡ºæ¨¡å—ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#memstore">5.5.4 MemStoreï¼ˆå†…å­˜å­˜å‚¨ä¸åˆ†å‘æ¥å£ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id26">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#evaluation">6 Evaluation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#end-to-end-evaluation-on-locomo"><strong>1. æ•´ä½“ç³»ç»Ÿè¯„ä¼°ï¼ˆEnd-to-End Evaluation on LOCOMOï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#evaluation-of-memory-retrieval"><strong>2. å†…å­˜æ£€ç´¢è¯„ä¼°ï¼ˆEvaluation of Memory Retrievalï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#kv-evaluation-of-kv-based-memory-acceleration"><strong>3. KVç¼“å­˜åŠ é€Ÿè¯„ä¼°ï¼ˆEvaluation of KV-Based Memory Accelerationï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id27"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#memos-for-architecture-innovation-and-applications">7 MemOS for Architecture Innovation and Applications</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id28">ä¸€ã€MemOSæ¨åŠ¨çš„æ¶æ„åˆ›æ–°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id29">äºŒã€MemOSçš„åº”ç”¨åœºæ™¯</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#id30">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.03724_MemOS.html#conclusion">8 Conclusion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../../other.html">å…¶ä»–</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../other.html#id3">æ•°æ®é›†&amp;æ•°æ®è’¸é¦</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../DataSets/1811.10959v3_Dataset_Distillation.html">1811.10959v3_Dataset Distillation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DataSets/1811.10959v3_Dataset_Distillation.html#abstract">ABSTRACT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DataSets/1811.10959v3_Dataset_Distillation.html#llm">LLMæ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DataSets/1811.10959v3_Dataset_Distillation.html#introduction">1. INTRODUCTION</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DataSets/1811.10959v3_Dataset_Distillation.html#approach">3. APPROACH</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../DataSets/2502.20653_Dataset_Distillation.html">2502.20653_Dataset Distillation with Neural Characteristic Function: A Minmax Perspective</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DataSets/2502.20653_Dataset_Distillation.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DataSets/2502.20653_Dataset_Distillation.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DataSets/2502.20653_Dataset_Distillation.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DataSets/2502.20653_Dataset_Distillation.html#conclusion">7. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../DataSets/normal.html">é€šç”¨</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DataSets/normal.html#dataset-distillation">Dataset distillation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="../../other.html#d">3D</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="2003.08934_NeRF.html">2003.08934_NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2003.08934_NeRF.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2003.08934_NeRF.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2003.08934_NeRF.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2003.08934_NeRF.html#neural-radiance-field-scene-representation">3. Neural Radiance Field Scene Representation</a></li>
<li class="toctree-l4"><a class="reference internal" href="2003.08934_NeRF.html#volume-rendering-with-radiance-fields">4. Volume Rendering with Radiance Fields</a></li>
<li class="toctree-l4"><a class="reference internal" href="2003.08934_NeRF.html#optimizing-a-neural-radiance-field">5. Optimizing a Neural Radiance Field</a></li>
<li class="toctree-l4"><a class="reference internal" href="2003.08934_NeRF.html#result">6. Result</a></li>
<li class="toctree-l4"><a class="reference internal" href="2003.08934_NeRF.html#conclusion">7. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2203.08586_VanishingPointEstimation.html">2203.08586: Deep vanishing point detection: Geometric priors make dataset variations vanish</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2203.08586_VanishingPointEstimation.html#id1">æ¦‚å¿µ</a></li>
<li class="toctree-l4"><a class="reference internal" href="2203.08586_VanishingPointEstimation.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2203.08586_VanishingPointEstimation.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2203.08586_VanishingPointEstimation.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2203.08586_VanishingPointEstimation.html#geometric-priors-for-vp-detection">3. Geometric priors for VP detection</a></li>
<li class="toctree-l4"><a class="reference internal" href="2203.08586_VanishingPointEstimation.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="2203.08586_VanishingPointEstimation.html#conclusion-and-limitations">5. Conclusion and limitations</a></li>
</ul>
</li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">2312.14132_DUSt3R: Geometric 3D Vision Made Easy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id1">å…³é”®è¯</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id2">ç›¸å…³æ¦‚å¿µ</a></li>
<li class="toctree-l4"><a class="reference internal" href="#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="#method">3. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="#experiments-with-dust3r">4. Experiments with DUSt3R</a></li>
<li class="toctree-l4"><a class="reference internal" href="#conclusion">5. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="#appendix-a">Appendix A <strong>é™„å½•æ¦‚è§ˆ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="#appendix-b-qualitative-results">Appendix B.  Qualitative results</a></li>
<li class="toctree-l4"><a class="reference internal" href="#appendix-c-extended-related-work">Appendix C. Extended Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="#appendix-d-multi-view-pose-estimation">Appendix D. å¤šè§†è§’å§¿æ€ä¼°è®¡ï¼ˆMulti-view Pose Estimationï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="#appendix-e-visual-localization">Appendix E. è§†è§‰å®šä½ï¼ˆVisual Localizationï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="#appendix-f-training-details">Appendix F. Training details</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2406.09756_MASt3R.html">2406.09756_MASt3R: Grounding Image Matching in 3D with MASt3R</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2406.09756_MASt3R.html#id1">å‰è¨€</a></li>
<li class="toctree-l4"><a class="reference internal" href="2406.09756_MASt3R.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2406.09756_MASt3R.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2406.09756_MASt3R.html#id2">ğŸ§  æ€ç»´å¯¼å›¾å¼æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2406.09756_MASt3R.html#related-works">2. Related works</a></li>
<li class="toctree-l4"><a class="reference internal" href="2406.09756_MASt3R.html#id3">ğŸ§  æ€»ç»“æ€ç»´å¯¼å›¾</a></li>
<li class="toctree-l4"><a class="reference internal" href="2406.09756_MASt3R.html#method">3. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="2406.09756_MASt3R.html#experimental-results">4. Experimental results</a></li>
<li class="toctree-l4"><a class="reference internal" href="2406.09756_MASt3R.html#conclusion">5. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="2406.09756_MASt3R.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="2406.09756_MASt3R.html#appendix-a-additional-qualitative-results">Appendix A Additional Qualitative Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="2406.09756_MASt3R.html#b-fast-reciprocal-matching">B. Fast Reciprocal Matching</a></li>
<li class="toctree-l4"><a class="reference internal" href="2406.09756_MASt3R.html#c-coarse-to-fine">C. Coarse-to-Fine</a></li>
<li class="toctree-l4"><a class="reference internal" href="2406.09756_MASt3R.html#d-detailed-experimental-settings">D. Detailed experimental settings</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2412.09401_SLAM3R.html">2412.09401_SLAM3R: Real-Time Dense Scene Reconstruction from Monocular RGB Videos</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2412.09401_SLAM3R.html#id1">æœ¯è¯­</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.09401_SLAM3R.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.09401_SLAM3R.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.09401_SLAM3R.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.09401_SLAM3R.html#method">3. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.09401_SLAM3R.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.09401_SLAM3R.html#conclusion">5. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.09401_SLAM3R.html#id14">6. è‡´è°¢</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.09401_SLAM3R.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.09401_SLAM3R.html#appendix-a-implementation-details">Appendix A Implementation details</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.09401_SLAM3R.html#appendix-b-details-for-experimental-settings">Appendix B Details for experimental settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.09401_SLAM3R.html#appendix-c-additional-comparisons-and-analyses">Appendix C Additional comparisons and analyses</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.09401_SLAM3R.html#d-more-visual-results">D. More visual results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html">2412.12392_MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html#gpt">GPT</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html#id1">å…ˆéªŒçŸ¥è¯†</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html#method">3. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html#results">4. Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html#limitations-and-future-work">5. Limitations and Future Workï¼ˆå±€é™ä¸æœªæ¥å·¥ä½œï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html#conclusion">ğŸ§¾ 6. Conclusionï¼ˆæ€»ç»“ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html#id32">ğŸ§  æ€»ç»“ä¸€å¥è¯ç‰ˆï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html#initialisation">8. Initialisationï¼ˆåˆå§‹åŒ–ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html#runtime-breakdown">9. Runtime Breakdownï¼ˆè¿è¡Œæ—¶åˆ†æï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html#evaluation-setup">10. Evaluation Setupï¼ˆè¯„ä¼°è®¾ç½®ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html#id35">11. EuRoC ç»“æœæ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2503.11651_VGGT.html">2503.11651_VGGT: Visual Geometry Grounded Transformer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2503.11651_VGGT.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2503.11651_VGGT.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2503.11651_VGGT.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2503.11651_VGGT.html#method">3. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="2503.11651_VGGT.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="2503.11651_VGGT.html#discussions">5. Discussions</a></li>
<li class="toctree-l4"><a class="reference internal" href="2503.11651_VGGT.html#conclusions">6. Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="2503.11651_VGGT.html#appendix-a-formal-definitions">Appendix A Formal Definitions</a></li>
<li class="toctree-l4"><a class="reference internal" href="2503.11651_VGGT.html#appendix-b-implementation-details">Appendix B Implementation Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="2503.11651_VGGT.html#appendix-c-additional-experiments">Appendix C Additional Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="2503.11651_VGGT.html#appendix-d-qualitative-examples">Appendix D Qualitative Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="2503.11651_VGGT.html#appendix-e-related-work">Appendix E Related Work</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../other.html#id4">å…¶ä»–</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html">A PAINLESS GUIDE TO CRC ERROR DETECTION ALGORITHMS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#the-basic-idea-behind-crc-algorithms">The Basic Idea Behind CRC Algorithms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#polynomical-arithmetic">Polynomical Arithmetic</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#binary-arithmetic-with-no-carries">Binary Arithmetic with No Carries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#id2">ä¸€ä¸ªå¯ç”¨çš„å®ä¾‹</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#choosing-a-poly">Choosing A Poly</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#a-straightforward-crc-implementation">A Straightforward CRC Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#a-table-driven-implementation">A Table-Driven Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#a-slightly-mangled-table-driven-implementation">A Slightly Mangled Table-Driven Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#id3">å‚è€ƒ</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../others/Distributed%20Representations%20of%20Sentences%20and%20Documents.html">Distributed Representations of Sentences and Documents</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">æ–°æºª-gordon</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../other.html">å…¶ä»–</a> &raquo;</li>
        
      <li>2312.14132_DUSt3R: Geometric 3D Vision Made Easy</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/others/3D/2312.14132_DUSt3R.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            <nav id="local-table-of-contents" role="navigation" aria-labelledby="local-table-of-contents-title">
              <h4 id="local-table-of-contents-title">On This Page</h4>
              <ul>
<li><a class="reference internal" href="#">2312.14132_DUSt3R: Geometric 3D Vision Made Easy</a><ul>
<li><a class="reference internal" href="#id1">å…³é”®è¯</a></li>
<li><a class="reference internal" href="#id2">ç›¸å…³æ¦‚å¿µ</a><ul>
<li><a class="reference internal" href="#intrinsic-parameters">ğŸ“· ä¸€ã€å†…å‚ï¼ˆIntrinsic Parametersï¼‰</a></li>
<li><a class="reference internal" href="#extrinsic-parameters">ğŸŒ äºŒã€å¤–å‚ï¼ˆExtrinsic Parametersï¼‰</a></li>
<li><a class="reference internal" href="#id3">ğŸ§® ä¸‰ã€ä¸‰ç»´ç‚¹åˆ°å›¾åƒç‚¹çš„æ˜ å°„å…¬å¼</a></li>
<li><a class="reference internal" href="#id4">ğŸ¯ åº”ç”¨åœºæ™¯</a></li>
</ul>
</li>
<li><a class="reference internal" href="#abstract">Abstract</a></li>
<li><a class="reference internal" href="#introduction">1. Introduction</a><ul>
<li><a class="reference internal" href="#id5">ğŸ’¡ ç¬¬ä¸€æ®µï¼šèƒŒæ™¯ä»‹ç»</a></li>
<li><a class="reference internal" href="#id6">ğŸ”§ ç¬¬äºŒæ®µï¼šä¼ ç»Ÿæ–¹æ³•çš„ä¸è¶³</a></li>
<li><a class="reference internal" href="#dust3r">ğŸš€ ç¬¬ä¸‰æ®µï¼šDUSt3R çš„æ ¸å¿ƒåˆ›æ–°</a></li>
<li><a class="reference internal" href="#id7">ğŸ“š ç¬¬å››æ®µï¼šè®­ç»ƒä¸å»ºæ¨¡æ€è·¯</a></li>
<li><a class="reference internal" href="#id8">ğŸ§© ç¬¬äº”æ®µï¼šå¤šè§†å›¾èåˆæ–¹å¼çš„æ–°è®¾è®¡</a></li>
<li><a class="reference internal" href="#id9">ğŸ“ æ€»ç»“ï¼šè®ºæ–‡è´¡çŒ®ï¼ˆå››ä¸ªæ–¹é¢ï¼‰</a></li>
</ul>
</li>
<li><a class="reference internal" href="#related-work">2. Related Work</a><ul>
<li><a class="reference internal" href="#structure-from-motion-sfm"><strong>1. Structure-from-Motion (SfM)</strong></a></li>
<li><a class="reference internal" href="#multi-view-stereo-mvs"><strong>2. Multi-View Stereo (MVS)</strong></a></li>
<li><a class="reference internal" href="#direct-rgb-to-3d"><strong>3. Direct RGB-to-3D</strong></a></li>
<li><a class="reference internal" href="#pointmaps"><strong>4. æœ¬æ–‡çš„æ–¹æ³•ï¼šPointmaps å’ŒåŒè§†è§’è¾“å…¥</strong></a></li>
<li><a class="reference internal" href="#id10"><strong>5. Pointmaps çš„ä½¿ç”¨</strong></a></li>
<li><a class="reference internal" href="#id11">ğŸ§  æ€»ç»“ï¼š</a></li>
</ul>
</li>
<li><a class="reference internal" href="#method">3. Method</a><ul>
<li><a class="reference internal" href="#id12">æ¦‚å¿µå®šä¹‰</a><ul>
<li><a class="reference internal" href="#pointmap">ğŸŸ¡ <strong>Pointmapï¼ˆç‚¹å›¾ï¼‰</strong></a></li>
<li><a class="reference internal" href="#cameras-and-scene">ğŸŸ¡ <strong>ç›¸æœºä¸åœºæ™¯å»ºæ¨¡ï¼ˆCameras and Sceneï¼‰</strong></a></li>
<li><a class="reference internal" href="#id13">ğŸŸ¡ <strong>è·¨ç›¸æœºåæ ‡è½¬æ¢ï¼ˆå¤šè§†è§’ç‚¹å›¾çš„è½¬æ¢ï¼‰</strong></a></li>
<li><a class="reference internal" href="#id14">âœï¸ æ€»ç»“ï¼š</a></li>
</ul>
</li>
<li><a class="reference internal" href="#overview">3.1 Overview</a><ul>
<li><a class="reference internal" href="#id15">ğŸ§  <strong>ç›®æ ‡æ¦‚è¿°</strong></a></li>
<li><a class="reference internal" href="#inspired-by-croco">ğŸ—ï¸ <strong>ç½‘ç»œæ¶æ„ï¼ˆInspired by CroCoï¼‰</strong></a></li>
<li><a class="reference internal" href="#discussion">ğŸ’¡ <strong>è®¾è®¡è®¨è®ºï¼ˆDiscussionï¼‰</strong></a></li>
<li><a class="reference internal" href="#id16">âœ… æ€»ç»“</a></li>
</ul>
</li>
<li><a class="reference internal" href="#training-objective">3.2 Training Objective</a><ul>
<li><a class="reference internal" href="#d-3d-regression-loss">ä¸€ã€3Då›å½’æŸå¤±ï¼ˆ3D Regression Lossï¼‰</a></li>
<li><a class="reference internal" href="#confidence-aware-loss">äºŒã€ç½®ä¿¡åº¦æ„ŸçŸ¥æŸå¤±ï¼ˆConfidence-aware Lossï¼‰</a></li>
<li><a class="reference internal" href="#id17">æ€»ç»“ç†è§£ï¼š</a></li>
</ul>
</li>
<li><a class="reference internal" href="#downstream-applications">3.3 Downstream Applications</a><ul>
<li><a class="reference internal" href="#point-matching">âœ… <strong>Point Matchingï¼ˆç‚¹åŒ¹é…ï¼‰</strong></a></li>
<li><a class="reference internal" href="#recovering-intrinsics">âœ… <strong>Recovering Intrinsicsï¼ˆæ¢å¤ç›¸æœºå†…å‚ï¼‰</strong></a></li>
<li><a class="reference internal" href="#relative-pose-estimation">âœ… <strong>Relative Pose Estimationï¼ˆç›¸å¯¹å§¿æ€ä¼°è®¡ï¼‰</strong></a></li>
<li><a class="reference internal" href="#id18">æ€»ç»“</a></li>
</ul>
</li>
<li><a class="reference internal" href="#global-alignment">3.4 Global Alignment</a><ul>
<li><a class="reference internal" href="#pairwise-graph">âœ¦ ä¸€ã€æ„å»ºå›¾ç»“æ„: Pairwise Graph</a></li>
<li><a class="reference internal" href="#global-optimization">âœ¦ äºŒã€å…¨å±€ä¼˜åŒ–: Global optimization</a></li>
<li><a class="reference internal" href="#camera-parameter-recovery">âœ¦ ä¸‰ã€ç›¸æœºå‚æ•°æ¢å¤ï¼šCamera Parameter Recovery</a></li>
<li><a class="reference internal" href="#id19">âœ… æ€»ç»“é‡ç‚¹</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#experiments-with-dust3r">4. Experiments with DUSt3R</a><ul>
<li><a class="reference internal" href="#id20">å‰è¨€</a><ul>
<li><a class="reference internal" href="#training-data">ğŸ§  <strong>1. è®­ç»ƒæ•°æ®ï¼ˆTraining dataï¼‰</strong></a></li>
<li><a class="reference internal" href="#training-details">ğŸ—ï¸ <strong>2. è®­ç»ƒç»†èŠ‚ï¼ˆTraining detailsï¼‰</strong></a></li>
<li><a class="reference internal" href="#evaluation">ğŸ“Š <strong>3. è¯„ä¼°ï¼ˆEvaluationï¼‰</strong></a></li>
<li><a class="reference internal" href="#qualitative-results">ğŸ¨ <strong>4. å®šæ€§ç»“æœï¼ˆQualitative resultsï¼‰</strong></a></li>
<li><a class="reference internal" href="#id21">âœ… æ€»ç»“ä¸€ä¸‹å…³é”®ç‚¹ï¼š</a></li>
</ul>
</li>
<li><a class="reference internal" href="#visual-localization"><strong>4.1 è§†è§‰å®šä½ï¼ˆVisual Localizationï¼‰</strong></a></li>
<li><a class="reference internal" href="#multi-view-pose-estimation"><strong>4.2 å¤šè§†è§’ç›¸å¯¹ä½å§¿ä¼°è®¡ï¼ˆMulti-view Pose Estimationï¼‰</strong></a></li>
<li><a class="reference internal" href="#monocular-depth-estimation"><strong>4.3 å•ç›®æ·±åº¦ä¼°è®¡ï¼ˆMonocular Depth Estimationï¼‰</strong></a></li>
<li><a class="reference internal" href="#multi-view-depth">4.4 å¤šè§†è§’æ·±åº¦ä¼°è®¡ï¼ˆMulti-view Depthï¼‰</a></li>
<li><a class="reference internal" href="#d-reconstruction">4.5 ä¸‰ç»´é‡å»ºï¼ˆ3D Reconstructionï¼‰</a></li>
<li><a class="reference internal" href="#ablations">4.6 æ¶ˆèå®éªŒï¼ˆAblationsï¼‰</a></li>
<li><a class="reference internal" href="#id22">ğŸ§© æ€»ç»“ä¸€å¥è¯ï¼š</a></li>
</ul>
</li>
<li><a class="reference internal" href="#conclusion">5. Conclusion</a><ul>
<li><a class="reference internal" href="#id23">ğŸ”š æ€»ç»“å†…å®¹è§£æ</a></li>
<li><a class="reference internal" href="#id24">âœ… å…³é”®è¯è§£é‡Šï¼š</a></li>
<li><a class="reference internal" href="#id25">ğŸ“Œ æ€»ç»“å…³é”®è¯æç‚¼</a></li>
</ul>
</li>
<li><a class="reference internal" href="#appendix-a">Appendix A <strong>é™„å½•æ¦‚è§ˆ</strong></a></li>
<li><a class="reference internal" href="#appendix-b-qualitative-results">Appendix B.  Qualitative results</a></li>
<li><a class="reference internal" href="#appendix-c-extended-related-work">Appendix C. Extended Related Work</a><ul>
<li><a class="reference internal" href="#implicit-camera-models">1. <strong>Implicit Camera Modelsï¼ˆéšå¼ç›¸æœºæ¨¡å‹ï¼‰</strong></a></li>
<li><a class="reference internal" href="#dense-visual-slam-slam">2. <strong>Dense Visual SLAMï¼ˆå¯†é›†è§†è§‰SLAMï¼‰</strong></a></li>
<li><a class="reference internal" href="#implicit-3d-reconstruction-3d">3. <strong>Implicit 3D Reconstructionï¼ˆéšå¼3Dé‡å»ºï¼‰</strong></a></li>
<li><a class="reference internal" href="#rgb-pairs-to-3d">4. <strong>RGB-pairs-to-3D</strong></a></li>
</ul>
</li>
<li><a class="reference internal" href="#appendix-d-multi-view-pose-estimation">Appendix D. å¤šè§†è§’å§¿æ€ä¼°è®¡ï¼ˆMulti-view Pose Estimationï¼‰</a><ul>
<li><a class="reference internal" href="#id26">ğŸŒŸ æ ¸å¿ƒç»“è®ºï¼š</a></li>
</ul>
</li>
<li><a class="reference internal" href="#appendix-e-visual-localization">Appendix E. è§†è§‰å®šä½ï¼ˆVisual Localizationï¼‰</a><ul>
<li><a class="reference internal" href="#id27">ğŸŒŸ æ ¸å¿ƒç»“è®ºï¼š</a></li>
<li><a class="reference internal" href="#id28">ğŸ§ª å®éªŒè®¾å®šï¼š</a></li>
<li><a class="reference internal" href="#tab-6">ğŸ“Š è¡¨æ ¼è§£è¯»ï¼ˆTab. 6ï¼‰ï¼š</a></li>
<li><a class="reference internal" href="#id29">ğŸ“Œ æ€»ç»“äº®ç‚¹ï¼š</a></li>
</ul>
</li>
<li><a class="reference internal" href="#appendix-f-training-details">Appendix F. Training details</a><ul>
<li><a class="reference internal" href="#id30">ä¸€ã€è®­ç»ƒæ•°æ®æ¥æºå’Œå¤„ç†</a></li>
<li><a class="reference internal" href="#id31">äºŒã€æ•°æ®å¢å¼ºç­–ç•¥</a></li>
<li><a class="reference internal" href="#id32">ä¸‰ã€è®­ç»ƒè¶…å‚æ•°ï¼ˆè§è¡¨ 7ï¼‰</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
  <section class="tex2jax_ignore mathjax_ignore" id="dust3r-geometric-3d-vision-made-easy">
<h1>2312.14132_DUSt3R: Geometric 3D Vision Made Easy<a class="headerlink" href="#dust3r-geometric-3d-vision-made-easy" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h1>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/html/2312.14132">https://arxiv.org/html/2312.14132</a></p></li>
<li><p>GitHub: <a class="reference external" href="https://github.com/naver/dust3r">https://github.com/naver/dust3r</a></p></li>
<li><p>ç»„ç»‡: Aalto University, Naver Labs Europe</p></li>
</ul>
<section id="id1">
<h2>å…³é”®è¯<a class="headerlink" href="#id1" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<ul class="simple">
<li><p>MVS: Multi-view stereo reconstruction</p></li>
<li><p>PnP: Perspective-n-Point</p></li>
</ul>
</section>
<section id="id2">
<h2>ç›¸å…³æ¦‚å¿µ<a class="headerlink" href="#id2" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<section id="intrinsic-parameters">
<h3>ğŸ“· ä¸€ã€å†…å‚ï¼ˆIntrinsic Parametersï¼‰<a class="headerlink" href="#intrinsic-parameters" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>å†…å‚æè¿°çš„æ˜¯<strong>æ‘„åƒå¤´è‡ªèº«çš„æˆåƒç‰¹æ€§</strong>ï¼Œå³å¦‚ä½•ä»æ‘„åƒå¤´åæ ‡ç³»ä¸­çš„ä¸‰ç»´ç‚¹æ˜ å°„åˆ°äºŒç»´å›¾åƒå¹³é¢ä¸Šã€‚å¸¸è§çš„å†…å‚åŒ…æ‹¬ï¼š</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>å‚æ•°</p></th>
<th class="head"><p>å«ä¹‰</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\( f_x, f_y \)</span></p></td>
<td><p>ç„¦è·åœ¨å›¾åƒxè½´å’Œyè½´çš„åƒç´ å•ä½å€¼ï¼ˆé€šå¸¸æ˜¯ç„¦è·ä¹˜ä»¥åƒç´ å¯†åº¦ï¼‰</p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\( c_x, c_y \)</span></p></td>
<td><p>ä¸»ç‚¹ï¼ˆprincipal pointï¼‰çš„åæ ‡ï¼Œé€šå¸¸æ˜¯å›¾åƒä¸­å¿ƒ</p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\( s \)</span></p></td>
<td><p>åè½´ç³»æ•°ï¼ˆskewï¼‰ï¼Œæè¿°xã€yè½´ä¸å‚ç›´æ—¶çš„æƒ…å†µï¼Œé€šå¸¸ä¸º0</p></td>
</tr>
</tbody>
</table>
<p><strong>å†…å‚çŸ©é˜µï¼ˆç›¸æœºçŸ©é˜µï¼‰K é€šå¸¸è¡¨ç¤ºä¸ºï¼š</strong></p>
<div class="math notranslate nohighlight">
\[\begin{split}
K = \begin{bmatrix}
f_x &amp; s &amp; c_x \\
0 &amp; f_y &amp; c_y \\
0 &amp; 0 &amp; 1
\end{bmatrix}
\end{split}\]</div>
<p>æ­¤å¤–ï¼Œæœ‰æ—¶è¿˜åŒ…æ‹¬<strong>ç•¸å˜å‚æ•°</strong>ï¼ˆdistortion coefficientsï¼‰ï¼š</p>
<ul class="simple">
<li><p>å¾„å‘ç•¸å˜ï¼š<span class="math notranslate nohighlight">\( k_1, k_2, k_3 \)</span></p></li>
<li><p>åˆ‡å‘ç•¸å˜ï¼š<span class="math notranslate nohighlight">\( p_1, p_2 \)</span></p></li>
</ul>
</section>
<hr class="docutils" />
<section id="extrinsic-parameters">
<h3>ğŸŒ äºŒã€å¤–å‚ï¼ˆExtrinsic Parametersï¼‰<a class="headerlink" href="#extrinsic-parameters" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>å¤–å‚æè¿°çš„æ˜¯<strong>æ‘„åƒå¤´ç›¸å¯¹äºä¸–ç•Œåæ ‡ç³»çš„ä½ç½®å’Œæœå‘</strong>ï¼Œå³ä¸–ç•Œåæ ‡å¦‚ä½•å˜æ¢åˆ°æ‘„åƒå¤´åæ ‡ã€‚åŒ…å«ï¼š</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>å‚æ•°</p></th>
<th class="head"><p>å«ä¹‰</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\( R \)</span></p></td>
<td><p>æ—‹è½¬çŸ©é˜µï¼Œè¡¨ç¤ºä¸–ç•Œåæ ‡ç³»åˆ°æ‘„åƒå¤´åæ ‡ç³»çš„æ—‹è½¬</p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\( t \)</span></p></td>
<td><p>å¹³ç§»å‘é‡ï¼Œè¡¨ç¤ºä¸–ç•Œåæ ‡ç³»åŸç‚¹åœ¨æ‘„åƒå¤´åæ ‡ç³»ä¸‹çš„ä½ç½®</p></td>
</tr>
</tbody>
</table>
<p>å¯ä»¥ç»„æˆä¸€ä¸ªå˜æ¢çŸ©é˜µï¼š</p>
<div class="math notranslate nohighlight">
\[
\text{Extrinsic} = [R \ | \ t]
\]</div>
</section>
<hr class="docutils" />
<section id="id3">
<h3>ğŸ§® ä¸‰ã€ä¸‰ç»´ç‚¹åˆ°å›¾åƒç‚¹çš„æ˜ å°„å…¬å¼<a class="headerlink" href="#id3" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>ç»™å®šä¸€ä¸ªä¸–ç•Œåæ ‡ç³»ä¸­çš„ä¸‰ç»´ç‚¹ <span class="math notranslate nohighlight">\( X_{world} \)</span>ï¼Œå®ƒæŠ•å½±åˆ°å›¾åƒåæ ‡ç³»çš„å…¬å¼å¦‚ä¸‹ï¼š</p>
<div class="math notranslate nohighlight">
\[
x_{image} = K \cdot [R \ | \ t] \cdot X_{world}
\]</div>
<p>å…¶ä¸­ï¼š</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( X_{world} \)</span> æ˜¯é½æ¬¡åæ ‡è¡¨ç¤ºçš„ä¸‰ç»´ç‚¹ï¼š$<span class="math notranslate nohighlight">\(
[X, Y, Z, 1]^T
\)</span>$</p></li>
<li><p><span class="math notranslate nohighlight">\( [R|t] \)</span> æ˜¯ 3x4 çš„å¤–å‚çŸ©é˜µ</p></li>
<li><p><span class="math notranslate nohighlight">\( K \)</span> æ˜¯ 3x3 çš„å†…å‚çŸ©é˜µ</p></li>
<li><p><span class="math notranslate nohighlight">\( x_{image} \)</span> æ˜¯å›¾åƒä¸­çš„ç‚¹ï¼Œé€šå¸¸éœ€è¦å†å½’ä¸€åŒ–å¤„ç†ï¼ˆé™¤ä»¥zï¼‰</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="id4">
<h3>ğŸ¯ åº”ç”¨åœºæ™¯<a class="headerlink" href="#id4" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p><strong>ç›¸æœºæ ‡å®šï¼ˆCamera Calibrationï¼‰</strong>ï¼šè·å–å†…å¤–å‚</p></li>
<li><p><strong>ä¸‰ç»´é‡å»º / SLAM</strong>ï¼šåˆ©ç”¨å¤–å‚è¿½è¸ªæ‘„åƒå¤´ä½ç½®</p></li>
<li><p><strong>AR å¢å¼ºç°å®</strong>ï¼šå®ç°è™šå®å¯¹é½ï¼Œå¿…é¡»å‡†ç¡®çŸ¥é“å†…å¤–å‚</p></li>
</ul>
</section>
</section>
<section id="abstract">
<h2>Abstract<a class="headerlink" href="#abstract" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<ul class="simple">
<li><p>åŸæ–‡ï¼š</p>
<ul>
<li><p><strong>Multi-view stereo reconstruction (MVS) in the wild requires to first estimate the camera parameters e.g. intrinsic and extrinsic parameters. These are usually tedious and cumbersome to obtain, yet they are mandatory to triangulate corresponding pixels in 3D space, which is the core of all best performing MVS algorithms.</strong></p></li>
</ul>
</li>
<li><p>ä¸­æ–‡è§£é‡Šï¼š</p>
<ul>
<li><p>åœ¨è‡ªç„¶ç¯å¢ƒä¸‹è¿›è¡Œå¤šè§†å›¾ç«‹ä½“é‡å»ºï¼ˆMVSï¼‰æ—¶ï¼Œé¦–å…ˆéœ€è¦ä¼°è®¡ç›¸æœºçš„å‚æ•°ï¼Œä¾‹å¦‚å†…å‚ï¼ˆintrinsicï¼‰å’Œå¤–å‚ï¼ˆextrinsicï¼‰ã€‚ä½†è¿™äº›å‚æ•°é€šå¸¸å¾ˆéš¾è·å–ä¸”è¿‡ç¨‹ç¹çã€‚ç„¶è€Œï¼Œå®ƒä»¬æ˜¯å¿…é¡»çš„ï¼Œå› ä¸ºåªæœ‰é€šè¿‡è¿™äº›å‚æ•°ï¼Œæ‰èƒ½å°†ä¸åŒå›¾åƒä¸­å¯¹åº”åƒç´ ç‚¹ä¸‰è§’æµ‹é‡è¿˜åŸä¸º3Dç©ºé—´ä¸­çš„ç‚¹ï¼Œè¿™æ˜¯ç›®å‰è¡¨ç°æœ€å¥½çš„MVSç®—æ³•çš„æ ¸å¿ƒã€‚</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<ul class="simple">
<li><p>åŸæ–‡ï¼š</p>
<ul>
<li><p><strong>In this work, we take an opposite stance and introduce DUSt3R, a radically novel paradigm for Dense and Unconstrained Stereo 3D Reconstruction of arbitrary image collections, i.e. operating without prior information about camera calibration nor viewpoint poses.</strong></p></li>
</ul>
</li>
<li><p>ä¸­æ–‡è§£é‡Šï¼š</p>
<ul>
<li><p>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§å®Œå…¨ä¸åŒçš„åšæ³•ï¼Œåä¸º <strong>DUSt3R</strong>ï¼Œå®ƒæ˜¯ä¸€ç§<strong>å¯†é›†ä¸”æ— çº¦æŸçš„ç«‹ä½“ä¸‰ç»´é‡å»ºæ–°èŒƒå¼</strong>ã€‚å®ƒèƒ½å¤„ç†ä»»æ„å›¾åƒé›†åˆï¼Œ<strong>ä¸éœ€è¦ä»»ä½•ç›¸æœºæ ‡å®šä¿¡æ¯æˆ–ç›¸æœºä½å§¿å…ˆéªŒ</strong>ï¼Œå½»åº•æ‘†è„±äº†ä¼ ç»ŸMVSçš„é™åˆ¶ã€‚</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<ul class="simple">
<li><p>åŸæ–‡ï¼š</p>
<ul>
<li><p><strong>We cast the pairwise reconstruction problem as a regression of pointmaps, relaxing the hard constraints of usual projective camera models. We show that this formulation smoothly unifies the monocular and binocular reconstruction cases.</strong></p></li>
</ul>
</li>
<li><p>ä¸­æ–‡è§£é‡Šï¼š</p>
<ul>
<li><p>æˆ‘ä»¬å°†ä¸¤å¼ å›¾åƒä¹‹é—´çš„é‡å»ºé—®é¢˜<strong>è½¬åŒ–ä¸ºâ€œç‚¹å›¾ï¼ˆpointmapsï¼‰â€çš„å›å½’ä»»åŠ¡</strong>ï¼Œä»è€Œæ”¾æ¾äº†ä¼ ç»ŸæŠ•å½±ç›¸æœºæ¨¡å‹çš„ä¸¥æ ¼çº¦æŸã€‚æˆ‘ä»¬è¯æ˜ï¼Œè¿™ç§è¡¨è¿°æ–¹å¼èƒ½å¤Ÿ<strong>è‡ªç„¶åœ°ç»Ÿä¸€å•ç›®å’ŒåŒç›®é‡å»ºä»»åŠ¡</strong>ã€‚</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<ul class="simple">
<li><p>åŸæ–‡ï¼š</p>
<ul>
<li><p><strong>In the case where more than two images are provided, we further propose a simple yet effective global alignment strategy that expresses all pairwise pointmaps in a common reference frame.</strong></p></li>
</ul>
</li>
<li><p>ä¸­æ–‡è§£é‡Šï¼š</p>
<ul>
<li><p>å½“è¾“å…¥çš„å›¾åƒè¶…è¿‡ä¸¤å¼ æ—¶ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥æå‡ºäº†ä¸€ç§<strong>ç®€å•è€Œæœ‰æ•ˆçš„å…¨å±€å¯¹é½ç­–ç•¥</strong>ï¼Œå¯ä»¥å°†æ‰€æœ‰ä¸¤ä¸¤å›¾åƒä¹‹é—´çš„ç‚¹å›¾<strong>ç»Ÿä¸€åˆ°ä¸€ä¸ªå…¬å…±å‚è€ƒåæ ‡ç³»ä¸­</strong>ã€‚</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<ul class="simple">
<li><p>åŸæ–‡ï¼š</p>
<ul>
<li><p><strong>We base our network architecture on standard Transformer encoders and decoders, allowing us to leverage powerful pretrained models.</strong></p></li>
</ul>
</li>
<li><p>ä¸­æ–‡è§£é‡Šï¼š</p>
<ul>
<li><p>æˆ‘ä»¬é‡‡ç”¨æ ‡å‡†çš„ Transformer ç¼–ç å™¨å’Œè§£ç å™¨ä½œä¸ºç½‘ç»œæ¶æ„ï¼Œ<strong>å¯ä»¥å……åˆ†åˆ©ç”¨å·²æœ‰çš„å¼ºå¤§é¢„è®­ç»ƒæ¨¡å‹</strong>ã€‚</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<ul class="simple">
<li><p>åŸæ–‡ï¼š</p>
<ul>
<li><p><strong>Our formulation directly provides a 3D model of the scene as well as depth information, but interestingly, we can seamlessly recover from it, pixel matches, relative and absolute cameras.</strong></p></li>
</ul>
</li>
<li><p>ä¸­æ–‡è§£é‡Šï¼š</p>
<ul>
<li><p>æˆ‘ä»¬çš„æ–¹æ³•ä¸ä»…èƒ½<strong>ç›´æ¥è¾“å‡ºåœºæ™¯çš„3Dæ¨¡å‹å’Œæ·±åº¦å›¾ä¿¡æ¯</strong>ï¼Œè€Œä¸”æœ‰è¶£çš„æ˜¯ï¼Œè¿˜èƒ½ä»ä¸­<strong>è‡ªç„¶æ¢å¤åƒç´ åŒ¹é…å…³ç³»ã€ç›¸å¯¹å’Œç»å¯¹çš„ç›¸æœºå‚æ•°</strong>ã€‚</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<ul class="simple">
<li><p>åŸæ–‡ï¼š</p>
<ul>
<li><p><strong>Exhaustive experiments on all these tasks showcase that the proposed DUSt3R can unify various 3D vision tasks and set new SoTAs on monocular/multi-view depth estimation as well as relative pose estimation.</strong></p></li>
</ul>
</li>
<li><p>ä¸­æ–‡è§£é‡Šï¼š</p>
<ul>
<li><p>å¤§é‡å®éªŒè¡¨æ˜ï¼ŒDUSt3R èƒ½<strong>ç»Ÿä¸€å¤šç§3Dè§†è§‰ä»»åŠ¡</strong>ï¼Œå¹¶åœ¨<strong>å•ç›®/å¤šè§†å›¾æ·±åº¦ä¼°è®¡ã€ç›¸å¯¹ä½å§¿ä¼°è®¡ç­‰ä»»åŠ¡ä¸Šè®¾ç«‹äº†æ–°çš„SOTAï¼ˆæœ€ä½³ç»“æœï¼‰</strong>ã€‚</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<ul class="simple">
<li><p>åŸæ–‡ï¼š</p>
<ul>
<li><p><strong>In summary, DUSt3R makes many geometric 3D vision tasks easy.</strong></p></li>
</ul>
</li>
<li><p>ä¸­æ–‡è§£é‡Šï¼š</p>
<ul>
<li><p>æ€»ä¹‹ï¼ŒDUSt3R <strong>è®©å¾ˆå¤šå‡ ä½•ç±»3Dè§†è§‰ä»»åŠ¡å˜å¾—æ›´ç®€å•</strong>äº†ã€‚</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<ul class="simple">
<li><p>æ€»ç»“è¦ç‚¹ï¼š</p></li>
</ul>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>å…³é”®ç‚¹</p></th>
<th class="head"><p>å†…å®¹</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ä¼ ç»ŸMVSé—®é¢˜</p></td>
<td><p>ä¾èµ–ç¹ççš„ç›¸æœºå†…å¤–å‚ä¼°è®¡</p></td>
</tr>
<tr class="row-odd"><td><p>DUSt3Råˆ›æ–°ç‚¹</p></td>
<td><p>ä¸ä¾èµ–ç›¸æœºå‚æ•°ï¼Œç›´æ¥ä»å›¾åƒæ„å»º3Dæ¨¡å‹</p></td>
</tr>
<tr class="row-even"><td><p>æŠ€æœ¯æ–¹æ³•</p></td>
<td><p>ç‚¹å›¾å›å½’ + Transformeræ¶æ„</p></td>
</tr>
<tr class="row-odd"><td><p>é€‚ç”¨èŒƒå›´</p></td>
<td><p>å•ç›®ã€åŒç›®ã€å¤šè§†å›¾éƒ½é€‚ç”¨</p></td>
</tr>
<tr class="row-even"><td><p>èƒ½åŠ›è¾“å‡º</p></td>
<td><p>å¯è·å–3Dæ¨¡å‹ã€æ·±åº¦å›¾ã€åƒç´ åŒ¹é…ã€ç›¸æœºå§¿æ€</p></td>
</tr>
<tr class="row-odd"><td><p>æˆæœè¡¨ç°</p></td>
<td><p>å¤šä¸ªä»»åŠ¡ä¸Šåˆ·æ–°SOTAè¡¨ç°</p></td>
</tr>
</tbody>
</table>
</section>
<hr class="docutils" />
<section id="introduction">
<h2>1. Introduction<a class="headerlink" href="#introduction" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p>DUSt3Rï¼šä¸€ç§ç”¨äºä»å¤šè§†å›¾å›¾åƒä¸­è¿›è¡Œç¨ å¯†ä¸‰ç»´é‡å»ºï¼ˆDense 3D Reconstructionï¼‰çš„æ–°æ–¹æ³•ã€‚</p>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/04/0xxYoP.png" /></p>
<p>Figure 1: Overview: Given an unconstrained image collection, i.e. a set of photographs with unknown camera poses and intrinsics, our proposed method DUSt3R outputs a set of corresponding pointmaps, from which we can straightforwardly recover a variety of geometric quantities normally difficult to estimate all at once, such as the camera parameters, pixel correspondences, depthmaps, and fully-consistent 3D reconstruction. Note that DUSt3R also works for a single input image (e.g. achieving in this case monocular reconstruction). We also show qualitative examples on the DTU, Tanks and Temples and ETH-3D datasets [108, 51, 1] obtained without known camera parameters. For each sample, from left to right: input image, colored point cloud, and rendered with shading for a better view of the underlying geometry.</p>
<hr class="docutils" />
<section id="id5">
<h3>ğŸ’¡ ç¬¬ä¸€æ®µï¼šèƒŒæ™¯ä»‹ç»<a class="headerlink" href="#id5" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<blockquote>
<div><p><strong>ä»»åŠ¡ç›®æ ‡ï¼š</strong></p>
</div></blockquote>
<ul class="simple">
<li><p>ä»å¤šå¼ å›¾åƒä¸­ï¼Œä¼°è®¡ä¸€ä¸ªåœºæ™¯çš„ä¸‰ç»´å‡ ä½•ç»“æ„å’Œç›¸æœºå‚æ•°â€”â€”è¿™æ˜¯è®¡ç®—æœºè§†è§‰é•¿æœŸè¿½æ±‚çš„ç»ˆæç›®æ ‡ä¹‹ä¸€ã€‚</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">å¤‡æ³¨</p>
<p>Unconstrained image-based dense 3D reconstruction from multiple views is one of a few long-researched end-goals of computer vision.</p>
</div>
<blockquote>
<div><p><strong>å®é™…æ„ä¹‰ï¼š</strong></p>
</div></blockquote>
<ul class="simple">
<li><p>å®ƒæœ‰å¾ˆå¤šåº”ç”¨ï¼Œå¦‚åœ°å›¾åˆ¶ä½œã€å¯¼èˆªã€è€ƒå¤ã€æ–‡åŒ–é—äº§ä¿æŠ¤ã€æœºå™¨äººç­‰ã€‚åŒæ—¶ï¼Œå®ƒä¹Ÿæ¶µç›–äº†å‡ ä¹æ‰€æœ‰å‡ ä½•ç›¸å…³çš„ 3D è§†è§‰ä»»åŠ¡ã€‚</p></li>
</ul>
<blockquote>
<div><p><strong>æŠ€æœ¯æ¼”è¿›ï¼š</strong></p>
</div></blockquote>
<ul class="simple">
<li><p>ä¼ ç»Ÿ 3D é‡å»ºæ–¹æ³•æ˜¯å¤šä¸ªå­é¢†åŸŸé•¿æœŸæŠ€æœ¯ç§¯ç´¯çš„æˆæœï¼Œæ¯”å¦‚</p>
<ul>
<li><p>å…³é”®ç‚¹æ£€æµ‹(keypoint detection)</p></li>
<li><p>ç‰¹å¾åŒ¹é…(keypoint matching)</p></li>
<li><p>é²æ£’ä¼°è®¡(robust estimation)</p></li>
<li><p>Structure-from-Motionï¼ˆSfMï¼‰ã€</p></li>
<li><p>Bundle Adjustmentï¼ˆBAï¼‰ã€</p></li>
<li><p>ç¨ å¯†å¤šè§†å›¾ç«‹ä½“(dense Multi-View Stereo (MVS) )</p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="id6">
<h3>ğŸ”§ ç¬¬äºŒæ®µï¼šä¼ ç»Ÿæ–¹æ³•çš„ä¸è¶³<a class="headerlink" href="#id6" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<blockquote>
<div><p><strong>ä¼ ç»Ÿ SfM + MVS æµç¨‹ï¼š</strong></p>
</div></blockquote>
<ul class="simple">
<li><p>æ˜¯ä¸€è¿ä¸²â€œæœ€å°å­é—®é¢˜â€ï¼ˆå¦‚ç‰¹å¾åŒ¹é…ã€ä¸‰è§’åŒ–ã€ç›¸æœºä¼°è®¡ã€ç¨€ç–é‡å»ºåˆ°ç¨ å¯†é‡å»ºï¼‰ç»„æˆçš„å¤æ‚æµç¨‹ã€‚</p></li>
</ul>
<blockquote>
<div><p><strong>é—®é¢˜åœ¨äºï¼š</strong></p>
</div></blockquote>
<ul class="simple">
<li><p>è¿™äº›å­é—®é¢˜ä¹‹é—´<strong>ç›¸äº’ç‹¬ç«‹</strong>ï¼Œå½¼æ­¤ä¸åä½œï¼Œé”™è¯¯ä¼šçº§è”ä¼ é€’ï¼Œå¯¼è‡´ç»“æœå®¹æ˜“å—åˆ°å½±å“ã€‚æ­¤å¤–ï¼Œä¸€äº›å…³é”®æ­¥éª¤ï¼ˆæ¯”å¦‚ SfMï¼‰åœ¨å¾ˆå¤šæƒ…å†µä¸‹ä¸ç¨³å›ºï¼Œå®¹æ˜“å¤±è´¥ï¼ˆæ¯”å¦‚å›¾åƒæ•°é‡å¤ªå°‘ã€ç‰©ä½“åå…‰ã€ç›¸æœºè¿åŠ¨å¤ªå°ç­‰ï¼‰ã€‚</p></li>
</ul>
<blockquote>
<div><p><strong>æ ¸å¿ƒé—®é¢˜ï¼š</strong></p>
</div></blockquote>
<ul class="simple">
<li><p>å¦‚æœç›¸æœºå‚æ•°ä¼°è®¡ä¸å‡†ï¼ŒMVS çš„ç»“æœè´¨é‡ä¹Ÿä¼šè·Ÿç€ä¸‹é™ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="dust3r">
<h3>ğŸš€ ç¬¬ä¸‰æ®µï¼šDUSt3R çš„æ ¸å¿ƒåˆ›æ–°<a class="headerlink" href="#dust3r" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<blockquote>
<div><p><strong>ç›®æ ‡ï¼š</strong></p>
</div></blockquote>
<ul class="simple">
<li><p>æå‡ºä¸€ç§æ–°çš„ã€<strong>ç«¯åˆ°ç«¯</strong>çš„ç³»ç»Ÿ DUSt3Rï¼Œæ”¯æŒä» <strong>ä»»æ„ä¸¤å¼ å›¾åƒ</strong> ä¸­ï¼Œé‡å»ºä¸‰ç»´ç»“æ„ï¼Œ<strong>ä¸éœ€è¦ä»»ä½•ç›¸æœºå‚æ•°ï¼ˆç”šè‡³è¿å†…å‚éƒ½ä¸éœ€è¦ï¼‰</strong>ã€‚</p></li>
</ul>
<blockquote>
<div><p><strong>å…³é”®ç‚¹ï¼š</strong></p>
</div></blockquote>
<ul class="simple">
<li><p>DUSt3R è¾“å‡ºçš„æ˜¯ä¸€ç§æ–°çš„ç»“æ„å« <strong>3D Pointmap</strong>ï¼Œå®ƒå…·æœ‰ä»¥ä¸‹èƒ½åŠ›ï¼š</p>
<ol class="arabic simple">
<li><p>è¡¨ç¤ºåœºæ™¯å‡ ä½•ï¼›</p></li>
<li><p>å…³è”å›¾åƒåƒç´ å’Œä¸‰ç»´ç‚¹ï¼›</p></li>
<li><p>è¡¨è¾¾ä¸¤ä¸ªè§†è§’ä¹‹é—´çš„å‡ ä½•å…³ç³»ã€‚</p></li>
</ol>
</li>
</ul>
<blockquote>
<div><p><strong>ä¼˜åŠ¿ï¼š</strong></p>
</div></blockquote>
<ul class="simple">
<li><p>åªé€šè¿‡ä¸€ä¸ªç½‘ç»œï¼Œå°±èƒ½è”åˆå¤„ç†è¾“å…¥å›¾åƒå’Œç”Ÿæˆçš„ 3D Pointmapï¼Œ<strong>æŠŠè¿‡å»å¤šä¸ªå­é—®é¢˜åˆå¹¶ä¸ºä¸€ä¸ªé—®é¢˜æ¥å­¦ä¹ å’Œè§£å†³</strong>ï¼Œä»è€Œæé«˜æ•´ä½“ååŒä¸å‡†ç¡®æ€§ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="id7">
<h3>ğŸ“š ç¬¬å››æ®µï¼šè®­ç»ƒä¸å»ºæ¨¡æ€è·¯<a class="headerlink" href="#id7" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<blockquote>
<div><p><strong>è®­ç»ƒæ–¹å¼ï¼š</strong></p>
</div></blockquote>
<ul class="simple">
<li><p>é‡‡ç”¨ç›‘ç£å­¦ä¹ ï¼Œä½¿ç”¨åˆæˆæ•°æ®ã€SfM é‡å»ºæ•°æ®æˆ–çœŸå®ä¼ æ„Ÿå™¨é‡‡é›†æ•°æ®ã€‚</p></li>
</ul>
<blockquote>
<div><p><strong>æ¶æ„é€‰æ‹©ï¼š</strong></p>
</div></blockquote>
<ul class="simple">
<li><p>æ‘’å¼ƒä»»åŠ¡ç‰¹å®šæ¨¡å—ï¼Œä½¿ç”¨<strong>é€šç”¨ Transformer æ¶æ„</strong>ï¼Œå®Œå…¨æ•°æ®é©±åŠ¨ï¼Œä¸å¼ºåŠ å‡ ä½•å…ˆéªŒã€‚</p></li>
</ul>
<blockquote>
<div><p><strong>ç½‘ç»œå­¦åˆ°çš„ä¸œè¥¿ï¼š</strong></p>
</div></blockquote>
<ul class="simple">
<li><p>åŒ…æ‹¬çº¹ç†ã€é˜´å½±ã€è½®å»“ç­‰å½¢çŠ¶å…ˆéªŒï¼Œä¸ä¼ ç»Ÿ MVS æ‰€ä¾èµ–çš„å‡ ä½• cue ç±»ä¼¼ï¼Œä½†æ˜¯é€šè¿‡å­¦ä¹ å¾—åˆ°çš„ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="id8">
<h3>ğŸ§© ç¬¬äº”æ®µï¼šå¤šè§†å›¾èåˆæ–¹å¼çš„æ–°è®¾è®¡<a class="headerlink" href="#id8" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<blockquote>
<div><p><strong>ä¼ ç»Ÿ BAï¼š</strong></p>
</div></blockquote>
<ul class="simple">
<li><p>é€šè¿‡æœ€å°åŒ–é‡æŠ•å½±è¯¯å·®å¯¹ç›¸æœºå’Œç‚¹è¿›è¡Œä¼˜åŒ–ã€‚</p></li>
</ul>
<blockquote>
<div><p><strong>DUSt3R çš„åšæ³•ï¼š</strong></p>
</div></blockquote>
<ul class="simple">
<li><p>å¼•å…¥ä¸€ç§æ–°çš„å…¨å±€å¯¹é½æ–¹æ³•ï¼Œä¸å†ä½¿ç”¨é‡æŠ•å½±è¯¯å·®ï¼Œè€Œæ˜¯<strong>ç›´æ¥åœ¨ä¸‰ç»´ç©ºé—´ä¸­å¯¹é½ç›¸æœºå’Œå‡ ä½•ä¿¡æ¯</strong>ï¼Œæ›´å¿«ã€æ›´ç¨³å®šã€‚</p></li>
</ul>
<blockquote>
<div><p><strong>æ•ˆæœï¼š</strong></p>
</div></blockquote>
<ul class="simple">
<li><p>åœ¨çœŸå®åœºæ™¯å’ŒæœªçŸ¥ç›¸æœºæ¡ä»¶ä¸‹ä¹Ÿèƒ½å¾—åˆ°ä¸€è‡´çš„é‡å»ºæ•ˆæœã€‚å¹¶ä¸”å¯ä»¥ç”¨äºå•ç›®å’Œå¤šè§†å›¾çš„åœºæ™¯ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="id9">
<h3>ğŸ“ æ€»ç»“ï¼šè®ºæ–‡è´¡çŒ®ï¼ˆå››ä¸ªæ–¹é¢ï¼‰<a class="headerlink" href="#id9" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ol class="arabic simple">
<li><p><strong>é¦–æ¬¡å®ç°ï¼š</strong><br />
ä¸€ä¸ªç»Ÿä¸€ã€ç«¯åˆ°ç«¯çš„ 3D é‡å»ºæ–¹æ³•ï¼Œä¸éœ€è¦ç›¸æœºå‚æ•°ï¼Œæ”¯æŒå•ç›®å’ŒåŒç›®è¾“å…¥ã€‚</p></li>
<li><p><strong>Pointmap è¡¨ç¤ºï¼š</strong><br />
æå‡º Pointmap çš„æ–¹å¼ä¿ç•™äº†åƒç´ ä¸åœºæ™¯ä¹‹é—´çš„å…³ç³»ï¼Œ<strong>è§„é¿äº†é€è§†æŠ•å½±ä¸­çš„çº¦æŸ</strong>ã€‚</p></li>
<li><p><strong>å¤šè§†å›¾èåˆæ–°ç­–ç•¥ï¼š</strong><br />
é€šè¿‡ 3D å¯¹é½æ¥èåˆå¤šå¯¹å›¾åƒçš„é‡å»ºç»“æœï¼Œ<strong>ä¸ä¾èµ– SfM/MVS çš„ä¸­é—´æ­¥éª¤</strong>ï¼Œä½†èƒ½å¯¼å‡ºå®ƒä»¬å¸¸è§çš„è¾“å‡ºï¼ˆç›¸æœºä½å§¿ã€ç¨€ç–ç‚¹äº‘ç­‰ï¼‰ã€‚</p></li>
<li><p><strong>ä¼˜å¼‚æ€§èƒ½è¡¨ç°ï¼š</strong><br />
åœ¨å•ç›®/å¤šè§†å›¾æ·±åº¦ä¼°è®¡ã€ç›¸æœºä½å§¿ä¼°è®¡ä»»åŠ¡ä¸­å–å¾— SOTAï¼ˆstate-of-the-artï¼‰ç»“æœã€‚</p></li>
</ol>
</section>
</section>
<hr class="docutils" />
<section id="related-work">
<h2>2. Related Work<a class="headerlink" href="#related-work" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<section id="structure-from-motion-sfm">
<h3><strong>1. Structure-from-Motion (SfM)</strong><a class="headerlink" href="#structure-from-motion-sfm" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p>ğŸ” æ˜¯ä»€ä¹ˆï¼Ÿ</p>
<ul>
<li><p>SfMï¼ˆè¿åŠ¨æ¢å¤ç»“æ„ï¼‰æ˜¯æŒ‡ä»å¤šå¼ å›¾åƒä¸­ä¼°è®¡ç›¸æœºå‚æ•°ï¼ŒåŒæ—¶é‡å»ºç¨€ç–çš„ 3D ç‚¹äº‘åœ°å›¾ã€‚</p></li>
</ul>
</li>
<li><p>ğŸ“Œ ä¼ ç»Ÿæµç¨‹ï¼š</p>
<ul>
<li><p>åŸºäºå…³é”®ç‚¹åŒ¹é…ï¼ˆkeypoint matchingï¼‰è·å¾—åƒç´ é—´çš„å¯¹åº”å…³ç³»ã€‚</p></li>
<li><p>ç„¶åé€šè¿‡æŸæŸè°ƒæ•´ï¼ˆbundle adjustmentï¼‰ä¼˜åŒ–ç›¸æœºå§¿æ€å’Œ 3D ç‚¹çš„ä½ç½®ã€‚</p></li>
</ul>
</li>
<li><p>ğŸš€ è¿‘å¹´æ¥çš„è¿›å±•ï¼š</p>
<ul>
<li><p>å¼•å…¥äº† <strong>å­¦ä¹ æ–¹æ³•</strong>ï¼Œå¢å¼ºäº†å¦‚ä¸‹æ¨¡å—ï¼š</p>
<ul>
<li><p>ç‰¹å¾æå–ä¸æè¿°ï¼ˆfeature descriptionï¼‰</p></li>
<li><p>å›¾åƒåŒ¹é…ï¼ˆimage matchingï¼‰</p></li>
<li><p>ç‰¹å¾åº¦é‡ä¼˜åŒ–ï¼ˆfeaturemetric refinementï¼‰</p></li>
<li><p>ç¥ç»æŸæŸè°ƒæ•´ï¼ˆneural bundle adjustmentï¼‰</p></li>
</ul>
</li>
</ul>
</li>
<li><p>âš ï¸ ä¸»è¦é—®é¢˜ï¼š</p>
<ul>
<li><p>å°½ç®¡æœ‰å¾ˆå¤šå­¦ä¹ é©±åŠ¨çš„æ”¹è¿›ï¼ŒSfM ä¾ç„¶æ˜¯ä¸€ä¸ª<strong>ä¸²è¡Œæµç¨‹ï¼ˆsequential pipelineï¼‰</strong>ï¼Œå„æ¨¡å—ä¹‹é—´å¼ºä¾èµ–ï¼Œå› æ­¤å®¹æ˜“å—åˆ°å™ªå£°ä¼ æ’­çš„å½±å“ã€‚</p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="multi-view-stereo-mvs">
<h3><strong>2. Multi-View Stereo (MVS)</strong><a class="headerlink" href="#multi-view-stereo-mvs" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p>ğŸ” æ˜¯ä»€ä¹ˆï¼Ÿ</p>
<ul>
<li><p>MVS æ˜¯ç”¨äºä»å¤šè§†è§’å›¾åƒä¸­<strong>å¯†é›†é‡å»ºç‰©ä½“è¡¨é¢</strong>çš„ä»»åŠ¡ï¼Œé€šå¸¸è¦æ±‚å·²çŸ¥ç›¸æœºå‚æ•°ã€‚</p></li>
</ul>
</li>
<li><p>ğŸ“Œ MVSæ–¹æ³•åˆ†ä¸ºä¸‰ç±»ï¼š</p>
<ul>
<li><p>çº¯æ‰‹å·¥è®¾è®¡çš„æ–¹æ³•</p></li>
<li><p>åŸºäºåœºæ™¯ä¼˜åŒ–çš„æ–¹æ³•</p></li>
<li><p>åŸºäºå­¦ä¹ çš„æ–¹æ³•</p></li>
</ul>
</li>
<li><p>âš ï¸ ä¸»è¦é—®é¢˜ï¼š
è¿™äº›æ–¹æ³•éƒ½ä¾èµ–å‡†ç¡®çš„ç›¸æœºå‚æ•°ï¼ˆå¦‚å†…å‚ã€ä½å§¿ï¼‰ï¼Œä½†<strong>ç°å®ä¸­è·å–å‡†ç¡®ç›¸æœºå‚æ•°å¹¶ä¸å®¹æ˜“</strong>ï¼Œå½±å“ç®—æ³•çš„é²æ£’æ€§ã€‚</p></li>
<li><p>âœ… æœ¬æ–‡çš„æ–¹æ³•ï¼š</p>
<ul>
<li><p>ç›´æ¥é¢„æµ‹å‡ ä½•ç»“æ„ï¼ˆ3D è¡¨é¢ï¼‰ï¼Œ<strong>ä¸ä¾èµ–ç›¸æœºå‚æ•°</strong>ï¼Œå‡å°‘å®é™…ä½¿ç”¨éš¾åº¦ã€‚</p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="direct-rgb-to-3d">
<h3><strong>3. Direct RGB-to-3D</strong><a class="headerlink" href="#direct-rgb-to-3d" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p>ğŸ” æ˜¯ä»€ä¹ˆï¼Ÿ</p>
<ul>
<li><p>è¿‘å¹´æ¥æœ‰äº›æ–¹æ³•å°è¯•ä»<strong>å•å¼  RGB å›¾åƒç›´æ¥é¢„æµ‹ 3D ç»“æ„</strong>ï¼Œä½†è¿™ä¸ªä»»åŠ¡æœ¬è´¨ä¸Šæ˜¯ç—…æ€é—®é¢˜ï¼ˆill-posedï¼‰ï¼Œå› ä¸ºç¼ºä¹æ·±åº¦ä¿¡æ¯ã€‚</p></li>
</ul>
</li>
<li><p>ğŸ“Œ ä¸¤ç±»æ–¹æ³•ï¼š</p>
<ol class="arabic simple">
<li><p><strong>åŸºäºç±»åˆ«çš„å½¢çŠ¶å…ˆéªŒ</strong>ï¼š</p>
<ul>
<li><p>ä»å¤§é‡å›¾åƒä¸­å­¦ä¹ æ¯ç±»ç‰©ä½“çš„é€šç”¨å¤–å½¢ï¼ˆå¦‚äººã€è½¦ç­‰ï¼‰ï¼Œå¦‚ Pavllo ç­‰äººçš„æ–¹æ³•ã€‚</p></li>
<li><p>ç¼ºç‚¹ï¼šæ³›åŒ–èƒ½åŠ›å·®ï¼Œæ— æ³•å¤„ç†æœªçŸ¥ç±»åˆ«ã€‚</p></li>
</ul>
</li>
<li><p><strong>åŸºäºåœºæ™¯çš„æ·±åº¦ä¼°è®¡</strong>ï¼ˆå’Œæœ¬æ–‡æ›´ç›¸å…³ï¼‰ï¼š</p>
<ul>
<li><p>é€šå¸¸ä¾èµ–**å•ç›®æ·±åº¦ä¼°è®¡ï¼ˆMDEï¼‰**ç½‘ç»œï¼Œç»“åˆç›¸æœºå†…å‚å°†æ·±åº¦å›¾è½¬æ¢ä¸ºç‚¹äº‘ã€‚</p></li>
<li><p>ä¹Ÿæœ‰æ–¹æ³•è¯•å›¾é€šè¿‡è§†é¢‘å¸§æ—¶åºä¿¡æ¯æ¢å¤ç›¸æœºå†…å‚ï¼Œæˆ–ç›´æ¥é¢„æµ‹ç›¸æœºå†…å‚ã€‚</p></li>
</ul>
</li>
</ol>
</li>
<li><p>âš ï¸ ä¸»è¦é—®é¢˜ï¼š</p>
<ul>
<li><p>è¿™äº›æ–¹æ³•æœ€ç»ˆä¾ç„¶ä¾èµ–äºæ·±åº¦ä¼°è®¡ï¼Œè€Œå•ç›®æ·±åº¦ä¼°è®¡æœ¬èº«ä¸å¯é ã€‚</p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="pointmaps">
<h3><strong>4. æœ¬æ–‡çš„æ–¹æ³•ï¼šPointmaps å’ŒåŒè§†è§’è¾“å…¥</strong><a class="headerlink" href="#pointmaps" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p>âœ… æ ¸å¿ƒåˆ›æ–°ï¼š</p>
<ul>
<li><p><strong>åŒæ—¶è¾“å…¥ä¸¤å¼ å›¾åƒï¼ˆä¸¤ä¸ªè§†è§’ï¼‰</strong>ï¼Œè¾“å‡ºä¸¤ä¸ªç‚¹å›¾ï¼ˆpointmapsï¼‰ï¼Œè€Œä¸æ˜¯ä¼ ç»Ÿæ·±åº¦å›¾ã€‚</p></li>
<li><p>æ‰€æœ‰è¾“å‡ºçš„ 3D ç‚¹éƒ½ç»Ÿä¸€åœ¨ç¬¬ä¸€ä¸ªè§†è§’çš„åæ ‡ç³»ä¸­ã€‚</p></li>
<li><p>ç†è®ºä¸Šå¯ä»¥é€šè¿‡ä¸‰è§’æµ‹é‡å®ç°å‡ ä½•é‡å»ºã€‚</p></li>
</ul>
</li>
<li><p>ğŸ”§ ä¸ä¼ ç»Ÿçš„ MVS/SfM åŒºåˆ«ï¼š</p>
<ul>
<li><p>ä¸éœ€è¦æ˜ç¡®çš„ç›¸æœºå‚æ•°è¾“å…¥ã€‚</p></li>
<li><p>ç½‘ç»œç»“æ„æ”¯æŒ end-to-end å­¦ä¹ ï¼Œä¸å†æ˜¯ä¼ ç»Ÿä¸²è¡Œæµç¨‹ã€‚</p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="id10">
<h3><strong>5. Pointmaps çš„ä½¿ç”¨</strong><a class="headerlink" href="#id10" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p>ğŸ” ä»€ä¹ˆæ˜¯ Pointmapï¼Ÿ</p>
<ul>
<li><p>Pointmap æ˜¯ä¸€ä¸ªäºŒç»´å›¾åƒå¤§å°çš„æ•°ç»„ï¼Œå…¶ä¸­æ¯ä¸ªåƒç´ å¯¹åº”ä¸€ä¸ª 3D åæ ‡ç‚¹ã€‚</p></li>
<li><p>æ¯”æ·±åº¦å›¾åŒ…å«æ›´ä¸°å¯Œçš„ä¿¡æ¯ï¼Œä¾¿äºç›´æ¥å¤„ç† 3D ç»“æ„ã€‚</p></li>
</ul>
</li>
<li><p>ğŸ“Œ ç”¨é€”ï¼š</p>
<ul>
<li><p>åœ¨è§†è§‰å®šä½ã€è§†å›¾åˆæˆã€å•ç›®é‡å»ºç­‰ä»»åŠ¡ä¸­è¶Šæ¥è¶Šå¸¸ç”¨ã€‚</p></li>
<li><p>æä¾›äº†ä¸€ç§å¯ä»¥â€œåœ¨å›¾åƒç©ºé—´å¤„ç† 3D å½¢çŠ¶â€çš„æ–¹å¼ã€‚</p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="id11">
<h3>ğŸ§  æ€»ç»“ï¼š<a class="headerlink" href="#id11" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>æ¨¡å—</p></th>
<th class="head"><p>å†…å®¹</p></th>
<th class="head"><p>é—®é¢˜/ç“¶é¢ˆ</p></th>
<th class="head"><p>æœ¬æ–‡åˆ›æ–°</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>SfM</p></td>
<td><p>ç¨€ç–é‡å»ºï¼Œä¾èµ–å…³é”®ç‚¹åŒ¹é…å’Œä¼˜åŒ–</p></td>
<td><p>ä¸²è¡Œç»“æ„ï¼Œæ˜“è¢«å™ªå£°ç ´å</p></td>
<td><p>End-to-end ç»“æ„é¿å…é”™è¯¯ç´¯ç§¯</p></td>
</tr>
<tr class="row-odd"><td><p>MVS</p></td>
<td><p>å¯†é›†é‡å»ºï¼Œè¦æ±‚å·²çŸ¥ç›¸æœºå‚æ•°</p></td>
<td><p>ç›¸æœºå‚æ•°ä¼°è®¡ä¸å‡†ç¡®</p></td>
<td><p>æ— éœ€ç›¸æœºå‚æ•°ï¼Œç›´æ¥é¢„æµ‹å‡ ä½•ç»“æ„</p></td>
</tr>
<tr class="row-even"><td><p>å•ç›® RGB-3D</p></td>
<td><p>å•å¼ å›¾é¢„æµ‹æ·±åº¦</p></td>
<td><p>æ·±åº¦ä¼°è®¡ä¸å¯é </p></td>
<td><p>åŒå›¾é¢„æµ‹ pointmapï¼Œæ˜¾å¼ä¸‰è§’æµ‹é‡</p></td>
</tr>
<tr class="row-odd"><td><p>æœ¬æ–‡æ–¹æ³•</p></td>
<td><p>åŒæ—¶å¤„ç†ä¸¤è§†è§’ï¼Œè¾“å‡º pointmap</p></td>
<td><p>-</p></td>
<td><p>å¯¹ç›¸æœºå‚æ•°é›¶å‡è®¾ã€é²æ£’æ³›åŒ–å¥½</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<hr class="docutils" />
<section id="method">
<h2>3. Method<a class="headerlink" href="#method" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<section id="id12">
<h3>æ¦‚å¿µå®šä¹‰<a class="headerlink" href="#id12" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<section id="pointmap">
<h4>ğŸŸ¡ <strong>Pointmapï¼ˆç‚¹å›¾ï¼‰</strong><a class="headerlink" href="#pointmap" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>æˆ‘ä»¬æŠŠä¸€å¼ å›¾ç‰‡ä¸Šæ¯ä¸€ä¸ªåƒç´ ç‚¹éƒ½å¯¹åº”ä¸€ä¸ªä¸‰ç»´ç©ºé—´çš„ç‚¹ï¼Œç»„ç»‡æˆä¸€ä¸ªäºŒç»´çš„ç»“æ„ï¼ˆå®½ Ã— é«˜ Ã— 3ï¼‰ï¼Œç§°ä¸ºä¸€ä¸ª <strong>pointmapï¼ˆç‚¹å›¾ï¼‰</strong>ï¼Œè®°ä½œï¼š</p>
<div class="math notranslate nohighlight">
\[X âˆˆ â„^{(WÃ—HÃ—3)}\]</div>
<p>è¿™æ„å‘³ç€ï¼š</p>
<ul class="simple">
<li><p>å›¾åƒæœ‰ <code class="docutils literal notranslate"><span class="pre">W</span> <span class="pre">Ã—</span> <span class="pre">H</span></code> ä¸ªåƒç´ ç‚¹</p></li>
<li><p>æ¯ä¸ªåƒç´ å¯¹åº”ä¸€ä¸ª <code class="docutils literal notranslate"><span class="pre">3Dåæ ‡</span> <span class="pre">(x,</span> <span class="pre">y,</span> <span class="pre">z)</span></code></p></li>
<li><p>æ‰€ä»¥ä¸€å¼ å›¾åƒå¯¹åº”äº†ä¸€ä¸ª <code class="docutils literal notranslate"><span class="pre">W</span> <span class="pre">Ã—</span> <span class="pre">H</span> <span class="pre">Ã—</span> <span class="pre">3</span></code> çš„ä¸‰ç»´å¼ é‡</p></li>
</ul>
<p>å¹¶ä¸”ï¼Œè¿™ä¸ª pointmap å’ŒåŸå§‹çš„ RGB å›¾åƒæ˜¯ <strong>ä¸€ä¸€å¯¹åº”</strong> çš„ï¼š</p>
<div class="math notranslate nohighlight">
\[I[i, j] â†” X[i, j]\]</div>
<p>å³æ¯ä¸ªåƒç´  <code class="docutils literal notranslate"><span class="pre">(i,</span> <span class="pre">j)</span></code> åœ¨å›¾åƒä¸­æœ‰é¢œè‰²ä¿¡æ¯ <code class="docutils literal notranslate"><span class="pre">I[i,j]</span></code>ï¼ŒåŒæ—¶ä¹Ÿæœ‰ä¸€ä¸ª 3D ç‚¹ <code class="docutils literal notranslate"><span class="pre">X[i,j]</span></code>ï¼Œè¡¨ç¤ºè¿™ä¸ªåƒç´ ç‚¹åœ¨ç°å®ä¸‰ç»´ç©ºé—´ä¸­æ‰€å¯¹åº”çš„ä½ç½®ã€‚</p>
<p>ğŸ‘‰ å¯ä»¥ç†è§£ä¸ºï¼š<strong>ç‚¹å›¾æ˜¯ä¸€ä¸ªåƒç´ åˆ°ä¸‰ç»´ä¸–ç•Œåæ ‡çš„æ˜ å°„ã€‚</strong></p>
<blockquote>
<div><p>ğŸ“Œ æ³¨æ„ï¼šè¿™é‡Œå‡è®¾æ¯ä¸ªåƒç´ å°„å‡ºå»çš„å…‰çº¿åªèƒ½æ‰“åˆ°ä¸€ä¸ªå”¯ä¸€çš„ä¸‰ç»´ç‚¹ï¼Œå³ä¸è€ƒè™‘é€æ˜æˆ–åŠé€æ˜è¡¨é¢ã€‚</p>
</div></blockquote>
</section>
<hr class="docutils" />
<section id="cameras-and-scene">
<h4>ğŸŸ¡ <strong>ç›¸æœºä¸åœºæ™¯å»ºæ¨¡ï¼ˆCameras and Sceneï¼‰</strong><a class="headerlink" href="#cameras-and-scene" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>æˆ‘ä»¬ä½¿ç”¨ç›¸æœºçš„å†…å‚çŸ©é˜µ <span class="math notranslate nohighlight">\(K âˆˆ â„^{(3Ã—3)}\)</span> å’Œä¸€å¼ å¯¹åº”çš„ <strong>æ·±åº¦å›¾ <span class="math notranslate nohighlight">\(D âˆˆ â„^{(WÃ—H)}\)</span></strong> æ¥ç”Ÿæˆ pointmap <code class="docutils literal notranslate"><span class="pre">X</span></code>ã€‚</p>
<p>å…·ä½“è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š</p>
<div class="math notranslate nohighlight">
\[X[i,j] = Kâ»Â¹ * [i * D[i,j], j * D[i,j], D[i,j]]^T\]</div>
<p>æ„æ€æ˜¯ï¼š</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">D[i,j]</span></code> æ˜¯ç¬¬ <code class="docutils literal notranslate"><span class="pre">(i,</span> <span class="pre">j)</span></code> ä¸ªåƒç´ ç‚¹çš„æ·±åº¦å€¼ï¼ˆç›¸æœºåˆ°ç‰©ä½“çš„è·ç¦»ï¼‰</p></li>
<li><p>æˆ‘ä»¬å°†åƒç´ åæ ‡ <code class="docutils literal notranslate"><span class="pre">(i,</span> <span class="pre">j)</span></code> ä¹˜ä»¥æ·±åº¦ï¼Œå†åŠ ä¸Šæ·±åº¦å€¼æœ¬èº«ï¼Œç»„æˆä¸€ä¸ª <code class="docutils literal notranslate"><span class="pre">[x,</span> <span class="pre">y,</span> <span class="pre">z]</span></code> å‘é‡</p></li>
<li><p>ç„¶åç”¨ç›¸æœºå†…å‚çŸ©é˜µçš„é€† <code class="docutils literal notranslate"><span class="pre">Kâ»Â¹</span></code> åæŠ•å½±å›ç›¸æœºåæ ‡ç³»ï¼Œå¾—åˆ° 3D ç‚¹ <code class="docutils literal notranslate"><span class="pre">X[i,j]</span></code></p></li>
</ul>
<blockquote>
<div><p>âœ… è¿™ä¸€æ­¥æ˜¯ä»â€œå›¾åƒå¹³é¢ + æ·±åº¦â€ â†’ â€œä¸‰ç»´åæ ‡â€çš„æ ‡å‡†åæŠ•å½±æ“ä½œã€‚</p>
</div></blockquote>
</section>
<hr class="docutils" />
<section id="id13">
<h4>ğŸŸ¡ <strong>è·¨ç›¸æœºåæ ‡è½¬æ¢ï¼ˆå¤šè§†è§’ç‚¹å›¾çš„è½¬æ¢ï¼‰</strong><a class="headerlink" href="#id13" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>å®šä¹‰ä¸€ä¸ªè®°å·ï¼š <span class="math notranslate nohighlight">\(X^{n,m}\)</span> è¡¨ç¤ºç¬¬ <code class="docutils literal notranslate"><span class="pre">n</span></code> ä¸ªç›¸æœºæ‹åˆ°çš„åœºæ™¯ï¼Œé€šè¿‡è½¬æ¢ï¼Œæ˜ å°„åˆ°ç¬¬ <code class="docutils literal notranslate"><span class="pre">m</span></code> ä¸ªç›¸æœºçš„åæ ‡ç³»ä¸­ã€‚</p>
<p>å…·ä½“å…¬å¼æ˜¯ï¼š</p>
<div class="math notranslate nohighlight">
\[X^{n,m} = P_m * P_nâ»Â¹ * h(X^n)\]</div>
<p>è§£é‡Šå¦‚ä¸‹ï¼š</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(X^n\)</span>ï¼šåœ¨ç›¸æœº <code class="docutils literal notranslate"><span class="pre">n</span></code> çš„åæ ‡ç³»ä¸‹çš„ç‚¹å›¾</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">h(X)</span></code>ï¼šè¡¨ç¤ºå¯¹ <code class="docutils literal notranslate"><span class="pre">X</span></code> ä¸­çš„æ¯ä¸ªç‚¹åšé½æ¬¡å˜æ¢ <code class="docutils literal notranslate"><span class="pre">(x,y,z)</span> <span class="pre">â†’</span> <span class="pre">(x,y,z,1)</span></code>ï¼Œè¿™æ˜¯ä¸ºäº†è§£å†³çŸ©é˜µä¹˜æ³•éœ€è¦é½æ¬¡åæ ‡</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">P_n</span></code> å’Œ <code class="docutils literal notranslate"><span class="pre">P_m</span></code> æ˜¯ä¸¤ä¸ªç›¸æœºçš„ <strong>ä¸–ç•Œåˆ°ç›¸æœºåæ ‡çš„å˜æ¢çŸ©é˜µï¼ˆposeï¼‰</strong>ï¼Œ <span class="math notranslate nohighlight">\(P âˆˆ â„^{(3Ã—4)}\)</span></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">P_nâ»Â¹</span></code>ï¼šæŠŠç›¸æœº <code class="docutils literal notranslate"><span class="pre">n</span></code> åæ ‡ç³»çš„ç‚¹å˜æ¢åˆ°ä¸–ç•Œåæ ‡ç³»</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">P_m</span></code>ï¼šå†ä»ä¸–ç•Œåæ ‡ç³»å˜æ¢åˆ°ç›¸æœº <code class="docutils literal notranslate"><span class="pre">m</span></code> çš„åæ ‡ç³»</p></li>
</ul>
<blockquote>
<div><p>âœ… æ‰€ä»¥è¿™ä¸€å…¬å¼å®Œæˆäº†ä»ç›¸æœº <code class="docutils literal notranslate"><span class="pre">n</span></code> æ‹åˆ°çš„ç‚¹å›¾ï¼Œå˜æ¢åˆ°ç›¸æœº <code class="docutils literal notranslate"><span class="pre">m</span></code> çš„åæ ‡ç³»ä¸‹çš„ç‚¹å›¾ã€‚</p>
</div></blockquote>
</section>
<hr class="docutils" />
<section id="id14">
<h4>âœï¸ æ€»ç»“ï¼š<a class="headerlink" href="#id14" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>é¡¹ç›®</p></th>
<th class="head"><p>å«ä¹‰</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Pointmap (X)</strong></p></td>
<td><p>å›¾åƒä¸­æ¯ä¸ªåƒç´ ç‚¹å¯¹åº”çš„ 3D ç‚¹ï¼Œç»´åº¦ä¸º <code class="docutils literal notranslate"><span class="pre">W</span> <span class="pre">Ã—</span> <span class="pre">H</span> <span class="pre">Ã—</span> <span class="pre">3</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><strong>I[i,j] â†” X[i,j]</strong></p></td>
<td><p>æ¯ä¸ªåƒç´ å’Œå…¶ä¸‰ç»´ç‚¹ä¸€ä¸€å¯¹åº”</p></td>
</tr>
<tr class="row-even"><td><p><strong>X[i,j] ç”Ÿæˆæ–¹å¼</strong></p></td>
<td><p>åˆ©ç”¨æ·±åº¦å›¾å’Œç›¸æœºå†…å‚è¿›è¡ŒåæŠ•å½±</p></td>
</tr>
<tr class="row-odd"><td><p><strong>X^{n,m}</strong></p></td>
<td><p>ç›¸æœº <code class="docutils literal notranslate"><span class="pre">n</span></code> æ‹åˆ°çš„ç‚¹å›¾ï¼Œè½¬æ¢åˆ°ç›¸æœº <code class="docutils literal notranslate"><span class="pre">m</span></code> çš„åæ ‡ç³»ä¸­</p></td>
</tr>
<tr class="row-even"><td><p><strong>å˜æ¢å…¬å¼</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">X^{n,m}</span> <span class="pre">=</span> <span class="pre">P_m</span> <span class="pre">*</span> <span class="pre">P_nâ»Â¹</span> <span class="pre">*</span> <span class="pre">h(X^n)</span></code></p></td>
</tr>
</tbody>
</table>
</section>
</section>
<hr class="docutils" />
<section id="overview">
<h3>3.1 Overview<a class="headerlink" href="#overview" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<section id="id15">
<h4>ğŸ§  <strong>ç›®æ ‡æ¦‚è¿°</strong><a class="headerlink" href="#id15" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>è®­ç»ƒä¸€ä¸ªç½‘ç»œæ¥è§£å†³ã€Œ<strong>å¹¿ä¹‰ç«‹ä½“è§†è§‰ä¸‹çš„3Dé‡å»ºä»»åŠ¡</strong>ã€ï¼Œé‡‡ç”¨çš„æ–¹å¼æ˜¯ <strong>ç›´æ¥å›å½’ï¼ˆregressionï¼‰</strong>ã€‚</p>
<p>è¾“å…¥ï¼š</p>
<ul class="simple">
<li><p>ä¸¤å¼  RGB å›¾åƒ <span class="math notranslate nohighlight">\( I^1, I^2 \in \mathbb{R}^{W \times H \times 3} \)</span></p></li>
</ul>
<p>è¾“å‡ºï¼š</p>
<ul class="simple">
<li><p>ä¸¤ä¸ªä¸å›¾åƒå¯¹åº”çš„ <strong>ç‚¹å›¾ï¼ˆpointmapsï¼‰</strong>ï¼Œåˆ†åˆ«æ˜¯ <span class="math notranslate nohighlight">\( X^{1,1}, X^{2,1} \in \mathbb{R}^{W \times H \times 3} \)</span>ï¼ˆæ¯ä¸ªåƒç´ éƒ½æœ‰ä¸€ä¸ªä¸‰ç»´åæ ‡ï¼‰</p></li>
<li><p>ä»¥åŠå„è‡ªçš„ <strong>ç½®ä¿¡å›¾ï¼ˆconfidence mapsï¼‰</strong> <span class="math notranslate nohighlight">\( C^{1,1}, C^{2,1} \in \mathbb{R}^{W \times H} \)</span></p></li>
</ul>
<p><strong>ç‰¹åˆ«ä¹‹å¤„ï¼š</strong> è¿™ä¸¤ä¸ªç‚¹å›¾éƒ½ç”¨ç¬¬ä¸€ä¸ªå›¾åƒ <span class="math notranslate nohighlight">\( I^1 \)</span> çš„åæ ‡ç³»æ¥è¡¨è¾¾ï¼Œè¿™æ˜¯ä¸€ä¸ªéå¸¸è§„ä½†å¾ˆæœ‰ä¼˜åŠ¿çš„è®¾è®¡ã€‚</p>
</section>
<section id="inspired-by-croco">
<h4>ğŸ—ï¸ <strong>ç½‘ç»œæ¶æ„ï¼ˆInspired by CroCoï¼‰</strong><a class="headerlink" href="#inspired-by-croco" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/04/OXutWV.png" /></p>
<p>Figure 2: Architecture of the network <span class="math notranslate nohighlight">\(\mathcal{F}\)</span> . Two views of a scene <span class="math notranslate nohighlight">\((I^{1},I^{2})\)</span> are first encoded in a Siamese manner with a shared ViT encoder. The resulting token representations <span class="math notranslate nohighlight">\(F^{1}\)</span> and <span class="math notranslate nohighlight">\(F^{2}\)</span> are then passed to two transformer decoders that constantly exchange information via cross-attention. Finally, two regression heads output the two corresponding pointmaps and associated confidence maps. Importantly, the two pointmaps are expressed in the same coordinate frame of the first image <span class="math notranslate nohighlight">\(I^{1}\)</span>. The network <span class="math notranslate nohighlight">\(\mathcal{F}\)</span> is trained using a simple regression loss</p>
<hr class="docutils" />
<p>æ•´ä½“ç»“æ„æ˜¯ä¸€ä¸ª <strong>Siamese åŒæ”¯è·¯ç½‘ç»œ</strong>ï¼Œå³ï¼š</p>
<ol class="arabic simple">
<li><p>ç¼–ç é˜¶æ®µï¼ˆEncoderï¼‰ï¼š
ä¸¤ä¸ªå›¾åƒ <span class="math notranslate nohighlight">\( I^1, I^2 \)</span> ä¼šè¢«ä¸€ä¸ªå…±äº«æƒé‡çš„ ViTï¼ˆVision Transformerï¼‰ç¼–ç å™¨ç¼–ç ä¸ºï¼š</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( F^1 = \text{Encoder}(I^1) \)</span></p></li>
<li><p><span class="math notranslate nohighlight">\( F^2 = \text{Encoder}(I^2) \)</span></p></li>
</ul>
</li>
</ol>
<hr class="docutils" />
<ol class="arabic" start="2">
<li><p>è§£ç é˜¶æ®µï¼ˆDecoderï¼‰ï¼š
é‡‡ç”¨ç±»ä¼¼ CroCo çš„ decoderï¼Œç”±å¤šä¸ª transformer block ç»„æˆï¼Œæ¯ä¸ª block æœ‰ï¼š</p>
<ul class="simple">
<li><p><strong>Self-Attentionï¼ˆè‡ªæ³¨æ„ï¼‰</strong>ï¼šåœ¨æ¯ä¸ªè§†è§’å†…è¿›è¡Œ</p></li>
<li><p><strong>Cross-Attentionï¼ˆäº¤å‰æ³¨æ„ï¼‰</strong>ï¼šè·¨ä¸¤ä¸ªå›¾åƒä¹‹é—´çš„ä¿¡æ¯äº¤äº’ï¼ˆæ¯”å¦‚ <span class="math notranslate nohighlight">\( G^1_i \)</span> éœ€è¦çœ‹ <span class="math notranslate nohighlight">\( G^2_{i-1} \)</span> çš„ tokenï¼‰</p></li>
</ul>
<p>è¿™ä¸ªè®¾è®¡çš„å…³é”®ç‚¹åœ¨äº <strong>æ¯ä¸€å±‚éƒ½åœ¨ä¸¤ä¸ªè§†è§’ä¹‹é—´ä¼ é€’ä¿¡æ¯</strong>ï¼Œç¡®ä¿ç”Ÿæˆçš„ç‚¹å›¾å½¼æ­¤å¯¹é½ï¼ˆalignedï¼‰ã€‚</p>
<p>åˆå§‹åŒ–ï¼š</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( G_0^1 := F^1 \)</span></p></li>
<li><p><span class="math notranslate nohighlight">\( G_0^2 := F^2 \)</span></p></li>
</ul>
<p>æ¯ä¸€å±‚çš„è®¡ç®—å½¢å¦‚ï¼š</p>
<div class="math notranslate nohighlight">
\[\begin{split}
G_i^1 = \text{DecoderBlock}_i^1(G_{i-1}^1, G_{i-1}^2) \\
    G_i^2 = \text{DecoderBlock}_i^2(G_{i-1}^2, G_{i-1}^1)
\end{split}\]</div>
</li>
</ol>
<hr class="docutils" />
<ol class="arabic" start="3">
<li><p>å›å½’å¤´ï¼ˆRegression Headsï¼‰ï¼š
å°†æ¯ä¸ªåˆ†æ”¯çš„ decoder token é€å…¥å„è‡ªçš„å›å½’å¤´ï¼Œè¾“å‡ºæœ€ç»ˆçš„ï¼š</p>
<ul class="simple">
<li><p>ç‚¹å›¾ï¼ˆpointmapï¼‰</p></li>
<li><p>ç½®ä¿¡å›¾ï¼ˆconfidence mapï¼‰</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
X^{1,1}, C^{1,1} = \text{Head}^1(G_0^1, ..., G_B^1) \\
    X^{2,1}, C^{2,1} = \text{Head}^2(G_0^2, ..., G_B^2)
\end{split}\]</div>
</li>
</ol>
</section>
<hr class="docutils" />
<section id="discussion">
<h4>ğŸ’¡ <strong>è®¾è®¡è®¨è®ºï¼ˆDiscussionï¼‰</strong><a class="headerlink" href="#discussion" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p>è¾“å‡ºçš„ç‚¹å›¾åªæ˜¯ã€Œç›¸å¯¹ç‚¹äº‘ã€ï¼Œå°ºåº¦æ˜¯æœªçŸ¥çš„ï¼ˆå³ scale-ambiguousï¼‰ã€‚</p></li>
<li><p>ç½‘ç»œæœ¬èº«<strong>ä¸å¼ºåˆ¶éµå®ˆå‡ ä½•çº¦æŸ</strong>ï¼Œè€Œæ˜¯å®Œå…¨ä¾èµ–æ•°æ®ä¸­çš„å‡ ä½•ä¸€è‡´æ€§æ¥ã€Œå­¦å‡ºå‡ ä½•ã€ã€‚</p></li>
<li><p>è™½ç„¶ä¸æ˜¯åŸºäºä¼ ç»Ÿç›¸æœºæ¨¡å‹ï¼ˆå¦‚æŠ•å½±å‡ ä½•ï¼‰ï¼Œä½†å¯ä»¥<strong>åˆ©ç”¨å¼ºå¤§çš„é¢„è®­ç»ƒæ¨¡å‹</strong>æ¥è·å¾—æ›´å¼ºæ³›åŒ–ã€‚</p></li>
<li><p>è¿™è®©å®ƒç›¸æ¯”äºä»»åŠ¡ç‰¹å®šè®¾è®¡çš„ç½‘ç»œï¼Œ<strong>æ›´é€šç”¨ã€æ‰©å±•æ€§æ›´å¼º</strong>ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="id16">
<h4>âœ… æ€»ç»“<a class="headerlink" href="#id16" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<blockquote>
<div><p>DUSt3R ç”¨ä¸€ä¸ª ViT ç¼–ç å™¨ + è·¨è§†è§’ transformer è§£ç å™¨ + å›å½’å¤´ï¼Œç›´æ¥ä»ä¸¤å¼  RGB å›¾ä¸­è¾“å‡ºä¸¤ä¸ªå¯¹é½çš„ 3D ç‚¹å›¾ï¼ˆä¸ä¾èµ–å‡ ä½•å»ºæ¨¡ï¼‰ï¼Œé€šè¿‡è®­ç»ƒæ•°æ®è‡ªåŠ¨å­¦ä¹ å‡ ä½•ã€‚</p>
</div></blockquote>
</section>
</section>
<hr class="docutils" />
<section id="training-objective">
<h3>3.2 Training Objective<a class="headerlink" href="#training-objective" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/04/7KBo1p.png" /></p>
<p>Figure 3: shows the outcome of global alignment</p>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/04/3ROUVD.png" /></p>
<p>Figure 3: Reconstruction examples on two scenes never seen during training. From left to right: RGB, depth map, confidence map, reconstruction. The left scene shows the raw result output from <span class="math notranslate nohighlight">\(\mathcal{F}(I^{1},I^{2})\)</span> .</p>
<section id="d-3d-regression-loss">
<h4>ä¸€ã€3Då›å½’æŸå¤±ï¼ˆ3D Regression Lossï¼‰<a class="headerlink" href="#d-3d-regression-loss" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>è¿™æ˜¯ç½‘ç»œçš„<strong>ä¸»è¦è®­ç»ƒç›®æ ‡</strong>ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯ï¼š</p>
<blockquote>
<div><p><strong>ç›´æ¥åœ¨ä¸‰ç»´ç©ºé—´ä¸Šè¿›è¡Œç‚¹çš„å›å½’æŸå¤±è®¡ç®—</strong>ï¼Œå³ï¼šé¢„æµ‹çš„3Dç‚¹å›¾ï¼ˆpointmapï¼‰ä¸çœŸå®çš„3Dç‚¹å›¾ä¹‹é—´çš„è¯¯å·®ï¼ˆæ¬§å‡ é‡Œå¾—è·ç¦»ï¼‰ã€‚</p>
</div></blockquote>
<ul>
<li><p>1.å˜é‡å®šä¹‰</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\bar{X}^{1,1}, \bar{X}^{2,1}\)</span>ï¼šæ¥è‡ª ground-truthï¼ˆçœŸå®ç‚¹å›¾ï¼‰çš„ä¸¤å¹…å›¾åƒå¯¹åº”çš„ 3D ç‚¹å›¾ã€‚</p></li>
<li><p><span class="math notranslate nohighlight">\(X^{1,1}, X^{2,1}\)</span>ï¼šå¯¹åº”é¢„æµ‹çš„ 3D ç‚¹å›¾ã€‚</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal{D}^{1}, \mathcal{D}^{2}\)</span>ï¼šåˆ†åˆ«æ˜¯æœ‰æ•ˆåƒç´ ï¼ˆå³æœ‰ ground-truth çš„åƒç´ ï¼‰çš„ä½ç½®é›†åˆã€‚</p></li>
<li><p><span class="math notranslate nohighlight">\(i \in \mathcal{D}^v\)</span>ï¼šè§†è§’ <span class="math notranslate nohighlight">\(v\)</span> ä¸­çš„ä¸€ä¸ªæœ‰æ•ˆåƒç´ ç‚¹ç´¢å¼•ã€‚</p></li>
<li><p><span class="math notranslate nohighlight">\(X_i^{v,1}\)</span>ï¼šåœ¨è§†è§’ <span class="math notranslate nohighlight">\(v\)</span> ä¸‹ï¼Œåƒç´  <span class="math notranslate nohighlight">\(i\)</span> å¯¹åº”çš„é¢„æµ‹ 3D ç‚¹ã€‚</p></li>
<li><p><span class="math notranslate nohighlight">\(\bar{X}_i^{v,1}\)</span>ï¼šå¯¹åº”çš„ ground-truth 3D ç‚¹ã€‚</p></li>
</ul>
</li>
<li><p>2.æŸå¤±å‡½æ•°å®šä¹‰
å•ä¸ªåƒç´  <span class="math notranslate nohighlight">\(i\)</span> çš„å›å½’æŸå¤±æ˜¯é¢„æµ‹ç‚¹ä¸çœŸå®ç‚¹ä¹‹é—´çš„ <strong>å½’ä¸€åŒ–æ¬§å‡ é‡Œå¾—è·ç¦»</strong>ï¼š</p>
<div class="math notranslate nohighlight">
\[
\ell_{\text{regr}}(v,i) = \left\|\frac{1}{z}X^{v,1}_{i}-\frac{1}{\bar{z}}\bar{X}^{v,1}_{i}\right\|
\]</div>
<ul class="simple">
<li><p>å½’ä¸€åŒ–çš„åŸå› ï¼š
ç”±äºè¾“å…¥å›¾åƒå¯¹çš„å°ºåº¦/æ·±åº¦èŒƒå›´ä¸ç¡®å®šï¼Œé¢„æµ‹ç»“æœå’Œ ground-truth å¯èƒ½å­˜åœ¨å°ºåº¦å·®å¼‚ã€‚æ‰€ä»¥ï¼š</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(z\)</span> æ˜¯å¯¹é¢„æµ‹ç‚¹å›¾çš„æ•´ä½“å°ºåº¦å½’ä¸€åŒ–å› å­</p></li>
<li><p><span class="math notranslate nohighlight">\(\bar{z}\)</span> æ˜¯å¯¹çœŸå®ç‚¹å›¾çš„æ•´ä½“å½’ä¸€åŒ–å› å­</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>å½’ä¸€åŒ–æ–¹å¼ä¸ºï¼š</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\text{norm}(X^1, X^2) = \frac{1}{|\mathcal{D}^1| + |\mathcal{D}^2|} \sum_{v \in \{1, 2\}} \sum_{i \in \mathcal{D}^v} \|X^v_i\|
\]</div>
<ul class="simple">
<li><p>æ„æ€æ˜¯ï¼š<strong>æ‰€æœ‰æœ‰æ•ˆåƒç´ çš„å¹³å‡æ¬§å‡ é‡Œå¾—è·ç¦»ï¼ˆä»åŸç‚¹å‡ºå‘ï¼‰</strong>ã€‚</p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="confidence-aware-loss">
<h4>äºŒã€ç½®ä¿¡åº¦æ„ŸçŸ¥æŸå¤±ï¼ˆConfidence-aware Lossï¼‰<a class="headerlink" href="#confidence-aware-loss" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p>ç°å®ä¸­å›¾åƒå­˜åœ¨å¾ˆå¤šâ€œä¸ç¡®å®šåŒºåŸŸâ€ï¼š</p>
<ul>
<li><p>æ¯”å¦‚å¤©ç©ºã€é€æ˜ç‰©ä½“ã€åå°„è¡¨é¢ç­‰ï¼Œè¿™äº›åœ°æ–¹çš„ 3D é‡å»ºä¸é è°±ï¼›</p></li>
<li><p>ç½‘ç»œé¢„æµ‹è¿™äº›åœ°æ–¹æ—¶ä¿¡å¿ƒä¹Ÿä½ã€‚</p></li>
</ul>
</li>
<li><p>å¼•å…¥ç½®ä¿¡åº¦çš„åŸå› ï¼š
è®©ç½‘ç»œä¸ä»…é¢„æµ‹ 3D ç‚¹ï¼Œè¿˜é¢„æµ‹å¯¹æ¯ä¸ªåƒç´ çš„ <strong>ç½®ä¿¡åº¦åˆ†æ•° <span class="math notranslate nohighlight">\(C_i^{v,1}\)</span></strong>ï¼Œç”¨æ¥è°ƒèŠ‚è¯¥åƒç´ å¯¹æŸå¤±å‡½æ•°çš„å½±å“ã€‚</p></li>
<li><p>ç½®ä¿¡åº¦åŠ æƒåçš„æœ€ç»ˆæŸå¤±å‡½æ•°ï¼š
$<span class="math notranslate nohighlight">\(
\mathcal{L}_{\text{conf}} = \sum_{v \in \{1,2\}} \sum_{i \in \mathcal{D}^v} C_i^{v,1} \cdot \ell_{\text{regr}}(v, i) - \alpha \log C_i^{v,1}
\)</span>$</p></li>
<li><p>å«ä¹‰å¦‚ä¸‹ï¼š</p>
<ul>
<li><p><strong>ç¬¬ä¸€é¡¹</strong>æ˜¯ç½®ä¿¡åº¦åŠ æƒçš„ 3D å›å½’æŸå¤±ï¼›</p></li>
<li><p><strong>ç¬¬äºŒé¡¹</strong>æ˜¯æ­£åˆ™é¡¹ï¼Œé¼“åŠ±ç½®ä¿¡åº¦ä¸è¦æ— é™å¤§ï¼ˆå¦åˆ™æ¨¡å‹å°±å¯ä»¥æ€»æ˜¯ç»™é«˜ç½®ä¿¡åº¦æ¥å‹ä½æŸå¤±ï¼‰ï¼›</p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha\)</span> æ˜¯æƒé‡è¶…å‚æ•°ã€‚</p></li>
</ul>
</li>
<li><p>ä¸ºä¿è¯ <span class="math notranslate nohighlight">\(C_i &gt; 0\)</span>ï¼Œå®šä¹‰æ–¹å¼ä¸ºï¼š
$<span class="math notranslate nohighlight">\(
C_i^{v,1} = 1 + \exp(\widetilde{C}_i^{v,1}) &gt; 1
\)</span>$</p>
<ul>
<li><p>å³ï¼šé¢„æµ‹çš„æ˜¯ <span class="math notranslate nohighlight">\(\widetilde{C}\)</span>ï¼Œç„¶åé€šè¿‡ <code class="docutils literal notranslate"><span class="pre">exp</span></code> å˜æ¢åŠ 1ï¼Œä¿è¯æœ€ç»ˆç½®ä¿¡åº¦å§‹ç»ˆä¸ºæ­£ã€‚</p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="id17">
<h4>æ€»ç»“ç†è§£ï¼š<a class="headerlink" href="#id17" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>DUSt3R ç½‘ç»œè®­ç»ƒç›®æ ‡è®¾è®¡éå¸¸ç®€æ´ç›´è§‚ï¼š</p>
<ul class="simple">
<li><p>æ ¸å¿ƒæ€æƒ³ï¼šç›´æ¥å¯¹<strong>ä¸‰ç»´ç‚¹äº‘è¿›è¡Œå›å½’</strong>ï¼Œè€Œéåƒå¾ˆå¤šæ–¹æ³•é‚£æ ·é¢„æµ‹æ·±åº¦æˆ–è§†å·®å›¾ï¼›</p></li>
<li><p>ä¸ºäº†åº”å¯¹ç°å®å›¾åƒä¸­å­˜åœ¨çš„ä¸ç¡®å®šåŒºåŸŸï¼Œå¼•å…¥<strong>æ¯åƒç´ ç½®ä¿¡åº¦é¢„æµ‹æœºåˆ¶</strong>ï¼Œå¹¶å°†å…¶ç”¨äºåŠ æƒæŸå¤±ï¼›</p></li>
<li><p>æ•´ä½“æŸå¤±å…·æœ‰<strong>å°ºåº¦ä¸å˜æ€§</strong>ï¼ˆé€šè¿‡ç‚¹å›¾å½’ä¸€åŒ–ï¼‰å’Œ<strong>ä¸ç¡®å®šæ€§é²æ£’æ€§</strong>ï¼ˆé€šè¿‡ç½®ä¿¡åº¦æƒé‡è°ƒèŠ‚ï¼‰ã€‚</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="downstream-applications">
<h3>3.3 Downstream Applications<a class="headerlink" href="#downstream-applications" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<section id="point-matching">
<h4>âœ… <strong>Point Matchingï¼ˆç‚¹åŒ¹é…ï¼‰</strong><a class="headerlink" href="#point-matching" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>è¿™éƒ¨åˆ†è®²çš„æ˜¯å¦‚ä½•åœ¨ä¸¤å¼ å›¾ç‰‡ä¹‹é—´å»ºç«‹åƒç´ çº§åˆ«çš„åŒ¹é…å…³ç³»ï¼š</p>
<blockquote>
<div><p>åœ¨ä¸¤å¼ å›¾ç‰‡çš„ pointmapï¼ˆä¾‹å¦‚ <span class="math notranslate nohighlight">\(X^{1,1}\)</span> å’Œ <span class="math notranslate nohighlight">\(X^{1,2}\)</span>ï¼‰ä¸­ï¼Œæ¯ä¸ªåƒç´ å¯¹åº”ä¸€ä¸ªä¸‰ç»´ç‚¹ï¼ˆx, y, zï¼‰ã€‚æ‰€ä»¥å¯ä»¥ç›´æ¥åœ¨ä¸‰ç»´ç©ºé—´ä¸­ä½¿ç”¨æœ€è¿‘é‚»ï¼ˆNearest Neighbor, NNï¼‰æœç´¢æ¥åšç‚¹åŒ¹é…ã€‚</p>
</div></blockquote>
<ul>
<li><p><strong>åŒå‘æœ€è¿‘é‚»åŒ¹é…</strong>ï¼šä¸ºäº†å‡å°‘é”™è¯¯åŒ¹é…ï¼Œä½¿ç”¨çš„æ˜¯ <em>äº’ä¸ºæœ€è¿‘é‚»</em> çš„ç‚¹å¯¹ï¼š</p>
<div class="math notranslate nohighlight">
\[
\mathcal{M}_{1,2} = \{(i, j)\ |\ i = \text{NN}_{1}^{1,2}(j)\ \text{and}\ j = \text{NN}_{1}^{2,1}(i)\}
\]</div>
<ul class="simple">
<li><p>ä¹Ÿå°±æ˜¯è¯´ï¼Œä»å›¾åƒ 1 çš„ç¬¬ <span class="math notranslate nohighlight">\( i \)</span> ä¸ªåƒç´ å‡ºå‘ï¼Œåœ¨å›¾åƒ 2 ä¸­æ‰¾åˆ°æœ€è¿‘çš„ä¸‰ç»´ç‚¹æ˜¯ <span class="math notranslate nohighlight">\( j \)</span>ï¼Œ</p></li>
<li><p>åŒæ—¶ï¼Œä»å›¾åƒ 2 çš„ <span class="math notranslate nohighlight">\( j \)</span> å‡ºå‘ï¼Œæœ€è¿‘çš„ä¸‰ç»´ç‚¹å›åˆ°äº†å›¾åƒ 1 çš„ <span class="math notranslate nohighlight">\( i \)</span>ï¼Œåˆ™è®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªåŒ¹é…å¯¹ã€‚</p></li>
</ul>
</li>
<li><p>æœ€è¿‘é‚»çš„å®šä¹‰ï¼š</p>
<div class="math notranslate nohighlight">
\[
\text{NN}_{k}^{n,m}(i) = \arg\min_{j \in \{0,\ldots,WH\}} \|X^{n,k}_j - X^{m,k}_i\|
\]</div>
<p>è¡¨ç¤ºåœ¨å›¾åƒ <span class="math notranslate nohighlight">\( n \)</span> å’Œ <span class="math notranslate nohighlight">\( m \)</span> çš„ç¬¬ <span class="math notranslate nohighlight">\( k \)</span> å±‚ä¹‹é—´ï¼Œå¯¹ <span class="math notranslate nohighlight">\( i \)</span> ç‚¹å¯»æ‰¾æœ€å°æ¬§æ°è·ç¦»çš„ <span class="math notranslate nohighlight">\( j \)</span> ç‚¹ã€‚</p>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="recovering-intrinsics">
<h4>âœ… <strong>Recovering Intrinsicsï¼ˆæ¢å¤ç›¸æœºå†…å‚ï¼‰</strong><a class="headerlink" href="#recovering-intrinsics" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<blockquote>
<div><p>Pointmap æ˜¯ä»¥å›¾åƒåæ ‡ç³»è¡¨è¾¾çš„ä¸‰ç»´ç‚¹ï¼Œæ‰€ä»¥å¯ä»¥ç”¨è¿™äº›ç‚¹å€’æ¨å‡ºç›¸æœºçš„å†…å‚ï¼Œç‰¹åˆ«æ˜¯ç„¦è· <span class="math notranslate nohighlight">\( f \)</span>ã€‚</p>
</div></blockquote>
<ul>
<li><p>å‡è®¾ä¸»ç‚¹ï¼ˆprincipal pointï¼‰åœ¨å›¾åƒä¸­å¿ƒï¼Œåƒç´ æ˜¯æ­£æ–¹å½¢ï¼Œæ‰€ä»¥åªéœ€ä¼°è®¡ç„¦è· <span class="math notranslate nohighlight">\( f_1^* \)</span>ã€‚</p></li>
<li><p>ä¼˜åŒ–ç›®æ ‡æ˜¯æœ€å°åŒ– 3D ç‚¹æŠ•å½±ä¸å®é™…åƒç´ ä½ç½®ä¹‹é—´çš„å·®å¼‚ï¼š</p>
<div class="math notranslate nohighlight">
\[
f_1^* = \arg\min_{f_1} \sum_{i=0}^{W} \sum_{j=0}^{H} C^{1,1}_{i,j} \left\|(i',j') - f_1 \cdot \frac{(X^{1,1}_{i,j,0}, X^{1,1}_{i,j,1})}{X^{1,1}_{i,j,2}} \right\|
\]</div>
<ul class="simple">
<li><p>å…¶ä¸­ï¼š</p>
<ul>
<li><p><span class="math notranslate nohighlight">\( (i', j') = (i - W/2, j - H/2) \)</span>ï¼Œå°†åƒç´ ä¸­å¿ƒåŒ–ï¼›</p></li>
<li><p><span class="math notranslate nohighlight">\( X^{1,1}_{i,j,*} \)</span> æ˜¯ä¸‰ç»´ç‚¹åæ ‡ï¼›</p></li>
<li><p><span class="math notranslate nohighlight">\( C^{1,1}_{i,j} \)</span> æ˜¯æƒé‡ï¼ˆä¾‹å¦‚å¯è§æ€§ã€ç½®ä¿¡åº¦ï¼‰ã€‚</p></li>
</ul>
</li>
</ul>
</li>
<li><p>å¯ç”¨ Weiszfeld ç®—æ³•ç­‰å¿«é€Ÿè¿­ä»£æ–¹æ³•æ±‚è§£ã€‚</p></li>
<li><p>ç¬¬äºŒå¼ å›¾åƒçš„ç„¦è· <span class="math notranslate nohighlight">\( f_2^* \)</span> åŒç†ï¼Œåªéœ€æ¢ç”¨ <span class="math notranslate nohighlight">\( X^{2,2} \)</span>ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="relative-pose-estimation">
<h4>âœ… <strong>Relative Pose Estimationï¼ˆç›¸å¯¹å§¿æ€ä¼°è®¡ï¼‰</strong><a class="headerlink" href="#relative-pose-estimation" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>ç›¸æœºä¹‹é—´çš„ç›¸å¯¹ä½ç½®å’Œæ–¹å‘å¯ä»¥é€šè¿‡ä¸¤ç§æ–¹å¼ä¼°è®¡ï¼š</p>
<ul>
<li><p>æ–¹æ³•ä¸€ï¼šä¼ ç»Ÿæ–¹å¼</p>
<ol class="arabic simple">
<li><p>ç”¨ pointmap åšç‚¹åŒ¹é…ï¼›</p></li>
<li><p>æ¢å¤å†…å‚ï¼›</p></li>
<li><p>ç”¨åŒ¹é…ç‚¹å¯¹è®¡ç®— <em>åŸºç¡€çŸ©é˜µæˆ–æœ¬è´¨çŸ©é˜µï¼ˆEpipolar Matrixï¼‰</em>ï¼›</p></li>
<li><p>ä»ä¸­æ¢å¤æ—‹è½¬ <span class="math notranslate nohighlight">\( R \)</span> å’Œä½ç§» <span class="math notranslate nohighlight">\( t \)</span>ã€‚</p></li>
</ol>
</li>
<li><p>æ–¹æ³•äºŒï¼šProcrustes å¯¹é½ï¼ˆæ¨èï¼‰</p>
<ul class="simple">
<li><p>æ›´ç›´æ¥çš„æ–¹æ³•æ˜¯å¯¹ä¸¤ä¸ª pointmap ç›´æ¥å¯¹é½ï¼š</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
R^*, t^* = \arg\min_{\sigma, R, t} \sum_i C^{1,1}_i C^{1,2}_i \left\| \sigma(R X^{1,1}_i + t) - X^{1,2}_i \right\|^2
\]</div>
<ul class="simple">
<li><p>è¿™æ˜¯ç»å…¸çš„ <em>å¸¦ç¼©æ”¾çš„ Procrustes å¯¹é½</em> é—®é¢˜ï¼›</p></li>
<li><p>ç›®æ ‡æ˜¯å¯»æ‰¾æœ€ä¼˜çš„æ—‹è½¬ <span class="math notranslate nohighlight">\( R \)</span>ã€å¹³ç§» <span class="math notranslate nohighlight">\( t \)</span> å’Œå°ºåº¦å› å­ <span class="math notranslate nohighlight">\( \sigma \)</span>ï¼Œä½¿ä¸¤ä¸ªç‚¹äº‘å¯¹é½ï¼›</p></li>
<li><p><span class="math notranslate nohighlight">\( C^{1,1}_i \)</span> å’Œ <span class="math notranslate nohighlight">\( C^{1,2}_i \)</span> æ˜¯æ¯ä¸ªç‚¹çš„æƒé‡æˆ–ç½®ä¿¡åº¦ã€‚</p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="id18">
<h4>æ€»ç»“<a class="headerlink" href="#id18" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>ä»»åŠ¡</p></th>
<th class="head"><p>åšæ³•</p></th>
<th class="head"><p>ç‰¹ç‚¹</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ç‚¹åŒ¹é…</p></td>
<td><p>æœ€è¿‘é‚»æœç´¢ pointmapï¼ŒåŒå‘è¿‡æ»¤</p></td>
<td><p>å¿«é€Ÿã€é²æ£’</p></td>
</tr>
<tr class="row-odd"><td><p>ç›¸æœºå†…å‚æ¢å¤</p></td>
<td><p>ä¼˜åŒ–åƒç´ ä¸ 3D æŠ•å½±çš„å·®å¼‚ï¼Œæ±‚ç„¦è·</p></td>
<td><p>å¯ç›´æ¥ä» pointmap å¾—åˆ°</p></td>
</tr>
<tr class="row-even"><td><p>ç›¸å¯¹å§¿æ€ä¼°è®¡</p></td>
<td><p>å¯é€‰ï¼šä¼ ç»ŸåŸºç¡€çŸ©é˜µ or Procrustes ç‚¹äº‘å¯¹é½</p></td>
<td><p>åè€…æ›´ç›´æ¥ã€é«˜æ•ˆ</p></td>
</tr>
</tbody>
</table>
<p>è¿™ä¸ªæ–¹æ³•çš„å…³é”®ä¼˜åŠ¿æ˜¯ï¼š<strong>å®ƒå°†åƒç´ æ˜ å°„åˆ°ä¸‰ç»´ç‚¹ï¼ˆpointmapï¼‰åï¼Œå¯ä»¥è·³è¿‡ä¸­é—´å¾ˆå¤šä¼ ç»Ÿæ­¥éª¤ï¼Œç›´æ¥ç”¨ 3D å‡ ä½•åšè§†è§‰ä»»åŠ¡ã€‚</strong></p>
</section>
</section>
<hr class="docutils" />
<section id="global-alignment">
<h3>3.4 Global Alignment<a class="headerlink" href="#global-alignment" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p>æ ¸å¿ƒæ€æƒ³æ˜¯ï¼šé€šè¿‡æ„å»ºä¸€ä¸ªå›¾ç»“æ„ï¼Œå°†å¤šä¸ªå›¾åƒå¯¹ä¸­é¢„æµ‹çš„ç‚¹äº‘è¿›è¡Œ<strong>å…¨å±€å¯¹é½</strong>ï¼Œä»è€Œå°†å¤šä¸ªè§†è§’ä¸‹çš„ç‚¹å›¾ï¼ˆpointmapï¼‰è”åˆä¼˜åŒ–ï¼Œç»Ÿä¸€åˆ°ä¸€ä¸ªä¸‰ç»´åæ ‡ç³»ä¸­ã€‚è¿™ç§ä¼˜åŒ–æ˜¯ <strong>DUSt3R</strong> è¿™ä¸€ç±»æ–¹æ³•å®ç°è·¨å›¾åƒä¸€è‡´æ€§çš„å…³é”®ã€‚æˆ‘ä»¬å¯ä»¥ä»ä¸‰ä¸ªå±‚é¢æ¥ç†è§£å®ƒï¼š</p></li>
</ul>
<hr class="docutils" />
<section id="pairwise-graph">
<h4>âœ¦ ä¸€ã€æ„å»ºå›¾ç»“æ„: Pairwise Graph<a class="headerlink" href="#pairwise-graph" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>ç»™å®šä¸€ç»„å›¾åƒ <span class="math notranslate nohighlight">\(\{I^1, I^2, \ldots, I^N\}\)</span>ï¼Œæˆ‘ä»¬æ„é€ ä¸€ä¸ªè¿æ¥å›¾ <span class="math notranslate nohighlight">\(\mathcal{G}(\mathcal{V}, \mathcal{E})\)</span>ï¼š</p>
<ul class="simple">
<li><p><strong>èŠ‚ç‚¹ <span class="math notranslate nohighlight">\(\mathcal{V}\)</span>ï¼š</strong> æ¯ä¸ªå›¾åƒä¸ºä¸€ä¸ªèŠ‚ç‚¹ã€‚</p></li>
<li><p><strong>è¾¹ <span class="math notranslate nohighlight">\(\mathcal{E}\)</span>ï¼š</strong> å›¾åƒå¯¹ä¹‹é—´å­˜åœ¨è§†è§‰é‡å ï¼ˆé€šè¿‡å›¾åƒæ£€ç´¢æˆ–ç½‘ç»œ <span class="math notranslate nohighlight">\(\mathcal{F}\)</span> æ¨ç†å¾—åˆ°ç½®ä¿¡åº¦é«˜çš„å›¾åƒå¯¹ï¼‰æ‰å»ºç«‹è¾¹ã€‚</p></li>
</ul>
<p>è¿™æ ·ä¸€æ¥ï¼Œæˆ‘ä»¬å°±å¾—åˆ°äº†å›¾åƒä¹‹é—´â€œå¯ä»¥ç›¸äº’é…å‡†â€çš„å…³ç³»å›¾ã€‚</p>
</section>
<hr class="docutils" />
<section id="global-optimization">
<h4>âœ¦ äºŒã€å…¨å±€ä¼˜åŒ–: Global optimization<a class="headerlink" href="#global-optimization" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>ç›®æ ‡æ˜¯å¯¹æ¯ä¸ªå›¾åƒ <span class="math notranslate nohighlight">\(n\)</span>ï¼Œä¼°è®¡å…¶åœ¨ä¸–ç•Œåæ ‡ç³»ä¸‹çš„ç‚¹å›¾ <span class="math notranslate nohighlight">\(\chi^n \in \mathbb{R}^{W \times H \times 3}\)</span>ï¼Œå³å°†æ¯å¹…å›¾åƒçš„æ·±åº¦æ˜ å°„ç»“æœå…¨å±€å¯¹é½ã€‚</p>
<p>æ­¥éª¤å¦‚ä¸‹ï¼š</p>
<ol class="arabic">
<li><p><strong>é¢„æµ‹æ¯å¯¹å›¾åƒçš„ç‚¹å›¾å’Œç½®ä¿¡åº¦ï¼š</strong></p>
<p>å¯¹æ¯æ¡è¾¹ <span class="math notranslate nohighlight">\(e = (n, m)\)</span>ï¼Œé€šè¿‡ç½‘ç»œ <span class="math notranslate nohighlight">\(\mathcal{F}\)</span> é¢„æµ‹å‡ºï¼š</p>
<ul class="simple">
<li><p>å›¾åƒ <span class="math notranslate nohighlight">\(n\)</span> å’Œ <span class="math notranslate nohighlight">\(m\)</span> çš„ç‚¹å›¾ <span class="math notranslate nohighlight">\(X^{n,n}, X^{m,n}\)</span>ï¼ˆç»Ÿä¸€åœ¨å›¾åƒ <span class="math notranslate nohighlight">\(n\)</span> çš„åæ ‡ç³»ä¸­ï¼‰</p></li>
<li><p>å¯¹åº”çš„ç½®ä¿¡åº¦å›¾ <span class="math notranslate nohighlight">\(C^{n,n}, C^{m,n}\)</span></p></li>
</ul>
<p>ä¸ºç»Ÿä¸€è®°å·ï¼Œå®šä¹‰ï¼š
$<span class="math notranslate nohighlight">\(
X^{n,e} := X^{n,n},\quad X^{m,e} := X^{m,n}
\)</span>$</p>
</li>
<li><p><strong>å¼•å…¥åˆšæ€§å˜æ¢(rigid transformation)å’Œå°ºåº¦ï¼š</strong></p>
<p>æ¯æ¡å›¾åƒå¯¹ <span class="math notranslate nohighlight">\(e\)</span> å…³è”ä¸€ä¸ªåˆšæ€§å˜æ¢çŸ©é˜µ <span class="math notranslate nohighlight">\(P_e \in \mathbb{R}^{3 \times 4}\)</span>ï¼ˆåŒ…å«æ—‹è½¬å’Œå¹³ç§»ï¼‰å’Œå°ºåº¦ <span class="math notranslate nohighlight">\(\sigma_e &gt; 0\)</span></p>
</li>
<li><p><strong>æ„å»ºä¼˜åŒ–ç›®æ ‡ï¼š</strong></p>
<p>æœ€ç»ˆä¼˜åŒ–ç›®æ ‡æ˜¯æœ€å°åŒ–æ¯ä¸ªç‚¹å›¾ <span class="math notranslate nohighlight">\(\chi^n\)</span> ä¸å…¶é¢„æµ‹çš„å˜æ¢ç‚¹å›¾ <span class="math notranslate nohighlight">\(\sigma_e P_e X^{n,e}\)</span> ä¹‹é—´çš„åŠ æƒ L2 è·ç¦»ï¼Œæƒé‡æ¥è‡ªç½®ä¿¡åº¦å›¾ï¼š</p>
<div class="math notranslate nohighlight">
\[
   \chi^* = \arg\min_{\chi, P, \sigma} \sum_{e \in \mathcal{E}} \sum_{v \in \{n, m\}} \sum_{i=1}^{HW} C^{v,e}_i \left\| \chi^v_i - \sigma_e P_e X^{v,e}_i \right\|
   \]</div>
<p>ç›´è§‚ç†è§£å°±æ˜¯ï¼šè®©æ¯å¼ å›¾åƒçš„é¢„æµ‹ç‚¹å›¾ï¼Œåœ¨åˆšæ€§å˜æ¢ä¸å°ºåº¦ä¸‹ï¼Œå°½å¯èƒ½æ¥è¿‘å®ƒåœ¨ä¸–ç•Œåæ ‡ä¸­çš„ä¼°è®¡å€¼ã€‚</p>
</li>
<li><p><strong>é˜²æ­¢é€€åŒ–ï¼ˆå…¨é›¶å°ºåº¦ï¼‰ï¼š</strong></p>
<p>ä¸ºé˜²æ­¢ <span class="math notranslate nohighlight">\(\sigma_e = 0\)</span> å¯¼è‡´çš„é€€åŒ–ï¼Œå¢åŠ çº¦æŸï¼š
$<span class="math notranslate nohighlight">\(
\prod_e \sigma_e = 1
\)</span>$</p>
</li>
</ol>
</section>
<hr class="docutils" />
<section id="camera-parameter-recovery">
<h4>âœ¦ ä¸‰ã€ç›¸æœºå‚æ•°æ¢å¤ï¼šCamera Parameter Recovery<a class="headerlink" href="#camera-parameter-recovery" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>å‰é¢æˆ‘ä»¬æ˜¯ç›´æ¥ä¼˜åŒ–æ¯ä¸ªå›¾åƒçš„ç‚¹å›¾ <span class="math notranslate nohighlight">\(\chi^n\)</span>ï¼Œä½†å®é™…ä¸Šä¹Ÿå¯ä»¥ä»æ·±åº¦å›¾ <span class="math notranslate nohighlight">\(D^n\)</span> åæ¨ <span class="math notranslate nohighlight">\(\chi^n\)</span>ï¼š</p>
<ul class="simple">
<li><p>ä½¿ç”¨æ ‡å‡†é’ˆå­”ç›¸æœºæ¨¡å‹ï¼ˆEq. 1ï¼‰ï¼š
$<span class="math notranslate nohighlight">\(
\chi^n_{i,j} := P_n^{-1} \cdot h \left( K_n^{-1} \cdot 
\begin{bmatrix}
i D^n_{i,j} \\
j D^n_{i,j} \\
D^n_{i,j}
\end{bmatrix} \right)
\)</span>$</p></li>
<li><p>è¿™æ ·å¯ä»¥é€šè¿‡ <span class="math notranslate nohighlight">\(\chi^n\)</span> åæ¨å‡ºæ¯ä¸ªç›¸æœºçš„ä½å§¿ <span class="math notranslate nohighlight">\(P_n\)</span> å’Œå†…å‚ <span class="math notranslate nohighlight">\(K_n\)</span>ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="id19">
<h4>âœ… æ€»ç»“é‡ç‚¹<a class="headerlink" href="#id19" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>æ¨¡å—</p></th>
<th class="head"><p>ä½œç”¨</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(\mathcal{F}\)</span> ç½‘ç»œ</p></td>
<td><p>å¯¹å›¾åƒå¯¹è¿›è¡Œç‚¹å›¾é¢„æµ‹</p></td>
</tr>
<tr class="row-odd"><td><p>å›¾ç»“æ„ <span class="math notranslate nohighlight">\(\mathcal{G}\)</span></p></td>
<td><p>æŒ‡ç¤ºå“ªäº›å›¾åƒéœ€è¦å¯¹é½</p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(P_e, \sigma_e\)</span></p></td>
<td><p>å¯¹æ¯å¯¹å›¾åƒçš„åˆšä½“å˜æ¢ä¸å°ºåº¦è¿›è¡Œå»ºæ¨¡</p></td>
</tr>
<tr class="row-odd"><td><p>ä¼˜åŒ–ç›®æ ‡</p></td>
<td><p>ä¿è¯æ‰€æœ‰ç‚¹å›¾åœ¨ç»Ÿä¸€ä¸–ç•Œåæ ‡ç³»ä¸­å¯¹é½ï¼Œä¿æŒä¸€è‡´æ€§</p></td>
</tr>
<tr class="row-even"><td><p>ç›¸æœºå‚æ•°æ¢å¤</p></td>
<td><p>åˆ©ç”¨ä¼˜åŒ–åçš„ç‚¹å›¾åæ¨æ¯ä¸ªå›¾åƒçš„ä½å§¿ä¸å†…å‚</p></td>
</tr>
</tbody>
</table>
</section>
</section>
</section>
<hr class="docutils" />
<section id="experiments-with-dust3r">
<h2>4. Experiments with DUSt3R<a class="headerlink" href="#experiments-with-dust3r" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<section id="id20">
<h3>å‰è¨€<a class="headerlink" href="#id20" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<section id="training-data">
<h4>ğŸ§  <strong>1. è®­ç»ƒæ•°æ®ï¼ˆTraining dataï¼‰</strong><a class="headerlink" href="#training-data" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>ä»–ä»¬ç”¨äº† <strong>8ä¸ªæ•°æ®é›†</strong> æ¥è®­ç»ƒæ¨¡å‹ï¼Œæ¶µç›–å„ç§åœºæ™¯ï¼š</p>
<ul class="simple">
<li><p><strong>å®¤å†…/å®¤å¤–</strong>ï¼ˆä¾‹å¦‚ ScanNet++ æ˜¯å®¤å†…ï¼ŒWaymo æ˜¯æˆ·å¤–ï¼‰</p></li>
<li><p><strong>çœŸå®/åˆæˆ</strong>ï¼ˆä¾‹å¦‚ Blended MVS æ˜¯åˆæˆæ•°æ®ï¼‰</p></li>
<li><p><strong>é¢å‘ç‰©ä½“/é¢å‘åœºæ™¯</strong>ï¼ˆä¾‹å¦‚ CO3D æ˜¯ç‰©ä½“ä¸­å¿ƒçš„ï¼‰</p></li>
</ul>
<p>æœ‰äº›æ•°æ®é›†æ²¡æœ‰è‡ªå¸¦å›¾åƒå¯¹ï¼ˆimage pairsï¼‰ï¼Œé‡‡ç”¨äº†ä¸€ç§æ–¹æ³•ï¼ˆå‚è€ƒæ–‡çŒ®[149]ï¼‰æ¥è‡ªåŠ¨æ„å»ºå›¾åƒå¯¹ï¼š</p>
<blockquote>
<div><p>ä½¿ç”¨ç°æˆçš„å›¾åƒæ£€ç´¢ + ç‰¹å¾åŒ¹é…æ–¹æ³•ï¼Œç­›é€‰å’ŒéªŒè¯å›¾åƒå¯¹ã€‚</p>
</div></blockquote>
<p>æœ€ç»ˆä¸€å…±æ”¶é›†äº† <strong>850 ä¸‡å¯¹å›¾åƒï¼ˆ8.5M pairsï¼‰</strong> ä½œä¸ºè®­ç»ƒæ•°æ®ã€‚</p>
</section>
<hr class="docutils" />
<section id="training-details">
<h4>ğŸ—ï¸ <strong>2. è®­ç»ƒç»†èŠ‚ï¼ˆTraining detailsï¼‰</strong><a class="headerlink" href="#training-details" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p><strong>æ•°æ®å¹³è¡¡</strong>ï¼šæ¯è½®è®­ç»ƒä¸­ï¼Œä¼šå‡åŒ€é‡‡æ ·æ¯ä¸ªæ•°æ®é›†ä¸­çš„å›¾åƒå¯¹ï¼Œé˜²æ­¢æŸäº›æ•°æ®é›†å æ¯”è¿‡å¤§ã€‚</p></li>
<li><p><strong>å›¾åƒåˆ†è¾¨ç‡ç­–ç•¥</strong>ï¼š</p>
<ul>
<li><p>åˆæœŸè®­ç»ƒç”¨è¾ƒå°å°ºå¯¸ <code class="docutils literal notranslate"><span class="pre">224Ã—224</span></code></p></li>
<li><p>åæœŸå†ç”¨æ›´é«˜çš„ <code class="docutils literal notranslate"><span class="pre">512px</span></code> æœ€å¤§è¾¹å°ºå¯¸å›¾åƒè®­ç»ƒï¼ˆæé«˜æ€§èƒ½ä½†æˆæœ¬æ›´é«˜ï¼‰</p></li>
</ul>
</li>
<li><p><strong>å›¾åƒå½¢çŠ¶å¤„ç†</strong>ï¼šéšæœºé€‰æ‹©é•¿å®½æ¯”ï¼ˆå¦‚ 16:9ã€4:3ï¼‰ï¼Œè£å‰ªåç»Ÿä¸€è°ƒæ•´æœ€å¤§è¾¹åˆ° 512pxï¼Œä½¿æ¨¡å‹å¯¹ä¸åŒå½¢çŠ¶å›¾åƒæ›´é²æ£’ã€‚</p></li>
<li><p><strong>æ•°æ®å¢å¼º</strong>ï¼šä½¿ç”¨å¸¸è§çš„æ•°æ®å¢å¼ºæ–¹æ³•ï¼ˆæ²¡æœ‰å…·ä½“åˆ—å‡ºï¼Œä½†å¯ç†è§£ä¸ºæ—‹è½¬ã€ç¼©æ”¾ã€é¢œè‰²æ‰°åŠ¨ç­‰ï¼‰ã€‚</p></li>
<li><p><strong>ç½‘ç»œç»“æ„</strong>ï¼š</p>
<ul>
<li><p><strong>Encoderï¼šViT-Largeï¼ˆå¤§æ¨¡å‹ï¼‰</strong></p></li>
<li><p><strong>Decoderï¼šViT-Baseï¼ˆä¸­æ¨¡å‹ï¼‰</strong></p></li>
<li><p><strong>Headï¼šDPT Headï¼ˆç”¨äºæ·±åº¦é¢„æµ‹ç­‰ä»»åŠ¡ï¼‰</strong></p></li>
</ul>
</li>
<li><p><strong>é¢„è®­ç»ƒåˆå§‹åŒ–</strong>ï¼š
ä½¿ç”¨ CroCo é¢„è®­ç»ƒæ¨¡å‹æƒé‡ä½œä¸ºåˆå§‹åŒ–ã€‚CroCo æ˜¯ä¸€ç§ <strong>è·¨è§†å›¾å›¾åƒæ¢å¤ä»»åŠ¡çš„è‡ªç›‘ç£é¢„è®­ç»ƒæ–¹æ³•</strong>ï¼Œéå¸¸é€‚åˆ 3D è§†è§‰ä»»åŠ¡ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="evaluation">
<h4>ğŸ“Š <strong>3. è¯„ä¼°ï¼ˆEvaluationï¼‰</strong><a class="headerlink" href="#evaluation" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p>ä½¿ç”¨ <strong>åŒä¸€ä¸ª DUSt3R æ¨¡å‹ï¼ˆDUSt3R 512ï¼‰</strong> æ¥è¯„ä¼°å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ï¼Œä»ä¸å¯¹ç‰¹å®šä»»åŠ¡è¿›è¡Œå¾®è°ƒï¼ˆzero-shot è¯„ä¼°é£æ ¼ï¼‰ã€‚</p></li>
<li><p>æ‰€æœ‰æµ‹è¯•å›¾åƒéƒ½ä¼šè¢«ç­‰æ¯”ä¾‹ç¼©æ”¾åˆ°æœ€å¤§è¾¹ 512pxã€‚</p></li>
<li><p>é’ˆå¯¹æ¯ä¸ªä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚ä¸‰ç»´é‡å»ºã€é…å‡†ã€å§¿æ€ä¼°è®¡ç­‰ï¼‰ï¼Œé‡‡ç”¨ä¸åŒè¾“å‡ºæ–¹å¼ï¼Œå…·ä½“æ–¹æ³•è§ç¬¬ 3.3 å’Œ 3.4 èŠ‚ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="qualitative-results">
<h4>ğŸ¨ <strong>4. å®šæ€§ç»“æœï¼ˆQualitative resultsï¼‰</strong><a class="headerlink" href="#qualitative-results" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p>DUSt3R å³ä½¿åœ¨å›°éš¾åœºæ™¯ä¸­ä¹Ÿèƒ½ç”Ÿæˆé«˜è´¨é‡ã€ç¨ å¯†çš„ 3D é‡å»ºç»“æœã€‚</p></li>
<li><p>é™„å½•ä¸­å±•ç¤ºäº†å¾ˆå¤š <strong>â€œéæŒ‘é€‰â€çš„å¯è§†åŒ–ä¾‹å­</strong>ï¼ŒåŒ…æ‹¬å›¾åƒå¯¹å’Œå¤šè§†å›¾çš„é‡å»ºæ•ˆæœã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="id21">
<h4>âœ… æ€»ç»“ä¸€ä¸‹å…³é”®ç‚¹ï¼š<a class="headerlink" href="#id21" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>éƒ¨åˆ†</p></th>
<th class="head"><p>å†…å®¹</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>è®­ç»ƒæ•°æ®</strong></p></td>
<td><p>å¤šæºæ•°æ®é›†ã€850ä¸‡å›¾åƒå¯¹ã€å¤šæ ·æ€§å¼º</p></td>
</tr>
<tr class="row-odd"><td><p><strong>è®­ç»ƒæ–¹æ³•</strong></p></td>
<td><p>å°åˆ†è¾¨ç‡é¢„çƒ­â†’å¤§åˆ†è¾¨ç‡ä¸»è®­ï¼Œæ•°æ®å¢å¼ºï¼Œéšæœºé•¿å®½æ¯”</p></td>
</tr>
<tr class="row-even"><td><p><strong>æ¨¡å‹ç»“æ„</strong></p></td>
<td><p>ViT-Large ç¼–ç å™¨ + ViT-Base è§£ç å™¨ + DPT Head</p></td>
</tr>
<tr class="row-odd"><td><p><strong>é¢„è®­ç»ƒ</strong></p></td>
<td><p>ä½¿ç”¨ CroCo åˆå§‹åŒ–ï¼Œé€‚åˆ 3D ä»»åŠ¡</p></td>
</tr>
<tr class="row-even"><td><p><strong>è¯„ä¼°ç­–ç•¥</strong></p></td>
<td><p>å•æ¨¡å‹ï¼Œå¤šä»»åŠ¡è¯„ä¼°ï¼Œæ— å¾®è°ƒï¼Œè¾“å…¥ç»Ÿä¸€ä¸º 512px</p></td>
</tr>
<tr class="row-odd"><td><p><strong>ç»“æœå±•ç¤º</strong></p></td>
<td><p>å¯è§†åŒ–æ•ˆæœå¥½ï¼Œä¸æŒ‘å›¾ï¼Œé²æ£’æ€§å¼º</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<hr class="docutils" />
<section id="visual-localization">
<h3><strong>4.1 è§†è§‰å®šä½ï¼ˆVisual Localizationï¼‰</strong><a class="headerlink" href="#visual-localization" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p><strong>å®éªŒç›®æ ‡ï¼š</strong>
è¯„ä¼° DUSt3R åœ¨ç»å¯¹ä½å§¿ä¼°è®¡ä»»åŠ¡ï¼ˆabsolute pose estimationï¼‰ä¸­çš„è¡¨ç°ï¼Œæµ‹è¯•é›†ä¸ºä¸¤ä¸ªç»å…¸æ•°æ®é›†ï¼š</p>
<ul class="simple">
<li><p><strong>7Scenes</strong>ï¼š7ä¸ªå®¤å†…åœºæ™¯ï¼ŒRGB-D å›¾åƒ+6è‡ªç”±åº¦ç›¸æœºä½å§¿ã€‚</p></li>
<li><p><strong>Cambridge Landmarks</strong>ï¼š6ä¸ªå®¤å¤–åœºæ™¯ï¼ŒRGB å›¾åƒ+SfMæ¢å¤çš„ç›¸æœºä½å§¿ã€‚</p></li>
</ul>
<p><strong>è¯„ä»·æŒ‡æ ‡ï¼š</strong></p>
<ul class="simple">
<li><p>ä¸­ä½æ•°å¹³ç§»è¯¯å·®ï¼ˆtranslation errorï¼Œå•ä½ cmï¼‰</p></li>
<li><p>ä¸­ä½æ•°æ—‹è½¬è¯¯å·®ï¼ˆrotation errorï¼Œå•ä½ Â°ï¼‰</p></li>
</ul>
<p><strong>å®éªŒæ–¹æ³•ï¼š</strong></p>
<ul class="simple">
<li><p>DUSt3R ä½œä¸ºä¸€ä¸ª <strong>2D-2Dåƒç´ åŒ¹é…å™¨ï¼ˆpixel matcherï¼‰</strong>ï¼Œç”¨äºè®¡ç®—æŸ¥è¯¢å›¾åƒä¸æ•°æ®åº“å›¾åƒä¹‹é—´çš„åƒç´ ç‚¹å¯¹åº”ã€‚</p></li>
<li><p>æ•°æ®åº“å›¾åƒé€šè¿‡å›¾åƒæ£€ç´¢æ–¹æ³• <strong>AP-GeM</strong> æ£€ç´¢è·å¾—ã€‚</p></li>
<li><p>å¯¹äº Cambridge ä½¿ç”¨ top 20 å›¾åƒï¼Œ7Scenes ä½¿ç”¨ top 1ã€‚</p></li>
<li><p>æ²¡æœ‰ä½¿ç”¨ä»»ä½•åå¤„ç†æˆ–ç²¾åŒ–ï¼ˆä¾‹å¦‚ bundle adjustmentï¼‰ï¼Œä¹Ÿæ²¡æœ‰ä½¿ç”¨ GT å†…å‚ä¼šæœ‰å•ç‹¬è¯´æ˜ã€‚</p></li>
</ul>
<p><strong>å…³é”®ç‚¹ï¼š</strong></p>
<ul class="simple">
<li><p>ä»…ä½¿ç”¨ DUSt3R è¾“å‡ºçš„ç‚¹äº‘åŒ¹é…ï¼ˆpointmapï¼‰æ¥åšä½å§¿ä¼°è®¡ï¼Œå®Œå…¨ <strong>é›¶è®­ç»ƒç”¨äºè§†è§‰å®šä½çš„ç›‘ç£</strong>ã€‚</p></li>
<li><p>DUSt3R è®­ç»ƒæ—¶ä¹Ÿæ²¡æœ‰è§è¿‡æµ‹è¯•é›†ä¸­çš„å›¾åƒã€‚</p></li>
<li><p>ä¸ç‰¹å¾åŒ¹é…ç±»æ–¹æ³•ï¼ˆå¦‚ HLocï¼‰å’Œç«¯åˆ°ç«¯å­¦ä¹ æ–¹æ³•æ¯”è¾ƒï¼Œè¡¨ç°ç›¸å½“ç”šè‡³è¶…è¶Šéƒ¨åˆ†å¼ºåŸºçº¿ï¼ˆå¦‚ HLocï¼‰ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="multi-view-pose-estimation">
<h3><strong>4.2 å¤šè§†è§’ç›¸å¯¹ä½å§¿ä¼°è®¡ï¼ˆMulti-view Pose Estimationï¼‰</strong><a class="headerlink" href="#multi-view-pose-estimation" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p><strong>å®éªŒç›®æ ‡ï¼š</strong></p>
<ul class="simple">
<li><p>æµ‹è¯• DUSt3R åœ¨å¤šè§†è§’åºåˆ—ä¸­çš„ç›¸å¯¹ä½å§¿ä¼°è®¡æ•ˆæœã€‚</p></li>
</ul>
<p><strong>æ•°æ®é›†ï¼š</strong></p>
<ul class="simple">
<li><p><strong>CO3Dv2</strong>ï¼š6M å¸§ï¼Œæ¥è‡ª 37K è§†é¢‘ï¼Œ51ç±»å¯¹è±¡ï¼ˆæ¥è‡ª MS-COCOï¼‰ï¼Œä½¿ç”¨ COLMAP è®¡ç®—çœŸå€¼ä½å§¿ã€‚</p></li>
<li><p><strong>RealEstate10k</strong>ï¼šå®¤å†…å¤–åœºæ™¯ï¼Œ10M å¸§ï¼Œçº¦ 80K YouTube è§†é¢‘ç‰‡æ®µï¼Œç”¨ SLAM + BA æå–ä½å§¿ã€‚</p></li>
</ul>
<p><strong>å®éªŒè®¾ç½®ï¼š</strong></p>
<ul class="simple">
<li><p>å¯¹æ¯æ®µè§†é¢‘éšæœºé€‰ 10 å¸§ï¼Œæ„æˆ 45 å¯¹å›¾åƒè¾“å…¥ DUSt3Rã€‚</p></li>
<li><p>ä½¿ç”¨ä¸¤ç§æ–¹å¼æ±‚è§£ç›¸å¯¹ä½å§¿ï¼š</p>
<ul>
<li><p>PnP-RANSAC</p></li>
<li><p>å…¨å±€å¯¹é½ï¼ˆglobal alignmentï¼‰</p></li>
</ul>
</li>
</ul>
<p><strong>è¯„ä»·æŒ‡æ ‡ï¼š</strong></p>
<ul class="simple">
<li><p><strong>RRA&#64;15</strong>ï¼šç›¸å¯¹æ—‹è½¬ç²¾åº¦ï¼ˆè§’åº¦è¯¯å·® &lt; 15Â° çš„æ¯”ä¾‹ï¼‰</p></li>
<li><p><strong>RTA&#64;15</strong>ï¼šç›¸å¯¹å¹³ç§»ç²¾åº¦ï¼ˆè§’åº¦è¯¯å·® &lt; 15Â° çš„æ¯”ä¾‹ï¼‰</p></li>
<li><p><strong>mAA&#64;30</strong>ï¼šæœ€å°å€¼ min(RRA&#64;30, RTA&#64;30) ä¸‹çš„å¹³å‡å‡†ç¡®ç‡ï¼ˆAUCï¼‰</p></li>
</ul>
<p><strong>ç»“æœäº®ç‚¹ï¼š</strong></p>
<ul class="simple">
<li><p>DUSt3R åœ¨ä¸¤ç§æ•°æ®é›†ä¸Šéƒ½è¡¨ç° <strong>ä¼˜äºç›®å‰æœ€å¼ºçš„æ–¹æ³• PoseDiffusion</strong>ã€‚</p></li>
<li><p>å³ä¾¿åªä½¿ç”¨ç®€å•çš„ PnP è§£æ³•ä¹Ÿè¶…è¿‡ç°æœ‰å­¦ä¹ ä¸å‡ ä½•åŸºçº¿ã€‚</p></li>
<li><p>RealEstate10K ä¸­ PoseDiffusion ä½¿ç”¨ CO3Dv2 è®­ç»ƒï¼Œä½† DUSt3R æ˜¯çº¯é›¶è®­ç»ƒã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="monocular-depth-estimation">
<h3><strong>4.3 å•ç›®æ·±åº¦ä¼°è®¡ï¼ˆMonocular Depth Estimationï¼‰</strong><a class="headerlink" href="#monocular-depth-estimation" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p><strong>æ–¹æ³•ç®€è¿°ï¼š</strong></p>
<ul class="simple">
<li><p>ç›´æ¥ç”¨å›¾åƒ <code class="docutils literal notranslate"><span class="pre">I</span></code> è¾“å…¥ DUSt3R è‡ªèº«ä½œä¸ºæŸ¥è¯¢å›¾åƒå’Œæ•°æ®åº“å›¾åƒï¼Œå³ <code class="docutils literal notranslate"><span class="pre">â„±(I,</span> <span class="pre">I)</span></code>ã€‚</p></li>
<li><p>è¾“å‡ºç‚¹äº‘ä¸­çš„ <strong>z è½´åæ ‡å³ä¸ºé¢„æµ‹æ·±åº¦</strong>ã€‚</p></li>
</ul>
<p><strong>æ•°æ®é›†ï¼š</strong></p>
<ul class="simple">
<li><p><strong>æˆ·å¤–ï¼š</strong> KITTI, DDAD</p></li>
<li><p><strong>å®¤å†…ï¼š</strong> NYUv2, BONN, TUM</p></li>
</ul>
<p><strong>è¯„ä»·æŒ‡æ ‡ï¼š</strong></p>
<ul class="simple">
<li><p><strong>AbsRel</strong>ï¼šç»å¯¹ç›¸å¯¹è¯¯å·® = |y - Å·| / y</p></li>
<li><p><strong>Î´&lt;1.25</strong>ï¼šé¢„æµ‹æ·±åº¦å’ŒçœŸå®æ·±åº¦ä¹‹æ¯”åœ¨ 1.25 å€ä»¥å†…çš„åƒç´ æ¯”ä¾‹</p></li>
</ul>
<p><strong>ç»“æœï¼š</strong></p>
<ul class="simple">
<li><p>DUSt3R å±äº <strong>zero-shot æ¨¡å‹</strong>ï¼Œæ²¡æœ‰é’ˆå¯¹æ·±åº¦ä¼°è®¡è®­ç»ƒã€‚</p></li>
<li><p>è¡¨ç°ä¼˜äºè‡ªç›‘ç£æ–¹æ³•ï¼Œç”šè‡³<strong>æ¥è¿‘æˆ–è¶…è¶Š</strong>å¾ˆå¤šç›‘ç£æ–¹æ³•ã€‚</p></li>
<li><p>å¯ä¸ SlowTvï¼ˆä¸€ä¸ªèåˆå¤šæºæ•°æ®è®­ç»ƒçš„å¤§æ¨¡å‹ï¼‰åª²ç¾ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="multi-view-depth">
<h3>4.4 å¤šè§†è§’æ·±åº¦ä¼°è®¡ï¼ˆMulti-view Depthï¼‰<a class="headerlink" href="#multi-view-depth" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>ğŸ“Œ æ–¹æ³•æ¦‚è¿°ï¼š</p>
<ul class="simple">
<li><p>DUSt3R è¢«ç”¨äºå¤šè§†å›¾ç«‹ä½“ï¼ˆMulti-view Stereo, MVSï¼‰æ·±åº¦ä¼°è®¡ä»»åŠ¡ï¼Œå…·ä½“åšæ³•æ˜¯ï¼š</p></li>
<li><p>åˆ©ç”¨å®ƒé¢„æµ‹å‡ºçš„ <strong>ç‚¹äº‘å›¾ï¼ˆpointmapsï¼‰ä¸­çš„ z åæ ‡ä½œä¸ºæ·±åº¦å›¾ï¼ˆdepthmapï¼‰</strong>ã€‚</p></li>
<li><p>å¦‚æœæŸå¼ å›¾åƒæœ‰å¤šä¸ªè§’åº¦çš„é¢„æµ‹æ·±åº¦å›¾ï¼Œå°±ä¼šå…ˆç»Ÿä¸€ç¼©æ”¾ï¼ˆrescaleï¼‰åˆ°åŒä¸€å°ºåº¦ï¼Œç„¶åé€šè¿‡**ç½®ä¿¡åº¦åŠ æƒå¹³å‡ï¼ˆweighted averaging by confidenceï¼‰**çš„æ–¹æ³•èåˆã€‚</p></li>
</ul>
<p>ğŸ“Š è¯„ä¼°æ–¹å¼ï¼š</p>
<ul class="simple">
<li><p>ä½¿ç”¨äº†å››ä¸ªå¸¸è§ MVS æ•°æ®é›†ï¼šDTUã€ETH3Dã€Tanks and Templesã€ScanNetã€‚</p></li>
<li><p>æŒ‡æ ‡åŒ…æ‹¬ï¼š</p>
<ul>
<li><p><strong>Absolute Relative Errorï¼ˆç»å¯¹ç›¸å¯¹è¯¯å·®ï¼‰</strong></p></li>
<li><p><strong>Inlier Ratioï¼ˆå†…ç‚¹æ¯”ï¼‰</strong>ï¼šé˜ˆå€¼ä¸º 1.03</p></li>
</ul>
</li>
<li><p>ä»–ä»¬<strong>ä¸ä½¿ç”¨ ground-truth æ‘„åƒæœºå‚æ•°æˆ–æ·±åº¦èŒƒå›´</strong>ï¼Œæ‰€ä»¥é¢„æµ‹ç»“æœåªæœ‰ç›¸å¯¹å°ºåº¦ã€‚</p></li>
<li><p>ä¸ºäº†åšé‡åŒ–è¯„ä¼°ï¼Œä¼šç”¨ <strong>é¢„æµ‹å€¼å’Œ GT æ·±åº¦çš„ä¸­ä½æ•°æ¯”å€¼</strong>æ¥åšå½’ä¸€åŒ–ï¼ˆå‚è€ƒæ–‡çŒ® [110] çš„æ–¹æ³•ï¼‰ã€‚</p></li>
</ul>
<p>ğŸ† å®éªŒç»“æœï¼š</p>
<ul class="simple">
<li><p>DUSt3R åœ¨ <strong>ETH3D æ•°æ®é›†ä¸Šè¾¾åˆ° SOTA ç²¾åº¦</strong>ï¼Œåœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šæ€»ä½“è¡¨ç°ä¹Ÿè¶…è¿‡äº†å¤§éƒ¨åˆ†ä½¿ç”¨ GT æ‘„åƒæœºä½å§¿çš„ SOTA æ–¹æ³•ã€‚</p></li>
<li><p><strong>é€Ÿåº¦æ–¹é¢</strong>ä¹Ÿè¿œè¶…ä¼ ç»Ÿçš„ COLMAP é‡å»ºç®¡çº¿ã€‚</p></li>
<li><p>è¿™è¯´æ˜è¯¥æ–¹æ³•åœ¨å¤šç§åœºæ™¯ï¼ˆå®¤å†…/å®¤å¤–ï¼Œå°å°ºåº¦/å¤§å°ºåº¦ï¼‰ä¸‹éƒ½å¾ˆé€‚ç”¨ï¼Œå°¤å…¶åœ¨æ²¡è§è¿‡çš„æµ‹è¯•é›†ä¸Šä¹Ÿèƒ½æ³›åŒ–ï¼ˆé™¤äº† ScanNetï¼Œå› ä¸ºå®ƒçš„è®­ç»ƒé›†æ˜¯ Habitat æ•°æ®é›†ä¸€éƒ¨åˆ†ï¼‰ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="d-reconstruction">
<h3>4.5 ä¸‰ç»´é‡å»ºï¼ˆ3D Reconstructionï¼‰<a class="headerlink" href="#d-reconstruction" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>ğŸ“Œ æ–¹æ³•æ¦‚è¿°ï¼š</p>
<ul class="simple">
<li><p>è¿™éƒ¨åˆ†è¯„ä¼°çš„æ˜¯æ•´å¥—æµç¨‹ï¼ˆåŒ…æ‹¬å‰é¢æåˆ°çš„ <strong>global alignment å¯¹é½è¿‡ç¨‹</strong>ï¼‰ä¹‹åå¾—åˆ°çš„ 3D é‡å»ºè´¨é‡ã€‚</p></li>
<li><p>è¯¥æ–¹æ³•ç‰¹åˆ«ä¹‹å¤„åœ¨äºï¼š<strong>æ— ç›‘ç£ã€æ— å…ˆéªŒï¼ˆunconstrained MVSï¼‰</strong> â€”â€” ä¹Ÿå°±æ˜¯è¯´ï¼Œ<strong>å®Œå…¨ä¸ä¾èµ–äºæ‘„åƒå¤´çš„å†…/å¤–å‚ä¿¡æ¯</strong>ã€‚</p></li>
<li><p>è¯„ä¼°æ—¶å°†é¢„æµ‹ç»“æœå¯¹é½åˆ° ground-truth åæ ‡ç³»ï¼ˆç”¨ Eq.5 çš„å‚æ•°ä½œä¸ºå¸¸æ•°ï¼‰ã€‚</p></li>
</ul>
<p>ğŸ“Š æ•°æ®é›†ä¸è¯„ä¼°æŒ‡æ ‡ï¼š</p>
<ul class="simple">
<li><p>ä½¿ç”¨ <strong>DTU</strong> æ•°æ®é›†ï¼Œ<strong>é›¶æ ·æœ¬æµ‹è¯•ï¼ˆzero-shotï¼‰</strong>ï¼šä¸åœ¨ DTU ä¸Šå¾®è°ƒï¼Œç›´æ¥ç”¨åŸå§‹æ¨¡å‹ã€‚</p></li>
<li><p>æŒ‡æ ‡åŒ…æ‹¬ï¼š</p>
<ul>
<li><p><strong>Accuracyï¼ˆç²¾åº¦ï¼‰</strong>ï¼šé¢„æµ‹ç‚¹åˆ° GT ç‚¹äº‘çš„æœ€å°è·ç¦»</p></li>
<li><p><strong>Completenessï¼ˆå®Œæ•´æ€§ï¼‰</strong>ï¼šGT ç‚¹åˆ°é¢„æµ‹ç‚¹äº‘çš„æœ€å°è·ç¦»</p></li>
<li><p><strong>Overall</strong>ï¼šä¸¤è€…çš„å¹³å‡</p></li>
</ul>
</li>
</ul>
<p>âš–ï¸ å®éªŒç»“æœåˆ†æï¼š</p>
<ul class="simple">
<li><p><strong>ç²¾åº¦ä¸Šç•¥ä½äº SOTA</strong> æ–¹æ³•ã€‚åŸå› ï¼š</p>
<ul>
<li><p>å…¶ä»–æ–¹æ³•ç”¨äº† GT æ‘„åƒæœºä½å§¿å¹¶åœ¨ DTU ä¸Šè®­ç»ƒè¿‡ã€‚</p></li>
<li><p>æœ€å¥½çš„é‡å»ºæ–¹æ³•ä¾èµ–<strong>äºšåƒç´ çº§ä¸‰è§’æµ‹é‡ï¼ˆsub-pixel triangulationï¼‰</strong>ï¼Œè¿™éœ€è¦æ˜ç¡®çš„ç›¸æœºå‚æ•°ã€‚</p></li>
</ul>
</li>
<li><p>è€Œ DUSt3R ä½¿ç”¨çš„æ˜¯<strong>å›å½’</strong>æ–¹å¼ï¼ˆregressionï¼‰ï¼Œç²¾åº¦æœ¬èº«å°±ä¼šå—é™ã€‚</p></li>
<li><p>å°½ç®¡å¦‚æ­¤ï¼Œåœ¨æ— ä»»ä½•ç›¸æœºä¿¡æ¯å‰æä¸‹ï¼Œ<strong>ä»è¾¾åˆ° 2.7mm çš„å¹³å‡ç²¾åº¦ï¼Œ0.8mm çš„å®Œæ•´æ€§ï¼Œæ€»ä½“è¯¯å·® 1.7mm</strong>ï¼Œå¯¹äºå®ç”¨åœºæ™¯å·²ç»ç›¸å½“ä¸é”™ï¼Œå°¤å…¶è€ƒè™‘åˆ°å®ƒæ˜¯ä¸€ä¸ª plug-and-play çš„æ–¹æ³•ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="ablations">
<h3>4.6 æ¶ˆèå®éªŒï¼ˆAblationsï¼‰<a class="headerlink" href="#ablations" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>ğŸ“Œ æ¶ˆèç‚¹ï¼š</p>
<ul class="simple">
<li><p>åˆ†æäº†ä¸¤ä¸ªå› ç´ å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ï¼š</p>
<ol class="arabic simple">
<li><p><strong>CroCo çš„é¢„è®­ç»ƒæ•ˆæœ</strong></p></li>
<li><p><strong>å›¾åƒåˆ†è¾¨ç‡çš„å½±å“</strong></p></li>
</ol>
</li>
</ul>
<p>ğŸ“Š å®éªŒæ–¹å¼ï¼š</p>
<ul class="simple">
<li><p>å¯¹æ¯”äº†å‰é¢ä»»åŠ¡ï¼ˆè§†è§‰å®šä½ã€å¤šè§†è§’ä½å§¿ä¼°è®¡ã€å¤šè§†è§’æ·±åº¦ä¼°è®¡ï¼‰åœ¨ä¸åŒè®¾ç½®ä¸‹çš„è¡¨ç°ï¼ˆè§è¡¨ 1ã€2ã€3ï¼‰ã€‚</p></li>
</ul>
<p>ğŸ§  ç»“è®ºï¼š</p>
<ul class="simple">
<li><p>é«˜åˆ†è¾¨ç‡å’Œè‰¯å¥½çš„é¢„è®­ç»ƒç­–ç•¥å¯¹æœ€ç»ˆè¡¨ç°æœ‰æ˜¾è‘—å¸®åŠ©ã€‚</p></li>
<li><p>å’Œå…¶ä»–ç ”ç©¶ï¼ˆå¦‚ [149] å’Œ [78]ï¼‰çš„ç»“è®ºä¸€è‡´ï¼šç°ä»£æ•°æ®é©±åŠ¨æ–¹æ³•<strong>é«˜åº¦ä¾èµ–é¢„è®­ç»ƒå’Œè¾“å…¥è´¨é‡</strong>ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="id22">
<h3>ğŸ§© æ€»ç»“ä¸€å¥è¯ï¼š<a class="headerlink" href="#id22" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<blockquote>
<div><p>DUSt3R æ˜¯ä¸€ä¸ªæ— éœ€æ‘„åƒæœºå‚æ•°ã€å¯ plug-and-play çš„ç«¯åˆ°ç«¯ 3D é‡å»ºç³»ç»Ÿï¼Œåœ¨å¤šç§ä»»åŠ¡ä¸Šå–å¾—äº†ä»¤äººç©ç›®çš„æ€§èƒ½ï¼Œè™½ç„¶åœ¨æé™ç²¾åº¦ä¸Šä¸åŠä¼ ç»Ÿæ–¹æ³•ï¼Œä½†å¤§å¤§ç®€åŒ–äº†æµç¨‹ï¼Œå¹¶ä¿æŒäº†è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
</div></blockquote>
</section>
</section>
<section id="conclusion">
<h2>5. Conclusion<a class="headerlink" href="#conclusion" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<section id="id23">
<h3>ğŸ”š æ€»ç»“å†…å®¹è§£æ<a class="headerlink" href="#id23" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<blockquote>
<div><p><strong>åŸæ–‡æ‘˜è¦ï¼š</strong><br />
â€œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°èŒƒå¼ï¼Œèƒ½å¤Ÿåœ¨æ²¡æœ‰ä»»ä½•å…³äºåœºæ™¯æˆ–ç›¸æœºçš„å…ˆéªŒä¿¡æ¯çš„æƒ…å†µä¸‹å®Œæˆ3Dé‡å»ºï¼Œå¹¶ä¸”é€‚ç”¨äºå„ç§3Dè§†è§‰ä»»åŠ¡ã€‚â€</p>
</div></blockquote>
</section>
<section id="id24">
<h3>âœ… å…³é”®è¯è§£é‡Šï¼š<a class="headerlink" href="#id24" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p><strong>æ–°èŒƒå¼ï¼ˆnovel paradigmï¼‰</strong>ï¼šDUSt3R å¼•å…¥çš„æ˜¯ä¸€ç§æ–°çš„æ€è·¯ï¼Œä¸åƒä¼ ç»Ÿæ–¹æ³•é‚£æ ·ä¾èµ–ç›¸æœºå‚æ•°æˆ–ç»“æ„å…ˆéªŒï¼Œè€Œæ˜¯é€šè¿‡è®­ç»ƒå¥½çš„æ¨¡å‹ä»å›¾åƒä¸­ç›´æ¥æ¢å¤3Dä¿¡æ¯ã€‚</p></li>
<li><p><strong>in-the-wild</strong>ï¼šè¿™æ„å‘³ç€æ–¹æ³•èƒ½åœ¨çœŸå®ç¯å¢ƒä¸­å·¥ä½œï¼Œä¸å±€é™äºå®éªŒå®¤æˆ–åˆæˆæ•°æ®ã€‚</p></li>
<li><p><strong>æ— éœ€å…ˆéªŒä¿¡æ¯</strong>ï¼šDUSt3R ä¸éœ€è¦å·²çŸ¥çš„ç›¸æœºå†…å‚ï¼ˆintrinsicsï¼‰ã€å¤–å‚ï¼ˆextrinsicsï¼‰ï¼Œæˆ–åœºæ™¯çš„æ·±åº¦èŒƒå›´ç­‰ä¿¡æ¯ã€‚</p></li>
<li><p><strong>å¤šç§ä»»åŠ¡</strong>ï¼šä¸åªæ˜¯ 3Dé‡å»ºï¼ŒDUSt3R è¿˜èƒ½å¤„ç†è§†è§‰å®šä½ã€å¤šè§†å›¾å‡ ä½•ç­‰ä»»åŠ¡ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="id25">
<h3>ğŸ“Œ æ€»ç»“å…³é”®è¯æç‚¼<a class="headerlink" href="#id25" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>å…³é”®è¯</p></th>
<th class="head"><p>å«ä¹‰</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Raw output</p></td>
<td><p>æœªåå¤„ç†çš„ç½‘ç»œåŸå§‹è¾“å‡ºï¼ˆæ·±åº¦ã€ç½®ä¿¡å›¾ã€ç‚¹äº‘ï¼‰</p></td>
</tr>
<tr class="row-odd"><td><p>Viewpoint/Focal change</p></td>
<td><p>æ‘„åƒæœºè§’åº¦æˆ–ç„¦è·å˜åŒ–ï¼ˆDUSt3Rèƒ½å¤„ç†ï¼‰</p></td>
</tr>
<tr class="row-even"><td><p>Pointmap recovery</p></td>
<td><p>ä»å›¾åƒæ¢å¤å‡º3Dç‚¹å›¾+ç›¸æœºå§¿æ€</p></td>
</tr>
<tr class="row-odd"><td><p>Unseen scenes</p></td>
<td><p>æµ‹è¯•å›¾åƒæ²¡æœ‰å‡ºç°åœ¨è®­ç»ƒä¸­ï¼ŒéªŒè¯æ³›åŒ–èƒ½åŠ›</p></td>
</tr>
<tr class="row-even"><td><p>Plug-and-play</p></td>
<td><p>å¼€ç®±å³ç”¨ï¼Œä¸éœ€è¦å…ˆéªŒä¿¡æ¯æˆ–å¤æ‚é…ç½®</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<hr class="docutils" />
<section id="appendix-a">
<h2>Appendix A <strong>é™„å½•æ¦‚è§ˆ</strong><a class="headerlink" href="#appendix-a" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p>æœ¬é™„å½•æä¾›äº†å…³äº <strong>DUSt3R</strong> çš„è¡¥å……ä¿¡æ¯ä¸å®šæ€§ç»“æœï¼Œå…·ä½“å†…å®¹å¦‚ä¸‹ï¼š</p>
<ul class="simple">
<li><p><strong>BèŠ‚</strong> å±•ç¤ºäº†è¯¥æ¶æ„åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„æˆå¯¹é¢„æµ‹çš„å®šæ€§ç»“æœï¼ŒåŒæ—¶è¿˜æè¿°äº†ä¸æœ¬æ–‡é…å¥—çš„è§†é¢‘èµ„æ–™ã€‚</p></li>
<li><p><strong>CèŠ‚</strong> æ‰©å±•äº†ç›¸å…³å·¥ä½œçš„è®¨è®ºï¼Œæ¶µç›–äº†æ›´å¹¿æ³›çš„æ–¹æ³•ç±»åˆ«åŠå‡ ä½•è§†è§‰ä»»åŠ¡ã€‚</p></li>
<li><p><strong>DèŠ‚</strong> æä¾›äº†å¤šè§†å›¾å§¿æ€ä¼°è®¡ä»»åŠ¡çš„è¾…åŠ©æ¶ˆèå®éªŒç»“æœï¼Œè¿™éƒ¨åˆ†ç”±äºç¯‡å¹…é™åˆ¶æœªèƒ½åŒ…å«åœ¨ä¸»æ–‡ä¸­ã€‚</p></li>
<li><p><strong>EèŠ‚</strong> æŠ¥å‘Šäº†ä¸€ä¸ªå®éªŒæ€§çš„è§†è§‰å®šä½ä»»åŠ¡çš„ç»“æœï¼Œåœ¨è¯¥ä»»åŠ¡ä¸­ï¼Œç›¸æœºå†…å‚æ˜¯æœªçŸ¥çš„ã€‚</p></li>
<li><p><strong>FèŠ‚</strong> è¯¦ç»†ä»‹ç»äº†è®­ç»ƒæµç¨‹ä¸æ‰€é‡‡ç”¨çš„æ•°æ®å¢å¼ºç­–ç•¥ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="appendix-b-qualitative-results">
<h2>Appendix B.  Qualitative results<a class="headerlink" href="#appendix-b-qualitative-results" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<ul class="simple">
<li><p>ç›¸å…³è§†é¢‘: <a class="reference external" href="https://europe.naverlabs.com/research/publications/dust3r-geometric-3d-vision-made-easy/">è§†é¢‘é“¾æ¥</a></p></li>
</ul>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/04/XmXf41.png" /></p>
<p>Figure 4:Example of 3D reconstruction of an unseen MegaDepth scene from two images (top-left). Note this is the raw output of the network, i.e. we show the output depthmaps (top-center, see Eq. 8) and confidence maps (top-right), as well as two different viewpoints on the colored pointcloud (middle and bottom). Camera parameters are recovered from the raw pointmaps, see Sec. 3.3 in the main paper. DUSt3R handles strong viewpoint and focal changes without apparent problems</p>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/04/qBUzKv.png" /></p>
<p>Figure 5:Example of 3D reconstruction of an unseen MegaDepth [56] scene from two images only. Note this is the raw output of the network, i.e. we show the output depthmaps (top-center) and confidence maps (top-right), as well as different viewpoints on the colored pointcloud (middle and bottom). Camera parameters are recovered from the raw pointmaps, see Sec. 3.3 in the main paper. DUSt3R handles strong viewpoint and focal changes without apparent problems</p>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/04/n0UVQk.png" /></p>
<p>Figure 6:Example of 3D reconstruction from two images only of unseen scenes, namely KingsCollege(Top-Left), OldHospital (Top-Middle), StMarysChurch(Top-Right), ShopFacade(Bottom-Left), GreatCourt(Bottom-Right). Note this is the raw output of the network, i.e. we show new viewpoints on the colored pointclouds. Camera parameters are recovered from the raw pointmaps, see Sec. 3.3 in the main paper.</p>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/04/u5GnVI.png" /></p>
<p>Figure 7:Example of 3D reconstruction from two images only of unseen scenes, namely Chess, Fire, Heads, Office (Top-Row), Pumpkin, Kitchen, Stairs (Bottom-Row). Note this is the raw output of the network, i.e. we show new viewpoints on the colored pointclouds. Camera parameters are recovered from the raw pointmaps, see Sec. 3.3 in the main paper.</p>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/04/DCU5oG.png" /></p>
<p>Figure 8:Examples of 3D reconstructions from nearly opposite viewpoints. For each of the 4 cases (motorcycle, toaster, bench, stop sign), we show the two input images (top-left) and the raw output of the network: output depthmaps (top-center) and confidence maps (top-right), as well as two different views on the colored point-clouds (middle and bottom). Camera parameters are recovered from the raw pointmaps, see Sec. 3.3 in the main paper. DUSt3R handles drastic viewpoint changes without apparent issues, even when there is almost no overlapping visual content between images, e.g. for the stop sign and motorcycle. Note that these example cases are not cherry-picked; they are randomly chosen from the set of unseen CO3D_v2 sequences. Please refer to the video for animated visualizations.</p>
</section>
<section id="appendix-c-extended-related-work">
<h2>Appendix C. Extended Related Work<a class="headerlink" href="#appendix-c-extended-related-work" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<section id="implicit-camera-models">
<h3>1. <strong>Implicit Camera Modelsï¼ˆéšå¼ç›¸æœºæ¨¡å‹ï¼‰</strong><a class="headerlink" href="#implicit-camera-models" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p>æ ¸å¿ƒæ€æƒ³ï¼šä¸æ˜¾å¼å»ºæ¨¡ç›¸æœºå‚æ•°ï¼Œè€Œæ˜¯å°†3Då½¢çŠ¶è¡¨ç¤ºä¸ºæŸç§è§„èŒƒç©ºé—´ä¸­çš„éšå¼è¡¨ç¤ºã€‚</p></li>
<li><p>è¡¨ç¤ºæ–¹å¼åŒ…æ‹¬ï¼š</p>
<ul>
<li><p>å æ®ç½‘æ ¼ï¼ˆoccupancy gridsï¼‰</p></li>
<li><p>å…«å‰æ ‘ç»“æ„ï¼ˆoctrees structuresï¼‰</p></li>
<li><p>å‚æ•°åŒ–æ›²é¢é›†åˆ</p></li>
<li><p>ç‚¹äº‘ç¼–ç å™¨</p></li>
<li><p>æ¨¡æ¿ç½‘æ ¼è‡ªç”±å½¢å˜</p></li>
<li><p>æ¯è§†å›¾æ·±åº¦å›¾</p></li>
</ul>
</li>
<li><p>é—®é¢˜ï¼š</p>
<ul>
<li><p>å¤šç”¨äº ShapeNet ç­‰äººå·¥æ•°æ®é›†ï¼Œæ³›åŒ–èƒ½åŠ›å·®ã€‚</p></li>
<li><p>éš¾ä»¥å¤„ç†å¤æ‚è‡ªç„¶åœºæ™¯ã€‚</p></li>
</ul>
</li>
<li><p>DUSt3R çš„åˆ›æ–°ç‚¹ï¼š</p>
<ul>
<li><p>ä½¿ç”¨ç‚¹å›¾ï¼ˆpointmapsï¼‰ä¿æŒåƒç´ ä¸3Dç©ºé—´ä¹‹é—´çš„è”ç³»ï¼Œå…·å¤‡æ›´å¥½çš„å¯è§£é‡Šæ€§å’Œä¸€è‡´æ€§ã€‚</p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="dense-visual-slam-slam">
<h3>2. <strong>Dense Visual SLAMï¼ˆå¯†é›†è§†è§‰SLAMï¼‰</strong><a class="headerlink" href="#dense-visual-slam-slam" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p>ä¼ ç»Ÿæ–¹æ³•åˆ©ç”¨æ·±åº¦ç›¸æœºæˆ– RGB è§†é¢‘æµè¿›è¡Œï¼š</p>
<ul>
<li><p>é«˜è´¨é‡æ·±åº¦å›¾ç”Ÿæˆ</p></li>
<li><p>ç›¸æœºè½¨è¿¹ä¼°è®¡</p></li>
</ul>
</li>
<li><p>å­˜åœ¨çš„é—®é¢˜ï¼š</p>
<ul>
<li><p>å™ªå£°ã€æ¼‚ç§»ã€åƒç´ å¯¹åº”è¯¯å·®è¾ƒå¤š</p></li>
<li><p>å‡è®¾å›¾åƒåºåˆ—ç´§å¯†ç›¸å…³ï¼ˆåŒä¸€ç›¸æœºã€ç›¸ä¼¼è§†è§’ã€å…‰ç…§å˜åŒ–å°ï¼‰</p></li>
</ul>
</li>
<li><p>DUSt3R çš„ä¸åŒï¼š</p>
<ul>
<li><p>ä¸ä¾èµ–å›¾åƒé¡ºåº</p></li>
<li><p>å¯å¤„ç†â€œå®Œå…¨éçº¦æŸâ€çš„å›¾åƒå¯¹é›†åˆ</p></li>
<li><p>ä¸è¦æ±‚å·²çŸ¥ç›¸æœºå†…å‚/å¤–å‚</p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="implicit-3d-reconstruction-3d">
<h3>3. <strong>Implicit 3D Reconstructionï¼ˆéšå¼3Dé‡å»ºï¼‰</strong><a class="headerlink" href="#implicit-3d-reconstruction-3d" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p>æ–¹æ³•å¦‚ NeRFã€Volumetric Rendering ç­‰ï¼Œä½¿ç”¨ MLP è¡¨è¾¾è¿ç»­çš„ 5D å‡½æ•°ã€‚</p></li>
<li><p>ä¼˜åŠ¿ï¼šæ–°è§†è§’åˆæˆèƒ½åŠ›å¼º</p></li>
<li><p>å±€é™ï¼š</p>
<ul>
<li><p>è®­ç»ƒå’Œæ¸²æŸ“æ—¶é—´é•¿</p></li>
<li><p>å‡ ä½•ç»“æ„ä¸æ˜ç¡®ï¼ˆéšå¼è¡¨ç¤ºä¸åˆ©äºä¸‹æ¸¸ä»»åŠ¡ï¼‰</p></li>
</ul>
</li>
<li><p>DUSt3R é‡‡ç”¨ <strong>æ˜¾å¼é‡å»ºï¼ˆexplicit 3D reconstructionï¼‰</strong>ï¼Œä»¥ç‚¹å›¾å½¢å¼è¾“å‡ºï¼Œå…·å¤‡ï¼š</p>
<ul>
<li><p>æ˜ç¡®çš„å‡ ä½•ç»“æ„</p></li>
<li><p>æ›´é€‚åˆä¸‹æ¸¸ä»»åŠ¡å¦‚é…å‡†ã€é‡å®šä½ã€å§¿æ€ä¼°è®¡ç­‰</p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="rgb-pairs-to-3d">
<h3>4. <strong>RGB-pairs-to-3D</strong><a class="headerlink" href="#rgb-pairs-to-3d" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p>ä¸¤è§†å›¾å‡ ä½•çš„ç»å…¸é—®é¢˜ï¼š</p>
<ul>
<li><p>æ·±åº¦å›¾ + ç›¸å¯¹ç›¸æœºå§¿æ€ä¼°è®¡</p></li>
</ul>
</li>
<li><p>å­¦ä¹ æ–¹æ³•ä¸¤ç±»ï¼š</p>
<ul>
<li><p>å•ç›®æ·±åº¦ + å§¿æ€å›å½’</p></li>
<li><p>ç«‹ä½“åŒ¹é… + å§¿æ€ä¼°è®¡</p></li>
</ul>
</li>
<li><p>æ–°è¶‹åŠ¿ï¼š</p>
<ul>
<li><p>ç”¨äºæ— ç›‘ç£é¢„è®­ç»ƒï¼ˆå¦‚ CroCoï¼‰ä»å¤§é‡å›¾åƒå¯¹ä¸­å­¦ä¹ éšå¼å‡ ä½•è¡¨ç¤º</p></li>
</ul>
</li>
<li><p>DUSt3R çš„ç­–ç•¥ï¼š</p>
<ul>
<li><p>å€Ÿé‰´ CroCoï¼Œä½†ç›®æ ‡æ˜¯<strong>ç›´æ¥ç”Ÿæˆ3Dç‚¹å›¾</strong>è€Œéä½œä¸ºé¢„è®­ç»ƒä»»åŠ¡</p></li>
<li><p>æ·±åº¦å›¾å’Œç›¸æœºå§¿æ€ä»…æ˜¯ä¸­é—´äº§ç‰©ï¼Œè€Œéæœ€ç»ˆç›®æ ‡</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<p>ğŸ“Œ DUSt3R æ–¹æ³•çš„æ ¸å¿ƒä¼˜åŠ¿å¯¹æ¯”æ€»ç»“</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>ç±»åˆ«</p></th>
<th class="head"><p>ä¼ ç»Ÿæ–¹æ³•é—®é¢˜</p></th>
<th class="head"><p>DUSt3R ä¼˜åŠ¿</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ç›¸æœºå»ºæ¨¡</p></td>
<td><p>å‡è®¾å·²çŸ¥æˆ–å…±äº«å†…å‚</p></td>
<td><p>å®Œå…¨æ— éœ€å·²çŸ¥ç›¸æœºå‚æ•°ï¼Œæ”¯æŒå¼‚æ„ç›¸æœº</p></td>
</tr>
<tr class="row-odd"><td><p>æ•°æ®çº¦æŸ</p></td>
<td><p>è¦æ±‚ç›¸é‚»è§†å›¾ã€é¡ºåºè¾“å…¥</p></td>
<td><p>æ”¯æŒéé¡ºåºã€ä»»æ„å›¾åƒå¯¹è¾“å…¥</p></td>
</tr>
<tr class="row-even"><td><p>è¡¨ç¤ºæ–¹å¼</p></td>
<td><p>éšå¼è¡¨ç¤ºéš¾æ³›åŒ–ã€ä¸å¯è§£é‡Š</p></td>
<td><p>æ˜¾å¼ç‚¹å›¾æ˜“è§£é‡Šã€æ˜“æ‰©å±•</p></td>
</tr>
<tr class="row-odd"><td><p>ä¸‹æ¸¸ä»»åŠ¡</p></td>
<td><p>éšå¼å»ºæ¨¡ç»“æœä¸é€šç”¨</p></td>
<td><p>æ˜ç¡®å‡ ä½•ç»“æ„é€‚é…å¤šä»»åŠ¡</p></td>
</tr>
<tr class="row-even"><td><p>è®­ç»ƒä¾èµ–</p></td>
<td><p>å¤šä½¿ç”¨å¤§è§„æ¨¡æ•°æ®+ç›‘ç£</p></td>
<td><p>æ”¯æŒå°‘é‡å›¾åƒï¼Œæ— éœ€ GT ç›¸æœº</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<hr class="docutils" />
<section id="appendix-d-multi-view-pose-estimation">
<h2>Appendix D. å¤šè§†è§’å§¿æ€ä¼°è®¡ï¼ˆMulti-view Pose Estimationï¼‰<a class="headerlink" href="#appendix-d-multi-view-pose-estimation" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<section id="id26">
<h3>ğŸŒŸ æ ¸å¿ƒç»“è®ºï¼š<a class="headerlink" href="#id26" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p>DUSt3R åœ¨ CO3Dv2 æ•°æ®é›†ä¸Šï¼Œå³ä¾¿åªæœ‰ 3 å¼ è¾“å…¥å›¾åƒï¼Œä¹Ÿå¤§å¹…è¶…è¿‡æ‰€æœ‰å·²æœ‰æ–¹æ³•ï¼ŒåŒ…æ‹¬å½“å‰æœ€å¼ºçš„ PoseDiffusionã€‚</p></li>
<li><p>[Fig. 9] å±•ç¤ºäº† RealEstate10K ä¸Šçš„ç¨ å¯†ç‚¹äº‘æ¢å¤æ•ˆæœï¼Œå³ä½¿é¦–å°¾å¸§è§†è§’å˜åŒ–å·¨å¤§ã€‚</p></li>
</ul>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/04/ZPAZsZ.png" /></p>
<p>Figure 9:Reconstruction example from 4 random frames of a RealEstate10K indoor sequence, after global alignment. On the left-hand side, we show the 4 input frames, and on the right-hand side the resulting point-cloud and the recovered camera intrinsics and poses.</p>
</section>
</section>
<hr class="docutils" />
<section id="appendix-e-visual-localization">
<h2>Appendix E. è§†è§‰å®šä½ï¼ˆVisual Localizationï¼‰<a class="headerlink" href="#appendix-e-visual-localization" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<section id="id27">
<h3>ğŸŒŸ æ ¸å¿ƒç»“è®ºï¼š<a class="headerlink" href="#id27" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>DUSt3R åœ¨ <strong>7-Scenes</strong> æ•°æ®é›†ï¼ˆå®¤å†…ï¼‰ä¸Šè¡¨ç°ç¨³å®šï¼Œä½†åœ¨ <strong>Cambridge-Landmarks</strong> æ•°æ®é›†ï¼ˆå®¤å¤–ï¼‰ä¸Šæ•ˆæœè¾ƒå·®ï¼ŒåŸå› æ˜¯åè€…ç‚¹äº‘ç¨€ç–ï¼Œéš¾ä»¥å¯¹é‡å»ºç»“æœåšæ¯”ä¾‹ç¼©æ”¾ã€‚</p>
</section>
<section id="id28">
<h3>ğŸ§ª å®éªŒè®¾å®šï¼š<a class="headerlink" href="#id28" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p>æ‘„åƒæœºç„¦è·æœªçŸ¥ï¼ˆRealistic settingï¼‰</p></li>
<li><p>æ–¹æ³•ï¼šä» DUSt3R è¾“å‡ºçš„ç›¸å¯¹å§¿æ€ï¼ˆRel-Poseï¼‰+ ä½¿ç”¨æ•°æ®åº“å›¾åƒ GT ç‚¹äº‘è¿›è¡Œæ¯”ä¾‹ç¼©æ”¾</p></li>
<li><p>æœ€ç»ˆä»ç¼©æ”¾åçš„ç‚¹äº‘æå–ç»å¯¹å§¿æ€</p></li>
</ul>
</section>
<section id="tab-6">
<h3>ğŸ“Š è¡¨æ ¼è§£è¯»ï¼ˆTab. 6ï¼‰ï¼š<a class="headerlink" href="#tab-6" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>æ•°æ®é›†</p></th>
<th class="head"><p>æ–¹æ³•</p></th>
<th class="head"><p>å¹³ç§»è¯¯å·®(cm) / æ—‹è½¬è¯¯å·®(Â°)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>7Scenesï¼ˆChessï¼‰</p></td>
<td><p>DUSt3Rï¼ˆscaled rel-poseï¼‰</p></td>
<td><p>5 / 1.08</p></td>
</tr>
<tr class="row-odd"><td><p>Cambridgeï¼ˆS. Facadeï¼‰</p></td>
<td><p>DUSt3Rï¼ˆscaled rel-poseï¼‰</p></td>
<td><p>64 / 0.97</p></td>
</tr>
</tbody>
</table>
<ul class="simple">
<li><p>åœ¨ 7Scenes ä¸Šå‡ ä¹éƒ½æ˜¯ 2~6cm çº§åˆ«çš„è¯¯å·®ï¼Œæ—‹è½¬ä¹Ÿåœ¨ 1Â° å·¦å³ï¼Œè¡¨ç°å¾ˆå¼ºã€‚</p></li>
<li><p>åœ¨ Cambridge ä¸Šå¹³ç§»è¯¯å·®éå¸¸å¤§ï¼ˆå‡ åcmï¼‰ï¼Œå…³é”®åŸå› æ˜¯â€œæ•°æ®åº“ç‚¹äº‘ç¨€ç–ï¼Œæ¯”ä¾‹ç¼©æ”¾ä¸å¯é â€ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="id29">
<h3>ğŸ“Œ æ€»ç»“äº®ç‚¹ï¼š<a class="headerlink" href="#id29" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>æ¨¡å—</p></th>
<th class="head"><p>ä¼˜åŠ¿</p></th>
<th class="head"><p>æŒ‘æˆ˜</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Multi-view Pose Estimation</p></td>
<td><p>æå°‘è§†å›¾ï¼ˆ3å¸§ï¼‰ä¸‹è¡¨ç°ä¼˜å¼‚ï¼Œæ³›åŒ–å¼ºï¼Œæ— éœ€ç›®æ ‡æ•°æ®é›†è®­ç»ƒ</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-odd"><td><p>Visual Localization</p></td>
<td><p>åœ¨å¯†é›† GT ç‚¹äº‘ä¸‹æœ‰è¾ƒå¥½å®šä½ç²¾åº¦</p></td>
<td><p>ç¨€ç–ç‚¹äº‘æ—¶æ¯”ä¾‹ç¼©æ”¾éš¾ä»¥ä¼°è®¡ï¼Œå½±å“å®šä½</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="appendix-f-training-details">
<h2>Appendix F. Training details<a class="headerlink" href="#appendix-f-training-details" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<section id="id30">
<h3>ä¸€ã€è®­ç»ƒæ•°æ®æ¥æºå’Œå¤„ç†<a class="headerlink" href="#id30" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>âœ… ç‚¹äº‘ï¼ˆpointmapsï¼‰çš„ç”Ÿæˆ</p>
<ul class="simple">
<li><p>å¯¹äºå›¾åƒ <span class="math notranslate nohighlight">\( I^1 \)</span> å’Œ <span class="math notranslate nohighlight">\( I^2 \)</span>ï¼ŒDUSt3R é€šè¿‡ç›¸æœºå†…å‚ <span class="math notranslate nohighlight">\( K_1, K_2 \in \mathbb{R}^{3\times3} \)</span>ã€ç›¸æœºå§¿æ€ <span class="math notranslate nohighlight">\( P_1, P_2 \in \mathbb{R}^{3\times4} \)</span> å’Œæ·±åº¦å›¾ <span class="math notranslate nohighlight">\( D_1, D_2 \in \mathbb{R}^{W\times H} \)</span> æ„å»ºå‚è€ƒå¸§ä¸‹çš„ç‚¹äº‘ï¼š</p>
<ul>
<li><p><span class="math notranslate nohighlight">\( \bar{X}^{1,1} = K_1^{-1}([U; V; 1] \cdot D_1) \)</span></p></li>
<li><p><span class="math notranslate nohighlight">\( \bar{X}^{2,1} = P_1 P_2^{-1} h(K_2^{-1}([U; V; 1] \cdot D_2)) \)</span></p></li>
<li><p>å…¶ä¸­ <span class="math notranslate nohighlight">\( U, V \in \mathbb{R}^{W \times H} \)</span> æ˜¯åƒç´ åæ ‡ç½‘æ ¼ï¼Œ<span class="math notranslate nohighlight">\( h(\cdot) \)</span> è¡¨ç¤ºé½æ¬¡åæ ‡å˜æ¢ã€‚</p></li>
</ul>
</li>
</ul>
<p>âœ… æ·±åº¦å›¾çš„æå–æ–¹å¼</p>
<ul class="simple">
<li><p>æ¯ä¸ªåƒç´ ç‚¹çš„æ·±åº¦å€¼ <span class="math notranslate nohighlight">\( D^1_{i,j} \)</span> å¯ç”±ç‚¹äº‘çš„ç¬¬ä¸‰ä¸ªåæ ‡ç»´åº¦ç›´æ¥è·å¾—ï¼š</p>
<ul>
<li><p><span class="math notranslate nohighlight">\( D^1_{i,j} = \bar{X}^{1,1}_{i,j,2} \)</span></p></li>
</ul>
</li>
<li><p>å› æ­¤ï¼Œä¸»æ–‡å’Œé™„å½•ä¸­çš„æ‰€æœ‰æ·±åº¦å›¾å‡å¯ç”±ç‚¹äº‘è¾“å‡ºçš„ç¬¬ 2 ç»´ç›´æ¥æå–ï¼ˆä¾‹å¦‚ï¼š<span class="math notranslate nohighlight">\( X^{1,1}_{:,:,2} \)</span>ï¼‰ã€‚</p></li>
</ul>
<p>âœ… è®­ç»ƒé›†æ··åˆ</p>
<ul class="simple">
<li><p>ä½¿ç”¨ 8 ä¸ªæ•°æ®é›†æ··åˆè®­ç»ƒï¼Œè¦†ç›–å„ç§åœºæ™¯ï¼ˆå®¤å†…ã€å®¤å¤–ã€çœŸå®ã€åˆæˆã€ç‰©ä½“ä¸­å¿ƒç­‰ï¼‰ï¼š</p>
<ul>
<li><p>Habitat, ARKitScenes, MegaDepth, Static Scenes 3D, Blended MVS, ScanNet++, CO3Dv2, Waymo</p></li>
<li><p>æ€»å…±æå–äº†çº¦ <strong>850 ä¸‡å¯¹å›¾åƒå¯¹</strong>ã€‚</p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="id31">
<h3>äºŒã€æ•°æ®å¢å¼ºç­–ç•¥<a class="headerlink" href="#id31" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p>æ ‡å‡†å›¾åƒå¢å¼ºï¼šéšæœºé¢œè‰²æŠ–åŠ¨ + å±…ä¸­è£å‰ªï¼ˆç„¦è·å¢å¼ºçš„ä¸€ç§å½¢å¼ï¼‰ã€‚</p></li>
<li><p>å±…ä¸­è£å‰ªç¡®ä¿ä¸»ç‚¹å§‹ç»ˆåœ¨ä¸­å¿ƒï¼Œæœ‰åŠ©äºç”Ÿæˆæ›´å¤šå˜åŒ–çš„ç„¦è·ç»„åˆã€‚</p></li>
<li><p>è®­ç»ƒæ—¶å›¾åƒå¯¹åŒå‘è¾“å…¥ï¼šå³åŒæ—¶è®­ç»ƒ <span class="math notranslate nohighlight">\( (I^1, I^2) \)</span> å’Œ <span class="math notranslate nohighlight">\( (I^2, I^1) \)</span>ï¼Œå¢å¼ºæ³›åŒ–èƒ½åŠ›ã€‚</p></li>
<li><p>æ³¨æ„ï¼šä¸¤ä¸ªæ–¹å‘çš„ token ä¸å‘ç”Ÿäº¤äº’ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="id32">
<h3>ä¸‰ã€è®­ç»ƒè¶…å‚æ•°ï¼ˆè§è¡¨ 7ï¼‰<a class="headerlink" href="#id32" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>é¡¹ç›®</p></th>
<th class="head"><p>ä½åˆ†è¾¨ç‡è®­ç»ƒ</p></th>
<th class="head"><p>é«˜åˆ†è¾¨ç‡è®­ç»ƒ</p></th>
<th class="head"><p>DPT è®­ç»ƒ</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Prediction Head</strong></p></td>
<td><p>Linear</p></td>
<td><p>Linear</p></td>
<td><p>DPT</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Optimizer</strong></p></td>
<td><p>AdamW</p></td>
<td><p>AdamW</p></td>
<td><p>AdamW</p></td>
</tr>
<tr class="row-even"><td><p><strong>å­¦ä¹ ç‡</strong></p></td>
<td><p>1e-4</p></td>
<td><p>1e-4</p></td>
<td><p>1e-4</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Weight Decay</strong></p></td>
<td><p>0.05</p></td>
<td><p>0.05</p></td>
<td><p>0.05</p></td>
</tr>
<tr class="row-even"><td><p><strong>Adam Î² å‚æ•°</strong></p></td>
<td><p>(0.9, 0.95)</p></td>
<td><p>(0.9, 0.95)</p></td>
<td><p>(0.9, 0.95)</p></td>
</tr>
<tr class="row-odd"><td><p><strong>æ¯è½®æ ·æœ¬å¯¹æ•°</strong></p></td>
<td><p>70 ä¸‡å¯¹</p></td>
<td><p>7 ä¸‡å¯¹</p></td>
<td><p>7 ä¸‡å¯¹</p></td>
</tr>
<tr class="row-even"><td><p><strong>Batch Size</strong></p></td>
<td><p>128</p></td>
<td><p>64</p></td>
<td><p>64</p></td>
</tr>
<tr class="row-odd"><td><p><strong>è®­ç»ƒè½®æ•°</strong></p></td>
<td><p>50</p></td>
<td><p>100</p></td>
<td><p>90</p></td>
</tr>
<tr class="row-even"><td><p><strong>Warmup</strong></p></td>
<td><p>10 è½®</p></td>
<td><p>20 è½®</p></td>
<td><p>15 è½®</p></td>
</tr>
<tr class="row-odd"><td><p><strong>å­¦ä¹ ç‡è°ƒåº¦å™¨</strong></p></td>
<td><p>Cosine Decay</p></td>
<td><p>Cosine Decay</p></td>
<td><p>Cosine Decay</p></td>
</tr>
<tr class="row-even"><td><p><strong>è¾“å…¥åˆ†è¾¨ç‡</strong></p></td>
<td><p>224Ã—224</p></td>
<td><p>å¤šç§ç»„åˆï¼ŒåŒ…æ‹¬ 512Ã—384, 512Ã—336, 512Ã—288, 512Ã—256, 512Ã—160 ç­‰</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</section>
</section>
</section>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="2406.09756_MASt3R.html" class="btn btn-neutral float-right" title="2406.09756_MASt3R: Grounding Image Matching in 3D with MASt3R" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="2203.08586_VanishingPointEstimation.html" class="btn btn-neutral" title="2203.08586: Deep vanishing point detection: Geometric priors make dataset variations vanish" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>
  
  <div id="gitalk-container"></div>
  <div role="contentinfo">
    <p>
        &copy; Copyright 2010-2025, æ–°æºª-gordon.

    </p>
  </div>
  <div>å¤‡æ¡ˆå· <a href="http://www.beian.miit.gov.cn">äº¬ICPå¤‡16018553å·</a></div><div>Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a></div>. 


</footer>

<script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?042289284b8eb33866001347a3e0b129";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
</script>     
        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'V2025.07',
            LANGUAGE:'zh-CN',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="../../_static/sphinx_highlight.js"></script>
      <script type="text/javascript" src="../../_static/clipboard.min.js"></script>
      <script type="text/javascript" src="../../_static/copybutton.js"></script>
      <script type="text/javascript" src="../../_static/translations.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script type="text/javascript" src="../../None"></script>
      <script type="text/javascript" src="https://fastly.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  

  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });


      // var gitalk = new Gitalk({
      //         clientID: '565177626b5d46427009',
      //         clientSecret: 'b2a36e67e1d2a73e43667f46d571c2624f8e1026',
      //         repo: 'knowledge',
      //         owner: 'zhaoweiguo',
      //         admin: ['zhaoweiguo'],
      //         id: location.pathname,      // Ensure uniqueness and length less than 50
      //         distractionFreeMode: false  // Facebook-like distraction free mode
      //       })
      // gitalk.render('gitalk-container')

  </script>


<script type="text/javascript" src="../../_static/js/table-of-contents-sidebar.js"></script>
<!-- <script type="text/javascript" src="https://table-of-contents-sidebar.github.io/table-of-contents-sidebar-lib/table-of-contents-sidebar.js"></script> -->
<script type="text/javascript">
    window.onload = function(e){
        TableOfContents.init({
            basePath: "https://table-of-contents-sidebar.github.io/table-of-contents-sidebar-lib/",
            querySelector: "body" // or other css querySelector
        });
    }
</script> 

</body>
</html>