

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="zh-CN" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="zh-CN" > <!--<![endif]-->
<head>


<!-- start added 2025-04-14   å¢åŠ å¯¹markdownä¸­å…¬å¼çš„æ”¯æŒ -->
<script>
window.MathJax = {
    tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true
    },
    options: {
        ignoreHtmlClass: "tex2jax_ignore|mathjax_ignore",
        processHtmlClass: "tex2jax_process|mathjax_process|math|output_area"
    }
};
</script>
<script defer="defer" src="https://fastly.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<!-- end added 2025-04-14   å¢åŠ å¯¹markdownä¸­å…¬å¼çš„æ”¯æŒ -->


<!-- start added 2025-08-06   å¢åŠ å¯¹mermaidå›¾çš„æ”¯æŒ -->
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', function() {
    mermaid.initialize({
        startOnLoad: true,
        theme: 'default',
        flowchart: { useMaxWidth: true }
    });
});
</script>
<!--  end added 2025-08-06   å¢åŠ å¯¹mermaidå›¾çš„æ”¯æŒ -->




  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>2406.09756_MASt3R: Grounding Image Matching in 3D with MASt3R &mdash; æ–°æºª-gordon V2025.09 æ–‡æ¡£</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
    <link rel="index" title="ç´¢å¼•" href="../../genindex.html" />
    <link rel="search" title="æœç´¢" href="../../search.html" />
    <link rel="next" title="2412.09401_SLAM3R: Real-Time Dense Scene Reconstruction from Monocular RGB Videos" href="2412.09401_SLAM3R.html" />
    <link rel="prev" title="2312.14132_DUSt3R: Geometric 3D Vision Made Easy" href="2312.14132_DUSt3R.html" /> 

  
  <script src="../../_static/js/modernizr.min.js"></script>
  <script src="../../_static/js/jquery.min.js"></script>


<!-- è¯„è®ºæ’ä»¶ gittalk start -->
<!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script> -->
<!-- è¯„è®ºæ’ä»¶ gittalk end -->


</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> æ–°æºª-gordon
          

          
          </a>

          
            
            
              <div class="version">
                V2025.09
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../Overview.html">ç»¼è¿°è®ºæ–‡</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Overview.html#id3">è¿‘é‚»æœç´¢</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Overviews/2508.09834_Overview_LLM.html">2508.09834â‡ï¸_Overview_LLM: Speed Always Wins: A Survey on Efficient Architectures for Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Overviews/2508.09834_Overview_LLM.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Overviews/2508.09834_Overview_LLM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Overviews/2508.09834_Overview_LLM.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Overviews/2508.09834_Overview_LLM.html#linear-sequence-modeling">2 Linear Sequence Modeling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Overviews/2508.09834_Overview_LLM.html#sparse-sequence-modeling">3 Sparse Sequence Modeling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Overviews/2508.09834_Overview_LLM.html#efficient-full-attention">4 Efficient Full Attention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Overviews/2508.09834_Overview_LLM.html#sparse-mixture-of-experts">5 Sparse Mixture-of-Experts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Overviews/2508.09834_Overview_LLM.html#hybrid-architectures">6 Hybrid Architectures</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Overviews/2508.09834_Overview_LLM.html#diffusion-large-language-models">7 Diffusion Large Language Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Overviews/2508.09834_Overview_LLM.html#applications-to-other-modalities">8 Applications to Other Modalities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Overviews/2508.09834_Overview_LLM.html#conclusion-and-future-directions">9 Conclusion and Future Directions</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../Benchmarking.html">è¯„æµ‹åŸºå‡†</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#id3">è¯„æµ‹åŸºå‡†</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html">02xx.xxxxx_BLEU: a Method for Automatic Evaluation of Machine Translation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html#id8">ç¤ºä¾‹è®²è§£</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html#the-baseline-bleu-metric">2.The Baseline BLEU Metric</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html#the-bleu-evaluation">3.The BLEU Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html#the-human-evaluation">4.The Human Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html#bleu-vs-the-human-evaluation">5.BLEU vs The Human Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html#conclusion">6.Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html">0401.xxxxx_ROUGE: A Package for Automatic Evaluation of Summaries</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html#rouge-n-n-gram-co-occurrence-statistics">2.ROUGE-N: N-gram Co-Occurrence Statistics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html#rouge-l-longest-common-subsequence">3.ROUGE-L: Longest Common Subsequence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html#rouge-w-weighted-longest-common-subsequence">4 ROUGE-W: Weighted Longest Common Subsequence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html#rouge-s-skip-bigram-co-occurrence-statistics">5.ROUGE-S: Skip-Bigram Co-Occurrence Statistics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html#evaluations-of-rouge">6 Evaluations of ROUGE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html#conclusions">7 Conclusions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html">é€šç”¨</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html#id2">è¯„æµ‹æ ‡å‡†</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html#accuracy">å‡†ç¡®ç‡(Accuracy)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html#precision">ç²¾ç¡®ç‡(Precision, ç²¾å‡†ç‡)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html#recall">å¬å›ç‡(Recall)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html#f1-score">F1 Score</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html#id3">å¯è§†åŒ–ç²¾åº¦å’Œå¬å›ç‡</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html#recall-k">Recall&#64;k</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html#precision-k">Precision&#64;k</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html#hr-k">HR&#64;k</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html#ndcg-k">NDCG&#64;k</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html#mrr-k">MRR&#64;k</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html#map-k">MAP&#64;k</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html#auc-area-under-the-roc-curve">AUC (Area Under the ROC Curve)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html#logloss-logarithmic-loss">LogLoss(Logarithmic Loss)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Standards/1803.01937_ROUGE2.html">1803.01937_ROUGE2.0: Updated and Improved Measures for Evaluation of Summarization Tasks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1803.01937_ROUGE2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1803.01937_ROUGE2.html#problems-with-the-current-rouge-measures">1. Problems with the current ROUGE measures</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1803.01937_ROUGE2.html#rouge-2-0">2. ROUGE 2.0</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Standards/1804.08771_SacreBLEU.html">1804.08771_SacreBLEU: A Call for Clarity in Reporting BLEU Scores</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1804.08771_SacreBLEU.html#bleu">BLEU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1804.08771_SacreBLEU.html#id3">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1804.08771_SacreBLEU.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1804.08771_SacreBLEU.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1804.08771_SacreBLEU.html#problem-description">2 Problem Description</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1804.08771_SacreBLEU.html#a-way-forward">3 A way forward</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1804.08771_SacreBLEU.html#summary">4 Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html">2303.08896_SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#background-and-related-work">2 Background and Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#grey-box-factuality-assessment">3 Grey-Box Factuality Assessment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#black-box-factuality-assessment">4 Black-Box Factuality Assessment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#selfcheckgpt">5 SelfCheckGPT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#data-and-annotation">6 Data and Annotation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#experiments">7 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#conclusions">8 Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#limitations">Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#ethics-statement">Ethics Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#acknowledgments">Acknowledgments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#appendix-a-models-and-implementation">Appendix A Models and Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#appendix-b-selfcheckgpt-with-qa">Appendix B SelfCheckGPT with QA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#appendix-c-selfcheckgpt-with-prompt">Appendix C SelfCheckGPT with Prompt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#appendix-d-additional-experimental-results">Appendix D Additional Experimental Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html">2306.05685_Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#mt-bench-and-chatbot-arena">2 MT-Bench and Chatbot Arena</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#llm-as-a-judge">3 LLM as a Judge</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#agreement-evaluation">4 Agreement Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#human-preference-benchmark-and-standardized-benchmark">5 Human Preference Benchmark and Standardized Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#discussion">6 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#appendix-a-prompt-templates">Appendix A Prompt templates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#appendix-b-case-study">Appendix B Case Study</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#appendix-c-data-collection">Appendix C Data Collection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#appendix-d-additional-experimental-results">Appendix D Additional Experimental Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#appendix-e-training-details-of-vicuna-models">Appendix E Training Details of Vicuna Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#appendix-f-exploring-vicuna-as-a-judge">Appendix F Exploring Vicuna as a judge</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html">2403.04132_Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#id12">2 ç›¸å…³å·¥ä½œï¼ˆRelated Workï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#human-preference-data-collection">3 Human Preference Data Collection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#id13">3 äººç±»åå¥½æ•°æ®æ”¶é›†</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#from-pairwise-comparisons-to-rankings">4 From Pairwise Comparisons to Rankings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#efficient-approximate-ranking">5 Efficient Approximate Ranking</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#data-analysis">6 Data Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#experiments">7 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#id25">7 å®éªŒ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#discussion">8 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#id32">8 è®¨è®º</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#conclusion">9 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#id33">9 ç»“è®º</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#acknowledgments">Acknowledgments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#id34">è‡´è°¢</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#appendix-a-confidence-interval-simulation-study">Appendix A Confidence Interval Simulation Study</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#a">é™„å½• A ç½®ä¿¡åŒºé—´æ¨¡æ‹Ÿç ”ç©¶</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#appendix-b-the-nonparametric-bradley-terry-model">Appendix B The Nonparametric Bradley-Terry Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#b-bradley-terry">é™„å½• Bï¼šéå‚æ•° Bradley-Terry æ¨¡å‹</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#appendix-c-valid-p-value">Appendix C Valid P-Value</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#p">1. på€¼çš„å®šä¹‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#id42">2. på€¼çš„ç­‰ä»·è¡¨è¾¾å¼</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#id43">3. æœ‰æ•ˆæ€§è¯æ˜çš„å…³é”®æ­¥éª¤</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#id46">4. è¯æ˜ç»“è®º</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#id47">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#appendix-d-sample-prompts">Appendix D Sample Prompts</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Standards/2404.04475_AlpacaEval2.0.html">2404.04475_AlpacaEval LC: A Simple Way to Debias Automatic Evaluators</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2404.04475_AlpacaEval2.0.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2404.04475_AlpacaEval2.0.html#from-deepseek">From Deepseek</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2404.04475_AlpacaEval2.0.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2404.04475_AlpacaEval2.0.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2404.04475_AlpacaEval2.0.html#background-and-problem-setting">2 Background and Problem Setting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2404.04475_AlpacaEval2.0.html#length-controlled-alpacaeval">3 Length-Controlled AlpacaEval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2404.04475_AlpacaEval2.0.html#results">4 Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2404.04475_AlpacaEval2.0.html#discussion">5 Discussion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#agent">æ•°æ®é›†-Agent</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2308.03688_AgentBench.html">2308.03688_AgentBench: Evaluating LLMs as Agents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2308.03688_AgentBench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2308.03688_AgentBench.html#from-deepseek">From Deepseek</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2308.03688_AgentBench.html#id7">æ•°æ®é›†ç¤ºä¾‹</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html">2312.14033_T-Eval: Evaluating the Tool Utilization Capability of Large Language Models Step by Step</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#t-eval">2 T-Eval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#experiments">3 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#discussion">4 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#related-work">5 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#appendix-a-t-eval-benchmark-details">Appendix A T-EvalÂ Benchmark Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#appendix-b-implementation-details">Appendix B Implementation Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#appendix-c-detailed-evaluation-metrics">Appendix C Detailed Evaluation Metrics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#appendix-d-api-documentation">Appendix D API Documentation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2406.12045_%CF%84-bench.html">2406.12045_Ï„-bench: A Benchmark for Tool-Agent-User</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2406.12045_%CF%84-bench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2406.12045_%CF%84-bench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2406.12045_%CF%84-bench.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2406.12045_%CF%84-bench.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2406.12045_%CF%84-bench.html#bench-a-benchmark-for-t-ool-a-gent-u-ser-interaction">3.Ï„-bench: A benchmark for T ool-A gent-U ser Interaction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2406.12045_%CF%84-bench.html#benchmark-construction">4. Benchmark Construction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2406.12045_%CF%84-bench.html#experiments">5.Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2406.12045_%CF%84-bench.html#disscussion">6.Disscussion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html">2506.07982_ğœÂ²-Bench: Evaluating Conversational Agents in a Dual-Control Environment</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#tau-2-bench-evaluating-agents-in-a-dual-control-environment">3 <span class="math notranslate nohighlight">\(\tau^{2}\)</span>-bench: Evaluating Agents in a Dual-Control Environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#broader-impact">Broader Impact</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#appendix-a-telecom-domain">Appendix A Telecom Domain</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#appendix-b-verifying-original-tau-2-bench">Appendix B Verifying Original <span class="math notranslate nohighlight">\(\tau^{2}\)</span>-bench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#appendix-c-prompts">Appendix C Prompts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#appendix-d-domain-policies">Appendix D Domain Policies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#appendix-e-user-simulator-quality">Appendix E User Simulator Quality</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#qa">æ•°æ®é›†-QA</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html">2109.07958_TruthfulQA: Measuring How Models Mimic Human Falsehoods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#the-truthfulqa-benchmark">2 The TruthfulQA Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#experiments">3 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#results">4 Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#discussion">5 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#related-work">6 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#ethics-and-impact">8 Ethics and Impact</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#appendix-a-additional-examples-from-truthfulqa">Appendix A Additional examples from TruthfulQA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#appendix-b-additional-results">Appendix B Additional results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#appendix-c-dataset-construction">Appendix C Dataset construction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#appendix-d-human-evaluations">Appendix D Human evaluations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#appendix-e-prompts">Appendix E Prompts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#appendix-f-checking-for-data-quality-and-disagreement">Appendix F Checking for data quality and disagreement</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html">2311.12022_GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html#data-collection">2.Data Collection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html#dataset-analysis">3.Dataset Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html#baseline">4.Baseline</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html#related-work">5.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html#limitations">6.Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html#conclusion">7.Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2411.04368_SimpleQA.html">2411.04368_SimpleQA: Measuring short-form factuality in large language models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2411.04368_SimpleQA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2411.04368_SimpleQA.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2411.04368_SimpleQA.html#data-collection-and-verification">2.Data Collection and Verification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2411.04368_SimpleQA.html#measuring-calibration">4.Measuring calibration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2411.04368_SimpleQA.html#appendix-b-guessing-strategy-and-f-score">Appendix B Guessing strategy and F-score</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#id4">æ•°æ®é›†-é•¿æ–‡æœ¬</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2308.14508_LongBench.html">2308.14508_LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2308.14508_LongBench.html#from-deepseek">From Deepseek</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html">2402.05136_LV-Eval: A Balanced Long-Context Benchmark with 5 Length Levels Up to 256K</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html#lv-eval-benchmark">3 LV-Eval Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html#evaluation">4 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html#appendix-c-detailed-evaluation-results">Appendix C Detailed Evaluation Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html#appendix-d-detailed-ablation-results">Appendix D Detailed Ablation Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html">2404.06654_RULER: Whatâ€™s the Real Context Size of Your Long-Context Language Models?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#the-ruler-benchmark">3 The RulerÂ Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#experiments-results">4 Experiments &amp; Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#task-error-analysis">5 Task Error Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#model-analysis">6 Model Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#limitations">8 Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#appendix-a-models">Appendix A Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#appendix-b-task-configurations">Appendix B Task Configurations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#appendix-c-task-correlation-analysis">Appendix C Task Correlation Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#appendix-d-prompt-templates">Appendix D Prompt Templates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#appendix-e-passkey-retrieval-and-vanilla-niah-results">Appendix E Passkey Retrieval and Vanilla NIAH Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#appendix-f-additional-results">Appendix F Additional Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html">2407.11963_NeedleBench: Can LLMs Do Retrieval and Reasoning in Information-Dense Context</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#tasks-and-datasets">3 Tasks and Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#impact-of-language-which-model-performs-better-under-the-bilingual-scenario">4.1.5 Impact of Language_ Which Model Performs Better under the Bilingual Scenario_</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#conclusion-and-future-work">5 Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#appendix-a-evaluated-models">Appendix A Evaluated Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#appendix-b-needlebench-prompt-examples">Appendix B NeedleBenchÂ Prompt Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#appendix-c-error-analysis-examples">Appendix C Error Analysis Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#rag">æ•°æ®é›†-RAG</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/1809.09600_HotpotQA.html">1809.09600_HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/1809.09600_HotpotQA.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/1809.09600_HotpotQA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/1809.09600_HotpotQA.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/1809.09600_HotpotQA.html#data-collection">2 Data Collection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/1809.09600_HotpotQA.html#processing-and-benchmark-settings">3 Processing and Benchmark Settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/1809.09600_HotpotQA.html#dataset-analysis">4 Dataset Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/1809.09600_HotpotQA.html#experiments">5 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/1809.09600_HotpotQA.html#related-work">6 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/1809.09600_HotpotQA.html#conclusions">7 Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/1809.09600_HotpotQA.html#appendix-a-data-collection-details">Appendix A Data Collection Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/1809.09600_HotpotQA.html#a">é™„å½•A æ•°æ®æ”¶é›†ç»†èŠ‚</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/1809.09600_HotpotQA.html#appendix-b-further-data-analysis">Appendix B Further Data Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/1809.09600_HotpotQA.html#appendix-c-full-wiki-setting-details">Appendix C Full Wiki Setting Details</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/2401.15391_MultiHop-RAG.html">2401.15391_MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/2401.15391_MultiHop-RAG.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/2401.15391_MultiHop-RAG.html#llm">LLMæ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/2401.15391_MultiHop-RAG.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/2401.15391_MultiHop-RAG.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/2401.15391_MultiHop-RAG.html#rag-with-multi-hop-queries">2 RAG with multi-Hop queries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/2401.15391_MultiHop-RAG.html#a-benchmarking-dataset-multihop-rag">3 A Benchmarking Dataset: MultiHop-RAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/2401.15391_MultiHop-RAG.html#benchmarking-rag-system-using-multihop-rag">4 Benchmarking RAG system using MultiHop-RAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/2401.15391_MultiHop-RAG.html#related-work">5 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/2401.15391_MultiHop-RAG.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/2401.15391_MultiHop-RAG.html#limitations">Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/2401.15391_MultiHop-RAG.html#appendix-a-appendix-a-gpt-4-prompts-used-for-data-generation">Appendix A Appendix A: GPT-4 Prompts Used for Data Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/2401.15391_MultiHop-RAG.html#appendix-b-dataset-examples">Appendix B: Dataset Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#id5">æ•°æ®é›†-å›¾</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html">2402.07630_G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#id2">ç¤ºä¾‹è®²è§£</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#formalization">3 Formalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#proposed-graphqa-benchmark">4 Proposed GraphQA Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#id12">5 G-Retriever</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#experiments">6 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#acknowledgment">Acknowledgment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#appendix-a-impact-statements">Appendix A Impact Statements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#appendix-b-experiment">Appendix B Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#appendix-c-graphqa-benchmark">Appendix C GraphQA Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#appendix-d-graph-retrieval-augmented-generation-graphrag">Appendix D Graph Retrieval-Augmented Generation (GraphRAG)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#appendix-e-discussion-on-the-complexity">Appendix E Discussion on the Complexity</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#e"><strong>é™„å½•E å¤æ‚æ€§è®¨è®ºæ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#appendix-f-hallucination-in-graph-llms">Appendix F Hallucination in Graph LLMs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#appendix-g-demonstrations">Appendix G Demonstrations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#id6">æ•°æ®é›†-ç¼–ç¨‹</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html">2107.03374_HumanEval: Evaluating Large Language Models Trained on Code</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#evaluation-framework">2.Evaluation Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#code-fine-tuning">3.Code Fine-Tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#supervised-fine-tuning">4.Supervised Fine-Tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#docstring-generation">5.Docstring Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#limitations">6.Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#broader-impacts-and-hazard-analysis">7.Broader Impacts and Hazard Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#related-work">8.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#conclusions">9.Conclusions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html">2108.07732_MBPP: Program Synthesis with Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#datasets">2 Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#model-and-methods">3 Model and Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#mbpp-synthesis-results">4 MBPP Synthesis Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#human-model-collaboration-results">5 Human-Model Collaboration Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#program-execution-results">6 Program Execution Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#mathqa-results">7 MathQA Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#related-work">8 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#risks-and-limitations">9 Risks and Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#conclusion">10 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#appendix-a-appendix">Appendix A Appendix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html">2310.06770_SWE-bench: Can Language Models Resolve Real-World GitHub Issues?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#id7">2 SWE-bench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#swe-llama-fine-tuning-codellama-for-swe-bench">3 SWE-Llama: Fine-tuning CodeLlama for SWE-bench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#experimental-setup">4 Experimental Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#results">5 Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#related-work">6 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#discussion">7 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#ethics-statement">8 Ethics Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#reproducibility-statement">9 Reproducibility Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#appendix-a-benchmark-details">Appendix A Benchmark Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#appendix-b-additional-details-on-training-swe-llama">Appendix B Additional Details on Training SWE-Llama</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#appendix-c-additional-results">Appendix C Additional Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#appendix-d-additional-experimental-details">Appendix D Additional Experimental Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#appendix-e-societal-impact">Appendix E Societal Impact</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#appendix-f-in-depth-analysis-of-swe-llama-generations">Appendix F In-depth Analysis of SWE-Llama Generations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html">2402.16694_HumanEval-XL: A Multilingual Code Generation Benchmark for Cross-lingual Natural Language Generalization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#a-multilingual-code-generation-benchmark-for-cross-lingual-natural-language-generalization">A Multilingual Code Generation Benchmark for Cross-lingual Natural Language Generalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#introduction">1.Â Â Â Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#related-work">2.Â Â Â Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#humaneval-xl">3.Â Â Â HumanEval-XL</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#experiments">4.Â Â Â Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#conclusion">5.Â Â Â Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#acknowledgments">Acknowledgments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#appendix-a-experiment-settings">Appendix A Experiment Settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#appendix-b-comprehensive-experiment-results">Appendix B Comprehensive Experiment Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html">2403.07974_LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#llm">LLMæ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#holistic-evaluation">2 Holistic Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#benchmark-curation">3 Benchmark Curation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#experiment-setup">4 Experiment Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#results">5 Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#related-work">6 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#limitations">7 Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#conclusion">8 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#appendix-a-dataset">Appendix A Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#appendix-b-ui">Appendix B UI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#appendix-c-experimental-setup">Appendix C Experimental Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#appendix-d-results">Appendix D Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#appendix-e-qualitative-examples">Appendix E Qualitative Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html">2407.10499_CIBench: Evaluating Your LLMs with a Code Interpreter Plugin</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#related-works">2 Related Works</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#cibench">3 CIBench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#appendix-a-dataset-details">Appendix A Dataset Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#appendix-b-construction-prompts-and-rules">Appendix B Construction Prompts and Rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#appendix-c-experiment-example-demo">Appendix C Experiment Example Demo</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#appendix-d-subjective-visualization-evaluation">Appendix D Subjective Visualization Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#appendix-e-dataset-error-analysis">Appendix E Dataset Error Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#appendix-f-human-annotator">Appendix F Human Annotator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#appendix-g-ethical-consideration">Appendix G Ethical Consideration</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html">2410.03859_SWE-bench-Multimodal: Do AI Systems Generalize to Visual Software Domains?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#swe-bench-multimodal">2 SWE-bench Multimodal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#evaluating-on-swe-bench-m">3 Evaluating on SWE-bench M</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#results">4 Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#related-work">5 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#appendix-a-dataset">Appendix A Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#appendix-b-collection">Appendix B Collection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#appendix-c-experiments">Appendix C Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#appendix-d-human-validation">Appendix D Human Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#appendix-e-limitations">Appendix E Limitations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html">2410.06992_SWE-Bench+: Enhanced Coding Benchmark for LLMs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html#robustness-analysis-of-swe-bench">2 Robustness Analysis of SWE-Bench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html#building-swe-bench">3 Building SWE-Bench+</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html#robustness-of-swe-bench">4 Robustness of SWE-Bench+</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html#effectiveness-aware-evaluation">5 Effectiveness-aware Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html#related-work">6 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html#conclusion">7 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html">2501.01257_CodeForces: Benchmarking Competition-level Code Generation of LLMs on CodeForces</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#codeforces-benchmark">3 CodeForces Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#evaluation-on-existing-llms">4 Evaluation on Existing LLMs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#analysis-experiments">5 Analysis Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#discussion">6 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#ethical-statement">8 Ethical Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#appendix-a-model-cards">Appendix A Model Cards</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#appendix-b-decoding-hyperparameters">Appendix B Decoding Hyperparameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#appendix-c-analysis-of-our-elo-rating-calculation-system">Appendix C Analysis of Our Elo Rating Calculation System</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#appendix-d-human-comparable-elo-rating">Appendix D Human-comparable Elo Rating</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#appendix-e-problem-demonstration">Appendix E Problem Demonstration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#appendix-f-special-judge">Appendix F Special Judge</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#id7">æ•°æ®é›†-æ•°å­¦</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2103.03874_MATH.html">2103.03874_MATH: Measuring Mathematical Problem Solving With the MATH Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html">2110.14168_GSM8K: Training Verifiers to Solve Math Word Problems</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#dataset">2 Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#related-work">3 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#methods">4 Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#additional-experiments">5 Additional Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#appendix-a-dataset-details">Appendix A Dataset Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#appendix-b-hyperparameters">Appendix B Hyperparameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#appendix-c-calculator-annotations">Appendix C Calculator Annotations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#appendix-d-example-model-solutions">Appendix D Example Model Solutions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#appendix-e-verifier-details">Appendix E Verifier Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#appendix-f-verifier-visualization">Appendix F Verifier Visualization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html">2405.12209_MathBench: Evaluating the Theory and Application Proficiency of LLMs with a Hierarchical Mathematics Benchmark</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#methodology">2 Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#experiments-and-analysis">3 Experiments and Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#discussion">4 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#related-work">5 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#limitations">7 Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#ethical-considerations">8 Ethical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#appendix-a-mathbench-statistics">Appendix A MathBench Statistics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#appendix-b-detailed-experimental-results">Appendix B Detailed Experimental Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#appendix-c-extra-analysis">Appendix C Extra Analysis</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#id8">æ•°æ®é›†-å›¾ç‰‡</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Images/2306.13394_MME.html">2306.13394_MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2306.13394_MME.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2306.13394_MME.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2306.13394_MME.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2306.13394_MME.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2306.13394_MME.html#mme-evaluation-suite">2 MME Evaluation Suite</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2306.13394_MME.html#experiments">3 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2306.13394_MME.html#analysis">4 Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2306.13394_MME.html#conclusion">5 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html">2307.06281_MMBench: Is Your Multi-modal Model an All-around Player?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#the-construction-of-mmbench">3 The construction of MMBench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#evaluation-strategy">4 Evaluation Strategy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#evaluation-results">5 Evaluation Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#appendix-a-more-details-about-the-data">Appendix A More Details about the Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#appendix-b-more-details-on-mmbench-construction">Appendix B More Details on MMBench Construction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#appendix-c-more-details-on-llm-based-choice-extraction">Appendix C More Details on LLM-based Choice Extraction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#appendix-d-evaluation-settings-and-results">Appendix D Evaluation Settings and Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.16125_SEED-Bench.html">2307.16125_SEED-Bench: Benchmarking Multimodal LLMs with Generative Comprehension</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.16125_SEED-Bench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.16125_SEED-Bench.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.16125_SEED-Bench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.16125_SEED-Bench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.16125_SEED-Bench.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.16125_SEED-Bench.html#id7">3 SEED-Bench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.16125_SEED-Bench.html#evaluation-results">4 Evaluation Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.16125_SEED-Bench.html#conclusion">5 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html">2311.12793_ShareGPT4V: Improving Large Multi-Modal Models with Better Captions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#sharegpt4v-dataset">3 ShareGPT4V Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#sharegpt4v-7b-model">4 ShareGPT4V-7B Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#id11"><strong>4.1 æ¨¡å‹æ¶æ„</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#id12"><strong>4.2 é¢„è®­ç»ƒ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#sft"><strong>4.3 ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#id13"><strong>æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#experiments">5 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#appendix-a-data-sources">Appendix A Data Sources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#appendix-b-caption-analysis">Appendix B Caption Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#appendix-c-prompts">Appendix C Prompts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#appendix-d-examples">Appendix D Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html">2506.18095_ShareGPT-4o-Image: Aligning Multimodal Models with GPT-4o-Level Image Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#sharegpt-4o-image">2 ShareGPT-4o-Image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#janus-4o-fine-tuning-with-sharegpt-4o-image">3 Janus-4o: Fine-Tuning with ShareGPT-4o-Image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#conclusion">5 conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#appendix-a-related-work">Appendix A Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#appendix-b-image-generation-categories">Appendix B Image Generation Categories</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#appendix-c-prompts-for-generation">Appendix C Prompts for Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#appendix-d-document-pipeline">Appendix D Document Pipeline</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#appendix-e-ethical-considerations-and-societal-impact">Appendix E Ethical Considerations and Societal Impact</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#id9">æ•°æ®é›†</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html">1804.07461_GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#id7">2 ç›¸å…³å·¥ä½œæ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#tasks">3 Tasks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#single-sentence-tasks">3.1 Single-Sentence Tasks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#similarity-and-paraphrase-tasks">3.2 Similarity and Paraphrase Tasks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#inference-tasks">3.3 Inference Tasks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#evaluation">3.4 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#diagnostic-dataset">4 Diagnostic Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#id9">4 è¯Šæ–­æ•°æ®é›†ï¼ˆDiagnostic Datasetï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#baselines">5 Baselines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#id14">5 Baselines æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#benchmark-results">6 Benchmark Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#id16">6 Benchmark Resultsï¼ˆåŸºå‡†æµ‹è¯•ç»“æœï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#analysis">7 Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#conclusion">8 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#id22">8 ç»“è®º</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#acknowledgments">Acknowledgments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#id23">è‡´è°¢</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#appendix-a-additional-benchmark-details">Appendix A Additional Benchmark Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#appendix-a-additional-benchmark-details-a">Appendix A Additional Benchmark Detailsï¼ˆé™„å½•Aï¼šæ›´å¤šåŸºå‡†ç»†èŠ‚ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#appendix-b-additional-baseline-details">Appendix B Additional Baseline Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#appendix-b-additional-baseline-details-b">Appendix B Additional Baseline Detailsï¼ˆé™„å½•B å…¶ä»–åŸºçº¿ç»†èŠ‚ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#appendix-c-development-set-results">Appendix C Development Set Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#id25">Appendix C Development Set Results æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#appendix-d-benchmark-website-details">Appendix D Benchmark Website Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#appendix-d-benchmark-website-details-d">Appendix D Benchmark Website Detailsï¼ˆé™„å½• D åŸºå‡†ç½‘ç«™è¯¦æƒ…ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#appendix-e-additional-diagnostic-data-details">Appendix E Additional Diagnostic Data Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#e"><strong>é™„å½• Eï¼šé¢å¤–çš„è¯Šæ–­æ•°æ®ç»†èŠ‚</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#id31"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Datasets/2009.03300_MMLU.html">2009.03300_MMLU: Measuring Massive Multitask Language Understanding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2009.03300_MMLU.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2009.03300_MMLU.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2009.03300_MMLU.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2009.03300_MMLU.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2009.03300_MMLU.html#a-multitask-test">3.A Multitask Test</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2009.03300_MMLU.html#experiments">4.Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2009.03300_MMLU.html#discussion">5.Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2009.03300_MMLU.html#conclusion">6.Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html">2305.08322_C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#id2">C-Eval_ A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#the-c-eval-evaluation-suite">2 The C-EvalÂ Evaluation Suite</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#experiment">3 Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#related-work">4 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#discussion">5 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#acknowledgement">Acknowledgement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#appendix-a-author-contributions">Appendix A Author Contributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#appendix-b-detailed-stats-of-c-eval">Appendix B Detailed Stats of C-Eval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#appendix-c-explanation-data-generation">Appendix C Explanation Data Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#appendix-d-evaluation-prompts">Appendix D Evaluation Prompts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#appendix-e-details-of-the-models-being-evaluated">Appendix E Details of the models being evaluated</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#appendix-f-breakdown-of-model-performance">Appendix F Breakdown of Model Performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#appendix-g-option-bias">Appendix G Option Bias</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#appendix-h-compute-and-resources-used-for-evaluation">Appendix H Compute and Resources Used for Evaluation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html">2306.09212_CMMLU: Measuring massive multitask language understanding in Chinese</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#cmmlu">3 CMMLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#impact-of-model-size-on-performance">Impact of model size on performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-a-comparison-to-concurrent-benchmarks">Appendix A Comparison to concurrent benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-b-cmmlu-subjects">Appendix B CMMLU Subjects</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-c-cmmlu-examples">Appendix C CMMLU Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-d-cmmlu-difficulty-distribution">Appendix D CMMLU Difficulty Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-e-emergent-ability-shown-in-cmmlu-subjects">Appendix E Emergent Ability shown in CMMLU subjects</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-f-models-being-evaluated">Appendix F Models being Evaluated</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-g-strategies-for-estimating-model-choices">Appendix G Strategies for Estimating Model Choices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-h-regular-expressions-matching-algorithmsl">Appendix H Regular expressions matching algorithmsl</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-i-correlation-to-other-benchmarks">Appendix I Correlation to other Benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-j-breakdown-of-model-performance">Appendix J Breakdown of Model Performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#j-3-the-effect-of-chain-of-thought-prompt">J.3 The effect of chain-of-thought prompt</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html">2307.15020_SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#superclue-benchmark">3 SuperCLUE Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#additional-analysis">5 Additional Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#appendix-a-evaluation-process">Appendix A Evaluation Process</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#appendix-b-capability-categories">Appendix B Capability Categories</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html">2311.12983_GAIA: a benchmark for General AI Assistants</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#related-work">2.Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#id4">3.GAIA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#llms-results-on-gaia">4.LLMs results on GAIA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#discussion">5.Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#limitations">6.Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#appendix-a-extended-related-work">Appendix A Extended related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#appendix-c-extended-description-of-gaia">Appendix C Extended description of GAIA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#appendix-d-extended-description-of-our-question-design-framework">Appendix D Extended description of our question design framework</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.18743_AlignBench.html">2311.18743_AlignBench: Benchmarking Chinese Alignment of Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.18743_AlignBench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.18743_AlignBench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.18743_AlignBench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.18743_AlignBench.html#dataset">2 Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.18743_AlignBench.html#methods">3 Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.18743_AlignBench.html#human-evaluation-on-alignbench">4 Human Evaluation on AlignBench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.18743_AlignBench.html#alignbench-benchmarking-results">5 AlignBench: Benchmarking Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.18743_AlignBench.html#related-work">6 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.18743_AlignBench.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.18743_AlignBench.html#appendix-a-appendix">Appendix A Appendix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html">2404.07972_OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#id2">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#osworld-environment">2. OSWORLD Environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#osworld-benchmark">3. OSWORLD Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#benchmarking-llm-and-vlm-agent-baselines">4. Benchmarking LLM and VLM Agent Baselines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#analysis">5. Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#related-work">6. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#conclusion-and-future-work">7. Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#a-details-of-osworld-environment">A. Details of OSWORLD Environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#c-details-of-baseline-methods">C. Details of Baseline Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#d-examples-of-qualitative-analysis">D. Examples of Qualitative Analysis</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html">2406.04770_WildBench: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html#wildbench-data-curation">2 WildBench Data Curation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html#automatic-evaluation-with-wildbench">3 Automatic Evaluation with WildBench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html#results-analysis">4 Results &amp; Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html#related-works">5 Related Works</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html#conclusion-and-future-directions">6 Conclusion and Future Directions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html#appendix-a-task-categories">Appendix A Task Categories</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html#appendix-b-more-information-on-wildbench-data">Appendix B More Information on WildBench Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html#appendix-c-more-information-on-wildbench-evaluation">Appendix C More Information on WildBench Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html#appendix-d-prompt-template-for-pairwise-evaluation-metric-wb-reward">Appendix D Prompt Template for Pairwise Evaluation Metric WB-Reward</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html#appendix-e-prompt-template-for-individual-evaluation-metric-wb-score">Appendix E Prompt Template for Individual Evaluation Metric WB-Score</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html#appendix-f-full-wildbench-leaderboard">Appendix F Full WildBench Leaderboard</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Datasets/2501.14249_HLE.html">2501.14249_HLE: Humanityâ€™s Last Exam</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2501.14249_HLE.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2501.14249_HLE.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2501.14249_HLE.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2501.14249_HLE.html#dataset">3.Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2501.14249_HLE.html#evaluation">4.Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2501.14249_HLE.html#discussion">5.Discussion</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../Memory.html">è®°å¿†</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Memory.html#id3">é€šç”¨</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Normals/0normal.html">é€šç”¨</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/0normal.html#id2">æ€»ç»“ä¸å±•æœ›</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/0normal.html#id3">è®°å¿†ç±»å‹</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/0normal.html#id5">å›¾ç¤º</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/0normal.html#id6">é•¿è®°å¿†çš„å¿…è¦æ€§ä¸æŒ‘æˆ˜</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/0normal.html#id7">å‚è€ƒ</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Normals/1911.00172_kNN-LMs.html">1911.00172_kNN-LMs: Generalization through Memorization: Nearest Neighbor Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/1911.00172_kNN-LMs.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/1911.00172_kNN-LMs.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/1911.00172_kNN-LMs.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/1911.00172_kNN-LMs.html#nearest-neighbor-language-modeling">2 Nearest Neighbor Language Modeling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/1911.00172_kNN-LMs.html#experimental-setup">3 Experimental Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/1911.00172_kNN-LMs.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/1911.00172_kNN-LMs.html#tuning-nearest-neighbor-search">5 Tuning Nearest Neighbor Search</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/1911.00172_kNN-LMs.html#analysis">6 Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/1911.00172_kNN-LMs.html#related-work">7 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/1911.00172_kNN-LMs.html#conclusion-and-future-work">8 Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/1911.00172_kNN-LMs.html#appendix-a-appendix">Appendix A Appendix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Normals/2304.13343_SCM.html">2304.13343_SCM: Enhancing Large Language Model with Self-Controlled Memory Framework</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2304.13343_SCM.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2304.13343_SCM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2304.13343_SCM.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2304.13343_SCM.html#self-controlled-memory">2 Self-Controlled Memory</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2304.13343_SCM.html#id7">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2304.13343_SCM.html#experiments">3 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2304.13343_SCM.html#related-work">4 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2304.13343_SCM.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2304.13343_SCM.html#limitations">Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2304.13343_SCM.html#ethical-considerations">Ethical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2304.13343_SCM.html#appendix-a-prompt-list">Appendix A Prompt List</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2304.13343_SCM.html#appendix-b-long-term-dialogue-qa-cases">Appendix B Long-term Dialogue QA Cases</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2304.13343_SCM.html#appendix-c-book-summarization-cases">Appendix C Book Summarization Cases</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2304.13343_SCM.html#appendix-d-meeting-summarization-cases">Appendix D Meeting Summarization Cases</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Normals/2305.10250_MemoryBank.html">2305.10250_MemoryBank: Enhancing Large Language Models with Long-Term Memory</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.10250_MemoryBank.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.10250_MemoryBank.html#from-deepseek">From Deepseek</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.10250_MemoryBank.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.10250_MemoryBank.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.10250_MemoryBank.html#memorybank-a-novel-memory-mechanism-tailored-for-llms">2 MemoryBank: A Novel Memory Mechanism Tailored for LLMs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.10250_MemoryBank.html#id16">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.10250_MemoryBank.html#siliconfriend-an-ai-chatbot-companion-powered-by-memorybank">3 SiliconFriend: An AI Chatbot Companion Powered by MemoryBank</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.10250_MemoryBank.html#id17"><strong>ä½¿ç”¨çš„ä¸‰ç§å¤§è¯­è¨€æ¨¡å‹</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.10250_MemoryBank.html#id18"><strong>SiliconFriend çš„å¼€å‘é˜¶æ®µ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.10250_MemoryBank.html#id23"><strong>æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.10250_MemoryBank.html#id24"><strong>é‡ç‚¹æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.10250_MemoryBank.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.10250_MemoryBank.html#related-works">5 Related Works</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.10250_MemoryBank.html#id27">5 ç›¸å…³å·¥ä½œï¼ˆRelated Worksï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.10250_MemoryBank.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.10250_MemoryBank.html#id29">6 ç»“è®º</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Normals/2305.11792_Cue-CoT.html">2305.11792_Cue-CoT: Chain-of-thought Prompting for Responding to In-depth Dialogue Questions with LLMs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.11792_Cue-CoT.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.11792_Cue-CoT.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.11792_Cue-CoT.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.11792_Cue-CoT.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.11792_Cue-CoT.html#method">3 Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.11792_Cue-CoT.html#id11">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.11792_Cue-CoT.html#datasets-collection">4 Datasets Collection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.11792_Cue-CoT.html#experiment">5 Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.11792_Cue-CoT.html#llms">5.1 LLMs å®¶æ—ä¸è¯„ä¼°ç»†èŠ‚</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.11792_Cue-CoT.html#id16">5.2 ä¸»è¦å®éªŒ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.11792_Cue-CoT.html#id20">5.3 äººå·¥è¯„ä¼°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.11792_Cue-CoT.html#analysis">6 Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.11792_Cue-CoT.html#discussion">7 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.11792_Cue-CoT.html#conclusion">8 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.11792_Cue-CoT.html#limitations">Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.11792_Cue-CoT.html#ethics-statement">Ethics Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.11792_Cue-CoT.html#acknowledgement">Acknowledgement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.11792_Cue-CoT.html#appendix-a-templates">Appendix A Templates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.11792_Cue-CoT.html#appendix-b-different-method-of-evaluation">Appendix B Different Method of Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.11792_Cue-CoT.html#appendix-c-discussion">Appendix C Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.11792_Cue-CoT.html#appendix-d-helpfulness-analysis-of-planning-step">Appendix D Helpfulness Analysis of Planning Step</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Normals/2305.17144_GITM.html">2305.17144_GITM: Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.17144_GITM.html#from-deepseek">From Deepseek</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2305.17144_GITM.html#id5">From Deepseek</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Normals/2306.03901_ChatDB.html">2306.03901_ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2306.03901_ChatDB.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2306.03901_ChatDB.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2306.03901_ChatDB.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2306.03901_ChatDB.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2306.03901_ChatDB.html#id6">3 ChatDB</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2306.03901_ChatDB.html#evaluation">4 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2306.03901_ChatDB.html#id10">4 è¯„ä¼°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2306.03901_ChatDB.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2306.03901_ChatDB.html#id17">5 ç»“è®º</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Normals/2308.10144_ExpeL.html">2308.10144_ExpeL: LLM Agents Are Experiential Learners</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2308.10144_ExpeL.html#from-deepseek">From Deepseek</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2308.10144_ExpeL.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2308.10144_ExpeL.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2308.10144_ExpeL.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2308.10144_ExpeL.html#preliminaries">3 Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2308.10144_ExpeL.html#expel-an-experiential-learning-agent">4 ExpeL: An Experiential Learning Agent</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2308.10144_ExpeL.html#experiments">5 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2308.10144_ExpeL.html#conclusion-and-limitations">6 Conclusion and Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2308.10144_ExpeL.html#acknowledgement">Acknowledgement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2308.10144_ExpeL.html#appendix-a-detailed-related-works">Appendix A Detailed Related Works</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2308.10144_ExpeL.html#appendix-b-broader-impacts">Appendix B Broader Impacts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2308.10144_ExpeL.html#appendix-c-computational-resources">Appendix C Computational Resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2308.10144_ExpeL.html#appendix-d-environment-details">Appendix D Environment Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2308.10144_ExpeL.html#appendix-e-environment-agent-retrieval-parameters">Appendix E Environment, Agent, Retrieval Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2308.10144_ExpeL.html#appendix-f-prompt-templates">Appendix F Prompt Templates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2308.10144_ExpeL.html#appendix-g-example-insights">Appendix G Example Insights</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2308.10144_ExpeL.html#appendix-h-emergent-abilities-showcase">Appendix H Emergent Abilities Showcase</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2308.10144_ExpeL.html#appendix-i-example-trajectories">Appendix I Example Trajectories</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2308.10144_ExpeL.html#appendix-j-additional-quantitative-results">Appendix J Additional Quantitative Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Normals/2309.02427_CoALA.html">2309.02427_â‡ï¸CoALA: Cognitive Architectures for Language Agents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2309.02427_CoALA.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2309.02427_CoALA.html#from-deepseek">From Deepseek</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2309.02427_CoALA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2309.02427_CoALA.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2309.02427_CoALA.html#background-from-strings-to-symbolic-agi">2 Background: From Strings to Symbolic AGI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2309.02427_CoALA.html#connections-between-language-models-and-production-systems">3 Connections between Language Models and Production Systems</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2309.02427_CoALA.html#cognitive-architectures-for-language-agents-coala-a-conceptual-framework">4 Cognitive Architectures for Language Agents (CoALA): A Conceptual Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2309.02427_CoALA.html#case-studies">5 Case Studies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2309.02427_CoALA.html#actionable-insights">6 Actionable Insights</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2309.02427_CoALA.html#discussion">7 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2309.02427_CoALA.html#conclusion">8 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Normals/2310.08560_MemGPT.html">2310.08560_MemGPT: Towards LLMs as Operating Systems</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2310.08560_MemGPT.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2310.08560_MemGPT.html#from-deepseek">From Deepseek</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2310.08560_MemGPT.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2310.08560_MemGPT.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2310.08560_MemGPT.html#memgpt-memorygpt">2 MemGPT (MemoryGPT)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2310.08560_MemGPT.html#id18">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2310.08560_MemGPT.html#experiments">3 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2310.08560_MemGPT.html#related-work">4 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2310.08560_MemGPT.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2310.08560_MemGPT.html#appendix">6 Appendix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Normals/2311.08719_Think-in-Memory.html">2311.08719_Think-in-Memory: Recalling and Post-thinking Enable LLMs with Long-Term Memory</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2311.08719_Think-in-Memory.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2311.08719_Think-in-Memory.html#from-deepseek">From Deepseek</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2311.08719_Think-in-Memory.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2311.08719_Think-in-Memory.html#introduction">1 INTRODUCTION</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2311.08719_Think-in-Memory.html#related-work">2 RELATED WORK</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2311.08719_Think-in-Memory.html#methodology">3 METHODOLOGY</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2311.08719_Think-in-Memory.html#experiment">4. Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2311.08719_Think-in-Memory.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Normals/2312.17653_LARP.html">2312.17653_â‡ï¸LARP: Language-Agent Role Play for Open-World Games</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2312.17653_LARP.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2312.17653_LARP.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2312.17653_LARP.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2312.17653_LARP.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2312.17653_LARP.html#cognitive-architecture">3 Cognitive Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2312.17653_LARP.html#environment-interaction">4 Environment Interaction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2312.17653_LARP.html#personalities">5 Personalities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2312.17653_LARP.html#discussions">6 Discussions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2312.17653_LARP.html#conclusion">7 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Normals/2402.04624_MemoryLLM.html">2402.04624_MemoryLLM: Towards Self-Updatable Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2402.04624_MemoryLLM.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2402.04624_MemoryLLM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2402.04624_MemoryLLM.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2402.04624_MemoryLLM.html#preliminaries">2 Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2402.04624_MemoryLLM.html#id5">3 MemoryLLM</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2402.04624_MemoryLLM.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2402.04624_MemoryLLM.html#related-work">5 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2402.04624_MemoryLLM.html#conclusion-and-future-work">6 Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2402.04624_MemoryLLM.html#impact-statement">Impact Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2402.04624_MemoryLLM.html#appendix-a-details-in-methodology">Appendix A Details in Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2402.04624_MemoryLLM.html#appendix-b-implementation-details">Appendix B Implementation Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2402.04624_MemoryLLM.html#appendix-c-additional-experiments">Appendix C Additional Experiments</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Normals/2402.09727_ReadAgent.html">2402.09727_ReadAgent: A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2402.09727_ReadAgent.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2402.09727_ReadAgent.html#id2">åˆ«äººçš„æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2402.09727_ReadAgent.html#from-deepseek">From Deepseek</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Normals/2404.11672_MemLLM.html">2404.11672_MemLLM: Finetuning LLMs to Use Explicit Read-Write Memory</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.11672_MemLLM.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.11672_MemLLM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.11672_MemLLM.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.11672_MemLLM.html#related-work">2 Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.11672_MemLLM.html#methodology">3 Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.11672_MemLLM.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.11672_MemLLM.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.11672_MemLLM.html#limitations">Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.11672_MemLLM.html#appendix-a-memory-write-decoding-method">Appendix A Memory-write Decoding Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.11672_MemLLM.html#appendix-b-filtering-ambiguous-queries">Appendix B Filtering Ambiguous Queries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.11672_MemLLM.html#appendix-c-memory-read-data-generation">Appendix C Memory-read Data Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.11672_MemLLM.html#appendix-d-hyperparameters-details">Appendix D Hyperparameters Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.11672_MemLLM.html#appendix-e-filtering-prompt">Appendix E Filtering Prompt</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Normals/2404.13501_Memory_Survey.html">2404.13501_LLM_Agent_Memory_Survey: A Survey on the Memory Mechanism of Large Language Model based Agents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.13501_Memory_Survey.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.13501_Memory_Survey.html#id2">åˆ«äººçš„æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.13501_Memory_Survey.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.13501_Memory_Survey.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.13501_Memory_Survey.html#related-surveys">2 Related Surveys</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.13501_Memory_Survey.html#what-is-the-memory-of-llm-based-agent">3 What is the Memory of LLM-based Agent</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.13501_Memory_Survey.html#why-we-need-the-memory-in-llm-based-agent">4 Why We Need the Memory in LLM-based Agent</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.13501_Memory_Survey.html#how-to-implement-the-memory-of-llm-based-agent">5 How to Implement the Memory of LLM-based Agent</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.13501_Memory_Survey.html#memory-sources">5.1 Memory Sourcesï¼ˆè®°å¿†æ¥æºï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.13501_Memory_Survey.html#memory-forms">5.2 Memory Formsï¼ˆè®°å¿†å½¢å¼ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.13501_Memory_Survey.html#memory-operations">5.3 Memory Operationsï¼ˆè®°å¿†æ“ä½œï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.13501_Memory_Survey.html#how-to-evaluate-the-memory-in-llm-based-agent">6 How to Evaluate the Memory in LLM-based Agent</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.13501_Memory_Survey.html#memory-enhanced-agent-applications">7 Memory-enhanced Agent Applications</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.13501_Memory_Survey.html#limitations-future-directions">8 Limitations &amp; Future Directions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.13501_Memory_Survey.html#conclusion">9 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.13501_Memory_Survey.html#id51">9 ç»“è®º</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.13501_Memory_Survey.html#acknowledgement">Acknowledgement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2404.13501_Memory_Survey.html#id52">è‡´è°¢</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Normals/2407.01178_Memory3.html">2407.01178_â‡ï¸Memory3: Language Modeling with Explicit Memory</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2407.01178_Memory3.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2407.01178_Memory3.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2407.01178_Memory3.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2407.01178_Memory3.html#introduction">1â€‚Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2407.01178_Memory3.html#memory-circuitry-theory">2â€‚|â€‚Memory Circuitry Theory</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2407.01178_Memory3.html#design">3â€‚|â€‚Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2407.01178_Memory3.html#pretraining-data">4â€‚|â€‚Pretraining Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2407.01178_Memory3.html#pretrain">5â€‚|â€‚Pretrain</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2407.01178_Memory3.html#fine-tuning-and-alignment">6â€‚|â€‚Fine-tuning and Alignment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2407.01178_Memory3.html#id32">6â€‚|â€‚å¾®è°ƒä¸å¯¹é½</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2407.01178_Memory3.html#evaluation">7â€‚|â€‚Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2407.01178_Memory3.html#conclusion">8â€‚|â€‚Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2407.01178_Memory3.html#id40">8â€‚|â€‚ç»“è®º</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2407.01178_Memory3.html#acknowledgement">Acknowledgement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2407.01178_Memory3.html#id47">è‡´è°¢</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2407.01178_Memory3.html#appendix-a-cost-estimation">Appendix A Cost Estimation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2407.01178_Memory3.html#a-1-implicit-memory"><strong>A.1â€‚|â€‚Implicit Memory</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2407.01178_Memory3.html#a-2-explicit-memory"><strong>A.2â€‚|â€‚Explicit Memory</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2407.01178_Memory3.html#a-3-external-information"><strong>A.3â€‚|â€‚External Information</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2407.01178_Memory3.html#id54"><strong>æ€»ç»“ä¸å¯¹æ¯”</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2407.01178_Memory3.html#remark-9"><strong>é™„æ³¨ï¼šçŸ¥è¯†ä¿ç•™é—®é¢˜ï¼ˆRemark 9ï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2407.01178_Memory3.html#appendix-b-vector-compression">Appendix B Vector Compression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2407.01178_Memory3.html#b">é™„å½• B å‘é‡å‹ç¼©</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2407.01178_Memory3.html#appendix-c-supplementary-evaluation-results">Appendix C Supplementary Evaluation Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2407.01178_Memory3.html#c">é™„å½• C è¡¥å……è¯„ä¼°ç»“æœæ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Normals/2410.15665_LongTermMemory.html">2410.15665_LongTermMemory: The Foundation of AI Self-Evolution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2410.15665_LongTermMemory.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2410.15665_LongTermMemory.html#id2">åˆ«äººçš„æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2410.15665_LongTermMemory.html#from-deepseek">From Deepseek</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2410.15665_LongTermMemory.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2410.15665_LongTermMemory.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2410.15665_LongTermMemory.html#ai-self-evolution">2 AI Self-Evolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2410.15665_LongTermMemory.html#id8"><strong>æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2410.15665_LongTermMemory.html#ltm-for-ai-self-evolution">3 LTM for AI Self-Evolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2410.15665_LongTermMemory.html#how-to-construct-ltm">4 How to Construct LTM?</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2410.15665_LongTermMemory.html#how-can-ltm-be-used-to-achieve-model-self-evolution">5 How can LTM be used to achieve model self-Evolution?</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2410.15665_LongTermMemory.html#the-practice-of-model-self-evolution-based-on-ltm">6 The Practice of model self-evolution based on LTM</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2410.15665_LongTermMemory.html#our-future-plans">7  Our Future Plans</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2410.15665_LongTermMemory.html#conclusion">8 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2410.15665_LongTermMemory.html#appendix-a-rtg-prompt">Appendix A RTG prompt</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Normals/2502.00592_M%2B.html">2502.00592_M+: Extending MemoryLLM with Scalable Long-Term Memory</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2502.00592_M%2B.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2502.00592_M%2B.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2502.00592_M%2B.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2502.00592_M%2B.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2502.00592_M%2B.html#methodology">3 Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2502.00592_M%2B.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2502.00592_M%2B.html#conclusion-and-future-work">5 Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2502.00592_M%2B.html#impact-statement">Impact Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2502.00592_M%2B.html#appendix-a-justifications-of-using-deepspeed-stage-2">Appendix A Justifications of using deepspeed-stage-2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2502.00592_M%2B.html#appendix-b-experiments-on-datasets-naturalqa">Appendix B Experiments on datasets NaturalQA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2502.00592_M%2B.html#appendix-c-statistics-of-the-dataset-of-long-documents">Appendix C Statistics of the Dataset of Long Documents</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2502.00592_M%2B.html#appendix-d-additional-training-details">Appendix D Additional Training Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2502.00592_M%2B.html#appendix-e-discussions">Appendix E Discussions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Normals/2502.12110_A-Mem.html">2502.12110_A-Mem: Agentic Memory for LLM Agents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2502.12110_A-Mem.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2502.12110_A-Mem.html#from-deepseek">From Deepseek</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2502.12110_A-Mem.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2502.12110_A-Mem.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2502.12110_A-Mem.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2502.12110_A-Mem.html#methodolodgy">3 Methodolodgy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2502.12110_A-Mem.html#experiment">4 Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2502.12110_A-Mem.html#conclusions">5 Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2502.12110_A-Mem.html#limitations">6 Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2502.12110_A-Mem.html#appendix-a-experiment">Appendix A Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2502.12110_A-Mem.html#appendix-b-prompt-templates-and-examples">Appendix B Prompt Templates and Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Normals/2504.15965_From_Human_to_AI_Memory.html">2504.15965_â‡ï¸From Human Memory to AI Memory: A Survey on Memory Mechanisms in the Era of LLMs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2504.15965_From_Human_to_AI_Memory.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2504.15965_From_Human_to_AI_Memory.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2504.15965_From_Human_to_AI_Memory.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2504.15965_From_Human_to_AI_Memory.html#overview">2 Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2504.15965_From_Human_to_AI_Memory.html#personal-memory">3 Personal Memory</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2504.15965_From_Human_to_AI_Memory.html#system-memory">4 System Memory</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2504.15965_From_Human_to_AI_Memory.html#open-problems-and-future-directions">5 Open Problems and Future Directions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2504.15965_From_Human_to_AI_Memory.html#conclusion">6 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Normals/2504.19413_Mem0.html">2504.19413_â‡ï¸Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2504.19413_Mem0.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2504.19413_Mem0.html#id2">åˆ«äººçš„æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2504.19413_Mem0.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2504.19413_Mem0.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2504.19413_Mem0.html#proposed-methods">2 Proposed Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2504.19413_Mem0.html#id13"><strong>æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2504.19413_Mem0.html#experimental-setup">3 Experimental Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2504.19413_Mem0.html#id16">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2504.19413_Mem0.html#evaluation-results-analysis-and-discussion">4 Evaluation Results, Analysis and Discussion.</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2504.19413_Mem0.html#conclusion-and-future-work">5 Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2504.19413_Mem0.html#acknowledgments">6 Acknowledgments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2504.19413_Mem0.html#appendix-a-prompts">Appendix A Prompts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2504.19413_Mem0.html#appendix-b-algorithm">Appendix B Algorithm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2504.19413_Mem0.html#appendix-c-selected-baselines">Appendix C Selected Baselines</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Normals/2505.00675_RethinkingMemory.html">2505.00675_â‡ï¸Rethinking Memory in AI: Taxonomy, Operations, Topics, and Future Directions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2505.00675_RethinkingMemory.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2505.00675_RethinkingMemory.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2505.00675_RethinkingMemory.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2505.00675_RethinkingMemory.html#memory-foundations">2 Memory Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2505.00675_RethinkingMemory.html#from-operations-to-key-research-topics">3 From Operations to Key Research Topics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2505.00675_RethinkingMemory.html#memory-in-practice">4 Memory In Practice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2505.00675_RethinkingMemory.html#id20">æ€»ä½“æ€»ç»“ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2505.00675_RethinkingMemory.html#memory-in-humans-and-ai-systems">5 Memory in Humans and AI Systems</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2505.00675_RethinkingMemory.html#open-challenges-and-future-directions">6 Open Challenges and Future Directions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2505.00675_RethinkingMemory.html#appendix-a-gpt-based-pipeline-selection">Appendix A GPT-based Pipeline Selection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2505.00675_RethinkingMemory.html#appendix-b-relative-citation-index">Appendix B Relative Citation Index</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2505.00675_RethinkingMemory.html#appendix-c-chord-analysis-of-interactions-among-memory-types-operations-topics-and-venues">Appendix C Chord Analysis of Interactions Among Memory Types, Operations, Topics, and Venues</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Normals/2505.22101_MemOS.html">2505.22101_MemOS: An Operating System for Memory-Augmented Generation (MAG) in LLM (Short Version)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2505.22101_MemOS.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2505.22101_MemOS.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2505.22101_MemOS.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2505.22101_MemOS.html#memory-in-large-language-models">2 Memory in Large Language Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2505.22101_MemOS.html#memos-design-philosophy">3 MemOS Design Philosophy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2505.22101_MemOS.html#memos">4 MemOS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2505.22101_MemOS.html#id2"><strong>4.1 MemOS ä¸­çš„è®°å¿†ç±»å‹</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2505.22101_MemOS.html#memcube"><strong>4.2 è®°å¿†ç«‹æ–¹ä½“ï¼ˆMemCubeï¼‰ï¼šæ ¸å¿ƒèµ„æº</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2505.22101_MemOS.html#id3"><strong>4.3 MemOS æ¶æ„</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2505.22101_MemOS.html#id4"><strong>4.4 ç³»ç»Ÿæ‰§è¡Œæµç¨‹</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2505.22101_MemOS.html#id5"><strong>æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2505.22101_MemOS.html#conclusion">5 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Normals/2507.03724_MemOS.html">2505.22101_â‡ï¸MemOS: A Memory OS for AI System</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2507.03724_MemOS.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2507.03724_MemOS.html#llm">LLM æ€»ç»“ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2507.03724_MemOS.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2507.03724_MemOS.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2507.03724_MemOS.html#memory-in-large-language-models">2 Memory in Large Language Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2507.03724_MemOS.html#memos-design-philosophy">3 MemOS Design Philosophy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2507.03724_MemOS.html#memory-modeling-in-memos">4 Memory Modeling in MemOS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2507.03724_MemOS.html#architecture-of-memos">5 Architecture of MemOS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2507.03724_MemOS.html#evaluation">6 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2507.03724_MemOS.html#memos-for-architecture-innovation-and-applications">7 MemOS for Architecture Innovation and Applications</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2507.03724_MemOS.html#conclusion">8 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Normals/2508.09874_MemoryDecoder.html">2508.09874_Memory Decoder: A Pretrained, Plug-and-Play Memory for Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2508.09874_MemoryDecoder.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2508.09874_MemoryDecoder.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2508.09874_MemoryDecoder.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2508.09874_MemoryDecoder.html#background">2 Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2508.09874_MemoryDecoder.html#id9">3 Memory Decoder</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2508.09874_MemoryDecoder.html#experimental-setup">4 Experimental Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2508.09874_MemoryDecoder.html#results">5 Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2508.09874_MemoryDecoder.html#analysis">6 Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2508.09874_MemoryDecoder.html#related-work">7 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2508.09874_MemoryDecoder.html#conclusion">8 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2508.09874_MemoryDecoder.html#limitations">9 Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2508.09874_MemoryDecoder.html#appendix-a-interpolation-hyperparameter-alpha-of-all-tasks">Appendix A Interpolation hyperparameter <span class="math notranslate nohighlight">\(\alpha\)</span> of all tasks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2508.09874_MemoryDecoder.html#appendix-b-analysis-of-dapt-performance-on-downstream-tasks">Appendix B Analysis of DAPT Performance on Downstream Tasks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2508.09874_MemoryDecoder.html#appendix-c-knowledge-intensive-reasoning-task-corpus-composition">Appendix C Knowledge-Intensive Reasoning Task Corpus Composition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2508.09874_MemoryDecoder.html#appendix-d-domain-specific-downstream-tasks">Appendix D Domain-Specific Downstream Tasks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2508.09874_MemoryDecoder.html#appendix-e-comparison-with-dapt-model-interpolation">Appendix E Comparison with DAPT Model Interpolation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2508.09874_MemoryDecoder.html#appendix-f-in-context-learning-performance-analysis">Appendix F In-Context Learning Performance Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2508.09874_MemoryDecoder.html#appendix-g-characteristics-of-kk-nn-distributions">Appendix G Characteristics of kk-NN Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Normals/2508.09874_MemoryDecoder.html#appendix-h-alternative-loss-functions-for-imitating-kk-nn-distributions">Appendix H Alternative Loss Functions for Imitating kk-NN Distributions</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Memory.html#id4">æ¨è</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Recommends/05xx.xxxxx_RS.html">Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/05xx.xxxxx_RS.html#id1">è®ºæ–‡åŸºæœ¬ä¿¡æ¯</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/05xx.xxxxx_RS.html#id2">æ ¸å¿ƒå†…å®¹ç®€ä»‹</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/05xx.xxxxx_RS.html#id3">é‡è¦æ€§ä¸å½±å“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/05xx.xxxxx_RS.html#id4">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Recommends/08xx.xxxxx_SVD%2B%2B.html">08xx.xxxxx_SVD++: Factorization meets the neighborhood: a multifaceted collaborative filtering model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/08xx.xxxxx_SVD%2B%2B.html#svd">SVD++</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/08xx.xxxxx_SVD%2B%2B.html#neighborhood-models">Neighborhood Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/08xx.xxxxx_SVD%2B%2B.html#latent-factor-models">Latent Factor Modelsï¼ˆæ½œåœ¨å› å­æ¨¡å‹ï¼‰</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Recommends/17xx.xxxxx_RS.html">Recommender systems: An overview of different approaches to recommendations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/17xx.xxxxx_RS.html#id1">è®ºæ–‡ç®€ä»‹</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/17xx.xxxxx_RS.html#id2">æ ¸å¿ƒå†…å®¹æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/17xx.xxxxx_RS.html#id6">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Recommends/1902.07153_SGCN.html">1902.07153_SGCN: Simplifying Graph Convolutional Networks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/1902.07153_SGCN.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/1902.07153_SGCN.html#id2">å‰æçŸ¥è¯†</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/1902.07153_SGCN.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/1902.07153_SGCN.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/1902.07153_SGCN.html#simple-graph-convolution">2 Simple Graph Convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/1902.07153_SGCN.html#spectral-analysis">3 Spectral Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/1902.07153_SGCN.html#related-works">4 Related Works</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/1902.07153_SGCN.html#experiments-and-discussion">5 Experiments and Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/1902.07153_SGCN.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/1902.07153_SGCN.html#acknowledgement">Acknowledgement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/1902.07153_SGCN.html#appendix-a-the-spectrum-of-symsubscript-sym">Appendix A The spectrum of ğš«~symsubscript~ğš«symï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/1902.07153_SGCN.html#appendix-b-experiment-details">Appendix B Experiment Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/1902.07153_SGCN.html#appendix-c-additional-experiments">Appendix C Additional Experiments</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Recommends/1905.08108_NGCF.html">1905.08108_NGCF: Neural Graph Collaborative Filtering</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/1905.08108_NGCF.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/1905.08108_NGCF.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/1905.08108_NGCF.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/1905.08108_NGCF.html#methodology">2. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/1905.08108_NGCF.html#related-work">3. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/1905.08108_NGCF.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/1905.08108_NGCF.html#conclusion-and-future-work">5. Conclusion and Future Work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Recommends/2001.10167_RGCF.html">2001.10167_RGCF: Revisiting Graph based Collaborative Filtering: A Linear Residual Graph Convolutional Network Approach</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2001.10167_RGCF.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2001.10167_RGCF.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2001.10167_RGCF.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2001.10167_RGCF.html#preliminaries-and-related-work">Preliminaries and Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2001.10167_RGCF.html#linear-residual-graph-convolutional-collaborative-filtering">Linear Residual Graph Convolutional Collaborative Filtering</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2001.10167_RGCF.html#experiments">Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2001.10167_RGCF.html#conclusions">Conclusions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Recommends/2002.02126_LightGCN.html">2002.02126_LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2002.02126_LightGCN.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2002.02126_LightGCN.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2002.02126_LightGCN.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2002.02126_LightGCN.html#preliminaries">2. Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2002.02126_LightGCN.html#method">3. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2002.02126_LightGCN.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2002.02126_LightGCN.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2002.02126_LightGCN.html#conclusion-and-future-work">6. Conclusion and Future Work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Recommends/2010.10783_SGL.html">2010.10783_SGL: Self-supervised Graph Learning for Recommendation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2010.10783_SGL.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2010.10783_SGL.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2010.10783_SGL.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2010.10783_SGL.html#preliminaries">2. Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2010.10783_SGL.html#methodology">3. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2010.10783_SGL.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2010.10783_SGL.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2010.10783_SGL.html#conclusion-and-future-work">6. Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2010.10783_SGL.html#appendix-a-gradient-of-infonce-loss-w-r-t-node-representation">Appendix A Gradient of InfoNCE Loss <em>w.r.t.</em> node representation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Recommends/2112.08679_SimGCL.html">2112.08679_SimGCL: Are Graph Augmentations Necessary? Simple Graph ContrastiveÂ Learning for Recommendation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2112.08679_SimGCL.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2112.08679_SimGCL.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2112.08679_SimGCL.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2112.08679_SimGCL.html#investigation-of-graph-contrastive-learning-in-recommendation">2. Investigation of Graph Contrastive Learning in Recommendation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2112.08679_SimGCL.html#simgcl-simple-graph-contrastive-learning-for-recommendation">3. SimGCL: Simple Graph Contrastive Learning for Recommendation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2112.08679_SimGCL.html#experimental-results">4. Experimental Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2112.08679_SimGCL.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2112.08679_SimGCL.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2112.08679_SimGCL.html#acknowledgement">Acknowledgement</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Recommends/2202.06200_NCL.html">2202.06200_NCL: Improving Graph Collaborative Filtering with Neighborhood-enriched Contrastive Learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2202.06200_NCL.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2202.06200_NCL.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2202.06200_NCL.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2202.06200_NCL.html#preliminary">2. Preliminary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2202.06200_NCL.html#methodology">3. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2202.06200_NCL.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2202.06200_NCL.html#related-work">5. Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2202.06200_NCL.html#conclusion-and-future-work">6. Conclusion And Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2202.06200_NCL.html#appendix-a-pseudo-code-for-ncl">Appendix A Pseudo-code for NCL</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2202.06200_NCL.html#appendix-b-case-study-on-selected-neighbors">Appendix B Case Study on Selected Neighbors</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Recommends/2203.13366_RLP_P5.html">2203.13366_RLP_P5: A Unified Pretrain, Personalized Prompt &amp; Predict Paradigm (P5)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2203.13366_RLP_P5.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2203.13366_RLP_P5.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2203.13366_RLP_P5.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2203.13366_RLP_P5.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2203.13366_RLP_P5.html#personalized-prompt-collection">3. Personalized Prompt Collection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2203.13366_RLP_P5.html#the-p5-paradigm-and-model">4. The P5 Paradigm and Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2203.13366_RLP_P5.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2203.13366_RLP_P5.html#conclusions-and-future-work">6. Conclusions and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2203.13366_RLP_P5.html#acknowledgment">Acknowledgment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2203.13366_RLP_P5.html#d-full-list-of-personalized-prompts-for-amazon-datasets">D FULL LIST OF PERSONALIZED PROMPTS FOR AMAZON DATASETS</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Recommends/2302.08191_LightGCL.html">2302.08191_LightGCL: Simple Yet Effective Graph Contrastive Learning for Recommendation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2302.08191_LightGCL.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2302.08191_LightGCL.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2302.08191_LightGCL.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2302.08191_LightGCL.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2302.08191_LightGCL.html#methodology">3 Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2302.08191_LightGCL.html#evaluation">4 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2302.08191_LightGCL.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2302.08191_LightGCL.html#appendix-a-details-of-the-baselines">Appendix A Details of the Baselines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2302.08191_LightGCL.html#appendix-b-performance-comparison-with-baselines-continued">Appendix B Performance Comparison with Baselines (Continued)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2302.08191_LightGCL.html#appendix-c-theoretical-analysis">Appendix C Theoretical Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2302.08191_LightGCL.html#appendix-d-calculation-of-complexity">Appendix D Calculation of Complexity</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2302.08191_LightGCL.html#appendix-e-performance-results-under-the-new-setting">Appendix E Performance Results under the New Setting</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Recommends/2303.14524_ChatRec.html">2303.14524_ChatRec: Towards Interactive and Explainable LLMs-Augmented Recommender System</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2303.14524_ChatRec.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2303.14524_ChatRec.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2303.14524_ChatRec.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2303.14524_ChatRec.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2303.14524_ChatRec.html#method">3 Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2303.14524_ChatRec.html#experiment">4 Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2303.14524_ChatRec.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2303.14524_ChatRec.html#appendix-0-a-implementation-details">Appendix 0.A Implementation Details</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Recommends/2305.00447_TALLRec.html">2305.00447_TALLRec: An Effective and Efficient Tuning Framework to Align Large Language Model with Recommendation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2305.00447_TALLRec.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2305.00447_TALLRec.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2305.00447_TALLRec.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2305.00447_TALLRec.html#id8">2. TALLRec</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2305.00447_TALLRec.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2305.00447_TALLRec.html#related-work">4. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2305.00447_TALLRec.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Recommends/2305.07001_InstructRec.html">2305.07001_InstructRec: Recommendation as Instruction Following: A Large Language Model Empowered Recommendation Approach</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2305.07001_InstructRec.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2305.07001_InstructRec.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2305.07001_InstructRec.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2305.07001_InstructRec.html#methodology">2. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2305.07001_InstructRec.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2305.07001_InstructRec.html#conclusion-and-future-work">4. Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2305.07001_InstructRec.html#appendix-a-instruction-templates-for-traditional-recommendation">Appendix A Instruction Templates for <em>Traditional Recommendation</em></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2305.07001_InstructRec.html#appendix-b-instruction-templates-for-traditional-product-search">Appendix B Instruction Templates for <em>Traditional Product search</em></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2305.07001_InstructRec.html#appendix-c-instruction-templates-for-personalized-search">Appendix C Instruction Templates for <em>Personalized Search</em></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Recommends/2306.10933_KAR.html">2306.10933_KAR: Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2306.10933_KAR.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2306.10933_KAR.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2306.10933_KAR.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2306.10933_KAR.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2306.10933_KAR.html#preliminaries">3. Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2306.10933_KAR.html#methodology">4. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2306.10933_KAR.html#experiment">5. Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2306.10933_KAR.html#broader-impact">6. Broader Impact</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2306.10933_KAR.html#conclusion">7. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Recommends/2308.11131_ReLLa.html">2308.11131_ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2308.11131_ReLLa.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2308.11131_ReLLa.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2308.11131_ReLLa.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2308.11131_ReLLa.html#preliminaries">2. Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2308.11131_ReLLa.html#methodology">3. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2308.11131_ReLLa.html#experiment">4. Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2308.11131_ReLLa.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2308.11131_ReLLa.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2308.11131_ReLLa.html#appendix-a-prompt-illustration">Appendix A Prompt Illustration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2308.11131_ReLLa.html#appendix-b-data-preprocessing">Appendix B Data Preprocessing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2308.11131_ReLLa.html#appendix-c-baseline-implementation">Appendix C Baseline Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2308.11131_ReLLa.html#id27">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2308.11131_ReLLa.html#appendix-d-additional-experiments">Appendix D Additional Experiments</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Recommends/2310.15950_RLMRec.html">2310.15950_RLMRec: Representation Learning with Large Language Models for Recommendation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2310.15950_RLMRec.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2310.15950_RLMRec.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2310.15950_RLMRec.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2310.15950_RLMRec.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2310.15950_RLMRec.html#methodology">3. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2310.15950_RLMRec.html#evaluation">4. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2310.15950_RLMRec.html#conclusion">5. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2310.15950_RLMRec.html#appendix-a-supplementary-material">Appendix A Supplementary Material</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Recommends/2311.01343_CLLM4Rec.html">2311.01343_CLLM4Rec: Collaborative Large Language Model for Recommender Systems</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2311.01343_CLLM4Rec.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2311.01343_CLLM4Rec.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2311.01343_CLLM4Rec.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2311.01343_CLLM4Rec.html#contribution">æœ¬èŠ‚è´¡çŒ®ï¼ˆContributionï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2311.01343_CLLM4Rec.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2311.01343_CLLM4Rec.html#id5">2. ç›¸å…³å·¥ä½œ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2311.01343_CLLM4Rec.html#methodology">3. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2311.01343_CLLM4Rec.html#empirical-study">4. Empirical Study</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2311.01343_CLLM4Rec.html#conclusion">5. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2311.01343_CLLM4Rec.html#acknowledgment">Acknowledgment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2311.01343_CLLM4Rec.html#appendix-a-technical-details">Appendix A Technical Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Recommends/2311.01343_CLLM4Rec.html#appendix-b-experiments">Appendix B Experiments</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Memory.html#agent">è®°å¿†ç›¸å…³Agent</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Agents/2504.10147_PersonalRAG%2B.html">2504.10147_PersonalRAGâ‡ï¸: A Survey of Personalization: From RAG to Agent</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Agents/2504.10147_PersonalRAG%2B.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Agents/2504.10147_PersonalRAG%2B.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Agents/2504.10147_PersonalRAG%2B.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Agents/2504.10147_PersonalRAG%2B.html#what-is-personalization">2. What is Personalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Agents/2504.10147_PersonalRAG%2B.html#how-to-adopt-personalization">3. How to Adopt Personalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Agents/2504.10147_PersonalRAG%2B.html#where-to-adopt-personalization">4. Where to Adopt Personalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Agents/2504.10147_PersonalRAG%2B.html#evaluation-and-dataset">5. Evaluation and Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Agents/2504.10147_PersonalRAG%2B.html#challenges-and-future-directions">6. Challenges and Future Directions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Agents/2504.10147_PersonalRAG%2B.html#conclusion">7. Conclusion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Memory.html#id5">è®°å¿†ç›¸å…³æ•°æ®é›†</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Databases/2308.08239_MemoChat.html">2308.08239_MemoChat: Tuning LLMs to Use Memos for Consistent Long-Range Open-Domain Conversation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2308.08239_MemoChat.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2308.08239_MemoChat.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2308.08239_MemoChat.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2308.08239_MemoChat.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2308.08239_MemoChat.html#methodology">3 Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2308.08239_MemoChat.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2308.08239_MemoChat.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2308.08239_MemoChat.html#appendix-a-basic-published-datasets">Appendix A Basic Published Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2308.08239_MemoChat.html#appendix-b-involved-prompts">Appendix B Involved Prompts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2308.08239_MemoChat.html#appendix-c-instruction-design-challenges">Appendix C Instruction Design Challenges</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2308.08239_MemoChat.html#id22">1. å¼•è¨€</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2308.08239_MemoChat.html#prompt-copy">2. Prompt Copyï¼ˆæç¤ºå¤åˆ¶ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2308.08239_MemoChat.html#catastrophic-forgetting">3. Catastrophic Forgettingï¼ˆç¾éš¾æ€§é—å¿˜ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2308.08239_MemoChat.html#prompt-misplacement">4. Prompt Misplacementï¼ˆæç¤ºé”™ä½ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2308.08239_MemoChat.html#id23">5. ç¤ºä¾‹ä»»åŠ¡è¯´æ˜</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2308.08239_MemoChat.html#id24">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Databases/2402.17753_LoCoMo.html">2402.17753_LoCoMoâ‡ï¸: Evaluating Very Long-Term Conversational Memory of LLM Agents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2402.17753_LoCoMo.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2402.17753_LoCoMo.html#id2">åˆ«äººçš„æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2402.17753_LoCoMo.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2402.17753_LoCoMo.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2402.17753_LoCoMo.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2402.17753_LoCoMo.html#generative-pipeline-for-locomo">3 Generative Pipeline for LoCoMo</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2402.17753_LoCoMo.html#locomo-evaluation-benchmark">4 LoCoMo Evaluation Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2402.17753_LoCoMo.html#experimental-setup">5 Experimental Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2402.17753_LoCoMo.html#experimental-results">6 Experimental Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2402.17753_LoCoMo.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2402.17753_LoCoMo.html#limitations">8 Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2402.17753_LoCoMo.html#broader-impacts">9 Broader Impacts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2402.17753_LoCoMo.html#appendix-overview">Appendix Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2402.17753_LoCoMo.html#appendix-a-generative-pipeline-for-locomo">Appendix A Generative Pipeline for LoCoMo</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2402.17753_LoCoMo.html#appendix-b-dataset">Appendix B Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2402.17753_LoCoMo.html#appendix-c-experimental-setup">Appendix C Experimental Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2402.17753_LoCoMo.html#appendix-d-results">Appendix D Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Databases/2507.05257_MemoryAgentBench.html">2507.05257_MemoryAgentBench: Evaluating Memory in LLM Agents via Incremental Multi-Turn Interactions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2507.05257_MemoryAgentBench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2507.05257_MemoryAgentBench.html#from-deepseek">From Deepseek</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2507.05257_MemoryAgentBench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2507.05257_MemoryAgentBench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2507.05257_MemoryAgentBench.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2507.05257_MemoryAgentBench.html#id12">3 MemoryAgentBench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2507.05257_MemoryAgentBench.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2507.05257_MemoryAgentBench.html#conclusion-and-future-work">5 Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2507.05257_MemoryAgentBench.html#appendix-a-details-of-dataset">Appendix A Details of Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2507.05257_MemoryAgentBench.html#appendix-b-prompts">Appendix B Prompts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2507.05257_MemoryAgentBench.html#appendix-c-detailed-experimental-results">Appendix C Detailed Experimental Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Databases/2507.05257_MemoryAgentBench.html#appendix-d-experimental-settings">Appendix D Experimental Settings</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Memory.html#id6">å¤šæ¨¡æ€è®°å¿†</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Memorys/Multimodals/2508.09736_M3-Agent.html">2508.09736_M3-Agentâ‡ï¸: Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Multimodals/2508.09736_M3-Agent.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Multimodals/2508.09736_M3-Agent.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Multimodals/2508.09736_M3-Agent.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Multimodals/2508.09736_M3-Agent.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Multimodals/2508.09736_M3-Agent.html#datasets">3 Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Multimodals/2508.09736_M3-Agent.html#approach">4 Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Multimodals/2508.09736_M3-Agent.html#experiments">5 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Multimodals/2508.09736_M3-Agent.html#conclusion-and-future-work">6 Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Multimodals/2508.09736_M3-Agent.html#acknowledgment">7 Acknowledgment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Multimodals/2508.09736_M3-Agent.html#id19">8 M3-Bench-robot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Multimodals/2508.09736_M3-Agent.html#id20">9 M3-Bench-web</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Multimodals/2508.09736_M3-Agent.html#implementation-details-of-tools">10 Implementation Details of Tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Multimodals/2508.09736_M3-Agent.html#demonstration-data-synthesis-for-memorization">11 Demonstration Data Synthesis for Memorization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Multimodals/2508.09736_M3-Agent.html#evaluation-of-memorization">12 Evaluation of Memorization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Multimodals/2508.09736_M3-Agent.html#rl-training-details">13 RL Training Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Multimodals/2508.09736_M3-Agent.html#id29">14 Case Study</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Memorys/Multimodals/2508.09736_M3-Agent.html#prompt-templates">15 Prompt Templates</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM.html">LLM æ¨¡å‹</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../LLM.html#nlp">NLP æ¨¡å‹</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/1810.04805_BERT.html">1810.04805_BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/1810.04805_BERT.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/1810.04805_BERT.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/1810.04805_BERT.html#bert">3 BERT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/1810.04805_BERT.html#appendix-a-additional-details-for-bert">Appendix A Additional Details for BERT</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html">18xx_GPT1: Improving Language Understanding by Generative Pre-Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#framework">3. Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#analysis">5 Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#id3">å¼•æ–‡å£ç¢‘</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#id4">è¦ç‚¹è§£è¯»</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/19_GPT2.html">19xx_GPT2: Language Models are Unsupervised Multitask Learners</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/19_GPT2.html#the-illustrated-gpt-2">The Illustrated GPT-2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/19_GPT2.html#id2">å‚è€ƒ</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2006.03654_DeBERTa.html">2006.03654_DeBERTa: Decoding-enhanced BERT with Disentangled Attention</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2006.03654_DeBERTa.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2006.03654_DeBERTa.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2006.03654_DeBERTa.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2006.03654_DeBERTa.html#background">2 Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2006.03654_DeBERTa.html#the-deberta-architecture">3 The DeBERTa Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2006.03654_DeBERTa.html#scale-invariant-fine-tuning">4 Scale Invariant Fine-Tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2006.03654_DeBERTa.html#id21">4 å°ºåº¦ä¸å˜å¾®è°ƒ (Scale Invariant Fine-Tuning)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2006.03654_DeBERTa.html#experiment">5 Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2006.03654_DeBERTa.html#conclusions">6 Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2006.03654_DeBERTa.html#acknowledgments">7 Acknowledgments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2006.03654_DeBERTa.html#appendix-a-appendix">Appendix A Appendix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2012.00413_CPM.html">2012.00413_CPM: A Large-scale Generative Chinese Pre-trained Language Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2302.13971_LLaMA.html">2302.13971_LLaMA: Open and Efficient Foundation Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2307.09288_Llama2.html">2307.09288_Llama 2: Open Foundation and Fine-Tuned Chat Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html">2309.16609_Qwen Technical Report</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#pretraining">2. Pretraining</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#alignment">3. Alignment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#code-qwen-specialized-model-for-coding">4. CODE-QWEN: SPECIALIZED MODEL FOR CODING</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#math-qwen-specialized-model-for-mathematics-reasoning">5. MATH-QWEN: SPECIALIZED MODEL FOR MATHEMATICS REASONING</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#related-work">6. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#conclusion">7. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#a-1-more-training-details">A.1 MORE TRAINING DETAILS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#a-2-evaluation">A.2 EVALUATION</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html">2310.19341_Skywork: A More Open Bilingual Foundation Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#methodology">2 Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#pre-training">3 Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#evaluation">4 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#discussion">5 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#limitation">6 Limitation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#appendix-a-details-on-gpt-7b-vs-llama-7b-experiment">Appendix A Details on GPT-7B vs. LLaMA-7B Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#appendix-b-preliminary-experiments-on-distributed-training">Appendix B Preliminary Experiments on Distributed Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#appendix-c-more-benchmark-results">Appendix C More Benchmark Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#appendix-d-details-on-lm-test-sets">Appendix D Details on LM Test Sets</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2401.14196_DeepSeek-Coder.html">2401.14196_DeepSeek-Coder: When the Large Language Model Meets Programming â€“ The Rise of Code Intelligence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2404.06395_MiniCPM.html">2404.06395_MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2404.06395_MiniCPM.html#two-stage-pre-training-strategy">5. Two Stage Pre-training Strategy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2404.06395_MiniCPM.html#model">6. Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2404.06395_MiniCPM.html#minicpm-family">7 MiniCPM Family</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2405.04434_DeepSeek-V2.html">2405.04434_DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2406.12793_ChatGLM.html">2406.12793_ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html">2407.10671_Qwen2 Technical Report</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html#tokenizer-model">2. Tokenizer &amp; Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html#pre-training">3. Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html#post-training">4. Post-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html">2412.15115_Qwen2.5</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html#architecture-and-tokenizer">2. Architecture and Tokenizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html#pre-training">3. Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html#post-training">4. Post-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2505.09388_Qwen3.html">2505.09388_Qwen3</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2505.09388_Qwen3.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2505.09388_Qwen3.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2505.09388_Qwen3.html#architecture">2. Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2505.09388_Qwen3.html#pre-training">3. Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2505.09388_Qwen3.html#post-training">4. Post-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2505.09388_Qwen3.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM.html#id2">å¤šæ¨¡æ€æ¨¡å‹</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html">2112.15093_CTR: Benchmarking Chinese Text Recognition: Datasets, Baselines, and an Empirical Study</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#preliminaries">2. Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#datasets">3. Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#baselines">4. Baselines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#an-empirical-study">5. An Empirical Study</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#conclusions">6. Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#appendix-a-details-of-prab">Appendix A Details of PRAB</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#appendix-c-visualization-of-failure-cases">Appendix C Visualization of Failure Cases.</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html">2304.08485_LLaVA: Visual Instruction Tuning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html#gpt-assisted-visual-instruction-data-generation">3. GPT-assisted Visual Instruction Data Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html#visual-instruction-tuning">4. Visual Instruction Tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2308.12966_Qwen-VL.html">2308.12966_Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2308.12966_Qwen-VL.html#methodology">Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2308.12966_Qwen-VL.html#training">Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2308.12966_Qwen-VL.html#evaluation">Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2308.12966_Qwen-VL.html#b-data-format-details-of-training">B. Data Format Details of Training</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html">2310.03744_LLaVA2: Improved Baselines with Visual Instruction Tuning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#approach">3. Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#empirical-evaluation">4. Empirical Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#open-problems-in-lmms">5. Open Problems in LMMs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#a-implementation-details">A. Implementation Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#b-qualitative-results">B. Qualitative Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html">2312.07533_VILA: On Pre-training for Visual Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html#on-pre-training-for-visual-language-models">3. On Pre-training for Visual Language Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2403.05525_DeepSeek-VL.html">2403.05525_DeepSeek-VL: Towards Real-World Vision-Language Understanding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2403.05525_DeepSeek-VL.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html">2408.01800_MiniCPM-V: A GPT-4V Level MLLM on Your Phone</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#model-architecture">3. Model Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#training">4. Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#end-side-deployment">5. End-side Deployment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#experiments">6. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#conclusion">7. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html">2409.17146_Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Vision-Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#architecture">2. Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#data">3. Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#training">4. Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#ablations">6. Ablations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-a-model-details">Appendix A: Model Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-b-training-details">Appendix B: Training Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-c-evaluation-results">Appendix C: Evaluation Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-d-result-details">Appendix D: Result Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-e-ablations-details">Appendix E Ablations Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-f-data-details">Appendix F Data Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-g-dataset-examples">Appendix G Dataset Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-h-related-work">Appendix H Related Work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html">2410.13848_Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#llm">LLMæ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#janus-a-simple-unified-and-flexible-multimodal-framework">3 Janus: A Simple, Unified and Flexible Multimodal Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#appendix-a-details-of-semantic-tokenizer-mentioned-in-ablation-study">Appendix A Details of Semantic Tokenizer Mentioned in Ablation Study</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#appendix-b-additional-qualitative-results">Appendix B Additional Qualitative Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2411.00774_Freeze-Omni.html">2411.00774_Freeze-Omni: A Smart and Low Latency Speech-to-speech Dialogue Model with Frozen LLM</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2411.00774_Freeze-Omni.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2411.00774_Freeze-Omni.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2411.00774_Freeze-Omni.html#model">2. Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2411.00774_Freeze-Omni.html#experience">3. Experience</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2411.00774_Freeze-Omni.html#conclusion-and-future-work">4. Conclusion and Future Work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html">2412.04468_NVILA: Efficient Frontier Visual Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html#approach">2. Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html#more-capabilities">4. More Capabilities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2502.13923_Qwen2.5-VL.html">2502.13923_Qwen2.5-VL</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2502.13923_Qwen2.5-VL.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2502.13923_Qwen2.5-VL.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2502.13923_Qwen2.5-VL.html#approach">2. Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2502.13923_Qwen2.5-VL.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2502.13923_Qwen2.5-VL.html#conclusion">4. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html">2503.20215_Qwen2.5-Omni Technical Report</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#archtecture">2. Archtecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#id2">3 é¢„è®­ç»ƒ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#post-training">4 åè®­ç»ƒï¼ˆPost-trainingï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html">2506.13642_Stream-Omni: Simultaneous Multimodal Interactions with Large Language-Vision-Speech Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#id4">3. Stream-Omni</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#results-and-analyses">5. Results and Analyses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#appendix-a-construction-of-instructomni">Appendix A Construction of InstructOmni</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#appendix-b-construction-of-spokenvisit">Appendix B Construction of SpokenVisIT</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html">2506.13642_Stream-Omni: Simultaneous Multimodal Interactions with Large Language-Vision-Speech Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#id9">3 Stream-Omni</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#data-construction">3.2.1 Data Construction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#results-and-analyses">5 Results and Analyses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#limitations">Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#appendix-a-construction-of-instructomni">Appendix A Construction of InstructOmni</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#appendix-b-construction-of-spokenvisit">Appendix B Construction of SpokenVisIT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#appendix-c-case-study">Appendix C Case Study</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM.html#embedding">Embedding æ¨¡å‹</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMEmbeddings/2506.05176_Qwen3_Embedding.html">2506.05176_Qwen3_Embedding: Advancing Text Embedding and Reranking Through Foundation Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMEmbeddings/2506.05176_Qwen3_Embedding.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMEmbeddings/2506.05176_Qwen3_Embedding.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMEmbeddings/2506.05176_Qwen3_Embedding.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMEmbeddings/2506.05176_Qwen3_Embedding.html#model-architecture">2 Model Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMEmbeddings/2506.05176_Qwen3_Embedding.html#models-training">3 Models Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMEmbeddings/2506.05176_Qwen3_Embedding.html#evaluation">4 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMEmbeddings/2506.05176_Qwen3_Embedding.html#settings">4.1 Settings è¯„ä¼°è®¾ç½®</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMEmbeddings/2506.05176_Qwen3_Embedding.html#main-results">4.2 Main Results ä¸»è¦ç»“æœ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMEmbeddings/2506.05176_Qwen3_Embedding.html#analysis">4.3 Analysis åˆ†æ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMEmbeddings/2506.05176_Qwen3_Embedding.html#id21">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMEmbeddings/2506.05176_Qwen3_Embedding.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMEmbeddings/2506.05176_Qwen3_Embedding.html#appendix-a-appendix">Appendix A Appendix</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM.html#id3">LLM éŸ³é¢‘</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2005.08100_Conformer.html">2005.08100_Conformer: Convolution-augmented Transformer for Speech Recognition</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2005.08100_Conformer.html#llm">LLMæ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2005.08100_Conformer.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2005.08100_Conformer.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2005.08100_Conformer.html#conformer-encoder">2 Conformer Encoder</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2005.08100_Conformer.html#experiments">3 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2005.08100_Conformer.html#conclusion">4 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html">2106.07447_HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#i-introduction">I Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#ii-method">II Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#iii-related-work">III Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#iv-experimental-details">IV Experimental Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#v-results">V Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#vi-conclusion">VI Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html">2112.02418_YourTTS: Towards Zero-Shot Multi-Speaker TTS and Zero-Shot Voice Conversion for everyone</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#id1">å…³é”®æ¦‚å¿µ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#yourtts-model">2. YourTTS Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#results-and-discussion">4. Results and Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#zero-shot-voice-conversion">5. Zero-Shot Voice Conversion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#speaker-adaptation">6. Speaker Adaptation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#conclusions-limitations-and-future-work">7. Conclusions, limitations and future work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html">2212.04356_whisper: Robust Speech Recognition via Large-Scale Weak Supervision</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#approach">2. Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#analysis-and-ablations">4. Analysis and Ablations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#limitations-and-future-work">6. Limitations and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#conclusions">7. Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#a-evaluation-datasets">A. Evaluation Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#b-compared-models">B Compared Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#c-text-standardization">C. Text Standardization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html">2301.02111_Vall-E: Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html#background-speech-quantization">3. Background: Speech Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html#id9">4. VALL-E</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html#conclusion-limitations-and-future-work">6. Conclusion, Limitations, and Future Work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html">2303.03926_VALL-E_X: Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural Codec Language Modeling</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#cross-lingual-codec-language-model">3 Cross-Lingual Codec Language Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#vall-e-x-application">4. VALL-E X Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#a-appendix">A. Appendix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2406.05370_VALL-E2.html">2406.05370_VALL-E2: Neural Codec Language Models are Human Parity Zero-Shot Text to Speech Synthesizers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2406.05370_VALL-E2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2406.05370_VALL-E2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2406.05370_VALL-E2.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2406.05370_VALL-E2.html#id5">3. VALL-E 2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2406.05370_VALL-E2.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2406.05370_VALL-E2.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2407.05407_CosyVoice.html">2407.05407_CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.05407_CosyVoice.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.05407_CosyVoice.html#instructions">1. Instructions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.05407_CosyVoice.html#cosyvoice-a-scalable-tts-model-using-supervised-semantic-tokens">2. CosyVoice: A Scalable TTS model using Supervised Semantic Tokens</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.05407_CosyVoice.html#dataset">3. Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.05407_CosyVoice.html#experimental-settings">4. Experimental Settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.05407_CosyVoice.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2407.10759_Qwen2-Audio.html">2407.10759_Qwen2-Audio Technical Report</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.10759_Qwen2-Audio.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.10759_Qwen2-Audio.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.10759_Qwen2-Audio.html#methodology">2. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.10759_Qwen2-Audio.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.10759_Qwen2-Audio.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html">2410.00037_Moshi: a speech-text foundation model for real-time dialogue</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#model">3.Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#datasets-and-training">4. Datasets and Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#safety">6.Safety</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#conclusion">7.Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2412.10117_CosyVoice2.html">2412.10117_CosyVoice2: Scalable Streaming Speech Synthesis with Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2412.10117_CosyVoice2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2412.10117_CosyVoice2.html#instroduction">1. Instroduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2412.10117_CosyVoice2.html#id5">2. CosyVoice 2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2412.10117_CosyVoice2.html#experimental-settings">3. Experimental Settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2412.10117_CosyVoice2.html#experimental-results">4. Experimental Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2412.10117_CosyVoice2.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html">2501.06282_MinMo: A Multimodal Large Language Model for Seamless Voice Interaction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#instruction">1.Instruction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#id9">3.MinMo</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#experiments">4.Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#conclusion">5.Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#limitations">6.Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#a-prompts-for-voice-understanding-tasks">A. Prompts for Voice Understanding Tasks</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2505.02707_Voila.html">2505.02707_Voila: Voice-Language Foundation Models for Real-Time Autonomous Interaction and Voice Role-Play</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.02707_Voila.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.02707_Voila.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.02707_Voila.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.02707_Voila.html#voila-voice-language-foundation-models">3. Voila: Voice-Language Foundation Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.02707_Voila.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.02707_Voila.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html">2505.17589_CosyVoice3: Towards In-the-wild Speech Generation via Scaling-up and Post-training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#id3">2.CosyVoice 3</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#the-multilingual-data-pipeline">3.The Multilingual Data Pipeline</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#experimental-settings">4.Experimental Settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#experimental-results">5.Experimental Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#conclusion">6.Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#limitations">7.Limitations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM.html#id4">LLM è§†é¢‘</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html">2301.12597_BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#bootstrapping-language-image-pre-training-with-frozen-image-encoders-and-large-language-models">Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#method">3 Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#experiment">4 Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#limitation">5 Limitation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#conclusion">6 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html">2308.01390_OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#id1">OpenFlamingo_ An Open-Source Framework for Training Large Autoregressive Vision-Language Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#related-work">2 Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#approach">3 Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#results">4 Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#discussion">5 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#appendix-a-extended-results">Appendix A Extended results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#appendix-b-additional-notes-on-filtering-mmc4">Appendix B Additional notes on filtering MMC4</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#appendix-c-synthetic-data-prompt">Appendix C Synthetic data prompt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#appendix-d-image-credits">Appendix D Image credits</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM.html#llm-moe">LLM MoE</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMoEs/2408.15664_AUXILIARY-LOSS-FREE_LB.html">2408.15664_AUXILIARY-LOSS-FREE LOAD BALANCING STRATEGY FOR MIXTURE-OF-EXPERTS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMoEs/2410.07490_MoDEM.html">2410.07490_MoDEM: Mixture of Domain Expert Models</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM.html#id5">å•†ä¸šæ¨¡å‹</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2303.08774_GPT4.html">2303.08774_GPT-4 Technical Report</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html">2312.11805_Gemini: A Family of Highly Capable Multimodal Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#model-architecture">2. Model Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#training-infrastructure">3. Training Infrastructure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#post-training-models">6. Post-Training Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#responsible-deployment">7. Responsible Deployment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#discussion-and-conclusion">8. Discussion and Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2403.05530_Gemini1.5.html">2403.05530_Gemini1.5: Unlocking multimodal understanding across millions of tokens of context</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html">2406.02430_Seed-TTS: A Family of High-Quality Versatile Speech Generation Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#method">2 Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#experiments">3 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#model-extensions">4 Model extensions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#model-applications-limitations-and-safety">5 Model applications, limitations, and safety</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#authors-alphabetical-order">6 Authors (alphabetical order)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#acknowledgement">7 Acknowledgement</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html">2407.04675_Seed-ASR: Understanding Diverse Speech and Contexts with LLM-based Speech Recognition</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html#motivation">2 Motivation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html#methods">3 Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html#model-and-evaluation">4 Model and Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html#appendix-a-appendix">Appendix A Appendix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2503.20020_Gemini2.html">2503.20020_Gemini2: Gemini Robotics: Bringing AI into the Physical World</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2504.xxxxx_Seed-Thinking-v1.5.html">2504.xxxxx_Seed-Thinking-v1.5: Advancing Superb Reasoning Models with Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html">2505.07062_Seed1.5-VL Technical Report</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#id1">Seed1.5-VL Technical Report</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#architecture">2 Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#pre-training">3 Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#training-recipe">3.2 Training Recipe</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#post-training">4 Post-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#hybrid-reinforcement-learning">4.4 Hybrid Reinforcement Learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#training-infrastructure">5 Training Infrastructure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#evaluation">6 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#video-task-evaluation">6.1.3 Video Task Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#comparison-with-state-of-the-arts">6.3.2 Comparison with State-of-the-arts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#conclusion-and-next-steps">7 Conclusion and Next Steps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#contributions-and-acknowledgments">8 Contributions and Acknowledgments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#qualitative-examples">9 Qualitative examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#visual-reasoning-visual-pattern-recognition">9.7 Visual Reasoning_ Visual Pattern Recognition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#failure-cases-combinatorial-search-i">9.19 Failure Cases_ Combinatorial Search I</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#evaluation-details">10 Evaluation Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#dream-1k">DREAM-1K</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM_tech.html">LLM å‘¨è¾¹æŠ€æœ¯</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#framework">Framework</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html">1712.05889_Ray: A Distributed Framework for Emerging AI Applications</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#motivation-and-requirements">2. Motivation and Requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#programming-and-computation-model">3. Programming and Computation Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#architecture">4. Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#related-work">6 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#discussion-and-experiences">7 Discussion and Experiences</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#conclusion">8. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html">1910.02054_DeepSpeed_ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#extended-introduction">1. Extended Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#where-did-all-the-memory-go">3 Where Did All the Memory Go?</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#zero-insights-and-overview">4 ZeRO: Insights and Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#deep-dive-into-zero-dp">5 Deep Dive into ZeRO-DP</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#deep-dive-into-zero-r">6 Deep Dive into ZeRO-R</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#communication-analysis-of-zero-dp">7 Communication Analysis of ZeRO-DP</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#communication-analysis-of-zero-r">8. Communication Analysis of ZeRO-R</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#step-towards-1-trillion-parameters">9. Step Towards 1 Trillion Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#implementation-and-evaluation">10. Implementation and Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#concluding-remarks">11. Concluding Remarks</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Frameworks/19XX_PyTorch.html">PyTorch: An Imperative Style, High-Performance Deep Learning Library</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Frameworks/20XX_Transformers.html">Transformers: State-of-the-Art Natural Language Processing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html">2210.XX_Ray v2 Architecture</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#architecture-overview">Architecture Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#object-management">Object Management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#task-management">Task Management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#resource-management-and-scheduling">Resource Management and Scheduling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#actor-management">Actor management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#global-control-service">Global Control Service</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#cluster-management">Cluster Management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#appendix">Appendix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html">2309.06180_vLLM: Efficient Memory Management for Large Language Model Serving with PagedAttention</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#id2">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#memory-challenges-in-llm-serving">3. Memory Challenges in LLM Serving</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#method">4. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#implementation">5. Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#evaluation">6. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#ablation-studies">7. Ablation Studies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#conclusion">10. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html">2312.07104_SGLangâ‡ï¸: Efficient Execution of Structured Language Model Programs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#openai-gpt-4">OpenAI GPT-4æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#qwen-plus">Qwen-Plusæ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#programming-model">2 Programming Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#efficient-kv-cache-reuse-with-radixattention">3 Efficient KV Cache Reuse with RadixAttention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#efficient-constrained-decoding-with-compressed-finite-state-machine">4 Efficient Constrained Decoding with Compressed Finite State Machine</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#efficient-endpoint-calling-with-api-speculative-execution">5 Efficient Endpoint Calling with API Speculative Execution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#evaluation">6 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#related-work">7 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#future-directions-and-conclusion">8 Future Directions and Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#acknowledgement">Acknowledgement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#appendix-a-additional-details-on-radixattention">Appendix A Additional Details on RadixAttention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#appendix-b-additional-details-on-compressed-finite-state-machine">Appendix B Additional Details on Compressed Finite State Machine</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#appendix-c-additional-experimental-setups-and-results">Appendix C Additional Experimental Setups and Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#appendix-d-compiler-mode">Appendix D Compiler Mode</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#appendix-d">Appendix D ç¼–è¯‘å™¨æ¨¡å¼</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#id2">å¤§æ¨¡å‹è°ƒä¼˜</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2101.00190_Prefix-Tuning.html">2101.00190_Prefix-Tuning: Optimizing Continuous Prompts for Generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2103.10385_p-tuning.html">2103.10385_p-tuning: GPT Understands, Too</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2104.08691_Prompt_Tuning.html">2104.08691_Prompt Tuning: The Power of Scale for Parameter-Efficient Prompt Tuning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2106.09685_LoRA.html">2106.09685_LoRA: Low-Rank Adaptation of Large Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2401.01335_Self-Play.html">2401.01335_Self-Play: Fine-Tuning Converts Weak Language Models to Strong Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2402.09353_DoRA.html">2402.09353_DoRA: Weight-Decomposed Low-Rank Adaptation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2402.12354_LoRA%2B.html">2402.12354_LoRA+: Efficient Low Rank Adaptation of Large Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2403.03507_GaLore.html">2403.03507_GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2403.13372_LlamaFactory.html">2403.13372_LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/FineTunes/2403.13372_LlamaFactory.html#id2">ç«äº‰æ¡†æ¶</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/FineTunes/2403.13372_LlamaFactory.html#efficient-fine-tuning-techniques">3. Efficient Fine-Tuning Techniques</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/FineTunes/2403.13372_LlamaFactory.html#llamafactory-framework">4 LlamaFactory Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/FineTunes/2403.13372_LlamaFactory.html#conclusion-and-future-work">6 Conclusion and Future Work</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#id3">å¤§æ¨¡å‹ç¼–è¾‘</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html">2405.16720_LAW: Large Scale Knowledge Washing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#preliminary">3 Preliminary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#problem-setup">4 Problem Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#methodology">5 Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#experiments">6 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#id25">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#conclusion-limitation-and-future-work">7 Conclusion, Limitation, and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#ethics-statement">Ethics Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#reproducibility-statement">Reproducibility Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#appendix-a-mathematical-details-of-preliminary">Appendix A Mathematical Details of Preliminary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#appendix-b-implementation-details">Appendix B Implementation Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#appendix-c-additional-experiments">Appendix C Additional Experiments</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.00487_SELF-PARAM.html">2410.00487_SELF-PARAM: Self-Updatable Large Language Models by Integrating Context into Model Parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.00487_SELF-PARAM.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.00487_SELF-PARAM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.00487_SELF-PARAM.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.00487_SELF-PARAM.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.00487_SELF-PARAM.html#methodology">3 Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.00487_SELF-PARAM.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.00487_SELF-PARAM.html#conclusion-and-future-work">5 Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.00487_SELF-PARAM.html#ethics-statement">Ethics Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.00487_SELF-PARAM.html#reproducibility-statement">Reproducibility Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.00487_SELF-PARAM.html#appendix-a-additional-settings">Appendix A Additional Settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.00487_SELF-PARAM.html#appendix-b-additional-experiments">Appendix B Additional Experiments</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html">2410.02355_AlphaEdit: Null-Space Constrained Knowledge Editing for Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#preliminary">2 Preliminary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#method">3 Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#experiment">4 Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#related-work">5 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#limitations-future-discussion">6 Limitations &amp; Future Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#ethics-statement">Ethics Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#reproducibility">Reproducibility</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#acknowledgement">Acknowledgement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#appendix-a-experimental-setup">Appendix A Experimental Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#appendix-b-implementation-details-of-current-model-editing-related-proofs">Appendix B Implementation Details of Current Model Editing &amp; Related Proofs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#appendix-c-more-experimental-results">Appendix C More Experimental Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#appendix-d-visualizing-the-counterfact-and-zsre-datasets-through-examples">Appendix D Visualizing the Counterfact and ZSRE Datasets Through Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#id4">åˆ†å¸ƒå¼æ¨¡å‹</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/1701.06538_MoE.html">1701.06538_MoE: Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/1806.03377_PipeDream.html">1806.03377_PipeDream: Fast and Efficient Pipeline Parallel DNN Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1806.03377_PipeDream.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1806.03377_PipeDream.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1806.03377_PipeDream.html#background-related-work">2. Background &amp; Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1806.03377_PipeDream.html#parallel-training-in-pipedream">3. Parallel Training in PipeDream</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1806.03377_PipeDream.html#implementation">4. Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1806.03377_PipeDream.html#evaluation">5. Evaluation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html">1811.06965_GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html#id2">æ”¶é›†</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html#the-gpipe-library">2. The GPipe Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html#performance-analyses">3. Performance Analyses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html#image-classification">4. Image Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html#massive-massively-multilingual-machine-translation">5. Massive Massively Multilingual Machine Translation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html#design-features-and-trade-offs">6. Design Features and Trade-Offs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/1909.08053_Megatron-LM.html">1909.08053_Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1909.08053_Megatron-LM.html#id2">æ”¶é›†</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1909.08053_Megatron-LM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1909.08053_Megatron-LM.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1909.08053_Megatron-LM.html#background-and-challenges">2. Background and Challenges</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1909.08053_Megatron-LM.html#model-parallel-transformers">3. Model Parallel Transformers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html">19xx_PipeDream: Generalized Pipeline Parallelism for DNN Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html#id2">æ”¶é›†</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html#abstract">ABSTRACT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html#background-and-related-work">2. BACKGROUND AND RELATED WORK</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html#pipeline-parallelism">3. æµæ°´çº¿å¹¶è¡Œ(PIPELINE PARALLELISM)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html#id5">4. å®ç°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html#id6">6. ç»“è®º</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/2006.09503_PipeDream-2BW.html">2006.09503_PipeDream-2BW: Memory-Efficient Pipeline-Parallel DNN Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2006.09503_PipeDream-2BW.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/2006.15704DataParallel.html">2006.15704_PyTorch Distributed: Experiences on Accelerating Data Parallel Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/2006.16668_GShard.html">2006.16668_GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/2104.04473_Megatron-LM2.html">2104.04473_Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2104.04473_Megatron-LM2.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html">2205.14135_FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#background">2 Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#flashattention-algorithm-analysis-and-extensions">3. FLASHATTENTION: Algorithm, Analysis, and Extensions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#limitations-and-future-directions">5. Limitations and Future Directions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#appendix-a-related-work">Appendix A Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#appendix-b-algorithm-details">Appendix B Algorithm Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#appendix-c-proofs">Appendix C Proofs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#appendix-d-extension-details">Appendix D Extension Details</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/2307.08691_FlashAttention2.html">2307.08691_FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2307.08691_FlashAttention2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2307.08691_FlashAttention2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2307.08691_FlashAttention2.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2307.08691_FlashAttention2.html#flashattention-2-algorithm-parallelism-and-work-partitioning">3. FlashAttention-2: Algorithm, Parallelism, and Work Partitioning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2307.08691_FlashAttention2.html#empirical-validation">4. Empirical Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2307.08691_FlashAttention2.html#discussion-and-future-directions">5. Discussion and Future Directions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/normal.html">é€šç”¨</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#id5">LLM é‡åŒ–</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/0normal.html">é€šç”¨</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/0normal.html#id2">æ··åˆç²¾åº¦</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/0normal.html#id3">æµ®ç‚¹æ•°æ ¼å¼</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/0normal.html#weight-only-quantization">weight-only quantization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2110.02861_bitsandbytes.html">2110.02861_bitsandbytes: 8-bit Optimizers via Block-wise Quantization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2110.02861_bitsandbytes.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2110.02861_bitsandbytes.html#background">1. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2110.02861_bitsandbytes.html#bit-optimizers">2. 8-bit Optimizers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2110.02861_bitsandbytes.html#bit-vs-32-bit-optimizer-performance-for-common-benchmarks">3. 8-bit vs 32-bit Optimizer Performance for common Benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2110.02861_bitsandbytes.html#analysis">4. Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2110.02861_bitsandbytes.html#related-work">5. Related Work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html">2206.01861_ZeroQuant: Efficient and Affordable Post-Training Quantization for Large-Scale Transformers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#relative-work">2. Relative Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#background-and-challenges">3. Background and Challenges</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#methodology">4. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#results">5. Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#conclusions">6. Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#appendix-a-background">Appendix A Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#appendix-d-details-about-system-optimization">Appendix D Details about System Optimization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html">2206.09557_LUT-GEMM: Quantized Matrix Multiplication based on LUTs for Efficient Inference in Large-Scale Generative Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#instructions">1. Instructions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#design-methodology-of-lut-gemm">3. Design Methodology of LUT-GEMM</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#experimental-results">4. Experimental results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#accelerating-quantized-opt-175b">5. Accelerating Quantized OPT-175B</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#appendix-a-llm-inference-latency-breakdown">Appendix A LLM Inference Latency Breakdown</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#appendix-b-detailed-implementation">Appendix B Detailed Implementation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html">2208.07339_LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#id1">ç›¸å…³å‚è€ƒ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#int8-matrix-multiplication-at-scale">3. Int8 Matrix Multiplication at Scale</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#emergent-large-magnitude-features-in-transformers-at-scale">4. Emergent Large Magnitude Features in Transformers at Scale</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#discussion-and-limitations">6. Discussion and Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#broader-impacts">7. Broader Impacts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#id17">å…¶ä»–</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html">2209.05433_FP8: FP8 Formats For Deep Learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html#aspects-of-fp8-usage-in-deep-learning">2. Aspects of FP8 Usage in Deep Learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html#fp8-binary-interchange-format">3. FP8 Binary Interchange Format</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html#id3">ç¤ºä¾‹è®²è§£</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html#empirical-results">4. Empirical Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html#conclusions">5. Conclusions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html">2210.17323_GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html#background">3. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html#the-gptq-algorithm">4. The GPTQ Algorithm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html#experimental-validation">5. Experimental Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html#summary-and-limitations">6. Summary and Limitations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html">2211.10438_SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#preliminaries">2. Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#review-of-quantization-difficulty">3. Review of Quantization Difficulty</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#id9">4. SmoothQuant</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#related-work">6. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#conclusion">7. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#appendix-a-discussion-on-weight-only-quantization">Appendix A. Discussion on Weight-Only Quantization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html">2305.14314_QLoRA: Efficient Finetuning of Quantized LLMs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#id1">å…³é”®è¯</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#qlora-finetuning">3. QLoRA Finetuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#qlora-vs-standard-finetuning">4. QLoRA vs. Standard Finetuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#pushing-the-chatbot-state-of-the-art-with-qlora">5. Pushing the Chatbot State-of-the-art with QLoRA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#qualitative-analysis">6. Qualitative Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#related-work">7. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#limitations-and-discussion">8. Limitations and Discussion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html">2306.00978_AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html#awq-activation-aware-weight-quantization">3. AWQ: Activation-aware Weight Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html#tinychat-mapping-awq-onto-edge-platforms">4. TinyChat: Mapping AWQ onto Edge Platforms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2309.05516_AutoRound.html">2309.05516_AutoRound: Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2309.05516_AutoRound.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2309.05516_AutoRound.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2309.05516_AutoRound.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2309.05516_AutoRound.html#methodology">3. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2309.05516_AutoRound.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2309.05516_AutoRound.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#id6">å›¾ç¥ç»ç½‘ç»œæ¨¡å‹</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html">1812.08434_GNNs: Graph Neural Networks: A Review of Methods and Applications</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#id1">è®ºæ–‡è§£è¯»</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#id4">ç»“è®º</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#general-design-pipeline-of-gnns">2. General design pipeline of GNNs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#instantiations-of-computational-modules">3. Instantiations of computational modules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#variants-considering-graph-type-and-scale-gnn">4. Variants considering graph type and scale(ä¸åŒå›¾ç±»å‹ä¸è§„æ¨¡çš„GNNå˜ä½“)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#variants-for-different-training-settings">5. Variants for different training settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#a-design-example-of-gnn">6. A design example of GNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#analyses-of-gnns">7. Analyses of GNNs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#applications">8. Applications</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#vs">âœ… æ€»ç»“è¡¨æ ¼ï¼ˆå›¾åƒ vs æ–‡æœ¬ï¼‰ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#open-problems">9. Open problems</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#conclusion">10. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#appendix-a-datasets">Appendix A. Datasets</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#id7">LLM å®‰å…¨</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Securitys/2312.06674_Llama_Guard.html">2312.06674_Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#id8">LLMå¼ºåŒ–å­¦ä¹ </a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/RLs/1703.03864_EvolutionStrategies.html">1703.03864_Evolution Strategies: as a Scalable Alternative to Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html">2305.14387_AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#background-problem-statement">2 Background &amp; problem statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#id14">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#constructing-the-alpacafarm">3 Constructing the AlpacaFarm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#validating-the-alpacafarm-simulator">4 Validating the AlpacaFarm simulator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#benchmarking-reference-methods-on-the-alpacafarm">5 Benchmarking reference methods on the AlpacaFarm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#related-work">6 Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#limitations-and-future-directions">7 Limitations and future directions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#acknowledgments-and-disclosure-of-funding">Acknowledgments and Disclosure of Funding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#appendix-a-reference-lpf-methods-on-alpacafarm">Appendix A Reference LPF methods on AlpacaFarm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#appendix-b-details-on-methods-implementation-and-hyperparameters">Appendix B Details on methods implementation and hyperparameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#appendix-c-pairwise-preference-simulation">Appendix C Pairwise preference simulation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#id36"><strong>æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#appendix-d-details-on-human-data-collection">Appendix D Details on human data collection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#appendix-e-additional-results">Appendix E Additional results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#appendix-f-additional-analysis-on-training-and-evaluation-instructions">Appendix F Additional Analysis on Training and Evaluation Instructions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html">2504.02495_DeepSeek-GRM: Inference-Time Scaling for Generalist Reward Modeling</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#preliminaries">2. Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#self-principled-critique-tuning-spct">3. Self-Principled Critique Tuning (SPCT)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#inference-time-scaling-with-spct">4. Inference-Time Scaling with SPCT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#results-on-reward-modeling-benchmarks">5. Results on Reward Modeling Benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#related-work">6. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#conclusion-and-future-work">7. Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#a-additional-related-work">A. Additional Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#b-limitations-and-future-directions">B. Limitations and Future Directions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#g-prompt-templates">G. Prompt Templates</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/RLs/2504.13958_ToolRL.html">2504.13958_ToolRL: Reward is All Tool Learning Needs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#id9">å…¶ä»–</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html">2203.02155_Training language models to follow instructions with human feedback(InstructGPT)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#related-work">2. Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#methods-and-experimental-details">3. Methods and experimental details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#results">4. Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#discussion">5. Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#appendix-a-additional-prompt-data-details">Appendix A Additional prompt data details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#appendix-b-additional-human-data-collection-details">Appendix B Additional human data collection details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#appendix-c-additional-model-details">Appendix C Additional model details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#appendix-d-automatic-evaluation-details">Appendix D Automatic evaluation details</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/others/2305.20050_LetsVerifyStepbyStep.html">2305.20050_Letâ€™s Verify Step by Step</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2305.20050_LetsVerifyStepbyStep.html#id2">1. ç ”ç©¶èƒŒæ™¯</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2305.20050_LetsVerifyStepbyStep.html#id3">2. ç›‘ç£æ–¹æ³•å¯¹æ¯”</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2305.20050_LetsVerifyStepbyStep.html#id4">3. æ ¸å¿ƒå‘ç°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2305.20050_LetsVerifyStepbyStep.html#id5">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/others/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html">2408.03314_Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html#how-to-scale-test-time-computation-optimally">3. How to Scale Test-Time Computation Optimally</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html#scaling-test-time-compute-via-verifiers">5. Scaling Test-Time Compute via Verifiers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html#refining-the-proposal-distribution">6. Refining the Proposal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html#id7">å…¶ä»–</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html">2412.14135_Scaling of Search and Learning: A Roadmap to Reproduce o1 from Reinforcement Learning Perspective</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#fromgpt">FromGPT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#id2">3. Policy Initialization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#id3">4. Reward Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#id5">5. Search</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#id8">6. Learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#open-source-o1-project">7 Open-source o1 Project</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#future-directions">8. Future Directions</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../ML.html">æœºå™¨å­¦ä¹ </a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../ML.html#id3">è¿‘é‚»æœç´¢</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ANNs/10xx.xxxxx_PQ.html">10xx.xxxxx_PQ: Product Quantization for Nearest Neighbor Search</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/10xx.xxxxx_PQ.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/10xx.xxxxx_PQ.html#from-deepseek">From Deepseek</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/10xx.xxxxx_PQ.html#id6">From Deepseek å…¨æ–‡æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/10xx.xxxxx_PQ.html#id7">å‘¨è¾¹æ¦‚å¿µ</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ANNs/1603.09320_HNSW.html">1603.09320_HNSW: Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/1603.09320_HNSW.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/1603.09320_HNSW.html#from-deepseek">From Deepseek</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/1603.09320_HNSW.html#id10">From Deepseek å…¨æ–‡æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ANNs/2007.00808_ANCE.html">2007.00808_ANCE: Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/2007.00808_ANCE.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/2007.00808_ANCE.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/2007.00808_ANCE.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/2007.00808_ANCE.html#preliminaries">2 Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/2007.00808_ANCE.html#analyses-on-the-convergence-of-dense-retrieval-training">3 Analyses on The Convergence of Dense Retrieval Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/2007.00808_ANCE.html#approximate-nearest-neighbor-noise-contrastive-estimation">4 Approximate Nearest Neighbor Noise Contrastive Estimation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/2007.00808_ANCE.html#experimental-methodologies">5 Experimental Methodologies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/2007.00808_ANCE.html#evaluation-results">6 Evaluation Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/2007.00808_ANCE.html#related-work">7 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/2007.00808_ANCE.html#conclusion">8 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/2007.00808_ANCE.html#appendix-a-appendix">Appendix A Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/2007.00808_ANCE.html#id31">æ€»ä½“æ€»ç»“</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../ML.html#embedding">Embedding</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/Embeddings/1603.09320_HNSW.html">1603.09320_HNSW: Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/1603.09320_HNSW.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/1603.09320_HNSW.html#from-deepseek">From Deepseek</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html">2004.04906_DPR: Dense Passage Retrieval for Open-Domain Question Answering</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#background">2 Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#dense-passage-retriever-dpr">3 Dense Passage Retriever (DPR)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#experimental-setup">4 Experimental Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#experiments-passage-retrieval">5 Experiments: Passage Retrieval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#experiments-question-answering">6 Experiments: Question Answering</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#related-work">7 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#conclusion">8 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#acknowledgments">Acknowledgments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#appendix-a-distant-supervision">Appendix A Distant Supervision</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#appendix-b-alternative-similarity-functions-triplet-loss">Appendix B Alternative Similarity Functions &amp; Triplet Loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#appendix-c-qualitative-analysis">Appendix C Qualitative Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#appendix-d-joint-training-of-retriever-and-reader">Appendix D Joint Training of Retriever and Reader</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/Embeddings/2205.12035_RetroMAE.html">2205.12035_RetroMAE: Pre-Training Retrieval-oriented Language Models Via Masked Auto-Encoder</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.12035_RetroMAE.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.12035_RetroMAE.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.12035_RetroMAE.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.12035_RetroMAE.html#related-works">2 Related works</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.12035_RetroMAE.html#methodology">3 Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.12035_RetroMAE.html#experimental-studies">4 Experimental Studies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.12035_RetroMAE.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.12035_RetroMAE.html#limitations">6 Limitations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html">2205.13147_MRL: Matryoshka Representation Learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#deepseek">DeepSeek æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#matryoshka-representation-learning">3 Matryoshka Representation Learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#applications">4 Applications</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#further-analysis-and-ablations">5 Further Analysis and Ablations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#discussion-and-conclusions">6 Discussion and Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#acknowledgments">Acknowledgments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#appendix-a-code-for-matryoshka-representation-learning">Appendix A Code for Matryoshka â€‹Representation â€‹Learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#appendix-b-datasets">Appendix B Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#appendix-c-matryoshka-representation-learning-model-training">Appendix C Matryoshka Representation Learning Model Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#appendix-d-classification-results">Appendix D Classification Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#appendix-e-image-retrieval">Appendix E Image Retrieval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#appendix-f-adaptive-retrieval">Appendix F Adaptive Retrieval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#appendix-g-few-shot-and-sample-efficiency">Appendix G Few-shot and Sample Efficiency</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#appendix-h-robustness-experiments">Appendix H Robustness Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#appendix-i-in-practice-costs">Appendix I In Practice Costs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#appendix-j-analysis-of-model-disagreement">Appendix J Analysis of Model Disagreement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#appendix-k-ablation-studies">Appendix K Ablation Studies</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../ML.html#ml-vision">ML Vision</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/1506.02640_YOLO.html">1506.02640_You Only Look Once: Unified, Real-Time Object Detection</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/1506.02640_YOLO.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/1612.08242_YOLO9000.html">1612.08242_YOLO9000: Better, Faster, Stronger</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/1612.08242_YOLO9000.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/1804.02767_YOLOv3.html">1804.02767_YOLOv3</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2004.10934_YOLOv4.html">2004.10934_YOLOv4: Optimal Speed and Accuracy of Object Detection</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2004.10934_YOLOv4.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2205.00159_SVTR.html">2205.00159_SVTR: Scene Text Recognition with a Single Visual Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2205.00159_SVTR.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2205.00159_SVTR.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2205.00159_SVTR.html#method">2. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2205.00159_SVTR.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2205.00159_SVTR.html#conclusion">4. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2207.02696_YOLOv7.html">2207.02696_YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2207.02696_YOLOv7.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2303.05499_GroundingDINO.html">Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2304.08485_VisualInstructionTuning.html">2304.08485_Visual Instruction Tuning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2402.13616_YOLOv9.html">2402.13616_YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2402.13616_YOLOv9.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2405.14458_YOLOv10.html">2405.14458_YOLOv10: Real-Time End-to-End Object Detection</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2405.14458_YOLOv10.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html">2411.15858_SVTRv2: CTC Beats Encoder-Decoder Models in Scene Text Recognition</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#id1">å®šä¹‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#methods">3. Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#conclusion">5. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#more-detail-of-real-world-datasets">8. More detail of real-world datasets</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../ML.html#ml">ML</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2108.00941_Human-in-the-loop.html">2108.00941_Human-in-the-loop: A Survey of Human-in-the-loop for Machine Learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ML_normals/2108.00941_Human-in-the-loop.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ML_normals/2108.00941_Human-in-the-loop.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ML_normals/2108.00941_Human-in-the-loop.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ML_normals/2108.00941_Human-in-the-loop.html#data-processing">2 Data Processing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ML_normals/2108.00941_Human-in-the-loop.html#model-training-and-inference">3 Model Training and Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ML_normals/2108.00941_Human-in-the-loop.html#system-construction-and-application">4 System construction and Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ML_normals/2108.00941_Human-in-the-loop.html#discussion-and-future-directions">5 Discussion and Future Directions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ML_normals/2108.00941_Human-in-the-loop.html#conclusion">6 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2112.09332_WebGPT.html">2112.09332_WebGPT: Browser-assisted question-answering with human feedback</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2203.11147_GopherCite.html">2203.11147_GopherCite: Teaching language models to support answers with verified quotes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2304.09848_Generative_Search.html">2304.09848_Generative_Search: Evaluating Verifiability in Generative Search Engines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2305.14251_FActScore.html">2305.14251_FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2305.14627_ALCE.html">2305.14627_ALCE: Enabling Large Language Models to Generate Text with Citations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ML_normals/2305.14627_ALCE.html#nli">NLI åœ¨å¼•ç”¨è´¨é‡è¯„ä¼°ä¸­çš„åº”ç”¨</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ML_normals/2305.14627_ALCE.html#prompt">è®ºæ–‡ä¸­ç”¨çš„prompt</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2307.02185_Citation.html">2307.02185_Citation: A Key to Building Responsible and Accountable Large Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2307.16883_HAGRID.html">2307.16883_HAGRID: A Human-LLM Collaborative Dataset for Generative Information-Seeking with Attribution</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../Agent.html">AI Agent</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Agent.html#agent">é€šç”¨ Agent</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2210.03629_ReAct.html">2210.03629_ReAct</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2303.08268_Chat-with-the-Environment.html">2303.08268_Chat-with-the-Environment</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2303.08268_Chat-with-the-Environment.html#id2">æ­£æ–‡</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2303.11366_Reflexion.html">2303.11366_Reflexion: Language Agents with Verbal Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2303.16434_TaskMatrix.AI.html">2303.16434_TaskMatrix.AI</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2303.16434_TaskMatrix.AI.html#id2">å¤§è„‘</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2303.16434_TaskMatrix.AI.html#id3">æ¥å£å¹³å°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2303.16434_TaskMatrix.AI.html#api">API é€‰æ‹©å™¨</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2304.03442_Generative-Agents.html">2304.03442_Generative-Agents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2304.03442_Generative-Agents.html#generative-agent-architecture">Generative Agent Architecture</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2307.07924_ChatDev.html">2307.07924_ChatDev: Communicative Agents for Software Development</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2308.00352_MetaGPT.html">2308.00352_MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2308.04026_AgentSims.html">2308.04026_AgentSims: An Open-Source Sandbox for Large Language Model Evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2308.08155_AutoGen.html">2308.08155_AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2308.10848_AgentVerse.html">2308.10848_AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2308.10848_AgentVerse.html#id2">ç†å¿µ</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2310.06117_Step-Back.html">2310.06117_Step-Back: Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html">2312.04511_LLMCompiler: An LLM Compiler for Parallel Function Calling</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#latency-optimization-in-llms-llms">2.1. Latency Optimization in LLMsï¼ˆLLMsçš„å»¶è¿Ÿä¼˜åŒ–ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#plan-and-solve-strategy">2.2. Plan and Solve Strategyï¼ˆè®¡åˆ’ä¸æ±‚è§£ç­–ç•¥ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#tool-augmented-llms-llms">2.3. Tool-Augmented LLMsï¼ˆå·¥å…·å¢å¼ºçš„LLMsï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#methodology">3. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#function-calling-planner">3.1. Function Calling Plannerï¼ˆåŠŸèƒ½è°ƒç”¨è§„åˆ’å™¨ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#task-fetching-unit">3.2. Task Fetching Unitï¼ˆä»»åŠ¡è·å–å•å…ƒï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#executor">3.3. Executorï¼ˆæ‰§è¡Œå™¨ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#dynamic-replanning">3.4. åŠ¨æ€é‡è§„åˆ’ï¼ˆDynamic Replanningï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#llmcompiler-details">4.LLMCompiler Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#user-supplied-information">4.1. ç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼ˆUser-Supplied Informationï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#planner-streamed-planner">4.2. æµå¼Plannerï¼ˆStreamed Plannerï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#results">5. Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#conclusions">6. Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#acknowledgements">è‡´è°¢ï¼ˆAcknowledgementsï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#a-accuracy-analysis-react-vs-llmcompiler">A. Accuracy Analysis: ReAct vs. LLMCompiler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#b-failure-case-analysis-of-llmcompiler">B. Failure Case Analysis of LLMCompiler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#c-related-work">C. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#d-experimental-details">D. Experimental Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#e-analysis">E. Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#id42"><strong>æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#f-additional-discussions-about-related-works">F. Additional Discussions about Related Works</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#g-user-supplied-examples-for-llmcompiler-configuration">G. User-Supplied Examples for LLMCompiler Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#g-1-movie-recommendation-example-prompts">G.1 ç”µå½±æ¨èç¤ºä¾‹æç¤ºè¯­ï¼ˆMovie Recommendation Example Promptsï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#g-2-24-game-of-24-example-prompts">G.2 24ç‚¹æ¸¸æˆç¤ºä¾‹æç¤ºè¯­ï¼ˆGame of 24 Example Promptsï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#h-pre-defined-llmcompiler-planner-prompts">H. Pre-defined LLMCompiler Planner Prompts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#i-parallelqa-benchmark-generation">I. ParallelQA Benchmark Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#j-details-of-the-game-of-24-and-the-tree-of-thoughts-approach">J. Details of the Game of 24 and the Tree-of-Thoughts Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#k-details-of-webshop-experiments">K. Details of WebShop Experiments</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2402.18679_MetaGPT_DI.html">2402.18679_MetaGPT_DI: Data Interpreter: An LLM Agent For Data Science</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2402.18679_MetaGPT_DI.html#introduction">INTRODUCTION</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2407.07061_IoA.html">2407.07061_IoA: Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2407.07061_IoA.html#overview-of-ioa">2.1 OVERVIEW OF IOA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2407.07061_IoA.html#architecture-of-ioa">2.2 ARCHITECTURE OF IOA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2407.07061_IoA.html#key-mechanisms">2.3 KEY MECHANISMS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2407.07061_IoA.html#putting-it-all-together">2.5 Putting It All Together</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2408.08435_ADAS.html">2408.08435_ADAS: Automated Design of Agentic Systems</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2408.08435_ADAS.html#prompt">Prompt</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2410.10762_AFlow.html">2408.08435_ADAS: Automating Agentic Workflow Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2410.10762_AFlow.html#introduce">Introduce</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2410.10762_AFlow.html#preliminary">PRELIMINARY</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2410.17238_SELA.html">2410.17238_SELA: Tree-Search Enhanced LLM Agents for Automated Machine Learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2410.17238_SELA.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2410.17238_SELA.html#related-works">2 Related Works</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2410.17238_SELA.html#method">3 Method</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2410.21012_FACT.html">2410.21012_FACT: Examining the Effectiveness of Iterative Context Rewriting for Multi-fact Retrieval</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2410.21012_FACT.html#introduce">Introduce</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2504.01990_foundation-agents.html">2504.01990_Advances and Challenges in Foundation Agents</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2506.12508_AgentOrchestra.html">2506.12508_AgentOrchestra: A Hierarchical Multi-Agent Framework for General-Purpose Task Solving</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2506.12508_AgentOrchestra.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2506.12508_AgentOrchestra.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2506.12508_AgentOrchestra.html#agentorchestra">3.AgentOrchestra</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2506.12508_AgentOrchestra.html#experiments">4.Experiments</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Agent.html#agent-aios">è§†è§‰ Agent&amp;AIOS</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2108.03353_Screen2Words.html">2108.03353_ Screen2Words: Automatic Mobile UI Summarization with Multimodal Learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2108.03353_Screen2Words.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2108.03353_Screen2Words.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2108.03353_Screen2Words.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2108.03353_Screen2Words.html#dataset-creation">3. Dataset Creation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2108.03353_Screen2Words.html#model-design">4. Model Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2108.03353_Screen2Words.html#id3">å…¶å®ƒ</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html">2209.08199_ScreenQA: Large-Scale Question-Answer Pairs over Mobile App Screenshots</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#problem-setting-tasks-and-metrics">3. Problem Setting: Tasks and Metrics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#data-annotation">4. Data Annotation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#dataset-analysis">5. Dataset Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#experiments-and-baselines">6. Experiments and Baselines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#conclusion">7. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#limitations">8. Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#ethical-considerations">9. Ethical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#a-data-annotation-details">A. Data Annotation Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#b-data-examples">B. Data Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html">2212.06817_RT-1: ROBOTICS TRANSFORMER FOR REAL-WORLD CONTROL AT SCALE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#abstract">ABSTRACT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#preliminaries">3. Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#system-overview">4. System Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#rt-1-robotics-transformer">5. RT-1: ROBOTICS TRANSFORMER</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#experiments">6. EXPERIMENTS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#conclusions-limitations-and-future-work">7. CONCLUSIONS, LIMITATIONS AND FUTURE WORK</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#b-model-card">B. MODEL CARD</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#c-model-and-data">C. MODEL AND DATA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#d-experiments">D. EXPERIMENTS</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2312.13771_AppAgent.html">2312.13771_AppAgent: Multimodal Agents as Smartphone Users</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2312.13771_AppAgent.html#environment-and-action-space">3.1 Environment and Action Space</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2312.13771_AppAgent.html#exploration-phase">3.2 Exploration Phase</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2312.13771_AppAgent.html#deployment-phase">3.3 Deployment Phase</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html">2401.10935_SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#related-work">2. Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#approach">3. Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#screenspot-a-grounding-benchmark">4. ScreenSpot: A Grounding Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#limitations">Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#ethical-considerations">Ethical considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#a-details-of-seeclick-pre-training">A. Details of SeeClick Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#b-screenspot-annotation-evaluation">B ScreenSpot Annotation &amp; Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#c-downstream-agent-tasks">C. Downstream Agent Tasks</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html">2402.04615_ScreenAI: A Vision-Language Model for UI and Infographics Understanding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#methodology">2. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#automatic-data-generation">3. Automatic data generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#data-mixtures">4. Data Mixtures</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#experiments-and-results">5. Experiments and Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#conclusions">6. Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#a-definitions-of-metrics">A Definitions of Metrics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#b-screen-schema-examples">B. Screen Schema Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#c-prompts-for-llm-generated-content">C. Prompts For LLM Generated Content</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#d-screen-navigation-generated-examples">D. Screen Navigation Generated Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#f-screenqa-short-answers-generation">F. ScreenQA Short Answers Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#g-complex-question-answering-datasets">G. Complex Question Answering Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#h-new-benchmarks-repositories">H. New Benchmarks Repositories</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html">2402.07939_UFO: A UI-Focused Agent for Windows OS Interaction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html#the-design-of-ufo">3.The Design of UFO</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html#experiment">4.Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html#limitations-lessons-learned">5.Limitations &amp; Lessons Learned</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html#conclusion">6.Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2403.16971_AIOS.html">2403.16971_AIOS: LLM Agent Operating System</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2403.16971_AIOS.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2403.16971_AIOS.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2403.16971_AIOS.html#the-architecture-of-aios">2. The Architecture of AIOS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2403.16971_AIOS.html#aios-kernel">3. AIOS Kernel</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2403.16971_AIOS.html#evaluation">4 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2403.16971_AIOS.html#appendix-e-discussion">Appendix E Discussion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2406.01014_Mobile-Agent-v2.html">2406.01014_Mobile-Agent-v2: Mobile Device Operation Assistant with Effective Navigation via Multi-Agent Collaboration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2411.00820_AutoGLM.html">2411.00820_AutoGLM: Autonomous Foundation Agents for GUIs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2411.00820_AutoGLM.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2411.00820_AutoGLM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2411.00820_AutoGLM.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2411.00820_AutoGLM.html#autoglm-techniques-and-insights">2 AutoGLM: Techniques and Insights</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2411.00820_AutoGLM.html#results">3 Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2411.00820_AutoGLM.html#id14">3.1 åœ¨ Web ä¸Šçš„è¯„ä¼°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2411.00820_AutoGLM.html#id15">3.2 åœ¨ Android ä¸Šçš„è¯„ä¼°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2411.00820_AutoGLM.html#conclusion">4 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2411.02059_TableGPT2.html">2411.02059_TableGPT2: A Large Multimodal Model with Tabular Data Integration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2411.02059_TableGPT2.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html">2501.11733_Mobile-Agent-E: Self-Evolving Mobile Assistant for Complex Tasks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#mobile-agent-e">2. Mobile-Agent-E</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#results">4. Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#conclusion-and-future-work">6. Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-a-full-trajectory-comparison-example-with-previous-sota">Appendix A Full Trajectory Comparison Example with Previous SOTA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-b-error-recovery-with-escalation-to-manager">Appendix B Error Recovery with Escalation to Manager</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-c-remaining-limitations">Appendix C Remaining Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-d-all-tasks-in-mobile-eval-e-benchmark">Appendix D All Tasks in Mobile-Eval-E Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-e-atomic-operation-space">Appendix E Atomic Operation Space</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-f-full-list-of-self-evolved-shortcuts">Appendix F Full list of Self-Evolved Shortcuts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-g-full-list-of-self-evolved-tips">Appendix G Full list of Self-Evolved Tips</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html">2501.12326_UI-TARS: Pioneering Automated GUI Interaction with Native Agents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html#evolution-path-of-gui-agents">2. Evolution Path of GUI Agents</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html#core-capabilities-of-native-agent-model">3. Core Capabilities of Native Agent Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html#ui-tars">4. UI-TARS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html#experiment">5. Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2502.14282_PC-Agent.html">2502.14282_PC-Agent: A Hierarchical Multi-Agent Collaboration Framework for Complex Task Automation on PC</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2502.14282_PC-Agent.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2502.14282_PC-Agent.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2502.14282_PC-Agent.html#pc-agent">2. PC-Agent</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2502.14282_PC-Agent.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2502.14282_PC-Agent.html#related-work">4. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2502.14282_PC-Agent.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html">2504.14603_UFO2: The Desktop AgentOS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#background">2.Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#system-design-of-ufo2">3.System Design of UFO2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#picture-in-picture-interface">4.Picture-in-Picture Interface</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#implementation-and-specialized-engineering-design">5.Implementation and Specialized Engineering Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#evaluation">6.Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#discussion-future-work">7.Discussion &amp; Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#related-work">8.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#conclusion">9.Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2508.04037_SEA.html">2508.04037_SEA: Self-Evolution Agent with Step-wise Reward for Computer Use</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2508.04037_SEA.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2508.04037_SEA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2508.04037_SEA.html#i-introduction">I Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2508.04037_SEA.html#i">I å¼•è¨€</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2508.04037_SEA.html#ii-related-works">II Related Works</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2508.04037_SEA.html#id7"><strong>II Related Works</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2508.04037_SEA.html#id8">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2508.04037_SEA.html#iii-method">III Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2508.04037_SEA.html#id9">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2508.04037_SEA.html#iv-experiments">IV Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2508.04037_SEA.html#iv">IV å®éªŒ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2508.04037_SEA.html#v-conclusion">V Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2508.04037_SEA.html#v">V ç»“è®º</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Agent.html#tools">Tools</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Tools/2205.00445_MRKL.html">2205.00445_MRKL</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Tools/2302.04761_Toolformer.html">2302.04761_Toolformer: Language Models Can Teach Themselves to Use Tools</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Tools/2303.17580_HuggingGPT.html">2303.17580_HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html">2307.16789_ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#llm">LLMæ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#dataset-construction">2 Dataset Construction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#experiments">3 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#related-work">4 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#appendix-a-implementation-details">Appendix A Implementation Details</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Agent.html#agi">AGI</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/AGIs/1905.10985_AI-GA.html">1905.10985_AI-GA: AI-generating algorithms, an alternate paradigm for producing general artificial intelligence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/AGIs/2408.06292_AI-Scientist.html">2408.06292_The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../RAG.html">RAG</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2005.11401_RAG_for_KI_NLP_task.html">2005.11401_Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html">2312.10997_Retrieval-Augmented Generation for Large Language Models: A Survey</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#ii-overview-of-rag">II. Overview of RAG</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#ii-a-naive-rag">II-A Naive RAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#ii-b-advanced-rag">II-B Advanced RAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#ii-c-modular-rag">II-C Modular RAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#ii-d-rag-vs-fine-tuning">II-D RAG vs Fine-tuning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iii-retrieval">III. Retrieval</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iii-a-retrieval-source">III-A Retrieval Source</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iii-b-indexing-optimization">III-B Indexing Optimization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iii-c-query-optimization">III-C Query Optimization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iii-d-embedding">III-D Embedding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iii-e-adapter">III-E Adapter</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iv-generation">IV. Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iv-a-context-curation">IV-A Context Curation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iv-b-llm-fine-tuning">IV-B LLM Fine-tuning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#v-augmentation-process-in-rag">V. Augmentation process in RAG</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#v-a-iterative-retrieval">V-A Iterative Retrieval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#v-b-recursive-retrieval">V-B Recursive Retrieval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#v-c-adaptive-retrieval">V-C Adaptive Retrieval</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vi-task-and-evaluation">VI. Task and Evaluation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vi-a-downstream-task">VI-A Downstream Task</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vi-b-evaluation-target">VI-B Evaluation Target</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vi-c-evaluation-aspects">VI-C Evaluation Aspects</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vi-d-evaluation-benchmarks-and-tools">VI-D Evaluation Benchmarks and Tools</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vii-discussion-and-future-prospects">VII. Discussion and Future Prospects</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vii-a-rag-vs-long-context">VII-A RAG vs Long Context</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vii-b-rag-robustness">VII-B RAG Robustness</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vii-c-hybrid-approaches">VII-C Hybrid Approaches</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vii-d-scaling-laws-of-rag">VII-D Scaling laws of RAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vii-e-production-ready-rag">VII-E Production-Ready RAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vii-f-multi-modal-rag">VII-F Multi-modal RAG</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2401.15884_CRAG.html">2401.15884_CRAG: Corrective Retrieval Augmented Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2403.14403_Adaptive-RAG.html">2403.14403_Adaptive-RAG</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html">2404.12457_RAGCache: Efficient Knowledge Caching for Retrieval-Augmented Generation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id1">æ€»ç»“</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#introduction">1. Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id2"><strong>1. å¼•è¨€æ¦‚è¿°</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id3"><strong>2. ç°æœ‰å·¥ä½œä¸å±€é™</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#ragcache"><strong>3. RAGCacheç³»ç»Ÿ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id4"><strong>4. å®éªŒç»“æœ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id5"><strong>5. ä¸»è¦è´¡çŒ®</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#background">2. Background</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#rag-system-characterization">3. RAG System Characterization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id6">ä¸€ã€æ€§èƒ½ç“¶é¢ˆåˆ†æ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id7">äºŒã€ä¼˜åŒ–æœºä¼šåˆ†æ â€”â€” ç¼“å­˜ä¸­é—´çŠ¶æ€</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id8">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#ragcache-overview">4. RAGCache Overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id9">ä¸»è¦å†…å®¹æ€»ç»“å¦‚ä¸‹ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id13">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#ragcache-design">5. RAGCache Design</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#cache-structure-and-replacement-policy">5.1. Cache Structure and Replacement Policy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#cache-aware-reordering">5.2. Cache-aware Reordering</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#dynamic-speculative-pipelining">5.3 åŠ¨æ€æ¨æµ‹æµæ°´çº¿ï¼ˆDynamic Speculative Pipeliningï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id27">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#implementation">6. Implementation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id28">ç³»ç»Ÿå®ç°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#pipelined-vector-search">å‘é‡æœç´¢ä¼˜åŒ–ï¼ˆPipelined Vector Searchï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#fault-tolerance">å®¹é”™æœºåˆ¶ï¼ˆFault Toleranceï¼‰</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#evaluation">7. Evaluation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id29">7.1 æ€»ä½“æ€§èƒ½</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id30">7.2 é€šç”¨è®¾ç½®ä¸‹çš„æ¡ˆä¾‹ç ”ç©¶</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id31">7.3 æ¶ˆèç ”ç©¶</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id32">7.4 è°ƒåº¦æ—¶é—´</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id33">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#discussion">8. Discussion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#related-work">9. Related Work</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#conclusion">10. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html">2404.16130_GraphRAG: From Local to Global: A GraphRAG Approach to Query-Focused Summarization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id1">æ€»ç»“</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#introduction">1 Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#background">2 Background</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#rag">2.1 RAGæ–¹æ³•ä¸ç³»ç»Ÿ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#llmrag">2.2 çŸ¥è¯†å›¾è°±åœ¨LLMä¸RAGä¸­çš„åº”ç”¨</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id2">2.3 è‡ªé€‚åº”åŸºå‡†æµ‹è¯•</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id3">2.4 RAGè¯„ä¼°æ ‡å‡†</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#methods">3 Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#graphrag"><strong>3.1 GraphRAG å·¥ä½œæµç¨‹</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id4"><strong>3.2 å…¨å±€ç†è§£é—®é¢˜ç”Ÿæˆ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id5"><strong>3.3 å…¨å±€ç†è§£è¯„ä¼°æ ‡å‡†</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id6"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#analysis">4 Analysis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id7">4.1 å®éªŒ1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id11">4.2 å®éªŒ2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id14">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#results">5 Results</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id15">5.1 å®éªŒä¸€ï¼šä¸åŒæ–¹æ³•åœ¨æ‘˜è¦ä»»åŠ¡ä¸­çš„è¡¨ç°æ¯”è¾ƒ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id18">5.2 å®éªŒäºŒï¼šåŸºäºå£°æ˜çš„æŒ‡æ ‡è¯„ä¼°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id20">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#discussion">6 Discussion</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id21">6.1 è¯„ä¼°æ–¹æ³•çš„å±€é™æ€§</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id22">6.2 æœªæ¥å·¥ä½œ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id23">æ›´å¹¿æ³›çš„å½±å“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#appendix-a-entity-and-relationship-extraction-approach">Appendix A Entity and Relationship Extraction Approach</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id24"><strong>1. å®ä½“ä¸å…³ç³»æŠ½å–æ–¹æ³•</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#self-reflection"><strong>2. è‡ªæˆ‘åæ€ï¼ˆSelf-Reflectionï¼‰æŠ€æœ¯</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id25"><strong>3. åˆ†å—å¤§å°ä¸æŠ½å–æ•ˆæœçš„å…³ç³»</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id26"><strong>4. å®éªŒç»“æœï¼ˆå›¾3ï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id27"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#appendix-b-example-community-detection">Appendix B Example Community Detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#appendix-c-context-window-selection">Appendix C Context Window Selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#appendix-d-example-answer-comparison">Appendix D Example Answer Comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#appendix-e-system-prompts">Appendix E System Prompts</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#e-1-element-instance-generation"><strong>E.1 å®ä½“å®ä¾‹ç”Ÿæˆï¼ˆElement Instance Generationï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#e-2-community-summary-generation"><strong>E.2 ç¤¾åŒºæ‘˜è¦ç”Ÿæˆï¼ˆCommunity Summary Generationï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#e-3-community-answer-generation"><strong>E.3 ç¤¾åŒºé—®é¢˜å›ç­”ç”Ÿæˆï¼ˆCommunity Answer Generationï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#e-4-global-answer-generation"><strong>E.4 å…¨å±€é—®é¢˜å›ç­”ç”Ÿæˆï¼ˆGlobal Answer Generationï¼‰</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#appendix-f-evaluation-prompts">Appendix F Evaluation Prompts</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#f-1-relative-assessment-prompt">F.1 Relative Assessment Prompt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#f-2-relative-assessment-metrics">F.2 Relative Assessment Metrics</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#appendix-g-statistical-analysis">Appendix G Statistical Analysis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id38">ç»Ÿè®¡æ–¹æ³•ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id39">ä¸»è¦ç»“æœæ€»ç»“ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id40">æ€»ä½“è¶‹åŠ¿ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id41">é‡è¦ç»“è®ºï¼š</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html">2405.16506_GRAG: Graph Retrieval-Augmented Generation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#id1">æ€»ç»“</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#introduction">1 Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#related-work">2 Related Work</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#prompt-tuning">2.1 Prompt Tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#llms">2.2 LLMsåœ¨å›¾ç›¸å…³ä»»åŠ¡ä¸­çš„åº”ç”¨</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#id2">2.3 å›¾ä¸Šçš„æ£€ç´¢æ–¹æ³•</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#problem-formalization">3 Problem Formalization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#methodology">4 Methodology</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#id3">æ¦‚è¿°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#id4">4.1 æ–‡æœ¬å­å›¾æ£€ç´¢</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#indexing">æ–‡æœ¬å­å›¾ç´¢å¼•ï¼ˆIndexingï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#ranking">æ–‡æœ¬å­å›¾æ’åºï¼ˆRankingï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#soft-pruning">æ–‡æœ¬å­å›¾è½¯å‰ªæï¼ˆSoft Pruningï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#id5">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#textual-graph-augmented-generation">4.2 Textual Graph Augmented Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#text-view-of-textual-graphs">1. æ–‡æœ¬è§†å›¾ï¼ˆText View of Textual Graphsï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#graph-view-of-textual-graphs">2. å›¾è§†å›¾ï¼ˆGraph View of Textual Graphsï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#generation-phase">3. ç”Ÿæˆé˜¶æ®µï¼ˆGeneration Phaseï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#id6">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#experiments">5 Experiments</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#id7">æ€»ç»“ï¼šç¬¬äº”ç«  å®éªŒéƒ¨åˆ†</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#limitations">7 Limitations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#acknowledgments">Acknowledgments</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#appendix-a-appendix">Appendix A Appendix</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#a"><strong>é™„å½•A æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#id13"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2406.13213_Multi-Meta-RAG.html">2406.13213_Multi-Meta-RAG: Improving RAG for Multi-Hop Queries using Database Filtering with LLM-Extracted Metadata</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html">2410.05779_LightRAG: Simple and Fast Retrieval-Augmented Generation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#id1">æ€»ç»“</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#introduction">1 Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#retrieval-augmented-generation">2 Retrieval-Augmented Generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#the-lightrag-architecture">3 The LightRAGÂ Architecture</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#lightrag">ä¸€ã€LightRAGæ¶æ„æ¦‚è¿°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#graph-based-text-indexing">äºŒã€åŸºäºå›¾çš„æ–‡æœ¬ç´¢å¼•ï¼ˆGraph-based Text Indexingï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#dual-level-retrieval-paradigm">ä¸‰ã€åŒå±‚æ£€ç´¢èŒƒå¼ï¼ˆDual-level Retrieval Paradigmï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#retrieval-augmented-answer-generation">å››ã€æ£€ç´¢å¢å¼ºçš„ç­”æ¡ˆç”Ÿæˆï¼ˆRetrieval-Augmented Answer Generationï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#id2">äº”ã€å¤æ‚åº¦åˆ†æ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#id3">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#evaluation">4 Evaluation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#experimental-settings"><strong>1. å®éªŒè®¾ç½®ï¼ˆ4.1 Experimental Settingsï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#lightrag-rag-4-2-rq1"><strong>2. LightRAG ä¸ç°æœ‰ RAG æ–¹æ³•çš„å¯¹æ¯”ï¼ˆ4.2 RQ1ï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#rq2"><strong>3. æ¶ˆèå®éªŒï¼ˆ4.3 RQ2ï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#id8"><strong>æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#case-study-rq3">4.4 Case Study (RQ3)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#rq3">4.4 æ¡ˆä¾‹ç ”ç©¶ï¼ˆRQ3ï¼‰æ€»ç»“ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#rq4">4.5 æ¨¡å‹æˆæœ¬ä¸é€‚åº”æ€§åˆ†æï¼ˆRQ4ï¼‰æ€»ç»“ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#id9">æ€»ä½“ç»“è®ºï¼š</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#related-work">5 Related Work</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#id10">ç¬¬5ç«  ç›¸å…³å·¥ä½œï¼ˆæ€»ç»“ï¼‰</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#appendix">7 Appendix</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html">2410.10450_KBLaM: Knowledge Base augmented Language Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#introduction">1. Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#related-work">2. Related work</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#background">3. Background</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#self-attention-layer">Self-attention layer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#augmenting-llm-with-the-kb">4. Augmenting LLM with the KB</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#knowledge-tokens">Knowledge tokens</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#rectangular-attention-injecting-knowledge-token-into-prompt-tokens">Rectangular Attention: Injecting knowledge token into prompt tokens</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#kb-length-generalization-through-attention-score-scaling">KB length generalization through attention score scaling</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#kb-instruction-tuning">5. KB instruction tuning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#experiments">6. EXPERIMENTS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#experiment-setting">6.1 EXPERIMENT SETTING</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#experiment-results">6.2 EXPERIMENT RESULTS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#id2">æ€»ç»“äº®ç‚¹</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#conclusion">7. CONCLUSION</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#limitations-and-future-work">8. LIMITATIONS AND FUTURE WORK</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#appendix-a-extended-related-work">Appendix A Extended related work</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#appendix-b-ablation-study">Appendix B Ablation study</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#appendix-c-sample-kb">Appendix C Sample KB</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#sample-q-a">SAMPLE Q&amp;A</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#prompt">PROMPT</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#prompt-for-synthetic-kb-generation">PROMPT FOR SYNTHETIC KB GENERATION</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#prompt-for-open-ended-q-a-generation">Prompt for open-ended Q&amp;A generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#prompt-for-gpt-evaluation-of-open-ended-q-a">PROMPT FOR GPT EVALUATION OF OPEN-ENDED Q&amp;A</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#prompt-for-llama-evaluation">PROMPT FOR LLAMA EVALUATION</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#question-template">QUESTION TEMPLATE</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#sample-output">SAMPLE OUTPUT</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#synthetic-kb">SYNTHETIC KB</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#enron">ENRON</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html">2504.03137_LightPROF: A Lightweight Reasoning Framework for Large Language Model on Knowledge Graph</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#related-work">Related Work</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#llm-prompt-engineering">LLM Prompt Engineering</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#kg-based-llm-reasoning">KG-based LLM Reasoning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#preliminaries">Preliminaries</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#knowledge-graph-kg">1. Knowledge Graph (KG)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#anchor-entities">2. Anchor Entities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#relation-link">3. Relation Link</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#reasoning-path">4. Reasoning Path</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#methodology">Methodology</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#stage1-reasoning-graph-retrieval">Stage1: Reasoning Graph Retrieval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#stage2-knowledge-embedding">Stage2: Knowledge Embedding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#stage3-knowledge-prompts-mixed-reasoning">Stage3: Knowledge Prompts Mixed Reasoning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#experiments">Experiments</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/graphrag.html">GraphRAG å®˜æ–¹æ–‡æ¡£</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/graphrag.html#indexing">Indexing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/graphrag.html#indexing-architecture">&gt; Indexing Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/graphrag.html#indexing-dataflow">&gt; Indexing Dataflow</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/graphrag.html#prompt-tuning">&gt; Prompt Tuning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/graphrag.html#query">Query</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../paper_pool.html">è®ºæ–‡æ± </a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html">2305.16300_Random-Access Infinite Context Length for Transformers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#introduction">1 Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#related-work">2 Related Work</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#methodology">3 Methodology</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id1"><strong>æ€»ä½“æ€è·¯</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id2"><strong>æ–¹æ³•è¯¦è§£</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id4"><strong>ä½ç½®ç¼–ç å¤„ç†</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id5"><strong>ä¸å…¶ä»–æ–¹æ³•çš„å¯¹æ¯”</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id6"><strong>æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#memory-computation">3.3 Memory &amp; Computation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#experiments">4 Experiments</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id7"><strong>4.1 è¯­è¨€å»ºæ¨¡å®éªŒ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id11"><strong>4.2 å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id15"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#future-work">5 Future Work</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#acknowledgment">Acknowledgment</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#appendix-a-grouped-softmax-example">Appendix A Grouped Softmax Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#appendix-b-dataset-description">Appendix B Dataset Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#appendix-c-number-of-unique-retrieved-blocks">Appendix C Number of Unique Retrieved Blocks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#appendix-d-context-miss-token">Appendix D Context Miss Token</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#appendix-e-positional-augmentation">Appendix E Positional Augmentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#appendix-f-additional-extensions-and-details">Appendix F Additional Extensions and Details</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#masked-language-modeling">1. <strong>æ©ç è¯­è¨€å»ºæ¨¡ï¼ˆMasked Language Modelingï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#flash-attention">2. <strong>ä¸ Flash Attention çš„ç»“åˆ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id16">3. <strong>æ£€ç´¢å—æ•°é‡ä¸å—å¤§å°çš„æƒè¡¡</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id17">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#appendix-g-offloading-kv-cache-to-cpu">Appendix G Offloading KV Cache to CPU</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html">2505.14683_Emerging Properties in Unified Multimodal Pretraining</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#from-deepseek">From Deepseek</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id1"><strong>è®ºæ–‡èƒŒæ™¯ä¸æ ¸å¿ƒç›®æ ‡</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id2"><strong>æ ¸å¿ƒè´¡çŒ®</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id3"><strong>å®éªŒç»“æœ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id4"><strong>æ„ä¹‰ä¸å±•æœ›</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#introduction">1 Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id5">æ ¸å¿ƒå†…å®¹æ€»ç»“ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id6">æ€»ç»“ï¼š</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#model">2 Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id7">1. æ¨¡å‹æ¶æ„æ¦‚è§ˆ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id8">2. ç”Ÿæˆç­–ç•¥</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id9">3. æ¨¡å‹ç»†èŠ‚</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#generalized-causal-attention">4. å¹¿ä¹‰å› æœæ³¨æ„åŠ›ï¼ˆGeneralized Causal Attentionï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#transformer">5. Transformerç»“æ„é€‰æ‹©ä¸å®éªŒ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id10">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#data">3 Data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id11">æ•°æ®ç‰¹ç‚¹ä¸ç›®æ ‡</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id12">æ•°æ®æ¥æºä¸ç»Ÿè®¡</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id13">æ•°æ®æ„å»ºæ–¹æ³•</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id20">æ•°æ®è®­ç»ƒç­–ç•¥</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id21">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#training">4 Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id22">1. å¤šé˜¶æ®µè®­ç»ƒç­–ç•¥</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id23">2. å…³é”®è¶…å‚æ•°è°ƒæ•´</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id26">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#evaluation">5 Evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#emerging-properties">6 Emerging Properties</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id27">1. <strong>æ–°å…´å±æ€§çš„å®šä¹‰ä¸ç ”ç©¶èƒŒæ™¯</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id28">2. <strong>ä»»åŠ¡è¡¨ç°ä¸è®­ç»ƒé˜¶æ®µçš„å…³ç³»</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id29">3. <strong>å¤šæ¨¡æ€ç‰¹å¾çš„é‡è¦æ€§</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id30">4. <strong>å®šæ€§åˆ†æä¸ç”Ÿæˆè´¨é‡æå‡</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id31">5. <strong>æ ¸å¿ƒå‘ç°ä¸ç»“è®º</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id32">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#main-results">7 Main Results</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id33">7.1 å›¾åƒç†è§£</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id34">7.2 å›¾åƒç”Ÿæˆ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id35">7.3 å›¾åƒç¼–è¾‘</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id36">7.4 å¸¦æœ‰æ¨ç†çš„ç”Ÿæˆ/ç¼–è¾‘</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id37">7.5 ä¸–ç•Œå»ºæ¨¡</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id38">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#more-qualitative-results">7.6 More Qualitative Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#conclusion">8 Conclusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#acknowledgement">9 Acknowledgement</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html">2507.10524_Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive Token-Level Computation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#introduction">1 Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id1">èƒŒæ™¯ä¸åŠ¨æœº</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#transformer">é€’å½’ Transformer ä¸æŒ‘æˆ˜</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#mor">MoRï¼šç»Ÿä¸€æ¡†æ¶</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id2">æ¦‚å¿µä¸æ„ä¹‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#contributions">è´¡çŒ®æ€»ç»“ï¼ˆContributionsï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id3">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#method">2 Method</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#preliminary">2.1 Preliminary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#mixture-of-recursions-mor">2.2 Mixture-of-Recursions (MoR)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id4">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#experiments">3 Experiments</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#table-3">è¡¨æ ¼æ€»ç»“ï¼ˆTable 3ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id5">3.1 ä¸»è¦ç»“æœ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#isoflop">3.2 IsoFLOP åˆ†æ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id11">3.3 æ¨ç†ååé‡è¯„ä¼°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id14">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#ablation-studies">4 Ablation Studies</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#parameter-sharing-strategies"><strong>4.1 Parameter Sharing Strategies</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#routing-strategies"><strong>4.2 Routing Strategies</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#kv-caching-strategies"><strong>4.3 KV Caching Strategies</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id16">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#analysis">5 Analysis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#compute-optimal-scaling-analysis">5.1 Compute-optimal Scaling Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#routing-analysis">5.2 Routing Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#test-time-scaling-analysis">5.3 Test-time Scaling Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id17">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#related-work">6 Related Work</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#recursive-transformers-transformer">Recursive Transformersï¼ˆé€’å½’Transformerï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#adaptive-computation">Adaptive Computationï¼ˆè‡ªé€‚åº”è®¡ç®—ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#routing-mechanism">Routing Mechanismï¼ˆè·¯ç”±æœºåˆ¶ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#key-value-caching">Key-value Cachingï¼ˆé”®å€¼ç¼“å­˜ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#latent-reasoning">Latent Reasoningï¼ˆéšå¼æ¨ç†ï¼‰</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#conclusion">7 Conclusion</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id18">7.1 å±€é™æ€§ä¸æœªæ¥å·¥ä½œ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id24">7.2 è‡´è°¢</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#appendix-a-details-of-design-choices-for-mixture-of-recursions">Appendix A Details of Design Choices for Mixture-of-Recursions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#a-1-parameter-sharing-strategy">A.1 å‚æ•°å…±äº«ç­–ç•¥ï¼ˆParameter-sharing Strategyï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#a-2-routing-strategy">A.2 è·¯ç”±ç­–ç•¥ï¼ˆRouting Strategyï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#a-3-kv-kv-caching-strategy">A.3 KV ç¼“å­˜ç­–ç•¥ï¼ˆKV Caching Strategyï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id26">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#appendix-b-experimental-setup">Appendix B Experimental Setup</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id27">è®­ç»ƒè®¾ç½®</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id28">è¯„ä¼°è®¾ç½®</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id29">æ¨¡å‹æ¶æ„ç»†èŠ‚</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id30">è¡¨6ï¼šæ¨¡å‹æ¶æ„å‚æ•°æ€»ç»“ï¼ˆé‡ç‚¹ï¼‰</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#appendix-c-expanded-results-of-isoflop-analysis">Appendix C Expanded Results of IsoFLOP Analysis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id31">æ€»ä½“æ¯”è¾ƒ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#transformerflops">Transformerçš„FLOPsè¿‘ä¼¼è®¡ç®—</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id32">å¸¦æ£€æŸ¥ç‚¹å¤ç”¨çš„æ¢¯å½¢å­¦ä¹ ç‡è°ƒåº¦</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id33">ç»“æœæ¦‚è§ˆ</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#appendix-d-details-of-experimental-settings-for-throughput-measurement">Appendix D Details of Experimental Settings for Throughput Measurement</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id34">å®éªŒç³»ç»Ÿä¸è¯„ä¼°æ–¹æ³•</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id35">æ¨¡å‹ååé‡å¯¹æ¯”è®¾ç½®</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id36">æ‰¹å¤„ç†è®¾ç½®</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id37">å®ç°ç»†èŠ‚</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#appendix-e-expanded-results-of-parameter-sharing-strategy">Appendix E Expanded Results of Parameter Sharing Strategy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#middle-cycle">Middle-Cycle æ˜¯æœ€ç¨³å®šçš„é€‰æ‹©</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#up-training">æŒç»­é¢„è®­ç»ƒï¼ˆup-trainingï¼‰ä¸‹çš„è¡¨ç°</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#appendix-f-expanded-results-of-design-choices-for-router">Appendix F Expanded Results of Design Choices for Router</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#f-1">F.1 è®¾è®¡é…ç½®ç»†èŠ‚</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#f-2">F.2 è·¯ç”±å™¨æ€§èƒ½è¯„ä¼°æŒ‡æ ‡</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#f-3">F.3 è·¯ç”±å™¨è®¾è®¡çš„æ‰©å±•è¯„ä¼°ç»“æœ</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#appendix-g-expanded-results-of-kv-cache-sharing-mechanism">Appendix G Expanded Results of KV Cache Sharing Mechanism</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#g-1-transformer">G.1 é€’å½’ Transformer ä¸­çš„å…³é”®å€¼è¡¨ç¤ºè¶‹åŠ¿</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#g-2-kv">G.2 KV ç¼“å­˜å…±äº«ç­–ç•¥çš„æ€§èƒ½æ¯”è¾ƒ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id44">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#appendix-h-expanded-qualitative-results">Appendix H Expanded Qualitative Results</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#h-1-analysis-on-adaptive-computation-paths">H.1 Analysis on Adaptive Computation Paths</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#h-2-analysis-on-router-weights">H.2 Analysis on Router Weights</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id45">æ€»ç»“</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html">2509.06221_Beamforming-LLM: What, Where and When Did I Miss?</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#abstract">Abstract</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#id1">æ ¸å¿ƒæŠ€æœ¯ä¸æµç¨‹</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#id2">ç”¨æˆ·æŸ¥è¯¢å¤„ç†æµç¨‹</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#id3">ç³»ç»Ÿè¾“å‡º</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#id4">åº”ç”¨ä¸æ„ä¹‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#id5">å…³é”®è¯ï¼ˆé‡ç‚¹æ ¸å¿ƒæ¦‚å¿µï¼‰</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#introduction">1. Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#related-work">2. Related Work</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#id6">ä¼šè¯è®°å¿†ç³»ç»Ÿ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#id7">è¯­éŸ³å¢å¼ºä¸ä¿¡æ¯æ£€ç´¢æŠ€æœ¯</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#id8">ç°æœ‰å·¥ä½œçš„ä¸è¶³ä¸æœ¬ç ”ç©¶çš„åˆ›æ–°</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#methods">3. Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#beamforming-and-directional-source-separation">3.1. Beamforming and Directional Source Separationï¼ˆæ³¢æŸæˆå½¢ä¸æ–¹å‘æ€§æºåˆ†ç¦»ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#automatic-speech-recognition-asr">3.2. Automatic Speech Recognition (ASR)ï¼ˆè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#retrieval-augmented-generation-with-vector-embeddings">3.3. Retrieval-Augmented Generation with Vector Embeddingsï¼ˆåŸºäºå‘é‡åµŒå…¥çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#natural-language-interface-and-semantic-retrieval">3.4. Natural Language Interface and Semantic Retrievalï¼ˆè‡ªç„¶è¯­è¨€æ¥å£ä¸è¯­ä¹‰æ£€ç´¢ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#deployment-and-llm-choice-llm">3.5. Deployment and LLM Choiceï¼ˆéƒ¨ç½²ä¸LLMé€‰æ‹©ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#id9">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#results">4. Results</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#id10">å®éªŒè®¾ç½®</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#beamforming-performance">4.1. Beamforming Performanceï¼ˆæ³¢æŸæˆå½¢æ€§èƒ½ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#retrieval-pipeline-evaluation">4.2. Retrieval Pipeline Evaluationï¼ˆæ£€ç´¢æµç¨‹è¯„ä¼°ï¼‰</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#discussion-and-conclusion">5. Discussion and Conclusion</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#mvp">åŠŸèƒ½æ€§MVPçš„å®ç°ä¸ç°æœ‰å±€é™</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#id11">å¤šæ¨¡æ€æ‰©å±•ä¸åº”ç”¨å‰æ™¯</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../paper_pool_sum.html">è®ºæ–‡æ± -sum</a><ul class="simple">
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../../other.html">å…¶ä»–</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../other.html#id3">æ•°æ®é›†&amp;æ•°æ®è’¸é¦</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../DataSets/1811.10959v3_Dataset_Distillation.html">1811.10959v3_Dataset Distillation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DataSets/1811.10959v3_Dataset_Distillation.html#abstract">ABSTRACT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DataSets/1811.10959v3_Dataset_Distillation.html#llm">LLMæ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DataSets/1811.10959v3_Dataset_Distillation.html#introduction">1. INTRODUCTION</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DataSets/1811.10959v3_Dataset_Distillation.html#approach">3. APPROACH</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../DataSets/2502.20653_Dataset_Distillation.html">2502.20653_Dataset Distillation with Neural Characteristic Function: A Minmax Perspective</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DataSets/2502.20653_Dataset_Distillation.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DataSets/2502.20653_Dataset_Distillation.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DataSets/2502.20653_Dataset_Distillation.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../DataSets/2502.20653_Dataset_Distillation.html#conclusion">7. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../DataSets/normal.html">é€šç”¨</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../DataSets/normal.html#dataset-distillation">Dataset distillation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="../../other.html#d">3D</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="2003.08934_NeRF.html">2003.08934_NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2003.08934_NeRF.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2003.08934_NeRF.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2003.08934_NeRF.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2003.08934_NeRF.html#neural-radiance-field-scene-representation">3. Neural Radiance Field Scene Representation</a></li>
<li class="toctree-l4"><a class="reference internal" href="2003.08934_NeRF.html#volume-rendering-with-radiance-fields">4. Volume Rendering with Radiance Fields</a></li>
<li class="toctree-l4"><a class="reference internal" href="2003.08934_NeRF.html#optimizing-a-neural-radiance-field">5. Optimizing a Neural Radiance Field</a></li>
<li class="toctree-l4"><a class="reference internal" href="2003.08934_NeRF.html#result">6. Result</a></li>
<li class="toctree-l4"><a class="reference internal" href="2003.08934_NeRF.html#conclusion">7. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2203.08586_VanishingPointEstimation.html">2203.08586: Deep vanishing point detection: Geometric priors make dataset variations vanish</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2203.08586_VanishingPointEstimation.html#id1">æ¦‚å¿µ</a></li>
<li class="toctree-l4"><a class="reference internal" href="2203.08586_VanishingPointEstimation.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2203.08586_VanishingPointEstimation.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2203.08586_VanishingPointEstimation.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2203.08586_VanishingPointEstimation.html#geometric-priors-for-vp-detection">3. Geometric priors for VP detection</a></li>
<li class="toctree-l4"><a class="reference internal" href="2203.08586_VanishingPointEstimation.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="2203.08586_VanishingPointEstimation.html#conclusion-and-limitations">5. Conclusion and limitations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2312.14132_DUSt3R.html">2312.14132_DUSt3R: Geometric 3D Vision Made Easy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2312.14132_DUSt3R.html#id1">å…³é”®è¯</a></li>
<li class="toctree-l4"><a class="reference internal" href="2312.14132_DUSt3R.html#id2">ç›¸å…³æ¦‚å¿µ</a></li>
<li class="toctree-l4"><a class="reference internal" href="2312.14132_DUSt3R.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2312.14132_DUSt3R.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2312.14132_DUSt3R.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2312.14132_DUSt3R.html#method">3. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="2312.14132_DUSt3R.html#experiments-with-dust3r">4. Experiments with DUSt3R</a></li>
<li class="toctree-l4"><a class="reference internal" href="2312.14132_DUSt3R.html#conclusion">5. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="2312.14132_DUSt3R.html#appendix-a">Appendix A <strong>é™„å½•æ¦‚è§ˆ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="2312.14132_DUSt3R.html#appendix-b-qualitative-results">Appendix B.  Qualitative results</a></li>
<li class="toctree-l4"><a class="reference internal" href="2312.14132_DUSt3R.html#appendix-c-extended-related-work">Appendix C. Extended Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2312.14132_DUSt3R.html#appendix-d-multi-view-pose-estimation">Appendix D. å¤šè§†è§’å§¿æ€ä¼°è®¡ï¼ˆMulti-view Pose Estimationï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="2312.14132_DUSt3R.html#appendix-e-visual-localization">Appendix E. è§†è§‰å®šä½ï¼ˆVisual Localizationï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="2312.14132_DUSt3R.html#appendix-f-training-details">Appendix F. Training details</a></li>
</ul>
</li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">2406.09756_MASt3R: Grounding Image Matching in 3D with MASt3R</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id1">å‰è¨€</a></li>
<li class="toctree-l4"><a class="reference internal" href="#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id2">ğŸ§  æ€ç»´å¯¼å›¾å¼æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="#related-works">2. Related works</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id3">ğŸ§  æ€»ç»“æ€ç»´å¯¼å›¾</a></li>
<li class="toctree-l4"><a class="reference internal" href="#method">3. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="#experimental-results">4. Experimental results</a></li>
<li class="toctree-l4"><a class="reference internal" href="#conclusion">5. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="#appendix-a-additional-qualitative-results">Appendix A Additional Qualitative Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="#b-fast-reciprocal-matching">B. Fast Reciprocal Matching</a></li>
<li class="toctree-l4"><a class="reference internal" href="#c-coarse-to-fine">C. Coarse-to-Fine</a></li>
<li class="toctree-l4"><a class="reference internal" href="#d-detailed-experimental-settings">D. Detailed experimental settings</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2412.09401_SLAM3R.html">2412.09401_SLAM3R: Real-Time Dense Scene Reconstruction from Monocular RGB Videos</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2412.09401_SLAM3R.html#id1">æœ¯è¯­</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.09401_SLAM3R.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.09401_SLAM3R.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.09401_SLAM3R.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.09401_SLAM3R.html#method">3. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.09401_SLAM3R.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.09401_SLAM3R.html#conclusion">5. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.09401_SLAM3R.html#id14">6. è‡´è°¢</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.09401_SLAM3R.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.09401_SLAM3R.html#appendix-a-implementation-details">Appendix A Implementation details</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.09401_SLAM3R.html#appendix-b-details-for-experimental-settings">Appendix B Details for experimental settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.09401_SLAM3R.html#appendix-c-additional-comparisons-and-analyses">Appendix C Additional comparisons and analyses</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.09401_SLAM3R.html#d-more-visual-results">D. More visual results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html">2412.12392_MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html#gpt">GPT</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html#id1">å…ˆéªŒçŸ¥è¯†</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html#method">3. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html#results">4. Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html#limitations-and-future-work">5. Limitations and Future Workï¼ˆå±€é™ä¸æœªæ¥å·¥ä½œï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html#conclusion">ğŸ§¾ 6. Conclusionï¼ˆæ€»ç»“ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html#id32">ğŸ§  æ€»ç»“ä¸€å¥è¯ç‰ˆï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html#initialisation">8. Initialisationï¼ˆåˆå§‹åŒ–ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html#runtime-breakdown">9. Runtime Breakdownï¼ˆè¿è¡Œæ—¶åˆ†æï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html#evaluation-setup">10. Evaluation Setupï¼ˆè¯„ä¼°è®¾ç½®ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="2412.12392_MASt3R-SLAM.html#id35">11. EuRoC ç»“æœæ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2503.11651_VGGT.html">2503.11651_VGGT: Visual Geometry Grounded Transformer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2503.11651_VGGT.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2503.11651_VGGT.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2503.11651_VGGT.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2503.11651_VGGT.html#method">3. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="2503.11651_VGGT.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="2503.11651_VGGT.html#discussions">5. Discussions</a></li>
<li class="toctree-l4"><a class="reference internal" href="2503.11651_VGGT.html#conclusions">6. Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="2503.11651_VGGT.html#appendix-a-formal-definitions">Appendix A Formal Definitions</a></li>
<li class="toctree-l4"><a class="reference internal" href="2503.11651_VGGT.html#appendix-b-implementation-details">Appendix B Implementation Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="2503.11651_VGGT.html#appendix-c-additional-experiments">Appendix C Additional Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="2503.11651_VGGT.html#appendix-d-qualitative-examples">Appendix D Qualitative Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="2503.11651_VGGT.html#appendix-e-related-work">Appendix E Related Work</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../other.html#id4">å…¶ä»–</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../others/2204.00598_SocraticModels.html">2204.00598_SocraticModels: Composing Zero-Shot Multimodal Reasoning with Language</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../others/2204.00598_SocraticModels.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/2204.00598_SocraticModels.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/2204.00598_SocraticModels.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/2204.00598_SocraticModels.html#problem-setting-background-and-related-work">2 Problem Setting, Background, and Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/2204.00598_SocraticModels.html#socratic-models">3 Socratic Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/2204.00598_SocraticModels.html#evaluation-methods-and-results">4 Evaluation: Methods and Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/2204.00598_SocraticModels.html#applications-methods-and-demonstrations">5 Applications: Methods and Demonstrations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/2204.00598_SocraticModels.html#discussion">6 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/2204.00598_SocraticModels.html#acknowledgments-and-disclosure-of-funding">Acknowledgments and Disclosure of Funding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/2204.00598_SocraticModels.html#appendix-a-overview">Appendix A Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/2204.00598_SocraticModels.html#appendix-b-unsupervised-socratic-model-selection">Appendix B Unsupervised Socratic Model Selection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/2204.00598_SocraticModels.html#appendix-c-additional-notes-on-experiments">Appendix C Additional Notes on Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/2204.00598_SocraticModels.html#appendix-d-egocentric-perception-appendix">Appendix D Egocentric Perception Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/2204.00598_SocraticModels.html#appendix-e-scaling-up-socratic-video-search">Appendix E Scaling Up Socratic Video Search</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/2204.00598_SocraticModels.html#appendix-f-additional-notes-on-robot-experiments">Appendix F Additional Notes on Robot Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/2204.00598_SocraticModels.html#appendix-g-socratic-deductive-reasoning">Appendix G Socratic Deductive Reasoning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/2204.00598_SocraticModels.html#appendix-h-broader-impact-energy-and-resource-consumption">Appendix H Broader Impact: Energy and Resource Consumption</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html">A PAINLESS GUIDE TO CRC ERROR DETECTION ALGORITHMS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#the-basic-idea-behind-crc-algorithms">The Basic Idea Behind CRC Algorithms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#polynomical-arithmetic">Polynomical Arithmetic</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#binary-arithmetic-with-no-carries">Binary Arithmetic with No Carries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#id2">ä¸€ä¸ªå¯ç”¨çš„å®ä¾‹</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#choosing-a-poly">Choosing A Poly</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#a-straightforward-crc-implementation">A Straightforward CRC Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#a-table-driven-implementation">A Table-Driven Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#a-slightly-mangled-table-driven-implementation">A Slightly Mangled Table-Driven Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#id3">å‚è€ƒ</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../others/Distributed%20Representations%20of%20Sentences%20and%20Documents.html">Distributed Representations of Sentences and Documents</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">æ–°æºª-gordon</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../other.html">å…¶ä»–</a> &raquo;</li>
        
      <li>2406.09756_MASt3R: Grounding Image Matching in 3D with MASt3R</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/others/3D/2406.09756_MASt3R.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            <nav id="local-table-of-contents" role="navigation" aria-labelledby="local-table-of-contents-title">
              <h4 id="local-table-of-contents-title">On This Page</h4>
              <ul>
<li><a class="reference internal" href="#">2406.09756_MASt3R: Grounding Image Matching in 3D with MASt3R</a><ul>
<li><a class="reference internal" href="#id1">å‰è¨€</a><ul>
<li><a class="reference internal" href="#sift-scale-invariant-feature-transform"><strong>SIFT (Scale-Invariant Feature Transform)</strong></a></li>
<li><a class="reference internal" href="#colmap"><strong>COLMAP</strong></a></li>
<li><a class="reference internal" href="#asmk-aggregated-selective-match-kernels">ASMK (Aggregated Selective Match Kernels)</a></li>
<li><a class="reference internal" href="#pnp-perspective-n-point">PnP(Perspective-n-Point)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#abstract">Abstract</a></li>
<li><a class="reference internal" href="#introduction">1. Introduction</a><ul>
<li><a class="reference internal" href="#why">â‘  <strong>ç ”ç©¶åŠ¨æœºä¸èƒŒæ™¯ï¼ˆWhyï¼‰</strong></a></li>
<li><a class="reference internal" href="#what-existed-before">â‘¡ <strong>ä¼ ç»Ÿæ–¹æ³•å›é¡¾ï¼ˆWhat existed beforeï¼‰</strong></a></li>
<li><a class="reference internal" href="#what-improved">â‘¢ <strong>è¿‘å¹´æ”¹è¿›æ–¹å‘ï¼ˆWhat improvedï¼‰</strong></a></li>
<li><a class="reference internal" href="#problem-statement">â‘£ <strong>æ ¸å¿ƒé—®é¢˜ï¼ˆProblem Statementï¼‰</strong></a></li>
<li><a class="reference internal" href="#mast3r-our-solution">â‘¤ <strong>æœ¬æ–‡æå‡ºçš„æ–¹æ³• MASt3Rï¼ˆOur Solutionï¼‰</strong></a></li>
<li><a class="reference internal" href="#claimed-contributions">â‘¥ <strong>ä¸‰å¤§è´¡çŒ®æ€»ç»“ï¼ˆClaimed Contributionsï¼‰</strong></a></li>
</ul>
</li>
<li><a class="reference internal" href="#id2">ğŸ§  æ€ç»´å¯¼å›¾å¼æ€»ç»“</a></li>
<li><a class="reference internal" href="#related-works">2. Related works</a><ul>
<li><a class="reference internal" href="#keypoint-based-matching">â‘  å…³é”®ç‚¹åŒ¹é…ï¼ˆKeypoint-based Matchingï¼‰</a></li>
<li><a class="reference internal" href="#dense-semi-dense-matching">â‘¡ ç¨ å¯†åŒ¹é…ï¼ˆDense/Semi-dense Matchingï¼‰</a></li>
<li><a class="reference internal" href="#camera-pose-estimation">â‘¢ ç›¸æœºä½å§¿ä¼°è®¡ï¼ˆCamera Pose Estimationï¼‰</a></li>
<li><a class="reference internal" href="#d-3d-aware-matching">â‘£ å‘3DåŒ¹é…è¿‡æ¸¡ï¼ˆ3D-Aware Matchingï¼‰</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id3">ğŸ§  æ€»ç»“æ€ç»´å¯¼å›¾</a></li>
<li><a class="reference internal" href="#method">3. Method</a><ul>
<li><a class="reference internal" href="#the-dust3r-framework">3.1 The DUSt3R framework</a></li>
<li><a class="reference internal" href="#matching-prediction-head-and-loss">3.2. Matching prediction head and loss</a></li>
<li><a class="reference internal" href="#fast-reciprocal-matching">3.3. Fast reciprocal matching</a></li>
<li><a class="reference internal" href="#coarse-to-fine-matching">3.4. Coarse-to-fine matching</a></li>
</ul>
</li>
<li><a class="reference internal" href="#experimental-results">4. Experimental results</a><ul>
<li><a class="reference internal" href="#training">4.1. Training</a></li>
<li><a class="reference internal" href="#map-free-localization">4.2 Map-free localization</a></li>
<li><a class="reference internal" href="#relative-pose-estimation">4.3. Relative pose estimation</a></li>
<li><a class="reference internal" href="#visual-localization-solute-pose-estimation">4.4. Visual localization(solute pose estimation)</a></li>
<li><a class="reference internal" href="#multiview-3d-reconstruction">4.5 Multiview 3D Reconstructionï¼ˆå¤šè§†å›¾ä¸‰ç»´é‡å»ºï¼‰</a></li>
</ul>
</li>
<li><a class="reference internal" href="#conclusion">5. Conclusion</a></li>
<li><a class="reference internal" href="#appendix">Appendix</a></li>
<li><a class="reference internal" href="#appendix-a-additional-qualitative-results">Appendix A Additional Qualitative Results</a></li>
<li><a class="reference internal" href="#b-fast-reciprocal-matching">B. Fast Reciprocal Matching</a><ul>
<li><a class="reference internal" href="#b-1-theoretical-study">B.1. Theoretical study</a></li>
<li><a class="reference internal" href="#b-2-performance-improves-with-fast-matching">B.2. Performance improves with fast matching</a></li>
</ul>
</li>
<li><a class="reference internal" href="#c-coarse-to-fine">C. Coarse-to-Fine</a></li>
<li><a class="reference internal" href="#d-detailed-experimental-settings">D. Detailed experimental settings</a></li>
</ul>
</li>
</ul>

            </nav>
  <section class="tex2jax_ignore mathjax_ignore" id="mast3r-grounding-image-matching-in-3d-with-mast3r">
<h1>2406.09756_MASt3R: Grounding Image Matching in 3D with MASt3R<a class="headerlink" href="#mast3r-grounding-image-matching-in-3d-with-mast3r" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h1>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/pdf/2406.09756">https://arxiv.org/pdf/2406.09756</a></p></li>
<li><p>GitHub: <a class="reference external" href="https://github.com/naver/mast3r">https://github.com/naver/mast3r</a></p></li>
<li><p>ç»„ç»‡: NAVER LABS Europe</p></li>
<li><p>Google Scholar(93, 2025-04-16)</p></li>
</ul>
<section id="id1">
<h2>å‰è¨€<a class="headerlink" href="#id1" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<section id="sift-scale-invariant-feature-transform">
<h3><strong>SIFT (Scale-Invariant Feature Transform)</strong><a class="headerlink" href="#sift-scale-invariant-feature-transform" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p><strong>å®šä¹‰</strong>:<br />
SIFT æ˜¯ä¸€ç§ç»å…¸çš„è®¡ç®—æœºè§†è§‰ç®—æ³•ï¼Œç”¨äºæ£€æµ‹å’Œæè¿°å›¾åƒä¸­çš„å±€éƒ¨ç‰¹å¾ã€‚å®ƒç”± David Lowe åœ¨ 1999 å¹´æå‡ºï¼Œå¹¶åœ¨ 2004 å¹´è¿›ä¸€æ­¥å®Œå–„ã€‚</p></li>
<li><p><strong>ä¸»è¦åŠŸèƒ½</strong>:</p>
<ul>
<li><p><strong>å…³é”®ç‚¹æ£€æµ‹</strong>: SIFT èƒ½å¤Ÿåœ¨å›¾åƒä¸­æ£€æµ‹å‡ºå…·æœ‰å°ºåº¦ä¸å˜æ€§å’Œæ—‹è½¬ä¸å˜æ€§çš„å…³é”®ç‚¹ï¼ˆå³å›¾åƒä¸­çš„æ˜¾è‘—ç‚¹ï¼‰ã€‚è¿™äº›å…³é”®ç‚¹é€šå¸¸ä½äºè§’ç‚¹ã€è¾¹ç¼˜æˆ–å…¶ä»–çº¹ç†ä¸°å¯Œçš„åŒºåŸŸã€‚</p></li>
<li><p><strong>ç‰¹å¾æè¿°</strong>: å¯¹äºæ¯ä¸ªæ£€æµ‹åˆ°çš„å…³é”®ç‚¹ï¼ŒSIFT ç”Ÿæˆä¸€ä¸ªæè¿°ç¬¦ï¼ˆdescriptorï¼‰ï¼Œè¯¥æè¿°ç¬¦å¯¹å…‰ç…§å˜åŒ–ã€è§†è§’å˜åŒ–å’Œå°ºåº¦å˜åŒ–å…·æœ‰é²æ£’æ€§ã€‚</p></li>
<li><p><strong>åŒ¹é…</strong>: é€šè¿‡æ¯”è¾ƒä¸¤å¹…å›¾åƒä¸­å…³é”®ç‚¹çš„æè¿°ç¬¦ï¼Œå¯ä»¥æ‰¾åˆ°å®ƒä»¬ä¹‹é—´çš„å¯¹åº”å…³ç³»ã€‚</p></li>
</ul>
</li>
<li><p><strong>ä¼˜ç‚¹</strong>:</p>
<ul>
<li><p>å¯¹å…‰ç…§ã€å°ºåº¦å’Œæ—‹è½¬å˜åŒ–å…·æœ‰å¾ˆå¼ºçš„é²æ£’æ€§ã€‚</p></li>
<li><p>åœ¨ç›¸ä¼¼æ¡ä»¶ä¸‹èƒ½å¤Ÿå¿«é€Ÿå®ç°é«˜ç²¾åº¦åŒ¹é…ã€‚</p></li>
<li><p>å¹¿æ³›åº”ç”¨äºå›¾åƒåŒ¹é…ã€3Dé‡å»ºã€ç‰©ä½“è¯†åˆ«ç­‰é¢†åŸŸã€‚</p></li>
</ul>
</li>
<li><p><strong>å±€é™æ€§</strong>:</p>
<ul>
<li><p>è®¡ç®—å¤æ‚åº¦è¾ƒé«˜ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†é«˜åˆ†è¾¨ç‡å›¾åƒæ—¶ã€‚</p></li>
<li><p>å¯¹ä½çº¹ç†åŒºåŸŸæˆ–é‡å¤æ¨¡å¼çš„è¡¨ç°è¾ƒå·®ã€‚</p></li>
</ul>
</li>
<li><p><strong>SIFT</strong> æ˜¯ä¸€ç§ç»å…¸çš„å…³é”®ç‚¹æ£€æµ‹å’Œæè¿°ç®—æ³•ï¼Œå¹¿æ³›åº”ç”¨äºå›¾åƒåŒ¹é…ä»»åŠ¡ä¸­ï¼Œå°¤å…¶åœ¨æ—©æœŸçš„3Dé‡å»ºæµæ°´çº¿ä¸­å‘æŒ¥äº†é‡è¦ä½œç”¨ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="colmap">
<h3><strong>COLMAP</strong><a class="headerlink" href="#colmap" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p><strong>å®šä¹‰</strong>:<br />
COLMAP æ˜¯ä¸€ä¸ªå¼€æºçš„ä¸‰ç»´é‡å»ºè½¯ä»¶å·¥å…·åŒ…ï¼Œå¹¿æ³›ç”¨äºè®¡ç®—æœºè§†è§‰å’Œæ‘„å½±æµ‹é‡é¢†åŸŸã€‚å®ƒç”± Johannes SchÃ¶nberger ç­‰äººå¼€å‘å¹¶ç»´æŠ¤ã€‚</p></li>
<li><p><strong>ä¸»è¦åŠŸèƒ½</strong>:</p>
<ul>
<li><p><strong>ç¨€ç–é‡å»º</strong>: é€šè¿‡å¤šè§†å›¾å‡ ä½•æ–¹æ³•ï¼Œä»ä¸€ç»„è¾“å…¥å›¾åƒä¸­ç”Ÿæˆç¨€ç–çš„3Dç‚¹äº‘æ¨¡å‹ã€‚</p></li>
<li><p><strong>å¯†é›†é‡å»º</strong>: ä½¿ç”¨å¤šè§†å›¾ç«‹ä½“è§†è§‰æŠ€æœ¯ï¼ˆMulti-View Stereo, MVSï¼‰ç”Ÿæˆå¯†é›†çš„3Dè¡¨é¢æ¨¡å‹ã€‚</p></li>
<li><p><strong>ç›¸æœºå§¿æ€ä¼°è®¡</strong>: é€šè¿‡å›¾åƒåŒ¹é…å’ŒæŸè°ƒæ•´ï¼ˆBundle Adjustmentï¼‰ï¼Œè®¡ç®—æ¯å¼ å›¾åƒçš„ç›¸æœºä½ç½®å’Œå§¿æ€ã€‚</p></li>
<li><p><strong>ç‰¹å¾æå–ä¸åŒ¹é…</strong>: å†…ç½®äº† SIFT ç­‰ç‰¹å¾æå–å’ŒåŒ¹é…ç®—æ³•ï¼Œç”¨äºå¤„ç†å›¾åƒé—´çš„å¯¹åº”å…³ç³»ã€‚</p></li>
</ul>
</li>
<li><p><strong>ä¼˜ç‚¹</strong>:</p>
<ul>
<li><p>é«˜åº¦çµæ´»ä¸”æ˜“äºä½¿ç”¨ï¼Œæ”¯æŒå¤šç§è¾“å…¥æ ¼å¼ã€‚</p></li>
<li><p>æä¾›å®Œæ•´çš„3Dé‡å»ºæµæ°´çº¿ï¼Œä»ç‰¹å¾æå–åˆ°æœ€ç»ˆçš„3Dæ¨¡å‹ç”Ÿæˆã€‚</p></li>
<li><p>æ”¯æŒå¤§è§„æ¨¡åœºæ™¯çš„é«˜æ•ˆå¤„ç†ã€‚</p></li>
</ul>
</li>
<li><p><strong>åº”ç”¨åœºæ™¯</strong>:</p>
<ul>
<li><p>æ–‡åŒ–é—äº§ä¿æŠ¤ï¼ˆå¦‚å¤å»ºç­‘çš„æ•°å­—åŒ–é‡å»ºï¼‰ã€‚</p></li>
<li><p>è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ä¸­çš„ç¯å¢ƒå»ºæ¨¡ã€‚</p></li>
<li><p>è‡ªä¸»å¯¼èˆªå’Œæœºå™¨äººæŠ€æœ¯ä¸­çš„åœ°å›¾æ„å»ºã€‚</p></li>
</ul>
</li>
<li><p><strong>COLMAP</strong> æ˜¯ä¸€ä¸ªå¼ºå¤§çš„3Dé‡å»ºå·¥å…·åŒ…ï¼Œé›†æˆäº† SIFT ç­‰ç®—æ³•ï¼Œç”¨äºä»å›¾åƒç”Ÿæˆç¨€ç–å’Œå¯†é›†çš„3Dæ¨¡å‹ï¼Œå¹¶åœ¨å­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œå¾—åˆ°äº†å¹¿æ³›åº”ç”¨ã€‚</p></li>
</ul>
</section>
<section id="asmk-aggregated-selective-match-kernels">
<h3>ASMK (Aggregated Selective Match Kernels)<a class="headerlink" href="#asmk-aggregated-selective-match-kernels" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>ASMKï¼ˆAggregated Selective Match Kernelsï¼‰æ˜¯ä¸€ç§ç”¨äº<strong>å›¾åƒæ£€ç´¢ï¼ˆImage Retrievalï¼‰<strong>çš„ç»å…¸æ–¹æ³•ï¼Œå±äº</strong>åŸºäºå±€éƒ¨ç‰¹å¾çš„å›¾åƒè¡¨ç¤º</strong>æŠ€æœ¯ã€‚å®ƒç”± <strong>Tolias et al.</strong> åœ¨ 2013 å¹´æå‡ºï¼Œå¹¶åœ¨ 2017 å¹´çš„å‡çº§ç‰ˆä¸­è¿›ä¸€æ­¥æ”¹è¿›ï¼Œç”¨äºæå‡å¤§å‹å›¾åƒæ•°æ®åº“ä¸­çš„æ£€ç´¢æ€§èƒ½ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯åœ¨ä¼ ç»Ÿ Bag-of-Wordsï¼ˆBoWï¼‰æ¡†æ¶çš„åŸºç¡€ä¸Šï¼Œå¼•å…¥äº†é€‰æ‹©æ€§åŒ¹é…å’Œæ ¸å‡½æ•°èšåˆæœºåˆ¶ï¼Œä½¿å¾—å›¾åƒç‰¹å¾è¡¨è¾¾æ›´åŠ ç²¾ç»†å’Œåˆ¤åˆ«åŠ›æ›´å¼ºã€‚</p>
<ul class="simple">
<li><p>ğŸ§  æ ¸å¿ƒæ€æƒ³
ASMK æ˜¯ä¸€ç§<strong>ç¨€ç–ã€å¯åŒºåˆ†çš„å›¾åƒç‰¹å¾ç¼–ç æ–¹å¼</strong>ï¼Œå®ƒä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªå…³é”®ç»„ä»¶ï¼š</p></li>
</ul>
<ol class="arabic simple">
<li><p><strong>å±€éƒ¨ç‰¹å¾æå–</strong></p>
<ul class="simple">
<li><p>ä½¿ç”¨ SIFTã€RootSIFTã€DELF æˆ–å…¶ä»–å±€éƒ¨æè¿°å­æå–å›¾åƒçš„å±€éƒ¨ç‰¹å¾ã€‚</p></li>
</ul>
</li>
<li><p><strong>è§†è§‰è¯å…¸ï¼ˆVisual Vocabularyï¼‰</strong></p>
<ul class="simple">
<li><p>é€šè¿‡ K-means ç­‰èšç±»æ–¹æ³•æ„å»ºä¸€ä¸ªè§†è§‰è¯æ±‡è¡¨ï¼Œæ¯ä¸ªèšç±»ä¸­å¿ƒä»£è¡¨ä¸€ä¸ªè§†è§‰è¯ã€‚</p></li>
</ul>
</li>
<li><p><strong>Selective Matchingï¼ˆé€‰æ‹©æ€§åŒ¹é…ï¼‰</strong></p>
<ul class="simple">
<li><p>å¯¹äºæ¯ä¸ªè§†è§‰è¯ï¼Œåªè€ƒè™‘ä¸å…¶<strong>ç›¸ä¼¼åº¦è¾ƒé«˜çš„å±€éƒ¨ç‰¹å¾å¯¹</strong>ï¼Œä»¥æ’é™¤å¹²æ‰°ä¿¡æ¯ï¼Œæå‡åŒ¹é…çš„é²æ£’æ€§ã€‚</p></li>
</ul>
</li>
<li><p><strong>Match Kernelsï¼ˆåŒ¹é…æ ¸å‡½æ•°ï¼‰</strong></p>
<ul class="simple">
<li><p>å¯¹åŒ¹é…å±€éƒ¨ç‰¹å¾å¯¹ä½¿ç”¨æ ¸å‡½æ•°ï¼ˆå¦‚å†…ç§¯æˆ–ä¸‰è§’æ ¸ï¼‰è®¡ç®—ç›¸ä¼¼åº¦ï¼Œè€Œä¸æ˜¯ç®€å•è®¡æ•°ï¼Œä»è€Œä¿ç•™æ›´å¤šå‡ ä½•å’Œè¯­ä¹‰ä¿¡æ¯ã€‚</p></li>
</ul>
</li>
<li><p><strong>Aggregationï¼ˆèšåˆï¼‰</strong></p>
<ul class="simple">
<li><p>å°†æ¯ä¸ªè§†è§‰è¯ä¸‹çš„å±€éƒ¨ç‰¹å¾æè¿°å­è¿›è¡Œèšåˆï¼ˆå¦‚ä½¿ç”¨ VLAD æˆ– Fisher Vector é£æ ¼çš„æ–¹å¼ï¼‰ï¼Œæœ€ç»ˆå¾—åˆ°æ•´å¼ å›¾åƒçš„å‘é‡è¡¨ç¤ºã€‚</p></li>
</ul>
</li>
<li><p><strong>å‹ç¼©ä¸é‡åŒ–</strong></p>
<ul class="simple">
<li><p>é€šå¸¸é‡‡ç”¨äºŒå€¼å“ˆå¸Œã€PQï¼ˆProduct Quantizationï¼‰ç­‰æ–¹æ³•å‹ç¼©èšåˆå‘é‡ï¼Œæé«˜æ£€ç´¢æ•ˆç‡ã€‚</p></li>
</ul>
</li>
</ol>
<ul class="simple">
<li><p>ğŸ§© ASMK vs. ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯”</p></li>
</ul>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>ç‰¹æ€§</p></th>
<th class="head"><p>BoW</p></th>
<th class="head"><p>VLAD</p></th>
<th class="head"><p>Fisher Vector</p></th>
<th class="head"><p><strong>ASMK</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>åŒ¹é…æ–¹å¼</p></td>
<td><p>è®¡æ•°</p></td>
<td><p>æ®‹å·®èšåˆ</p></td>
<td><p>æ¦‚ç‡å»ºæ¨¡</p></td>
<td><p>é€‰æ‹©æ€§åŒ¹é… + æ ¸å‡½æ•°</p></td>
</tr>
<tr class="row-odd"><td><p>åŒ¹é…ç»†ç²’åº¦</p></td>
<td><p>ä½</p></td>
<td><p>ä¸­</p></td>
<td><p>é«˜</p></td>
<td><p><strong>é«˜</strong></p></td>
</tr>
<tr class="row-even"><td><p>ç‰¹å¾åŒºåˆ†æ€§</p></td>
<td><p>ä¸€èˆ¬</p></td>
<td><p>å¥½</p></td>
<td><p>å¥½</p></td>
<td><p><strong>ä¼˜ç§€</strong></p></td>
</tr>
<tr class="row-odd"><td><p>é€Ÿåº¦</p></td>
<td><p>å¿«</p></td>
<td><p>ä¸­</p></td>
<td><p>æ…¢</p></td>
<td><p>ä¸­</p></td>
</tr>
</tbody>
</table>
<ul class="simple">
<li><p>ğŸ§ª æ€§èƒ½è¡¨ç°</p>
<ul>
<li><p>ASMK åœ¨å¤šä¸ªå›¾åƒæ£€ç´¢åŸºå‡†ï¼ˆå¦‚ <strong>Oxford5k</strong>, <strong>Paris6k</strong>, <strong>Holidays</strong>, <strong>INSTRE</strong>ï¼‰ä¸­å–å¾—é¢†å…ˆæ€§èƒ½ã€‚</p></li>
<li><p>å°¤å…¶é€‚ç”¨äºç»†ç²’åº¦æ£€ç´¢ä»»åŠ¡ï¼Œå¦‚åœ°æ ‡è¯†åˆ«ã€ç‰©ä½“é‡è¯†åˆ«ç­‰ã€‚</p></li>
</ul>
</li>
<li><p>ğŸ“Œ å˜ç§ä¸æ‹“å±•</p>
<ul>
<li><p><strong>ASMK*</strong>ï¼šå¢åŠ å½’ä¸€åŒ–å’Œæ›´å¤æ‚æ ¸å‡½æ•°çš„æ”¹è¿›ç‰ˆã€‚</p></li>
<li><p><strong>DELF + ASMK</strong>ï¼šç»“åˆæ·±åº¦å­¦ä¹ å±€éƒ¨ç‰¹å¾ï¼ˆå¦‚ DELFï¼‰å’Œ ASMK ç¼–ç ï¼Œæˆä¸ºè¿‘å¹´æ¥éå¸¸å¼ºå¤§çš„ç»„åˆã€‚</p></li>
<li><p><strong>GeM + ASMK</strong>ï¼šå°†å…¨å±€æè¿°ä¸å±€éƒ¨èšåˆäº’è¡¥ï¼Œæé«˜æ•´ä½“æ£€ç´¢ç²¾åº¦ã€‚</p></li>
</ul>
</li>
</ul>
</section>
<section id="pnp-perspective-n-point">
<h3>PnP(Perspective-n-Point)<a class="headerlink" href="#pnp-perspective-n-point" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p>from: <a class="reference external" href="https://dl.acm.org/doi/10.1145/358669.358692">è®ºæ–‡</a></p></li>
</ul>
<p>ğŸŒ¼ å®šä¹‰</p>
<ul class="simple">
<li><p>Fischler å’Œ Bolles åœ¨ 1981 å¹´çš„ç»å…¸è®ºæ–‡ã€ŠRandom Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartographyã€‹ä¸­é¦–æ¬¡æå‡ºäº† Perspective-n-Pointï¼ˆPnPï¼‰é—®é¢˜çš„æ¦‚å¿µã€‚â€‹</p></li>
<li><p>å®šä¹‰ï¼šç»™å®šä¸€ç»„å·²çŸ¥çš„ä¸‰ç»´æ§åˆ¶ç‚¹åŠå…¶åœ¨å›¾åƒä¸­çš„äºŒç»´æŠ•å½±ï¼Œä¼°è®¡ç›¸æœºçš„å§¿æ€ï¼ˆå³ä½ç½®å’Œæ–¹å‘ï¼‰ã€‚â€‹è¿™é¡¹å·¥ä½œæ˜¯è®¡ç®—æœºè§†è§‰ä¸­ç›¸æœºä½å§¿ä¼°è®¡çš„åŸºç¡€ä¹‹ä¸€ã€‚</p></li>
<li><p>PnPï¼ˆPerspective-n-Pointï¼‰é—®é¢˜æ˜¯è®¡ç®—æœºè§†è§‰ä¸­çš„ä¸€ä¸ªåŸºæœ¬é—®é¢˜ï¼Œæ—¨åœ¨é€šè¿‡å·²çŸ¥çš„ä¸‰ç»´ç‚¹ä¸å…¶åœ¨å›¾åƒä¸­çš„äºŒç»´æŠ•å½±ï¼Œä¼°è®¡ç›¸æœºçš„å§¿æ€ï¼ˆå³ä½ç½®å’Œå¹³ç§»ï¼‰ã€‚â€‹</p></li>
</ul>
<p>ğŸ“Œ PnP é—®é¢˜æ¦‚è¿°
PnP é—®é¢˜çš„æ ¸å¿ƒæ˜¯ç»™å®šä¸€ç»„å·²çŸ¥çš„ä¸‰ç»´ç©ºé—´ç‚¹åŠå…¶åœ¨å›¾åƒä¸­çš„äºŒç»´æŠ•å½±ï¼Œæ±‚è§£ç›¸æœºçš„å§¿æ€ï¼ˆæ—‹è½¬çŸ©é˜µ R å’Œå¹³ç§»å‘é‡ tï¼‰</p>
<hr class="docutils" />
<p>ğŸ” å¸¸è§çš„ PnP æ±‚è§£æ–¹æ³•</p>
<ul class="simple">
<li><p><strong>P3Pï¼ˆPerspective-3-Pointï¼‰</strong>ï¼šä½¿ç”¨ä¸‰ä¸ªç‚¹å¯¹æ±‚è§£ç›¸æœºå§¿æ€ï¼Œé€‚ç”¨äºæœ€å°è§£é—®</p></li>
<li><p><strong>DLTï¼ˆDirect Linear Transformï¼‰</strong>ï¼šç›´æ¥çº¿æ€§å˜æ¢æ³•ï¼Œé€‚ç”¨äºç‚¹æ•°è¾ƒå¤šçš„æƒ…</p></li>
<li><p><strong>EPnPï¼ˆEfficient PnPï¼‰</strong>ï¼šé«˜æ•ˆçš„ PnP è§£æ³•ï¼Œé€‚ç”¨äºå¤§è§„æ¨¡ç‚¹é›†ï¼Œè®¡ç®—æ•ˆç‡</p></li>
<li><p><strong>UPnPï¼ˆUniversal PnPï¼‰</strong>ï¼šé€šç”¨çš„ PnP è§£æ³•ï¼Œé€‚ç”¨äºå„ç§ç›¸æœºæ¨¡</p></li>
<li><p><strong>RPnPï¼ˆRobust PnPï¼‰</strong>ï¼šé²æ£’çš„ PnP è§£æ³•ï¼Œå¢å¼ºäº†å¯¹å¼‚å¸¸å€¼çš„å¤„ç†èƒ½</p></li>
<li><p><strong>BAï¼ˆBundle Adjustmentï¼‰</strong>ï¼šæŸæŸè°ƒæ•´ï¼Œé€šè¿‡æœ€å°åŒ–é‡æŠ•å½±è¯¯å·®ä¼˜åŒ–ç›¸æœºå§¿æ€å’Œä¸‰ç»´ç‚¹ä½</p></li>
</ul>
<hr class="docutils" />
<p>ğŸ§­ åº”ç”¨é¢†åŸŸ</p>
<ul class="simple">
<li><p><strong>è§†è§‰ SLAMï¼ˆSimultaneous Localization and Mappingï¼‰</strong>ï¼šå®ç°ç›¸æœºçš„å®æ—¶å®šä½ä¸åœ°å›¾æ„å»º</p></li>
<li><p><strong>å¢å¼ºç°å®ï¼ˆARï¼‰</strong>ï¼šå®ç°è™šæ‹Ÿå¯¹è±¡ä¸ç°å®ä¸–ç•Œçš„å‡†ç¡®å¯¹é½</p></li>
<li><p><strong>ä¸‰ç»´é‡å»º</strong>ï¼šä»äºŒç»´å›¾åƒä¸­é‡å»ºä¸‰ç»´åœºæ™¯</p></li>
<li><p><strong>æœºå™¨äººå¯¼èˆª</strong>ï¼šå¸®åŠ©æœºå™¨äººåœ¨æœªçŸ¥ç¯å¢ƒä¸­å®šä½å’Œå¯¼èˆª</p></li>
</ul>
<hr class="docutils" />
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/04/IwXC4U.png" /></p>
<p>Figure 1: Dense Correspondences. MASt3R extends DUSt3R as it predicts dense correspondences, even in
regions where camera motion significantly degrades the visual similarity. Focal length can be derived from the
predicted 3D geometry, making our approach a standalone method for camera calibration, camera pose estimation
and 3D scene reconstruction, attaining and improving the performance of the state of the art on several extremely
challenging benchmarks.</p>
</section>
</section>
<section id="abstract">
<h2>Abstract<a class="headerlink" href="#abstract" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<ul class="simple">
<li><p>ğŸ§  <strong>èƒŒæ™¯ï¼šä¸ºä»€ä¹ˆè¦åšè¿™é¡¹ç ”ç©¶ï¼Ÿ</strong></p>
<ul>
<li><p>å›¾åƒåŒ¹é…ï¼ˆImage Matchingï¼‰æ˜¯<strong>3Dè§†è§‰ç³»ç»Ÿä¸­çš„æ ¸å¿ƒæ¨¡å—</strong>ï¼Œå®ƒç”¨äºåœ¨ä¸åŒè§†è§’ä¸‹çš„å›¾åƒä¸­æ‰¾åˆ°å¯¹åº”ç‚¹ã€‚</p></li>
<li><p>å°½ç®¡åŒ¹é…æœ¬è´¨ä¸Šæ¶‰åŠç›¸æœºå§¿æ€å’Œåœºæ™¯å‡ ä½•ï¼Œå³<strong>3Dä¿¡æ¯</strong>ï¼Œä½†è¿‡å»çš„æ–¹æ³•å‡ ä¹éƒ½æ˜¯ä»<strong>2Dè§’åº¦</strong>æ¥å¤„ç†é—®é¢˜ã€‚</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<ul class="simple">
<li><p>â—<strong>é—®é¢˜ï¼šç°æœ‰æ–¹æ³•çš„å±€é™</strong></p>
<ul>
<li><p>å½“å‰ä¸»æµæ–¹æ³•åªåœ¨<strong>2Då›¾åƒå¹³é¢</strong>ä¸­å¯»æ‰¾åƒç´ ç‚¹çš„å¯¹åº”å…³ç³»ã€‚</p></li>
<li><p>DUSt3R ä½œä¸ºä¸€ä¸ªåŸºäº Transformer çš„<strong>3Dé‡å»ºæ¡†æ¶</strong>ï¼Œæ˜¾ç¤ºå‡ºåœ¨è§†è§’å˜åŒ–å¤§æ—¶åŒ¹é…éå¸¸é²æ£’ï¼Œä½†å…¶åŒ¹é…çš„<strong>ç²¾åº¦æœ‰é™</strong>ã€‚</p></li>
<li><p>é«˜ç²¾åº¦çš„<strong>ç¨ å¯†åŒ¹é…</strong>ç®—æ³•é€šå¸¸è®¡ç®—å¤æ‚åº¦æ˜¯<strong>äºŒæ¬¡æ–¹å¤æ‚åº¦ï¼ˆquadratic complexityï¼‰</strong>ï¼Œåœ¨å®é™…åº”ç”¨ä¸­ä¼š<strong>éå¸¸æ…¢</strong>ã€‚</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<ul>
<li><p>ğŸ’¡<strong>è§£å†³æ–¹æ¡ˆï¼ˆè¿™ç¯‡è®ºæ–‡åšäº†ä»€ä¹ˆï¼‰</strong></p>
<ol class="arabic simple">
<li><p><strong>æå‡º MASt3R</strong>ï¼šå¢å¼ºç‰ˆ DUSt3Rï¼Œé€šè¿‡åŠ å…¥æ–°çš„<strong>dense local feature head</strong>ï¼ˆè¾“å‡ºç¨ å¯†å±€éƒ¨ç‰¹å¾ï¼‰ï¼Œä½¿ç”¨<strong>é¢å¤–çš„åŒ¹é…æŸå¤±å‡½æ•°è¿›è¡Œè®­ç»ƒ</strong>ï¼Œæå‡åŒ¹é…èƒ½åŠ›ã€‚</p></li>
<li><p><strong>å¼•å…¥ reciprocal matchingï¼ˆäº’æƒ åŒ¹é…ï¼‰æœºåˆ¶</strong>ï¼š</p></li>
</ol>
<ul class="simple">
<li><p>æ˜¾è‘—<strong>åŠ é€ŸåŒ¹é…</strong>é€Ÿåº¦ï¼ˆæ•°é‡çº§æå‡ï¼‰ã€‚</p></li>
<li><p>é™„å¸¦<strong>ç†è®ºä¿éšœ</strong>ã€‚</p></li>
<li><p>è¿˜èƒ½è¿›ä¸€æ­¥æå‡åŒ¹é…æ€§èƒ½ã€‚</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<ul class="simple">
<li><p>ğŸš€<strong>å®éªŒç»“æœ</strong></p>
<ul>
<li><p>MASt3R åœ¨å¤šä¸ªå›¾åƒåŒ¹é…ä»»åŠ¡ä¸Šéƒ½è¶…è¿‡ç°æœ‰ SOTAã€‚</p></li>
<li><p>åœ¨æœ€å…·æŒ‘æˆ˜æ€§çš„<strong>Map-free localization æ•°æ®é›†</strong>ä¸Šï¼Œ<strong>VCRE AUC æå‡è¾¾ 30% çš„ç»å¯¹å€¼</strong>ï¼Œè¯´æ˜åŒ¹é…è´¨é‡æ˜¾è‘—æå‡ã€‚</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<ul class="simple">
<li><p>ğŸ§©å…³é”®è¯æ€»ç»“ï¼š</p>
<ul>
<li><p>3D å›¾åƒåŒ¹é…</p></li>
<li><p>DUSt3R å¢å¼ºç‰ˆï¼ˆMASt3Rï¼‰</p></li>
<li><p>Dense featuresï¼ˆç¨ å¯†å±€éƒ¨ç‰¹å¾ï¼‰</p></li>
<li><p>Reciprocal matchingï¼ˆäº’æƒ åŒ¹é…ï¼‰</p></li>
<li><p>Transformer</p></li>
<li><p>æç«¯è§†è§’é²æ£’æ€§</p></li>
<li><p>å¿«é€Ÿä¸”ç²¾ç¡®çš„åŒ¹é…</p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="introduction">
<h2>1. Introduction<a class="headerlink" href="#introduction" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<section id="why">
<h3>â‘  <strong>ç ”ç©¶åŠ¨æœºä¸èƒŒæ™¯ï¼ˆWhyï¼‰</strong><a class="headerlink" href="#why" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<blockquote>
<div><p>å›¾åƒåŒ¹é…æ˜¯æ‰€æœ‰ 3D è§†è§‰ä»»åŠ¡ï¼ˆå¦‚å»ºå›¾ã€å®šä½ã€å¯¼èˆªã€æµ‹ç»˜ã€æœºå™¨äººï¼‰ä¸­ä¸å¯æˆ–ç¼ºçš„ç»„æˆéƒ¨åˆ†ã€‚</p>
</div></blockquote>
<ul class="simple">
<li><p>åœ¨ offline é˜¶æ®µï¼ˆå»ºå›¾ï¼‰å’Œ online é˜¶æ®µï¼ˆå®šä½ï¼‰éƒ½ä¾èµ–åŒ¹é…ï¼ˆå¦‚ COLMAP + PnPï¼‰ã€‚</p></li>
<li><p>ç›®æ ‡ï¼š<strong>åœ¨ä¸¤ä¸ªå›¾åƒä¸­æ‰¾åˆ°é«˜ç²¾åº¦ã€ç¨ å¯†ä¸”é²æ£’çš„å¯¹åº”ç‚¹</strong>ï¼Œå°¤å…¶æ˜¯å¯¹è§†è§’å’Œå…‰ç…§å˜åŒ–é²æ£’ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="what-existed-before">
<h3>â‘¡ <strong>ä¼ ç»Ÿæ–¹æ³•å›é¡¾ï¼ˆWhat existed beforeï¼‰</strong><a class="headerlink" href="#what-existed-before" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p><strong>ç»å…¸ä¸‰æ­¥åŒ¹é…æµç¨‹ï¼š</strong></p>
<ol class="arabic simple">
<li><p><strong>å…³é”®ç‚¹æå–</strong>ï¼ˆsparse, repeatableï¼‰</p></li>
<li><p><strong>å±€éƒ¨ç‰¹å¾æè¿°</strong>ï¼ˆå¦‚ SIFTï¼‰</p></li>
<li><p><strong>åŸºäºç‰¹å¾è·ç¦»è¿›è¡ŒåŒ¹é…</strong></p></li>
</ol>
</li>
<li><p>ä¼˜ç‚¹ï¼š</p>
<ul>
<li><p>å¿«é€Ÿï¼ˆæ¯«ç§’çº§ï¼‰</p></li>
<li><p>å°è§†è§’/å…‰ç…§å˜åŒ–ä¸‹å‡†ç¡®</p></li>
</ul>
</li>
<li><p>ç¼ºç‚¹ï¼š</p>
<ul>
<li><p>ä¸¢å¼ƒäº†å…¨å±€å‡ ä½•ä¸Šä¸‹æ–‡</p></li>
<li><p>å®¹æ˜“å—<strong>é‡å¤çº¹ç†ã€ä½çº¹ç†åŒºåŸŸ</strong>å½±å“</p></li>
<li><p>åŒ¹é…é”™è¯¯ï¼Œå°¤å…¶æ˜¯åœ¨çœŸå®åœºæ™¯ä¸‹è¡¨ç°ä¸ä½³</p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="what-improved">
<h3>â‘¢ <strong>è¿‘å¹´æ”¹è¿›æ–¹å‘ï¼ˆWhat improvedï¼‰</strong><a class="headerlink" href="#what-improved" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<blockquote>
<div><p>ä¸ºäº†è§£å†³å±€éƒ¨åŒ¹é…ä¸ç¨³çš„é—®é¢˜ï¼Œå¼•å…¥äº†å…¨å±€ä¸Šä¸‹æ–‡</p>
</div></blockquote>
<ul class="simple">
<li><p><strong>SuperGlue</strong>ï¼šå¼•å…¥å…¨å±€ä¼˜åŒ–ç­–ç•¥å­¦ä¹ åŒ¹é…å…ˆéªŒ</p>
<ul>
<li><p>ä½†å¦‚æœå…³é”®ç‚¹/ç‰¹å¾ä¸å¯é ï¼Œåå¤„ç†ä¹Ÿâ€œè¡¥æ•‘â€ä¸äº†</p></li>
</ul>
</li>
<li><p><strong>Dense Matching</strong>ï¼ˆå¦‚ LoFTRï¼‰ï¼šç›´æ¥åŒ¹é…æ•´å¼ å›¾åƒ</p>
<ul>
<li><p>å€ŸåŠ©<strong>Transformer çš„å…¨å±€æ³¨æ„åŠ›æœºåˆ¶</strong></p></li>
<li><p>å¯é²æ£’åº”å¯¹é‡å¤/ä½çº¹ç†åŒºåŸŸ</p></li>
<li><p>LoFTR åœ¨ Map-free benchmark ä¸Šæ ‘ç«‹æ–° SOTA</p></li>
</ul>
</li>
</ul>
<p>âš ï¸ <strong>ä½†</strong>ï¼šLoFTR çš„ VCRE ç²¾åº¦ä»… 34%ï¼Œå®é™…ä»åä½ã€‚</p>
</section>
<hr class="docutils" />
<section id="problem-statement">
<h3>â‘£ <strong>æ ¸å¿ƒé—®é¢˜ï¼ˆProblem Statementï¼‰</strong><a class="headerlink" href="#problem-statement" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<blockquote>
<div><p>å¤§å¤šæ•°æ–¹æ³•æŠŠåŒ¹é…å½“ä½œ<strong>2Dä»»åŠ¡</strong>ï¼Œè€Œå®é™…ä¸Šå®ƒæ˜¯ä¸€ä¸ª<strong>3Dä»»åŠ¡</strong>ã€‚</p>
</div></blockquote>
<ul class="simple">
<li><p>åŒ¹é…ç›®æ ‡æ˜¯æ‰¾å‡º<strong>è§‚å¯ŸåŒä¸€ 3D ç‚¹çš„åƒç´ </strong></p></li>
<li><p>æœ¬è´¨ä¸Šç”±ç›¸æœºå§¿æ€å’Œåœºæ™¯å‡ ä½•å†³å®šï¼ˆepipolar å‡ ä½•ï¼‰</p></li>
<li><p>DUSt3R è™½ç„¶æ˜¯ 3D é‡å»ºæ–¹æ³•ï¼Œä½†å…¶äº§å‡ºçš„â€œå‰¯äº§å“â€åŒ¹é…ç»“æœå·²è¶…è¿‡å¤§å¤šæ•° 2D æ–¹æ³•</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="mast3r-our-solution">
<h3>â‘¤ <strong>æœ¬æ–‡æå‡ºçš„æ–¹æ³• MASt3Rï¼ˆOur Solutionï¼‰</strong><a class="headerlink" href="#mast3r-our-solution" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<blockquote>
<div><p>åœ¨ DUSt3R ä¸Šå¢å¼ºè®¾è®¡ï¼Œä¸“æ³¨æå‡åŒ¹é…ç²¾åº¦ï¼ŒåŒæ—¶ä¿æŒé²æ£’æ€§ã€‚</p>
</div></blockquote>
<ul class="simple">
<li><p>å¢åŠ  <strong>second head</strong>ï¼šå›å½’ç¨ å¯†å±€éƒ¨ç‰¹å¾å›¾ï¼ˆdense local feature mapsï¼‰</p></li>
<li><p>ä½¿ç”¨ <strong>InfoNCE loss</strong> è¿›è¡ŒåŒ¹é…è®­ç»ƒ</p></li>
<li><p>æå‡º <strong>coarse-to-fine åŒ¹é…æœºåˆ¶</strong>ï¼Œå¤šå°ºåº¦å¤„ç†åŒ¹é…é—®é¢˜</p></li>
<li><p><strong>å…³é”®æŠ€æœ¯çªç ´</strong>ï¼š</p>
<ul>
<li><p>reciprocal matchingï¼ˆäº’æƒ åŒ¹é…ï¼‰</p></li>
<li><p>å¿«é€Ÿç®—æ³•ï¼ˆå‡ ä¹å¿« 100 å€ï¼‰</p></li>
<li><p>ç²¾åº¦å’Œæ•ˆç‡åŒæå‡</p></li>
</ul>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="claimed-contributions">
<h3>â‘¥ <strong>ä¸‰å¤§è´¡çŒ®æ€»ç»“ï¼ˆClaimed Contributionsï¼‰</strong><a class="headerlink" href="#claimed-contributions" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ol class="arabic simple">
<li><p><strong>æå‡º MASt3R æ¡†æ¶</strong>ï¼šåŸºäº DUSt3Rï¼Œå…·å¤‡é«˜ç²¾åº¦å’Œé²æ£’æ€§ï¼Œè¾“å‡ºå±€éƒ¨ç‰¹å¾å›¾ç”¨äºåŒ¹é…</p></li>
<li><p><strong>æå‡º coarse-to-fine å¤šå°ºåº¦åŒ¹é…æœºåˆ¶ + é«˜é€Ÿ reciprocal matching ç®—æ³•</strong></p></li>
<li><p><strong>åœ¨å¤šä¸ªå®šä½ benchmark ä¸Šè¶…è¶Š SOTA</strong></p></li>
</ol>
</section>
</section>
<hr class="docutils" />
<section id="id2">
<h2>ğŸ§  æ€ç»´å¯¼å›¾å¼æ€»ç»“<a class="headerlink" href="#id2" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>æ ¸å¿ƒé—®é¢˜ï¼šå›¾åƒåŒ¹é… â‰  çº¯2Dé—®é¢˜ â†’ æ˜¯3Dé—®é¢˜

ä¼ ç»Ÿæ–¹æ³•ï¼ˆSIFT/Keypointï¼‰ï¼š
  âœ” å¿«é€Ÿ
  âœ˜ ä¸¢å¤±å…¨å±€å‡ ä½•ï¼Œé‡å¤çº¹ç†/ä½çº¹ç†å¤±è´¥

å¯†é›†æ–¹æ³•ï¼ˆLoFTRï¼‰ï¼š
  âœ” Transformer+å…¨å±€åŒ¹é… â†’ æ›´é²æ£’
  âœ˜ ç²¾åº¦ä»ä½ï¼ˆ34% VCREï¼‰

å¯å‘ï¼šDUSt3R ç”¨äº3Dé‡å»ºï¼Œå…¶3Dâ€œå‰¯äº§å“â€åŒ¹é…åè€Œæ›´å¥½ï¼

åˆ›æ–°æ–¹æ³• MASt3Rï¼š
  ğŸ”§ æ–°å¢ dense feature headï¼ˆInfoNCE lossï¼‰
  ğŸ” Reciprocal Matching + Multi-scale Matching
  ğŸš€ å¿«ã€å‡†ã€é²æ£’

è´¡çŒ®æ€»ç»“ï¼š
  âœ… MASt3R â†’ ç²¾åº¦ + é²æ£’æ€§å…¼å¤‡
  âœ… å¿«é€Ÿ reciprocal matchingï¼Œæ”¯æŒé«˜åˆ†è¾¨ç‡
  âœ… SOTA åœ¨å¤šä¸ª benchmark ä¸Šå¤§å¹…é¢†å…ˆ
</pre></div>
</div>
</section>
<section id="related-works">
<h2>2. Related works<a class="headerlink" href="#related-works" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<ul class="simple">
<li><p>ç³»ç»Ÿåœ°æ¢³ç†äº†å›¾åƒåŒ¹é…çš„å‘å±•è·¯å¾„ï¼Œä»ä¼ ç»Ÿå…³é”®ç‚¹åŒ¹é…ï¼Œåˆ°ç¨ å¯†åŒ¹é…ï¼Œå†åˆ°èåˆ 3D å‡ ä½•çš„ç°ä»£å°è¯•ã€‚</p></li>
</ul>
<section id="keypoint-based-matching">
<h3>â‘  å…³é”®ç‚¹åŒ¹é…ï¼ˆKeypoint-based Matchingï¼‰<a class="headerlink" href="#keypoint-based-matching" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p><strong>æ–¹æ³•æµç¨‹ï¼š</strong></p>
<ol class="arabic simple">
<li><p>å…³é”®ç‚¹æ£€æµ‹ï¼ˆkeypoint detectionï¼‰</p></li>
<li><p>ç‰¹å¾æè¿°ï¼ˆdescriptorï¼‰</p></li>
<li><p>ç‰¹å¾ç©ºé—´æœ€è¿‘é‚»åŒ¹é…ï¼ˆnearest-neighbor searchï¼‰</p></li>
</ol>
<p><strong>æ¼”è¿›æ–¹å‘ï¼š</strong></p>
<ul class="simple">
<li><p>ä» SIFT ç­‰æ‰‹å·¥æ–¹æ³• â†’ å‘æ·±åº¦å­¦ä¹ æ–¹æ³•å‘å±•</p></li>
<li><p>æ¨¡å—å¯å­¦ä¹ åŒ–ï¼š</p>
<ul>
<li><p>å­¦ä¹ æ£€æµ‹å…³é”®ç‚¹</p></li>
<li><p>å­¦ä¹ ç‰¹å¾æè¿°</p></li>
<li><p>è”åˆå­¦ä¹ æ£€æµ‹+æè¿°</p></li>
</ul>
</li>
</ul>
<p><strong>ä¼˜åŠ¿ï¼š</strong></p>
<ul class="simple">
<li><p>é€Ÿåº¦å¿«ï¼Œç²¾åº¦é«˜ï¼ˆå°¤å…¶åœ¨å…‰ç…§/è§†è§’å˜åŒ–ä¸å‰§çƒˆæ—¶ï¼‰</p></li>
<li><p>åœ¨å¤šä¸ª benchmark è¡¨ç°ä»ç„¶ä¼˜ç§€</p></li>
</ul>
<p><strong>å±€é™æ€§ï¼š</strong></p>
<ul class="simple">
<li><p>ä»…è€ƒè™‘å±€éƒ¨ï¼ˆlocalï¼‰ç‰¹å¾ï¼Œæ— æ³•æ•æ‰å…¨å±€è¯­ä¹‰</p></li>
<li><p>åœ¨é‡å¤çº¹ç†/ä½çº¹ç†åŒºåŸŸè¡¨ç°å·®</p></li>
<li><p>å¯¹å¤§å°ºåº¦è§†è§’å˜åŒ–ä¸é²æ£’</p></li>
</ul>
<p><strong>æ”¹è¿›å°è¯•ï¼š</strong></p>
<ul class="simple">
<li><p><strong>SuperGlue</strong> ç­‰æ–¹æ³• å¼•å…¥å›¾ç¥ç»ç½‘ç»œï¼Œåœ¨åŒ¹é…é˜¶æ®µåŠ å…¥å…¨å±€æ¨ç†ï¼ˆä½†æ£€æµ‹å’Œæè¿°é˜¶æ®µä»ç„¶æ˜¯å±€éƒ¨çš„ï¼‰</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="dense-semi-dense-matching">
<h3>â‘¡ ç¨ å¯†åŒ¹é…ï¼ˆDense/Semi-dense Matchingï¼‰<a class="headerlink" href="#dense-semi-dense-matching" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p><strong>æ–¹æ³•ç‰¹ç‚¹ï¼š</strong></p>
<ul class="simple">
<li><p>è€ƒè™‘æ¯ä¸€ä¸ªåƒç´ ä¹‹é—´çš„å¯¹åº”å…³ç³»</p></li>
<li><p>ä»£è¡¨æ–¹æ³•ï¼š</p>
<ul>
<li><p>åŠç¨ å¯†</p></li>
<li><p>å…¨ç¨ å¯†</p></li>
</ul>
</li>
</ul>
<p><strong>ä¸å…‰æµæ–¹æ³•çš„å…³ç³»ï¼š</strong></p>
<ul class="simple">
<li><p>ä¸ optical flow æ–¹æ³•é«˜åº¦ç›¸ä¼¼</p></li>
<li><p>éƒ½ä½¿ç”¨ coarse-to-fine ç­–ç•¥é™ä½å¤æ‚åº¦</p></li>
</ul>
<p><strong>ä¼˜åŠ¿ï¼š</strong></p>
<ul class="simple">
<li><p>å…¨å±€ä¸Šä¸‹æ–‡ï¼Œæ›´å¥½å¤„ç†ä½çº¹ç†/é‡å¤å›¾æ¡ˆ</p></li>
<li><p>åœ¨è¯¸å¦‚ viewpoint/illumination å·¨å˜çš„æ•°æ®é›†ä¸­æ•ˆæœä¼˜è¶Š</p></li>
</ul>
<p><strong>å±€é™æ€§ï¼š</strong></p>
<ul class="simple">
<li><p>è®¡ç®—èµ„æºå¼€é”€å¤§</p></li>
<li><p>ä¾æ—§æ˜¯<strong>äºŒç»´å›¾åƒç©ºé—´ä¸­çš„åŒ¹é…</strong>ï¼Œä¸è€ƒè™‘å‡ ä½•ä¸€è‡´æ€§ â†’ å¯¹äºè§†è§‰å®šä½åœºæ™¯ä»ç„¶æœ‰é™åˆ¶</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="camera-pose-estimation">
<h3>â‘¢ ç›¸æœºä½å§¿ä¼°è®¡ï¼ˆCamera Pose Estimationï¼‰<a class="headerlink" href="#camera-pose-estimation" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p><strong>ä¸»æµç­–ç•¥ï¼š</strong></p>
<ul class="simple">
<li><p>éƒ½ä¾èµ–åƒç´ çº§åˆ«çš„å›¾åƒåŒ¹é…</p></li>
<li><p>è¿‘å¹´æ¥ä¸æ–­æœ‰æ–°çš„ã€æ›´å…·æŒ‘æˆ˜æ€§çš„ benchmarkï¼š</p>
<ul>
<li><p>Aachen Day-Nightã€InLocã€CO3Dã€Map-free</p></li>
</ul>
</li>
</ul>
<p><strong>æœ€å…·æŒ‘æˆ˜çš„æ•°æ®é›†ï¼š</strong></p>
<ul class="simple">
<li><p><strong>Map-free</strong>ï¼šä»…æä¾›ä¸€å¼ å‚è€ƒå›¾ï¼Œæ— åœ°å›¾ï¼Œè§†è§’å˜åŒ–å¯è¾¾ <span class="math notranslate nohighlight">\(180^\circ\)</span></p></li>
</ul>
</section>
<hr class="docutils" />
<section id="d-3d-aware-matching">
<h3>â‘£ å‘3DåŒ¹é…è¿‡æ¸¡ï¼ˆ3D-Aware Matchingï¼‰<a class="headerlink" href="#d-3d-aware-matching" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p><strong>ä¸ºä»€ä¹ˆéœ€è¦ 3D è§†è§’ï¼Ÿ</strong></p>
<ul class="simple">
<li><p>ä¼ ç»Ÿ 2D åŒ¹é…æ–¹æ³•åœ¨å¤§è§†è§’å˜åŒ–ä¸‹å¤±è´¥</p></li>
<li><p>çœŸæ­£çš„å¯¹åº”å…³ç³»æ˜¯â€œè§‚å¯ŸåŒä¸€ 3D ç‚¹â€</p></li>
</ul>
<p><strong>å·²æœ‰å°è¯•ï¼š</strong></p>
<ul class="simple">
<li><p>ä½¿ç”¨ç‰©ç†å…ˆéªŒï¼ˆepipolar å‡ ä½•ï¼‰æ¥ç›‘ç£åŒ¹é…</p>
<ul>
<li><p>ä½†åŸºæœ¬å±äºè¾…åŠ©è®­ç»ƒï¼Œä¸æ”¹å˜æ–¹æ³•æœ¬è´¨</p></li>
</ul>
</li>
<li><p><strong>Toft et al.</strong>ï¼šç”¨å•ç›®æ·±åº¦ä¼°è®¡åšé€è§†å˜æ¢æ¥æ ¡æ­£å›¾åƒ â†’ æå‡ keypoint æè¿°ç¬¦ç¨³å®šæ€§</p></li>
<li><p><strong>Diffusion for pose/rays</strong>ï¼šé€šè¿‡å¼•å…¥ 3D å‡ ä½•çº¦æŸè¿›è¡Œå§¿æ€ä¼°è®¡ï¼ˆä¸æ˜¯åŒ¹é…æ–¹æ³•ï¼Œä½†æ€æƒ³ç±»ä¼¼ï¼‰</p></li>
</ul>
<p><strong>é‡è¦é‡Œç¨‹ç¢‘ï¼šDUSt3R</strong></p>
<ul class="simple">
<li><p>èµ·åˆæ˜¯åš<strong>æ— æ ‡å®šå›¾åƒçš„ 3D é‡å»º</strong></p></li>
<li><p>åŒ¹é…ç»“æœåªæ˜¯â€œå‰¯äº§ç‰©â€</p></li>
<li><p>å´åœ¨ Map-free benchmark ä¸Šæ’åç¬¬ä¸€ [5]</p></li>
</ul>
<p><strong>æœ¬æ–‡çš„åˆ‡å…¥ç‚¹ï¼š</strong></p>
<blockquote>
<div><p>å»¶ç»­ DUSt3R æ€è·¯ï¼Œè¿›ä¸€æ­¥<strong>æ˜¾å¼å­¦ä¹ ç”¨äºåŒ¹é…çš„å±€éƒ¨ç‰¹å¾</strong>ï¼Œè€Œéè¢«åŠ¨ä¾èµ–é‡å»ºå‰¯äº§å“ã€‚</p>
</div></blockquote>
</section>
</section>
<hr class="docutils" />
<section id="id3">
<h2>ğŸ§  æ€»ç»“æ€ç»´å¯¼å›¾<a class="headerlink" href="#id3" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>å›¾åƒåŒ¹é…æŠ€æœ¯å‘å±•è·¯çº¿ï¼š

1ï¸âƒ£ Keypoint-based Matching ï¼ˆç»å…¸ï¼‰
  - SIFT â†’ SuperPoint
  - æ£€æµ‹ + æè¿° + åŒ¹é…
  - âœ” å¿«é€Ÿ
  - âœ˜ æœ¬åœ°ä¿¡æ¯ï¼Œå¼±è§†è§’é²æ£’

2ï¸âƒ£ Dense/Semi-dense Matching ï¼ˆå…¨å±€ï¼‰
  - LoFTRã€DenseGAP
  - âœ” å…¨å±€ä¸Šä¸‹æ–‡ï¼Œå¼ºé²æ£’
  - âœ˜ è®¡ç®—é‡å¤§ï¼Œä¾ç„¶æ˜¯2Dæ–¹æ³•

3ï¸âƒ£ Pose Estimation â†’ æå‡ºæ›´å¼º benchmark
  - Aachenã€Map-free ç­‰
  - åŒ¹é…èƒ½åŠ›æˆæ€§èƒ½ç“¶é¢ˆ

4ï¸âƒ£ 3D-Aware Matching ï¼ˆè¶‹åŠ¿ï¼‰
  - Epipolar çº¦æŸã€å•ç›®æ·±åº¦æ ¡æ­£
  - DUSt3R â†’ ç”¨ 3D é‡å»ºåšåŒ¹é…ï¼Œæ•ˆæœåè¶…å¤šæ•°æ–¹æ³•
  - æœ¬æ–‡å·¥ä½œï¼šæ˜¾å¼è®­ç»ƒ dense features â†’ æå‡ DUSt3R åŒ¹é…ç²¾åº¦
</pre></div>
</div>
</section>
<section id="method">
<h2>3. Method<a class="headerlink" href="#method" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p>ğŸ¯ ä»»åŠ¡ç›®æ ‡</p>
<p>ç»™å®šä¸¤å¼ å›¾åƒ <span class="math notranslate nohighlight">\(I^{1}\)</span> å’Œ <span class="math notranslate nohighlight">\(I^{2}\)</span>ï¼Œåˆ†åˆ«ç”±ä¸¤å°ç›¸æœº <span class="math notranslate nohighlight">\(C^{1}\)</span> å’Œ <span class="math notranslate nohighlight">\(C^{2}\)</span> æ‹æ‘„ï¼Œå…¶å‚æ•°æœªçŸ¥ï¼Œæˆ‘ä»¬å¸Œæœ›æ¢å¤ä¸€ç»„åƒç´ å¯¹åº”å…³ç³» <span class="math notranslate nohighlight">\(\{(i,j)\}\)</span>ï¼Œå…¶ä¸­ <span class="math notranslate nohighlight">\(i,j\)</span> æ˜¯åƒç´  <span class="math notranslate nohighlight">\(i=(u_{i},\nu_{i}),j=(u_{j},\nu_{j})\in \{1,\ldots,W\}\times\{1,\ldots,H\}\)</span>ï¼Œ<span class="math notranslate nohighlight">\(W, H\)</span> åˆ†åˆ«ä¸ºå›¾åƒçš„å®½åº¦å’Œé«˜åº¦ã€‚ä¸ºäº†ç®€åŒ–èµ·è§ï¼Œæˆ‘ä»¬å‡è®¾å®ƒä»¬å…·æœ‰ç›¸åŒçš„åˆ†è¾¨ç‡ï¼Œä½†ä¸å¤±ä¸€èˆ¬æ€§ã€‚æœ€ç»ˆç½‘ç»œå¯ä»¥å¤„ç†ä¸åŒå®½é«˜æ¯”çš„å›¾åƒå¯¹ã€‚</p>
<hr class="docutils" />
<p>ğŸŒ æ•´ä½“æ¶æ„ï¼ˆå¦‚å›¾2æ‰€ç¤ºï¼‰</p>
<ol class="arabic simple">
<li><p><strong>è¾“å…¥</strong>ï¼š</p>
<ul class="simple">
<li><p>ä¸¤å¼ å›¾åƒ <span class="math notranslate nohighlight">\( I^1 \)</span>, <span class="math notranslate nohighlight">\( I^2 \)</span></p></li>
<li><p>ä½¿ç”¨ Vision Transformer (ViT) ç¼–ç æ¯å¼ å›¾åƒç‰¹å¾ï¼š<span class="math notranslate nohighlight">\( H^1, H^2 \)</span></p></li>
</ul>
</li>
<li><p><strong>è§£ç </strong>ï¼š</p>
<ul class="simple">
<li><p>ä½¿ç”¨ä¸¤ä¸ª<strong>äº¤å‰æ³¨æ„åŠ›è§£ç å™¨</strong>å¯¹å›¾åƒç‰¹å¾è¿›è¡Œè”åˆè§£ç ï¼Œæ„å»ºç©ºé—´å‡ ä½•å…³ç³»ï¼š<span class="math notranslate nohighlight">\( H'^1, H'^2 \)</span></p></li>
</ul>
</li>
<li><p><strong>è¾“å‡º</strong>ï¼ˆæ¯ä¸ªåƒç´ ï¼‰ï¼š</p>
<ul class="simple">
<li><p>ä¸€ä¸ª 3D ç‚¹ï¼ˆPointMapï¼‰ï¼š<span class="math notranslate nohighlight">\( X^{1,1}, X^{2,1} \)</span></p></li>
<li><p>ä¸€ä¸ªç½®ä¿¡åº¦å€¼ï¼š<span class="math notranslate nohighlight">\( C^1, C^2 \)</span></p></li>
<li><p>ä¸€ä¸ªå±€éƒ¨ç‰¹å¾å‘é‡ï¼ˆåœ¨åç»­éƒ¨åˆ†ä»‹ç»ï¼‰</p></li>
</ul>
</li>
</ol>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/04/E99eEB.png" /></p>
<p>Figure 2: Overview of the proposed approach. Given two input images to match, our network regresses for each image and each input pixel a 3D point, a confidence value and a local feature. Plugging either 3D points or local features into our fast reciprocal NN matcher (3.3) yields robust correspondences. Compared to the DUSt3R framework which we build upon, our contributions are highlighted in blue.</p>
<hr class="docutils" />
<section id="the-dust3r-framework">
<h3>3.1 The DUSt3R framework<a class="headerlink" href="#the-dust3r-framework" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p><strong>DUSt3R æ¡†æ¶</strong> çš„åŸç†ï¼Œå®ƒæ˜¯ä¸€ä¸ªå¯ä»¥<strong>ä»å›¾åƒä¸­è”åˆå®Œæˆç›¸æœºæ ‡å®šï¼ˆcalibrationï¼‰å’Œä¸‰ç»´é‡å»ºï¼ˆ3D reconstructionï¼‰</strong> çš„æ–°æ–¹æ³•ã€‚</p>
<hr class="docutils" />
<p>ğŸ”§ DUSt3R æ˜¯ä»€ä¹ˆï¼Ÿ</p>
<p>DUSt3R æ˜¯ä¸€ä¸ªåŸºäº Transformer çš„ç½‘ç»œï¼Œè¾“å…¥ä¸¤å¼ å›¾åƒï¼Œå°±å¯ä»¥é¢„æµ‹è¿™ä¸¤ä¸ªè§†è§’ä¸‹çš„ä¸‰ç»´ç‚¹äº‘ï¼ˆç§°ä¸º <em>pointmaps</em>ï¼‰ï¼Œè¿™ç›¸å½“äºå¯¹åœºæ™¯åšäº†å±€éƒ¨ 3D é‡å»ºã€‚</p>
<p>å…·ä½“æ¥è¯´ï¼š</p>
<ul class="simple">
<li><p>è¾“å‡ºçš„æ˜¯ä¸¤ä¸ª <strong>dense 3D pointmaps</strong>ï¼š<span class="math notranslate nohighlight">\(X^{1,1}\)</span> å’Œ <span class="math notranslate nohighlight">\(X^{2,1}\)</span>ã€‚</p></li>
<li><p>æ¯ä¸ª pointmap <span class="math notranslate nohighlight">\(X^{a,b} \in \mathbb{R}^{H \times W \times 3}\)</span> è¡¨ç¤º <strong>å›¾åƒ <span class="math notranslate nohighlight">\(I^a\)</span> ä¸­æ¯ä¸ªåƒç´ </strong>ï¼ˆæ€»å…± <span class="math notranslate nohighlight">\(H \times W\)</span> ä¸ªï¼‰<strong>åœ¨ç›¸æœº <span class="math notranslate nohighlight">\(C^b\)</span> åæ ‡ç³»ä¸‹çš„ä¸‰ç»´ä½ç½®</strong>ã€‚</p></li>
</ul>
<p>æ¯”å¦‚ï¼š</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(X^{1,1}\)</span> æ˜¯å›¾åƒ <span class="math notranslate nohighlight">\(I^1\)</span> çš„ç‚¹åœ¨ç›¸æœº <span class="math notranslate nohighlight">\(C^1\)</span> åæ ‡ç³»ä¸‹çš„ 3D ç‚¹ï¼›</p></li>
<li><p><span class="math notranslate nohighlight">\(X^{2,1}\)</span> æ˜¯å›¾åƒ <span class="math notranslate nohighlight">\(I^2\)</span> çš„ç‚¹åœ¨ç›¸æœº <span class="math notranslate nohighlight">\(C^1\)</span> åæ ‡ç³»ä¸‹çš„ 3D ç‚¹ã€‚</p></li>
</ul>
<p>é€šè¿‡æŠŠè¿™ä¸¤ä¸ªè§†è§’ä¸‹çš„ç‚¹éƒ½æ˜ å°„åˆ° <strong>åŒä¸€ä¸ªåæ ‡ç³»ä¸‹ï¼ˆ<span class="math notranslate nohighlight">\(C^1\)</span>ï¼‰</strong>ï¼Œå®ƒå°±å®Œæˆäº†ï¼š</p>
<ul class="simple">
<li><p>ç›¸æœºä¹‹é—´çš„ç©ºé—´å‡ ä½•å…³ç³»æ¨æ–­ï¼ˆ= æ ‡å®šï¼‰</p></li>
<li><p>æ¯å¼ å›¾åƒçš„ä¸‰ç»´é‡å»º</p></li>
</ul>
<hr class="docutils" />
<p>ğŸ§  ç½‘ç»œç»“æ„ï¼šä¸‰æ­¥èµ°</p>
<ol class="arabic simple">
<li><p><strong>ViT ç¼–ç å™¨</strong>ï¼ˆSiamese æ¶æ„ï¼‰ï¼š</p>
<ul class="simple">
<li><p>ä¸¤å¼ å›¾åˆ†åˆ«è¾“å…¥ Vision Transformer ç¼–ç å™¨ï¼Œå¾—åˆ°ç‰¹å¾è¡¨ç¤º <span class="math notranslate nohighlight">\(H^1\)</span> å’Œ <span class="math notranslate nohighlight">\(H^2\)</span>ï¼š
$<span class="math notranslate nohighlight">\(
\boldsymbol{H}^{1}=\operatorname{Encoder}({\boldsymbol{I}}^{1}), \quad \boldsymbol{H}^{2}=\operatorname{Encoder}({\boldsymbol{I}}^{2})
\)</span>$</p></li>
</ul>
</li>
<li><p><strong>åŒè§£ç å™¨ï¼ˆIntertwined Decodersï¼‰</strong>ï¼š</p>
<ul class="simple">
<li><p>ä¸¤ä¸ª Decoder å¯¹ä¸¤ä¸ªè§†è§’çš„ç‰¹å¾è¿›è¡Œäº¤å‰æ³¨æ„åŠ›å¤„ç†ï¼Œå½¼æ­¤é€šä¿¡ï¼Œä»è€Œç†è§£ï¼š</p>
<ul>
<li><p>ä¸¤ä¸ªè§†è§’çš„ç›¸å¯¹ä½ç½®å…³ç³»</p></li>
<li><p>æ•´ä¸ªåœºæ™¯çš„ 3D å‡ ä½•</p></li>
</ul>
</li>
<li><p>è¾“å‡ºæ–°çš„å¢å¼ºåçš„è¡¨ç¤ºï¼š<span class="math notranslate nohighlight">\(H^{\prime 1}, H^{\prime 2}\)</span></p></li>
</ul>
</li>
<li><p><strong>é¢„æµ‹å¤´ï¼ˆHeadï¼‰</strong>ï¼š</p>
<ul class="simple">
<li><p>æŠŠç¼–ç å™¨å’Œè§£ç å™¨çš„è¾“å‡ºæ‹¼æ¥åï¼Œè¾“å…¥åˆ°ä¸€ä¸ªé¢„æµ‹å¤´ï¼Œå¾—åˆ°ï¼š</p>
<ul>
<li><p>ç‚¹äº‘ <span class="math notranslate nohighlight">\(X^{1,1}\)</span> å’Œ <span class="math notranslate nohighlight">\(X^{2,1}\)</span>ï¼ˆ3D ä½ç½®ï¼‰</p></li>
<li><p>å¯¹åº”çš„ç½®ä¿¡å›¾ï¼ˆConfidence Mapï¼‰<span class="math notranslate nohighlight">\(C^1\)</span> å’Œ <span class="math notranslate nohighlight">\(C^2\)</span>ï¼š
$<span class="math notranslate nohighlight">\(
\boldsymbol{X}^{1,1},\boldsymbol{C}^{1}=\mathrm{Head}_{3\mathrm{D}}^{1}([\boldsymbol{H}^{1},\boldsymbol{H}^{\prime1}])
\)</span>$</p></li>
</ul>
</li>
</ul>
</li>
</ol>
<hr class="docutils" />
<p>ğŸ§ª ç›‘ç£è®­ç»ƒï¼šå›å½’æŸå¤±ï¼ˆRegression Lossï¼‰</p>
<p>DUSt3R ç”¨çš„æ˜¯ç›‘ç£è®­ç»ƒï¼Œå³åˆ©ç”¨çœŸå®çš„ 3D ç‚¹äº‘ä½œä¸º GT æ¥è®­ç»ƒã€‚</p>
<p>åŸºæœ¬çš„å›å½’æŸå¤±å½¢å¼ï¼š
$<span class="math notranslate nohighlight">\(
\ell_{\mathrm{regr}}(\nu,i)=\left\|\frac{1}{z}X_{i}^{\nu,1}-\frac{1}{\hat{z}}\hat{X}_{i}^{\nu,1}\right\|
\)</span>$</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\nu \in \{1, 2\}\)</span>ï¼šå½“å‰è§†è§’ï¼ˆå›¾åƒï¼‰</p></li>
<li><p><span class="math notranslate nohighlight">\(i\)</span> æ˜¯åƒç´ ä½ç½®</p></li>
<li><p><span class="math notranslate nohighlight">\(X_{i}^{\nu,1}\)</span> æ˜¯æ¨¡å‹é¢„æµ‹çš„ 3D ç‚¹ï¼ˆåœ¨ <span class="math notranslate nohighlight">\(C^1\)</span> ä¸‹ï¼‰</p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{X}_{i}^{\nu,1}\)</span> æ˜¯çœŸå®çš„ 3D ç‚¹ï¼ˆground truthï¼‰</p></li>
</ul>
<p>è¿™é‡Œçš„ <span class="math notranslate nohighlight">\(\frac{1}{z}\)</span> å’Œ <span class="math notranslate nohighlight">\(\frac{1}{\hat{z}}\)</span> æ˜¯<strong>å½’ä¸€åŒ–å› å­</strong>ï¼Œç›®çš„æ˜¯ï¼š</p>
<ul class="simple">
<li><p>æ¶ˆé™¤å°ºåº¦ï¼ˆscaleï¼‰çš„å½±å“</p></li>
<li><p>æ›´å…³æ³¨ç›¸å¯¹å½¢çŠ¶è€Œä¸æ˜¯ç»å¯¹å¤§å°</p></li>
</ul>
<p>è¿™äº›å› å­å®šä¹‰ä¸ºï¼šæ‰€æœ‰æœ‰æ•ˆç‚¹åˆ°åŸç‚¹çš„å¹³å‡è·ç¦»ã€‚</p>
<hr class="docutils" />
<p>ğŸ“ æ”¹è¿›ï¼šæ”¯æŒ <em>metric-scale</em> é‡å»º</p>
<p>è®ºæ–‡æŒ‡å‡ºï¼š</p>
<blockquote>
<div><p>æœ‰äº›ä»»åŠ¡ï¼ˆæ¯”å¦‚ map-free visual localizationï¼‰æ˜¯éœ€è¦<strong>ç»å¯¹å°ºåº¦çš„</strong>ï¼Œä¹Ÿå°±æ˜¯è¯´ä¸èƒ½ç”¨å½’ä¸€åŒ–ã€‚</p>
</div></blockquote>
<p>å› æ­¤ï¼Œè®ºæ–‡ä¿®æ”¹äº†æŸå¤±ï¼š</p>
<ul class="simple">
<li><p>å¦‚æœ Ground Truth æ˜¯å…·æœ‰ç»å¯¹å°ºåº¦çš„ï¼ˆmetricï¼‰ï¼Œé‚£ä¹ˆå°±è®¾ <span class="math notranslate nohighlight">\(z = \hat{z}\)</span>ï¼Œä¹Ÿå°±æ˜¯ä¸åšå½’ä¸€åŒ–ã€‚</p></li>
<li><p>æŸå¤±å°±å˜æˆäº†ï¼š
$<span class="math notranslate nohighlight">\(
\ell_{\mathrm{regr}}(\nu,i)=\left\|X_{i}^{\nu,1}-\hat{X}_{i}^{\nu,1}\right\|/\hat{z}
\)</span>$</p></li>
</ul>
<hr class="docutils" />
<p>âœ… ç½®ä¿¡æ„ŸçŸ¥æŸå¤±ï¼ˆConfidence-Aware Lossï¼‰</p>
<p>æœ€ç»ˆçš„æŸå¤±å‡½æ•°è€ƒè™‘äº†ç½®ä¿¡åº¦ï¼š
$<span class="math notranslate nohighlight">\(
\mathcal{L}_{\mathrm{conf}}=\sum_{\nu\in\{1,2\}}\sum_{i\in\mathcal{V}^{\nu}}C_{i}^{\nu}\ell_{\mathrm{regr}}(\nu,i)-\alpha\log C_{i}^{\nu}
\)</span>$
å«ä¹‰ï¼š</p>
<ul class="simple">
<li><p>ç½®ä¿¡åº¦ <span class="math notranslate nohighlight">\(C_i^\nu\)</span> è¶Šé«˜ï¼ŒæŸå¤±çš„æƒé‡è¶Šå¤§ï¼›</p></li>
<li><p>åŒæ—¶åŠ å…¥ä¸€ä¸ªè´Ÿçš„ <span class="math notranslate nohighlight">\(\log C\)</span> é¡¹ï¼Œé¼“åŠ±æ¨¡å‹åœ¨ä¸ç¡®å®šçš„åœ°æ–¹é™ä½ç½®ä¿¡åº¦ï¼Œé¿å…è¿‡åº¦è‡ªä¿¡ã€‚</p></li>
</ul>
<hr class="docutils" />
<p>æ€»ç»“ä¸€å¥è¯ï¼š</p>
<blockquote>
<div><p><strong>DUSt3R æ˜¯ä¸€ä¸ªç”¨ Transformer ç½‘ç»œã€ä»ä¸¤å¼ å›¾åƒç›´æ¥é¢„æµ‹ç›¸æœºæ ‡å®šå’Œ 3D é‡å»ºçš„ç³»ç»Ÿï¼Œå®ƒè¾“å‡º dense pointmapï¼Œå¹¶é€šè¿‡æœ‰ç½®ä¿¡åº¦çš„å›å½’æŸå¤±è¿›è¡Œç›‘ç£è®­ç»ƒï¼ŒåŒæ—¶æ”¯æŒå¯¹å°ºåº¦æ•æ„Ÿçš„ä»»åŠ¡ã€‚</strong></p>
</div></blockquote>
</section>
<hr class="docutils" />
<section id="matching-prediction-head-and-loss">
<h3>3.2. Matching prediction head and loss<a class="headerlink" href="#matching-prediction-head-and-loss" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p><strong>MASt3R æ¡†æ¶åœ¨ DUSt3R åŸºç¡€ä¸Šå¢åŠ çš„â€œåŒ¹é…é¢„æµ‹å¤´â€ï¼ˆMatching prediction headï¼‰å’Œå®ƒçš„åŒ¹é…æŸå¤±å‡½æ•°ï¼ˆMatching lossï¼‰</strong>ã€‚å®ƒçš„ç›®çš„æ˜¯è§£å†³ DUSt3R åœ¨åƒç´ åŒ¹é…ç²¾åº¦ä¸Šçš„ä¸è¶³ã€‚</p>
<hr class="docutils" />
<p>ğŸ’¥ é—®é¢˜èƒŒæ™¯ï¼šDUSt3R åŒ¹é…ä¸å¤Ÿå‡†</p>
<p>è™½ç„¶ DUSt3R è¾“å‡ºçš„ç‚¹äº‘ï¼ˆpointmapï¼‰å¯ä»¥ç”¨äºåƒç´ çº§åŒ¹é…ï¼ˆä¾‹å¦‚æ‰¾å›¾åƒ1ä¸­åƒç´ å’Œå›¾åƒ2ä¸­åƒç´ å¯¹åº”çš„ç‚¹ï¼‰ï¼Œ
ä½†ï¼š</p>
<ol class="arabic simple">
<li><p>ç‚¹äº‘æ˜¯é€šè¿‡å›å½’ï¼ˆregressionï¼‰æ–¹å¼å¾—åˆ°çš„ï¼Œå¤©ç„¶å®¹æ˜“æœ‰ <strong>å™ªå£°</strong>ï¼›</p></li>
<li><p>DUSt3R åŸå§‹è®¾è®¡<strong>æ²¡æœ‰ä¸“é—¨ä¸ºåƒç´ çº§åŒ¹é…è®­ç»ƒ</strong>ï¼›</p></li>
<li><p>æ‰€ä»¥ï¼Œä» pointmap é‡Œåšâ€œäº’ç›¸åŒ¹é…â€ï¼ˆreciprocal matchingï¼‰è™½ç„¶å¯è¡Œï¼Œä½†<strong>ç²¾åº¦ä¸å¤Ÿé«˜</strong>ã€‚</p></li>
</ol>
<hr class="docutils" />
<p>âœ… è§£å†³æ–¹æ¡ˆï¼šå¼•å…¥ä¸“é—¨çš„åŒ¹é…å¤´ï¼ˆMatching Headï¼‰</p>
<p>ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½œè€…å¢åŠ äº†ä¸€ä¸ªæ–°åˆ†æ”¯ï¼ˆheadï¼‰ï¼Œä¸“é—¨ç”¨äºå­¦ä¹ åƒç´ åŒ¹é…ç”¨çš„æè¿°ç¬¦ï¼ˆdescriptorï¼‰ï¼š</p>
<ul class="simple">
<li><p>è¾“å‡ºä¸¤ä¸ª dense ç‰¹å¾å›¾ï¼š<span class="math notranslate nohighlight">\(D^1\)</span> å’Œ <span class="math notranslate nohighlight">\(D^2\)</span>ï¼Œæ¯ä¸ªåƒç´ éƒ½æœ‰ä¸€ä¸ª <span class="math notranslate nohighlight">\(d\)</span> ç»´çš„æè¿°ç¬¦ã€‚</p></li>
<li><p>å½¢å¼ä¸Šï¼š
$<span class="math notranslate nohighlight">\(
D^1 = \mathrm{Head}_{\mathrm{desc}}^1([H^1, H^{\prime1}]),\quad D^2 = \mathrm{Head}_{\mathrm{desc}}^2([H^2, H^{\prime2}])
\)</span>$</p>
<ul>
<li><p>è¾“å…¥æ˜¯ç¼–ç å™¨è¾“å‡º <span class="math notranslate nohighlight">\(H\)</span> å’Œè§£ç å™¨è¾“å‡º <span class="math notranslate nohighlight">\(H'\)</span> çš„æ‹¼æ¥ï¼›</p></li>
<li><p>Head æ˜¯ä¸€ä¸ªä¸¤å±‚çš„ MLPï¼Œå¸¦ GELU æ¿€æ´»ï¼›</p></li>
<li><p>è¾“å‡ºçš„æ¯ä¸ªæè¿°ç¬¦åšå•ä½èŒƒæ•°å½’ä¸€åŒ–ï¼ˆunit-normï¼‰ã€‚</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<p>ğŸ¯ åŒ¹é…ç›®æ ‡ï¼šç”¨ infoNCE è®­ç»ƒé«˜ç²¾åº¦åŒ¹é…</p>
<p>ä½¿ç”¨ <strong>InfoNCE æŸå¤±</strong> æ¥è®­ç»ƒè¿™ä¸ªæè¿°ç¬¦ï¼š</p>
<ul class="simple">
<li><p>Ground truth åŒ¹é…å¯¹è®°ä¸ºï¼š</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\hat{\mathcal{M}} = \{(i, j) \mid \hat{X}_{i}^{1,1} = \hat{X}_{j}^{2,1} \}\)</span></p></li>
<li><p>è¡¨ç¤ºå›¾åƒ1ä¸­åƒç´  <span class="math notranslate nohighlight">\(i\)</span> å’Œå›¾åƒ2ä¸­åƒç´  <span class="math notranslate nohighlight">\(j\)</span> åœ¨ 3D ä¸Šæ˜¯åŒä¸€ä¸ªç‚¹ã€‚</p></li>
</ul>
</li>
<li><p>æŸå¤±å‡½æ•°å½¢å¼å¦‚ä¸‹ï¼ˆInfoNCE å¯¹ç§°ç‰ˆï¼‰ï¼š</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(
\mathcal{L}_{\mathrm{match}} = -\sum_{(i,j)\in\hat{\mathcal{M}}} \log\frac{s_{\tau}(i,j)}{\sum_{k\in\mathcal{P}^{1}}s_{\tau}(k,j)} + \log\frac{s_{\tau}(i,j)}{\sum_{k\in\mathcal{P}^{2}}s_{\tau}(i,k)}
\)</span></p></li>
<li><p>å…¶ä¸­ï¼š</p>
<ul>
<li><p>ç›¸ä¼¼åº¦å‡½æ•° <span class="math notranslate nohighlight">\(s_\tau(i, j) = \exp(-\tau \cdot D_i^{1\top} D_j^2)\)</span>ï¼Œæ˜¯<strong>è´Ÿçš„ç‚¹ç§¯</strong>å†å– softmaxï¼Œ<span class="math notranslate nohighlight">\(\tau\)</span> æ˜¯æ¸©åº¦è¶…å‚æ•°ï¼›</p></li>
<li><p>ç¬¬ä¸€é¡¹æ˜¯å›¾åƒ2ä¸­åƒç´  <span class="math notranslate nohighlight">\(j\)</span> åŒ¹é…å›¾åƒ1ä¸­æ‰€æœ‰å€™é€‰åƒç´  <span class="math notranslate nohighlight">\(i\)</span> çš„ softmaxï¼›</p></li>
<li><p>ç¬¬äºŒé¡¹åè¿‡æ¥ï¼Œæ˜¯å›¾åƒ1ä¸­åƒç´  <span class="math notranslate nohighlight">\(i\)</span> åŒ¹é…å›¾åƒ2ä¸­æ‰€æœ‰ <span class="math notranslate nohighlight">\(j\)</span>ï¼›</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal{P}^{1}, \mathcal{P}^{2}\)</span> æ˜¯å‚ä¸è®¡ç®—æŸå¤±çš„åƒç´ é›†åˆã€‚</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<div><p>ğŸ“Œ æŸå¤±çš„æœ¬è´¨ï¼š<strong>äº¤å‰ç†µåˆ†ç±»æŸå¤±</strong>ï¼Œç›®æ ‡æ˜¯è®©æŸä¸ªåƒç´ <strong>åªå’Œå”¯ä¸€ä¸€ä¸ªæ­£ç¡®åƒç´ åŒ¹é…æˆåŠŸ</strong>ï¼Œè€Œä¸æ˜¯å‘¨å›´çš„ä¹Ÿç®—å¯¹ã€‚è¿™å’Œä¹‹å‰çš„å›å½’æŸå¤±ä¸åŒï¼Œè¦æ±‚çš„æ˜¯<strong>é«˜ç²¾åº¦åŒ¹é…ï¼ˆsub-pixel precisionï¼‰</strong>ã€‚</p>
</div></blockquote>
<hr class="docutils" />
<p>ğŸ§© æœ€ç»ˆæŸå¤±å‡½æ•°</p>
<p>æœ€ç»ˆï¼ŒåŒ¹é…æŸå¤±å’Œç‚¹äº‘å›å½’æŸå¤±å…±åŒè®­ç»ƒæ•´ä¸ªæ¨¡å‹ï¼š</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathcal{L}_{\mathrm{total}} = \mathcal{L}_{\mathrm{conf}} + \beta \mathcal{L}_{\mathrm{match}}\)</span></p></li>
<li><p>å…¶ä¸­ <span class="math notranslate nohighlight">\(\beta\)</span> æ˜¯æƒé‡è¶…å‚æ•°ï¼Œç”¨äºå¹³è¡¡å›å½’æŸå¤±å’ŒåŒ¹é…æŸå¤±ã€‚</p></li>
</ul>
<hr class="docutils" />
<p>âœ… æ€»ç»“ä¸€å¥è¯ï¼š</p>
<blockquote>
<div><p><strong>MASt3R åœ¨ DUSt3R åŸºç¡€ä¸Šå¢åŠ äº†ä¸€ä¸ªä¸“é—¨ç”¨äºåƒç´ ç²¾ç¡®åŒ¹é…çš„â€œæè¿°ç¬¦é¢„æµ‹å¤´â€å’ŒåŸºäº InfoNCE çš„åŒ¹é…æŸå¤±ï¼Œä»è€Œå®ç°é«˜ç²¾åº¦çš„ç¨ å¯†åŒ¹é…ï¼Œå°¤å…¶é€‚åˆ 3D é‡å»ºã€è§†è§‰å®šä½ç­‰ç²¾åº¦è¦æ±‚é«˜çš„ä»»åŠ¡ã€‚</strong></p>
</div></blockquote>
</section>
<hr class="docutils" />
<section id="fast-reciprocal-matching">
<h3>3.3. Fast reciprocal matching<a class="headerlink" href="#fast-reciprocal-matching" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p><strong>MASt3R ä¸­æå‡ºçš„ä¸€ç§é«˜æ•ˆçš„ç¨ å¯†åƒç´ åŒ¹é…ç­–ç•¥ï¼šFast Reciprocal Matchingï¼ˆå¿«é€Ÿäº’ç›¸åŒ¹é…ï¼‰</strong>ã€‚å®ƒè§£å†³äº†åƒç´ çº§æœ€è¿‘é‚»åŒ¹é…åœ¨è®¡ç®—å¤æ‚åº¦ä¸Šçš„ç“¶é¢ˆé—®é¢˜ï¼ŒåŒæ—¶è¿˜èƒ½è¿‡æ»¤ç¦»ç¾¤ç‚¹ã€æå‡åŒ¹é…ç²¾åº¦ã€‚</p>
<hr class="docutils" />
<p>ğŸŒŸ é—®é¢˜èƒŒæ™¯ï¼šäº’ç›¸åŒ¹é…ä»£ä»·é«˜</p>
<p>ç»™å®šä¸¤ä¸ªå›¾åƒå¯¹åº”çš„ç‰¹å¾å›¾ <span class="math notranslate nohighlight">\(D^1\)</span> å’Œ <span class="math notranslate nohighlight">\(D^2\)</span>ï¼Œæˆ‘ä»¬æƒ³æ‰¾å‡º<strong>å¯é åƒç´ å¯¹åº”å…³ç³»</strong>ï¼š</p>
<blockquote>
<div><p>ä¸¤ä¸ªåƒç´  <span class="math notranslate nohighlight">\((i, j)\)</span> æ„æˆåŒ¹é…å¯¹ï¼Œå½“ä¸”ä»…å½“å®ƒä»¬<strong>æ˜¯å½¼æ­¤çš„æœ€è¿‘é‚»ï¼ˆmutual nearest neighborsï¼‰</strong>ï¼š</p>
</div></blockquote>
<div class="math notranslate nohighlight">
\[
M = \{(i,j) \mid j = \mathrm{NN}_2(D_i^1) \ \text{and}\ i = \mathrm{NN}_1(D_j^2) \}
\]</div>
<p>å…¶ä¸­ <span class="math notranslate nohighlight">\(\mathrm{NN}_A(D_j^B)\)</span> è¡¨ç¤ºåœ¨ç‰¹å¾ç©ºé—´ä¸­æ‰¾åˆ°æœ€è¿‘çš„ç‚¹ï¼ŒåŸºäº <span class="math notranslate nohighlight">\(L_2\)</span> è·ç¦»ã€‚</p>
<p>ğŸ”´ <strong>é—®é¢˜æ˜¯ï¼š</strong></p>
<ul class="simple">
<li><p>æ¯ä¸ªå›¾åƒæœ‰ <span class="math notranslate nohighlight">\(H \times W\)</span> ä¸ªåƒç´ ï¼›</p></li>
<li><p>æ‰€ä»¥ç›´æ¥æš´åŠ›æ‰¾å…¨éƒ¨äº’ç›¸æœ€è¿‘é‚»ï¼Œæ—¶é—´å¤æ‚åº¦æ˜¯ <span class="math notranslate nohighlight">\(O(W^2 H^2)\)</span>ï¼Œå¤ªæ…¢äº†ï¼›</p></li>
<li><p>è€Œä¸”é«˜ç»´ç‰¹å¾ç©ºé—´ä¸­ï¼ˆæ¯”å¦‚ <span class="math notranslate nohighlight">\(d=128\)</span>ï¼‰ï¼Œä½¿ç”¨ K-d tree è¿™ç±»åŠ é€Ÿæ–¹æ³•ä¹Ÿå˜å¾—ä½æ•ˆã€‚</p></li>
</ul>
<hr class="docutils" />
<p>ğŸš€ è§£å†³æ–¹æ¡ˆï¼šFast Reciprocal Matching</p>
<p><strong>æ ¸å¿ƒæ€æƒ³ï¼šä¸ä»æ‰€æœ‰åƒç´ åšæœ€è¿‘é‚»æœç´¢ï¼Œè€Œæ˜¯ä»ä¸€ä¸ªç¨€ç–çš„åˆå§‹åƒç´ é›†åˆå¼€å§‹ï¼Œé€šè¿‡è¿­ä»£æ‰©å±•å’ŒéªŒè¯æ¥æ„å»ºäº’ç›¸åŒ¹é…å¯¹ã€‚</strong></p>
<p>å…·ä½“æ­¥éª¤å¦‚ä¸‹ï¼š</p>
<ul class="simple">
<li><p>1ï¸âƒ£ åˆå§‹é‡‡æ ·ï¼šä»å›¾åƒ <span class="math notranslate nohighlight">\(I^1\)</span> ä¸­<strong>å‡åŒ€é‡‡æ ·</strong>ä¸€ç»„ç¨€ç–åƒç´ ç‚¹ <span class="math notranslate nohighlight">\(k\)</span> ä¸ªä½œä¸ºèµ·å§‹é›†ï¼š</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\mathcal{U}^0 = \{\mathcal{U}_n^0\}_{n=1}^k\)</span></p></li>
<li><p>æ¯”å¦‚æ¯éš” 8 ä¸ªåƒç´ é‡‡ä¸€ä¸ªç‚¹ã€‚</p></li>
</ul>
</li>
<li><p>2ï¸âƒ£ åŒå‘ NN åŒ¹é… + éªŒè¯ï¼š
æ¯è½®è¿­ä»£ä¸­ï¼Œæ‰§è¡Œå¦‚ä¸‹è¿‡ç¨‹ï¼š</p>
<ul>
<li><p>ä» <span class="math notranslate nohighlight">\(U^t\)</span> ä¸­çš„æ¯ä¸ªåƒç´ ï¼Œåœ¨ <span class="math notranslate nohighlight">\(D^2\)</span> ä¸­æ‰¾æœ€è¿‘é‚»ï¼Œå¾— <span class="math notranslate nohighlight">\(V^t\)</span>ï¼›</p></li>
<li><p>ç„¶åå†ä» <span class="math notranslate nohighlight">\(V^t\)</span> ä¸­çš„æ¯ä¸ªåƒç´ ï¼Œåœ¨ <span class="math notranslate nohighlight">\(D^1\)</span> ä¸­æ‰¾å›æœ€è¿‘é‚»ï¼Œå¾— <span class="math notranslate nohighlight">\(U^{t+1}\)</span>ï¼›</p></li>
<li><p><span class="math notranslate nohighlight">\(U^{t}\longmapsto[\mathrm{NN}_{2}(D_{u}^{1})]_{u\in U^{t}}\equiv V^{t}\longmapsto[\mathrm{NN}_{1}(D_{v}^{2})]_{v\in V^{t}}\equiv U^{t+1}\)</span></p></li>
<li><p>æ‰¾å‡ºå½¢æˆé—­ç¯çš„åŒ¹é…å¯¹ï¼ˆå³ä» <span class="math notranslate nohighlight">\(i\)</span> æ˜ å°„åˆ° <span class="math notranslate nohighlight">\(j\)</span> å†æ˜ å°„å›æ¥ä»ç„¶æ˜¯ <span class="math notranslate nohighlight">\(i\)</span>ï¼‰ï¼š</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal{M}_k^t = \{(U_n^t, V_n^t)\ |\ U_n^t = U_n^{t+1} \}\)</span></p></li>
</ul>
</li>
<li><p>3ï¸âƒ£ æ”¶æ•›åˆ¤å®š + è¿‡æ»¤ï¼š</p>
<ul>
<li><p>æŠŠå·²æ”¶æ•›çš„åŒ¹é…å¯¹ä»ä¸‹ä¸€è½®çš„èµ·å§‹é›†ä¸­å‰”é™¤ï¼Œé¿å…é‡å¤è®¡ç®—ï¼›</p></li>
<li><p>åŒæ—¶æ£€æŸ¥ <span class="math notranslate nohighlight">\(V^{t+1}\)</span> å’Œ <span class="math notranslate nohighlight">\(V^t\)</span> çš„ä¸€è‡´æ€§ï¼ŒåšåŒå‘éªŒè¯ï¼›</p></li>
<li><p>é‡å¤è¯¥è¿‡ç¨‹ï¼Œç›´åˆ°å¤§å¤šæ•°ç‚¹éƒ½æ”¶æ•›ï¼Œé€šå¸¸åªéœ€å‡ è½®ã€‚</p></li>
</ul>
</li>
<li><p>4ï¸âƒ£ è¾“å‡ºç»“æœï¼š</p>
<ul>
<li><p>æœ€ç»ˆçš„åŒ¹é…é›†åˆä¸ºï¼š<span class="math notranslate nohighlight">\(\mathcal{M}_k = \bigcup_t \mathcal{M}_k^t\)</span></p></li>
<li><p>å³æ‰€æœ‰è½®æ¬¡ä¸­æ”¶æ•›çš„äº’ç›¸åŒ¹é…å¯¹ã€‚</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<p>ğŸ“Š ç†è®ºä¼˜åŠ¿å’Œå®é™…è¡¨ç°</p>
<ul class="simple">
<li><p><strong>è®¡ç®—å¤æ‚åº¦ï¼š</strong></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(O(k \cdot WH)\)</span></p></li>
<li><p>æ¯”å…¨åŒ¹é…çš„ <span class="math notranslate nohighlight">\(O(W^2 H^2)\)</span> å¿«äº† <span class="math notranslate nohighlight">\(WH/k\)</span> å€ï¼ˆæ¯”å¦‚ <span class="math notranslate nohighlight">\(k=1\%\)</span> çš„åƒç´ ï¼Œç†è®ºä¸Šå¿« <span class="math notranslate nohighlight">\(100\times\)</span>ï¼‰ï¼›</p></li>
</ul>
</li>
<li><p><strong>ç»“æœæ›´é²æ£’ï¼š</strong></p>
<ul>
<li><p>è™½ç„¶ <span class="math notranslate nohighlight">\(\mathcal{M}_k\)</span> æ˜¯å®Œæ•´åŒ¹é…é›† <span class="math notranslate nohighlight">\(\mathcal{M}\)</span> çš„å­é›†ï¼ˆæœ€å¤š <span class="math notranslate nohighlight">\(k\)</span> ä¸ªåŒ¹é…ï¼‰ï¼Œ</p></li>
<li><p>ä½†ç”±äºè¿­ä»£è¿‡ç¨‹ä¸­åªæœ‰ç¨³å®šæ”¶æ•›çš„ç‚¹æ‰è¢«ä¿ç•™ï¼Œ<strong>å¤©ç„¶å…·æœ‰ç¦»ç¾¤ç‚¹è¿‡æ»¤åŠŸèƒ½ï¼ˆoutlier filteringï¼‰</strong>ï¼›</p></li>
<li><p>å®é™…ä¸Šï¼Œè¿™ç§æ–¹å¼åè€Œèƒ½å¸¦æ¥<strong>æ›´é«˜çš„åŒ¹é…ç²¾åº¦</strong>ï¼ˆå‚è§ Fig. 3 (right)ï¼‰ï¼›</p></li>
</ul>
</li>
</ul>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/04/g9Y6VW.png" /></p>
<p>Figure 3: Fast reciprocal matching. Left: Illustration of the fast matching process, starting from an initial subset of pixels <span class="math notranslate nohighlight">\(U^{0}\)</span> and propagating it iteratively using ğ‘ ğ‘ search. Searching for cycles (blue arrows) detect reciprocal correspondences and allows to accelerate the subsequent steps, by removing points that converged. Center: Average number of remaining points in <span class="math notranslate nohighlight">\(U^{t}\)</span> at iteration <span class="math notranslate nohighlight">\(t=1\ldots6\)</span> . After only 5 iterations, nearly all points have already converged to a reciprocal match. Right: Performance-versus-time trade-off on the Map-free dataset. Performance actually improves, along with matching speed, when performing moderate levels of subsampling.</p>
<hr class="docutils" />
<p>âœ… æ€»ç»“ä¸€å¥è¯ï¼š</p>
<blockquote>
<div><p><strong>Fast Reciprocal Matching</strong> æ˜¯ä¸€ç§ç¨€ç–èµ·å§‹ã€è¿­ä»£æ”¶æ•›ã€åŒå‘éªŒè¯çš„å¿«é€Ÿåƒç´ åŒ¹é…ç­–ç•¥ï¼Œä¸ä»…æ˜¾è‘—æå‡æ•ˆç‡ï¼ˆ<span class="math notranslate nohighlight">\(O(kWH)\)</span>ï¼‰ï¼Œè¿˜èƒ½æå‡æœ€ç»ˆåŒ¹é…çš„ç²¾åº¦å’Œé²æ£’æ€§ã€‚</p>
</div></blockquote>
</section>
<hr class="docutils" />
<section id="coarse-to-fine-matching">
<h3>3.4. Coarse-to-fine matching<a class="headerlink" href="#coarse-to-fine-matching" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>MASt3R ä¸ºå¤„ç†é«˜åˆ†è¾¨ç‡å›¾åƒåŒ¹é…è€Œæå‡ºçš„ <strong>Coarse-to-Fine Matchingï¼ˆç²—åˆ°ç»†åŒ¹é…ï¼‰</strong> æ–¹æ³•ï¼Œç”¨æ¥å…‹æœ Transformer åœ¨å¤§å›¾åƒä¸Šæ— æ³•ç›´æ¥è®¡ç®—çš„é—®é¢˜ã€‚</p>
<hr class="docutils" />
<p>âš ï¸ é—®é¢˜èƒŒæ™¯</p>
<p><strong>Transformer çš„ attention æ˜¯ <span class="math notranslate nohighlight">\(O((WH)^2)\)</span> çš„å¤æ‚åº¦</strong>ï¼Œæ‰€ä»¥ï¼š</p>
<ul class="simple">
<li><p>MASt3R é»˜è®¤åªæ”¯æŒå›¾åƒçš„æœ€å¤§è¾¹ä¸º 512 åƒç´ ï¼›</p></li>
<li><p>é¢å¯¹ç™¾ä¸‡çº§åƒç´ å›¾åƒï¼ˆä¾‹å¦‚ 1M åƒç´ ï¼‰ï¼Œéœ€è¦å…ˆä¸‹é‡‡æ ·æ‰èƒ½è¾“å…¥ï¼›</p></li>
<li><p>ä½†è¿™ç§ç¼©æ”¾æ“ä½œä¼šæŸå¤±ç²¾åº¦ï¼Œå¯¼è‡´ï¼š</p>
<ul>
<li><p>åŒ¹é…ç‚¹ä½ç½®ä¸å‡†ç¡®ï¼ˆå®šä½è¯¯å·®ï¼‰ï¼›</p></li>
<li><p>ç”šè‡³å½±å“åç»­ 3D é‡å»ºè´¨é‡ã€‚</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<p>ğŸ’¡ è§£å†³æ–¹æ³•ï¼šCoarse-to-Fine Matching</p>
<p><strong>æ€è·¯æ˜¯ï¼šå…ˆä½åˆ†è¾¨ç‡å…¨å±€åŒ¹é…ï¼Œå†å±€éƒ¨é«˜åˆ†è¾¨ç‡ç»†åŒ–åŒ¹é…ã€‚</strong></p>
<p>è¯¦ç»†æµç¨‹å¦‚ä¸‹ï¼š</p>
<ul class="simple">
<li><p>1ï¸âƒ£ Step 1ï¼šå…¨å±€ç²—åŒ¹é…ï¼ˆcoarse matchï¼‰</p>
<ul>
<li><p>å¯¹ä¸‹é‡‡æ ·ç‰ˆæœ¬çš„ä¸¤ä¸ªå›¾åƒè¿›è¡ŒåŒ¹é…ï¼ˆå¦‚ 512Ã—512ï¼‰ï¼›</p></li>
<li><p>ä½¿ç”¨å‰é¢æåˆ°çš„ fast reciprocal matching å¾—åˆ°åŒ¹é…é›†åˆï¼š</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal{M}_{k}^{0}\)</span></p></li>
<li><p>è¿™æ˜¯ä½åˆ†è¾¨ç‡ä¸‹çš„ç²—åŒ¹é…å¯¹ã€‚</p></li>
</ul>
</li>
<li><p>2ï¸âƒ£ Step 2ï¼šæ»‘çª—è£å‰ª + åŒ¹é…è¦†ç›–</p>
<ul>
<li><p>å¯¹ä¸¤ä¸ª<strong>åŸå§‹é«˜åˆ†è¾¨ç‡å›¾åƒ</strong>ç”Ÿæˆæ»‘åŠ¨çª—å£ï¼š</p>
<ul>
<li><p>æ¯ä¸ªçª—å£æœ€å¤§è¾¹ä¸º 512 åƒç´ ï¼Œå’Œ MASt3R è¾“å…¥ä¸€è‡´ï¼›</p></li>
<li><p>æ¯ä¸ªçª—å£<strong>é‡å  50%</strong>ï¼Œç¡®ä¿è¿ç»­æ€§ï¼›</p></li>
</ul>
</li>
<li><p>æšä¸¾æ‰€æœ‰çª—å£å¯¹ <span class="math notranslate nohighlight">\((w_1, w_2) \in W^1 \times W^2\)</span>ï¼›</p></li>
<li><p>ç„¶åé‡‡ç”¨<strong>è´ªå¿ƒç­–ç•¥</strong>é€‰å‡ºä¸€ç»„çª—å£å¯¹ï¼Œ<strong>å°½å¯èƒ½è¦†ç›– <span class="math notranslate nohighlight">\(\mathcal{M}_k^0\)</span> ä¸­çš„ç²—åŒ¹é…ç‚¹</strong>ï¼ˆç›´åˆ°è¦†ç›– 90% çš„ç²—åŒ¹é…ç‚¹ä¸ºæ­¢ï¼‰ã€‚</p></li>
</ul>
</li>
<li><p>3ï¸âƒ£ Step 3ï¼šå±€éƒ¨ç»†åŒ¹é…ï¼ˆfine matchï¼‰</p>
<ul>
<li><p>å¯¹æ¯å¯¹çª—å£ <span class="math notranslate nohighlight">\((w_1, w_2)\)</span>ï¼š</p>
<ul>
<li><p>ä½¿ç”¨ MASt3R ç”Ÿæˆå±€éƒ¨ç‰¹å¾å›¾ï¼š</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(D^{w_1}, D^{w_2} = \mathrm{MASt3R}(I^{1}_{w_1}, I^{2}_{w_2})\)</span></p></li>
</ul>
</li>
<li><p>ç„¶åä½¿ç”¨ Fast Reciprocal Matching æå–åŒ¹é…ç‚¹ï¼š</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(M^{w_1, w_2}_k = \mathrm{fast\_reciprocal\_NN}(D^{w_1}, D^{w_2})\)</span></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>4ï¸âƒ£ Step 4ï¼šæ˜ å°„å›åŸå›¾å¹¶åˆå¹¶</p>
<ul>
<li><p>å°†æ‰€æœ‰çª—å£å¯¹ä¸­æå–åˆ°çš„åŒ¹é…ç‚¹ <strong>æ˜ å°„å›åŸå›¾åæ ‡</strong>ï¼›</p></li>
<li><p>æœ€åå°†å®ƒä»¬æ‹¼æ¥ï¼Œå¾—åˆ°å…¨åˆ†è¾¨ç‡ä¸‹çš„ç¨ å¯†åŒ¹é…å¯¹ã€‚</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<p>âœ… æ€»ç»“ä¸€å¥è¯ï¼š</p>
<blockquote>
<div><p><strong>Coarse-to-Fine Matching</strong> å…ˆåœ¨ç¼©å°å›¾åƒä¸Šåšå…¨å±€ç²—åŒ¹é…ï¼Œå†åˆ©ç”¨è¦†ç›–è¿™äº›åŒ¹é…çš„æ»‘åŠ¨çª—å£åœ¨åŸå›¾ä¸Šåšå±€éƒ¨ç»†åŒ¹é…ï¼Œä»è€Œå…¼é¡¾äº†æ•ˆç‡ä¸é«˜åˆ†è¾¨ç‡ç²¾åº¦ã€‚</p>
</div></blockquote>
<hr class="docutils" />
<p>ğŸ” ä¼˜åŠ¿äº®ç‚¹ï¼š</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>ç‰¹æ€§</p></th>
<th class="head"><p>æè¿°</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ğŸ¯ ç²¾åº¦</p></td>
<td><p>ä¿ç•™é«˜åˆ†è¾¨ç‡å›¾åƒçš„ç»†èŠ‚ï¼Œæé«˜åƒç´ çº§å®šä½ç²¾åº¦</p></td>
</tr>
<tr class="row-odd"><td><p>âš¡ æ•ˆç‡</p></td>
<td><p>é™å®šåœ¨å°çª—å£åŒºåŸŸåšé«˜åˆ†è¾¨ç‡è®¡ç®—ï¼Œé¿å…å…¨å›¾ ViT æ¨ç†å¼€é”€</p></td>
</tr>
<tr class="row-even"><td><p>ğŸ” ååŒ</p></td>
<td><p>å’Œ fast reciprocal matching æœºåˆ¶å¤©ç„¶å…¼å®¹</p></td>
</tr>
<tr class="row-odd"><td><p>ğŸ” æ§åˆ¶</p></td>
<td><p>é€šè¿‡è¦†ç›–æ¯”ä¾‹ï¼ˆå¦‚ 90%ï¼‰å’Œå¹³è¡¡çª—å£æ•°é‡è¿›è¡Œé€Ÿåº¦-ç²¾åº¦æƒè¡¡</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<hr class="docutils" />
<section id="experimental-results">
<h2>4. Experimental results<a class="headerlink" href="#experimental-results" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p>ä¸»è¦è®²çš„æ˜¯è¯¥æ–¹æ³•çš„è®­ç»ƒè¿‡ç¨‹ã€æ‰€ç”¨æ•°æ®é›†ï¼Œä»¥åŠåœ¨ä¸åŒä»»åŠ¡ï¼ˆç‰¹åˆ«æ˜¯åœ°å›¾æ— å…³çš„å®šä½ Map-Free Localizationï¼‰ä¸Šçš„è¡¨ç°ã€‚</p>
<ol class="arabic simple">
<li><p><strong>4.1</strong> æè¿°è®­ç»ƒæ–¹æ³•ï¼›</p></li>
<li><p><strong>4.2</strong> è¯„ä¼°åœ¨ <strong>Map-Free Relocalization Benchmark</strong> ä¸Šçš„å®šä½ç²¾åº¦ï¼›</p></li>
<li><p><strong>4.3-4.5</strong> åˆ™æ¶‰åŠå…¶ä»–æ•°æ®é›†å’Œä»»åŠ¡ï¼ˆå¦‚Dense MVSç­‰ï¼‰ï¼›</p></li>
<li><p>æ¶‰åŠçš„æ•°æ®é›†ç§ç±»éå¸¸å¹¿æ³›ï¼ˆå…±14ä¸ªï¼‰ï¼Œæ¶µç›–å®¤å†…/å®¤å¤–ã€çœŸå®/åˆæˆã€ç‰©ä½“/åœºæ™¯ç­‰ï¼›</p></li>
<li><p>æœ€ååœ¨å¤šä¸ªåŸºå‡†ä»»åŠ¡ä¸­ï¼ŒMASt3Rçš„è¡¨ç°æ˜¾è‘—è¶…è¿‡ç°æœ‰æ–¹æ³•ã€‚</p></li>
</ol>
<section id="training">
<h3>4.1. Training<a class="headerlink" href="#training" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>âœ… æ¨¡å‹æ¶æ„ä¸åˆå§‹åŒ–</p>
<ul class="simple">
<li><p>åŸºäºå·²æœ‰çš„ <strong>DUSt3R æ¨¡å‹æ¶æ„</strong>ï¼›</p></li>
<li><p>ç¼–ç å™¨ï¼šViT-Largeï¼Œè§£ç å™¨ï¼šViT-Baseï¼›</p></li>
<li><p>ç”¨DUSt3Rçš„å…¬å¼€checkpointåˆå§‹åŒ–ï¼Œç»§æ‰¿å…¶åœ¨3DåŒ¹é…æ–¹é¢çš„èƒ½åŠ›ã€‚</p></li>
</ul>
<p>âœ… æ•°æ®ä¸è®­ç»ƒç­–ç•¥</p>
<ul class="simple">
<li><p>ä½¿ç”¨ <strong>14ä¸ªä¸åŒæ•°æ®é›†</strong>ï¼ˆå¦‚CO3D, MegaDepthç­‰ï¼‰ï¼Œæ¯ä¸ªepochéšæœºé‡‡æ · 65 ä¸‡å¯¹å›¾åƒå¯¹ï¼›</p></li>
<li><p>è®­ç»ƒæ€»å…± 35 ä¸ª epochï¼Œä½¿ç”¨ <strong>ä½™å¼¦å­¦ä¹ ç‡è¡°å‡(cosine schedule)</strong>ï¼›</p></li>
<li><p><strong>å›¾åƒæœ€å¤§è¾¹ç¼©æ”¾ä¸º512åƒç´ (the largest image dimension is 512 pixels)</strong></p></li>
<li><p>éšæœºæ¯”ä¾‹è£å‰ªå’Œå˜æ¢ä¿æŒä¸»ç‚¹ä¸å˜ï¼Œå¢å¼ºå°ºåº¦ä¸å˜æ€§ï¼›</p></li>
<li><p>è®¾ç½®</p>
<ul>
<li><p>initial learning rate set to 0.0001</p></li>
<li><p>local feature dimension to ğ‘‘ = 24</p></li>
<li><p>matching loss weight to ğ›½ = 1</p></li>
</ul>
</li>
</ul>
<p>âœ… Correspondence sampling</p>
<ul class="simple">
<li><p>ä»3Dç‚¹å›¾ä¸­æ‰¾â€œäº’ä¸ºæœ€è¿‘é‚»â€çš„å¯¹åº”ç‚¹ï¼ˆreciprocal correspondencesï¼‰ï¼Œæ¯å¯¹å›¾åƒéšæœºæŠ½å–4096å¯¹ï¼›</p></li>
<li><p>è‹¥ä¸å¤Ÿï¼Œåˆ™è¡¥å……éšæœºé”™é…ï¼ˆä¿è¯çœŸåŒ¹é…æ¯”ä¾‹ç¨³å®šï¼‰ï¼›</p></li>
</ul>
<p>âœ… å¿«é€Ÿæœ€è¿‘é‚»æŸ¥æ‰¾æ–¹æ³•(Fast nearest neighbors)</p>
<ul class="simple">
<li><p>å¯¹3Dç‚¹åŒ¹é…ï¼šç”¨ <strong>K-dæ ‘</strong>ï¼›</p></li>
<li><p>å¯¹é«˜ç»´å±€éƒ¨ç‰¹å¾ï¼ˆd=24ï¼‰ï¼šæ”¹ç”¨ <strong>FAISS åº“</strong>ï¼Œå› ä¸ºK-dæ ‘åœ¨é«˜ç»´ä¸‹æ•ˆç‡å¾ˆå·®ï¼ˆç»´åº¦ç¾éš¾ï¼‰ï¼›</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="map-free-localization">
<h3>4.2 Map-free localization<a class="headerlink" href="#map-free-localization" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>ğŸ“š Dataset description</p>
<ul class="simple">
<li><p>ä½¿ç”¨ Map-Free Relocalization Benchmarkï¼š</p>
<ul>
<li><p>æ²¡æœ‰åœ°å›¾ï¼Œä»…ä¾èµ–ä¸€å¼ å‚è€ƒå›¾åƒè¿›è¡Œå®šä½ï¼›</p></li>
<li><p>It comprises a training, validation and test sets of 460, 65 and 130 scenes</p></li>
<li><p>è¯„ä¼°æŒ‡æ ‡ï¼š<strong>VCREï¼ˆVirtual Correspondence Reprojection Errorï¼‰</strong> å’Œç›¸æœºå§¿æ€ç²¾åº¦ã€‚</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<p>ğŸ” Impact of subsampling</p>
<ul class="simple">
<li><p>åœ¨è¿™ä¸ªä»»åŠ¡ä¸Šï¼Œ<strong>ä¸ä½¿ç”¨ coarse-to-fine matching</strong>ï¼Œå› ä¸ºè¾“å…¥å›¾åƒåˆ†è¾¨ç‡ï¼ˆ720Ã—540ï¼‰å·²ç»æ¥è¿‘ MASt3R çš„å·¥ä½œåˆ†è¾¨ç‡ï¼ˆ512Ã—384ï¼‰ã€‚</p></li>
<li><p>ç”±äº<strong>å¯†é›†çš„ reciprocal matching éå¸¸æ…¢</strong>ï¼Œå³ä¾¿ä½¿ç”¨äº†ä¼˜åŒ–çš„æœ€è¿‘é‚»æŸ¥æ‰¾ï¼Œä¹Ÿå¾ˆè€—æ—¶ã€‚</p></li>
<li><p>æ‰€ä»¥ä»–ä»¬é‡‡å–äº†ä¸‹é‡‡æ ·çš„ç­–ç•¥ï¼š<strong>åªä¿ç•™ <span class="math notranslate nohighlight">\(k\)</span> ä¸ª reciprocal å¯¹åº”ç‚¹</strong>ï¼ˆæ¥è‡ªå…¬å¼ 13ï¼‰ã€‚</p></li>
<li><p>å®éªŒå‘ç°ï¼šé€‚å½“ä¸‹é‡‡æ ·ï¼ˆå¦‚ <span class="math notranslate nohighlight">\(k=3000\)</span>ï¼‰åè€Œ<strong>æå‡äº†æ€§èƒ½å¹¶åŠ å¿«é€Ÿåº¦</strong>ï¼ˆå¿«äº† 64 å€ï¼‰ã€‚</p></li>
<li><p>è¿™ç§åç›´è§‰çš„ç°è±¡ï¼ˆå°‘ç‚¹åŒ¹é…æ›´å‡†ï¼‰åœ¨è¡¥å……ææ–™ä¸­æœ‰è¿›ä¸€æ­¥åˆ†æã€‚</p></li>
<li><p><strong>åç»­å®éªŒéƒ½ä½¿ç”¨ <span class="math notranslate nohighlight">\(k=3000\)</span> ä½œä¸ºé»˜è®¤é…ç½®</strong>ã€‚</p></li>
</ul>
<hr class="docutils" />
<p>âœ… Ablations on losses and matching modesï¼ˆæŸå¤±å‡½æ•°å’ŒåŒ¹é…æ¨¡å¼çš„æ¶ˆèå®éªŒï¼‰</p>
<ul class="simple">
<li><p>ä½å§¿ä¼°è®¡æ–¹æ³•ç»Ÿä¸€ä½¿ç”¨ï¼š</p>
<ul>
<li><p>é€šè¿‡é¢„æµ‹åŒ¹é…è®¡ç®— Essential matrixï¼Œå†ç®—ç›¸å¯¹ä½å§¿ï¼›</p></li>
<li><p>æˆ–ä½¿ç”¨ PnPï¼ˆæ•ˆæœç±»ä¼¼ï¼‰ï¼›</p></li>
<li><p>åœºæ™¯å°ºåº¦é€šè¿‡ DPT ä¼°è®¡æ·±åº¦ï¼ˆI-IVï¼‰ï¼Œæˆ– MASt3R ç›´æ¥é¢„æµ‹æ·±åº¦ï¼ˆVï¼‰ã€‚</p></li>
</ul>
</li>
</ul>
<p><strong>ç»“è®ºï¼š</strong></p>
<ul class="simple">
<li><p>æ‰€æœ‰ MASt3R æ–¹æ³•éƒ½è¿œä¼˜äº DUSt3Rï¼ˆè®­ç»ƒæ›´å……åˆ†ï¼Œæ•°æ®æ›´å¤šï¼‰ã€‚</p></li>
<li><p><strong>åŒ¹é… descriptors æ˜æ˜¾ä¼˜äºåŒ¹é… 3D ç‚¹</strong>ï¼ˆII vs. IVï¼‰ï¼Œå°è¯äº†è®ºæ–‡ç¬¬ 3.2 èŠ‚ä¸­æåˆ°çš„ï¼šç›´æ¥å›å½’åƒç´ åŒ¹é…ä¸å¦‚é€šè¿‡ç‰¹å¾åŒ¹é…ã€‚</p></li>
<li><p><strong>åªç”¨åŒ¹é…æŸå¤±ï¼ˆIIIï¼‰ä¸å¦‚åŒæ—¶è®­ç»ƒ 3D + åŒ¹é…æŸå¤±ï¼ˆIVï¼‰</strong>ï¼Œè¯´æ˜ 3D é‡å»ºèƒ½è¾…åŠ©ç‰¹å¾åŒ¹é…ã€‚</p>
<ul>
<li><p>æ¯”å¦‚æ—‹è½¬è¯¯å·®ä» 10.8Â° é™åˆ° 3.0Â°ã€‚</p></li>
</ul>
</li>
<li><p>ä½¿ç”¨ MASt3R ç›´æ¥è¾“å‡ºçš„æ·±åº¦ï¼ˆVï¼‰è¿›ä¸€æ­¥æå‡æ€§èƒ½ï¼Œè¯´æ˜æ·±åº¦é¢„æµ‹å’ŒåŒ¹é…æ˜¯<strong>äº’è¡¥ä¸”é«˜åº¦ç›¸å…³çš„ä»»åŠ¡</strong>ã€‚</p></li>
</ul>
<hr class="docutils" />
<p>âœ… Direct regression çš„æ„å¤–ç»“æœ</p>
<ul class="simple">
<li><p>ä½œè€…è¿˜å°è¯•äº† MASt3R çš„ç›´æ¥å›å½’ç‰ˆæœ¬ï¼š<strong>ä¸åŒ¹é…ï¼Œè€Œæ˜¯ç›´æ¥ç”¨ PointMap å›å½’ç›¸æœºä½å§¿</strong>ã€‚</p></li>
<li><p>ç»“æœä¸ä½¿ç”¨åŒ¹é…çš„æ–¹æ³•å·®ä¸å¤šï¼Œ<strong>è¿™å¾ˆæ„å¤–</strong>ã€‚</p></li>
<li><p>ä¸è¿‡ä½œè€…æŒ‡å‡ºï¼šè¿™åªåœ¨è¿™ä¸ªç‰¹å®šæ•°æ®é›†æˆç«‹ï¼Œ<strong>å…¶ä»–å®šä½ä»»åŠ¡ä¸­ä»æ¨èä½¿ç”¨åŒ¹é…ï¼ˆ+ å·²çŸ¥å†…å‚ï¼‰æ¥ä¼°è®¡å§¿æ€</strong>ã€‚</p></li>
</ul>
<hr class="docutils" />
<p>âœ… Qualitative resultsï¼ˆå®šæ€§åˆ†æï¼‰</p>
<ul class="simple">
<li><p>å›¾ 4 å±•ç¤ºäº†æç«¯è§†è§’å˜åŒ–ï¼ˆç”šè‡³ 180Â°ï¼‰ä¸‹çš„åŒ¹é…æ•ˆæœã€‚</p></li>
<li><p>MASt3R èƒ½å¤Ÿ<strong>æˆåŠŸåŒ¹é…ä¸€äº› 2D æ–¹æ³•éš¾ä»¥åŒ¹é…çš„åŒºåŸŸ</strong>ï¼Œå³ä½¿å¤–è§‚å˜åŒ–å¾ˆå¤§ã€‚</p></li>
<li><p>è¿™æ˜¯å› ä¸º MASt3R çš„åŒ¹é…<strong>å»ºç«‹åœ¨ 3D åœºæ™¯ç†è§£åŸºç¡€ä¸Š</strong>ï¼Œè€Œä¸æ˜¯å•çº¯åŸºäºå›¾åƒå±€éƒ¨å¤–è§‚ã€‚</p></li>
</ul>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/04/c7q3bt.png" /></p>
<p>Figure 4: Qualitative examples on the Map-free dataset. Top row: Pairs with strong viewpoint changes. Third one is a failure case. For clarity, we only draw a subset of all correspondences. Bottom row: We highlight interesting spots in close-up. These regions could hardly be matched by local keypoints. See text for details.</p>
<hr class="docutils" />
<p>æ€»ç»“ä¸€å¥è¯ï¼š</p>
<blockquote>
<div><p>MASt3R åœ¨ map-free camera localization ä»»åŠ¡ä¸­è¡¨ç°éå¸¸å‡ºè‰²ï¼Œå¾—ç›Šäºå…¶å°†ç‰¹å¾åŒ¹é…ã€3D åœºæ™¯é‡å»ºå’Œæ·±åº¦ä¼°è®¡èä¸ºä¸€ä½“çš„è”åˆå­¦ä¹ æ¶æ„ï¼Œå¤§å¹…è¶…è¿‡ç°æœ‰æ–¹æ³•ï¼Œä¸”åœ¨æ•ˆç‡å’Œé²æ£’æ€§ä¸Šéƒ½è¡¨ç°ä¼˜å¼‚ã€‚</p>
</div></blockquote>
</section>
<hr class="docutils" />
<section id="relative-pose-estimation">
<h3>4.3. Relative pose estimation<a class="headerlink" href="#relative-pose-estimation" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>âœ… ä¸€ã€Datasets and Protocolï¼ˆæ•°æ®é›†ä¸å®éªŒè®¾ç½®ï¼‰
â—¾ æ•°æ®é›†ç®€ä»‹ï¼š</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>æ•°æ®é›†</p></th>
<th class="head"><p>ç±»å‹</p></th>
<th class="head"><p>å…³é”®ç‰¹å¾</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>CO3Dv2</strong></p></td>
<td><p>å®¤å†…å¤–æ··åˆï¼Œå¸¦ç±»åˆ«</p></td>
<td><p>æ¥è‡ª 37K è§†é¢‘ï¼Œ600 ä¸‡å¸§ï¼Œ51 ä¸ª COCO ç±»åˆ«ï¼›ç”¨ COLMAP ä»æ¯æ®µè§†é¢‘çš„ 200 å¸§é‡å»ºç›¸æœºå§¿æ€</p></td>
</tr>
<tr class="row-odd"><td><p><strong>RealEstate10k</strong></p></td>
<td><p>çœŸå®æˆ¿äº§è§†é¢‘</p></td>
<td><p>80K ä¸ª YouTube è§†é¢‘ç‰‡æ®µï¼ˆå…± 1000 ä¸‡å¸§ï¼‰ï¼Œç›¸æœºå§¿æ€ç”± SLAM + BA å¾—åˆ°</p></td>
</tr>
</tbody>
</table>
<ul class="simple">
<li><p>ä½œè€…ä½¿ç”¨ CO3Dv2 çš„ 41 ç±»å’Œ RealEstate10k çš„ 1.8K æ®µæµ‹è¯•è§†é¢‘ã€‚</p></li>
<li><p>æ¯æ®µè§†é¢‘ä¸­é€‰ 10 å¸§ï¼Œ<strong>åœ¨æ‰€æœ‰å¯èƒ½çš„å›¾åƒå¯¹ä¹‹é—´ä¼°è®¡ç›¸å¯¹å§¿æ€</strong>ï¼ˆå…± 45 ä¸ªç»„åˆï¼‰ã€‚</p></li>
<li><p><strong>ä¸ä½¿ç”¨çœŸå®çš„ç›¸æœºç„¦è·</strong>ï¼ˆå¢åŠ éš¾åº¦ï¼‰ï¼</p></li>
</ul>
<hr class="docutils" />
<p>âœ… äºŒã€Baselines and Metricsï¼ˆå¯¹æ¯”æ–¹æ³•å’Œè¯„ä¼°æŒ‡æ ‡ï¼‰</p>
<p>â—¾ MASt3R æ€ä¹ˆä¼°å§¿æ€ï¼š</p>
<ul class="simple">
<li><p>åƒä¹‹å‰ä¸€æ ·ï¼Œé€šè¿‡åŒ¹é…ç‚¹ä¼°è®¡ Essential Matrixï¼Œå†æ¢å¤ç›¸å¯¹å§¿æ€ï¼›</p></li>
<li><p>ä¸å…¶ä»–æ–¹æ³•ä¸åŒï¼š<strong>MASt3R åªä½¿ç”¨å›¾åƒå¯¹ï¼Œä¸ä½¿ç”¨å¤šè§†å›¾ä¿¡æ¯</strong>ï¼›</p>
<ul>
<li><p>æ‰€ä»¥ä¸å¤§å¤šæ•° baseline æ–¹æ³•ä¸å®Œå…¨å…¬å¹³ï¼ˆå› ä¸ºå…¶ä»–æ–¹æ³•ç”¨æ›´å¤šä¿¡æ¯ï¼‰ï¼›</p></li>
<li><p>åªæœ‰ DUSt3R PnP ä¹Ÿæ˜¯ pairwiseã€‚</p></li>
</ul>
</li>
</ul>
<p>â—¾ å¯¹æ¯”æ–¹æ³•ï¼ˆåŒ…æ‹¬ä¼ ç»Ÿ SfM å’Œæ–°å‹å­¦ä¹ æ–¹æ³•ï¼‰ï¼š</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>æ–¹æ³•ç±»å‹</p></th>
<th class="head"><p>æ–¹æ³•å</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>å­¦ä¹ æ–¹æ³•</p></td>
<td><p>RelPose, RelPose++, PoseReg, PoseDiff, RayDiff, DUSt3R</p></td>
</tr>
<tr class="row-odd"><td><p>SfM æ–¹æ³•</p></td>
<td><p>PixSFM, COLMAP + SuperPoint + SuperGlue</p></td>
</tr>
</tbody>
</table>
<p>â—¾ è¯„ä¼°æŒ‡æ ‡ï¼š</p>
<ul class="simple">
<li><p><strong>RRA&#64;15</strong>ï¼šæ—‹è½¬è§’è¯¯å·®å°äº 15Â° çš„åŒ¹é…æ¯”ä¾‹ï¼›</p></li>
<li><p><strong>RTA&#64;15</strong>ï¼šå¹³ç§»è§’è¯¯å·®å°äº 15Â° çš„åŒ¹é…æ¯”ä¾‹ï¼›</p></li>
<li><p><strong>mAA30</strong>ï¼šæœ€å°(RRA&#64;30, RTA&#64;30) çš„å‡†ç¡®ç‡æ›²çº¿ä¸‹çš„é¢ç§¯ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰ï¼›ç±»ä¼¼ mAPï¼Œåªä¸è¿‡è¯„ä¼°å§¿æ€è§’åº¦è¯¯å·®ã€‚</p></li>
</ul>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/04/npLx0f.png" /></p>
<p>Table 3: Left(4.3èŠ‚): Multi-view pose regression on the CO3Dv2 and RealEstate10K with 10 random frames. Parenthesis () denote methods that do not report results on the 10 views set, we report their best for comparison (8 views). We distinguish between (a) multi-view and (b) pairwise methods. Right(4.5èŠ‚): Dense MVS results on the DTU dataset, in mm. Handcrafted methods (c) perform worse than learning-based approaches (d) that train on this specific domain. Among the methods that operate in a zero-shot setting (e), MASt3R is the only one attaining reasonable performance.</p>
<hr class="docutils" />
<p>âœ… ä¸‰ã€Resultsï¼ˆå®éªŒç»“æœï¼‰</p>
<ul class="simple">
<li><p><strong>ä¼ ç»Ÿ SfM æ–¹æ³•è¡¨ç°å¾ˆå·®</strong>ï¼ŒåŸå› ï¼š</p>
<ul>
<li><p>å¾ˆå¤šå›¾åƒå¯¹è§†è§’è·¨åº¦å¤§ï¼ˆæœ‰çš„è¾¾åˆ° 180Â°ï¼‰ï¼›</p></li>
<li><p>å›¾åƒä¸­ç‰©ä½“å°ã€èƒŒæ™¯å°‘ï¼Œéš¾ä»¥ä¸‰è§’æµ‹é‡ï¼›</p></li>
</ul>
</li>
<li><p><strong>3D-grounded å­¦ä¹ æ–¹æ³•è¡¨ç°æ›´å¥½</strong>ï¼Œå¦‚ï¼š</p>
<ul>
<li><p>RayDiffusionã€DUSt3R å’Œ MASt3R æ˜¯è¡¨ç°æœ€å¼ºçš„ï¼›</p></li>
<li><p>MASt3R åœ¨å¹³ç§»ç²¾åº¦å’Œæ•´ä½“å‡†ç¡®ç‡ï¼ˆmAAï¼‰ä¸Š<strong>é¢†å…ˆæ‰€æœ‰æ–¹æ³•</strong>ï¼›</p></li>
<li><p>åœ¨ RealEstate10k ä¸Šï¼Œ<strong>mAA æ¯”æœ€å¥½çš„å¤šè§†å›¾æ–¹æ³•é«˜äº† 8.7 åˆ†</strong>ï¼›</p></li>
<li><p>æ¯” DUSt3Rï¼ˆä¹Ÿåªç”¨å›¾åƒå¯¹ï¼‰é«˜äº† <strong>15.2 åˆ†</strong>ï¼</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<p>âœ… æ€»ç»“ä¸€å¥è¯ï¼š</p>
<blockquote>
<div><p>åœ¨éå¸¸å›°éš¾çš„ç›¸å¯¹ä½å§¿ä¼°è®¡ä»»åŠ¡ä¸­ï¼Œå³ä½¿åªä½¿ç”¨å›¾åƒå¯¹ï¼ˆä¸åƒå…¶ä»–æ–¹æ³•ç”¨å¤šè§†å›¾ä¿¡æ¯ï¼‰ï¼ŒMASt3R ä¾ç„¶åœ¨å¹³ç§»ç²¾åº¦å’Œæ€»ä½“å‡†ç¡®ç‡ä¸Šå¤§å¹…é¢†å…ˆï¼Œå±•ç°äº†å¼ºå¤§çš„é²æ£’æ€§å’Œå¯¹å°ç‰©ä½“ã€å¤§è§†è§’å·®åœºæ™¯çš„é€‚åº”èƒ½åŠ›ã€‚</p>
</div></blockquote>
</section>
<section id="visual-localization-solute-pose-estimation">
<h3>4.4. Visual localization(solute pose estimation)<a class="headerlink" href="#visual-localization-solute-pose-estimation" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>â—¾ æ•°æ®é›†ä»‹ç»ï¼š</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>æ•°æ®é›†</p></th>
<th class="head"><p>åœºæ™¯ç±»å‹</p></th>
<th class="head"><p>ç‰¹ç‚¹</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Aachen Day-Night</strong></p></td>
<td><p>åŸå¸‚æˆ·å¤–</p></td>
<td><p>4328 å¼ å‚è€ƒå›¾ï¼ˆç›¸æœºå·²çŸ¥ï¼‰ï¼Œ824 å¼ ç™½å¤© + 98 å¼ å¤œæ™šæŸ¥è¯¢å›¾ï¼ˆæ‰‹æœºæ‹æ‘„ï¼‰</p></td>
</tr>
<tr class="row-odd"><td><p><strong>InLoc</strong></p></td>
<td><p>å®¤å†…</p></td>
<td><p>9972 å¼  RGB-D å‚è€ƒå›¾ + 329 å¼ æŸ¥è¯¢å›¾ï¼ˆiPhone7 æ‹æ‘„ï¼‰ï¼ŒæŒ‘æˆ˜åœ¨äºå…‰ç…§å˜åŒ–å¤§</p></td>
</tr>
</tbody>
</table>
<hr class="docutils" />
<p>â—¾ è¯„ä¼°æŒ‡æ ‡ï¼š</p>
<ul class="simple">
<li><p><strong>Aachen</strong>ï¼šä¸‰ä¸ªé˜ˆå€¼ï¼š</p>
<ul>
<li><p>0.25 ç±³ &amp; 2Â°</p></li>
<li><p>0.5 ç±³ &amp; 5Â°</p></li>
<li><p>5 ç±³ &amp; 10Â°</p></li>
</ul>
</li>
<li><p><strong>InLoc</strong>ï¼šä¸‰ä¸ªé˜ˆå€¼ï¼Œè§’åº¦å›ºå®šï¼ˆ10Â°ï¼‰ï¼š</p>
<ul>
<li><p>0.25 ç±³ã€0.5 ç±³ã€1 ç±³</p></li>
</ul>
</li>
</ul>
<p>åªæœ‰ä½ç§»å’Œæ—‹è½¬è¯¯å·®éƒ½å°äºé˜ˆå€¼ï¼Œå›¾åƒæ‰ç®—æˆåŠŸå®šä½ã€‚</p>
<hr class="docutils" />
<p>â—¾ å®éªŒç»“æœäº®ç‚¹ï¼š</p>
<ol class="arabic simple">
<li><p><strong>ä¸åŒçš„æ£€ç´¢å›¾æ•°é‡ï¼ˆTop-K retrieved imagesï¼‰å¯¹æ•ˆæœæœ‰å½±å“</strong>ï¼š</p>
<ul class="simple">
<li><p>ä½¿ç”¨ Top-40 æ£€ç´¢å›¾æ—¶ï¼Œæ•ˆæœæœ€ä½³ï¼›</p></li>
<li><p>åœ¨ InLoc ä¸Šè¡¨ç° <strong>æ˜¾è‘—è¶…è¶Šç°æœ‰æ–¹æ³•</strong>ï¼›</p></li>
</ul>
</li>
<li><p><strong>å³ä¾¿åªç”¨ Top-1 æ£€ç´¢å›¾ï¼ˆä¹Ÿå°±æ˜¯åªå‚è€ƒä¸€å¼ å›¾ï¼‰ï¼Œæ•ˆæœä¾ç„¶å¾ˆå¼º</strong>ï¼Œä½“ç°å‡ºï¼š</p>
<ul class="simple">
<li><p>MASt3R 3D-grounded åŒ¹é…çš„é²æ£’æ€§ï¼›</p></li>
</ul>
</li>
<li><p>ä½œè€…ä¹Ÿåšäº†ä¸€ä¸ªå¯¹æ¯”å®éªŒ â€”â€” <strong>ç›´æ¥å›å½’ç›¸æœºä½å§¿</strong>ï¼ˆä¸åšåŒ¹é…ï¼‰ï¼š</p>
<ul class="simple">
<li><p>æ•ˆæœå¾ˆå·®ï¼Œç‰¹åˆ«æ˜¯æ•°æ®é›†å°ºåº¦å¤§æ—¶ï¼ˆåœºæ™¯å¤§æ—¶ï¼Œè¯¯å·®æ›´æ˜æ˜¾ï¼‰ï¼›</p></li>
<li><p>è¿™è¯´æ˜ï¼š<strong>â€åŒ¹é… + ä¼°è®¡â€ çš„ pipeline æ˜æ˜¾æ›´ç¨³ï¼Œæ›´å¯é ã€‚</strong></p></li>
</ul>
</li>
</ol>
<p>âœ… æ€»ç»“ä¸€å¥è¯ï¼š</p>
<blockquote>
<div><p>MASt3R åœ¨è§†è§‰å®šä½ä¸­æ•ˆæœä¼˜å¼‚ï¼Œå°¤å…¶åœ¨ä»…ä½¿ç”¨ä¸€å¼ å‚è€ƒå›¾æ—¶ä¾ç„¶è¡¨ç°ç¨³å®šï¼Œè¿œè¶…å›å½’æ–¹æ³•ï¼Œå¹¶ä¸”åœ¨å®¤å†… InLoc æ•°æ®é›†ä¸Šé¦–æ¬¡å¤§å¹…è¶…è¶Šç°æœ‰ SOTA æ–¹æ³•ã€‚</p>
</div></blockquote>
</section>
<hr class="docutils" />
<section id="multiview-3d-reconstruction">
<h3>4.5 Multiview 3D Reconstructionï¼ˆå¤šè§†å›¾ä¸‰ç»´é‡å»ºï¼‰<a class="headerlink" href="#multiview-3d-reconstruction" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>è¿™æ˜¯æŒ‡ï¼šåœ¨çŸ¥é“å¤šå¼ å›¾åƒä¹‹é—´çš„åŒ¹é…ç‚¹åï¼Œé€šè¿‡ä¸‰è§’æµ‹é‡æ¢å¤ä¸‰ç»´ç‚¹äº‘æ¨¡å‹ã€‚</p>
<hr class="docutils" />
<p>â—¾ å…³é”®åšæ³•ï¼š</p>
<ul class="simple">
<li><p>MASt3R ä¸ä¾èµ–ç›¸æœºä¿¡æ¯ï¼ˆå†…å‚/å¤–å‚ï¼‰ï¼Œ<strong>å…ˆåšåŒ¹é…ï¼Œå†ç”¨ ground-truth ç›¸æœºä½å§¿åšä¸‰è§’æµ‹é‡</strong>ï¼›</p></li>
<li><p>ä¸ºäº†æ¸…é™¤é”™è¯¯åŒ¹é…ç‚¹ï¼Œä½œè€…è¿˜ç”¨äº†å‡ ä½•ä¸€è‡´æ€§åå¤„ç†ï¼›</p></li>
<li><p>æ‰€æœ‰åŒ¹é…éƒ½åœ¨å…¨åˆ†è¾¨ç‡ä¸‹è¿›è¡Œï¼ˆæ›´ç²¾ç»†ï¼‰ï¼›</p></li>
</ul>
<hr class="docutils" />
<p>â—¾ æ•°æ®é›†å’Œè¯„ä¼°æŒ‡æ ‡ï¼š</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>æ•°æ®é›†</p></th>
<th class="head"><p>è¯´æ˜</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>DTU</strong></p></td>
<td><p>å¤šè§†å›¾é‡å»º benchmarkï¼Œå®¤å†…ç»“æ„å…‰è·å–çš„å‚è€ƒç‚¹äº‘ï¼Œå¹¿æ³›ç”¨äº 3D é‡å»ºä»»åŠ¡</p></td>
</tr>
</tbody>
</table>
<p>æŒ‡æ ‡ï¼š</p>
<ul class="simple">
<li><p><strong>Accuracy</strong>ï¼šé‡å»ºç‚¹åˆ°çœŸå®ç‚¹äº‘æœ€è¿‘è·ç¦»çš„å¹³å‡å€¼ï¼›</p></li>
<li><p><strong>Completeness</strong>ï¼šçœŸå®ç‚¹äº‘ä¸­æ¯ä¸ªç‚¹åˆ°é‡å»ºç‚¹æœ€è¿‘è·ç¦»ï¼›</p></li>
<li><p><strong>Chamfer Distance</strong>ï¼šä»¥ä¸Šä¸¤è€…çš„å¹³å‡å€¼ï¼ˆè¶Šä½è¶Šå¥½ï¼‰</p></li>
</ul>
<p>å…·ä½“å‚è§ Table 3</p>
<hr class="docutils" />
<p>â—¾ å®éªŒç»“æœäº®ç‚¹ï¼š</p>
<ol class="arabic simple">
<li><p><strong>æ‰‹å·¥æ–¹æ³•ï¼ˆæ¯”å¦‚ä¼ ç»Ÿ SfMï¼‰è¿œè¿œä¸å¦‚å­¦ä¹ æ–¹æ³•</strong>ï¼›</p>
<ul class="simple">
<li><p>æ•°æ®é©±åŠ¨æ–¹æ³• Chamfer è·ç¦»å‡åŠï¼›</p></li>
</ul>
</li>
<li><p>MASt3R æ˜¯ <strong>zero-shot setting</strong>ï¼š</p>
<ul class="simple">
<li><p>æ²¡æœ‰åœ¨ DTU æ•°æ®é›†è®­ç»ƒã€finetuneï¼›</p></li>
<li><p>ç›´æ¥ä½¿ç”¨æ¨¡å‹å°±èƒ½è¾¾åˆ°é«˜æ°´å¹³ï¼›</p></li>
</ul>
</li>
<li><p>MASt3R å³ä½¿ <strong>ä¸ä½¿ç”¨ç›¸æœºå†…å‚/å§¿æ€æ¥åšåŒ¹é…</strong>ï¼Œä¾ç„¶è¶…è¶Š DUSt3R baselineï¼›</p>
<ul class="simple">
<li><p>ç”šè‡³ä¸æœ€å¥½çš„è®­ç»ƒæ–¹æ³•ç«äº‰ï¼</p></li>
</ul>
</li>
</ol>
<p>âœ… æ€»ç»“ä¸€å¥è¯ï¼š</p>
<blockquote>
<div><p>MASt3R ç¬¬ä¸€æ¬¡åœ¨ zero-shot æƒ…å†µä¸‹å®ç°ä¸æœ‰ç›‘ç£æ–¹æ³•ç›¸å½“çš„é‡å»ºç²¾åº¦ï¼Œä¸”å®Œå…¨ä¸ä¾èµ–ç›¸æœºæ ‡å®šï¼Œå±•ç¤ºå‡ºè¶…å¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
</div></blockquote>
<hr class="docutils" />
<p>âœ… æ€»ç»“æ€»è§ˆ</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>ä»»åŠ¡ç±»å‹</p></th>
<th class="head"><p>MASt3R ä¼˜åŠ¿</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>ç»å¯¹å®šä½</strong></p></td>
<td><p>Top-1 è¡¨ç°ä¾ç„¶ä¼˜ç§€ï¼Œè¶…è¶Šå¤šå›¾æ–¹æ³•ï¼Œè¿œè¶…å›å½’</p></td>
</tr>
<tr class="row-odd"><td><p><strong>3D é‡å»º</strong></p></td>
<td><p>æ— éœ€è®­ç»ƒã€æ— ç›¸æœºä¿¡æ¯ä¹Ÿèƒ½è¾¾åˆ°é¢†å…ˆç²¾åº¦</p></td>
</tr>
<tr class="row-even"><td><p><strong>æ–¹æ³•æ ¸å¿ƒ</strong></p></td>
<td><p>3D-grounded feature matching + å¯æ³›åŒ–åˆ°å¤šä»»åŠ¡</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="conclusion">
<h2>5. Conclusion<a class="headerlink" href="#conclusion" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p>Grounding image matching in 3D with MASt3R significantly raised the bar on camera pose and localization tasks on many public benchmarks. We successfully improved DUSt3R with matching, getting the best of both worlds: enhanced robustness, while attaining and even surpassing what could be done with pixel matching alone. We introduced a fast reciprocal matcher and a coarse to fine approach for efficient processing, allowing users to balance between accuracy and speed. MASt3R is able to perform in few-view regimes (even in top1), that we believe will greatly increase versatility of localization.</p>
<ul class="simple">
<li><p>é€šè¿‡å°†å›¾åƒåŒ¹é…â€œé”šå®šâ€åˆ° 3D ä¸Šï¼ˆå³è€ƒè™‘ä¸‰ç»´å‡ ä½•çº¦æŸï¼‰ï¼ŒMASt3R åœ¨å¤šä¸ªå…¬å¼€æ•°æ®é›†ä¸Šæ˜¾è‘—æå‡äº†ç›¸æœºå§¿æ€ä¼°è®¡å’Œå®šä½ä»»åŠ¡çš„æ€§èƒ½ã€‚</p></li>
<li><p>æˆ‘ä»¬åœ¨ DUSt3R çš„åŸºç¡€ä¸Šè¿›ä¸€æ­¥å¼•å…¥äº†åŒ¹é…æœºåˆ¶ï¼Œå®ç°äº†åŒèµ¢ï¼š</p>
<ul>
<li><p><strong>æ›´å¼ºçš„é²æ£’æ€§</strong>ï¼ˆå¯¹ä¸åŒè§†è§’ã€é®æŒ¡ã€æ¨¡ç³Šçš„é€‚åº”åŠ›æ›´å¥½ï¼‰</p></li>
<li><p><strong>ç”šè‡³è¶…è¶Šäº†ä¼ ç»Ÿçš„åƒç´ çº§åŒ¹é…æ–¹æ³•çš„æ€§èƒ½</strong></p></li>
</ul>
</li>
<li><p>æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªå¿«é€Ÿçš„<strong>äº’ç›¸åŒ¹é…å™¨ï¼ˆreciprocal matcherï¼‰</strong>ï¼Œä»¥åŠ**ç²—åˆ°ç»†ï¼ˆcoarse-to-fineï¼‰**çš„å¤„ç†ç­–ç•¥ï¼š</p>
<ul>
<li><p>è¿™ä½¿å¾—åœ¨è¿è¡Œæ—¶å¯ä»¥çµæ´»æƒè¡¡<strong>ç²¾åº¦</strong>å’Œ<strong>é€Ÿåº¦</strong>ï¼Œé€‚åº”ä¸åŒçš„å®é™…åœºæ™¯éœ€æ±‚ã€‚</p></li>
</ul>
</li>
<li><p>MASt3R åœ¨<strong>å°‘è§†å›¾ï¼ˆfew-viewï¼‰åœºæ™¯ä¸‹è¡¨ç°ä¾ç„¶å¼ºå¤§</strong>ï¼Œç”šè‡³åªç”¨ä¸€å¼ å‚è€ƒå›¾ï¼ˆtop1ï¼‰å°±èƒ½è¿›è¡Œé«˜è´¨é‡å®šä½ï¼Œ</p>
<ul>
<li><p>æˆ‘ä»¬è®¤ä¸ºè¿™å°†å¤§å¤§æå‡å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„<strong>é€šç”¨æ€§å’Œé€‚åº”åŠ›</strong>ã€‚</p></li>
</ul>
</li>
</ul>
<p>âœ… æ€»ç»“ä¸€å¥è¯ï¼š</p>
<blockquote>
<div><p><strong>MASt3R å°†å›¾åƒåŒ¹é…å¸¦å…¥äº† 3D ç»´åº¦ï¼Œåœ¨å§¿æ€ä¼°è®¡ä¸å®šä½ä»»åŠ¡ä¸­æ ‘ç«‹äº†æ–°æ ‡æ†ã€‚å…¶é«˜é²æ£’æ€§ã€è¿è¡Œæ•ˆç‡ä¸å°‘å›¾åƒé€‚åº”æ€§ï¼Œä½¿å…¶åœ¨å¤šç§ç°å®åœºæ™¯ä¸‹å…·å¤‡å¼ºå¤§å®ç”¨ä»·å€¼ã€‚</strong></p>
</div></blockquote>
</section>
<section id="appendix">
<h2>Appendix<a class="headerlink" href="#appendix" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<ul class="simple">
<li><p>åœ¨é™„å½• A ä¸­å±•ç¤ºäº†åœ¨ä¸åŒä»»åŠ¡ä¸Šçš„é¢å¤–å®šæ€§ç¤ºä¾‹</p></li>
<li><p>åœ¨é™„å½• B ä¸­æä¾›äº†å¿«é€Ÿäº’æƒ åŒ¹é…ç®—æ³•æ”¶æ•›æ€§çš„è¯æ˜åŠç›¸å…³çš„æ€§èƒ½å¢ç›Šæ·±å…¥ç ”ç©¶</p></li>
<li><p>åœ¨é™„å½• C ä¸­å±•ç¤ºäº†ä¸€ä¸ªå…³äºç²—åˆ°ç²¾åŒ¹é…å½±å“çš„æ¶ˆèç ”ç©¶ã€‚</p></li>
</ul>
</section>
<section id="appendix-a-additional-qualitative-results">
<h2>Appendix A Additional Qualitative Results<a class="headerlink" href="#appendix-a-additional-qualitative-results" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<blockquote>
<div><p>Appendix A ä¸»è¦å±•ç¤º MASt3R åœ¨å››ä¸ªæ•°æ®é›†ä¸Šçš„å®é™…è§†è§‰è¡¨ç°ï¼š</p>
</div></blockquote>
<ul class="simple">
<li><p><strong>DTU</strong>ï¼ˆå¤šè§†å›¾3Dé‡å»ºï¼‰</p></li>
<li><p><strong>InLoc</strong>ï¼ˆå®¤å†…å®šä½ï¼‰</p></li>
<li><p><strong>Aachen Day-Night</strong>ï¼ˆæ—¥å¤œåŸå¸‚å®šä½ï¼‰</p></li>
<li><p><strong>Map-Free Benchmark</strong>ï¼ˆé›¶åœ°å›¾å®šä½ï¼‰</p></li>
</ul>
<hr class="docutils" />
<p>ğŸŸ§ 1. <strong>MVS on DTUï¼šä¸‰ç»´é‡å»ºè´¨é‡</strong></p>
<ul class="simple">
<li><p><strong>ç‚¹äº‘å±•ç¤º</strong>ï¼šFigure 5å±•ç¤ºäº† MASt3R é€šè¿‡<strong>ç²—åˆ°ç»†åŒ¹é…</strong>è·å¾—çš„ç‚¹äº‘ï¼ˆä¸‰è§’åŒ–åï¼‰ï¼›</p></li>
<li><p><strong>æ²¡æœ‰ç”¨ GT ç›¸æœºå‚æ•°</strong>ï¼šå…¨ç¨‹æ²¡æœ‰ä½¿ç”¨ç›¸æœºå†…å‚æˆ–å¤–å‚ï¼Œè€Œæ˜¯<strong>one-versus-all ç­–ç•¥</strong>ï¼Œå³ï¼šæ¯å¼ å›¾åƒéƒ½å’Œæ‰€æœ‰å…¶ä»–å›¾åƒåŒ¹é…ï¼›</p></li>
<li><p><strong>ç»“æœè´¨é‡</strong>ï¼š</p>
<ul>
<li><p><strong>ç»“æ„å®Œæ•´</strong>ï¼ˆå³ä¾¿æ˜¯ä½å¯¹æ¯”åŒºåŸŸå¦‚è”¬èœè¡¨é¢ã€ç”µæºä¾§é¢ï¼‰ï¼›</p></li>
<li><p><strong>çº¹ç†/æè´¨/å…‰ç…§å˜åŒ–é²æ£’</strong>ï¼ˆå³ä½¿å¡‘æ–™åå…‰ã€ç™½è‰²é›•å¡‘ã€é«˜åå°„è¡¨é¢ä¹Ÿèƒ½å¤„ç†ï¼‰ã€‚</p></li>
</ul>
</li>
</ul>
<p>ğŸ“Œ ä¸€å¥è¯æ€»ç»“ï¼š<strong>åœ¨ä¸ä¾èµ–ç›¸æœºå‚æ•°çš„å‰æä¸‹ï¼Œä»èƒ½å®ç°é«˜è´¨é‡ 3D é‡å»ºï¼Œæ˜¯ä¸€é¡¹çªç ´ã€‚</strong></p>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/04/fXzdzl.png" /></p>
<p>Figure 5: Qualitative MVS results on the DTU dataset simply obtained by triangulating the dense matches from MASt3R.</p>
<hr class="docutils" />
<p>ğŸŸ§ 2. <strong>Qualitative Matching ç»“æœï¼ˆå›¾6ã€7ã€8ï¼‰</strong></p>
<ul class="simple">
<li><p><strong>å›¾6ï¼šMap-Free æ•°æ®é›†åŒ¹é…ç»“æœ</strong></p>
<ul>
<li><p>èƒ½å¤„ç†è§†è§’æå·®å˜åŒ–ï¼ˆå¦‚ä¸¤å¼ å›¾æ˜¯äº’ç›¸å¯¹æ‹çš„ï¼‰ï¼Œä¾ç„¶èƒ½åŒ¹é…å¤§è‡´å¯¹åº”åŒºåŸŸï¼›</p></li>
<li><p>åº”å¯¹**å°ºåº¦å˜åŒ–å¤§ã€é‡å¤å›¾æ¡ˆã€ç¯å¢ƒå˜åŒ–ï¼ˆå¦‚å…‰ç…§ä¸åŒï¼‰**ç­‰å›°éš¾åœºæ™¯ï¼›</p></li>
</ul>
</li>
</ul>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/04/ZS0BbM.png" /></p>
<p>Figure 6: Qualitative examples of matching on Map-free localization benchmark.</p>
<ul class="simple">
<li><p><strong>å›¾7ï¼šInLocï¼ˆå®¤å†…ï¼‰</strong></p>
<ul>
<li><p>å³ä½¿é¢å¯¹é¢è§†è§’ï¼ˆå¦‚èµ°å»Šï¼‰ä¹Ÿèƒ½æ‰¾åˆ°åˆç†åŒ¹é…ï¼›</p></li>
<li><p>æ˜¾ç¤ºå…¶ç»§æ‰¿äº† DUSt3R åœ¨æç«¯è§†è§’å˜åŒ–ä¸‹çš„é²æ£’æ€§ï¼›</p></li>
</ul>
</li>
</ul>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/04/vdb2bl.png" /></p>
<p>Figure 7: Qualitative examples of matching on the InLoc localization benchmark.</p>
<ul class="simple">
<li><p><strong>å›¾8ï¼šAachen Day-Nightï¼ˆåŸå¸‚æ—¥å¤œï¼‰</strong></p>
<ul>
<li><p><strong>å·¦åˆ—ï¼šç™½å¤©å›¾å¯¹ç™½å¤©å›¾</strong>ï¼›</p></li>
<li><p><strong>å³åˆ—ï¼šå¤œæ™šå›¾å¯¹å¤œæ™šå›¾</strong>ï¼›</p></li>
<li><p>èƒ½æœ‰æ•ˆå¤„ç†æ—¥å¤œå…‰ç…§å˜åŒ–å¸¦æ¥çš„åŒ¹é…æŒ‘æˆ˜ã€‚</p></li>
</ul>
</li>
</ul>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/04/pJKlIL.png" /></p>
<p>Figure 8: Qualitative examples of matching on the Aachen Day-Night localization benchmark. Pairs from the day subset are on the left column, and pairs from the night subset are on the right column.</p>
<p>ğŸ“Œ å…±åŒç»“è®ºï¼š</p>
<ul class="simple">
<li><p>MASt3R èƒ½<strong>åœ¨æç«¯å›°éš¾æ¡ä»¶ä¸‹ä¿ç•™åŒ¹é…å‡†ç¡®æ€§</strong>ï¼›</p></li>
<li><p><strong>å³ä½¿åŒ¹é…ä¸ç²¾ç¡®ï¼Œä¹Ÿèƒ½æ¢å¤å‡ºåˆç†çš„ç›¸å¯¹ä½å§¿</strong>ï¼›</p></li>
<li><p><strong>é›¶æ ·æœ¬æƒ…å†µä¸‹ä¹Ÿèƒ½è¾¾åˆ°SOTAæˆ–æ¥è¿‘SOTAæ°´å¹³</strong>ã€‚</p></li>
</ul>
<hr class="docutils" />
<p>âœ… æœ€åä¸€å¥ç‚¹é¢˜ï¼š</p>
<blockquote>
<div><p>â€œWe hope this work will foster research in the direction of pointmap regressionâ€¦â€<br />
æˆ‘ä»¬å¸Œæœ›è¿™é¡¹å·¥ä½œèƒ½æ¨åŠ¨å›¾åƒè§†è§‰ä»»åŠ¡ä¸­â€œç‚¹å›¾å›å½’â€çš„ç ”ç©¶å‘å±• â€”â€” ç‰¹åˆ«æ˜¯é‚£äº›å¯¹<strong>é²æ£’æ€§</strong>ä¸<strong>ç²¾åº¦</strong>è¦æ±‚æé«˜çš„ä»»åŠ¡ã€‚</p>
</div></blockquote>
</section>
<hr class="docutils" />
<section id="b-fast-reciprocal-matching">
<h2>B. Fast Reciprocal Matching<a class="headerlink" href="#b-fast-reciprocal-matching" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<section id="b-1-theoretical-study">
<h3>B.1. Theoretical study<a class="headerlink" href="#b-1-theoretical-study" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p><strong>Fast Reciprocal Matchingï¼ˆFRMï¼‰ç®—æ³•çš„ç†è®ºæ”¶æ•›æ€§è¯æ˜</strong>ï¼Œä¸»è¦å›´ç»•å®ƒå¦‚ä½•åœ¨å›¾ç»“æ„ä¸­é«˜æ•ˆåœ°æ‰¾åˆ°åƒç´ ä¹‹é—´çš„äº’ä¸ºæœ€è¿‘é‚»ï¼ˆreciprocal nearest neighborï¼‰å¯¹åº”å…³ç³»ã€‚</p>
<hr class="docutils" />
<p>ğŸ§  <strong>èƒŒæ™¯ä¸ç›®æ ‡</strong></p>
<p>ä¼ ç»Ÿçš„åƒç´ åŒ¹é…æ–¹æ³•ï¼ˆæ¯”å¦‚åŸºäºäºŒåˆ†å›¾åŒ¹é…ï¼‰é€šå¸¸è®¡ç®—çš„æ˜¯<strong>å…¨å›¾</strong>çš„å¯¹åº”å…³ç³»ï¼Œè¿™æ ·è®¡ç®—é‡å¤§ã€‚è€ŒFRMçš„ç›®æ ‡æ˜¯ï¼š</p>
<ul class="simple">
<li><p><strong>åªåŒ¹é…éƒ¨åˆ†å›¾</strong>ï¼Œå‡å°‘è®¡ç®—ï¼›</p></li>
<li><p>å¹¶ä¸”<strong>ä»ç„¶ä¿è¯åŒ¹é…çš„æ­£ç¡®æ€§</strong>å’Œ<strong>ç†è®ºä¸Šçš„æ”¶æ•›æ€§</strong>ã€‚</p></li>
</ul>
<hr class="docutils" />
<p>ğŸ“Œ <strong>ç®—æ³•å›é¡¾</strong></p>
<p>æˆ‘ä»¬æœ‰ä¸¤ä¸ªå›¾åƒçš„ç‰¹å¾å›¾ <span class="math notranslate nohighlight">\(D^1, D^2 \in \mathbb{R}^{H \times W \times d}\)</span>ã€‚</p>
<p>äº’ä¸ºæœ€è¿‘é‚»ï¼ˆmutual NNï¼‰çš„åŒ¹é…ç‚¹å®šä¹‰å¦‚ä¸‹ï¼š
$<span class="math notranslate nohighlight">\(
M = \{(i, j) \mid j = \mathrm{NN}_2(D_i^1) \text{ ä¸” } i = \mathrm{NN}_1(D_j^2)\}
\)</span><span class="math notranslate nohighlight">\(
ä¹Ÿå°±æ˜¯ä»å›¾åƒ1çš„åƒç´ \)</span>i<span class="math notranslate nohighlight">\(æ˜ å°„åˆ°å›¾åƒ2ä¸­æœ€è¿‘çš„\)</span>j<span class="math notranslate nohighlight">\(ï¼Œç„¶åä»\)</span>j<span class="math notranslate nohighlight">\(å†æ˜ å°„å›æ¥ï¼Œå¦‚æœåˆå›åˆ°\)</span>i$ï¼Œå°±è®¤ä¸ºè¿™æ˜¯ä¸€ä¸ª<strong>åˆæ³•çš„åŒ¹é…å¯¹</strong>ã€‚</p>
<hr class="docutils" />
<p>ğŸ” <strong>ç®—æ³•æµç¨‹</strong></p>
<ol class="arabic simple">
<li><p><strong>èµ·å§‹ï¼š</strong> ä»å›¾åƒ <span class="math notranslate nohighlight">\(I^1\)</span> ä¸­éšæœºé€‰æ‹© <span class="math notranslate nohighlight">\(k \ll HW\)</span> ä¸ªèµ·ç‚¹ <span class="math notranslate nohighlight">\(U^0\)</span>ï¼›</p></li>
<li><p><strong>å‰å‘ï¼š</strong> æ¯ä¸ªç‚¹æ‰¾åˆ°åœ¨ <span class="math notranslate nohighlight">\(I^2\)</span> ä¸­çš„æœ€è¿‘é‚»ï¼Œå¾— <span class="math notranslate nohighlight">\(V^t\)</span>ï¼›</p></li>
<li><p><strong>åå‘ï¼š</strong> <span class="math notranslate nohighlight">\(V^t\)</span> ä¸­çš„ç‚¹å†æ‰¾å›åœ¨ <span class="math notranslate nohighlight">\(I^1\)</span> ä¸­çš„æœ€è¿‘é‚»ï¼Œå¾— <span class="math notranslate nohighlight">\(U^{t+1}\)</span>ï¼›</p></li>
<li><p><strong>æ£€æŸ¥ç¯ï¼š</strong> å¦‚æœ <span class="math notranslate nohighlight">\(U^{t+1}\)</span> ä¸­æŸä¸ªç‚¹å›åˆ°äº†åˆå§‹ä½ç½®ï¼Œå½¢æˆäº†<strong>é—­ç¯ï¼ˆäº’ä¸ºæœ€è¿‘é‚»ï¼‰</strong>ï¼Œå°±è®°å½•ä¸‹æ¥ï¼›</p></li>
<li><p><strong>è¿­ä»£ï¼š</strong> å¯¹æœªé—­ç¯çš„ç‚¹ç»§ç»­è¿›è¡Œä¸Šé¢çš„è¿‡ç¨‹ï¼Œç›´åˆ°æ”¶æ•›æˆ–è¾¾åˆ°æœ€å¤§è½®æ•°ã€‚</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
U^t \longmapsto V^t \longmapsto U^{t+1}
\]</div>
<p>è¿™ä¸ªè¿‡ç¨‹å°±åƒåœ¨å›¾ä¸­æ¥å›â€œè·³è·ƒâ€ï¼Œç›´åˆ°æ‰¾åˆ°é‚£äº›â€œé—­ç¯è·¯å¾„â€ã€‚</p>
<hr class="docutils" />
<p>ğŸ§© <strong>å›¾ç»“æ„åˆ†æ</strong></p>
<p>FRMå…¶å®éšå¼åœ°åœ¨ä¸€ä¸ª<strong>æœ‰å‘äºŒåˆ†å›¾ <span class="math notranslate nohighlight">\(\mathcal{G}\)</span></strong> ä¸Šæ“ä½œï¼Œè¿™ä¸ªå›¾çš„ç»“æ„æ˜¯è¿™æ ·çš„ï¼š</p>
<ul class="simple">
<li><p>æ¯ä¸ªåƒç´ æ˜¯ä¸€ä¸ªèŠ‚ç‚¹ï¼›</p></li>
<li><p>æ¯ä¸ªèŠ‚ç‚¹æœ‰ä¸€æ¡<strong>æŒ‡å‘å…¶æœ€è¿‘é‚»</strong>çš„è¾¹ï¼›</p></li>
<li><p>æ‰€ä»¥<strong>æ¯ä¸ªèŠ‚ç‚¹å‡ºåº¦ä¸º1</strong>ï¼›</p></li>
<li><p>è¿™æ ·çš„å›¾ç”±è‹¥å¹²ä¸ª<strong>å­å›¾ <span class="math notranslate nohighlight">\(\mathcal{G}^i\)</span> ç»„æˆ</strong>ï¼Œæ¯ä¸ªå­å›¾è¦ä¹ˆæ˜¯ä¸€ä¸ªç®€å•çš„ç¯ï¼Œè¦ä¹ˆæ˜¯ä¸€ä¸ª<strong>æœ‰å‘æ ‘ç»“æ„ï¼Œæœ€ç»ˆæŒ‡å‘æŸä¸ªç¯</strong>ã€‚</p></li>
</ul>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/04/j1mthP.png" /></p>
<p>Figure 9: Illustration of the iterative FRM algorithm. Starting from 5 pixels in <span class="math notranslate nohighlight">\(I^{1}\)</span> at <span class="math notranslate nohighlight">\(t=0\)</span> , the FRM connects them to their Nearest Neighbors (NN) in <span class="math notranslate nohighlight">\(I^{2}\)</span> , and maps them back to their NN in <span class="math notranslate nohighlight">\(I^{1}\)</span> . If they go back to their starting point (top pink), a cycle (reciprocal match) is detected and returned. Otherwise (bottom) the algorithm continues iterating until a cycle is detected for all starting samples, or until the maximal number of iterations is reached. We show in orange the starting points of a convergence basin, i.e. nodes of a sub-graph for which the algorithm will converge towards the same cycle. For clarity, all edges of <span class="math notranslate nohighlight">\(\mathcal{G}\)</span> were not drawn.</p>
<p>å›¾ä¸­æ©™è‰²ç‚¹è¡¨ç¤ºå±äºåŒä¸€ä¸ªâ€œæ”¶æ•›ç›†åœ°ï¼ˆconvergence basinï¼‰â€çš„èµ·å§‹ç‚¹ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œè¿™äº›ç‚¹è™½ç„¶åˆå§‹ä½ç½®ä¸åŒï¼Œä½†è¿­ä»£å‡ è½®ä¹‹åï¼Œéƒ½ä¼šæ”¶æ•›åˆ°åŒä¸€ä¸ª reciprocal match ä¸Šã€‚</p>
<p>å›¾ä¸­è¦ç‚¹ï¼š</p>
<ul class="simple">
<li><p>**ç²‰è‰²ç‚¹ï¼ˆä¸Šæ–¹ï¼‰**è¡¨ç¤ºé‚£äº›å¾ˆå¿«å°±æ„æˆ reciprocal match çš„èµ·å§‹ç‚¹ã€‚</p></li>
<li><p>**è“è‰²è·¯å¾„ï¼ˆä¸‹æ–¹ï¼‰**å±•ç¤ºé‚£äº›éœ€è¦å¤šè½®è¿­ä»£æ‰èƒ½æ”¶æ•›çš„ç‚¹ã€‚</p></li>
</ul>
<hr class="docutils" />
<p>ğŸ§© <strong>æ”¶æ•›æ€§è¯æ˜</strong></p>
<ol class="arabic simple">
<li><p>ğŸ§  â€œFRMåœ¨æœ€è¿‘é‚»æœ‰å‘äºŒåˆ†å›¾<span class="math notranslate nohighlight">\(\mathcal{G}\)</span>ä¸Šè¿è¡Œâ€</p>
<ul class="simple">
<li><p>æŠŠä¸¤å¼ å›¾åƒ <span class="math notranslate nohighlight">\(I^1\)</span> å’Œ <span class="math notranslate nohighlight">\(I^2\)</span> çœ‹ä½œå›¾çš„ä¸¤ä¸ªå­é›†ï¼ˆä¸¤ä¸ªèŠ‚ç‚¹é›†ï¼‰ï¼Œæ„æˆä¸€ä¸ª<strong>äºŒåˆ†å›¾</strong>ã€‚</p></li>
<li><p>å¯¹äº <span class="math notranslate nohighlight">\(I^1\)</span> ä¸­çš„æ¯ä¸ªåƒç´  <span class="math notranslate nohighlight">\(u\)</span>ï¼Œæˆ‘ä»¬ä¼šæ‰¾åˆ°å®ƒåœ¨ <span class="math notranslate nohighlight">\(I^2\)</span> ä¸­çš„æœ€è¿‘é‚»ï¼ˆ<span class="math notranslate nohighlight">\(\mathrm{NN}_2(D_u^1)\)</span>ï¼‰ï¼Œè¿ä¸€æ¡<strong>æœ‰å‘è¾¹</strong>è¿‡å»ã€‚</p></li>
<li><p>åä¹‹äº¦ç„¶ï¼Œ<span class="math notranslate nohighlight">\(I^2\)</span> ä¸­æ¯ä¸ªç‚¹ä¹Ÿä¼šè¿å‘ <span class="math notranslate nohighlight">\(I^1\)</span> ä¸­å®ƒçš„æœ€è¿‘é‚»ã€‚</p></li>
<li><p>æ‰€ä»¥è¿™ä¸ªå›¾æ˜¯ä¸€ä¸ª<strong>æœ‰å‘äºŒåˆ†å›¾</strong>ï¼ˆDirected Bipartite Graphï¼‰ã€‚</p></li>
</ul>
</li>
<li><p>ğŸ§© â€œæ¯ä¸ªåƒç´ éƒ½åœ¨å›¾ä¸­ï¼Œéƒ½æœ‰æŒ‡å‘è‡ªå·±çš„æœ€è¿‘é‚»çš„è¾¹â€</p>
<ul class="simple">
<li><p>å› ä¸ºæ¯ä¸ªåƒç´ éƒ½è‡³å°‘ä¼šæŒ‡å‘å®ƒçš„æœ€è¿‘é‚»ï¼Œæ‰€ä»¥æ²¡æœ‰â€œå­¤ç«‹ç‚¹â€ï¼Œæ¯ä¸ªç‚¹éƒ½åœ¨å›¾é‡Œå‚ä¸æ„å›¾ã€‚</p></li>
</ul>
</li>
<li><p>â—â€œä½†ä¸æ˜¯æ‰€æœ‰åƒç´ ä¹‹é—´éƒ½èƒ½ç›¸äº’åˆ°è¾¾ï¼ˆæ— å®Œå…¨è¿é€šï¼‰â€</p>
<ul class="simple">
<li><p>æ³¨æ„ï¼Œè™½ç„¶æ‰€æœ‰ç‚¹éƒ½åœ¨å›¾é‡Œï¼Œä½†è¿™ä¸ªå›¾å¹¶ä¸æ˜¯ä¸€ä¸ªå¼ºè¿é€šå›¾ã€‚ä½ ä»æŸäº›ç‚¹å‡ºå‘ï¼Œ<strong>æœªå¿…èƒ½åˆ°è¾¾å›¾ä¸­çš„ä»»æ„å…¶ä»–ç‚¹</strong>ã€‚</p></li>
<li><p>ä¾‹å¦‚ï¼Œä»ç‚¹ <span class="math notranslate nohighlight">\(u\)</span> å‡ºå‘åªçŸ¥é“å®ƒæœ€è¿‘é‚»æ˜¯ <span class="math notranslate nohighlight">\(v\)</span>ï¼Œå†ä» <span class="math notranslate nohighlight">\(v\)</span> æ‰¾å›æœ€è¿‘é‚»æ˜¯ <span class="math notranslate nohighlight">\(u\)</span>ï¼Œè¿™ä¸ªç¯å°±åªæœ‰ <span class="math notranslate nohighlight">\((u,v)\)</span>ã€‚</p></li>
<li><p>å…¶ä»–ç‚¹å¯èƒ½å®Œå…¨ä¸èƒ½åˆ°è¾¾è¿™å¯¹ç‚¹ï¼Œæˆ–è€…å±äºå¦ä¸€ä¸ªå®Œå…¨ä¸ç›¸è¿çš„â€œä¸–ç•Œâ€ã€‚</p></li>
</ul>
</li>
<li><p>ğŸ§â€â™€ï¸â†”ï¸ğŸ§â€â™‚ï¸ â€œå¦‚æœä¸¤ä¸ªåƒç´ æ­£å¥½äº’ä¸ºæœ€è¿‘é‚»ï¼Œå®ƒä»¬å°±åªäº’ç›¸è¿æ¥ï¼Œæ²¡æœ‰åˆ«çš„è¿è¾¹â€</p>
<ul class="simple">
<li><p>ä¸¾ä¸ªä¾‹å­ï¼Œå‡è®¾å›¾åƒ <span class="math notranslate nohighlight">\(I^1\)</span> ä¸­çš„åƒç´  <span class="math notranslate nohighlight">\(u\)</span> çš„æœ€è¿‘é‚»æ˜¯å›¾åƒ <span class="math notranslate nohighlight">\(I^2\)</span> ä¸­çš„åƒç´  <span class="math notranslate nohighlight">\(v\)</span>ï¼ŒåŒæ—¶ <span class="math notranslate nohighlight">\(v\)</span> çš„æœ€è¿‘é‚»åˆæ˜¯ <span class="math notranslate nohighlight">\(u\)</span>ã€‚</p></li>
<li><p>è¿™ä¸¤è€…å°±ç»„æˆäº†ä¸€ä¸ª reciprocal matchã€‚</p></li>
<li><p>åœ¨å›¾ <span class="math notranslate nohighlight">\(\mathcal{G}\)</span> ä¸­ï¼Œä»–ä»¬åªäº’ç›¸æœ‰è¾¹ï¼Œå’Œå…¶ä»–ä»»ä½•åƒç´ <strong>æ²¡æœ‰è¿è¾¹</strong>ã€‚</p></li>
</ul>
</li>
<li><p>ğŸ”—â€œå› æ­¤ï¼Œæ•´ä¸ªå›¾<span class="math notranslate nohighlight">\(\mathcal{G}\)</span>æ˜¯ç”±å¤šä¸ªäº’ä¸è¿é€šçš„å­å›¾<span class="math notranslate nohighlight">\(\mathcal{G}^i\)</span>ç»„æˆçš„â€</p>
<ul class="simple">
<li><p>ç”±äºåƒä¸Šé¢ä¾‹å­é‚£æ ·çš„ç‚¹å¯¹åªèƒ½å½¼æ­¤è¿æ¥ï¼Œæ•´ä¸ªå›¾ <span class="math notranslate nohighlight">\(\mathcal{G}\)</span> å®é™…ä¸Šè¢«åˆ’åˆ†æˆäº†å¤šä¸ª<strong>äº’ä¸ç›¸é€šçš„å­å›¾</strong>ã€‚</p></li>
<li><p>æ¯ä¸ªå­å›¾ <span class="math notranslate nohighlight">\(\mathcal{G}^i\)</span> å°±æ˜¯æŸäº›ç‚¹ä¹‹é—´äº’ç›¸å¯è¾¾ã€äº’ä¸ºæœ€è¿‘é‚»å…³ç³»å½¢æˆçš„å±€éƒ¨é—­ç¯æˆ–æ ‘å½¢ç»“æ„ã€‚</p></li>
<li><p>ç†è®ºä¸Šæœ€å¤šå¯èƒ½æœ‰ <span class="math notranslate nohighlight">\(HW\)</span> ä¸ªå­å›¾ï¼ˆå›¾åƒæ€»åƒç´ æ•°ï¼‰ï¼Œä½†å®é™…ä¸­ä¼šå°‘äºè¿™ä¸ªå€¼ã€‚</p></li>
</ul>
</li>
</ol>
<p>ğŸ“Œ è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆåœ¨å›¾ 9 é‡Œï¼Œä¼šç”»å‡ºä¸åŒâ€œæ”¶æ•›ç›†åœ°â€ï¼ˆconvergence basinsï¼‰ï¼šæ¯ä¸ªç›†åœ°å…¶å®å°±æ˜¯æŸä¸ª <span class="math notranslate nohighlight">\(\mathcal{G}^i\)</span> å­å›¾çš„å†…éƒ¨è·¯å¾„ã€‚</p>
<hr class="docutils" />
<p>ğŸ“Œ <strong>å‘½é¢˜(Proposition) B.1</strong>ï¼šæ¯ä¸ªå­å›¾ <span class="math notranslate nohighlight">\(\mathcal{G}^i\)</span> åªå¯èƒ½æœ‰ä¸€ä¸ªç¯</p>
<ul class="simple">
<li><p>å› ä¸ºæ¯ä¸ªèŠ‚ç‚¹åªæŒ‡å‘ä¸€ä¸ªç›®æ ‡ï¼Œä¸”å›¾æ˜¯æœ‰å‘çš„ï¼›æ‰€ä»¥ä¸€æ—¦è¿›å…¥ç¯ä¸­ï¼Œæ— æ³•é€ƒå‡ºï¼›è‡ªç„¶æ— æ³•æœ‰ç¬¬äºŒä¸ªç¯ã€‚</p></li>
<li><p>è¯æ˜ï¼šå¦‚æœä½ ä»æŸä¸ªå­å›¾ <span class="math notranslate nohighlight">\(\mathcal{G}^i\)</span> ä¸­çš„ä»»æ„èŠ‚ç‚¹å¼€å§‹ï¼ŒæŒ‰ç…§è¾¹ï¼ˆæœ€è¿‘é‚»å…³ç³»ï¼‰èµ°ä¸‹å»ï¼Œä¸€æ—¦ä½ èµ°åˆ°äº†ä¸€ä¸ªå±äºæŸä¸ª<strong>ç¯</strong>ï¼ˆcycleï¼‰çš„èŠ‚ç‚¹ï¼Œä½ å°†æ— æ³•â€œè·³å‡ºâ€è¿™ä¸ªç¯ï¼Œå› ä¸ºæ¯ä¸ªç‚¹åªæœ‰ä¸€æ¡è¾¹æŒ‡å‘å®ƒçš„æœ€è¿‘é‚»ï¼Œè€Œè¿™ä¸ªæœ€è¿‘é‚»å…³ç³»<strong>å·²ç»æ„æˆäº†è¿™ä¸ªé—­ç¯</strong>ï¼Œæ²¡æœ‰å…¶ä»–è·¯å¾„å¯ä»¥ç¦»å¼€è¿™ä¸ªç¯ã€‚</p></li>
</ul>
<hr class="docutils" />
<p>ğŸŒ³ <strong>å¼•ç†(Lemma) B.2</strong>ï¼šæ¯ä¸ªå­å›¾æ˜¯ä¸€ä¸ªâ€œä»¥ç¯ä¸ºæ ¹â€çš„<strong>æœ‰å‘æ ‘ï¼ˆarborescenceï¼‰</strong></p>
<ul class="simple">
<li><p>è¦ä¹ˆå®ƒæœ¬èº«å°±æ˜¯ä¸€ä¸ªç¯ï¼›è¦ä¹ˆå®ƒåƒä¸€æ£µå€’ç½®çš„æ ‘ï¼Œæ‰€æœ‰è·¯å¾„æœ€ç»ˆéƒ½ä¼šè¿›å…¥é‚£ä¸ªå”¯ä¸€çš„ç¯ï¼›åœ¨è·¯å¾„ä¸Šï¼ŒåŒ¹é…çš„<strong>ç›¸ä¼¼åº¦æ˜¯å•è°ƒé€’å¢çš„</strong>ï¼Œæœ€ç»ˆä¼šè¾¾åˆ°æœ€å¤§å€¼ï¼Œä»è€Œè¿›å…¥ç¯ã€‚</p></li>
</ul>
<p>ç»“æ„ç±»æ¯”ä¸ºï¼š</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>     u1     u2       u3
      â†˜     â†“         â†˜
        v1 â†’ v2 â†’ v3 â†’ v1    â† ä¸€ä¸ªæ ¹ç¯ï¼ˆv1â†’v2â†’v3â†’v1ï¼‰
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">u1,</span> <span class="pre">u2,</span> <span class="pre">u3</span></code> æ˜¯<strong>éç¯èŠ‚ç‚¹</strong>ï¼Œå®ƒä»¬æŒ‡å‘æŸä¸ªç¯ä¸Šçš„èŠ‚ç‚¹</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">v1,</span> <span class="pre">v2,</span> <span class="pre">v3</span></code> æ„æˆ<strong>ä¸€ä¸ªé—­ç¯</strong></p></li>
<li><p>è¿™ç§ç»“æ„å°±æ˜¯æ‰€è°“çš„ â€œspecial arborescence + root cycleâ€</p></li>
</ul>
<p>å°ç»“ï¼š<strong>æ¯ä¸ª FRM å­å›¾ <span class="math notranslate nohighlight">\(\mathcal{G}^i\)</span> æœ€ç»ˆéƒ½å½¢æˆä¸€ä¸ªæœ‰å‘â€œæ ‘ + æ ¹ç¯â€ç»“æ„</strong>ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼šä»ä»»æ„ç‚¹å‡ºå‘ä¸æ–­æ‰¾æœ€è¿‘é‚»ï¼Œæœ€ç»ˆéƒ½èƒ½æ”¶æ•›åˆ°ä¸€ä¸ªç¯ï¼ˆè¿™ä¸ªç¯å³ä¸º reciprocal match ç»“æœï¼‰ã€‚è¿™å°±æ˜¯ FRM ç®—æ³•èƒ½è¿­ä»£æ”¶æ•›çš„ç†è®ºä¿è¯ã€‚</p>
<hr class="docutils" />
<p>ğŸ” <strong>æ¨è®º(Corollary) B.3</strong>ï¼šæ— è®ºä»å›¾ <span class="math notranslate nohighlight">\(\mathcal{G}^i\)</span> ä¸­å“ªä¸ªåƒç´ å‡ºå‘ï¼ŒFRM ç®—æ³•æ€»ä¼šæ”¶æ•›åˆ° reciprocal matchï¼ˆäº’ä¸ºæœ€è¿‘é‚»çš„åŒ¹é…å¯¹ï¼‰ã€‚</p>
<ul class="simple">
<li><p>è¿™æ„å‘³ç€FRMæ˜¯<strong>æ”¶æ•›çš„</strong>ï¼Œä¸”ä¸€å®šä¼šæ‰¾åˆ°å¯¹åº”çš„ç‚¹å¯¹ã€‚</p></li>
</ul>
<p>âœ… æ€»ç»“ä¸€å¥è¯</p>
<blockquote>
<div><p>Corollary B.3 ä¿è¯äº† FRM ç®—æ³•ä»ä»»æ„åˆå§‹ç‚¹å‡ºå‘éƒ½èƒ½åœ¨æœ‰é™æ­¥å†…æ”¶æ•›ï¼Œå¹¶æœ€ç»ˆæ‰¾åˆ° reciprocal matchï¼Œå¯¹æ•´ä¸ªç®—æ³•çš„ç¨³å®šæ€§å’Œé«˜æ•ˆæ€§æä¾›äº†ç†è®ºæ”¯æ’‘ã€‚</p>
</div></blockquote>
<hr class="docutils" />
<p>âœ… <strong>å‘½é¢˜(Proposition) B.4</strong>ï¼šFRMä» <span class="math notranslate nohighlight">\(k\)</span> ä¸ªèµ·ç‚¹å‡ºå‘ï¼Œæœ€å¤šèƒ½æ‰¾åˆ° <span class="math notranslate nohighlight">\(k\)</span> ä¸ªåŒ¹é…ï¼ˆå®é™…å¯èƒ½æ›´å°‘ï¼‰</p>
<p>è¿™æ˜¯ç”±äºä¸åŒèµ·ç‚¹å¯èƒ½è½å…¥åŒä¸€ä¸ªå­å›¾å¹¶å…±äº«åŒä¸€ä¸ªåŒ¹é…è·¯å¾„ã€‚</p>
</section>
<section id="b-2-performance-improves-with-fast-matching">
<h3>B.2. Performance improves with fast matching<a class="headerlink" href="#b-2-performance-improves-with-fast-matching" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>ä¸»è¦è§£é‡Šäº† <strong>Fast Reciprocal Matching (FRM)</strong> ç›¸å¯¹äºä¼ ç»Ÿå…¨å›¾åŒ¹é…æ–¹æ³•çš„ä¼˜åŠ¿ï¼Œä¸åªæ˜¯è®¡ç®—é€Ÿåº¦å¿«ï¼Œè€Œä¸”è¿˜èƒ½åœ¨æ€§èƒ½ï¼ˆæ¯”å¦‚å§¿æ€ä¼°è®¡ã€æŠ•å½±è¯¯å·®ï¼‰ä¸Šè¡¨ç°å¾—æ›´å¥½ã€‚</p>
<p>ğŸ”¹1. FRM ä½¿æ€§èƒ½æ˜¾è‘—æå‡ï¼ˆæ¥è‡ªå›¾2å’Œå›¾9ï¼‰</p>
<ul class="simple">
<li><p>FRM å€¾å‘äºä¼˜å…ˆé‡‡åˆ°é‚£äº› <strong>æœ‰å¤§â€œæ±‡èšç›†åœ°â€ï¼ˆbasinï¼‰</strong> çš„ reciprocal match</p></li>
<li><p>ä¸¾ä¸ªç±»æ¯”ï¼šä½ ä»åœ°å›¾ä¸Šéšæœºæ’’ç‚¹ï¼Œç‚¹è¶Šå¤šè¶Šå¯èƒ½è½åœ¨â€œå¤§çš„æ°´æ± â€é‡Œï¼ŒFRM å°±ä¼šæ›´å¿«æ‰¾åˆ°è¿™äº›â€œæ± å­é‡Œçš„å¥½åŒ¹é…â€</p></li>
<li><p>å›¾9ï¼šä¸‹å›¾æ˜¯â€œå¤§ basinâ€ï¼Œå¤šä¸ªèµ·ç‚¹æœ€åèµ°å‘åŒä¸€ä¸ª reciprocal matchï¼›ä¸Šå›¾æ˜¯â€œå° basinâ€ï¼Œåªæœ‰å°‘æ•°èµ·ç‚¹æ‰å¯èƒ½æ‰¾åˆ°é‚£ä¸ª match</p></li>
</ul>
<hr class="docutils" />
<p>ğŸ”¹2. Basin è¶Šå¤§ï¼Œè¶Šå®¹æ˜“å‘½ä¸­ï¼›ä½†åŒ¹é…å¯†åº¦å´è¶Šä½</p>
<ul class="simple">
<li><p>â€œå¤§ basinâ€æ„å‘³ç€ä»æ›´å¤šçš„åƒç´ å‡ºå‘éƒ½èƒ½èµ°å‘é‚£ä¸ª match â†’ <strong>ç¨³å®šå¯é </strong></p></li>
<li><p>ä½†è¿™äº› basin å†…éƒ¨çš„ reciprocal match æ•°é‡å¯†åº¦è¾ƒä½ï¼ˆå› ä¸ºç‚¹å¤ªåˆ†æ•£ï¼‰</p></li>
</ul>
<p>æ‰€ä»¥ï¼š</p>
<ul class="simple">
<li><p><strong>å…¨å›¾æš´åŠ›åŒ¹é…</strong>ï¼šè™½ç„¶è¦†ç›–æ‰€æœ‰ matchï¼Œä½†å¯èƒ½å¾ˆå¤šéƒ½é›†ä¸­åœ¨å±€éƒ¨ï¼ˆå¯†é›†ä½†ä¸ç¨³å®šï¼‰</p></li>
<li><p><strong>FRM</strong>ï¼šåå‘å¤§ basinï¼Œç»“æœç©ºé—´åˆ†å¸ƒæ›´å‡åŒ€ã€ç»“æ„æ›´ç¨³å®šï¼ˆå³ä¾¿å°‘äº†ä¸€äº› matchï¼‰</p></li>
</ul>
<hr class="docutils" />
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/04/Sx5drg.png" /></p>
<p>Figure 10: Illustration of the difference in matching density when using dense reciprocal matching (baseline) and fast reciprocal matching with <span class="math notranslate nohighlight">\(k=3000\)</span> . Fast reciprocal matching samples correspondences with a bias for large convergence basins, resulting in a more uniform coverage of the images. Coverage can be measured in terms of the mean and standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span> of the point matches in each density map, plotted as colored ellipses (red, green and blue correspond respectively to <span class="math notranslate nohighlight">\(1\sigma,1.5\sigma\)</span> and <span class="math notranslate nohighlight">\(2\sigma\mathrm{\dot{\Omega}}\)</span> ).</p>
<hr class="docutils" />
<p>ğŸ”¹3. æ›´å‡åŒ€çš„ç©ºé—´åˆ†å¸ƒ â†’ æ›´å¥½çš„å‡ ä½•ä¼°è®¡</p>
<ul class="simple">
<li><p>è¿™å¥éå¸¸å…³é”®ï¼š</p></li>
<li><p>å¦‚æœåŒ¹é…ç‚¹éƒ½é›†ä¸­åœ¨æŸä¸€å°å—åŒºåŸŸï¼ˆå¦‚è§’è½ï¼‰ï¼ŒRANSAC ä¼°ç®—ç›¸æœºå§¿æ€å°±å®¹æ˜“ä¸å‡†ç¡®ç”šè‡³å¤±è´¥ï¼›</p></li>
<li><p>è€Œ FRM çš„ basin-biased æ•ˆæœï¼Œä¼šè®©åŒ¹é…ç‚¹<strong>åœ¨æ•´å¼ å›¾ä¸Šåˆ†å¸ƒå¾—æ›´å‡åŒ€</strong>ï¼›</p></li>
<li><p>â†’ æ›´å¥½çš„æœ¬è´¨çŸ©é˜µä¼°è®¡ / ä½å§¿ä¼°è®¡</p></li>
<li><p>å¦‚å›¾10æ‰€ç¤ºã€‚ç”±äºç©ºé—´è¦†ç›–æ›´å‡åŒ€ï¼ŒRANSAC èƒ½å¤Ÿæ¯”åœ¨å°å›¾åƒåŒºåŸŸå†…å¯†é›†å †ç§¯ç‚¹çš„æƒ…å†µä¸‹æ›´å¥½åœ°ä¼°è®¡æçº¿ï¼Œä»è€Œæä¾›æ›´å¥½ä¸”æ›´ç¨³å®šçš„å§¿æ€ä¼°è®¡ã€‚</p></li>
</ul>
<hr class="docutils" />
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/04/ZLKkp2.png" /></p>
<p>Figure 11: Illustration of convergence basins for one of the image in fig. 10. Each basin is filled with the same (random) color. A convergence basin is an area for which any of its point will converge to the same correspondence when applying the fast reciprocal matching algorithm.</p>
<p>ğŸ”¹4. å¯¹æ¯”å®éªŒï¼šä¸‰ç§ subsampling ç­–ç•¥</p>
<p>å®éªŒæ–¹å¼ï¼š
ä»<strong>å®Œæ•´çš„ reciprocal match é›†åˆ</strong> <span class="math notranslate nohighlight">\(\mathcal{M}\)</span> ä¸­å–æ ·</p>
<p>æ–¹å¼æœ‰ä¸‰ç§ï¼š</p>
<ol class="arabic simple">
<li><p><strong>éšæœº subsample</strong>ï¼Œå–å‡ºå’Œ FRM ä¸€æ ·å¤šçš„åŒ¹é…ç‚¹</p>
<ul class="simple">
<li><p>âŒ ç»“æœéå¸¸å·®ï¼Œå› ä¸ºæœ‰å¯èƒ½å…¨éƒ½é›†ä¸­åœ¨æŸå°åŒºåŸŸ</p></li>
</ul>
</li>
<li><p><strong>basin-biased subsample</strong></p>
<ul class="simple">
<li><p>åˆ©ç”¨æ¯ä¸ª reciprocal match çš„ basin å¤§å°ä½œæ¦‚ç‡åˆ†å¸ƒï¼Œä¼˜å…ˆé‡‡å¤§ basin</p></li>
<li><p>âœ… ç»“æœåè€Œæ¯”ç”¨å…¨éƒ¨åŒ¹é…ç‚¹è¿˜å¥½ï¼ˆå› ä¸ºå¯†åº¦å‡è¡¡ + å»å™ªï¼‰</p></li>
</ul>
</li>
<li><p><strong>FRM æœ¬èº«</strong></p>
<ul class="simple">
<li><p>å®é™…ç»“æœå‡ ä¹ä¸ basin-biased ç›¸åŒï¼Œä½†<strong>è®¡ç®—é‡è¿œè¿œæ›´ä½</strong>ï¼ˆå› ä¸ºä¸ç”¨é¢„å…ˆçŸ¥é“ basin å¤§å°ï¼‰</p></li>
</ul>
</li>
</ol>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/04/eZ8Skd.png" /></p>
<p>Figure 12: Comparison of the performance on the Map-free benchmark (validation set) for different subsampling approaches: â€˜naiveâ€™ denotes the random uniform subsampling of the original full set of reciprocal matches; â€˜fastâ€™ denotes the proposed fast reciprocal matching; and â€˜basinâ€™ denotes random subsampling weighted by the size of the convergence basin. The â€˜fastâ€™ and â€˜basinâ€™ strategies perform similarly whereas naive subsampling leads to catastrophic results.</p>
<hr class="docutils" />
<p>ğŸ”¹5. ç»“è®º</p>
<p>æ— è®ºä½ ç”¨å“ªç§ RANSACï¼ˆæ™®é€š/é²æ£’/æœ€å°åŒ–é‡æŠ•å½±è¯¯å·®ï¼‰ï¼Œåªè¦ä½ çš„åŒ¹é…ç‚¹æ¥è‡ª FRMï¼Œéƒ½ä¼šå¸¦æ¥æ›´å¥½çš„å‡ ä½•ä¼°è®¡ç»“æœã€‚</p>
<hr class="docutils" />
<p>âœ… æ€»ç»“ä¸€å¥è¯ï¼š</p>
<blockquote>
<div><p><strong>FRM ä¸æ˜¯ç®€å•åœ°åŠ é€ŸåŒ¹é…ï¼Œè€Œæ˜¯å€ŸåŠ© basin ç»“æ„åœ¨â€œé«˜æ•ˆ+å‡è¡¡åˆ†å¸ƒâ€çš„åŒæ—¶ï¼Œå¸¦æ¥äº†æ›´ç¨³å®šã€ç²¾åº¦æ›´é«˜çš„å‡ ä½•ä¼°è®¡æ•ˆæœ â€”â€” ç”šè‡³ä¼˜äºæš´åŠ›å…¨å›¾åŒ¹é…ã€‚</strong></p>
</div></blockquote>
</section>
</section>
<section id="c-coarse-to-fine">
<h2>C. Coarse-to-Fine<a class="headerlink" href="#c-coarse-to-fine" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p>ä¸»è¦è®²çš„æ˜¯ MASt3R ä¸­ <strong>â€œCoarse-to-Fineâ€ åŒ¹é…ç­–ç•¥</strong>çš„é‡è¦æ€§ï¼Œå°¤å…¶æ˜¯ç›¸å¯¹äºåªä½¿ç”¨ Coarse åŒ¹é…ï¼ˆcoarse-onlyï¼‰çš„æ–¹æ³•ï¼Œå®ƒåœ¨<strong>è§†è§‰å®šä½</strong>å’Œ**å¤šè§†è§’é‡å»ºï¼ˆMVSï¼‰**ä»»åŠ¡ä¸Šæ€§èƒ½æå‡éå¸¸æ˜æ˜¾ã€‚</p>
<p>ğŸ§­ ä¸€ã€Coarse vs. Coarse-to-Fine åŒºåˆ«</p>
<ul class="simple">
<li><p><strong>Coarse-only</strong>ï¼šç›´æ¥åœ¨ä½åˆ†è¾¨ç‡ä¸‹åšåŒ¹é…ï¼ˆå›¾åƒä¸‹é‡‡æ ·åå°±ç›´æ¥åšå¯¹åº”å…³ç³»ï¼‰</p></li>
<li><p><strong>Coarse-to-Fine</strong>ï¼š</p>
<ol class="arabic simple">
<li><p>å…ˆåœ¨ä½åˆ†è¾¨ç‡ä¸‹æ‰¾ç²—åŒ¹é…ï¼›</p></li>
<li><p>ç„¶ååœ¨é«˜åˆ†è¾¨ç‡åŸå›¾ä¸Šåšç²¾ç»†å¯¹é½ï¼ˆé€šå¸¸æ˜¯å±€éƒ¨ refinementï¼‰</p></li>
</ol>
</li>
</ul>
<p>ğŸ”‘ <strong>ä¼˜ç‚¹ï¼š</strong></p>
<ul class="simple">
<li><p><strong>æ•ˆç‡é«˜</strong>ï¼ˆcoarseé˜¶æ®µå¿«é€Ÿå…¨å±€å¯¹é½ï¼‰+ <strong>ç²¾åº¦é«˜</strong>ï¼ˆfineé˜¶æ®µæå‡å±€éƒ¨å‡ ä½•ç»†èŠ‚ï¼‰</p></li>
</ul>
<hr class="docutils" />
<p>ğŸŒ‡ äºŒã€è§†è§‰å®šä½ä»»åŠ¡ï¼šAachen Day-Night</p>
<ul class="simple">
<li><p>å›¾åƒåŸå§‹åˆ†è¾¨ç‡ï¼š1600Ã—1200 å’Œ 1024Ã—768ï¼Œåˆ†åˆ«ç¼©å°ä¸º 512Ã—384 æˆ– 384Ã—512</p></li>
<li><p>æµ‹è¯•äº†ä¸‰ä¸ªé˜ˆå€¼ä¸‹çš„å®šä½æˆåŠŸç‡ï¼š</p>
<ul>
<li><p>(0.25m, 2Â°)ï¼šé«˜ç²¾åº¦</p></li>
<li><p>(0.5m, 5Â°)ï¼šä¸­ç²¾åº¦</p></li>
<li><p>(5m, 10Â°)ï¼šä½ç²¾åº¦å®¹å¿åº¦</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<p>âœ… æ€»ç»“ä¸€å¥è¯ï¼š</p>
<blockquote>
<div><p><strong>Coarse-to-Fine ä¸åªæ˜¯æ€§èƒ½å¾®è°ƒï¼Œè€Œæ˜¯å†³å®šæ€§åœ°æå‡åŒ¹é…çš„å‡ ä½•ç²¾åº¦ã€è§†è§‰å®šä½æˆåŠŸç‡å’Œ MVS é‡å»ºè´¨é‡ã€‚</strong> å°¤å…¶æ˜¯åœ¨å¤œé—´ã€é®æŒ¡ã€ä½çº¹ç†ç­‰å›°éš¾æ¡ä»¶ä¸‹ï¼Œè¿™ç§ç­–ç•¥èƒ½æ˜¾è‘—æå‡ç»“æœã€‚</p>
</div></blockquote>
</section>
<hr class="docutils" />
<section id="d-detailed-experimental-settings">
<h2>D. Detailed experimental settings<a class="headerlink" href="#d-detailed-experimental-settings" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/04/neJPCn.png" /></p>
<p>Table 6: Detailed hyper-parameters for the training</p>
</section>
</section>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="2412.09401_SLAM3R.html" class="btn btn-neutral float-right" title="2412.09401_SLAM3R: Real-Time Dense Scene Reconstruction from Monocular RGB Videos" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="2312.14132_DUSt3R.html" class="btn btn-neutral" title="2312.14132_DUSt3R: Geometric 3D Vision Made Easy" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>
  
  <div id="gitalk-container"></div>
  <div role="contentinfo">
    <p>
        &copy; Copyright 2010-2025, æ–°æºª-gordon.

    </p>
  </div>
  <div>å¤‡æ¡ˆå· <a href="http://www.beian.miit.gov.cn">äº¬ICPå¤‡16018553å·</a></div><div>Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a></div>. 


</footer>

<script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?042289284b8eb33866001347a3e0b129";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
</script>     
        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'V2025.09',
            LANGUAGE:'zh-CN',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="../../_static/sphinx_highlight.js"></script>
      <script type="text/javascript" src="../../_static/clipboard.min.js"></script>
      <script type="text/javascript" src="../../_static/copybutton.js"></script>
      <script type="text/javascript" src="../../_static/translations.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script type="text/javascript" src="../../None"></script>
      <script type="text/javascript" src="https://fastly.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  

  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });


      // var gitalk = new Gitalk({
      //         clientID: '565177626b5d46427009',
      //         clientSecret: 'b2a36e67e1d2a73e43667f46d571c2624f8e1026',
      //         repo: 'knowledge',
      //         owner: 'zhaoweiguo',
      //         admin: ['zhaoweiguo'],
      //         id: location.pathname,      // Ensure uniqueness and length less than 50
      //         distractionFreeMode: false  // Facebook-like distraction free mode
      //       })
      // gitalk.render('gitalk-container')

  </script>


<script type="text/javascript" src="../../_static/js/table-of-contents-sidebar.js"></script>
<!-- <script type="text/javascript" src="https://table-of-contents-sidebar.github.io/table-of-contents-sidebar-lib/table-of-contents-sidebar.js"></script> -->
<script type="text/javascript">
    window.onload = function(e){
        TableOfContents.init({
            basePath: "https://table-of-contents-sidebar.github.io/table-of-contents-sidebar-lib/",
            querySelector: "body" // or other css querySelector
        });
    }
</script> 

</body>
</html>