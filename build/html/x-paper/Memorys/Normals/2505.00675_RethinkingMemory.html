

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="zh-CN" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="zh-CN" > <!--<![endif]-->
<head>


<!-- start added 2025-04-14   å¢åŠ å¯¹markdownä¸­å…¬å¼çš„æ”¯æŒ -->
<script>
window.MathJax = {
    tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true
    },
    options: {
        ignoreHtmlClass: "tex2jax_ignore|mathjax_ignore",
        processHtmlClass: "tex2jax_process|mathjax_process|math|output_area"
    }
};
</script>
<script defer="defer" src="https://fastly.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<!-- end added 2025-04-14   å¢åŠ å¯¹markdownä¸­å…¬å¼çš„æ”¯æŒ -->


<!-- start added 2025-08-06   å¢åŠ å¯¹mermaidå›¾çš„æ”¯æŒ -->
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', function() {
    mermaid.initialize({
        startOnLoad: true,
        theme: 'default',
        flowchart: { useMaxWidth: true }
    });
});
</script>
<!--  end added 2025-08-06   å¢åŠ å¯¹mermaidå›¾çš„æ”¯æŒ -->




  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>2505.00675_â‡ï¸Rethinking Memory in AI: Taxonomy, Operations, Topics, and Future Directions &mdash; æ–°æºª-gordon V2025.09 æ–‡æ¡£</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
    <link rel="index" title="ç´¢å¼•" href="../../genindex.html" />
    <link rel="search" title="æœç´¢" href="../../search.html" />
    <link rel="next" title="2505.22101_MemOS: An Operating System for Memory-Augmented Generation (MAG) in LLM (Short Version)" href="2505.22101_MemOS.html" />
    <link rel="prev" title="2504.19413_â‡ï¸Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory" href="2504.19413_Mem0.html" /> 

  
  <script src="../../_static/js/modernizr.min.js"></script>
  <script src="../../_static/js/jquery.min.js"></script>


<!-- è¯„è®ºæ’ä»¶ gittalk start -->
<!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script> -->
<!-- è¯„è®ºæ’ä»¶ gittalk end -->


</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> æ–°æºª-gordon
          

          
          </a>

          
            
            
              <div class="version">
                V2025.09
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../Overview.html">ç»¼è¿°è®ºæ–‡</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Overview.html#id3">è¿‘é‚»æœç´¢</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Overviews/2508.09834_Overview_LLM.html">2508.09834â‡ï¸_Overview_LLM: Speed Always Wins: A Survey on Efficient Architectures for Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Overviews/2508.09834_Overview_LLM.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Overviews/2508.09834_Overview_LLM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Overviews/2508.09834_Overview_LLM.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Overviews/2508.09834_Overview_LLM.html#linear-sequence-modeling">2 Linear Sequence Modeling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Overviews/2508.09834_Overview_LLM.html#sparse-sequence-modeling">3 Sparse Sequence Modeling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Overviews/2508.09834_Overview_LLM.html#efficient-full-attention">4 Efficient Full Attention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Overviews/2508.09834_Overview_LLM.html#sparse-mixture-of-experts">5 Sparse Mixture-of-Experts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Overviews/2508.09834_Overview_LLM.html#hybrid-architectures">6 Hybrid Architectures</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Overviews/2508.09834_Overview_LLM.html#diffusion-large-language-models">7 Diffusion Large Language Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Overviews/2508.09834_Overview_LLM.html#applications-to-other-modalities">8 Applications to Other Modalities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Overviews/2508.09834_Overview_LLM.html#conclusion-and-future-directions">9 Conclusion and Future Directions</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../Benchmarking.html">è¯„æµ‹åŸºå‡†</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#id3">è¯„æµ‹åŸºå‡†</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html">02xx.xxxxx_BLEU: a Method for Automatic Evaluation of Machine Translation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html#id8">ç¤ºä¾‹è®²è§£</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html#the-baseline-bleu-metric">2.The Baseline BLEU Metric</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html#the-bleu-evaluation">3.The BLEU Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html#the-human-evaluation">4.The Human Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html#bleu-vs-the-human-evaluation">5.BLEU vs The Human Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/02xx.xxxxx_BLEU.html#conclusion">6.Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html">0401.xxxxx_ROUGE: A Package for Automatic Evaluation of Summaries</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html#rouge-n-n-gram-co-occurrence-statistics">2.ROUGE-N: N-gram Co-Occurrence Statistics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html#rouge-l-longest-common-subsequence">3.ROUGE-L: Longest Common Subsequence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html#rouge-w-weighted-longest-common-subsequence">4 ROUGE-W: Weighted Longest Common Subsequence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html#rouge-s-skip-bigram-co-occurrence-statistics">5.ROUGE-S: Skip-Bigram Co-Occurrence Statistics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html#evaluations-of-rouge">6 Evaluations of ROUGE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0401.xxxxx_ROUGE.html#conclusions">7 Conclusions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html">é€šç”¨</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html#id2">è¯„æµ‹æ ‡å‡†</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html#accuracy">å‡†ç¡®ç‡(Accuracy)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html#precision">ç²¾ç¡®ç‡(Precision, ç²¾å‡†ç‡)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html#recall">å¬å›ç‡(Recall)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html#f1-score">F1 Score</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html#id3">å¯è§†åŒ–ç²¾åº¦å’Œå¬å›ç‡</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html#recall-k">Recall&#64;k</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html#precision-k">Precision&#64;k</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html#hr-k">HR&#64;k</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html#ndcg-k">NDCG&#64;k</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html#mrr-k">MRR&#64;k</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html#map-k">MAP&#64;k</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html#auc-area-under-the-roc-curve">AUC (Area Under the ROC Curve)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/0normal.html#logloss-logarithmic-loss">LogLoss(Logarithmic Loss)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Standards/1803.01937_ROUGE2.html">1803.01937_ROUGE2.0: Updated and Improved Measures for Evaluation of Summarization Tasks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1803.01937_ROUGE2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1803.01937_ROUGE2.html#problems-with-the-current-rouge-measures">1. Problems with the current ROUGE measures</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1803.01937_ROUGE2.html#rouge-2-0">2. ROUGE 2.0</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Standards/1804.08771_SacreBLEU.html">1804.08771_SacreBLEU: A Call for Clarity in Reporting BLEU Scores</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1804.08771_SacreBLEU.html#bleu">BLEU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1804.08771_SacreBLEU.html#id3">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1804.08771_SacreBLEU.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1804.08771_SacreBLEU.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1804.08771_SacreBLEU.html#problem-description">2 Problem Description</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1804.08771_SacreBLEU.html#a-way-forward">3 A way forward</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/1804.08771_SacreBLEU.html#summary">4 Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html">2303.08896_SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#background-and-related-work">2 Background and Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#grey-box-factuality-assessment">3 Grey-Box Factuality Assessment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#black-box-factuality-assessment">4 Black-Box Factuality Assessment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#selfcheckgpt">5 SelfCheckGPT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#data-and-annotation">6 Data and Annotation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#experiments">7 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#conclusions">8 Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#limitations">Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#ethics-statement">Ethics Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#acknowledgments">Acknowledgments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#appendix-a-models-and-implementation">Appendix A Models and Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#appendix-b-selfcheckgpt-with-qa">Appendix B SelfCheckGPT with QA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#appendix-c-selfcheckgpt-with-prompt">Appendix C SelfCheckGPT with Prompt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2303.08896_SelfCheckGPT.html#appendix-d-additional-experimental-results">Appendix D Additional Experimental Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html">2306.05685_Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#mt-bench-and-chatbot-arena">2 MT-Bench and Chatbot Arena</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#llm-as-a-judge">3 LLM as a Judge</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#agreement-evaluation">4 Agreement Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#human-preference-benchmark-and-standardized-benchmark">5 Human Preference Benchmark and Standardized Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#discussion">6 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#appendix-a-prompt-templates">Appendix A Prompt templates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#appendix-b-case-study">Appendix B Case Study</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#appendix-c-data-collection">Appendix C Data Collection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#appendix-d-additional-experimental-results">Appendix D Additional Experimental Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#appendix-e-training-details-of-vicuna-models">Appendix E Training Details of Vicuna Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2306.05685_LLM-as-a-Judge_MT-Bench.html#appendix-f-exploring-vicuna-as-a-judge">Appendix F Exploring Vicuna as a judge</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html">2403.04132_Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#id12">2 ç›¸å…³å·¥ä½œï¼ˆRelated Workï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#human-preference-data-collection">3 Human Preference Data Collection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#id13">3 äººç±»åå¥½æ•°æ®æ”¶é›†</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#from-pairwise-comparisons-to-rankings">4 From Pairwise Comparisons to Rankings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#efficient-approximate-ranking">5 Efficient Approximate Ranking</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#data-analysis">6 Data Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#experiments">7 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#id25">7 å®éªŒ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#discussion">8 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#id32">8 è®¨è®º</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#conclusion">9 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#id33">9 ç»“è®º</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#acknowledgments">Acknowledgments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#id34">è‡´è°¢</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#appendix-a-confidence-interval-simulation-study">Appendix A Confidence Interval Simulation Study</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#a">é™„å½• A ç½®ä¿¡åŒºé—´æ¨¡æ‹Ÿç ”ç©¶</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#appendix-b-the-nonparametric-bradley-terry-model">Appendix B The Nonparametric Bradley-Terry Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#b-bradley-terry">é™„å½• Bï¼šéå‚æ•° Bradley-Terry æ¨¡å‹</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#appendix-c-valid-p-value">Appendix C Valid P-Value</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#p">1. på€¼çš„å®šä¹‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#id42">2. på€¼çš„ç­‰ä»·è¡¨è¾¾å¼</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#id43">3. æœ‰æ•ˆæ€§è¯æ˜çš„å…³é”®æ­¥éª¤</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#id46">4. è¯æ˜ç»“è®º</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#id47">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2403.04132_ChatbotArena.html#appendix-d-sample-prompts">Appendix D Sample Prompts</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Standards/2404.04475_AlpacaEval2.0.html">2404.04475_AlpacaEval LC: A Simple Way to Debias Automatic Evaluators</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2404.04475_AlpacaEval2.0.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2404.04475_AlpacaEval2.0.html#from-deepseek">From Deepseek</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2404.04475_AlpacaEval2.0.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2404.04475_AlpacaEval2.0.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2404.04475_AlpacaEval2.0.html#background-and-problem-setting">2 Background and Problem Setting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2404.04475_AlpacaEval2.0.html#length-controlled-alpacaeval">3 Length-Controlled AlpacaEval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2404.04475_AlpacaEval2.0.html#results">4 Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Standards/2404.04475_AlpacaEval2.0.html#discussion">5 Discussion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#agent">æ•°æ®é›†-Agent</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2308.03688_AgentBench.html">2308.03688_AgentBench: Evaluating LLMs as Agents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2308.03688_AgentBench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2308.03688_AgentBench.html#from-deepseek">From Deepseek</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2308.03688_AgentBench.html#id7">æ•°æ®é›†ç¤ºä¾‹</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html">2312.14033_T-Eval: Evaluating the Tool Utilization Capability of Large Language Models Step by Step</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#t-eval">2 T-Eval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#experiments">3 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#discussion">4 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#related-work">5 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#appendix-a-t-eval-benchmark-details">Appendix A T-EvalÂ Benchmark Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#appendix-b-implementation-details">Appendix B Implementation Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#appendix-c-detailed-evaluation-metrics">Appendix C Detailed Evaluation Metrics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2312.14033_T-Eval.html#appendix-d-api-documentation">Appendix D API Documentation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2406.12045_%CF%84-bench.html">2406.12045_Ï„-bench: A Benchmark for Tool-Agent-User</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2406.12045_%CF%84-bench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2406.12045_%CF%84-bench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2406.12045_%CF%84-bench.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2406.12045_%CF%84-bench.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2406.12045_%CF%84-bench.html#bench-a-benchmark-for-t-ool-a-gent-u-ser-interaction">3.Ï„-bench: A benchmark for T ool-A gent-U ser Interaction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2406.12045_%CF%84-bench.html#benchmark-construction">4. Benchmark Construction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2406.12045_%CF%84-bench.html#experiments">5.Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2406.12045_%CF%84-bench.html#disscussion">6.Disscussion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html">2506.07982_ğœÂ²-Bench: Evaluating Conversational Agents in a Dual-Control Environment</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#tau-2-bench-evaluating-agents-in-a-dual-control-environment">3 <span class="math notranslate nohighlight">\(\tau^{2}\)</span>-bench: Evaluating Agents in a Dual-Control Environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#broader-impact">Broader Impact</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#appendix-a-telecom-domain">Appendix A Telecom Domain</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#appendix-b-verifying-original-tau-2-bench">Appendix B Verifying Original <span class="math notranslate nohighlight">\(\tau^{2}\)</span>-bench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#appendix-c-prompts">Appendix C Prompts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#appendix-d-domain-policies">Appendix D Domain Policies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Agents/2506.07982_%F0%9D%9C%8F%C2%B2-Bench.html#appendix-e-user-simulator-quality">Appendix E User Simulator Quality</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#qa">æ•°æ®é›†-QA</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html">2109.07958_TruthfulQA: Measuring How Models Mimic Human Falsehoods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#the-truthfulqa-benchmark">2 The TruthfulQA Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#experiments">3 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#results">4 Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#discussion">5 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#related-work">6 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#ethics-and-impact">8 Ethics and Impact</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#appendix-a-additional-examples-from-truthfulqa">Appendix A Additional examples from TruthfulQA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#appendix-b-additional-results">Appendix B Additional results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#appendix-c-dataset-construction">Appendix C Dataset construction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#appendix-d-human-evaluations">Appendix D Human evaluations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#appendix-e-prompts">Appendix E Prompts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2109.07958_TruthfulQA.html#appendix-f-checking-for-data-quality-and-disagreement">Appendix F Checking for data quality and disagreement</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html">2311.12022_GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html#data-collection">2.Data Collection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html#dataset-analysis">3.Dataset Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html#baseline">4.Baseline</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html#related-work">5.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html#limitations">6.Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2311.12022_GPQA.html#conclusion">7.Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2411.04368_SimpleQA.html">2411.04368_SimpleQA: Measuring short-form factuality in large language models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2411.04368_SimpleQA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2411.04368_SimpleQA.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2411.04368_SimpleQA.html#data-collection-and-verification">2.Data Collection and Verification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2411.04368_SimpleQA.html#measuring-calibration">4.Measuring calibration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_QAs/2411.04368_SimpleQA.html#appendix-b-guessing-strategy-and-f-score">Appendix B Guessing strategy and F-score</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#id4">æ•°æ®é›†-é•¿æ–‡æœ¬</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2308.14508_LongBench.html">2308.14508_LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2308.14508_LongBench.html#from-deepseek">From Deepseek</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html">2402.05136_LV-Eval: A Balanced Long-Context Benchmark with 5 Length Levels Up to 256K</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html#lv-eval-benchmark">3 LV-Eval Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html#evaluation">4 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html#appendix-c-detailed-evaluation-results">Appendix C Detailed Evaluation Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.html#appendix-d-detailed-ablation-results">Appendix D Detailed Ablation Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html">2404.06654_RULER: Whatâ€™s the Real Context Size of Your Long-Context Language Models?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#the-ruler-benchmark">3 The RulerÂ Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#experiments-results">4 Experiments &amp; Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#task-error-analysis">5 Task Error Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#model-analysis">6 Model Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#limitations">8 Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#appendix-a-models">Appendix A Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#appendix-b-task-configurations">Appendix B Task Configurations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#appendix-c-task-correlation-analysis">Appendix C Task Correlation Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#appendix-d-prompt-templates">Appendix D Prompt Templates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#appendix-e-passkey-retrieval-and-vanilla-niah-results">Appendix E Passkey Retrieval and Vanilla NIAH Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2404.06654_RULER.html#appendix-f-additional-results">Appendix F Additional Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html">2407.11963_NeedleBench: Can LLMs Do Retrieval and Reasoning in Information-Dense Context</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#tasks-and-datasets">3 Tasks and Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#impact-of-language-which-model-performs-better-under-the-bilingual-scenario">4.1.5 Impact of Language_ Which Model Performs Better under the Bilingual Scenario_</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#conclusion-and-future-work">5 Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#appendix-a-evaluated-models">Appendix A Evaluated Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#appendix-b-needlebench-prompt-examples">Appendix B NeedleBenchÂ Prompt Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.html#appendix-c-error-analysis-examples">Appendix C Error Analysis Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#rag">æ•°æ®é›†-RAG</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/1809.09600_HotpotQA.html">1809.09600_HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/1809.09600_HotpotQA.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/1809.09600_HotpotQA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/1809.09600_HotpotQA.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/1809.09600_HotpotQA.html#data-collection">2 Data Collection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/1809.09600_HotpotQA.html#processing-and-benchmark-settings">3 Processing and Benchmark Settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/1809.09600_HotpotQA.html#dataset-analysis">4 Dataset Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/1809.09600_HotpotQA.html#experiments">5 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/1809.09600_HotpotQA.html#related-work">6 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/1809.09600_HotpotQA.html#conclusions">7 Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/1809.09600_HotpotQA.html#appendix-a-data-collection-details">Appendix A Data Collection Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/1809.09600_HotpotQA.html#a">é™„å½•A æ•°æ®æ”¶é›†ç»†èŠ‚</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/1809.09600_HotpotQA.html#appendix-b-further-data-analysis">Appendix B Further Data Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/1809.09600_HotpotQA.html#appendix-c-full-wiki-setting-details">Appendix C Full Wiki Setting Details</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/2401.15391_MultiHop-RAG.html">2401.15391_MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/2401.15391_MultiHop-RAG.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/2401.15391_MultiHop-RAG.html#llm">LLMæ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/2401.15391_MultiHop-RAG.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/2401.15391_MultiHop-RAG.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/2401.15391_MultiHop-RAG.html#rag-with-multi-hop-queries">2 RAG with multi-Hop queries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/2401.15391_MultiHop-RAG.html#a-benchmarking-dataset-multihop-rag">3 A Benchmarking Dataset: MultiHop-RAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/2401.15391_MultiHop-RAG.html#benchmarking-rag-system-using-multihop-rag">4 Benchmarking RAG system using MultiHop-RAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/2401.15391_MultiHop-RAG.html#related-work">5 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/2401.15391_MultiHop-RAG.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/2401.15391_MultiHop-RAG.html#limitations">Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/2401.15391_MultiHop-RAG.html#appendix-a-appendix-a-gpt-4-prompts-used-for-data-generation">Appendix A Appendix A: GPT-4 Prompts Used for Data Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_RAGs/2401.15391_MultiHop-RAG.html#appendix-b-dataset-examples">Appendix B: Dataset Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#id5">æ•°æ®é›†-å›¾</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html">2402.07630_G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#id2">ç¤ºä¾‹è®²è§£</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#formalization">3 Formalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#proposed-graphqa-benchmark">4 Proposed GraphQA Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#id12">5 G-Retriever</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#experiments">6 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#acknowledgment">Acknowledgment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#appendix-a-impact-statements">Appendix A Impact Statements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#appendix-b-experiment">Appendix B Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#appendix-c-graphqa-benchmark">Appendix C GraphQA Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#appendix-d-graph-retrieval-augmented-generation-graphrag">Appendix D Graph Retrieval-Augmented Generation (GraphRAG)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#appendix-e-discussion-on-the-complexity">Appendix E Discussion on the Complexity</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#e"><strong>é™„å½•E å¤æ‚æ€§è®¨è®ºæ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#appendix-f-hallucination-in-graph-llms">Appendix F Hallucination in Graph LLMs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Graphs/2402.07630_G-Retriever.html#appendix-g-demonstrations">Appendix G Demonstrations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#id6">æ•°æ®é›†-ç¼–ç¨‹</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html">2107.03374_HumanEval: Evaluating Large Language Models Trained on Code</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#evaluation-framework">2.Evaluation Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#code-fine-tuning">3.Code Fine-Tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#supervised-fine-tuning">4.Supervised Fine-Tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#docstring-generation">5.Docstring Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#limitations">6.Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#broader-impacts-and-hazard-analysis">7.Broader Impacts and Hazard Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#related-work">8.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2107.03374_HumanEval.html#conclusions">9.Conclusions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html">2108.07732_MBPP: Program Synthesis with Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#datasets">2 Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#model-and-methods">3 Model and Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#mbpp-synthesis-results">4 MBPP Synthesis Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#human-model-collaboration-results">5 Human-Model Collaboration Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#program-execution-results">6 Program Execution Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#mathqa-results">7 MathQA Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#related-work">8 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#risks-and-limitations">9 Risks and Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#conclusion">10 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2108.07732_MBPP.html#appendix-a-appendix">Appendix A Appendix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html">2310.06770_SWE-bench: Can Language Models Resolve Real-World GitHub Issues?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#id7">2 SWE-bench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#swe-llama-fine-tuning-codellama-for-swe-bench">3 SWE-Llama: Fine-tuning CodeLlama for SWE-bench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#experimental-setup">4 Experimental Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#results">5 Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#related-work">6 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#discussion">7 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#ethics-statement">8 Ethics Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#reproducibility-statement">9 Reproducibility Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#appendix-a-benchmark-details">Appendix A Benchmark Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#appendix-b-additional-details-on-training-swe-llama">Appendix B Additional Details on Training SWE-Llama</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#appendix-c-additional-results">Appendix C Additional Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#appendix-d-additional-experimental-details">Appendix D Additional Experimental Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#appendix-e-societal-impact">Appendix E Societal Impact</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2310.06770_SWE-bench.html#appendix-f-in-depth-analysis-of-swe-llama-generations">Appendix F In-depth Analysis of SWE-Llama Generations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html">2402.16694_HumanEval-XL: A Multilingual Code Generation Benchmark for Cross-lingual Natural Language Generalization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#a-multilingual-code-generation-benchmark-for-cross-lingual-natural-language-generalization">A Multilingual Code Generation Benchmark for Cross-lingual Natural Language Generalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#introduction">1.Â Â Â Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#related-work">2.Â Â Â Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#humaneval-xl">3.Â Â Â HumanEval-XL</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#experiments">4.Â Â Â Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#conclusion">5.Â Â Â Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#acknowledgments">Acknowledgments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#appendix-a-experiment-settings">Appendix A Experiment Settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.html#appendix-b-comprehensive-experiment-results">Appendix B Comprehensive Experiment Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html">2403.07974_LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#llm">LLMæ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#holistic-evaluation">2 Holistic Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#benchmark-curation">3 Benchmark Curation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#experiment-setup">4 Experiment Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#results">5 Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#related-work">6 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#limitations">7 Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#conclusion">8 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#appendix-a-dataset">Appendix A Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#appendix-b-ui">Appendix B UI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#appendix-c-experimental-setup">Appendix C Experimental Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#appendix-d-results">Appendix D Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.html#appendix-e-qualitative-examples">Appendix E Qualitative Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html">2407.10499_CIBench: Evaluating Your LLMs with a Code Interpreter Plugin</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#related-works">2 Related Works</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#cibench">3 CIBench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#appendix-a-dataset-details">Appendix A Dataset Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#appendix-b-construction-prompts-and-rules">Appendix B Construction Prompts and Rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#appendix-c-experiment-example-demo">Appendix C Experiment Example Demo</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#appendix-d-subjective-visualization-evaluation">Appendix D Subjective Visualization Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#appendix-e-dataset-error-analysis">Appendix E Dataset Error Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#appendix-f-human-annotator">Appendix F Human Annotator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2407.10499_CIBench.html#appendix-g-ethical-consideration">Appendix G Ethical Consideration</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html">2410.03859_SWE-bench-Multimodal: Do AI Systems Generalize to Visual Software Domains?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#swe-bench-multimodal">2 SWE-bench Multimodal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#evaluating-on-swe-bench-m">3 Evaluating on SWE-bench M</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#results">4 Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#related-work">5 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#appendix-a-dataset">Appendix A Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#appendix-b-collection">Appendix B Collection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#appendix-c-experiments">Appendix C Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#appendix-d-human-validation">Appendix D Human Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.html#appendix-e-limitations">Appendix E Limitations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html">2410.06992_SWE-Bench+: Enhanced Coding Benchmark for LLMs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html#robustness-analysis-of-swe-bench">2 Robustness Analysis of SWE-Bench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html#building-swe-bench">3 Building SWE-Bench+</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html#robustness-of-swe-bench">4 Robustness of SWE-Bench+</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html#effectiveness-aware-evaluation">5 Effectiveness-aware Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html#related-work">6 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2410.06992_SWE-Bench%2B.html#conclusion">7 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html">2501.01257_CodeForces: Benchmarking Competition-level Code Generation of LLMs on CodeForces</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#codeforces-benchmark">3 CodeForces Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#evaluation-on-existing-llms">4 Evaluation on Existing LLMs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#analysis-experiments">5 Analysis Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#discussion">6 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#ethical-statement">8 Ethical Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#appendix-a-model-cards">Appendix A Model Cards</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#appendix-b-decoding-hyperparameters">Appendix B Decoding Hyperparameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#appendix-c-analysis-of-our-elo-rating-calculation-system">Appendix C Analysis of Our Elo Rating Calculation System</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#appendix-d-human-comparable-elo-rating">Appendix D Human-comparable Elo Rating</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#appendix-e-problem-demonstration">Appendix E Problem Demonstration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Codes/2501.01257_CodeForces.html#appendix-f-special-judge">Appendix F Special Judge</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#id7">æ•°æ®é›†-æ•°å­¦</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2103.03874_MATH.html">2103.03874_MATH: Measuring Mathematical Problem Solving With the MATH Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html">2110.14168_GSM8K: Training Verifiers to Solve Math Word Problems</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#dataset">2 Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#related-work">3 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#methods">4 Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#additional-experiments">5 Additional Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#appendix-a-dataset-details">Appendix A Dataset Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#appendix-b-hyperparameters">Appendix B Hyperparameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#appendix-c-calculator-annotations">Appendix C Calculator Annotations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#appendix-d-example-model-solutions">Appendix D Example Model Solutions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#appendix-e-verifier-details">Appendix E Verifier Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2110.14168_GSM8K.html#appendix-f-verifier-visualization">Appendix F Verifier Visualization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html">2405.12209_MathBench: Evaluating the Theory and Application Proficiency of LLMs with a Hierarchical Mathematics Benchmark</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#methodology">2 Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#experiments-and-analysis">3 Experiments and Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#discussion">4 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#related-work">5 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#limitations">7 Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#ethical-considerations">8 Ethical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#appendix-a-mathbench-statistics">Appendix A MathBench Statistics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#appendix-b-detailed-experimental-results">Appendix B Detailed Experimental Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Maths/2405.12209_MathBench.html#appendix-c-extra-analysis">Appendix C Extra Analysis</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#id8">æ•°æ®é›†-å›¾ç‰‡</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Images/2306.13394_MME.html">2306.13394_MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2306.13394_MME.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2306.13394_MME.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2306.13394_MME.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2306.13394_MME.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2306.13394_MME.html#mme-evaluation-suite">2 MME Evaluation Suite</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2306.13394_MME.html#experiments">3 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2306.13394_MME.html#analysis">4 Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2306.13394_MME.html#conclusion">5 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html">2307.06281_MMBench: Is Your Multi-modal Model an All-around Player?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#the-construction-of-mmbench">3 The construction of MMBench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#evaluation-strategy">4 Evaluation Strategy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#evaluation-results">5 Evaluation Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#appendix-a-more-details-about-the-data">Appendix A More Details about the Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#appendix-b-more-details-on-mmbench-construction">Appendix B More Details on MMBench Construction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#appendix-c-more-details-on-llm-based-choice-extraction">Appendix C More Details on LLM-based Choice Extraction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.06281_MMBench.html#appendix-d-evaluation-settings-and-results">Appendix D Evaluation Settings and Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.16125_SEED-Bench.html">2307.16125_SEED-Bench: Benchmarking Multimodal LLMs with Generative Comprehension</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.16125_SEED-Bench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.16125_SEED-Bench.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.16125_SEED-Bench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.16125_SEED-Bench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.16125_SEED-Bench.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.16125_SEED-Bench.html#id7">3 SEED-Bench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.16125_SEED-Bench.html#evaluation-results">4 Evaluation Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2307.16125_SEED-Bench.html#conclusion">5 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html">2311.12793_ShareGPT4V: Improving Large Multi-Modal Models with Better Captions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#sharegpt4v-dataset">3 ShareGPT4V Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#sharegpt4v-7b-model">4 ShareGPT4V-7B Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#id11"><strong>4.1 æ¨¡å‹æ¶æ„</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#id12"><strong>4.2 é¢„è®­ç»ƒ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#sft"><strong>4.3 ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#id13"><strong>æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#experiments">5 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#appendix-a-data-sources">Appendix A Data Sources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#appendix-b-caption-analysis">Appendix B Caption Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#appendix-c-prompts">Appendix C Prompts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2311.12793_ShareGPT4V.html#appendix-d-examples">Appendix D Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html">2506.18095_ShareGPT-4o-Image: Aligning Multimodal Models with GPT-4o-Level Image Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#sharegpt-4o-image">2 ShareGPT-4o-Image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#janus-4o-fine-tuning-with-sharegpt-4o-image">3 Janus-4o: Fine-Tuning with ShareGPT-4o-Image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#conclusion">5 conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#appendix-a-related-work">Appendix A Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#appendix-b-image-generation-categories">Appendix B Image Generation Categories</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#appendix-c-prompts-for-generation">Appendix C Prompts for Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#appendix-d-document-pipeline">Appendix D Document Pipeline</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.html#appendix-e-ethical-considerations-and-societal-impact">Appendix E Ethical Considerations and Societal Impact</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Benchmarking.html#id9">æ•°æ®é›†</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html">1804.07461_GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#id7">2 ç›¸å…³å·¥ä½œæ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#tasks">3 Tasks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#single-sentence-tasks">3.1 Single-Sentence Tasks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#similarity-and-paraphrase-tasks">3.2 Similarity and Paraphrase Tasks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#inference-tasks">3.3 Inference Tasks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#evaluation">3.4 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#diagnostic-dataset">4 Diagnostic Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#id9">4 è¯Šæ–­æ•°æ®é›†ï¼ˆDiagnostic Datasetï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#baselines">5 Baselines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#id14">5 Baselines æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#benchmark-results">6 Benchmark Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#id16">6 Benchmark Resultsï¼ˆåŸºå‡†æµ‹è¯•ç»“æœï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#analysis">7 Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#conclusion">8 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#id22">8 ç»“è®º</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#acknowledgments">Acknowledgments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#id23">è‡´è°¢</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#appendix-a-additional-benchmark-details">Appendix A Additional Benchmark Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#appendix-a-additional-benchmark-details-a">Appendix A Additional Benchmark Detailsï¼ˆé™„å½•Aï¼šæ›´å¤šåŸºå‡†ç»†èŠ‚ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#appendix-b-additional-baseline-details">Appendix B Additional Baseline Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#appendix-b-additional-baseline-details-b">Appendix B Additional Baseline Detailsï¼ˆé™„å½•B å…¶ä»–åŸºçº¿ç»†èŠ‚ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#appendix-c-development-set-results">Appendix C Development Set Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#id25">Appendix C Development Set Results æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#appendix-d-benchmark-website-details">Appendix D Benchmark Website Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#appendix-d-benchmark-website-details-d">Appendix D Benchmark Website Detailsï¼ˆé™„å½• D åŸºå‡†ç½‘ç«™è¯¦æƒ…ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#appendix-e-additional-diagnostic-data-details">Appendix E Additional Diagnostic Data Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#e"><strong>é™„å½• Eï¼šé¢å¤–çš„è¯Šæ–­æ•°æ®ç»†èŠ‚</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/1804.07461_GLUE.html#id31"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Datasets/2009.03300_MMLU.html">2009.03300_MMLU: Measuring Massive Multitask Language Understanding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2009.03300_MMLU.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2009.03300_MMLU.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2009.03300_MMLU.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2009.03300_MMLU.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2009.03300_MMLU.html#a-multitask-test">3.A Multitask Test</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2009.03300_MMLU.html#experiments">4.Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2009.03300_MMLU.html#discussion">5.Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2009.03300_MMLU.html#conclusion">6.Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html">2305.08322_C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#id2">C-Eval_ A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#the-c-eval-evaluation-suite">2 The C-EvalÂ Evaluation Suite</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#experiment">3 Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#related-work">4 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#discussion">5 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#acknowledgement">Acknowledgement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#appendix-a-author-contributions">Appendix A Author Contributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#appendix-b-detailed-stats-of-c-eval">Appendix B Detailed Stats of C-Eval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#appendix-c-explanation-data-generation">Appendix C Explanation Data Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#appendix-d-evaluation-prompts">Appendix D Evaluation Prompts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#appendix-e-details-of-the-models-being-evaluated">Appendix E Details of the models being evaluated</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#appendix-f-breakdown-of-model-performance">Appendix F Breakdown of Model Performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#appendix-g-option-bias">Appendix G Option Bias</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2305.08322_C-Eval.html#appendix-h-compute-and-resources-used-for-evaluation">Appendix H Compute and Resources Used for Evaluation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html">2306.09212_CMMLU: Measuring massive multitask language understanding in Chinese</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#cmmlu">3 CMMLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#impact-of-model-size-on-performance">Impact of model size on performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-a-comparison-to-concurrent-benchmarks">Appendix A Comparison to concurrent benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-b-cmmlu-subjects">Appendix B CMMLU Subjects</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-c-cmmlu-examples">Appendix C CMMLU Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-d-cmmlu-difficulty-distribution">Appendix D CMMLU Difficulty Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-e-emergent-ability-shown-in-cmmlu-subjects">Appendix E Emergent Ability shown in CMMLU subjects</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-f-models-being-evaluated">Appendix F Models being Evaluated</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-g-strategies-for-estimating-model-choices">Appendix G Strategies for Estimating Model Choices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-h-regular-expressions-matching-algorithmsl">Appendix H Regular expressions matching algorithmsl</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-i-correlation-to-other-benchmarks">Appendix I Correlation to other Benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#appendix-j-breakdown-of-model-performance">Appendix J Breakdown of Model Performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2306.09212_CMMLU.html#j-3-the-effect-of-chain-of-thought-prompt">J.3 The effect of chain-of-thought prompt</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html">2307.15020_SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#superclue-benchmark">3 SuperCLUE Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#additional-analysis">5 Additional Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#appendix-a-evaluation-process">Appendix A Evaluation Process</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2307.15020_SuperCLUE.html#appendix-b-capability-categories">Appendix B Capability Categories</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html">2311.12983_GAIA: a benchmark for General AI Assistants</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#related-work">2.Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#id4">3.GAIA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#llms-results-on-gaia">4.LLMs results on GAIA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#discussion">5.Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#limitations">6.Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#appendix-a-extended-related-work">Appendix A Extended related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#appendix-c-extended-description-of-gaia">Appendix C Extended description of GAIA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.12983_GAIA.html#appendix-d-extended-description-of-our-question-design-framework">Appendix D Extended description of our question design framework</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.18743_AlignBench.html">2311.18743_AlignBench: Benchmarking Chinese Alignment of Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.18743_AlignBench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.18743_AlignBench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.18743_AlignBench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.18743_AlignBench.html#dataset">2 Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.18743_AlignBench.html#methods">3 Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.18743_AlignBench.html#human-evaluation-on-alignbench">4 Human Evaluation on AlignBench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.18743_AlignBench.html#alignbench-benchmarking-results">5 AlignBench: Benchmarking Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.18743_AlignBench.html#related-work">6 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.18743_AlignBench.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2311.18743_AlignBench.html#appendix-a-appendix">Appendix A Appendix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html">2404.07972_OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#id2">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#osworld-environment">2. OSWORLD Environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#osworld-benchmark">3. OSWORLD Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#benchmarking-llm-and-vlm-agent-baselines">4. Benchmarking LLM and VLM Agent Baselines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#analysis">5. Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#related-work">6. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#conclusion-and-future-work">7. Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#a-details-of-osworld-environment">A. Details of OSWORLD Environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#c-details-of-baseline-methods">C. Details of Baseline Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2404.07972_OSWorld.html#d-examples-of-qualitative-analysis">D. Examples of Qualitative Analysis</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html">2406.04770_WildBench: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html#wildbench-data-curation">2 WildBench Data Curation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html#automatic-evaluation-with-wildbench">3 Automatic Evaluation with WildBench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html#results-analysis">4 Results &amp; Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html#related-works">5 Related Works</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html#conclusion-and-future-directions">6 Conclusion and Future Directions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html#appendix-a-task-categories">Appendix A Task Categories</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html#appendix-b-more-information-on-wildbench-data">Appendix B More Information on WildBench Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html#appendix-c-more-information-on-wildbench-evaluation">Appendix C More Information on WildBench Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html#appendix-d-prompt-template-for-pairwise-evaluation-metric-wb-reward">Appendix D Prompt Template for Pairwise Evaluation Metric WB-Reward</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html#appendix-e-prompt-template-for-individual-evaluation-metric-wb-score">Appendix E Prompt Template for Individual Evaluation Metric WB-Score</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2406.04770_WildBench.html#appendix-f-full-wildbench-leaderboard">Appendix F Full WildBench Leaderboard</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Benchmarkings/Datasets/2501.14249_HLE.html">2501.14249_HLE: Humanityâ€™s Last Exam</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2501.14249_HLE.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2501.14249_HLE.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2501.14249_HLE.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2501.14249_HLE.html#dataset">3.Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2501.14249_HLE.html#evaluation">4.Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Benchmarkings/Datasets/2501.14249_HLE.html#discussion">5.Discussion</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../../Memory.html">è®°å¿†</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../../Memory.html#id3">é€šç”¨</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="0normal.html">é€šç”¨</a><ul>
<li class="toctree-l4"><a class="reference internal" href="0normal.html#id2">æ€»ç»“ä¸å±•æœ›</a></li>
<li class="toctree-l4"><a class="reference internal" href="0normal.html#id3">è®°å¿†ç±»å‹</a></li>
<li class="toctree-l4"><a class="reference internal" href="0normal.html#id5">å›¾ç¤º</a></li>
<li class="toctree-l4"><a class="reference internal" href="0normal.html#id6">é•¿è®°å¿†çš„å¿…è¦æ€§ä¸æŒ‘æˆ˜</a></li>
<li class="toctree-l4"><a class="reference internal" href="0normal.html#id7">å‚è€ƒ</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="1911.00172_kNN-LMs.html">1911.00172_kNN-LMs: Generalization through Memorization: Nearest Neighbor Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="1911.00172_kNN-LMs.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="1911.00172_kNN-LMs.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="1911.00172_kNN-LMs.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="1911.00172_kNN-LMs.html#nearest-neighbor-language-modeling">2 Nearest Neighbor Language Modeling</a></li>
<li class="toctree-l4"><a class="reference internal" href="1911.00172_kNN-LMs.html#experimental-setup">3 Experimental Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="1911.00172_kNN-LMs.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="1911.00172_kNN-LMs.html#tuning-nearest-neighbor-search">5 Tuning Nearest Neighbor Search</a></li>
<li class="toctree-l4"><a class="reference internal" href="1911.00172_kNN-LMs.html#analysis">6 Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="1911.00172_kNN-LMs.html#related-work">7 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="1911.00172_kNN-LMs.html#conclusion-and-future-work">8 Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="1911.00172_kNN-LMs.html#appendix-a-appendix">Appendix A Appendix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2304.13343_SCM.html">2304.13343_SCM: Enhancing Large Language Model with Self-Controlled Memory Framework</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2304.13343_SCM.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2304.13343_SCM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2304.13343_SCM.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2304.13343_SCM.html#self-controlled-memory">2 Self-Controlled Memory</a></li>
<li class="toctree-l4"><a class="reference internal" href="2304.13343_SCM.html#id7">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2304.13343_SCM.html#experiments">3 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="2304.13343_SCM.html#related-work">4 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2304.13343_SCM.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="2304.13343_SCM.html#limitations">Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="2304.13343_SCM.html#ethical-considerations">Ethical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="2304.13343_SCM.html#appendix-a-prompt-list">Appendix A Prompt List</a></li>
<li class="toctree-l4"><a class="reference internal" href="2304.13343_SCM.html#appendix-b-long-term-dialogue-qa-cases">Appendix B Long-term Dialogue QA Cases</a></li>
<li class="toctree-l4"><a class="reference internal" href="2304.13343_SCM.html#appendix-c-book-summarization-cases">Appendix C Book Summarization Cases</a></li>
<li class="toctree-l4"><a class="reference internal" href="2304.13343_SCM.html#appendix-d-meeting-summarization-cases">Appendix D Meeting Summarization Cases</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2305.10250_MemoryBank.html">2305.10250_MemoryBank: Enhancing Large Language Models with Long-Term Memory</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2305.10250_MemoryBank.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.10250_MemoryBank.html#from-deepseek">From Deepseek</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.10250_MemoryBank.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.10250_MemoryBank.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.10250_MemoryBank.html#memorybank-a-novel-memory-mechanism-tailored-for-llms">2 MemoryBank: A Novel Memory Mechanism Tailored for LLMs</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.10250_MemoryBank.html#id16">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.10250_MemoryBank.html#siliconfriend-an-ai-chatbot-companion-powered-by-memorybank">3 SiliconFriend: An AI Chatbot Companion Powered by MemoryBank</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.10250_MemoryBank.html#id17"><strong>ä½¿ç”¨çš„ä¸‰ç§å¤§è¯­è¨€æ¨¡å‹</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.10250_MemoryBank.html#id18"><strong>SiliconFriend çš„å¼€å‘é˜¶æ®µ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.10250_MemoryBank.html#id23"><strong>æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.10250_MemoryBank.html#id24"><strong>é‡ç‚¹æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.10250_MemoryBank.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.10250_MemoryBank.html#related-works">5 Related Works</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.10250_MemoryBank.html#id27">5 ç›¸å…³å·¥ä½œï¼ˆRelated Worksï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.10250_MemoryBank.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.10250_MemoryBank.html#id29">6 ç»“è®º</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2305.11792_Cue-CoT.html">2305.11792_Cue-CoT: Chain-of-thought Prompting for Responding to In-depth Dialogue Questions with LLMs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2305.11792_Cue-CoT.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.11792_Cue-CoT.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.11792_Cue-CoT.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.11792_Cue-CoT.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.11792_Cue-CoT.html#method">3 Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.11792_Cue-CoT.html#id11">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.11792_Cue-CoT.html#datasets-collection">4 Datasets Collection</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.11792_Cue-CoT.html#experiment">5 Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.11792_Cue-CoT.html#llms">5.1 LLMs å®¶æ—ä¸è¯„ä¼°ç»†èŠ‚</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.11792_Cue-CoT.html#id16">5.2 ä¸»è¦å®éªŒ</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.11792_Cue-CoT.html#id20">5.3 äººå·¥è¯„ä¼°</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.11792_Cue-CoT.html#analysis">6 Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.11792_Cue-CoT.html#discussion">7 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.11792_Cue-CoT.html#conclusion">8 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.11792_Cue-CoT.html#limitations">Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.11792_Cue-CoT.html#ethics-statement">Ethics Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.11792_Cue-CoT.html#acknowledgement">Acknowledgement</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.11792_Cue-CoT.html#appendix-a-templates">Appendix A Templates</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.11792_Cue-CoT.html#appendix-b-different-method-of-evaluation">Appendix B Different Method of Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.11792_Cue-CoT.html#appendix-c-discussion">Appendix C Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.11792_Cue-CoT.html#appendix-d-helpfulness-analysis-of-planning-step">Appendix D Helpfulness Analysis of Planning Step</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2305.17144_GITM.html">2305.17144_GITM: Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2305.17144_GITM.html#from-deepseek">From Deepseek</a></li>
<li class="toctree-l4"><a class="reference internal" href="2305.17144_GITM.html#id5">From Deepseek</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2306.03901_ChatDB.html">2306.03901_ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2306.03901_ChatDB.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2306.03901_ChatDB.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2306.03901_ChatDB.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2306.03901_ChatDB.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2306.03901_ChatDB.html#id6">3 ChatDB</a></li>
<li class="toctree-l4"><a class="reference internal" href="2306.03901_ChatDB.html#evaluation">4 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="2306.03901_ChatDB.html#id10">4 è¯„ä¼°</a></li>
<li class="toctree-l4"><a class="reference internal" href="2306.03901_ChatDB.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="2306.03901_ChatDB.html#id17">5 ç»“è®º</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2308.10144_ExpeL.html">2308.10144_ExpeL: LLM Agents Are Experiential Learners</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2308.10144_ExpeL.html#from-deepseek">From Deepseek</a></li>
<li class="toctree-l4"><a class="reference internal" href="2308.10144_ExpeL.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2308.10144_ExpeL.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2308.10144_ExpeL.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2308.10144_ExpeL.html#preliminaries">3 Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="2308.10144_ExpeL.html#expel-an-experiential-learning-agent">4 ExpeL: An Experiential Learning Agent</a></li>
<li class="toctree-l4"><a class="reference internal" href="2308.10144_ExpeL.html#experiments">5 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="2308.10144_ExpeL.html#conclusion-and-limitations">6 Conclusion and Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="2308.10144_ExpeL.html#acknowledgement">Acknowledgement</a></li>
<li class="toctree-l4"><a class="reference internal" href="2308.10144_ExpeL.html#appendix-a-detailed-related-works">Appendix A Detailed Related Works</a></li>
<li class="toctree-l4"><a class="reference internal" href="2308.10144_ExpeL.html#appendix-b-broader-impacts">Appendix B Broader Impacts</a></li>
<li class="toctree-l4"><a class="reference internal" href="2308.10144_ExpeL.html#appendix-c-computational-resources">Appendix C Computational Resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="2308.10144_ExpeL.html#appendix-d-environment-details">Appendix D Environment Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="2308.10144_ExpeL.html#appendix-e-environment-agent-retrieval-parameters">Appendix E Environment, Agent, Retrieval Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="2308.10144_ExpeL.html#appendix-f-prompt-templates">Appendix F Prompt Templates</a></li>
<li class="toctree-l4"><a class="reference internal" href="2308.10144_ExpeL.html#appendix-g-example-insights">Appendix G Example Insights</a></li>
<li class="toctree-l4"><a class="reference internal" href="2308.10144_ExpeL.html#appendix-h-emergent-abilities-showcase">Appendix H Emergent Abilities Showcase</a></li>
<li class="toctree-l4"><a class="reference internal" href="2308.10144_ExpeL.html#appendix-i-example-trajectories">Appendix I Example Trajectories</a></li>
<li class="toctree-l4"><a class="reference internal" href="2308.10144_ExpeL.html#appendix-j-additional-quantitative-results">Appendix J Additional Quantitative Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2309.02427_CoALA.html">2309.02427_â‡ï¸CoALA: Cognitive Architectures for Language Agents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2309.02427_CoALA.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2309.02427_CoALA.html#from-deepseek">From Deepseek</a></li>
<li class="toctree-l4"><a class="reference internal" href="2309.02427_CoALA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2309.02427_CoALA.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2309.02427_CoALA.html#background-from-strings-to-symbolic-agi">2 Background: From Strings to Symbolic AGI</a></li>
<li class="toctree-l4"><a class="reference internal" href="2309.02427_CoALA.html#connections-between-language-models-and-production-systems">3 Connections between Language Models and Production Systems</a></li>
<li class="toctree-l4"><a class="reference internal" href="2309.02427_CoALA.html#cognitive-architectures-for-language-agents-coala-a-conceptual-framework">4 Cognitive Architectures for Language Agents (CoALA): A Conceptual Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="2309.02427_CoALA.html#case-studies">5 Case Studies</a></li>
<li class="toctree-l4"><a class="reference internal" href="2309.02427_CoALA.html#actionable-insights">6 Actionable Insights</a></li>
<li class="toctree-l4"><a class="reference internal" href="2309.02427_CoALA.html#discussion">7 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="2309.02427_CoALA.html#conclusion">8 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2310.08560_MemGPT.html">2310.08560_MemGPT: Towards LLMs as Operating Systems</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2310.08560_MemGPT.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2310.08560_MemGPT.html#from-deepseek">From Deepseek</a></li>
<li class="toctree-l4"><a class="reference internal" href="2310.08560_MemGPT.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2310.08560_MemGPT.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2310.08560_MemGPT.html#memgpt-memorygpt">2 MemGPT (MemoryGPT)</a></li>
<li class="toctree-l4"><a class="reference internal" href="2310.08560_MemGPT.html#id18">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2310.08560_MemGPT.html#experiments">3 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="2310.08560_MemGPT.html#related-work">4 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2310.08560_MemGPT.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="2310.08560_MemGPT.html#appendix">6 Appendix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2311.08719_Think-in-Memory.html">2311.08719_Think-in-Memory: Recalling and Post-thinking Enable LLMs with Long-Term Memory</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2311.08719_Think-in-Memory.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2311.08719_Think-in-Memory.html#from-deepseek">From Deepseek</a></li>
<li class="toctree-l4"><a class="reference internal" href="2311.08719_Think-in-Memory.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2311.08719_Think-in-Memory.html#introduction">1 INTRODUCTION</a></li>
<li class="toctree-l4"><a class="reference internal" href="2311.08719_Think-in-Memory.html#related-work">2 RELATED WORK</a></li>
<li class="toctree-l4"><a class="reference internal" href="2311.08719_Think-in-Memory.html#methodology">3 METHODOLOGY</a></li>
<li class="toctree-l4"><a class="reference internal" href="2311.08719_Think-in-Memory.html#experiment">4. Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="2311.08719_Think-in-Memory.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2312.17653_LARP.html">2312.17653_â‡ï¸LARP: Language-Agent Role Play for Open-World Games</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2312.17653_LARP.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2312.17653_LARP.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2312.17653_LARP.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2312.17653_LARP.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2312.17653_LARP.html#cognitive-architecture">3 Cognitive Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="2312.17653_LARP.html#environment-interaction">4 Environment Interaction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2312.17653_LARP.html#personalities">5 Personalities</a></li>
<li class="toctree-l4"><a class="reference internal" href="2312.17653_LARP.html#discussions">6 Discussions</a></li>
<li class="toctree-l4"><a class="reference internal" href="2312.17653_LARP.html#conclusion">7 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2402.04624_MemoryLLM.html">2402.04624_MemoryLLM: Towards Self-Updatable Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2402.04624_MemoryLLM.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2402.04624_MemoryLLM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2402.04624_MemoryLLM.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2402.04624_MemoryLLM.html#preliminaries">2 Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="2402.04624_MemoryLLM.html#id5">3 MemoryLLM</a></li>
<li class="toctree-l4"><a class="reference internal" href="2402.04624_MemoryLLM.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="2402.04624_MemoryLLM.html#related-work">5 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2402.04624_MemoryLLM.html#conclusion-and-future-work">6 Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2402.04624_MemoryLLM.html#impact-statement">Impact Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="2402.04624_MemoryLLM.html#appendix-a-details-in-methodology">Appendix A Details in Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="2402.04624_MemoryLLM.html#appendix-b-implementation-details">Appendix B Implementation Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="2402.04624_MemoryLLM.html#appendix-c-additional-experiments">Appendix C Additional Experiments</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2402.09727_ReadAgent.html">2402.09727_ReadAgent: A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2402.09727_ReadAgent.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2402.09727_ReadAgent.html#id2">åˆ«äººçš„æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2402.09727_ReadAgent.html#from-deepseek">From Deepseek</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2404.11672_MemLLM.html">2404.11672_MemLLM: Finetuning LLMs to Use Explicit Read-Write Memory</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2404.11672_MemLLM.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.11672_MemLLM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.11672_MemLLM.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.11672_MemLLM.html#related-work">2 Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.11672_MemLLM.html#methodology">3 Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.11672_MemLLM.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.11672_MemLLM.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.11672_MemLLM.html#limitations">Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.11672_MemLLM.html#appendix-a-memory-write-decoding-method">Appendix A Memory-write Decoding Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.11672_MemLLM.html#appendix-b-filtering-ambiguous-queries">Appendix B Filtering Ambiguous Queries</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.11672_MemLLM.html#appendix-c-memory-read-data-generation">Appendix C Memory-read Data Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.11672_MemLLM.html#appendix-d-hyperparameters-details">Appendix D Hyperparameters Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.11672_MemLLM.html#appendix-e-filtering-prompt">Appendix E Filtering Prompt</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2404.13501_Memory_Survey.html">2404.13501_LLM_Agent_Memory_Survey: A Survey on the Memory Mechanism of Large Language Model based Agents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2404.13501_Memory_Survey.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.13501_Memory_Survey.html#id2">åˆ«äººçš„æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.13501_Memory_Survey.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.13501_Memory_Survey.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.13501_Memory_Survey.html#related-surveys">2 Related Surveys</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.13501_Memory_Survey.html#what-is-the-memory-of-llm-based-agent">3 What is the Memory of LLM-based Agent</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.13501_Memory_Survey.html#why-we-need-the-memory-in-llm-based-agent">4 Why We Need the Memory in LLM-based Agent</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.13501_Memory_Survey.html#how-to-implement-the-memory-of-llm-based-agent">5 How to Implement the Memory of LLM-based Agent</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.13501_Memory_Survey.html#memory-sources">5.1 Memory Sourcesï¼ˆè®°å¿†æ¥æºï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.13501_Memory_Survey.html#memory-forms">5.2 Memory Formsï¼ˆè®°å¿†å½¢å¼ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.13501_Memory_Survey.html#memory-operations">5.3 Memory Operationsï¼ˆè®°å¿†æ“ä½œï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.13501_Memory_Survey.html#how-to-evaluate-the-memory-in-llm-based-agent">6 How to Evaluate the Memory in LLM-based Agent</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.13501_Memory_Survey.html#memory-enhanced-agent-applications">7 Memory-enhanced Agent Applications</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.13501_Memory_Survey.html#limitations-future-directions">8 Limitations &amp; Future Directions</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.13501_Memory_Survey.html#conclusion">9 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.13501_Memory_Survey.html#id51">9 ç»“è®º</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.13501_Memory_Survey.html#acknowledgement">Acknowledgement</a></li>
<li class="toctree-l4"><a class="reference internal" href="2404.13501_Memory_Survey.html#id52">è‡´è°¢</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2407.01178_Memory3.html">2407.01178_â‡ï¸Memory3: Language Modeling with Explicit Memory</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2407.01178_Memory3.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.01178_Memory3.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.01178_Memory3.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.01178_Memory3.html#introduction">1â€‚Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.01178_Memory3.html#memory-circuitry-theory">2â€‚|â€‚Memory Circuitry Theory</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.01178_Memory3.html#design">3â€‚|â€‚Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.01178_Memory3.html#pretraining-data">4â€‚|â€‚Pretraining Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.01178_Memory3.html#pretrain">5â€‚|â€‚Pretrain</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.01178_Memory3.html#fine-tuning-and-alignment">6â€‚|â€‚Fine-tuning and Alignment</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.01178_Memory3.html#id32">6â€‚|â€‚å¾®è°ƒä¸å¯¹é½</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.01178_Memory3.html#evaluation">7â€‚|â€‚Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.01178_Memory3.html#conclusion">8â€‚|â€‚Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.01178_Memory3.html#id40">8â€‚|â€‚ç»“è®º</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.01178_Memory3.html#acknowledgement">Acknowledgement</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.01178_Memory3.html#id47">è‡´è°¢</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.01178_Memory3.html#appendix-a-cost-estimation">Appendix A Cost Estimation</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.01178_Memory3.html#a-1-implicit-memory"><strong>A.1â€‚|â€‚Implicit Memory</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.01178_Memory3.html#a-2-explicit-memory"><strong>A.2â€‚|â€‚Explicit Memory</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.01178_Memory3.html#a-3-external-information"><strong>A.3â€‚|â€‚External Information</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.01178_Memory3.html#id54"><strong>æ€»ç»“ä¸å¯¹æ¯”</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.01178_Memory3.html#remark-9"><strong>é™„æ³¨ï¼šçŸ¥è¯†ä¿ç•™é—®é¢˜ï¼ˆRemark 9ï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.01178_Memory3.html#appendix-b-vector-compression">Appendix B Vector Compression</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.01178_Memory3.html#b">é™„å½• B å‘é‡å‹ç¼©</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.01178_Memory3.html#appendix-c-supplementary-evaluation-results">Appendix C Supplementary Evaluation Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="2407.01178_Memory3.html#c">é™„å½• C è¡¥å……è¯„ä¼°ç»“æœæ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2410.15665_LongTermMemory.html">2410.15665_LongTermMemory: The Foundation of AI Self-Evolution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2410.15665_LongTermMemory.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2410.15665_LongTermMemory.html#id2">åˆ«äººçš„æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2410.15665_LongTermMemory.html#from-deepseek">From Deepseek</a></li>
<li class="toctree-l4"><a class="reference internal" href="2410.15665_LongTermMemory.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2410.15665_LongTermMemory.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2410.15665_LongTermMemory.html#ai-self-evolution">2 AI Self-Evolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="2410.15665_LongTermMemory.html#id8"><strong>æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="2410.15665_LongTermMemory.html#ltm-for-ai-self-evolution">3 LTM for AI Self-Evolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="2410.15665_LongTermMemory.html#how-to-construct-ltm">4 How to Construct LTM?</a></li>
<li class="toctree-l4"><a class="reference internal" href="2410.15665_LongTermMemory.html#how-can-ltm-be-used-to-achieve-model-self-evolution">5 How can LTM be used to achieve model self-Evolution?</a></li>
<li class="toctree-l4"><a class="reference internal" href="2410.15665_LongTermMemory.html#the-practice-of-model-self-evolution-based-on-ltm">6 The Practice of model self-evolution based on LTM</a></li>
<li class="toctree-l4"><a class="reference internal" href="2410.15665_LongTermMemory.html#our-future-plans">7  Our Future Plans</a></li>
<li class="toctree-l4"><a class="reference internal" href="2410.15665_LongTermMemory.html#conclusion">8 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="2410.15665_LongTermMemory.html#appendix-a-rtg-prompt">Appendix A RTG prompt</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2502.00592_M%2B.html">2502.00592_M+: Extending MemoryLLM with Scalable Long-Term Memory</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2502.00592_M%2B.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2502.00592_M%2B.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2502.00592_M%2B.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2502.00592_M%2B.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2502.00592_M%2B.html#methodology">3 Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="2502.00592_M%2B.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="2502.00592_M%2B.html#conclusion-and-future-work">5 Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2502.00592_M%2B.html#impact-statement">Impact Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="2502.00592_M%2B.html#appendix-a-justifications-of-using-deepspeed-stage-2">Appendix A Justifications of using deepspeed-stage-2</a></li>
<li class="toctree-l4"><a class="reference internal" href="2502.00592_M%2B.html#appendix-b-experiments-on-datasets-naturalqa">Appendix B Experiments on datasets NaturalQA</a></li>
<li class="toctree-l4"><a class="reference internal" href="2502.00592_M%2B.html#appendix-c-statistics-of-the-dataset-of-long-documents">Appendix C Statistics of the Dataset of Long Documents</a></li>
<li class="toctree-l4"><a class="reference internal" href="2502.00592_M%2B.html#appendix-d-additional-training-details">Appendix D Additional Training Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="2502.00592_M%2B.html#appendix-e-discussions">Appendix E Discussions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2502.12110_A-Mem.html">2502.12110_A-Mem: Agentic Memory for LLM Agents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2502.12110_A-Mem.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2502.12110_A-Mem.html#from-deepseek">From Deepseek</a></li>
<li class="toctree-l4"><a class="reference internal" href="2502.12110_A-Mem.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2502.12110_A-Mem.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2502.12110_A-Mem.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2502.12110_A-Mem.html#methodolodgy">3 Methodolodgy</a></li>
<li class="toctree-l4"><a class="reference internal" href="2502.12110_A-Mem.html#experiment">4 Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="2502.12110_A-Mem.html#conclusions">5 Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="2502.12110_A-Mem.html#limitations">6 Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="2502.12110_A-Mem.html#appendix-a-experiment">Appendix A Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="2502.12110_A-Mem.html#appendix-b-prompt-templates-and-examples">Appendix B Prompt Templates and Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2504.15965_From_Human_to_AI_Memory.html">2504.15965_â‡ï¸From Human Memory to AI Memory: A Survey on Memory Mechanisms in the Era of LLMs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2504.15965_From_Human_to_AI_Memory.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2504.15965_From_Human_to_AI_Memory.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2504.15965_From_Human_to_AI_Memory.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2504.15965_From_Human_to_AI_Memory.html#overview">2 Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="2504.15965_From_Human_to_AI_Memory.html#personal-memory">3 Personal Memory</a></li>
<li class="toctree-l4"><a class="reference internal" href="2504.15965_From_Human_to_AI_Memory.html#system-memory">4 System Memory</a></li>
<li class="toctree-l4"><a class="reference internal" href="2504.15965_From_Human_to_AI_Memory.html#open-problems-and-future-directions">5 Open Problems and Future Directions</a></li>
<li class="toctree-l4"><a class="reference internal" href="2504.15965_From_Human_to_AI_Memory.html#conclusion">6 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2504.19413_Mem0.html">2504.19413_â‡ï¸Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2504.19413_Mem0.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2504.19413_Mem0.html#id2">åˆ«äººçš„æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2504.19413_Mem0.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2504.19413_Mem0.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2504.19413_Mem0.html#proposed-methods">2 Proposed Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="2504.19413_Mem0.html#id13"><strong>æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="2504.19413_Mem0.html#experimental-setup">3 Experimental Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="2504.19413_Mem0.html#id16">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2504.19413_Mem0.html#evaluation-results-analysis-and-discussion">4 Evaluation Results, Analysis and Discussion.</a></li>
<li class="toctree-l4"><a class="reference internal" href="2504.19413_Mem0.html#conclusion-and-future-work">5 Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2504.19413_Mem0.html#acknowledgments">6 Acknowledgments</a></li>
<li class="toctree-l4"><a class="reference internal" href="2504.19413_Mem0.html#appendix-a-prompts">Appendix A Prompts</a></li>
<li class="toctree-l4"><a class="reference internal" href="2504.19413_Mem0.html#appendix-b-algorithm">Appendix B Algorithm</a></li>
<li class="toctree-l4"><a class="reference internal" href="2504.19413_Mem0.html#appendix-c-selected-baselines">Appendix C Selected Baselines</a></li>
</ul>
</li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">2505.00675_â‡ï¸Rethinking Memory in AI: Taxonomy, Operations, Topics, and Future Directions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="#memory-foundations">2 Memory Foundations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#from-operations-to-key-research-topics">3 From Operations to Key Research Topics</a></li>
<li class="toctree-l4"><a class="reference internal" href="#memory-in-practice">4 Memory In Practice</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id20">æ€»ä½“æ€»ç»“ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="#memory-in-humans-and-ai-systems">5 Memory in Humans and AI Systems</a></li>
<li class="toctree-l4"><a class="reference internal" href="#open-challenges-and-future-directions">6 Open Challenges and Future Directions</a></li>
<li class="toctree-l4"><a class="reference internal" href="#appendix-a-gpt-based-pipeline-selection">Appendix A GPT-based Pipeline Selection</a></li>
<li class="toctree-l4"><a class="reference internal" href="#appendix-b-relative-citation-index">Appendix B Relative Citation Index</a></li>
<li class="toctree-l4"><a class="reference internal" href="#appendix-c-chord-analysis-of-interactions-among-memory-types-operations-topics-and-venues">Appendix C Chord Analysis of Interactions Among Memory Types, Operations, Topics, and Venues</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2505.22101_MemOS.html">2505.22101_MemOS: An Operating System for Memory-Augmented Generation (MAG) in LLM (Short Version)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2505.22101_MemOS.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2505.22101_MemOS.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2505.22101_MemOS.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2505.22101_MemOS.html#memory-in-large-language-models">2 Memory in Large Language Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="2505.22101_MemOS.html#memos-design-philosophy">3 MemOS Design Philosophy</a></li>
<li class="toctree-l4"><a class="reference internal" href="2505.22101_MemOS.html#memos">4 MemOS</a></li>
<li class="toctree-l4"><a class="reference internal" href="2505.22101_MemOS.html#id2"><strong>4.1 MemOS ä¸­çš„è®°å¿†ç±»å‹</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="2505.22101_MemOS.html#memcube"><strong>4.2 è®°å¿†ç«‹æ–¹ä½“ï¼ˆMemCubeï¼‰ï¼šæ ¸å¿ƒèµ„æº</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="2505.22101_MemOS.html#id3"><strong>4.3 MemOS æ¶æ„</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="2505.22101_MemOS.html#id4"><strong>4.4 ç³»ç»Ÿæ‰§è¡Œæµç¨‹</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="2505.22101_MemOS.html#id5"><strong>æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="2505.22101_MemOS.html#conclusion">5 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2507.03724_MemOS.html">2505.22101_â‡ï¸MemOS: A Memory OS for AI System</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2507.03724_MemOS.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2507.03724_MemOS.html#llm">LLM æ€»ç»“ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="2507.03724_MemOS.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2507.03724_MemOS.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2507.03724_MemOS.html#memory-in-large-language-models">2 Memory in Large Language Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="2507.03724_MemOS.html#memos-design-philosophy">3 MemOS Design Philosophy</a></li>
<li class="toctree-l4"><a class="reference internal" href="2507.03724_MemOS.html#memory-modeling-in-memos">4 Memory Modeling in MemOS</a></li>
<li class="toctree-l4"><a class="reference internal" href="2507.03724_MemOS.html#architecture-of-memos">5 Architecture of MemOS</a></li>
<li class="toctree-l4"><a class="reference internal" href="2507.03724_MemOS.html#evaluation">6 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="2507.03724_MemOS.html#memos-for-architecture-innovation-and-applications">7 MemOS for Architecture Innovation and Applications</a></li>
<li class="toctree-l4"><a class="reference internal" href="2507.03724_MemOS.html#conclusion">8 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2508.09874_MemoryDecoder.html">2508.09874_Memory Decoder: A Pretrained, Plug-and-Play Memory for Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2508.09874_MemoryDecoder.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="2508.09874_MemoryDecoder.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="2508.09874_MemoryDecoder.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="2508.09874_MemoryDecoder.html#background">2 Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="2508.09874_MemoryDecoder.html#id9">3 Memory Decoder</a></li>
<li class="toctree-l4"><a class="reference internal" href="2508.09874_MemoryDecoder.html#experimental-setup">4 Experimental Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="2508.09874_MemoryDecoder.html#results">5 Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="2508.09874_MemoryDecoder.html#analysis">6 Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="2508.09874_MemoryDecoder.html#related-work">7 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="2508.09874_MemoryDecoder.html#conclusion">8 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="2508.09874_MemoryDecoder.html#limitations">9 Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="2508.09874_MemoryDecoder.html#appendix-a-interpolation-hyperparameter-alpha-of-all-tasks">Appendix A Interpolation hyperparameter <span class="math notranslate nohighlight">\(\alpha\)</span> of all tasks</a></li>
<li class="toctree-l4"><a class="reference internal" href="2508.09874_MemoryDecoder.html#appendix-b-analysis-of-dapt-performance-on-downstream-tasks">Appendix B Analysis of DAPT Performance on Downstream Tasks</a></li>
<li class="toctree-l4"><a class="reference internal" href="2508.09874_MemoryDecoder.html#appendix-c-knowledge-intensive-reasoning-task-corpus-composition">Appendix C Knowledge-Intensive Reasoning Task Corpus Composition</a></li>
<li class="toctree-l4"><a class="reference internal" href="2508.09874_MemoryDecoder.html#appendix-d-domain-specific-downstream-tasks">Appendix D Domain-Specific Downstream Tasks</a></li>
<li class="toctree-l4"><a class="reference internal" href="2508.09874_MemoryDecoder.html#appendix-e-comparison-with-dapt-model-interpolation">Appendix E Comparison with DAPT Model Interpolation</a></li>
<li class="toctree-l4"><a class="reference internal" href="2508.09874_MemoryDecoder.html#appendix-f-in-context-learning-performance-analysis">Appendix F In-Context Learning Performance Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="2508.09874_MemoryDecoder.html#appendix-g-characteristics-of-kk-nn-distributions">Appendix G Characteristics of kk-NN Distributions</a></li>
<li class="toctree-l4"><a class="reference internal" href="2508.09874_MemoryDecoder.html#appendix-h-alternative-loss-functions-for-imitating-kk-nn-distributions">Appendix H Alternative Loss Functions for Imitating kk-NN Distributions</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Memory.html#id4">æ¨è</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../Recommends/05xx.xxxxx_RS.html">Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/05xx.xxxxx_RS.html#id1">è®ºæ–‡åŸºæœ¬ä¿¡æ¯</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/05xx.xxxxx_RS.html#id2">æ ¸å¿ƒå†…å®¹ç®€ä»‹</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/05xx.xxxxx_RS.html#id3">é‡è¦æ€§ä¸å½±å“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/05xx.xxxxx_RS.html#id4">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Recommends/08xx.xxxxx_SVD%2B%2B.html">08xx.xxxxx_SVD++: Factorization meets the neighborhood: a multifaceted collaborative filtering model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/08xx.xxxxx_SVD%2B%2B.html#svd">SVD++</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/08xx.xxxxx_SVD%2B%2B.html#neighborhood-models">Neighborhood Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/08xx.xxxxx_SVD%2B%2B.html#latent-factor-models">Latent Factor Modelsï¼ˆæ½œåœ¨å› å­æ¨¡å‹ï¼‰</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Recommends/17xx.xxxxx_RS.html">Recommender systems: An overview of different approaches to recommendations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/17xx.xxxxx_RS.html#id1">è®ºæ–‡ç®€ä»‹</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/17xx.xxxxx_RS.html#id2">æ ¸å¿ƒå†…å®¹æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/17xx.xxxxx_RS.html#id6">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Recommends/1902.07153_SGCN.html">1902.07153_SGCN: Simplifying Graph Convolutional Networks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/1902.07153_SGCN.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/1902.07153_SGCN.html#id2">å‰æçŸ¥è¯†</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/1902.07153_SGCN.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/1902.07153_SGCN.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/1902.07153_SGCN.html#simple-graph-convolution">2 Simple Graph Convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/1902.07153_SGCN.html#spectral-analysis">3 Spectral Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/1902.07153_SGCN.html#related-works">4 Related Works</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/1902.07153_SGCN.html#experiments-and-discussion">5 Experiments and Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/1902.07153_SGCN.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/1902.07153_SGCN.html#acknowledgement">Acknowledgement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/1902.07153_SGCN.html#appendix-a-the-spectrum-of-symsubscript-sym">Appendix A The spectrum of ğš«~symsubscript~ğš«symï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/1902.07153_SGCN.html#appendix-b-experiment-details">Appendix B Experiment Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/1902.07153_SGCN.html#appendix-c-additional-experiments">Appendix C Additional Experiments</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Recommends/1905.08108_NGCF.html">1905.08108_NGCF: Neural Graph Collaborative Filtering</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/1905.08108_NGCF.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/1905.08108_NGCF.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/1905.08108_NGCF.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/1905.08108_NGCF.html#methodology">2. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/1905.08108_NGCF.html#related-work">3. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/1905.08108_NGCF.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/1905.08108_NGCF.html#conclusion-and-future-work">5. Conclusion and Future Work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Recommends/2001.10167_RGCF.html">2001.10167_RGCF: Revisiting Graph based Collaborative Filtering: A Linear Residual Graph Convolutional Network Approach</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2001.10167_RGCF.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2001.10167_RGCF.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2001.10167_RGCF.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2001.10167_RGCF.html#preliminaries-and-related-work">Preliminaries and Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2001.10167_RGCF.html#linear-residual-graph-convolutional-collaborative-filtering">Linear Residual Graph Convolutional Collaborative Filtering</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2001.10167_RGCF.html#experiments">Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2001.10167_RGCF.html#conclusions">Conclusions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Recommends/2002.02126_LightGCN.html">2002.02126_LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2002.02126_LightGCN.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2002.02126_LightGCN.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2002.02126_LightGCN.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2002.02126_LightGCN.html#preliminaries">2. Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2002.02126_LightGCN.html#method">3. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2002.02126_LightGCN.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2002.02126_LightGCN.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2002.02126_LightGCN.html#conclusion-and-future-work">6. Conclusion and Future Work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Recommends/2010.10783_SGL.html">2010.10783_SGL: Self-supervised Graph Learning for Recommendation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2010.10783_SGL.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2010.10783_SGL.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2010.10783_SGL.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2010.10783_SGL.html#preliminaries">2. Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2010.10783_SGL.html#methodology">3. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2010.10783_SGL.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2010.10783_SGL.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2010.10783_SGL.html#conclusion-and-future-work">6. Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2010.10783_SGL.html#appendix-a-gradient-of-infonce-loss-w-r-t-node-representation">Appendix A Gradient of InfoNCE Loss <em>w.r.t.</em> node representation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Recommends/2112.08679_SimGCL.html">2112.08679_SimGCL: Are Graph Augmentations Necessary? Simple Graph ContrastiveÂ Learning for Recommendation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2112.08679_SimGCL.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2112.08679_SimGCL.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2112.08679_SimGCL.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2112.08679_SimGCL.html#investigation-of-graph-contrastive-learning-in-recommendation">2. Investigation of Graph Contrastive Learning in Recommendation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2112.08679_SimGCL.html#simgcl-simple-graph-contrastive-learning-for-recommendation">3. SimGCL: Simple Graph Contrastive Learning for Recommendation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2112.08679_SimGCL.html#experimental-results">4. Experimental Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2112.08679_SimGCL.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2112.08679_SimGCL.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2112.08679_SimGCL.html#acknowledgement">Acknowledgement</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Recommends/2202.06200_NCL.html">2202.06200_NCL: Improving Graph Collaborative Filtering with Neighborhood-enriched Contrastive Learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2202.06200_NCL.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2202.06200_NCL.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2202.06200_NCL.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2202.06200_NCL.html#preliminary">2. Preliminary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2202.06200_NCL.html#methodology">3. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2202.06200_NCL.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2202.06200_NCL.html#related-work">5. Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2202.06200_NCL.html#conclusion-and-future-work">6. Conclusion And Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2202.06200_NCL.html#appendix-a-pseudo-code-for-ncl">Appendix A Pseudo-code for NCL</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2202.06200_NCL.html#appendix-b-case-study-on-selected-neighbors">Appendix B Case Study on Selected Neighbors</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Recommends/2203.13366_RLP_P5.html">2203.13366_RLP_P5: A Unified Pretrain, Personalized Prompt &amp; Predict Paradigm (P5)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2203.13366_RLP_P5.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2203.13366_RLP_P5.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2203.13366_RLP_P5.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2203.13366_RLP_P5.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2203.13366_RLP_P5.html#personalized-prompt-collection">3. Personalized Prompt Collection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2203.13366_RLP_P5.html#the-p5-paradigm-and-model">4. The P5 Paradigm and Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2203.13366_RLP_P5.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2203.13366_RLP_P5.html#conclusions-and-future-work">6. Conclusions and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2203.13366_RLP_P5.html#acknowledgment">Acknowledgment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2203.13366_RLP_P5.html#d-full-list-of-personalized-prompts-for-amazon-datasets">D FULL LIST OF PERSONALIZED PROMPTS FOR AMAZON DATASETS</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Recommends/2302.08191_LightGCL.html">2302.08191_LightGCL: Simple Yet Effective Graph Contrastive Learning for Recommendation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2302.08191_LightGCL.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2302.08191_LightGCL.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2302.08191_LightGCL.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2302.08191_LightGCL.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2302.08191_LightGCL.html#methodology">3 Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2302.08191_LightGCL.html#evaluation">4 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2302.08191_LightGCL.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2302.08191_LightGCL.html#appendix-a-details-of-the-baselines">Appendix A Details of the Baselines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2302.08191_LightGCL.html#appendix-b-performance-comparison-with-baselines-continued">Appendix B Performance Comparison with Baselines (Continued)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2302.08191_LightGCL.html#appendix-c-theoretical-analysis">Appendix C Theoretical Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2302.08191_LightGCL.html#appendix-d-calculation-of-complexity">Appendix D Calculation of Complexity</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2302.08191_LightGCL.html#appendix-e-performance-results-under-the-new-setting">Appendix E Performance Results under the New Setting</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Recommends/2303.14524_ChatRec.html">2303.14524_ChatRec: Towards Interactive and Explainable LLMs-Augmented Recommender System</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2303.14524_ChatRec.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2303.14524_ChatRec.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2303.14524_ChatRec.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2303.14524_ChatRec.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2303.14524_ChatRec.html#method">3 Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2303.14524_ChatRec.html#experiment">4 Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2303.14524_ChatRec.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2303.14524_ChatRec.html#appendix-0-a-implementation-details">Appendix 0.A Implementation Details</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Recommends/2305.00447_TALLRec.html">2305.00447_TALLRec: An Effective and Efficient Tuning Framework to Align Large Language Model with Recommendation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2305.00447_TALLRec.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2305.00447_TALLRec.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2305.00447_TALLRec.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2305.00447_TALLRec.html#id8">2. TALLRec</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2305.00447_TALLRec.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2305.00447_TALLRec.html#related-work">4. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2305.00447_TALLRec.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Recommends/2305.07001_InstructRec.html">2305.07001_InstructRec: Recommendation as Instruction Following: A Large Language Model Empowered Recommendation Approach</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2305.07001_InstructRec.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2305.07001_InstructRec.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2305.07001_InstructRec.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2305.07001_InstructRec.html#methodology">2. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2305.07001_InstructRec.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2305.07001_InstructRec.html#conclusion-and-future-work">4. Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2305.07001_InstructRec.html#appendix-a-instruction-templates-for-traditional-recommendation">Appendix A Instruction Templates for <em>Traditional Recommendation</em></a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2305.07001_InstructRec.html#appendix-b-instruction-templates-for-traditional-product-search">Appendix B Instruction Templates for <em>Traditional Product search</em></a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2305.07001_InstructRec.html#appendix-c-instruction-templates-for-personalized-search">Appendix C Instruction Templates for <em>Personalized Search</em></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Recommends/2306.10933_KAR.html">2306.10933_KAR: Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2306.10933_KAR.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2306.10933_KAR.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2306.10933_KAR.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2306.10933_KAR.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2306.10933_KAR.html#preliminaries">3. Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2306.10933_KAR.html#methodology">4. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2306.10933_KAR.html#experiment">5. Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2306.10933_KAR.html#broader-impact">6. Broader Impact</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2306.10933_KAR.html#conclusion">7. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Recommends/2308.11131_ReLLa.html">2308.11131_ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2308.11131_ReLLa.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2308.11131_ReLLa.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2308.11131_ReLLa.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2308.11131_ReLLa.html#preliminaries">2. Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2308.11131_ReLLa.html#methodology">3. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2308.11131_ReLLa.html#experiment">4. Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2308.11131_ReLLa.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2308.11131_ReLLa.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2308.11131_ReLLa.html#appendix-a-prompt-illustration">Appendix A Prompt Illustration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2308.11131_ReLLa.html#appendix-b-data-preprocessing">Appendix B Data Preprocessing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2308.11131_ReLLa.html#appendix-c-baseline-implementation">Appendix C Baseline Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2308.11131_ReLLa.html#id27">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2308.11131_ReLLa.html#appendix-d-additional-experiments">Appendix D Additional Experiments</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Recommends/2310.15950_RLMRec.html">2310.15950_RLMRec: Representation Learning with Large Language Models for Recommendation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2310.15950_RLMRec.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2310.15950_RLMRec.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2310.15950_RLMRec.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2310.15950_RLMRec.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2310.15950_RLMRec.html#methodology">3. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2310.15950_RLMRec.html#evaluation">4. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2310.15950_RLMRec.html#conclusion">5. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2310.15950_RLMRec.html#appendix-a-supplementary-material">Appendix A Supplementary Material</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Recommends/2311.01343_CLLM4Rec.html">2311.01343_CLLM4Rec: Collaborative Large Language Model for Recommender Systems</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2311.01343_CLLM4Rec.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2311.01343_CLLM4Rec.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2311.01343_CLLM4Rec.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2311.01343_CLLM4Rec.html#contribution">æœ¬èŠ‚è´¡çŒ®ï¼ˆContributionï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2311.01343_CLLM4Rec.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2311.01343_CLLM4Rec.html#id5">2. ç›¸å…³å·¥ä½œ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2311.01343_CLLM4Rec.html#methodology">3. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2311.01343_CLLM4Rec.html#empirical-study">4. Empirical Study</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2311.01343_CLLM4Rec.html#conclusion">5. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2311.01343_CLLM4Rec.html#acknowledgment">Acknowledgment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2311.01343_CLLM4Rec.html#appendix-a-technical-details">Appendix A Technical Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Recommends/2311.01343_CLLM4Rec.html#appendix-b-experiments">Appendix B Experiments</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Memory.html#agent">è®°å¿†ç›¸å…³Agent</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../Agents/2504.10147_PersonalRAG%2B.html">2504.10147_PersonalRAGâ‡ï¸: A Survey of Personalization: From RAG to Agent</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Agents/2504.10147_PersonalRAG%2B.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Agents/2504.10147_PersonalRAG%2B.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Agents/2504.10147_PersonalRAG%2B.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Agents/2504.10147_PersonalRAG%2B.html#what-is-personalization">2. What is Personalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Agents/2504.10147_PersonalRAG%2B.html#how-to-adopt-personalization">3. How to Adopt Personalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Agents/2504.10147_PersonalRAG%2B.html#where-to-adopt-personalization">4. Where to Adopt Personalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Agents/2504.10147_PersonalRAG%2B.html#evaluation-and-dataset">5. Evaluation and Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Agents/2504.10147_PersonalRAG%2B.html#challenges-and-future-directions">6. Challenges and Future Directions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Agents/2504.10147_PersonalRAG%2B.html#conclusion">7. Conclusion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Memory.html#id5">è®°å¿†ç›¸å…³æ•°æ®é›†</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../Databases/2308.08239_MemoChat.html">2308.08239_MemoChat: Tuning LLMs to Use Memos for Consistent Long-Range Open-Domain Conversation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2308.08239_MemoChat.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2308.08239_MemoChat.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2308.08239_MemoChat.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2308.08239_MemoChat.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2308.08239_MemoChat.html#methodology">3 Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2308.08239_MemoChat.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2308.08239_MemoChat.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2308.08239_MemoChat.html#appendix-a-basic-published-datasets">Appendix A Basic Published Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2308.08239_MemoChat.html#appendix-b-involved-prompts">Appendix B Involved Prompts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2308.08239_MemoChat.html#appendix-c-instruction-design-challenges">Appendix C Instruction Design Challenges</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2308.08239_MemoChat.html#id22">1. å¼•è¨€</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2308.08239_MemoChat.html#prompt-copy">2. Prompt Copyï¼ˆæç¤ºå¤åˆ¶ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2308.08239_MemoChat.html#catastrophic-forgetting">3. Catastrophic Forgettingï¼ˆç¾éš¾æ€§é—å¿˜ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2308.08239_MemoChat.html#prompt-misplacement">4. Prompt Misplacementï¼ˆæç¤ºé”™ä½ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2308.08239_MemoChat.html#id23">5. ç¤ºä¾‹ä»»åŠ¡è¯´æ˜</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2308.08239_MemoChat.html#id24">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Databases/2402.17753_LoCoMo.html">2402.17753_LoCoMoâ‡ï¸: Evaluating Very Long-Term Conversational Memory of LLM Agents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2402.17753_LoCoMo.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2402.17753_LoCoMo.html#id2">åˆ«äººçš„æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2402.17753_LoCoMo.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2402.17753_LoCoMo.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2402.17753_LoCoMo.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2402.17753_LoCoMo.html#generative-pipeline-for-locomo">3 Generative Pipeline for LoCoMo</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2402.17753_LoCoMo.html#locomo-evaluation-benchmark">4 LoCoMo Evaluation Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2402.17753_LoCoMo.html#experimental-setup">5 Experimental Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2402.17753_LoCoMo.html#experimental-results">6 Experimental Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2402.17753_LoCoMo.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2402.17753_LoCoMo.html#limitations">8 Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2402.17753_LoCoMo.html#broader-impacts">9 Broader Impacts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2402.17753_LoCoMo.html#appendix-overview">Appendix Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2402.17753_LoCoMo.html#appendix-a-generative-pipeline-for-locomo">Appendix A Generative Pipeline for LoCoMo</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2402.17753_LoCoMo.html#appendix-b-dataset">Appendix B Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2402.17753_LoCoMo.html#appendix-c-experimental-setup">Appendix C Experimental Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2402.17753_LoCoMo.html#appendix-d-results">Appendix D Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Databases/2507.05257_MemoryAgentBench.html">2507.05257_MemoryAgentBench: Evaluating Memory in LLM Agents via Incremental Multi-Turn Interactions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2507.05257_MemoryAgentBench.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2507.05257_MemoryAgentBench.html#from-deepseek">From Deepseek</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2507.05257_MemoryAgentBench.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2507.05257_MemoryAgentBench.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2507.05257_MemoryAgentBench.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2507.05257_MemoryAgentBench.html#id12">3 MemoryAgentBench</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2507.05257_MemoryAgentBench.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2507.05257_MemoryAgentBench.html#conclusion-and-future-work">5 Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2507.05257_MemoryAgentBench.html#appendix-a-details-of-dataset">Appendix A Details of Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2507.05257_MemoryAgentBench.html#appendix-b-prompts">Appendix B Prompts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2507.05257_MemoryAgentBench.html#appendix-c-detailed-experimental-results">Appendix C Detailed Experimental Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Databases/2507.05257_MemoryAgentBench.html#appendix-d-experimental-settings">Appendix D Experimental Settings</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Memory.html#id6">å¤šæ¨¡æ€è®°å¿†</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../Multimodals/2508.09736_M3-Agent.html">2508.09736_M3-Agentâ‡ï¸: Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Multimodals/2508.09736_M3-Agent.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Multimodals/2508.09736_M3-Agent.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Multimodals/2508.09736_M3-Agent.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Multimodals/2508.09736_M3-Agent.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Multimodals/2508.09736_M3-Agent.html#datasets">3 Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Multimodals/2508.09736_M3-Agent.html#approach">4 Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Multimodals/2508.09736_M3-Agent.html#experiments">5 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Multimodals/2508.09736_M3-Agent.html#conclusion-and-future-work">6 Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Multimodals/2508.09736_M3-Agent.html#acknowledgment">7 Acknowledgment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Multimodals/2508.09736_M3-Agent.html#id19">8 M3-Bench-robot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Multimodals/2508.09736_M3-Agent.html#id20">9 M3-Bench-web</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Multimodals/2508.09736_M3-Agent.html#implementation-details-of-tools">10 Implementation Details of Tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Multimodals/2508.09736_M3-Agent.html#demonstration-data-synthesis-for-memorization">11 Demonstration Data Synthesis for Memorization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Multimodals/2508.09736_M3-Agent.html#evaluation-of-memorization">12 Evaluation of Memorization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Multimodals/2508.09736_M3-Agent.html#rl-training-details">13 RL Training Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Multimodals/2508.09736_M3-Agent.html#id29">14 Case Study</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Multimodals/2508.09736_M3-Agent.html#prompt-templates">15 Prompt Templates</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM.html">LLM æ¨¡å‹</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../LLM.html#nlp">NLP æ¨¡å‹</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/1810.04805_BERT.html">1810.04805_BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/1810.04805_BERT.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/1810.04805_BERT.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/1810.04805_BERT.html#bert">3 BERT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/1810.04805_BERT.html#appendix-a-additional-details-for-bert">Appendix A Additional Details for BERT</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html">18xx_GPT1: Improving Language Understanding by Generative Pre-Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#framework">3. Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#analysis">5 Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#id3">å¼•æ–‡å£ç¢‘</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/18_GPT1.html#id4">è¦ç‚¹è§£è¯»</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/19_GPT2.html">19xx_GPT2: Language Models are Unsupervised Multitask Learners</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/19_GPT2.html#the-illustrated-gpt-2">The Illustrated GPT-2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/19_GPT2.html#id2">å‚è€ƒ</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2006.03654_DeBERTa.html">2006.03654_DeBERTa: Decoding-enhanced BERT with Disentangled Attention</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2006.03654_DeBERTa.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2006.03654_DeBERTa.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2006.03654_DeBERTa.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2006.03654_DeBERTa.html#background">2 Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2006.03654_DeBERTa.html#the-deberta-architecture">3 The DeBERTa Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2006.03654_DeBERTa.html#scale-invariant-fine-tuning">4 Scale Invariant Fine-Tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2006.03654_DeBERTa.html#id21">4 å°ºåº¦ä¸å˜å¾®è°ƒ (Scale Invariant Fine-Tuning)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2006.03654_DeBERTa.html#experiment">5 Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2006.03654_DeBERTa.html#conclusions">6 Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2006.03654_DeBERTa.html#acknowledgments">7 Acknowledgments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2006.03654_DeBERTa.html#appendix-a-appendix">Appendix A Appendix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2012.00413_CPM.html">2012.00413_CPM: A Large-scale Generative Chinese Pre-trained Language Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2302.13971_LLaMA.html">2302.13971_LLaMA: Open and Efficient Foundation Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2307.09288_Llama2.html">2307.09288_Llama 2: Open Foundation and Fine-Tuned Chat Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html">2309.16609_Qwen Technical Report</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#pretraining">2. Pretraining</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#alignment">3. Alignment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#code-qwen-specialized-model-for-coding">4. CODE-QWEN: SPECIALIZED MODEL FOR CODING</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#math-qwen-specialized-model-for-mathematics-reasoning">5. MATH-QWEN: SPECIALIZED MODEL FOR MATHEMATICS REASONING</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#related-work">6. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#conclusion">7. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#a-1-more-training-details">A.1 MORE TRAINING DETAILS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2309.16609_Qwen.html#a-2-evaluation">A.2 EVALUATION</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html">2310.19341_Skywork: A More Open Bilingual Foundation Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#methodology">2 Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#pre-training">3 Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#evaluation">4 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#discussion">5 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#limitation">6 Limitation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#appendix-a-details-on-gpt-7b-vs-llama-7b-experiment">Appendix A Details on GPT-7B vs. LLaMA-7B Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#appendix-b-preliminary-experiments-on-distributed-training">Appendix B Preliminary Experiments on Distributed Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#appendix-c-more-benchmark-results">Appendix C More Benchmark Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2310.19341_Skywork.html#appendix-d-details-on-lm-test-sets">Appendix D Details on LM Test Sets</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2401.14196_DeepSeek-Coder.html">2401.14196_DeepSeek-Coder: When the Large Language Model Meets Programming â€“ The Rise of Code Intelligence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2404.06395_MiniCPM.html">2404.06395_MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2404.06395_MiniCPM.html#two-stage-pre-training-strategy">5. Two Stage Pre-training Strategy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2404.06395_MiniCPM.html#model">6. Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2404.06395_MiniCPM.html#minicpm-family">7 MiniCPM Family</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2405.04434_DeepSeek-V2.html">2405.04434_DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2406.12793_ChatGLM.html">2406.12793_ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html">2407.10671_Qwen2 Technical Report</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html#tokenizer-model">2. Tokenizer &amp; Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html#pre-training">3. Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html#post-training">4. Post-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2407.10671_Qwen2.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html">2412.15115_Qwen2.5</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html#architecture-and-tokenizer">2. Architecture and Tokenizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html#pre-training">3. Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html#post-training">4. Post-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2412.15115_Qwen2.5.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLM_NLPs/2505.09388_Qwen3.html">2505.09388_Qwen3</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2505.09388_Qwen3.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2505.09388_Qwen3.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2505.09388_Qwen3.html#architecture">2. Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2505.09388_Qwen3.html#pre-training">3. Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2505.09388_Qwen3.html#post-training">4. Post-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLM_NLPs/2505.09388_Qwen3.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM.html#id2">å¤šæ¨¡æ€æ¨¡å‹</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html">2112.15093_CTR: Benchmarking Chinese Text Recognition: Datasets, Baselines, and an Empirical Study</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#preliminaries">2. Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#datasets">3. Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#baselines">4. Baselines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#an-empirical-study">5. An Empirical Study</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#conclusions">6. Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#appendix-a-details-of-prab">Appendix A Details of PRAB</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2112.15093_CTR.html#appendix-c-visualization-of-failure-cases">Appendix C Visualization of Failure Cases.</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html">2304.08485_LLaVA: Visual Instruction Tuning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html#gpt-assisted-visual-instruction-data-generation">3. GPT-assisted Visual Instruction Data Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html#visual-instruction-tuning">4. Visual Instruction Tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2304.08485_LLaVA.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2308.12966_Qwen-VL.html">2308.12966_Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2308.12966_Qwen-VL.html#methodology">Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2308.12966_Qwen-VL.html#training">Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2308.12966_Qwen-VL.html#evaluation">Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2308.12966_Qwen-VL.html#b-data-format-details-of-training">B. Data Format Details of Training</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html">2310.03744_LLaVA2: Improved Baselines with Visual Instruction Tuning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#approach">3. Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#empirical-evaluation">4. Empirical Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#open-problems-in-lmms">5. Open Problems in LMMs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#a-implementation-details">A. Implementation Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2310.03744_LLaVA2.html#b-qualitative-results">B. Qualitative Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html">2312.07533_VILA: On Pre-training for Visual Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html#on-pre-training-for-visual-language-models">3. On Pre-training for Visual Language Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2312.07533_VILA.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2403.05525_DeepSeek-VL.html">2403.05525_DeepSeek-VL: Towards Real-World Vision-Language Understanding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2403.05525_DeepSeek-VL.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html">2408.01800_MiniCPM-V: A GPT-4V Level MLLM on Your Phone</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#model-architecture">3. Model Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#training">4. Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#end-side-deployment">5. End-side Deployment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#experiments">6. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2408.01800_MiniCPM-V.html#conclusion">7. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html">2409.17146_Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Vision-Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#architecture">2. Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#data">3. Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#training">4. Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#ablations">6. Ablations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-a-model-details">Appendix A: Model Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-b-training-details">Appendix B: Training Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-c-evaluation-results">Appendix C: Evaluation Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-d-result-details">Appendix D: Result Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-e-ablations-details">Appendix E Ablations Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-f-data-details">Appendix F Data Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-g-dataset-examples">Appendix G Dataset Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-h-related-work">Appendix H Related Work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html">2410.13848_Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#llm">LLMæ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#janus-a-simple-unified-and-flexible-multimodal-framework">3 Janus: A Simple, Unified and Flexible Multimodal Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#appendix-a-details-of-semantic-tokenizer-mentioned-in-ablation-study">Appendix A Details of Semantic Tokenizer Mentioned in Ablation Study</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2410.13848_Janus.html#appendix-b-additional-qualitative-results">Appendix B Additional Qualitative Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2411.00774_Freeze-Omni.html">2411.00774_Freeze-Omni: A Smart and Low Latency Speech-to-speech Dialogue Model with Frozen LLM</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2411.00774_Freeze-Omni.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2411.00774_Freeze-Omni.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2411.00774_Freeze-Omni.html#model">2. Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2411.00774_Freeze-Omni.html#experience">3. Experience</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2411.00774_Freeze-Omni.html#conclusion-and-future-work">4. Conclusion and Future Work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html">2412.04468_NVILA: Efficient Frontier Visual Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html#approach">2. Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html#more-capabilities">4. More Capabilities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2412.04468_NVILA.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2502.13923_Qwen2.5-VL.html">2502.13923_Qwen2.5-VL</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2502.13923_Qwen2.5-VL.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2502.13923_Qwen2.5-VL.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2502.13923_Qwen2.5-VL.html#approach">2. Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2502.13923_Qwen2.5-VL.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2502.13923_Qwen2.5-VL.html#conclusion">4. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html">2503.20215_Qwen2.5-Omni Technical Report</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#archtecture">2. Archtecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#id2">3 é¢„è®­ç»ƒ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#post-training">4 åè®­ç»ƒï¼ˆPost-trainingï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html">2506.13642_Stream-Omni: Simultaneous Multimodal Interactions with Large Language-Vision-Speech Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#id4">3. Stream-Omni</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#results-and-analyses">5. Results and Analyses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#appendix-a-construction-of-instructomni">Appendix A Construction of InstructOmni</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni.html#appendix-b-construction-of-spokenvisit">Appendix B Construction of SpokenVisIT</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html">2506.13642_Stream-Omni: Simultaneous Multimodal Interactions with Large Language-Vision-Speech Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#id9">3 Stream-Omni</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#data-construction">3.2.1 Data Construction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#results-and-analyses">5 Results and Analyses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#limitations">Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#appendix-a-construction-of-instructomni">Appendix A Construction of InstructOmni</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#appendix-b-construction-of-spokenvisit">Appendix B Construction of SpokenVisIT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMMultimodals/2506.13642_Stream-Omni2.html#appendix-c-case-study">Appendix C Case Study</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM.html#embedding">Embedding æ¨¡å‹</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMEmbeddings/2506.05176_Qwen3_Embedding.html">2506.05176_Qwen3_Embedding: Advancing Text Embedding and Reranking Through Foundation Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMEmbeddings/2506.05176_Qwen3_Embedding.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMEmbeddings/2506.05176_Qwen3_Embedding.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMEmbeddings/2506.05176_Qwen3_Embedding.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMEmbeddings/2506.05176_Qwen3_Embedding.html#model-architecture">2 Model Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMEmbeddings/2506.05176_Qwen3_Embedding.html#models-training">3 Models Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMEmbeddings/2506.05176_Qwen3_Embedding.html#evaluation">4 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMEmbeddings/2506.05176_Qwen3_Embedding.html#settings">4.1 Settings è¯„ä¼°è®¾ç½®</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMEmbeddings/2506.05176_Qwen3_Embedding.html#main-results">4.2 Main Results ä¸»è¦ç»“æœ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMEmbeddings/2506.05176_Qwen3_Embedding.html#analysis">4.3 Analysis åˆ†æ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMEmbeddings/2506.05176_Qwen3_Embedding.html#id21">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMEmbeddings/2506.05176_Qwen3_Embedding.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMEmbeddings/2506.05176_Qwen3_Embedding.html#appendix-a-appendix">Appendix A Appendix</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM.html#id3">LLM éŸ³é¢‘</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2005.08100_Conformer.html">2005.08100_Conformer: Convolution-augmented Transformer for Speech Recognition</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2005.08100_Conformer.html#llm">LLMæ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2005.08100_Conformer.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2005.08100_Conformer.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2005.08100_Conformer.html#conformer-encoder">2 Conformer Encoder</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2005.08100_Conformer.html#experiments">3 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2005.08100_Conformer.html#conclusion">4 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html">2106.07447_HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#i-introduction">I Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#ii-method">II Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#iii-related-work">III Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#iv-experimental-details">IV Experimental Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#v-results">V Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2106.07447_HuBERT.html#vi-conclusion">VI Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html">2112.02418_YourTTS: Towards Zero-Shot Multi-Speaker TTS and Zero-Shot Voice Conversion for everyone</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#id1">å…³é”®æ¦‚å¿µ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#yourtts-model">2. YourTTS Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#results-and-discussion">4. Results and Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#zero-shot-voice-conversion">5. Zero-Shot Voice Conversion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#speaker-adaptation">6. Speaker Adaptation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2112.02418_YourTTS.html#conclusions-limitations-and-future-work">7. Conclusions, limitations and future work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html">2212.04356_whisper: Robust Speech Recognition via Large-Scale Weak Supervision</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#approach">2. Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#analysis-and-ablations">4. Analysis and Ablations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#limitations-and-future-work">6. Limitations and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#conclusions">7. Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#a-evaluation-datasets">A. Evaluation Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#b-compared-models">B Compared Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2212.04356_whisper.html#c-text-standardization">C. Text Standardization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html">2301.02111_Vall-E: Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html#background-speech-quantization">3. Background: Speech Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html#id9">4. VALL-E</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2301.02111_Vall-E.html#conclusion-limitations-and-future-work">6. Conclusion, Limitations, and Future Work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html">2303.03926_VALL-E_X: Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural Codec Language Modeling</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#cross-lingual-codec-language-model">3 Cross-Lingual Codec Language Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#vall-e-x-application">4. VALL-E X Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2303.03926_VALL-E_X.html#a-appendix">A. Appendix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2406.05370_VALL-E2.html">2406.05370_VALL-E2: Neural Codec Language Models are Human Parity Zero-Shot Text to Speech Synthesizers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2406.05370_VALL-E2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2406.05370_VALL-E2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2406.05370_VALL-E2.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2406.05370_VALL-E2.html#id5">3. VALL-E 2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2406.05370_VALL-E2.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2406.05370_VALL-E2.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2407.05407_CosyVoice.html">2407.05407_CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.05407_CosyVoice.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.05407_CosyVoice.html#instructions">1. Instructions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.05407_CosyVoice.html#cosyvoice-a-scalable-tts-model-using-supervised-semantic-tokens">2. CosyVoice: A Scalable TTS model using Supervised Semantic Tokens</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.05407_CosyVoice.html#dataset">3. Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.05407_CosyVoice.html#experimental-settings">4. Experimental Settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.05407_CosyVoice.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2407.10759_Qwen2-Audio.html">2407.10759_Qwen2-Audio Technical Report</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.10759_Qwen2-Audio.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.10759_Qwen2-Audio.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.10759_Qwen2-Audio.html#methodology">2. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.10759_Qwen2-Audio.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2407.10759_Qwen2-Audio.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html">2410.00037_Moshi: a speech-text foundation model for real-time dialogue</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#model">3.Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#datasets-and-training">4. Datasets and Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#safety">6.Safety</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2410.00037_Moshi.html#conclusion">7.Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2412.10117_CosyVoice2.html">2412.10117_CosyVoice2: Scalable Streaming Speech Synthesis with Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2412.10117_CosyVoice2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2412.10117_CosyVoice2.html#instroduction">1. Instroduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2412.10117_CosyVoice2.html#id5">2. CosyVoice 2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2412.10117_CosyVoice2.html#experimental-settings">3. Experimental Settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2412.10117_CosyVoice2.html#experimental-results">4. Experimental Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2412.10117_CosyVoice2.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html">2501.06282_MinMo: A Multimodal Large Language Model for Seamless Voice Interaction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#instruction">1.Instruction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#id9">3.MinMo</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#experiments">4.Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#conclusion">5.Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#limitations">6.Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2501.06282_MinMo.html#a-prompts-for-voice-understanding-tasks">A. Prompts for Voice Understanding Tasks</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2505.02707_Voila.html">2505.02707_Voila: Voice-Language Foundation Models for Real-Time Autonomous Interaction and Voice Role-Play</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.02707_Voila.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.02707_Voila.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.02707_Voila.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.02707_Voila.html#voila-voice-language-foundation-models">3. Voila: Voice-Language Foundation Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.02707_Voila.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.02707_Voila.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html">2505.17589_CosyVoice3: Towards In-the-wild Speech Generation via Scaling-up and Post-training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#id3">2.CosyVoice 3</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#the-multilingual-data-pipeline">3.The Multilingual Data Pipeline</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#experimental-settings">4.Experimental Settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#experimental-results">5.Experimental Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#conclusion">6.Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMAudio/2505.17589_CosyVoice3.html#limitations">7.Limitations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM.html#id4">LLM è§†é¢‘</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html">2301.12597_BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#bootstrapping-language-image-pre-training-with-frozen-image-encoders-and-large-language-models">Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#method">3 Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#experiment">4 Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#limitation">5 Limitation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2301.12597_BLIP-2.html#conclusion">6 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html">2308.01390_OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#id1">OpenFlamingo_ An Open-Source Framework for Training Large Autoregressive Vision-Language Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#related-work">2 Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#approach">3 Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#results">4 Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#discussion">5 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#appendix-a-extended-results">Appendix A Extended results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#appendix-b-additional-notes-on-filtering-mmc4">Appendix B Additional notes on filtering MMC4</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#appendix-c-synthetic-data-prompt">Appendix C Synthetic data prompt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMVideos/2308.01390_OpenFlamingo.html#appendix-d-image-credits">Appendix D Image credits</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM.html#llm-moe">LLM MoE</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMoEs/2408.15664_AUXILIARY-LOSS-FREE_LB.html">2408.15664_AUXILIARY-LOSS-FREE LOAD BALANCING STRATEGY FOR MIXTURE-OF-EXPERTS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMMoEs/2410.07490_MoDEM.html">2410.07490_MoDEM: Mixture of Domain Expert Models</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM.html#id5">å•†ä¸šæ¨¡å‹</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2303.08774_GPT4.html">2303.08774_GPT-4 Technical Report</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html">2312.11805_Gemini: A Family of Highly Capable Multimodal Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#model-architecture">2. Model Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#training-infrastructure">3. Training Infrastructure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#post-training-models">6. Post-Training Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#responsible-deployment">7. Responsible Deployment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2312.11805_Gemini.html#discussion-and-conclusion">8. Discussion and Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2403.05530_Gemini1.5.html">2403.05530_Gemini1.5: Unlocking multimodal understanding across millions of tokens of context</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html">2406.02430_Seed-TTS: A Family of High-Quality Versatile Speech Generation Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#method">2 Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#experiments">3 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#model-extensions">4 Model extensions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#model-applications-limitations-and-safety">5 Model applications, limitations, and safety</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#authors-alphabetical-order">6 Authors (alphabetical order)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2406.02430_Seed-TTS.html#acknowledgement">7 Acknowledgement</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html">2407.04675_Seed-ASR: Understanding Diverse Speech and Contexts with LLM-based Speech Recognition</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html#motivation">2 Motivation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html#methods">3 Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html#model-and-evaluation">4 Model and Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2407.04675_Seed-ASR.html#appendix-a-appendix">Appendix A Appendix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2503.20020_Gemini2.html">2503.20020_Gemini2: Gemini Robotics: Bringing AI into the Physical World</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2504.xxxxx_Seed-Thinking-v1.5.html">2504.xxxxx_Seed-Thinking-v1.5: Advancing Superb Reasoning Models with Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html">2505.07062_Seed1.5-VL Technical Report</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#id1">Seed1.5-VL Technical Report</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#architecture">2 Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#pre-training">3 Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#training-recipe">3.2 Training Recipe</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#post-training">4 Post-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#hybrid-reinforcement-learning">4.4 Hybrid Reinforcement Learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#training-infrastructure">5 Training Infrastructure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#evaluation">6 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#video-task-evaluation">6.1.3 Video Task Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#comparison-with-state-of-the-arts">6.3.2 Comparison with State-of-the-arts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#conclusion-and-next-steps">7 Conclusion and Next Steps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#contributions-and-acknowledgments">8 Contributions and Acknowledgments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#qualitative-examples">9 Qualitative examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#visual-reasoning-visual-pattern-recognition">9.7 Visual Reasoning_ Visual Pattern Recognition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#failure-cases-combinatorial-search-i">9.19 Failure Cases_ Combinatorial Search I</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#evaluation-details">10 Evaluation Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLMs/LLMCommercials/2505.07062_Seed1.5-VL.html#dream-1k">DREAM-1K</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../LLM_tech.html">LLM å‘¨è¾¹æŠ€æœ¯</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#framework">Framework</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html">1712.05889_Ray: A Distributed Framework for Emerging AI Applications</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#motivation-and-requirements">2. Motivation and Requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#programming-and-computation-model">3. Programming and Computation Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#architecture">4. Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#related-work">6 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#discussion-and-experiences">7 Discussion and Experiences</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1712.05889_Ray.html#conclusion">8. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html">1910.02054_DeepSpeed_ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#extended-introduction">1. Extended Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#where-did-all-the-memory-go">3 Where Did All the Memory Go?</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#zero-insights-and-overview">4 ZeRO: Insights and Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#deep-dive-into-zero-dp">5 Deep Dive into ZeRO-DP</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#deep-dive-into-zero-r">6 Deep Dive into ZeRO-R</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#communication-analysis-of-zero-dp">7 Communication Analysis of ZeRO-DP</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#communication-analysis-of-zero-r">8. Communication Analysis of ZeRO-R</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#step-towards-1-trillion-parameters">9. Step Towards 1 Trillion Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#implementation-and-evaluation">10. Implementation and Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.html#concluding-remarks">11. Concluding Remarks</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Frameworks/19XX_PyTorch.html">PyTorch: An Imperative Style, High-Performance Deep Learning Library</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Frameworks/20XX_Transformers.html">Transformers: State-of-the-Art Natural Language Processing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html">2210.XX_Ray v2 Architecture</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#architecture-overview">Architecture Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#object-management">Object Management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#task-management">Task Management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#resource-management-and-scheduling">Resource Management and Scheduling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#actor-management">Actor management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#global-control-service">Global Control Service</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#cluster-management">Cluster Management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2210.XX_Ray_v2.html#appendix">Appendix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html">2309.06180_vLLM: Efficient Memory Management for Large Language Model Serving with PagedAttention</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#id2">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#memory-challenges-in-llm-serving">3. Memory Challenges in LLM Serving</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#method">4. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#implementation">5. Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#evaluation">6. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#ablation-studies">7. Ablation Studies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2309.06180_vLLM.html#conclusion">10. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html">2312.07104_SGLangâ‡ï¸: Efficient Execution of Structured Language Model Programs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#openai-gpt-4">OpenAI GPT-4æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#qwen-plus">Qwen-Plusæ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#programming-model">2 Programming Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#efficient-kv-cache-reuse-with-radixattention">3 Efficient KV Cache Reuse with RadixAttention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#efficient-constrained-decoding-with-compressed-finite-state-machine">4 Efficient Constrained Decoding with Compressed Finite State Machine</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#efficient-endpoint-calling-with-api-speculative-execution">5 Efficient Endpoint Calling with API Speculative Execution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#evaluation">6 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#related-work">7 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#future-directions-and-conclusion">8 Future Directions and Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#acknowledgement">Acknowledgement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#appendix-a-additional-details-on-radixattention">Appendix A Additional Details on RadixAttention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#appendix-b-additional-details-on-compressed-finite-state-machine">Appendix B Additional Details on Compressed Finite State Machine</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#appendix-c-additional-experimental-setups-and-results">Appendix C Additional Experimental Setups and Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#appendix-d-compiler-mode">Appendix D Compiler Mode</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Frameworks/2312.07104_SGLang.html#appendix-d">Appendix D ç¼–è¯‘å™¨æ¨¡å¼</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#id2">å¤§æ¨¡å‹è°ƒä¼˜</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2101.00190_Prefix-Tuning.html">2101.00190_Prefix-Tuning: Optimizing Continuous Prompts for Generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2103.10385_p-tuning.html">2103.10385_p-tuning: GPT Understands, Too</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2104.08691_Prompt_Tuning.html">2104.08691_Prompt Tuning: The Power of Scale for Parameter-Efficient Prompt Tuning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2106.09685_LoRA.html">2106.09685_LoRA: Low-Rank Adaptation of Large Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2401.01335_Self-Play.html">2401.01335_Self-Play: Fine-Tuning Converts Weak Language Models to Strong Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2402.09353_DoRA.html">2402.09353_DoRA: Weight-Decomposed Low-Rank Adaptation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2402.12354_LoRA%2B.html">2402.12354_LoRA+: Efficient Low Rank Adaptation of Large Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2403.03507_GaLore.html">2403.03507_GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/FineTunes/2403.13372_LlamaFactory.html">2403.13372_LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/FineTunes/2403.13372_LlamaFactory.html#id2">ç«äº‰æ¡†æ¶</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/FineTunes/2403.13372_LlamaFactory.html#efficient-fine-tuning-techniques">3. Efficient Fine-Tuning Techniques</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/FineTunes/2403.13372_LlamaFactory.html#llamafactory-framework">4 LlamaFactory Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/FineTunes/2403.13372_LlamaFactory.html#conclusion-and-future-work">6 Conclusion and Future Work</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#id3">å¤§æ¨¡å‹ç¼–è¾‘</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html">2405.16720_LAW: Large Scale Knowledge Washing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#preliminary">3 Preliminary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#problem-setup">4 Problem Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#methodology">5 Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#experiments">6 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#id25">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#conclusion-limitation-and-future-work">7 Conclusion, Limitation, and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#ethics-statement">Ethics Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#reproducibility-statement">Reproducibility Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#appendix-a-mathematical-details-of-preliminary">Appendix A Mathematical Details of Preliminary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#appendix-b-implementation-details">Appendix B Implementation Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2405.16720_LAW.html#appendix-c-additional-experiments">Appendix C Additional Experiments</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.00487_SELF-PARAM.html">2410.00487_SELF-PARAM: Self-Updatable Large Language Models by Integrating Context into Model Parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.00487_SELF-PARAM.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.00487_SELF-PARAM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.00487_SELF-PARAM.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.00487_SELF-PARAM.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.00487_SELF-PARAM.html#methodology">3 Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.00487_SELF-PARAM.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.00487_SELF-PARAM.html#conclusion-and-future-work">5 Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.00487_SELF-PARAM.html#ethics-statement">Ethics Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.00487_SELF-PARAM.html#reproducibility-statement">Reproducibility Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.00487_SELF-PARAM.html#appendix-a-additional-settings">Appendix A Additional Settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.00487_SELF-PARAM.html#appendix-b-additional-experiments">Appendix B Additional Experiments</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html">2410.02355_AlphaEdit: Null-Space Constrained Knowledge Editing for Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#preliminary">2 Preliminary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#method">3 Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#experiment">4 Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#related-work">5 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#limitations-future-discussion">6 Limitations &amp; Future Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#ethics-statement">Ethics Statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#reproducibility">Reproducibility</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#acknowledgement">Acknowledgement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#appendix-a-experimental-setup">Appendix A Experimental Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#appendix-b-implementation-details-of-current-model-editing-related-proofs">Appendix B Implementation Details of Current Model Editing &amp; Related Proofs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#appendix-c-more-experimental-results">Appendix C More Experimental Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/ModelEditings/2410.02355_AlphaEdit.html#appendix-d-visualizing-the-counterfact-and-zsre-datasets-through-examples">Appendix D Visualizing the Counterfact and ZSRE Datasets Through Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#id4">åˆ†å¸ƒå¼æ¨¡å‹</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/1701.06538_MoE.html">1701.06538_MoE: Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/1806.03377_PipeDream.html">1806.03377_PipeDream: Fast and Efficient Pipeline Parallel DNN Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1806.03377_PipeDream.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1806.03377_PipeDream.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1806.03377_PipeDream.html#background-related-work">2. Background &amp; Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1806.03377_PipeDream.html#parallel-training-in-pipedream">3. Parallel Training in PipeDream</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1806.03377_PipeDream.html#implementation">4. Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1806.03377_PipeDream.html#evaluation">5. Evaluation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html">1811.06965_GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html#id2">æ”¶é›†</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html#the-gpipe-library">2. The GPipe Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html#performance-analyses">3. Performance Analyses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html#image-classification">4. Image Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html#massive-massively-multilingual-machine-translation">5. Massive Massively Multilingual Machine Translation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1811.06965_GPipe.html#design-features-and-trade-offs">6. Design Features and Trade-Offs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/1909.08053_Megatron-LM.html">1909.08053_Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1909.08053_Megatron-LM.html#id2">æ”¶é›†</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1909.08053_Megatron-LM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1909.08053_Megatron-LM.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1909.08053_Megatron-LM.html#background-and-challenges">2. Background and Challenges</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1909.08053_Megatron-LM.html#model-parallel-transformers">3. Model Parallel Transformers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html">19xx_PipeDream: Generalized Pipeline Parallelism for DNN Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html#id2">æ”¶é›†</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html#abstract">ABSTRACT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html#background-and-related-work">2. BACKGROUND AND RELATED WORK</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html#pipeline-parallelism">3. æµæ°´çº¿å¹¶è¡Œ(PIPELINE PARALLELISM)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html#id5">4. å®ç°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/1910_PipeDream2.html#id6">6. ç»“è®º</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/2006.09503_PipeDream-2BW.html">2006.09503_PipeDream-2BW: Memory-Efficient Pipeline-Parallel DNN Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2006.09503_PipeDream-2BW.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/2006.15704DataParallel.html">2006.15704_PyTorch Distributed: Experiences on Accelerating Data Parallel Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/2006.16668_GShard.html">2006.16668_GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/2104.04473_Megatron-LM2.html">2104.04473_Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2104.04473_Megatron-LM2.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html">2205.14135_FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#background">2 Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#flashattention-algorithm-analysis-and-extensions">3. FLASHATTENTION: Algorithm, Analysis, and Extensions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#limitations-and-future-directions">5. Limitations and Future Directions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#appendix-a-related-work">Appendix A Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#appendix-b-algorithm-details">Appendix B Algorithm Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#appendix-c-proofs">Appendix C Proofs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2205.14135_FlashAttention.html#appendix-d-extension-details">Appendix D Extension Details</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/2307.08691_FlashAttention2.html">2307.08691_FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2307.08691_FlashAttention2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2307.08691_FlashAttention2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2307.08691_FlashAttention2.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2307.08691_FlashAttention2.html#flashattention-2-algorithm-parallelism-and-work-partitioning">3. FlashAttention-2: Algorithm, Parallelism, and Work Partitioning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2307.08691_FlashAttention2.html#empirical-validation">4. Empirical Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Parallelism/2307.08691_FlashAttention2.html#discussion-and-future-directions">5. Discussion and Future Directions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Parallelism/normal.html">é€šç”¨</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#id5">LLM é‡åŒ–</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/0normal.html">é€šç”¨</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/0normal.html#id2">æ··åˆç²¾åº¦</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/0normal.html#id3">æµ®ç‚¹æ•°æ ¼å¼</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/0normal.html#weight-only-quantization">weight-only quantization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2110.02861_bitsandbytes.html">2110.02861_bitsandbytes: 8-bit Optimizers via Block-wise Quantization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2110.02861_bitsandbytes.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2110.02861_bitsandbytes.html#background">1. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2110.02861_bitsandbytes.html#bit-optimizers">2. 8-bit Optimizers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2110.02861_bitsandbytes.html#bit-vs-32-bit-optimizer-performance-for-common-benchmarks">3. 8-bit vs 32-bit Optimizer Performance for common Benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2110.02861_bitsandbytes.html#analysis">4. Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2110.02861_bitsandbytes.html#related-work">5. Related Work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html">2206.01861_ZeroQuant: Efficient and Affordable Post-Training Quantization for Large-Scale Transformers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#relative-work">2. Relative Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#background-and-challenges">3. Background and Challenges</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#methodology">4. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#results">5. Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#conclusions">6. Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#appendix-a-background">Appendix A Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.01861_ZeroQuant.html#appendix-d-details-about-system-optimization">Appendix D Details about System Optimization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html">2206.09557_LUT-GEMM: Quantized Matrix Multiplication based on LUTs for Efficient Inference in Large-Scale Generative Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#instructions">1. Instructions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#design-methodology-of-lut-gemm">3. Design Methodology of LUT-GEMM</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#experimental-results">4. Experimental results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#accelerating-quantized-opt-175b">5. Accelerating Quantized OPT-175B</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#appendix-a-llm-inference-latency-breakdown">Appendix A LLM Inference Latency Breakdown</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2206.09557_LUT-GEMM.html#appendix-b-detailed-implementation">Appendix B Detailed Implementation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html">2208.07339_LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#id1">ç›¸å…³å‚è€ƒ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#int8-matrix-multiplication-at-scale">3. Int8 Matrix Multiplication at Scale</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#emergent-large-magnitude-features-in-transformers-at-scale">4. Emergent Large Magnitude Features in Transformers at Scale</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#discussion-and-limitations">6. Discussion and Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#broader-impacts">7. Broader Impacts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2208.07339_LLM.int8.html#id17">å…¶ä»–</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html">2209.05433_FP8: FP8 Formats For Deep Learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html#aspects-of-fp8-usage-in-deep-learning">2. Aspects of FP8 Usage in Deep Learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html#fp8-binary-interchange-format">3. FP8 Binary Interchange Format</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html#id3">ç¤ºä¾‹è®²è§£</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html#empirical-results">4. Empirical Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2209.05433_FP8.html#conclusions">5. Conclusions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html">2210.17323_GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html#background">3. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html#the-gptq-algorithm">4. The GPTQ Algorithm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html#experimental-validation">5. Experimental Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2210.17323_GPTQ.html#summary-and-limitations">6. Summary and Limitations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html">2211.10438_SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#preliminaries">2. Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#review-of-quantization-difficulty">3. Review of Quantization Difficulty</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#id9">4. SmoothQuant</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#related-work">6. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#conclusion">7. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2211.10438_SmoothQuant.html#appendix-a-discussion-on-weight-only-quantization">Appendix A. Discussion on Weight-Only Quantization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html">2305.14314_QLoRA: Efficient Finetuning of Quantized LLMs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#id1">å…³é”®è¯</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#qlora-finetuning">3. QLoRA Finetuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#qlora-vs-standard-finetuning">4. QLoRA vs. Standard Finetuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#pushing-the-chatbot-state-of-the-art-with-qlora">5. Pushing the Chatbot State-of-the-art with QLoRA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#qualitative-analysis">6. Qualitative Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#related-work">7. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2305.14314_QLoRA.html#limitations-and-discussion">8. Limitations and Discussion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html">2306.00978_AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html#awq-activation-aware-weight-quantization">3. AWQ: Activation-aware Weight Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html#tinychat-mapping-awq-onto-edge-platforms">4. TinyChat: Mapping AWQ onto Edge Platforms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2306.00978_AWQ.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Quantizations/2309.05516_AutoRound.html">2309.05516_AutoRound: Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2309.05516_AutoRound.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2309.05516_AutoRound.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2309.05516_AutoRound.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2309.05516_AutoRound.html#methodology">3. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2309.05516_AutoRound.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Quantizations/2309.05516_AutoRound.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#id6">å›¾ç¥ç»ç½‘ç»œæ¨¡å‹</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html">1812.08434_GNNs: Graph Neural Networks: A Review of Methods and Applications</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#id1">è®ºæ–‡è§£è¯»</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#id4">ç»“è®º</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#general-design-pipeline-of-gnns">2. General design pipeline of GNNs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#instantiations-of-computational-modules">3. Instantiations of computational modules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#variants-considering-graph-type-and-scale-gnn">4. Variants considering graph type and scale(ä¸åŒå›¾ç±»å‹ä¸è§„æ¨¡çš„GNNå˜ä½“)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#variants-for-different-training-settings">5. Variants for different training settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#a-design-example-of-gnn">6. A design example of GNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#analyses-of-gnns">7. Analyses of GNNs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#applications">8. Applications</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#vs">âœ… æ€»ç»“è¡¨æ ¼ï¼ˆå›¾åƒ vs æ–‡æœ¬ï¼‰ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#open-problems">9. Open problems</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#conclusion">10. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/Graphs/1812.08434_GNNs.html#appendix-a-datasets">Appendix A. Datasets</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#id7">LLM å®‰å…¨</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/Securitys/2312.06674_Llama_Guard.html">2312.06674_Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#id8">LLMå¼ºåŒ–å­¦ä¹ </a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/RLs/1703.03864_EvolutionStrategies.html">1703.03864_Evolution Strategies: as a Scalable Alternative to Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html">2305.14387_AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#background-problem-statement">2 Background &amp; problem statement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#id14">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#constructing-the-alpacafarm">3 Constructing the AlpacaFarm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#validating-the-alpacafarm-simulator">4 Validating the AlpacaFarm simulator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#benchmarking-reference-methods-on-the-alpacafarm">5 Benchmarking reference methods on the AlpacaFarm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#related-work">6 Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#limitations-and-future-directions">7 Limitations and future directions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#acknowledgments-and-disclosure-of-funding">Acknowledgments and Disclosure of Funding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#appendix-a-reference-lpf-methods-on-alpacafarm">Appendix A Reference LPF methods on AlpacaFarm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#appendix-b-details-on-methods-implementation-and-hyperparameters">Appendix B Details on methods implementation and hyperparameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#appendix-c-pairwise-preference-simulation">Appendix C Pairwise preference simulation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#id36"><strong>æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#appendix-d-details-on-human-data-collection">Appendix D Details on human data collection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#appendix-e-additional-results">Appendix E Additional results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2305.14387_AlpacaFarm.html#appendix-f-additional-analysis-on-training-and-evaluation-instructions">Appendix F Additional Analysis on Training and Evaluation Instructions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html">2504.02495_DeepSeek-GRM: Inference-Time Scaling for Generalist Reward Modeling</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#preliminaries">2. Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#self-principled-critique-tuning-spct">3. Self-Principled Critique Tuning (SPCT)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#inference-time-scaling-with-spct">4. Inference-Time Scaling with SPCT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#results-on-reward-modeling-benchmarks">5. Results on Reward Modeling Benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#related-work">6. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#conclusion-and-future-work">7. Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#a-additional-related-work">A. Additional Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#b-limitations-and-future-directions">B. Limitations and Future Directions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/RLs/2504.02495_DeepSeek_GRM.html#g-prompt-templates">G. Prompt Templates</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/RLs/2504.13958_ToolRL.html">2504.13958_ToolRL: Reward is All Tool Learning Needs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../LLM_tech.html#id9">å…¶ä»–</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html">2203.02155_Training language models to follow instructions with human feedback(InstructGPT)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#related-work">2. Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#methods-and-experimental-details">3. Methods and experimental details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#results">4. Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#discussion">5. Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#appendix-a-additional-prompt-data-details">Appendix A Additional prompt data details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#appendix-b-additional-human-data-collection-details">Appendix B Additional human data collection details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#appendix-c-additional-model-details">Appendix C Additional model details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2203.02155_InstructGPT.html#appendix-d-automatic-evaluation-details">Appendix D Automatic evaluation details</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/others/2305.20050_LetsVerifyStepbyStep.html">2305.20050_Letâ€™s Verify Step by Step</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2305.20050_LetsVerifyStepbyStep.html#id2">1. ç ”ç©¶èƒŒæ™¯</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2305.20050_LetsVerifyStepbyStep.html#id3">2. ç›‘ç£æ–¹æ³•å¯¹æ¯”</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2305.20050_LetsVerifyStepbyStep.html#id4">3. æ ¸å¿ƒå‘ç°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2305.20050_LetsVerifyStepbyStep.html#id5">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/others/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html">2408.03314_Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html#how-to-scale-test-time-computation-optimally">3. How to Scale Test-Time Computation Optimally</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html#scaling-test-time-compute-via-verifiers">5. Scaling Test-Time Compute via Verifiers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html#refining-the-proposal-distribution">6. Refining the Proposal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html#id7">å…¶ä»–</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html">2412.14135_Scaling of Search and Learning: A Roadmap to Reproduce o1 from Reinforcement Learning Perspective</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#fromgpt">FromGPT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#id2">3. Policy Initialization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#id3">4. Reward Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#id5">5. Search</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#id8">6. Learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#open-source-o1-project">7 Open-source o1 Project</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.html#future-directions">8. Future Directions</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../ML.html">æœºå™¨å­¦ä¹ </a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../ML.html#id3">è¿‘é‚»æœç´¢</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ANNs/10xx.xxxxx_PQ.html">10xx.xxxxx_PQ: Product Quantization for Nearest Neighbor Search</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/10xx.xxxxx_PQ.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/10xx.xxxxx_PQ.html#from-deepseek">From Deepseek</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/10xx.xxxxx_PQ.html#id6">From Deepseek å…¨æ–‡æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/10xx.xxxxx_PQ.html#id7">å‘¨è¾¹æ¦‚å¿µ</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ANNs/1603.09320_HNSW.html">1603.09320_HNSW: Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/1603.09320_HNSW.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/1603.09320_HNSW.html#from-deepseek">From Deepseek</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/1603.09320_HNSW.html#id10">From Deepseek å…¨æ–‡æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ANNs/2007.00808_ANCE.html">2007.00808_ANCE: Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/2007.00808_ANCE.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/2007.00808_ANCE.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/2007.00808_ANCE.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/2007.00808_ANCE.html#preliminaries">2 Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/2007.00808_ANCE.html#analyses-on-the-convergence-of-dense-retrieval-training">3 Analyses on The Convergence of Dense Retrieval Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/2007.00808_ANCE.html#approximate-nearest-neighbor-noise-contrastive-estimation">4 Approximate Nearest Neighbor Noise Contrastive Estimation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/2007.00808_ANCE.html#experimental-methodologies">5 Experimental Methodologies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/2007.00808_ANCE.html#evaluation-results">6 Evaluation Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/2007.00808_ANCE.html#related-work">7 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/2007.00808_ANCE.html#conclusion">8 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/2007.00808_ANCE.html#appendix-a-appendix">Appendix A Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ANNs/2007.00808_ANCE.html#id31">æ€»ä½“æ€»ç»“</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../ML.html#embedding">Embedding</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/Embeddings/1603.09320_HNSW.html">1603.09320_HNSW: Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/1603.09320_HNSW.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/1603.09320_HNSW.html#from-deepseek">From Deepseek</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html">2004.04906_DPR: Dense Passage Retrieval for Open-Domain Question Answering</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#background">2 Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#dense-passage-retriever-dpr">3 Dense Passage Retriever (DPR)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#experimental-setup">4 Experimental Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#experiments-passage-retrieval">5 Experiments: Passage Retrieval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#experiments-question-answering">6 Experiments: Question Answering</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#related-work">7 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#conclusion">8 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#acknowledgments">Acknowledgments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#appendix-a-distant-supervision">Appendix A Distant Supervision</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#appendix-b-alternative-similarity-functions-triplet-loss">Appendix B Alternative Similarity Functions &amp; Triplet Loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#appendix-c-qualitative-analysis">Appendix C Qualitative Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2004.04906_DPR.html#appendix-d-joint-training-of-retriever-and-reader">Appendix D Joint Training of Retriever and Reader</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/Embeddings/2205.12035_RetroMAE.html">2205.12035_RetroMAE: Pre-Training Retrieval-oriented Language Models Via Masked Auto-Encoder</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.12035_RetroMAE.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.12035_RetroMAE.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.12035_RetroMAE.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.12035_RetroMAE.html#related-works">2 Related works</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.12035_RetroMAE.html#methodology">3 Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.12035_RetroMAE.html#experimental-studies">4 Experimental Studies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.12035_RetroMAE.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.12035_RetroMAE.html#limitations">6 Limitations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html">2205.13147_MRL: Matryoshka Representation Learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#deepseek">DeepSeek æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#matryoshka-representation-learning">3 Matryoshka Representation Learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#applications">4 Applications</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#further-analysis-and-ablations">5 Further Analysis and Ablations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#discussion-and-conclusions">6 Discussion and Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#acknowledgments">Acknowledgments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#appendix-a-code-for-matryoshka-representation-learning">Appendix A Code for Matryoshka â€‹Representation â€‹Learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#appendix-b-datasets">Appendix B Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#appendix-c-matryoshka-representation-learning-model-training">Appendix C Matryoshka Representation Learning Model Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#appendix-d-classification-results">Appendix D Classification Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#appendix-e-image-retrieval">Appendix E Image Retrieval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#appendix-f-adaptive-retrieval">Appendix F Adaptive Retrieval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#appendix-g-few-shot-and-sample-efficiency">Appendix G Few-shot and Sample Efficiency</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#appendix-h-robustness-experiments">Appendix H Robustness Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#appendix-i-in-practice-costs">Appendix I In Practice Costs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#appendix-j-analysis-of-model-disagreement">Appendix J Analysis of Model Disagreement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/Embeddings/2205.13147_MRL.html#appendix-k-ablation-studies">Appendix K Ablation Studies</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../ML.html#ml-vision">ML Vision</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/1506.02640_YOLO.html">1506.02640_You Only Look Once: Unified, Real-Time Object Detection</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/1506.02640_YOLO.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/1612.08242_YOLO9000.html">1612.08242_YOLO9000: Better, Faster, Stronger</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/1612.08242_YOLO9000.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/1804.02767_YOLOv3.html">1804.02767_YOLOv3</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2004.10934_YOLOv4.html">2004.10934_YOLOv4: Optimal Speed and Accuracy of Object Detection</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2004.10934_YOLOv4.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2205.00159_SVTR.html">2205.00159_SVTR: Scene Text Recognition with a Single Visual Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2205.00159_SVTR.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2205.00159_SVTR.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2205.00159_SVTR.html#method">2. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2205.00159_SVTR.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2205.00159_SVTR.html#conclusion">4. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2207.02696_YOLOv7.html">2207.02696_YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2207.02696_YOLOv7.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2303.05499_GroundingDINO.html">Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2304.08485_VisualInstructionTuning.html">2304.08485_Visual Instruction Tuning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2402.13616_YOLOv9.html">2402.13616_YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2402.13616_YOLOv9.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2405.14458_YOLOv10.html">2405.14458_YOLOv10: Real-Time End-to-End Object Detection</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2405.14458_YOLOv10.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html">2411.15858_SVTRv2: CTC Beats Encoder-Decoder Models in Scene Text Recognition</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#id1">å®šä¹‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#methods">3. Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#conclusion">5. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/MLVisions/2411.15858_SVTRv2.html#more-detail-of-real-world-datasets">8. More detail of real-world datasets</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../ML.html#ml">ML</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2108.00941_Human-in-the-loop.html">2108.00941_Human-in-the-loop: A Survey of Human-in-the-loop for Machine Learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ML_normals/2108.00941_Human-in-the-loop.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ML_normals/2108.00941_Human-in-the-loop.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ML_normals/2108.00941_Human-in-the-loop.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ML_normals/2108.00941_Human-in-the-loop.html#data-processing">2 Data Processing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ML_normals/2108.00941_Human-in-the-loop.html#model-training-and-inference">3 Model Training and Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ML_normals/2108.00941_Human-in-the-loop.html#system-construction-and-application">4 System construction and Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ML_normals/2108.00941_Human-in-the-loop.html#discussion-and-future-directions">5 Discussion and Future Directions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ML_normals/2108.00941_Human-in-the-loop.html#conclusion">6 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2112.09332_WebGPT.html">2112.09332_WebGPT: Browser-assisted question-answering with human feedback</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2203.11147_GopherCite.html">2203.11147_GopherCite: Teaching language models to support answers with verified quotes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2304.09848_Generative_Search.html">2304.09848_Generative_Search: Evaluating Verifiability in Generative Search Engines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2305.14251_FActScore.html">2305.14251_FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2305.14627_ALCE.html">2305.14627_ALCE: Enabling Large Language Models to Generate Text with Citations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ML_normals/2305.14627_ALCE.html#nli">NLI åœ¨å¼•ç”¨è´¨é‡è¯„ä¼°ä¸­çš„åº”ç”¨</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../MLs/ML_normals/2305.14627_ALCE.html#prompt">è®ºæ–‡ä¸­ç”¨çš„prompt</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2307.02185_Citation.html">2307.02185_Citation: A Key to Building Responsible and Accountable Large Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../MLs/ML_normals/2307.16883_HAGRID.html">2307.16883_HAGRID: A Human-LLM Collaborative Dataset for Generative Information-Seeking with Attribution</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../Agent.html">AI Agent</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Agent.html#agent">é€šç”¨ Agent</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2210.03629_ReAct.html">2210.03629_ReAct</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2303.08268_Chat-with-the-Environment.html">2303.08268_Chat-with-the-Environment</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2303.08268_Chat-with-the-Environment.html#id2">æ­£æ–‡</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2303.11366_Reflexion.html">2303.11366_Reflexion: Language Agents with Verbal Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2303.16434_TaskMatrix.AI.html">2303.16434_TaskMatrix.AI</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2303.16434_TaskMatrix.AI.html#id2">å¤§è„‘</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2303.16434_TaskMatrix.AI.html#id3">æ¥å£å¹³å°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2303.16434_TaskMatrix.AI.html#api">API é€‰æ‹©å™¨</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2304.03442_Generative-Agents.html">2304.03442_Generative-Agents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2304.03442_Generative-Agents.html#generative-agent-architecture">Generative Agent Architecture</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2307.07924_ChatDev.html">2307.07924_ChatDev: Communicative Agents for Software Development</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2308.00352_MetaGPT.html">2308.00352_MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2308.04026_AgentSims.html">2308.04026_AgentSims: An Open-Source Sandbox for Large Language Model Evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2308.08155_AutoGen.html">2308.08155_AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2308.10848_AgentVerse.html">2308.10848_AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2308.10848_AgentVerse.html#id2">ç†å¿µ</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2310.06117_Step-Back.html">2310.06117_Step-Back: Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html">2312.04511_LLMCompiler: An LLM Compiler for Parallel Function Calling</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#latency-optimization-in-llms-llms">2.1. Latency Optimization in LLMsï¼ˆLLMsçš„å»¶è¿Ÿä¼˜åŒ–ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#plan-and-solve-strategy">2.2. Plan and Solve Strategyï¼ˆè®¡åˆ’ä¸æ±‚è§£ç­–ç•¥ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#tool-augmented-llms-llms">2.3. Tool-Augmented LLMsï¼ˆå·¥å…·å¢å¼ºçš„LLMsï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#methodology">3. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#function-calling-planner">3.1. Function Calling Plannerï¼ˆåŠŸèƒ½è°ƒç”¨è§„åˆ’å™¨ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#task-fetching-unit">3.2. Task Fetching Unitï¼ˆä»»åŠ¡è·å–å•å…ƒï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#executor">3.3. Executorï¼ˆæ‰§è¡Œå™¨ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#dynamic-replanning">3.4. åŠ¨æ€é‡è§„åˆ’ï¼ˆDynamic Replanningï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#llmcompiler-details">4.LLMCompiler Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#user-supplied-information">4.1. ç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼ˆUser-Supplied Informationï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#planner-streamed-planner">4.2. æµå¼Plannerï¼ˆStreamed Plannerï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#results">5. Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#conclusions">6. Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#acknowledgements">è‡´è°¢ï¼ˆAcknowledgementsï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#a-accuracy-analysis-react-vs-llmcompiler">A. Accuracy Analysis: ReAct vs. LLMCompiler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#b-failure-case-analysis-of-llmcompiler">B. Failure Case Analysis of LLMCompiler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#c-related-work">C. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#d-experimental-details">D. Experimental Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#e-analysis">E. Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#id42"><strong>æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#f-additional-discussions-about-related-works">F. Additional Discussions about Related Works</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#g-user-supplied-examples-for-llmcompiler-configuration">G. User-Supplied Examples for LLMCompiler Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#g-1-movie-recommendation-example-prompts">G.1 ç”µå½±æ¨èç¤ºä¾‹æç¤ºè¯­ï¼ˆMovie Recommendation Example Promptsï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#g-2-24-game-of-24-example-prompts">G.2 24ç‚¹æ¸¸æˆç¤ºä¾‹æç¤ºè¯­ï¼ˆGame of 24 Example Promptsï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#h-pre-defined-llmcompiler-planner-prompts">H. Pre-defined LLMCompiler Planner Prompts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#i-parallelqa-benchmark-generation">I. ParallelQA Benchmark Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#j-details-of-the-game-of-24-and-the-tree-of-thoughts-approach">J. Details of the Game of 24 and the Tree-of-Thoughts Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2312.04511_LLMCompiler.html#k-details-of-webshop-experiments">K. Details of WebShop Experiments</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2402.18679_MetaGPT_DI.html">2402.18679_MetaGPT_DI: Data Interpreter: An LLM Agent For Data Science</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2402.18679_MetaGPT_DI.html#introduction">INTRODUCTION</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2407.07061_IoA.html">2407.07061_IoA: Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2407.07061_IoA.html#overview-of-ioa">2.1 OVERVIEW OF IOA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2407.07061_IoA.html#architecture-of-ioa">2.2 ARCHITECTURE OF IOA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2407.07061_IoA.html#key-mechanisms">2.3 KEY MECHANISMS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2407.07061_IoA.html#putting-it-all-together">2.5 Putting It All Together</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2408.08435_ADAS.html">2408.08435_ADAS: Automated Design of Agentic Systems</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2408.08435_ADAS.html#prompt">Prompt</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2410.10762_AFlow.html">2408.08435_ADAS: Automating Agentic Workflow Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2410.10762_AFlow.html#introduce">Introduce</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2410.10762_AFlow.html#preliminary">PRELIMINARY</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2410.17238_SELA.html">2410.17238_SELA: Tree-Search Enhanced LLM Agents for Automated Machine Learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2410.17238_SELA.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2410.17238_SELA.html#related-works">2 Related Works</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2410.17238_SELA.html#method">3 Method</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2410.21012_FACT.html">2410.21012_FACT: Examining the Effectiveness of Iterative Context Rewriting for Multi-fact Retrieval</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2410.21012_FACT.html#introduce">Introduce</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2504.01990_foundation-agents.html">2504.01990_Advances and Challenges in Foundation Agents</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_normals/2506.12508_AgentOrchestra.html">2506.12508_AgentOrchestra: A Hierarchical Multi-Agent Framework for General-Purpose Task Solving</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2506.12508_AgentOrchestra.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2506.12508_AgentOrchestra.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2506.12508_AgentOrchestra.html#agentorchestra">3.AgentOrchestra</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_normals/2506.12508_AgentOrchestra.html#experiments">4.Experiments</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Agent.html#agent-aios">è§†è§‰ Agent&amp;AIOS</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2108.03353_Screen2Words.html">2108.03353_ Screen2Words: Automatic Mobile UI Summarization with Multimodal Learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2108.03353_Screen2Words.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2108.03353_Screen2Words.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2108.03353_Screen2Words.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2108.03353_Screen2Words.html#dataset-creation">3. Dataset Creation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2108.03353_Screen2Words.html#model-design">4. Model Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2108.03353_Screen2Words.html#id3">å…¶å®ƒ</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html">2209.08199_ScreenQA: Large-Scale Question-Answer Pairs over Mobile App Screenshots</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#problem-setting-tasks-and-metrics">3. Problem Setting: Tasks and Metrics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#data-annotation">4. Data Annotation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#dataset-analysis">5. Dataset Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#experiments-and-baselines">6. Experiments and Baselines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#conclusion">7. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#limitations">8. Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#ethical-considerations">9. Ethical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#a-data-annotation-details">A. Data Annotation Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2209.08199_ScreenQA.html#b-data-examples">B. Data Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html">2212.06817_RT-1: ROBOTICS TRANSFORMER FOR REAL-WORLD CONTROL AT SCALE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#abstract">ABSTRACT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#preliminaries">3. Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#system-overview">4. System Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#rt-1-robotics-transformer">5. RT-1: ROBOTICS TRANSFORMER</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#experiments">6. EXPERIMENTS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#conclusions-limitations-and-future-work">7. CONCLUSIONS, LIMITATIONS AND FUTURE WORK</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#b-model-card">B. MODEL CARD</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#c-model-and-data">C. MODEL AND DATA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2212.06817_RT-1.html#d-experiments">D. EXPERIMENTS</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2312.13771_AppAgent.html">2312.13771_AppAgent: Multimodal Agents as Smartphone Users</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2312.13771_AppAgent.html#environment-and-action-space">3.1 Environment and Action Space</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2312.13771_AppAgent.html#exploration-phase">3.2 Exploration Phase</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2312.13771_AppAgent.html#deployment-phase">3.3 Deployment Phase</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html">2401.10935_SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#related-work">2. Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#approach">3. Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#screenspot-a-grounding-benchmark">4. ScreenSpot: A Grounding Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#limitations">Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#ethical-considerations">Ethical considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#a-details-of-seeclick-pre-training">A. Details of SeeClick Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#b-screenspot-annotation-evaluation">B ScreenSpot Annotation &amp; Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2401.10935_SeeClick.html#c-downstream-agent-tasks">C. Downstream Agent Tasks</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html">2402.04615_ScreenAI: A Vision-Language Model for UI and Infographics Understanding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#methodology">2. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#automatic-data-generation">3. Automatic data generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#data-mixtures">4. Data Mixtures</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#experiments-and-results">5. Experiments and Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#conclusions">6. Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#a-definitions-of-metrics">A Definitions of Metrics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#b-screen-schema-examples">B. Screen Schema Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#c-prompts-for-llm-generated-content">C. Prompts For LLM Generated Content</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#d-screen-navigation-generated-examples">D. Screen Navigation Generated Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#f-screenqa-short-answers-generation">F. ScreenQA Short Answers Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#g-complex-question-answering-datasets">G. Complex Question Answering Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.04615_ScreenAI.html#h-new-benchmarks-repositories">H. New Benchmarks Repositories</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html">2402.07939_UFO: A UI-Focused Agent for Windows OS Interaction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html#the-design-of-ufo">3.The Design of UFO</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html#experiment">4.Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html#limitations-lessons-learned">5.Limitations &amp; Lessons Learned</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2402.07939_UFO.html#conclusion">6.Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2403.16971_AIOS.html">2403.16971_AIOS: LLM Agent Operating System</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2403.16971_AIOS.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2403.16971_AIOS.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2403.16971_AIOS.html#the-architecture-of-aios">2. The Architecture of AIOS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2403.16971_AIOS.html#aios-kernel">3. AIOS Kernel</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2403.16971_AIOS.html#evaluation">4 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2403.16971_AIOS.html#appendix-e-discussion">Appendix E Discussion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2406.01014_Mobile-Agent-v2.html">2406.01014_Mobile-Agent-v2: Mobile Device Operation Assistant with Effective Navigation via Multi-Agent Collaboration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2411.00820_AutoGLM.html">2411.00820_AutoGLM: Autonomous Foundation Agents for GUIs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2411.00820_AutoGLM.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2411.00820_AutoGLM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2411.00820_AutoGLM.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2411.00820_AutoGLM.html#autoglm-techniques-and-insights">2 AutoGLM: Techniques and Insights</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2411.00820_AutoGLM.html#results">3 Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2411.00820_AutoGLM.html#id14">3.1 åœ¨ Web ä¸Šçš„è¯„ä¼°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2411.00820_AutoGLM.html#id15">3.2 åœ¨ Android ä¸Šçš„è¯„ä¼°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2411.00820_AutoGLM.html#conclusion">4 Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2411.02059_TableGPT2.html">2411.02059_TableGPT2: A Large Multimodal Model with Tabular Data Integration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2411.02059_TableGPT2.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html">2501.11733_Mobile-Agent-E: Self-Evolving Mobile Assistant for Complex Tasks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#mobile-agent-e">2. Mobile-Agent-E</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#results">4. Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#conclusion-and-future-work">6. Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-a-full-trajectory-comparison-example-with-previous-sota">Appendix A Full Trajectory Comparison Example with Previous SOTA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-b-error-recovery-with-escalation-to-manager">Appendix B Error Recovery with Escalation to Manager</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-c-remaining-limitations">Appendix C Remaining Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-d-all-tasks-in-mobile-eval-e-benchmark">Appendix D All Tasks in Mobile-Eval-E Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-e-atomic-operation-space">Appendix E Atomic Operation Space</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-f-full-list-of-self-evolved-shortcuts">Appendix F Full list of Self-Evolved Shortcuts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-g-full-list-of-self-evolved-tips">Appendix G Full list of Self-Evolved Tips</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html">2501.12326_UI-TARS: Pioneering Automated GUI Interaction with Native Agents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html#evolution-path-of-gui-agents">2. Evolution Path of GUI Agents</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html#core-capabilities-of-native-agent-model">3. Core Capabilities of Native Agent Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html#ui-tars">4. UI-TARS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html#experiment">5. Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2501.12326_UI-TARS.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2502.14282_PC-Agent.html">2502.14282_PC-Agent: A Hierarchical Multi-Agent Collaboration Framework for Complex Task Automation on PC</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2502.14282_PC-Agent.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2502.14282_PC-Agent.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2502.14282_PC-Agent.html#pc-agent">2. PC-Agent</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2502.14282_PC-Agent.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2502.14282_PC-Agent.html#related-work">4. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2502.14282_PC-Agent.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html">2504.14603_UFO2: The Desktop AgentOS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#background">2.Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#system-design-of-ufo2">3.System Design of UFO2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#picture-in-picture-interface">4.Picture-in-Picture Interface</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#implementation-and-specialized-engineering-design">5.Implementation and Specialized Engineering Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#evaluation">6.Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#discussion-future-work">7.Discussion &amp; Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#related-work">8.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2504.14603_UFO2.html#conclusion">9.Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Agent_Visions/2508.04037_SEA.html">2508.04037_SEA: Self-Evolution Agent with Step-wise Reward for Computer Use</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2508.04037_SEA.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2508.04037_SEA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2508.04037_SEA.html#i-introduction">I Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2508.04037_SEA.html#i">I å¼•è¨€</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2508.04037_SEA.html#ii-related-works">II Related Works</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2508.04037_SEA.html#id7"><strong>II Related Works</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2508.04037_SEA.html#id8">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2508.04037_SEA.html#iii-method">III Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2508.04037_SEA.html#id9">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2508.04037_SEA.html#iv-experiments">IV Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2508.04037_SEA.html#iv">IV å®éªŒ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2508.04037_SEA.html#v-conclusion">V Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Agent_Visions/2508.04037_SEA.html#v">V ç»“è®º</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Agent.html#tools">Tools</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Tools/2205.00445_MRKL.html">2205.00445_MRKL</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Tools/2302.04761_Toolformer.html">2302.04761_Toolformer: Language Models Can Teach Themselves to Use Tools</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Tools/2303.17580_HuggingGPT.html">2303.17580_HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html">2307.16789_ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#llm">LLMæ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#dataset-construction">2 Dataset Construction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#experiments">3 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#related-work">4 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#conclusion">5 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../Agents/Tools/2307.16789_ToolLLM.html#appendix-a-implementation-details">Appendix A Implementation Details</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../Agent.html#agi">AGI</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/AGIs/1905.10985_AI-GA.html">1905.10985_AI-GA: AI-generating algorithms, an alternate paradigm for producing general artificial intelligence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../Agents/AGIs/2408.06292_AI-Scientist.html">2408.06292_The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../RAG.html">RAG</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2005.11401_RAG_for_KI_NLP_task.html">2005.11401_Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html">2312.10997_Retrieval-Augmented Generation for Large Language Models: A Survey</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#ii-overview-of-rag">II. Overview of RAG</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#ii-a-naive-rag">II-A Naive RAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#ii-b-advanced-rag">II-B Advanced RAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#ii-c-modular-rag">II-C Modular RAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#ii-d-rag-vs-fine-tuning">II-D RAG vs Fine-tuning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iii-retrieval">III. Retrieval</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iii-a-retrieval-source">III-A Retrieval Source</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iii-b-indexing-optimization">III-B Indexing Optimization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iii-c-query-optimization">III-C Query Optimization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iii-d-embedding">III-D Embedding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iii-e-adapter">III-E Adapter</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iv-generation">IV. Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iv-a-context-curation">IV-A Context Curation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#iv-b-llm-fine-tuning">IV-B LLM Fine-tuning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#v-augmentation-process-in-rag">V. Augmentation process in RAG</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#v-a-iterative-retrieval">V-A Iterative Retrieval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#v-b-recursive-retrieval">V-B Recursive Retrieval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#v-c-adaptive-retrieval">V-C Adaptive Retrieval</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vi-task-and-evaluation">VI. Task and Evaluation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vi-a-downstream-task">VI-A Downstream Task</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vi-b-evaluation-target">VI-B Evaluation Target</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vi-c-evaluation-aspects">VI-C Evaluation Aspects</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vi-d-evaluation-benchmarks-and-tools">VI-D Evaluation Benchmarks and Tools</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vii-discussion-and-future-prospects">VII. Discussion and Future Prospects</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vii-a-rag-vs-long-context">VII-A RAG vs Long Context</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vii-b-rag-robustness">VII-B RAG Robustness</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vii-c-hybrid-approaches">VII-C Hybrid Approaches</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vii-d-scaling-laws-of-rag">VII-D Scaling laws of RAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vii-e-production-ready-rag">VII-E Production-Ready RAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2312.10997_RAG_for_LLM.html#vii-f-multi-modal-rag">VII-F Multi-modal RAG</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2401.15884_CRAG.html">2401.15884_CRAG: Corrective Retrieval Augmented Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2403.14403_Adaptive-RAG.html">2403.14403_Adaptive-RAG</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html">2404.12457_RAGCache: Efficient Knowledge Caching for Retrieval-Augmented Generation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id1">æ€»ç»“</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#introduction">1. Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id2"><strong>1. å¼•è¨€æ¦‚è¿°</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id3"><strong>2. ç°æœ‰å·¥ä½œä¸å±€é™</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#ragcache"><strong>3. RAGCacheç³»ç»Ÿ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id4"><strong>4. å®éªŒç»“æœ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id5"><strong>5. ä¸»è¦è´¡çŒ®</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#background">2. Background</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#rag-system-characterization">3. RAG System Characterization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id6">ä¸€ã€æ€§èƒ½ç“¶é¢ˆåˆ†æ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id7">äºŒã€ä¼˜åŒ–æœºä¼šåˆ†æ â€”â€” ç¼“å­˜ä¸­é—´çŠ¶æ€</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id8">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#ragcache-overview">4. RAGCache Overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id9">ä¸»è¦å†…å®¹æ€»ç»“å¦‚ä¸‹ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id13">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#ragcache-design">5. RAGCache Design</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#cache-structure-and-replacement-policy">5.1. Cache Structure and Replacement Policy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#cache-aware-reordering">5.2. Cache-aware Reordering</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#dynamic-speculative-pipelining">5.3 åŠ¨æ€æ¨æµ‹æµæ°´çº¿ï¼ˆDynamic Speculative Pipeliningï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id27">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#implementation">6. Implementation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id28">ç³»ç»Ÿå®ç°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#pipelined-vector-search">å‘é‡æœç´¢ä¼˜åŒ–ï¼ˆPipelined Vector Searchï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#fault-tolerance">å®¹é”™æœºåˆ¶ï¼ˆFault Toleranceï¼‰</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#evaluation">7. Evaluation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id29">7.1 æ€»ä½“æ€§èƒ½</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id30">7.2 é€šç”¨è®¾ç½®ä¸‹çš„æ¡ˆä¾‹ç ”ç©¶</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id31">7.3 æ¶ˆèç ”ç©¶</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id32">7.4 è°ƒåº¦æ—¶é—´</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#id33">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#discussion">8. Discussion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#related-work">9. Related Work</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.12457_RAGCache.html#conclusion">10. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html">2404.16130_GraphRAG: From Local to Global: A GraphRAG Approach to Query-Focused Summarization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id1">æ€»ç»“</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#introduction">1 Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#background">2 Background</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#rag">2.1 RAGæ–¹æ³•ä¸ç³»ç»Ÿ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#llmrag">2.2 çŸ¥è¯†å›¾è°±åœ¨LLMä¸RAGä¸­çš„åº”ç”¨</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id2">2.3 è‡ªé€‚åº”åŸºå‡†æµ‹è¯•</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id3">2.4 RAGè¯„ä¼°æ ‡å‡†</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#methods">3 Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#graphrag"><strong>3.1 GraphRAG å·¥ä½œæµç¨‹</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id4"><strong>3.2 å…¨å±€ç†è§£é—®é¢˜ç”Ÿæˆ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id5"><strong>3.3 å…¨å±€ç†è§£è¯„ä¼°æ ‡å‡†</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id6"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#analysis">4 Analysis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id7">4.1 å®éªŒ1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id11">4.2 å®éªŒ2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id14">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#results">5 Results</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id15">5.1 å®éªŒä¸€ï¼šä¸åŒæ–¹æ³•åœ¨æ‘˜è¦ä»»åŠ¡ä¸­çš„è¡¨ç°æ¯”è¾ƒ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id18">5.2 å®éªŒäºŒï¼šåŸºäºå£°æ˜çš„æŒ‡æ ‡è¯„ä¼°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id20">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#discussion">6 Discussion</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id21">6.1 è¯„ä¼°æ–¹æ³•çš„å±€é™æ€§</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id22">6.2 æœªæ¥å·¥ä½œ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id23">æ›´å¹¿æ³›çš„å½±å“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#conclusion">7 Conclusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#appendix-a-entity-and-relationship-extraction-approach">Appendix A Entity and Relationship Extraction Approach</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id24"><strong>1. å®ä½“ä¸å…³ç³»æŠ½å–æ–¹æ³•</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#self-reflection"><strong>2. è‡ªæˆ‘åæ€ï¼ˆSelf-Reflectionï¼‰æŠ€æœ¯</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id25"><strong>3. åˆ†å—å¤§å°ä¸æŠ½å–æ•ˆæœçš„å…³ç³»</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id26"><strong>4. å®éªŒç»“æœï¼ˆå›¾3ï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id27"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#appendix-b-example-community-detection">Appendix B Example Community Detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#appendix-c-context-window-selection">Appendix C Context Window Selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#appendix-d-example-answer-comparison">Appendix D Example Answer Comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#appendix-e-system-prompts">Appendix E System Prompts</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#e-1-element-instance-generation"><strong>E.1 å®ä½“å®ä¾‹ç”Ÿæˆï¼ˆElement Instance Generationï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#e-2-community-summary-generation"><strong>E.2 ç¤¾åŒºæ‘˜è¦ç”Ÿæˆï¼ˆCommunity Summary Generationï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#e-3-community-answer-generation"><strong>E.3 ç¤¾åŒºé—®é¢˜å›ç­”ç”Ÿæˆï¼ˆCommunity Answer Generationï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#e-4-global-answer-generation"><strong>E.4 å…¨å±€é—®é¢˜å›ç­”ç”Ÿæˆï¼ˆGlobal Answer Generationï¼‰</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#appendix-f-evaluation-prompts">Appendix F Evaluation Prompts</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#f-1-relative-assessment-prompt">F.1 Relative Assessment Prompt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#f-2-relative-assessment-metrics">F.2 Relative Assessment Metrics</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#appendix-g-statistical-analysis">Appendix G Statistical Analysis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id38">ç»Ÿè®¡æ–¹æ³•ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id39">ä¸»è¦ç»“æœæ€»ç»“ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id40">æ€»ä½“è¶‹åŠ¿ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2404.16130_GraphRAG.html#id41">é‡è¦ç»“è®ºï¼š</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html">2405.16506_GRAG: Graph Retrieval-Augmented Generation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#id1">æ€»ç»“</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#introduction">1 Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#related-work">2 Related Work</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#prompt-tuning">2.1 Prompt Tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#llms">2.2 LLMsåœ¨å›¾ç›¸å…³ä»»åŠ¡ä¸­çš„åº”ç”¨</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#id2">2.3 å›¾ä¸Šçš„æ£€ç´¢æ–¹æ³•</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#problem-formalization">3 Problem Formalization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#methodology">4 Methodology</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#id3">æ¦‚è¿°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#id4">4.1 æ–‡æœ¬å­å›¾æ£€ç´¢</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#indexing">æ–‡æœ¬å­å›¾ç´¢å¼•ï¼ˆIndexingï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#ranking">æ–‡æœ¬å­å›¾æ’åºï¼ˆRankingï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#soft-pruning">æ–‡æœ¬å­å›¾è½¯å‰ªæï¼ˆSoft Pruningï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#id5">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#textual-graph-augmented-generation">4.2 Textual Graph Augmented Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#text-view-of-textual-graphs">1. æ–‡æœ¬è§†å›¾ï¼ˆText View of Textual Graphsï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#graph-view-of-textual-graphs">2. å›¾è§†å›¾ï¼ˆGraph View of Textual Graphsï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#generation-phase">3. ç”Ÿæˆé˜¶æ®µï¼ˆGeneration Phaseï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#id6">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#experiments">5 Experiments</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#id7">æ€»ç»“ï¼šç¬¬äº”ç«  å®éªŒéƒ¨åˆ†</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#limitations">7 Limitations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#acknowledgments">Acknowledgments</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#appendix-a-appendix">Appendix A Appendix</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#a"><strong>é™„å½•A æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2405.16506_GRAG.html#id13"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2406.13213_Multi-Meta-RAG.html">2406.13213_Multi-Meta-RAG: Improving RAG for Multi-Hop Queries using Database Filtering with LLM-Extracted Metadata</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html">2410.05779_LightRAG: Simple and Fast Retrieval-Augmented Generation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#id1">æ€»ç»“</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#introduction">1 Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#retrieval-augmented-generation">2 Retrieval-Augmented Generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#the-lightrag-architecture">3 The LightRAGÂ Architecture</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#lightrag">ä¸€ã€LightRAGæ¶æ„æ¦‚è¿°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#graph-based-text-indexing">äºŒã€åŸºäºå›¾çš„æ–‡æœ¬ç´¢å¼•ï¼ˆGraph-based Text Indexingï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#dual-level-retrieval-paradigm">ä¸‰ã€åŒå±‚æ£€ç´¢èŒƒå¼ï¼ˆDual-level Retrieval Paradigmï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#retrieval-augmented-answer-generation">å››ã€æ£€ç´¢å¢å¼ºçš„ç­”æ¡ˆç”Ÿæˆï¼ˆRetrieval-Augmented Answer Generationï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#id2">äº”ã€å¤æ‚åº¦åˆ†æ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#id3">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#evaluation">4 Evaluation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#experimental-settings"><strong>1. å®éªŒè®¾ç½®ï¼ˆ4.1 Experimental Settingsï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#lightrag-rag-4-2-rq1"><strong>2. LightRAG ä¸ç°æœ‰ RAG æ–¹æ³•çš„å¯¹æ¯”ï¼ˆ4.2 RQ1ï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#rq2"><strong>3. æ¶ˆèå®éªŒï¼ˆ4.3 RQ2ï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#id8"><strong>æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#case-study-rq3">4.4 Case Study (RQ3)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#rq3">4.4 æ¡ˆä¾‹ç ”ç©¶ï¼ˆRQ3ï¼‰æ€»ç»“ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#rq4">4.5 æ¨¡å‹æˆæœ¬ä¸é€‚åº”æ€§åˆ†æï¼ˆRQ4ï¼‰æ€»ç»“ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#id9">æ€»ä½“ç»“è®ºï¼š</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#related-work">5 Related Work</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#id10">ç¬¬5ç«  ç›¸å…³å·¥ä½œï¼ˆæ€»ç»“ï¼‰</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.05779_LightRAG.html#appendix">7 Appendix</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html">2410.10450_KBLaM: Knowledge Base augmented Language Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#introduction">1. Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#related-work">2. Related work</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#background">3. Background</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#self-attention-layer">Self-attention layer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#augmenting-llm-with-the-kb">4. Augmenting LLM with the KB</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#knowledge-tokens">Knowledge tokens</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#rectangular-attention-injecting-knowledge-token-into-prompt-tokens">Rectangular Attention: Injecting knowledge token into prompt tokens</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#kb-length-generalization-through-attention-score-scaling">KB length generalization through attention score scaling</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#kb-instruction-tuning">5. KB instruction tuning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#experiments">6. EXPERIMENTS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#experiment-setting">6.1 EXPERIMENT SETTING</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#experiment-results">6.2 EXPERIMENT RESULTS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#id2">æ€»ç»“äº®ç‚¹</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#conclusion">7. CONCLUSION</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#limitations-and-future-work">8. LIMITATIONS AND FUTURE WORK</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#appendix-a-extended-related-work">Appendix A Extended related work</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#appendix-b-ablation-study">Appendix B Ablation study</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#appendix-c-sample-kb">Appendix C Sample KB</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#sample-q-a">SAMPLE Q&amp;A</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#prompt">PROMPT</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#prompt-for-synthetic-kb-generation">PROMPT FOR SYNTHETIC KB GENERATION</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#prompt-for-open-ended-q-a-generation">Prompt for open-ended Q&amp;A generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#prompt-for-gpt-evaluation-of-open-ended-q-a">PROMPT FOR GPT EVALUATION OF OPEN-ENDED Q&amp;A</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#prompt-for-llama-evaluation">PROMPT FOR LLAMA EVALUATION</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#question-template">QUESTION TEMPLATE</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#sample-output">SAMPLE OUTPUT</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#synthetic-kb">SYNTHETIC KB</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2410.10450_KBLaM.html#enron">ENRON</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html">2504.03137_LightPROF: A Lightweight Reasoning Framework for Large Language Model on Knowledge Graph</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#related-work">Related Work</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#llm-prompt-engineering">LLM Prompt Engineering</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#kg-based-llm-reasoning">KG-based LLM Reasoning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#preliminaries">Preliminaries</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#knowledge-graph-kg">1. Knowledge Graph (KG)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#anchor-entities">2. Anchor Entities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#relation-link">3. Relation Link</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#reasoning-path">4. Reasoning Path</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#methodology">Methodology</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#stage1-reasoning-graph-retrieval">Stage1: Reasoning Graph Retrieval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#stage2-knowledge-embedding">Stage2: Knowledge Embedding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#stage3-knowledge-prompts-mixed-reasoning">Stage3: Knowledge Prompts Mixed Reasoning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#experiments">Experiments</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/2504.03137_LightPROF.html#conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../RAGs/graphrag.html">GraphRAG å®˜æ–¹æ–‡æ¡£</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/graphrag.html#indexing">Indexing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/graphrag.html#indexing-architecture">&gt; Indexing Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/graphrag.html#indexing-dataflow">&gt; Indexing Dataflow</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../RAGs/graphrag.html#prompt-tuning">&gt; Prompt Tuning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../RAGs/graphrag.html#query">Query</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../paper_pool.html">è®ºæ–‡æ± </a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html">2305.16300_Random-Access Infinite Context Length for Transformers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#introduction">1 Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#related-work">2 Related Work</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#methodology">3 Methodology</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id1"><strong>æ€»ä½“æ€è·¯</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id2"><strong>æ–¹æ³•è¯¦è§£</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id4"><strong>ä½ç½®ç¼–ç å¤„ç†</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id5"><strong>ä¸å…¶ä»–æ–¹æ³•çš„å¯¹æ¯”</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id6"><strong>æ€»ç»“</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#memory-computation">3.3 Memory &amp; Computation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#experiments">4 Experiments</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id7"><strong>4.1 è¯­è¨€å»ºæ¨¡å®éªŒ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id11"><strong>4.2 å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id15"><strong>æ€»ç»“</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#future-work">5 Future Work</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#acknowledgment">Acknowledgment</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#appendix-a-grouped-softmax-example">Appendix A Grouped Softmax Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#appendix-b-dataset-description">Appendix B Dataset Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#appendix-c-number-of-unique-retrieved-blocks">Appendix C Number of Unique Retrieved Blocks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#appendix-d-context-miss-token">Appendix D Context Miss Token</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#appendix-e-positional-augmentation">Appendix E Positional Augmentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#appendix-f-additional-extensions-and-details">Appendix F Additional Extensions and Details</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#masked-language-modeling">1. <strong>æ©ç è¯­è¨€å»ºæ¨¡ï¼ˆMasked Language Modelingï¼‰</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#flash-attention">2. <strong>ä¸ Flash Attention çš„ç»“åˆ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id16">3. <strong>æ£€ç´¢å—æ•°é‡ä¸å—å¤§å°çš„æƒè¡¡</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#id17">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2305.16300.html#appendix-g-offloading-kv-cache-to-cpu">Appendix G Offloading KV Cache to CPU</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html">2505.14683_Emerging Properties in Unified Multimodal Pretraining</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#from-deepseek">From Deepseek</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id1"><strong>è®ºæ–‡èƒŒæ™¯ä¸æ ¸å¿ƒç›®æ ‡</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id2"><strong>æ ¸å¿ƒè´¡çŒ®</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id3"><strong>å®éªŒç»“æœ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id4"><strong>æ„ä¹‰ä¸å±•æœ›</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#llm">LLM æ€»ç»“</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#introduction">1 Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id5">æ ¸å¿ƒå†…å®¹æ€»ç»“ï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id6">æ€»ç»“ï¼š</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#model">2 Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id7">1. æ¨¡å‹æ¶æ„æ¦‚è§ˆ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id8">2. ç”Ÿæˆç­–ç•¥</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id9">3. æ¨¡å‹ç»†èŠ‚</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#generalized-causal-attention">4. å¹¿ä¹‰å› æœæ³¨æ„åŠ›ï¼ˆGeneralized Causal Attentionï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#transformer">5. Transformerç»“æ„é€‰æ‹©ä¸å®éªŒ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id10">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#data">3 Data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id11">æ•°æ®ç‰¹ç‚¹ä¸ç›®æ ‡</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id12">æ•°æ®æ¥æºä¸ç»Ÿè®¡</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id13">æ•°æ®æ„å»ºæ–¹æ³•</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id20">æ•°æ®è®­ç»ƒç­–ç•¥</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id21">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#training">4 Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id22">1. å¤šé˜¶æ®µè®­ç»ƒç­–ç•¥</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id23">2. å…³é”®è¶…å‚æ•°è°ƒæ•´</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id26">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#evaluation">5 Evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#emerging-properties">6 Emerging Properties</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id27">1. <strong>æ–°å…´å±æ€§çš„å®šä¹‰ä¸ç ”ç©¶èƒŒæ™¯</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id28">2. <strong>ä»»åŠ¡è¡¨ç°ä¸è®­ç»ƒé˜¶æ®µçš„å…³ç³»</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id29">3. <strong>å¤šæ¨¡æ€ç‰¹å¾çš„é‡è¦æ€§</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id30">4. <strong>å®šæ€§åˆ†æä¸ç”Ÿæˆè´¨é‡æå‡</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id31">5. <strong>æ ¸å¿ƒå‘ç°ä¸ç»“è®º</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id32">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#main-results">7 Main Results</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id33">7.1 å›¾åƒç†è§£</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id34">7.2 å›¾åƒç”Ÿæˆ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id35">7.3 å›¾åƒç¼–è¾‘</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id36">7.4 å¸¦æœ‰æ¨ç†çš„ç”Ÿæˆ/ç¼–è¾‘</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id37">7.5 ä¸–ç•Œå»ºæ¨¡</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#id38">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#more-qualitative-results">7.6 More Qualitative Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#conclusion">8 Conclusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2505.14683.html#acknowledgement">9 Acknowledgement</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html">2507.10524_Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive Token-Level Computation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#introduction">1 Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id1">èƒŒæ™¯ä¸åŠ¨æœº</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#transformer">é€’å½’ Transformer ä¸æŒ‘æˆ˜</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#mor">MoRï¼šç»Ÿä¸€æ¡†æ¶</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id2">æ¦‚å¿µä¸æ„ä¹‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#contributions">è´¡çŒ®æ€»ç»“ï¼ˆContributionsï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id3">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#method">2 Method</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#preliminary">2.1 Preliminary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#mixture-of-recursions-mor">2.2 Mixture-of-Recursions (MoR)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id4">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#experiments">3 Experiments</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#table-3">è¡¨æ ¼æ€»ç»“ï¼ˆTable 3ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id5">3.1 ä¸»è¦ç»“æœ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#isoflop">3.2 IsoFLOP åˆ†æ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id11">3.3 æ¨ç†ååé‡è¯„ä¼°</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id14">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#ablation-studies">4 Ablation Studies</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#parameter-sharing-strategies"><strong>4.1 Parameter Sharing Strategies</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#routing-strategies"><strong>4.2 Routing Strategies</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#kv-caching-strategies"><strong>4.3 KV Caching Strategies</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id16">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#analysis">5 Analysis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#compute-optimal-scaling-analysis">5.1 Compute-optimal Scaling Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#routing-analysis">5.2 Routing Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#test-time-scaling-analysis">5.3 Test-time Scaling Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id17">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#related-work">6 Related Work</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#recursive-transformers-transformer">Recursive Transformersï¼ˆé€’å½’Transformerï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#adaptive-computation">Adaptive Computationï¼ˆè‡ªé€‚åº”è®¡ç®—ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#routing-mechanism">Routing Mechanismï¼ˆè·¯ç”±æœºåˆ¶ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#key-value-caching">Key-value Cachingï¼ˆé”®å€¼ç¼“å­˜ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#latent-reasoning">Latent Reasoningï¼ˆéšå¼æ¨ç†ï¼‰</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#conclusion">7 Conclusion</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id18">7.1 å±€é™æ€§ä¸æœªæ¥å·¥ä½œ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id24">7.2 è‡´è°¢</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#appendix-a-details-of-design-choices-for-mixture-of-recursions">Appendix A Details of Design Choices for Mixture-of-Recursions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#a-1-parameter-sharing-strategy">A.1 å‚æ•°å…±äº«ç­–ç•¥ï¼ˆParameter-sharing Strategyï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#a-2-routing-strategy">A.2 è·¯ç”±ç­–ç•¥ï¼ˆRouting Strategyï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#a-3-kv-kv-caching-strategy">A.3 KV ç¼“å­˜ç­–ç•¥ï¼ˆKV Caching Strategyï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id26">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#appendix-b-experimental-setup">Appendix B Experimental Setup</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id27">è®­ç»ƒè®¾ç½®</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id28">è¯„ä¼°è®¾ç½®</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id29">æ¨¡å‹æ¶æ„ç»†èŠ‚</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id30">è¡¨6ï¼šæ¨¡å‹æ¶æ„å‚æ•°æ€»ç»“ï¼ˆé‡ç‚¹ï¼‰</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#appendix-c-expanded-results-of-isoflop-analysis">Appendix C Expanded Results of IsoFLOP Analysis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id31">æ€»ä½“æ¯”è¾ƒ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#transformerflops">Transformerçš„FLOPsè¿‘ä¼¼è®¡ç®—</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id32">å¸¦æ£€æŸ¥ç‚¹å¤ç”¨çš„æ¢¯å½¢å­¦ä¹ ç‡è°ƒåº¦</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id33">ç»“æœæ¦‚è§ˆ</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#appendix-d-details-of-experimental-settings-for-throughput-measurement">Appendix D Details of Experimental Settings for Throughput Measurement</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id34">å®éªŒç³»ç»Ÿä¸è¯„ä¼°æ–¹æ³•</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id35">æ¨¡å‹ååé‡å¯¹æ¯”è®¾ç½®</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id36">æ‰¹å¤„ç†è®¾ç½®</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id37">å®ç°ç»†èŠ‚</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#appendix-e-expanded-results-of-parameter-sharing-strategy">Appendix E Expanded Results of Parameter Sharing Strategy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#middle-cycle">Middle-Cycle æ˜¯æœ€ç¨³å®šçš„é€‰æ‹©</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#up-training">æŒç»­é¢„è®­ç»ƒï¼ˆup-trainingï¼‰ä¸‹çš„è¡¨ç°</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#appendix-f-expanded-results-of-design-choices-for-router">Appendix F Expanded Results of Design Choices for Router</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#f-1">F.1 è®¾è®¡é…ç½®ç»†èŠ‚</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#f-2">F.2 è·¯ç”±å™¨æ€§èƒ½è¯„ä¼°æŒ‡æ ‡</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#f-3">F.3 è·¯ç”±å™¨è®¾è®¡çš„æ‰©å±•è¯„ä¼°ç»“æœ</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#appendix-g-expanded-results-of-kv-cache-sharing-mechanism">Appendix G Expanded Results of KV Cache Sharing Mechanism</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#g-1-transformer">G.1 é€’å½’ Transformer ä¸­çš„å…³é”®å€¼è¡¨ç¤ºè¶‹åŠ¿</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#g-2-kv">G.2 KV ç¼“å­˜å…±äº«ç­–ç•¥çš„æ€§èƒ½æ¯”è¾ƒ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id44">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#appendix-h-expanded-qualitative-results">Appendix H Expanded Qualitative Results</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#h-1-analysis-on-adaptive-computation-paths">H.1 Analysis on Adaptive Computation Paths</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#h-2-analysis-on-router-weights">H.2 Analysis on Router Weights</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2507.10524_Mixture-of-Recursions.html#id45">æ€»ç»“</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html">2509.06221_Beamforming-LLM: What, Where and When Did I Miss?</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#abstract">Abstract</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#id1">æ ¸å¿ƒæŠ€æœ¯ä¸æµç¨‹</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#id2">ç”¨æˆ·æŸ¥è¯¢å¤„ç†æµç¨‹</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#id3">ç³»ç»Ÿè¾“å‡º</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#id4">åº”ç”¨ä¸æ„ä¹‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#id5">å…³é”®è¯ï¼ˆé‡ç‚¹æ ¸å¿ƒæ¦‚å¿µï¼‰</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#introduction">1. Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#related-work">2. Related Work</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#id6">ä¼šè¯è®°å¿†ç³»ç»Ÿ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#id7">è¯­éŸ³å¢å¼ºä¸ä¿¡æ¯æ£€ç´¢æŠ€æœ¯</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#id8">ç°æœ‰å·¥ä½œçš„ä¸è¶³ä¸æœ¬ç ”ç©¶çš„åˆ›æ–°</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#methods">3. Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#beamforming-and-directional-source-separation">3.1. Beamforming and Directional Source Separationï¼ˆæ³¢æŸæˆå½¢ä¸æ–¹å‘æ€§æºåˆ†ç¦»ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#automatic-speech-recognition-asr">3.2. Automatic Speech Recognition (ASR)ï¼ˆè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#retrieval-augmented-generation-with-vector-embeddings">3.3. Retrieval-Augmented Generation with Vector Embeddingsï¼ˆåŸºäºå‘é‡åµŒå…¥çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#natural-language-interface-and-semantic-retrieval">3.4. Natural Language Interface and Semantic Retrievalï¼ˆè‡ªç„¶è¯­è¨€æ¥å£ä¸è¯­ä¹‰æ£€ç´¢ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#deployment-and-llm-choice-llm">3.5. Deployment and LLM Choiceï¼ˆéƒ¨ç½²ä¸LLMé€‰æ‹©ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#id9">æ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#results">4. Results</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#id10">å®éªŒè®¾ç½®</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#beamforming-performance">4.1. Beamforming Performanceï¼ˆæ³¢æŸæˆå½¢æ€§èƒ½ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#retrieval-pipeline-evaluation">4.2. Retrieval Pipeline Evaluationï¼ˆæ£€ç´¢æµç¨‹è¯„ä¼°ï¼‰</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#discussion-and-conclusion">5. Discussion and Conclusion</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#mvp">åŠŸèƒ½æ€§MVPçš„å®ç°ä¸ç°æœ‰å±€é™</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../zzz_paper_pools/2509.06221.html#id11">å¤šæ¨¡æ€æ‰©å±•ä¸åº”ç”¨å‰æ™¯</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../paper_pool_sum.html">è®ºæ–‡æ± -sum</a><ul class="simple">
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../other.html">å…¶ä»–</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../other.html#id3">æ•°æ®é›†&amp;æ•°æ®è’¸é¦</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../others/DataSets/1811.10959v3_Dataset_Distillation.html">1811.10959v3_Dataset Distillation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../others/DataSets/1811.10959v3_Dataset_Distillation.html#abstract">ABSTRACT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/DataSets/1811.10959v3_Dataset_Distillation.html#llm">LLMæ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/DataSets/1811.10959v3_Dataset_Distillation.html#introduction">1. INTRODUCTION</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/DataSets/1811.10959v3_Dataset_Distillation.html#approach">3. APPROACH</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../others/DataSets/2502.20653_Dataset_Distillation.html">2502.20653_Dataset Distillation with Neural Characteristic Function: A Minmax Perspective</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../others/DataSets/2502.20653_Dataset_Distillation.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/DataSets/2502.20653_Dataset_Distillation.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/DataSets/2502.20653_Dataset_Distillation.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/DataSets/2502.20653_Dataset_Distillation.html#conclusion">7. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../others/DataSets/normal.html">é€šç”¨</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../others/DataSets/normal.html#dataset-distillation">Dataset distillation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../other.html#d">3D</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../others/3D/2003.08934_NeRF.html">2003.08934_NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2003.08934_NeRF.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2003.08934_NeRF.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2003.08934_NeRF.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2003.08934_NeRF.html#neural-radiance-field-scene-representation">3. Neural Radiance Field Scene Representation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2003.08934_NeRF.html#volume-rendering-with-radiance-fields">4. Volume Rendering with Radiance Fields</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2003.08934_NeRF.html#optimizing-a-neural-radiance-field">5. Optimizing a Neural Radiance Field</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2003.08934_NeRF.html#result">6. Result</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2003.08934_NeRF.html#conclusion">7. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../others/3D/2203.08586_VanishingPointEstimation.html">2203.08586: Deep vanishing point detection: Geometric priors make dataset variations vanish</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2203.08586_VanishingPointEstimation.html#id1">æ¦‚å¿µ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2203.08586_VanishingPointEstimation.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2203.08586_VanishingPointEstimation.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2203.08586_VanishingPointEstimation.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2203.08586_VanishingPointEstimation.html#geometric-priors-for-vp-detection">3. Geometric priors for VP detection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2203.08586_VanishingPointEstimation.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2203.08586_VanishingPointEstimation.html#conclusion-and-limitations">5. Conclusion and limitations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html">2312.14132_DUSt3R: Geometric 3D Vision Made Easy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html#id1">å…³é”®è¯</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html#id2">ç›¸å…³æ¦‚å¿µ</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html#method">3. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html#experiments-with-dust3r">4. Experiments with DUSt3R</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html#conclusion">5. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html#appendix-a">Appendix A <strong>é™„å½•æ¦‚è§ˆ</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html#appendix-b-qualitative-results">Appendix B.  Qualitative results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html#appendix-c-extended-related-work">Appendix C. Extended Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html#appendix-d-multi-view-pose-estimation">Appendix D. å¤šè§†è§’å§¿æ€ä¼°è®¡ï¼ˆMulti-view Pose Estimationï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html#appendix-e-visual-localization">Appendix E. è§†è§‰å®šä½ï¼ˆVisual Localizationï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2312.14132_DUSt3R.html#appendix-f-training-details">Appendix F. Training details</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html">2406.09756_MASt3R: Grounding Image Matching in 3D with MASt3R</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html#id1">å‰è¨€</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html#id2">ğŸ§  æ€ç»´å¯¼å›¾å¼æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html#related-works">2. Related works</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html#id3">ğŸ§  æ€»ç»“æ€ç»´å¯¼å›¾</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html#method">3. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html#experimental-results">4. Experimental results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html#conclusion">5. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html#appendix-a-additional-qualitative-results">Appendix A Additional Qualitative Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html#b-fast-reciprocal-matching">B. Fast Reciprocal Matching</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html#c-coarse-to-fine">C. Coarse-to-Fine</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2406.09756_MASt3R.html#d-detailed-experimental-settings">D. Detailed experimental settings</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../others/3D/2412.09401_SLAM3R.html">2412.09401_SLAM3R: Real-Time Dense Scene Reconstruction from Monocular RGB Videos</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.09401_SLAM3R.html#id1">æœ¯è¯­</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.09401_SLAM3R.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.09401_SLAM3R.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.09401_SLAM3R.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.09401_SLAM3R.html#method">3. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.09401_SLAM3R.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.09401_SLAM3R.html#conclusion">5. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.09401_SLAM3R.html#id14">6. è‡´è°¢</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.09401_SLAM3R.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.09401_SLAM3R.html#appendix-a-implementation-details">Appendix A Implementation details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.09401_SLAM3R.html#appendix-b-details-for-experimental-settings">Appendix B Details for experimental settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.09401_SLAM3R.html#appendix-c-additional-comparisons-and-analyses">Appendix C Additional comparisons and analyses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.09401_SLAM3R.html#d-more-visual-results">D. More visual results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html">2412.12392_MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html#gpt">GPT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html#id1">å…ˆéªŒçŸ¥è¯†</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html#method">3. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html#results">4. Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html#limitations-and-future-work">5. Limitations and Future Workï¼ˆå±€é™ä¸æœªæ¥å·¥ä½œï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html#conclusion">ğŸ§¾ 6. Conclusionï¼ˆæ€»ç»“ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html#id32">ğŸ§  æ€»ç»“ä¸€å¥è¯ç‰ˆï¼š</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html#initialisation">8. Initialisationï¼ˆåˆå§‹åŒ–ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html#runtime-breakdown">9. Runtime Breakdownï¼ˆè¿è¡Œæ—¶åˆ†æï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html#evaluation-setup">10. Evaluation Setupï¼ˆè¯„ä¼°è®¾ç½®ï¼‰</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2412.12392_MASt3R-SLAM.html#id35">11. EuRoC ç»“æœæ€»ç»“</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../others/3D/2503.11651_VGGT.html">2503.11651_VGGT: Visual Geometry Grounded Transformer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2503.11651_VGGT.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2503.11651_VGGT.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2503.11651_VGGT.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2503.11651_VGGT.html#method">3. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2503.11651_VGGT.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2503.11651_VGGT.html#discussions">5. Discussions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2503.11651_VGGT.html#conclusions">6. Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2503.11651_VGGT.html#appendix-a-formal-definitions">Appendix A Formal Definitions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2503.11651_VGGT.html#appendix-b-implementation-details">Appendix B Implementation Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2503.11651_VGGT.html#appendix-c-additional-experiments">Appendix C Additional Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2503.11651_VGGT.html#appendix-d-qualitative-examples">Appendix D Qualitative Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/3D/2503.11651_VGGT.html#appendix-e-related-work">Appendix E Related Work</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../other.html#id4">å…¶ä»–</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../others/others/2204.00598_SocraticModels.html">2204.00598_SocraticModels: Composing Zero-Shot Multimodal Reasoning with Language</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/2204.00598_SocraticModels.html#id1">æ€»ç»“</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/2204.00598_SocraticModels.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/2204.00598_SocraticModels.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/2204.00598_SocraticModels.html#problem-setting-background-and-related-work">2 Problem Setting, Background, and Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/2204.00598_SocraticModels.html#socratic-models">3 Socratic Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/2204.00598_SocraticModels.html#evaluation-methods-and-results">4 Evaluation: Methods and Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/2204.00598_SocraticModels.html#applications-methods-and-demonstrations">5 Applications: Methods and Demonstrations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/2204.00598_SocraticModels.html#discussion">6 Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/2204.00598_SocraticModels.html#acknowledgments-and-disclosure-of-funding">Acknowledgments and Disclosure of Funding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/2204.00598_SocraticModels.html#appendix-a-overview">Appendix A Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/2204.00598_SocraticModels.html#appendix-b-unsupervised-socratic-model-selection">Appendix B Unsupervised Socratic Model Selection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/2204.00598_SocraticModels.html#appendix-c-additional-notes-on-experiments">Appendix C Additional Notes on Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/2204.00598_SocraticModels.html#appendix-d-egocentric-perception-appendix">Appendix D Egocentric Perception Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/2204.00598_SocraticModels.html#appendix-e-scaling-up-socratic-video-search">Appendix E Scaling Up Socratic Video Search</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/2204.00598_SocraticModels.html#appendix-f-additional-notes-on-robot-experiments">Appendix F Additional Notes on Robot Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/2204.00598_SocraticModels.html#appendix-g-socratic-deductive-reasoning">Appendix G Socratic Deductive Reasoning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/2204.00598_SocraticModels.html#appendix-h-broader-impact-energy-and-resource-consumption">Appendix H Broader Impact: Energy and Resource Consumption</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../others/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html">A PAINLESS GUIDE TO CRC ERROR DETECTION ALGORITHMS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#the-basic-idea-behind-crc-algorithms">The Basic Idea Behind CRC Algorithms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#polynomical-arithmetic">Polynomical Arithmetic</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#binary-arithmetic-with-no-carries">Binary Arithmetic with No Carries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#id2">ä¸€ä¸ªå¯ç”¨çš„å®ä¾‹</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#choosing-a-poly">Choosing A Poly</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#a-straightforward-crc-implementation">A Straightforward CRC Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#a-table-driven-implementation">A Table-Driven Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#a-slightly-mangled-table-driven-implementation">A Slightly Mangled Table-Driven Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../others/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#id3">å‚è€ƒ</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../others/others/Distributed%20Representations%20of%20Sentences%20and%20Documents.html">Distributed Representations of Sentences and Documents</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">æ–°æºª-gordon</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../Memory.html">è®°å¿†</a> &raquo;</li>
        
      <li>2505.00675_â‡ï¸Rethinking Memory in AI: Taxonomy, Operations, Topics, and Future Directions</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/Memorys/Normals/2505.00675_RethinkingMemory.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            <nav id="local-table-of-contents" role="navigation" aria-labelledby="local-table-of-contents-title">
              <h4 id="local-table-of-contents-title">On This Page</h4>
              <ul>
<li><a class="reference internal" href="#">2505.00675_â‡ï¸Rethinking Memory in AI: Taxonomy, Operations, Topics, and Future Directions</a><ul>
<li><a class="reference internal" href="#id1">æ€»ç»“</a></li>
<li><a class="reference internal" href="#abstract">Abstract</a></li>
<li><a class="reference internal" href="#introduction">1 Introduction</a><ul>
<li><a class="reference internal" href="#id2">1.1 å½“å‰ç ”ç©¶çš„å±€é™æ€§</a></li>
<li><a class="reference internal" href="#id3">1.2 æœ¬æ–‡çš„è´¡çŒ®</a><ul>
<li><a class="reference internal" href="#id4">1.2.1 è®°å¿†ç±»å‹åˆ’åˆ†</a></li>
<li><a class="reference internal" href="#id5">1.2.2 è®°å¿†æ“ä½œåˆ’åˆ†</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id6">1.3 æ ¸å¿ƒç ”ç©¶æ–¹å‘</a></li>
<li><a class="reference internal" href="#id7">1.4 æ•°æ®ä¸åˆ†ææ–¹æ³•</a></li>
<li><a class="reference internal" href="#id8">1.5 è®ºæ–‡ç»“æ„</a></li>
<li><a class="reference internal" href="#id9">å°ç»“</a></li>
</ul>
</li>
<li><a class="reference internal" href="#memory-foundations">2 Memory Foundations</a><ul>
<li><a class="reference internal" href="#memory-taxonomy">2.1 Memory Taxonomyï¼ˆè®°å¿†åˆ†ç±»ï¼‰</a><ul>
<li><a class="reference internal" href="#parametric-memory">Parametric Memoryï¼ˆå‚æ•°è®°å¿†ï¼‰</a></li>
<li><a class="reference internal" href="#contextual-memory">Contextual Memoryï¼ˆä¸Šä¸‹æ–‡è®°å¿†ï¼‰</a></li>
</ul>
</li>
<li><a class="reference internal" href="#memory-operations">2.2 Memory Operationsï¼ˆè®°å¿†æ“ä½œï¼‰</a></li>
<li><a class="reference internal" href="#memory-management">2.3 Memory Managementï¼ˆè®°å¿†ç®¡ç†ï¼‰</a><ul>
<li><a class="reference internal" href="#consolidation">1. Consolidationï¼ˆè®°å¿†æ•´åˆï¼‰</a></li>
<li><a class="reference internal" href="#indexing">2. Indexingï¼ˆç´¢å¼•ï¼‰</a></li>
<li><a class="reference internal" href="#updating">3. Updatingï¼ˆæ›´æ–°ï¼‰</a></li>
<li><a class="reference internal" href="#forgetting">4. Forgettingï¼ˆé—å¿˜ï¼‰</a></li>
<li><a class="reference internal" href="#id10">é£é™©ä¸æŒ‘æˆ˜</a></li>
</ul>
</li>
<li><a class="reference internal" href="#memory-utilization">2.4 Memory Utilizationï¼ˆè®°å¿†åˆ©ç”¨ï¼‰</a><ul>
<li><a class="reference internal" href="#retrieval">1. Retrievalï¼ˆæ£€ç´¢ï¼‰</a></li>
<li><a class="reference internal" href="#compression">2. Compressionï¼ˆå‹ç¼©ï¼‰</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id11">æ€»ç»“</a></li>
</ul>
</li>
<li><a class="reference internal" href="#from-operations-to-key-research-topics">3 From Operations to Key Research Topics</a><ul>
<li><a class="reference internal" href="#long-term-memory"><strong>3.1 é•¿æœŸè®°å¿† (Long-term Memory)</strong></a><ul>
<li><a class="reference internal" href="#id12"><strong>æ ¸å¿ƒæ¦‚å¿µ</strong></a></li>
<li><a class="reference internal" href="#management"><strong>3.1.1 ç®¡ç† (Management)</strong></a></li>
<li><a class="reference internal" href="#utilization"><strong>3.1.2 åˆ©ç”¨ (Utilization)</strong></a></li>
<li><a class="reference internal" href="#personalization"><strong>3.1.3 ä¸ªæ€§åŒ– (Personalization)</strong></a></li>
<li><a class="reference internal" href="#discussion"><strong>3.1.4 è®¨è®º (Discussion)</strong></a></li>
</ul>
</li>
<li><a class="reference internal" href="#long-context"><strong>3.2 é•¿ä¸Šä¸‹æ–‡ (Long-context)</strong></a><ul>
<li><a class="reference internal" href="#parametric-efficiency"><strong>3.2.1 å‚æ•°æ•ˆç‡ (Parametric Efficiency)</strong></a><ul>
<li><a class="reference internal" href="#kv-kv-cache-dropping"><strong>KVç¼“å­˜ä¸¢å¼ƒ (KV Cache Dropping)</strong></a></li>
<li><a class="reference internal" href="#kv-kv-cache-storing-optimization"><strong>KVç¼“å­˜å­˜å‚¨ä¼˜åŒ– (KV Cache Storing Optimization)</strong></a></li>
<li><a class="reference internal" href="#kv-kv-cache-selection"><strong>KVç¼“å­˜é€‰æ‹© (KV Cache Selection)</strong></a></li>
</ul>
</li>
<li><a class="reference internal" href="#contextual-utilization"><strong>3.2.2 ä¸Šä¸‹æ–‡åˆ©ç”¨ (Contextual Utilization)</strong></a><ul>
<li><a class="reference internal" href="#context-retrieval"><strong>ä¸Šä¸‹æ–‡æ£€ç´¢ (Context Retrieval)</strong></a></li>
<li><a class="reference internal" href="#context-compression"><strong>ä¸Šä¸‹æ–‡å‹ç¼© (Context Compression)</strong></a></li>
</ul>
</li>
<li><a class="reference internal" href="#id13"><strong>3.2.3 è®¨è®º (Discussion)</strong></a><ul>
<li><a class="reference internal" href="#lost-in-the-context"><strong>è¿·å¤±åœ¨ä¸Šä¸‹æ–‡ä¸­ (Lost in the Context)</strong></a></li>
<li><a class="reference internal" href="#trade-off-between-compression-rate-and-performance-drop"><strong>å‹ç¼©ç‡ä¸æ€§èƒ½ä¸‹é™çš„æƒè¡¡ (Trade-off between compression rate and performance drop)</strong></a></li>
<li><a class="reference internal" href="#publication-trending"><strong>å‘è¡¨è¶‹åŠ¿ (Publication Trending)</strong></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#parametric-memory-modification"><strong>3.3 Parametric Memory Modificationï¼ˆå‚æ•°åŒ–è®°å¿†ä¿®æ”¹ï¼‰</strong></a><ul>
<li><a class="reference internal" href="#editing"><strong>3.3.1 Editingï¼ˆç¼–è¾‘ï¼‰</strong></a></li>
<li><a class="reference internal" href="#unlearning"><strong>3.3.2 Unlearningï¼ˆé—å¿˜/åå­¦ä¹ ï¼‰</strong></a></li>
<li><a class="reference internal" href="#continual-learning"><strong>3.3.3 Continual Learningï¼ˆæŒç»­å­¦ä¹ ï¼‰</strong></a></li>
<li><a class="reference internal" href="#id14"><strong>3.3.4 Discussionï¼ˆè®¨è®ºï¼‰</strong></a><ul>
<li><a class="reference internal" href="#sota-solution-analysis"><strong>SOTA Solution Analysisï¼ˆé¡¶å°–æ–¹æ¡ˆåˆ†æï¼‰</strong></a></li>
<li><a class="reference internal" href="#scaling-challenges"><strong>Scaling Challengesï¼ˆæ‰©å±•æ€§æŒ‘æˆ˜ï¼‰</strong></a></li>
<li><a class="reference internal" href="#id15"><strong>Publication Trendingï¼ˆå‘è¡¨è¶‹åŠ¿ï¼‰</strong></a></li>
<li><a class="reference internal" href="#id16"><strong>æ ¸å¿ƒæ€»ç»“ï¼ˆä½ çš„æ€»ç»“å¾ˆæ£’ï¼Œå®Œå…¨æ­£ç¡®ï¼‰</strong></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#multi-source-memory">3.4 å¤šæºè®°å¿† (Multi-source Memory)</a><ul>
<li><a class="reference internal" href="#cross-textual-integration">3.4.1 è·¨æ–‡æœ¬æ•´åˆ (Cross-textual Integration)</a><ul>
<li><a class="reference internal" href="#reasoning">æ¨ç† (Reasoning)</a></li>
<li><a class="reference internal" href="#conflict">å†²çª (Conflict)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#multi-modal-coordination">3.4.2 å¤šæ¨¡æ€åè°ƒ (Multi-Modal Coordination)</a><ul>
<li><a class="reference internal" href="#fusion">èåˆ (Fusion)</a></li>
<li><a class="reference internal" href="#id17">æ£€ç´¢ (Retrieval)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id18">3.4.3 è®¨è®º (Discussion)</a><ul>
<li><a class="reference internal" href="#trends-in-multi-source-memory-integration">å¤šæºè®°å¿†æ•´åˆè¶‹åŠ¿ (Trends in Multi-Source Memory Integration)</a></li>
<li><a class="reference internal" href="#publication-trend">å‘è¡¨è¶‹åŠ¿ (Publication Trend)</a></li>
<li><a class="reference internal" href="#id19">æœªæ¥æ–¹å‘ (éšå«åœ¨æ–‡æœ¬ä¸­çš„æ€»ç»“)</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#memory-in-practice">4 Memory In Practice</a><ul>
<li><a class="reference internal" href="#applications">4.1 Applicationsï¼ˆåº”ç”¨åœºæ™¯ï¼‰</a></li>
<li><a class="reference internal" href="#products">4.2 Productsï¼ˆäº§å“åº”ç”¨ï¼‰</a></li>
<li><a class="reference internal" href="#tools">4.3 Toolsï¼ˆå·¥å…·ä¸æ¡†æ¶ï¼‰</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id20">æ€»ä½“æ€»ç»“ï¼š</a></li>
<li><a class="reference internal" href="#memory-in-humans-and-ai-systems">5 Memory in Humans and AI Systems</a><ul>
<li><a class="reference internal" href="#id21">åŠŸèƒ½ä¸Šçš„ç›¸ä¼¼æ€§</a></li>
<li><a class="reference internal" href="#id22">ç»“æ„ä¸æœºåˆ¶ä¸Šçš„å·®å¼‚</a></li>
<li><a class="reference internal" href="#id23">æ·±å±‚æ¬¡æŒ‘æˆ˜ä¸æœªæ¥æ–¹å‘</a></li>
</ul>
</li>
<li><a class="reference internal" href="#open-challenges-and-future-directions">6 Open Challenges and Future Directions</a><ul>
<li><a class="reference internal" href="#id24">6.1 ä¸“é¢˜æ–¹å‘</a></li>
<li><a class="reference internal" href="#id25">6.2 æ›´å¹¿æ³›çš„è§†è§’</a></li>
</ul>
</li>
<li><a class="reference internal" href="#appendix-a-gpt-based-pipeline-selection">Appendix A GPT-based Pipeline Selection</a></li>
<li><a class="reference internal" href="#appendix-b-relative-citation-index">Appendix B Relative Citation Index</a><ul>
<li><a class="reference internal" href="#id26">ä¸€ã€è®ºæ–‡çš„â€œå¹´é¾„â€å®šä¹‰</a></li>
<li><a class="reference internal" href="#id27">äºŒã€æ„å»ºå¼•ç”¨â€“å¹´é¾„å…³ç³»æ¨¡å‹</a></li>
<li><a class="reference internal" href="#id28">ä¸‰ã€æ•°æ®æ”¶é›†ä¸é¢„å¤„ç†</a></li>
<li><a class="reference internal" href="#id29">å››ã€æ¨¡å‹é€‰æ‹©ä¸ç»“æœ</a></li>
<li><a class="reference internal" href="#rci">äº”ã€ç›¸å¯¹å¼•ç”¨æŒ‡æ•°ï¼ˆRCIï¼‰çš„è®¡ç®—</a></li>
<li><a class="reference internal" href="#id30">å…­ã€RCI ä¸ç ”ç©¶è¶‹åŠ¿åˆ†æ</a><ul>
<li><a class="reference internal" href="#id31">å›¾ 16ï¼šå„ä¸»é¢˜çš„ä¸­ä½ RCI åˆ†å¸ƒ</a></li>
<li><a class="reference internal" href="#id32">å›¾ 17ï¼šå„ä¸»é¢˜çš„è®ºæ–‡æ•°é‡ä¸ RCI è¶‹åŠ¿</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id33">æ€»ç»“</a></li>
</ul>
</li>
<li><a class="reference internal" href="#appendix-c-chord-analysis-of-interactions-among-memory-types-operations-topics-and-venues">Appendix C Chord Analysis of Interactions Among Memory Types, Operations, Topics, and Venues</a><ul>
<li><a class="reference internal" href="#c-1">C.1 è®°å¿†ç±»å‹ã€æ“ä½œä¸ä¸»é¢˜ä¹‹é—´çš„äº¤äº’åˆ†æ</a><ul>
<li><a class="reference internal" href="#memory-types">1. <strong>è®°å¿†ç±»å‹è§†è§’ï¼ˆMemory Typesï¼‰</strong></a></li>
<li><a class="reference internal" href="#operations">2. <strong>æ“ä½œè§†è§’ï¼ˆOperationsï¼‰</strong></a></li>
<li><a class="reference internal" href="#topics">3. <strong>ä¸»é¢˜è§†è§’ï¼ˆTopicsï¼‰</strong></a></li>
</ul>
</li>
<li><a class="reference internal" href="#id34">æ€»ç»“ä¸ç ”ç©¶æ–¹å‘</a></li>
<li><a class="reference internal" href="#c-2-memory-interactions-across-conference-venues">C.2 Memory Interactions Across Conference Venues</a><ul>
<li><a class="reference internal" href="#id35">1. <strong>ä¸åŒä¼šè®®ä¸­çš„æ“ä½œåˆ†å¸ƒ</strong></a></li>
<li><a class="reference internal" href="#id36">2. <strong>ä¸åŒä¼šè®®ä¸­çš„ä¸»é¢˜åˆ†å¸ƒ</strong></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
  <section class="tex2jax_ignore mathjax_ignore" id="rethinking-memory-in-ai-taxonomy-operations-topics-and-future-directions">
<h1>2505.00675_â‡ï¸Rethinking Memory in AI: Taxonomy, Operations, Topics, and Future Directions<a class="headerlink" href="#rethinking-memory-in-ai-taxonomy-operations-topics-and-future-directions" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h1>
<ul class="simple">
<li><p>é¦–é¡µ: <a class="reference external" href="https://arxiv.org/abs/2505.00675">https://arxiv.org/abs/2505.00675</a></p></li>
<li><p>PDF: <a class="reference external" href="https://arxiv.org/pdf/2505.00675">https://arxiv.org/pdf/2505.00675</a></p></li>
<li><p>å¼•ç”¨: 13(2025-08-29)</p></li>
<li><p>ç»„ç»‡:</p>
<ul>
<li><p>1The Chinese University of Hong Kong</p></li>
<li><p>2The University of Edinburgh(çˆ±ä¸å ¡å¤§å­¦)</p></li>
<li><p>3HKUST(é¦™æ¸¯ç§‘æŠ€å¤§å­¦)</p></li>
<li><p>4Poisson Lab, CSI, Huawei UK R&amp;D Ltd.</p></li>
</ul>
</li>
<li><p>GitHub: <a class="reference external" href="https://github.com/Elvin-Yiming-Du/Survey_Memory_in_AI">https://github.com/Elvin-Yiming-Du/Survey_Memory_in_AI</a></p></li>
</ul>
<section id="id1">
<h2>æ€»ç»“<a class="headerlink" href="#id1" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p><strong>æ€»ç»“</strong></p>
<ul class="simple">
<li><p>æ€»ç»“</p>
<ul>
<li><p>é‡Œé¢æœ‰å„ç§è¡¨æ ¼&amp;å›¾ç‰‡ï¼ŒæŠŠè®°å¿†ç›¸å…³çš„è®ºæ–‡åˆ†é—¨åˆ«ç±»çš„åˆ—å‡ºæ¥â‡ï¸â‡ï¸â‡ï¸</p></li>
</ul>
</li>
<li><p>ç®€ä»‹</p>
<ul>
<li><p>æœ¬æ–‡æ˜¯å¯¹è®°å¿†ç›¸å…³è®ºæ–‡çš„ç»¼è¿°</p></li>
<li><p>GitHub ä¸Šæœ‰æ”¶é›†åˆ°çš„ç›¸å…³è®ºæ–‡â‡ï¸</p>
<ul>
<li><p>åé¢å¯ä»¥æŒ‰å›¾ç´¢éª¥äº†</p></li>
</ul>
</li>
</ul>
</li>
<li><p>è®°å¿†ä¸ä»…æ˜¯å­˜å‚¨ï¼Œæ›´æ˜¯æ¨ç†ã€è§„åˆ’ä¸é€‚åº”çš„å…³é”®ä½¿èƒ½è€…</p></li>
<li><p>ä¸åŒç±»å‹çš„ç³»ç»Ÿï¼ˆçŸ¥è¯†å‹ã€ç”¨æˆ·å‹ã€ä»»åŠ¡å‹ã€å¤šæ¨¡æ€ï¼‰å¯¹è®°å¿†çš„éœ€æ±‚å„ä¸ç›¸åŒï¼›</p></li>
</ul>
<p><strong>è´¡çŒ®</strong></p>
<ul class="simple">
<li><p>æ”¶é›†å¹¶æ ‡æ³¨äº†è¶…è¿‡3ä¸‡ç¯‡è®ºæ–‡ï¼Œä½¿ç”¨åŸºäºGPTçš„ç­›é€‰æµç¨‹ä¿ç•™3,923ç¯‡é«˜ç›¸å…³æ€§è®ºæ–‡</p></li>
</ul>
<p><strong>ç»Ÿä¸€çš„åˆ†ç±»æ¡†æ¶</strong></p>
<ul class="simple">
<li><p>è®°å¿†åˆ†ä¸ºä¸¤ç§å½¢å¼ã€‚</p>
<ul>
<li><p>å‚æ•°è®°å¿†ï¼ˆParametric Memoryï¼‰ï¼šçŸ¥è¯†éšå¼åœ°ç¼–ç åœ¨æ¨¡å‹å‚æ•°ä¸­</p></li>
<li><p>ä¸Šä¸‹æ–‡è®°å¿†ï¼ˆContextual Memoryï¼‰ï¼šå¤–éƒ¨ä¿¡æ¯æ˜¾å¼å­˜å‚¨ï¼Œå¯ç»“æ„åŒ–æˆ–éç»“æ„åŒ–</p>
<ul>
<li><p>Unstructured Contextual Memoryï¼ˆæ— ç»“æ„ä¸Šä¸‹æ–‡è®°å¿†ï¼‰</p>
<ul>
<li><p>å®šä¹‰ï¼šä¸€ç§é€šç”¨çš„è®°å¿†ç³»ç»Ÿï¼Œå¯ä»¥è·¨å¤šç§è¾“å…¥ï¼ˆå¦‚æ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘ï¼‰å­˜å‚¨å’Œæ£€ç´¢ä¿¡æ¯</p></li>
<li><p>åŠŸèƒ½ï¼šæ”¯æŒå°†æ¨ç†è¿‡ç¨‹ä¸æ„ŸçŸ¥ä¿¡å·ç»“åˆï¼Œé›†æˆå¤šæ¨¡æ€ä¸Šä¸‹æ–‡</p></li>
</ul>
</li>
<li><p>Structured Contextual Memoryï¼ˆç»“æ„åŒ–ä¸Šä¸‹æ–‡è®°å¿†ï¼‰</p>
<ul>
<li><p>å®šä¹‰ï¼šä»¥é¢„å®šä¹‰ã€å¯è§£é‡Šå½¢å¼ç»„ç»‡çš„è®°å¿†ï¼Œå¦‚çŸ¥è¯†å›¾ã€å…³ç³»è¡¨æˆ–æœ¬ä½“(ontologies)ã€‚</p></li>
<li><p>åŠŸèƒ½ï¼šæ”¯æŒç¬¦å·æ¨ç†å’Œç²¾ç¡®æŸ¥è¯¢ï¼Œå¸¸ä¸é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„å…³è”èƒ½åŠ›äº’è¡¥ã€‚</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>å…­ä¸ªåŸºæœ¬çš„è®°å¿†æ“ä½œ</p>
<ol class="arabic simple">
<li><p><strong>Consolidationï¼ˆå·©å›ºï¼‰</strong>ï¼šå°†çŸ­æœŸè®°å¿†è½¬åŒ–ä¸ºé•¿æœŸè®°å¿†ã€‚</p></li>
<li><p><strong>Updatingï¼ˆæ›´æ–°ï¼‰</strong>ï¼šæ ¹æ®æ–°ä¿¡æ¯æ›´æ–°å·²æœ‰è®°å¿†ã€‚</p></li>
<li><p><strong>Indexingï¼ˆç´¢å¼•ï¼‰</strong>ï¼šä¸ºè®°å¿†å»ºç«‹ç´¢å¼•ï¼Œä»¥ä¾¿å¿«é€Ÿæ£€ç´¢ã€‚</p></li>
<li><p><strong>Forgettingï¼ˆé—å¿˜ï¼‰</strong>ï¼šé€‰æ‹©æ€§åœ°åˆ é™¤æˆ–å¼±åŒ–ä¸å†ç›¸å…³çš„ä¿¡æ¯ã€‚</p></li>
<li><p><strong>Retrievalï¼ˆæ£€ç´¢ï¼‰</strong>ï¼šä»è®°å¿†ä¸­æå–ç›¸å…³ä¿¡æ¯ã€‚</p></li>
<li><p><strong>Compressionï¼ˆå‹ç¼©ï¼‰</strong>ï¼šå¯¹è®°å¿†è¿›è¡Œå‹ç¼©ï¼Œä»¥æé«˜å­˜å‚¨æ•ˆç‡æˆ–å“åº”é€Ÿåº¦ã€‚</p></li>
</ol>
</li>
</ul>
<p><strong>ç®¡ç†ï¼ˆManagementï¼‰</strong>ï¼š</p>
<ul class="simple">
<li><p><strong>æ•´åˆï¼ˆConsolidationï¼‰</strong>ï¼šå°†æ–°çŸ¥è¯†æ•´åˆè¿›æŒä¹…è®°å¿†ã€‚</p></li>
<li><p><strong>ç´¢å¼•ï¼ˆIndexingï¼‰</strong>ï¼šç»„ç»‡è®°å¿†ä»¥ä¾¿æ£€ç´¢ã€‚</p>
<ul>
<li><p>åˆ†ä¸ºä¸‰ç§èŒƒå¼</p>
<ul>
<li><p>graph-based: åŸºäºå›¾çš„æ–¹æ³•ï¼šå¦‚HippoRAGï¼Œæ„å»ºè½»é‡çº§çŸ¥è¯†å›¾è°±æ¥æ˜¾å¼æ­ç¤ºä¸åŒçŸ¥è¯†ç‰‡æ®µé—´çš„è”ç³»ã€‚</p></li>
<li><p>signal-enhanced: ä¿¡å·å¢å¼ºçš„æ–¹æ³•ï¼šå¦‚LongMemEvalï¼Œç”¨æ—¶é—´æˆ³ã€äº‹å®å†…å®¹å’Œæ‘˜è¦æ¥å¢å¼ºè®°å¿†é”®ã€‚</p></li>
<li><p>timeline-based approaches: åŸºäºæ—¶é—´çº¿çš„æ–¹æ³•ï¼šå¦‚Theanineï¼Œæ²¿ç€æ¼”åŒ–çš„æ—¶é—´å’Œå› æœé“¾ç»„ç»‡è®°å¿†ï¼Œæ”¯æŒåŸºäºç›¸å…³æ€§å’Œæ—¶é—´çº¿çš„æ£€ç´¢ï¼Œå®ç°ç»ˆèº«å’ŒåŠ¨æ€ä¸ªæ€§åŒ–ã€‚</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>æ›´æ–°ï¼ˆUpdatingï¼‰</strong>ï¼šæ ¹æ®æ–°è¾“å…¥æ›´æ–°è®°å¿†</p>
<ul>
<li><p>å†…åœ¨æ›´æ–° (Intrinsic Updating)ï¼šé€šè¿‡å†…éƒ¨æœºåˆ¶æ›´æ–°ï¼Œæ— å¤–éƒ¨åé¦ˆã€‚åŒ…æ‹¬é€‰æ‹©æ€§ç¼–è¾‘åˆ é™¤è¿‡æ—¶ä¿¡æ¯ã€é€’å½’æ‘˜è¦å‹ç¼©å¯¹è¯å†å²ã€è®°å¿†æ··åˆä¸ç²¾ç‚¼åˆå¹¶è¿‡å»å’Œç°åœ¨çš„è¡¨å¾ã€åŸºäºè¯æ®æ£€ç´¢å’ŒéªŒè¯çš„è‡ªæˆ‘åæ€å¼è®°å¿†æ¼”åŒ–ã€‚</p></li>
<li><p>å¤–åœ¨æ›´æ–° (Extrinsic Updating)ï¼šä¾èµ–å¤–éƒ¨ä¿¡å·ï¼ˆç‰¹åˆ«æ˜¯ç”¨æˆ·åé¦ˆï¼‰æ›´æ–°ã€‚å¦‚å­˜å‚¨ç”¨æˆ·ä¿®æ­£åˆ°è®°å¿†ä¸­ä»¥å®ç°æŒç»­æ”¹è¿›ï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒã€‚</p></li>
</ul>
</li>
<li><p><strong>é—å¿˜ï¼ˆForgettingï¼‰</strong>ï¼šåˆ é™¤è¿‡æ—¶æˆ–é”™è¯¯çš„å†…å®¹</p>
<ul>
<li><p>è‡ªç„¶é—å¿˜ï¼šéµå¾ªè‰¾å®¾æµ©æ–¯é—å¿˜æ›²çº¿ï¼Œè®°å¿†ç—•è¿¹éšæ—¶é—´é€æ¸è¡°å‡</p></li>
<li><p>ä¸»åŠ¨é—å¿˜ï¼šæ•…æ„ä»è®°å¿†ç³»ç»Ÿä¸­ç§»é™¤ç‰¹å®šä¿¡æ¯ï¼ˆå¦‚å‡ºäºéšç§ã€å®‰å…¨ã€åˆè§„åŸå› ï¼‰</p></li>
</ul>
</li>
</ul>
<p><strong>åˆ©ç”¨ï¼ˆUtilizationï¼‰</strong>ï¼š</p>
<ul class="simple">
<li><p><strong>æ£€ç´¢ï¼ˆRetrievalï¼‰</strong>ï¼šè®¿é—®ç›¸å…³è®°å¿†ã€‚</p>
<ul>
<li><p>ä»¥æŸ¥è¯¢ä¸ºä¸­å¿ƒï¼šæ”¹è¿›æŸ¥è¯¢ formulation å’Œé€‚åº”ï¼ˆå¦‚FLAREä¸­çš„å‰å‘æŸ¥è¯¢é‡å†™ï¼ŒIterCQRä¸­çš„è¿­ä»£ç²¾ç‚¼ï¼‰</p></li>
<li><p>ä»¥è®°å¿†ä¸ºä¸­å¿ƒï¼šå¢å¼ºè®°å¿†å€™é€‰çš„ç»„ç»‡å’Œæ’åº(å¦‚æ›´å¥½çš„ç´¢å¼•ç­–ç•¥ï¼Œé‡æ’åºæ–¹æ³•)</p></li>
<li><p>ä»¥äº‹ä»¶ä¸ºä¸­å¿ƒï¼šåŸºäºæ—¶é—´å’Œå› æœç»“æ„æ£€ç´¢è®°å¿†ï¼ˆå¦‚LoCoMo, CC, MSCï¼‰</p></li>
</ul>
</li>
<li><p><strong>å‹ç¼©ï¼ˆCompressionï¼‰</strong>ï¼šç¼©å‡è®°å¿†è§„æ¨¡åŒæ—¶ä¿ç•™å…³é”®ä¿¡æ¯</p>
<ul>
<li><p>Pre-input compressionï¼ˆè¾“å…¥å‰å‹ç¼©ï¼‰ï¼šç”¨äºæœªä½¿ç”¨æ£€ç´¢çš„é•¿ä¸Šä¸‹æ–‡æ¨¡å‹</p></li>
<li><p>Post-retrieval compressionï¼ˆæ£€ç´¢åå‹ç¼©ï¼‰ï¼šå‡å°‘æ£€ç´¢åˆ°çš„å†…å®¹</p></li>
</ul>
</li>
<li><p>è®°å¿†æ•´åˆ (Memory Integration)ï¼š</p>
<ul>
<li><p>é€‰æ‹©æ€§åœ°å°†æ£€ç´¢åˆ°çš„è®°å¿†ä¸æ¨¡å‹ä¸Šä¸‹æ–‡ç»“åˆï¼Œä»¥åœ¨æ¨ç†è¿‡ç¨‹ä¸­å®ç°è¿è´¯æ¨ç†æˆ–å†³ç­–ã€‚</p></li>
<li><p>æ•´åˆå¯èƒ½è·¨è¶Šå¤šä¸ªè®°å¿†æºå’Œæ¨¡æ€ã€‚</p></li>
</ul>
</li>
<li><p>è®°å¿†æ¥åœ°ç”Ÿæˆ (Memory Grounded Generation)ï¼šåˆ©ç”¨å·²æ•´åˆçš„æ£€ç´¢è®°å¿†å†…å®¹æ¥æŒ‡å¯¼å“åº”ç”Ÿæˆ</p>
<ul>
<li><p>è‡ªæˆ‘åæ€æ¨ç†ï¼šæ£€ç´¢è‡ªæˆ‘ç”Ÿæˆæˆ–ç»“æ„åŒ–çš„è®°å¿†è½¨è¿¹æ¥æŒ‡å¯¼ä¸­é—´æ¨ç†æ­¥éª¤ï¼Œå¢å¼ºè§£ç è¿‡ç¨‹ä¸­çš„å¤šè·³æ¨ç†ï¼ˆå¦‚MoT, StructRAGï¼‰ã€‚</p></li>
<li><p>åé¦ˆå¼•å¯¼ä¿®æ­£ï¼šåˆ©ç”¨åé¦ˆè®°å¿†æˆ–è®°å¿†ä¿¡æ¯çº¿ç´¢æ¥çº¦æŸç”Ÿæˆï¼Œé˜²æ­¢é‡å¤é”™è¯¯å’Œæé«˜è¾“å‡ºé²æ£’æ€§ï¼ˆå¦‚MemoRAG, Repairï¼‰ã€‚</p></li>
<li><p>ä¸Šä¸‹æ–‡å¯¹é½çš„é•¿æœŸç”Ÿæˆï¼šå°†å‹ç¼©æˆ–æå–çš„è®°å¿†æ‘˜è¦æ•´åˆåˆ°ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œä»¥åœ¨é•¿å¯¹è¯æˆ–é•¿æ–‡æ¡£ä¸­ä¿æŒè¿è´¯æ€§ï¼ˆå¦‚COMEDY, MemoChat, ReadAgentï¼‰ã€‚</p></li>
</ul>
</li>
</ul>
<p><strong>ä¸ªæ€§åŒ– (Personalization)</strong></p>
<ul class="simple">
<li><p>æ¨¡å‹çº§é€‚åº” (Model-Level Adaptation)</p>
<ul>
<li><p>é€šè¿‡å¾®è°ƒæˆ–è½»é‡çº§æ›´æ–°å°†ç”¨æˆ·åå¥½ç¼–ç åˆ°æ¨¡å‹å‚æ•°ä¸­</p></li>
</ul>
</li>
<li><p>å¤–éƒ¨è®°å¿†å¢å¼º (External Memory Augmentation)</p>
<ul>
<li><p>åœ¨æ¨ç†æ—¶ä»å¤–éƒ¨è®°å¿†ä¸­æ£€ç´¢ç”¨æˆ·ç‰¹å®šä¿¡æ¯æ¥ä¸ªæ€§åŒ–LLM</p></li>
</ul>
</li>
</ul>
<p><strong>å±€é™</strong></p>
<ul class="simple">
<li><p>è¯„ä¼°å±€é™</p>
<ul>
<li><p>å½“å‰é•¿æœŸè®°å¿†çš„è¯„ä¼°å—é™äºé™æ€å‡è®¾ã€‚</p></li>
</ul>
</li>
<li><p>è®°å¿†æ“ä½œè¯„ä¼°ä¸è¶³</p>
<ul>
<li><p>å½“å‰è¯„ä¼°ä¸»è¦å…³æ³¨æ£€ç´¢å‡†ç¡®æ€§å’Œç”Ÿæˆè´¨é‡ï¼Œä½†å¾ˆå¤§ç¨‹åº¦ä¸Šå¿½ç•¥äº†è®°å¿†ä½¿ç”¨çš„è¿‡ç¨‹æ–¹é¢ï¼ˆå¦‚å·©å›ºã€æ›´æ–°ã€é—å¿˜ã€é€‰æ‹©æ€§ä¿ç•™ï¼‰</p></li>
</ul>
</li>
</ul>
<p><strong>Parametric Memory Modificationï¼ˆå‚æ•°åŒ–è®°å¿†ä¿®æ”¹ï¼‰</strong></p>
<ul class="simple">
<li><p>Editingï¼ˆç¼–è¾‘ï¼‰ï¼š å¯¹æ¨¡å‹å‚æ•°è¿›è¡Œå±€éƒ¨ä¿®æ”¹ï¼Œæ— éœ€å®Œå…¨é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚</p></li>
<li><p>Unlearningï¼ˆé—å¿˜/åå­¦ä¹ ï¼‰ï¼š é€‰æ‹©æ€§ç§»é™¤æ¨¡å‹ä¸­ä¸éœ€è¦çš„æˆ–æ•æ„Ÿçš„ä¿¡æ¯ã€‚</p></li>
<li><p>Continual Learningï¼ˆæŒç»­å­¦ä¹ ï¼‰ï¼š é€æ­¥å¸æ”¶æ–°çŸ¥è¯†ï¼ŒåŒæ—¶é˜²æ­¢å¯¹æ—§çŸ¥è¯†çš„â€œç¾éš¾æ€§é—å¿˜â€ã€‚</p></li>
</ul>
<p><strong>Practice</strong></p>
<ul class="simple">
<li><p>Applicationsï¼ˆåº”ç”¨åœºæ™¯ï¼‰</p>
<ul>
<li><p>çŸ¥è¯†ä¸­å¿ƒå‹ç³»ç»Ÿï¼ˆKnowledge-centric systemsï¼‰</p>
<ul>
<li><p>å€ŸåŠ©å‚æ•°åŒ–è®°å¿†ï¼ˆparametric memoryï¼‰å°†é€šç”¨çŸ¥è¯†ç¼–ç è¿›æ¨¡å‹æƒé‡ä¸­</p></li>
</ul>
</li>
<li><p>ç”¨æˆ·ä¸­å¿ƒå‹ç³»ç»Ÿï¼ˆUser-centric systemsï¼‰</p>
<ul>
<li><p>ä¾èµ–æƒ…å¢ƒè®°å¿†ï¼ˆcontextual memoryï¼‰å»ºæ¨¡ç”¨æˆ·åå¥½å’Œè¡Œä¸ºå†å²ï¼Œå®ç°ä¸ªæ€§åŒ–å¯¹è¯å’Œè‡ªé€‚åº”æ•™å­¦ã€‚</p></li>
<li><p>è¿™ç±»ç³»ç»Ÿéœ€è¦æŒç»­æ›´æ–°è®°å¿†ä»¥é€‚åº”ç”¨æˆ·çš„åŠ¨æ€éœ€æ±‚ã€‚</p></li>
</ul>
</li>
<li><p>ä»»åŠ¡å¯¼å‘å‹ç³»ç»Ÿï¼ˆTask-oriented agentsï¼‰</p>
<ul>
<li><p>ä½¿ç”¨ç»“æ„åŒ–è®°å¿†ï¼ˆå¦‚é”®å€¼å­˜å‚¨ã€å·¥ä½œæµå›¾ï¼‰æ¥ç»´æŠ¤å¯¹è¯è¿ç»­æ€§ï¼Œå¹¶æ”¯æŒé•¿æœŸæ¨ç†</p></li>
<li><p>å¦‚é¡¹ç›®ç®¡ç†æˆ–è™šæ‹ŸåŠ©æ‰‹åœºæ™¯ã€‚</p></li>
</ul>
</li>
<li><p>å¤šæ¨¡æ€ç³»ç»Ÿï¼ˆMulti-modal systemsï¼‰</p>
<ul>
<li><p>èåˆè¯­è¨€ã€è§†è§‰ã€éŸ³é¢‘ç­‰æ¨¡æ€çš„å‚æ•°åŒ–è®°å¿†å’Œæƒ…å¢ƒè®°å¿†</p></li>
<li><p>åœ¨è‡ªåŠ¨é©¾é©¶å’ŒåŒ»ç–—å†³ç­–ç­‰å¤æ‚ç¯å¢ƒä¸­å®ç°è¿è´¯äº¤äº’</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Productsï¼ˆäº§å“åº”ç”¨ï¼‰</p>
<ul>
<li><p>ç”¨æˆ·ä¸­å¿ƒå‹äº§å“ï¼ˆUser-centric productsï¼‰</p>
<ul>
<li><p>å¦‚ Replikaï¼ˆAIä¼´ä¾£ï¼‰ã€Amazon æ¨èç³»ç»Ÿ</p></li>
<li><p>åˆ©ç”¨æŒä¹…åŒ–ç”¨æˆ·æ¨¡å‹å®ç°æƒ…æ„Ÿè¿ç»­æ€§å’Œä¸ªæ€§åŒ–æ¨è</p></li>
</ul>
</li>
<li><p>ä»»åŠ¡å¯¼å‘å‹äº§å“ï¼ˆTask-oriented productsï¼‰</p>
<ul>
<li><p>å¦‚ ChatGPTã€Grokã€GitHub Copilotã€Coze</p></li>
<li><p>é€šè¿‡ç»“æ„åŒ–è®°å¿†ï¼ˆå¦‚å¯¹è¯å†å²å’Œä»»åŠ¡è¡¨ç¤ºï¼‰æ”¯æŒå¤šè½®å¯¹è¯å’Œé•¿æœŸä»»åŠ¡è§„åˆ’</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Toolsï¼ˆå·¥å…·ä¸æ¡†æ¶ï¼‰</p>
<ul>
<li><p><strong>åŸºç¡€ç»„ä»¶</strong>ï¼ˆComponentsï¼‰ï¼š</p>
<ul>
<li><p>åŒ…æ‹¬å‘é‡æ•°æ®åº“ï¼ˆå¦‚ <strong>FAISS</strong>ï¼‰ã€å›¾æ•°æ®åº“ï¼ˆå¦‚ <strong>Neo4j</strong>ï¼‰å’Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ <strong>Llama</strong>ã€<strong>GPT-4</strong>ï¼‰ã€‚</p></li>
<li><p>æ£€ç´¢æœºåˆ¶ï¼ˆå¦‚ <strong>BM25</strong>ã€<strong>Contriever</strong>ã€<strong>OpenAI Embeddings</strong>ï¼‰ç”¨äºè¯­ä¹‰è®¿é—®å¤–éƒ¨è®°å¿†ã€‚</p></li>
<li><p><strong>é‡ç‚¹</strong>ï¼šè¿™äº›ç»„ä»¶æ˜¯æ„å»ºè®°å¿†èƒ½åŠ›çš„åŸºç¡€ï¼Œå¦‚è¯­ä¹‰ç›¸ä¼¼æ€§æœç´¢ã€é•¿æœŸä¸Šä¸‹æ–‡ç†è§£ç­‰ã€‚</p></li>
</ul>
</li>
<li><p><strong>æ¨¡å—åŒ–æ¡†æ¶</strong>ï¼ˆFrameworksï¼‰ï¼š</p>
<ul>
<li><p>æä¾›å¯é…ç½®çš„è®°å¿†æ“ä½œæ¥å£ï¼Œå¦‚ <strong>LlamaIndex</strong>ã€<strong>LangChain</strong>ã€<strong>Graphiti</strong>ã€<strong>Letta</strong> ç­‰ã€‚</p></li>
<li><p><strong>é‡ç‚¹</strong>ï¼šè¿™äº›æ¡†æ¶å°†å¤æ‚çš„è®°å¿†å¤„ç†æµç¨‹æ¨¡å—åŒ–ï¼Œæ”¯æŒå¼€å‘è€…æ„å»ºå¤šæ¨¡æ€ã€æŒä¹…åŒ–ã€å¯æ›´æ–°çš„è®°å¿†æ¨¡å—ã€‚</p></li>
</ul>
</li>
<li><p><strong>è®°å¿†å±‚ç³»ç»Ÿ</strong>ï¼ˆMemory Layer Systemsï¼‰ï¼š</p>
<ul>
<li><p>ä½œä¸ºâ€œè®°å¿†æœåŠ¡å±‚â€ï¼Œæä¾›è°ƒåº¦ã€æŒä¹…åŒ–å’Œç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼Œä¾‹å¦‚ <strong>Mem0</strong>ã€<strong>Zep</strong>ã€<strong>Memary</strong>ã€<strong>Memobase</strong>ã€‚</p></li>
<li><p><strong>é‡ç‚¹</strong>ï¼šè¿™ç±»ç³»ç»Ÿæ³¨é‡<strong>æ—¶é—´ä¸€è‡´æ€§</strong>ã€ä¼šè¯/è¯é¢˜ç´¢å¼•å’Œé«˜æ•ˆè®°å¿†æ£€ç´¢ï¼Œé€šå¸¸ç»“åˆç¬¦å·ä¸äºšç¬¦å·è®°å¿†è¡¨ç¤ºã€‚</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>æ ¸å¿ƒç ”ç©¶æ–¹å‘</strong></p>
<ol class="arabic simple">
<li><p><strong>é•¿æœŸè®°å¿†ï¼ˆLong-Term Memoryï¼‰</strong></p>
<ul class="simple">
<li><p>å…³æ³¨å¤šä¼šè¯ç³»ç»Ÿä¸­çš„è®°å¿†ç®¡ç†ä¸ä¸ªæ€§åŒ–ï¼Œä»¥åŠæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ã€ä¸ªæ€§åŒ–ä»£ç†å’Œé—®ç­”ç³»ç»Ÿ</p></li>
</ul>
</li>
<li><p><strong>é•¿ä¸Šä¸‹æ–‡è®°å¿†ï¼ˆLong-Context Memoryï¼‰</strong></p>
<ul class="simple">
<li><p>æ¶‰åŠå‚æ•°æ•ˆç‡å’Œä¸Šä¸‹æ–‡åˆ©ç”¨æ•ˆæœï¼Œå¦‚â€œKVç¼“å­˜ä¸¢å¼ƒâ€ä¸é•¿ä¸Šä¸‹æ–‡å‹ç¼©</p></li>
</ul>
</li>
<li><p><strong>å‚æ•°è®°å¿†ä¿®æ”¹ï¼ˆParametric Memory Modificationï¼‰</strong></p>
<ul class="simple">
<li><p>åŒ…æ‹¬æ¨¡å‹ç¼–è¾‘ã€é—å¿˜ã€æŒç»­å­¦ä¹ ç­‰å†…å­˜å†…éƒ¨æ“ä½œ</p></li>
</ul>
</li>
<li><p><strong>å¤šæºè®°å¿†ï¼ˆMulti-Source Memoryï¼‰</strong></p>
<ul class="simple">
<li><p>å¼ºè°ƒè·¨å¼‚æ„æ–‡æœ¬æºå’Œå¤šæ¨¡æ€è¾“å…¥çš„è®°å¿†æ•´åˆ</p></li>
</ul>
</li>
</ol>
<p><strong>Open Challenges and Future Directions</strong></p>
<ul class="simple">
<li><p>ä¸“é¢˜æ–¹å‘</p>
<ul>
<li><p>ç»Ÿä¸€è¯„ä¼°çš„å¿…è¦æ€§</p></li>
<li><p>é•¿ä¸Šä¸‹æ–‡å¤„ç†ï¼šæ•ˆç‡ä¸è¡¨è¾¾æ€§çš„å¹³è¡¡</p></li>
<li><p>å‚æ•°åŒ–è®°å¿†ä¿®æ”¹çš„ç ”ç©¶</p></li>
<li><p>å¤šæºæ•´åˆï¼šä¸€è‡´æ€§ã€å‹ç¼©ä¸åè°ƒ</p></li>
</ul>
</li>
<li><p>æ›´å¹¿æ³›çš„è§†è§’</p>
<ul>
<li><p>æ—¶ç©ºè®°å¿†</p></li>
<li><p>å‚æ•°çŸ¥è¯†çš„æ£€ç´¢</p></li>
<li><p>ç»ˆèº«å­¦ä¹ </p></li>
<li><p>å—ç”Ÿç‰©å­¦å¯å‘çš„è®°å¿†è®¾è®¡</p></li>
<li><p>K-Lineç†è®ºä¸å±‚çº§è®°å¿†</p></li>
<li><p>ç»Ÿä¸€çš„è®°å¿†è¡¨ç¤º</p></li>
<li><p>å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„è®°å¿†</p></li>
<li><p>è®°å¿†å¨èƒä¸å®‰å…¨æ€§</p></li>
</ul>
</li>
</ul>
</section>
<section id="abstract">
<h2>Abstract<a class="headerlink" href="#abstract" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p><strong>Memory is a fundamental component of AI systems, underpinning large language models (LLMs)-based agents.</strong><br />
è®°å¿†æ˜¯äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„åŸºæœ¬ç»„æˆéƒ¨åˆ†ï¼Œæ˜¯åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä»£ç†ç³»ç»Ÿçš„æ ¸å¿ƒåŸºç¡€ã€‚</p>
<p><strong>While prior surveys have focused on memory applications with LLMs (e.g., enabling personalized memory in conversational agents), they often overlook the atomic operations that underlie memory dynamics.</strong><br />
å°½ç®¡ä»¥å¾€çš„ç»¼è¿°æ–‡ç« å…³æ³¨äº†LLMsä¸­çš„è®°å¿†åº”ç”¨ï¼ˆä¾‹å¦‚åœ¨å¯¹è¯ä»£ç†ä¸­å®ç°ä¸ªæ€§åŒ–è®°å¿†ï¼‰ï¼Œä½†å®ƒä»¬å¾€å¾€å¿½ç•¥äº†æ”¯æ’‘è®°å¿†åŠ¨æ€çš„åŸºæœ¬æ“ä½œã€‚</p>
<p><strong>In this survey, we first categorize memory representations into parametric and contextual forms,</strong><br />
åœ¨æœ¬ç»¼è¿°ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆå°†è®°å¿†è¡¨ç¤ºåˆ†ä¸ºå‚æ•°åŒ–ï¼ˆparametricï¼‰å’Œä¸Šä¸‹æ–‡ï¼ˆcontextualï¼‰ä¸¤ç§å½¢å¼ã€‚</p>
<ul class="simple">
<li><p><strong>å‚æ•°åŒ–è¡¨ç¤º</strong>ï¼šè®°å¿†è¢«ç¼–ç åœ¨æ¨¡å‹å‚æ•°ä¸­ï¼Œé€‚ç”¨äºé•¿æœŸè®°å¿†ã€‚</p></li>
<li><p><strong>ä¸Šä¸‹æ–‡è¡¨ç¤º</strong>ï¼šè®°å¿†é€šè¿‡å¤–éƒ¨ä¸Šä¸‹æ–‡æˆ–ç¼“å­˜çš„æ–¹å¼å¼•å…¥ï¼Œé€‚ç”¨äºçŸ­æœŸæˆ–ä»»åŠ¡ç›¸å…³çš„è®°å¿†ã€‚</p></li>
</ul>
<p><strong>and then introduce six fundamental memory operations: Consolidation, Updating, Indexing, Forgetting, Retrieval, and Compression.</strong><br />
éšåï¼Œæˆ‘ä»¬æå‡ºäº†å…­ä¸ªåŸºæœ¬çš„è®°å¿†æ“ä½œï¼Œè¿™äº›æ“ä½œå¯¹äºç†è§£è®°å¿†ç³»ç»Ÿçš„åŠŸèƒ½è‡³å…³é‡è¦ï¼š</p>
<ol class="arabic simple">
<li><p><strong>Consolidationï¼ˆå·©å›ºï¼‰</strong>ï¼šå°†çŸ­æœŸè®°å¿†è½¬åŒ–ä¸ºé•¿æœŸè®°å¿†ã€‚</p></li>
<li><p><strong>Updatingï¼ˆæ›´æ–°ï¼‰</strong>ï¼šæ ¹æ®æ–°ä¿¡æ¯æ›´æ–°å·²æœ‰è®°å¿†ã€‚</p></li>
<li><p><strong>Indexingï¼ˆç´¢å¼•ï¼‰</strong>ï¼šä¸ºè®°å¿†å»ºç«‹ç´¢å¼•ï¼Œä»¥ä¾¿å¿«é€Ÿæ£€ç´¢ã€‚</p></li>
<li><p><strong>Forgettingï¼ˆé—å¿˜ï¼‰</strong>ï¼šé€‰æ‹©æ€§åœ°åˆ é™¤æˆ–å¼±åŒ–ä¸å†ç›¸å…³çš„ä¿¡æ¯ã€‚</p></li>
<li><p><strong>Retrievalï¼ˆæ£€ç´¢ï¼‰</strong>ï¼šä»è®°å¿†ä¸­æå–ç›¸å…³ä¿¡æ¯ã€‚</p></li>
<li><p><strong>Compressionï¼ˆå‹ç¼©ï¼‰</strong>ï¼šå¯¹è®°å¿†è¿›è¡Œå‹ç¼©ï¼Œä»¥æé«˜å­˜å‚¨æ•ˆç‡æˆ–å“åº”é€Ÿåº¦ã€‚</p></li>
</ol>
<p><strong>We map these operations to the most relevant research topics across long-term, long-context, parametric modification, and multi-source memory.</strong><br />
æˆ‘ä»¬å°†è¿™äº›æ“ä½œæ˜ å°„åˆ°ä¸é•¿æœŸè®°å¿†ã€é•¿ä¸Šä¸‹æ–‡å¤„ç†ã€å‚æ•°ä¿®æ”¹ä»¥åŠå¤šæºè®°å¿†ç­‰ç ”ç©¶ä¸»é¢˜ç›¸å…³çš„é¢†åŸŸï¼Œå±•ç¤ºäº†å®ƒä»¬åœ¨ä¸åŒåº”ç”¨åœºæ™¯ä¸‹çš„é€‚ç”¨æ€§ã€‚</p>
<p><strong>By reframing memory systems through the lens of atomic operations and representation types,</strong><br />
é€šè¿‡ä»åŸºæœ¬æ“ä½œå’Œè¡¨ç¤ºå½¢å¼çš„è§’åº¦é‡æ–°å®¡è§†è®°å¿†ç³»ç»Ÿï¼Œ<br />
<strong>this survey provides a structured and dynamic perspective on research, benchmark datasets, and tools related to memory in AI,</strong><br />
æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªç»“æ„åŒ–ä¸”åŠ¨æ€çš„è§†è§’ï¼Œæ¶µç›–äº†è®°å¿†åœ¨AIä¸­çš„ç ”ç©¶ã€åŸºå‡†æ•°æ®é›†å’Œå·¥å…·ã€‚<br />
<strong>clarifying the functional interplay in LLMs based agents while outlining promising directions for future research.</strong><br />
è¿™æœ‰åŠ©äºæ¾„æ¸…LLMsä»£ç†ä¸­å„åŠŸèƒ½ä¹‹é—´çš„ç›¸äº’ä½œç”¨ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æŒ‡æ˜äº†æœ‰å‰æ™¯çš„æ–¹å‘ã€‚</p>
</section>
<section id="introduction">
<h2>1 Introduction<a class="headerlink" href="#introduction" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/08/ToVtcx.png" /></p>
<p>Figure 1:A unified framework of memory Taxonomy, Operations, and Applications in AI systems.</p>
<p>æœ¬èŠ‚ä¸»è¦ä»‹ç»äº†åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ç³»ç»Ÿä¸­<strong>è®°å¿†ï¼ˆMemoryï¼‰<strong>çš„é‡è¦æ€§ï¼Œå¹¶æŒ‡å‡ºå½“å‰çš„ç ”ç©¶åœ¨</strong>æ¶æ„å±‚é¢å°šä¸å®Œå–„</strong>ã€‚å°½ç®¡å·²æœ‰ç ”ç©¶åœ¨<strong>è®°å¿†çš„å­˜å‚¨ã€æ£€ç´¢å’Œç”Ÿæˆ</strong>ç­‰æ–¹é¢å–å¾—äº†è¿›å±•ï¼Œä½†ç¼ºä¹ä¸€ä¸ª<strong>ç»Ÿä¸€çš„æ¡†æ¶</strong>æ¥æ•´åˆè¿™äº›ç ”ç©¶ã€‚</p>
<section id="id2">
<h3>1.1 å½“å‰ç ”ç©¶çš„å±€é™æ€§<a class="headerlink" href="#id2" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p>æœ€è¿‘çš„ç»¼è¿°æ–‡ç« è™½ç„¶æå‡ºäº†è®°å¿†çš„æ“ä½œè§†è§’ï¼Œä½†å¤§å¤š<strong>å±€é™äºç‰¹å®šå­é¢†åŸŸ</strong>ï¼ˆå¦‚é•¿ä¸Šä¸‹æ–‡å»ºæ¨¡ã€é•¿æœŸè®°å¿†ã€ä¸ªæ€§åŒ–ã€çŸ¥è¯†ç¼–è¾‘ç­‰ï¼‰ï¼Œç¼ºä¹<strong>ç»Ÿä¸€çš„æ“ä½œæ¡†æ¶</strong>ã€‚</p></li>
<li><p>ç°æœ‰ç ”ç©¶<strong>æœªæ˜ç¡®ç•Œå®šè®°å¿†ç ”ç©¶çš„èŒƒå›´</strong>ï¼Œä¹Ÿç¼ºä¹æŠ€æœ¯å®ç°åˆ†æå’Œå®è·µåŸºç¡€ï¼ˆå¦‚åŸºå‡†æµ‹è¯•å’Œå·¥å…·ï¼‰ã€‚</p></li>
</ul>
</section>
<section id="id3">
<h3>1.2 æœ¬æ–‡çš„è´¡çŒ®<a class="headerlink" href="#id3" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>ä¸ºå¡«è¡¥ä¸Šè¿°ç©ºç™½ï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ª<strong>ç»Ÿä¸€çš„åˆ†ç±»æ¡†æ¶</strong>ï¼Œå°†è®°å¿†åˆ†ä¸ºä¸¤å¤§ç±»ï¼š</p>
<section id="id4">
<h4>1.2.1 è®°å¿†ç±»å‹åˆ’åˆ†<a class="headerlink" href="#id4" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p><strong>å‚æ•°è®°å¿†ï¼ˆParametric Memoryï¼‰</strong>ï¼šçŸ¥è¯†éšå¼åœ°ç¼–ç åœ¨æ¨¡å‹å‚æ•°ä¸­ã€‚</p></li>
<li><p><strong>ä¸Šä¸‹æ–‡è®°å¿†ï¼ˆContextual Memoryï¼‰</strong>ï¼šå¤–éƒ¨ä¿¡æ¯æ˜¾å¼å­˜å‚¨ï¼Œå¯ç»“æ„åŒ–æˆ–éç»“æ„åŒ–ã€‚</p></li>
<li><p><strong>æ—¶é—´ç»´åº¦</strong>ï¼šè®°å¿†å¯åˆ†ä¸º<strong>é•¿æœŸè®°å¿†ï¼ˆLong-termï¼‰</strong>ï¼ˆå¦‚å¤šè½®å¯¹è¯ã€é•¿æœŸè§‚å¯Ÿï¼‰å’Œ<strong>çŸ­æœŸä¸Šä¸‹æ–‡ï¼ˆShort-termï¼‰</strong>ï¼ˆå¦‚å½“å‰å¯¹è¯æˆ–ä»»åŠ¡ä¸Šä¸‹æ–‡ï¼‰ã€‚</p></li>
</ul>
</section>
<section id="id5">
<h4>1.2.2 è®°å¿†æ“ä½œåˆ’åˆ†<a class="headerlink" href="#id5" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>åŸºäºä¸Šè¿°ç±»å‹ï¼Œä½œè€…å°†è®°å¿†æ“ä½œåˆ†ä¸ºä¸¤ç±»ï¼š</p>
<ul class="simple">
<li><p><strong>ç®¡ç†ï¼ˆManagementï¼‰</strong>ï¼š</p>
<ul>
<li><p><strong>æ•´åˆï¼ˆConsolidationï¼‰</strong>ï¼šå°†æ–°çŸ¥è¯†æ•´åˆè¿›æŒä¹…è®°å¿†ã€‚</p></li>
<li><p><strong>ç´¢å¼•ï¼ˆIndexingï¼‰</strong>ï¼šç»„ç»‡è®°å¿†ä»¥ä¾¿æ£€ç´¢ã€‚</p></li>
<li><p><strong>æ›´æ–°ï¼ˆUpdatingï¼‰</strong>ï¼šæ ¹æ®æ–°è¾“å…¥æ›´æ–°è®°å¿†ã€‚</p></li>
<li><p><strong>é—å¿˜ï¼ˆForgettingï¼‰</strong>ï¼šåˆ é™¤è¿‡æ—¶æˆ–é”™è¯¯çš„å†…å®¹ã€‚</p></li>
</ul>
</li>
<li><p><strong>åˆ©ç”¨ï¼ˆUtilizationï¼‰</strong>ï¼š</p>
<ul>
<li><p><strong>æ£€ç´¢ï¼ˆRetrievalï¼‰</strong>ï¼šè®¿é—®ç›¸å…³è®°å¿†ã€‚</p></li>
<li><p><strong>å‹ç¼©ï¼ˆCompressionï¼‰</strong>ï¼šç¼©å‡è®°å¿†è§„æ¨¡åŒæ—¶ä¿ç•™å…³é”®ä¿¡æ¯ã€‚</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section id="id6">
<h3>1.3 æ ¸å¿ƒç ”ç©¶æ–¹å‘<a class="headerlink" href="#id6" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>é€šè¿‡åˆæ­¥ç ”ç©¶ï¼Œä½œè€…æ€»ç»“å‡ºå››ä¸ªæ ¸å¿ƒæ–¹å‘ï¼Œåˆ†åˆ«ä»<strong>æ—¶é—´ã€ä¸Šä¸‹æ–‡ã€æ¨¡å‹å†…éƒ¨ã€å¤šæ¨¡æ€</strong>ç­‰è§’åº¦æ¢è®¨è®°å¿†ï¼š</p>
<ol class="arabic simple">
<li><p><strong>é•¿æœŸè®°å¿†ï¼ˆLong-Term Memoryï¼‰</strong>ï¼šå…³æ³¨å¤šä¼šè¯ç³»ç»Ÿä¸­çš„è®°å¿†ç®¡ç†ä¸ä¸ªæ€§åŒ–ï¼Œä»¥åŠæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ã€ä¸ªæ€§åŒ–ä»£ç†å’Œé—®ç­”ç³»ç»Ÿã€‚</p></li>
<li><p><strong>é•¿ä¸Šä¸‹æ–‡è®°å¿†ï¼ˆLong-Context Memoryï¼‰</strong>ï¼šæ¶‰åŠå‚æ•°æ•ˆç‡å’Œä¸Šä¸‹æ–‡åˆ©ç”¨æ•ˆæœï¼Œå¦‚â€œKVç¼“å­˜ä¸¢å¼ƒâ€ä¸é•¿ä¸Šä¸‹æ–‡å‹ç¼©ã€‚</p></li>
<li><p><strong>å‚æ•°è®°å¿†ä¿®æ”¹ï¼ˆParametric Memory Modificationï¼‰</strong>ï¼šåŒ…æ‹¬æ¨¡å‹ç¼–è¾‘ã€é—å¿˜ã€æŒç»­å­¦ä¹ ç­‰å†…å­˜å†…éƒ¨æ“ä½œã€‚</p></li>
<li><p><strong>å¤šæºè®°å¿†ï¼ˆMulti-Source Memoryï¼‰</strong>ï¼šå¼ºè°ƒè·¨å¼‚æ„æ–‡æœ¬æºå’Œå¤šæ¨¡æ€è¾“å…¥çš„è®°å¿†æ•´åˆã€‚</p></li>
</ol>
</section>
<section id="id7">
<h3>1.4 æ•°æ®ä¸åˆ†ææ–¹æ³•<a class="headerlink" href="#id7" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p>ä½œè€…ä»å¤šä¸ªé¡¶ä¼šï¼ˆå¦‚NeurIPS, ICLR, ICMLç­‰ï¼‰ä¸­æ”¶é›†å¹¶æ ‡æ³¨äº†<strong>è¶…è¿‡3ä¸‡ç¯‡è®ºæ–‡</strong>ï¼Œä½¿ç”¨åŸºäºGPTçš„ç­›é€‰æµç¨‹ä¿ç•™<strong>3,923ç¯‡é«˜ç›¸å…³æ€§è®ºæ–‡</strong>ã€‚</p></li>
<li><p>æå‡ºäº† **ç›¸å¯¹å¼•ç”¨æŒ‡æ•°ï¼ˆRCIï¼‰**ä½œä¸ºæ—¶é—´å½’ä¸€åŒ–çš„å¼•ç”¨åº¦é‡æŒ‡æ ‡ï¼Œç”¨äºè¯†åˆ«æœ‰å½±å“åŠ›çš„å·¥ä½œã€‚</p></li>
<li><p>é€šè¿‡ç»Ÿä¸€çš„åˆ†ç±»ä¸æ“ä½œæ¡†æ¶å¯¹è¿™äº›è®ºæ–‡è¿›è¡Œç³»ç»Ÿåˆ†æã€‚</p></li>
</ul>
</section>
<section id="id8">
<h3>1.5 è®ºæ–‡ç»“æ„<a class="headerlink" href="#id8" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p>ç¬¬2èŠ‚ä»‹ç»è®°å¿†çš„åˆ†ç±»å’Œæ ¸å¿ƒæ“ä½œã€‚</p></li>
<li><p>ç¬¬3èŠ‚æ˜ å°„é«˜å½±å“åŠ›ç ”ç©¶æ–¹å‘ï¼Œå¹¶æ€»ç»“å…³é”®æ–¹æ³•å’Œæ•°æ®é›†ã€‚</p></li>
<li><p>ç¬¬4èŠ‚è®¨è®ºå®é™…åº”ç”¨åŠå·¥å…·ã€‚</p></li>
<li><p>ç¬¬5èŠ‚å¯¹æ¯”äººç±»ä¸AIè®°å¿†ç³»ç»Ÿçš„å¼‚åŒã€‚</p></li>
<li><p>ç¬¬6èŠ‚å±•æœ›æœªæ¥ç ”ç©¶æ–¹å‘ã€‚</p></li>
</ul>
</section>
<section id="id9">
<h3>å°ç»“<a class="headerlink" href="#id9" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>æœ¬èŠ‚ä¸ºå…¨æ–‡å¥ å®šäº†åŸºç¡€ï¼Œæ˜ç¡®æå‡ºäº†å½“å‰ç ”ç©¶çš„ä¸è¶³ï¼Œå¹¶æ„å»ºäº†ä¸€ä¸ª<strong>ç»Ÿä¸€çš„åˆ†ç±»ä¸æ“ä½œæ¡†æ¶</strong>ï¼Œä¸ºåç»­ç« èŠ‚çš„æ·±å…¥åˆ†ææä¾›äº†æ¸…æ™°çš„ç»“æ„ã€‚é‡ç‚¹åœ¨äº<strong>è®°å¿†çš„åˆ†ç±»ã€æ“ä½œã€ç ”ç©¶æ–¹å‘å’Œæ•°æ®æ”¯æŒ</strong>ï¼Œä¸ºè¯»è€…ç†è§£AIä¸­çš„è®°å¿†æœºåˆ¶å’Œç ”ç©¶ç°çŠ¶æä¾›äº†å…¨é¢çš„æ¦‚è¿°ã€‚</p>
</section>
</section>
<section id="memory-foundations">
<h2>2 Memory Foundations<a class="headerlink" href="#memory-foundations" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<section id="memory-taxonomy">
<h3>2.1 Memory Taxonomyï¼ˆè®°å¿†åˆ†ç±»ï¼‰<a class="headerlink" href="#memory-taxonomy" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>æœ¬èŠ‚ä»è®°å¿†è¡¨ç¤ºçš„è§’åº¦å‡ºå‘ï¼Œå°†è®°å¿†åˆ†ä¸º<strong>Parametric Memoryï¼ˆå‚æ•°è®°å¿†ï¼‰</strong> å’Œ <strong>Contextual Memoryï¼ˆä¸Šä¸‹æ–‡è®°å¿†ï¼‰</strong> ä¸¤ç±»ï¼Œåè€…åˆè¿›ä¸€æ­¥åˆ†ä¸º<strong>æ— ç»“æ„</strong>ä¸<strong>æœ‰ç»“æ„</strong>ä¸¤ç§å½¢å¼ã€‚</p>
<section id="parametric-memory">
<h4>Parametric Memoryï¼ˆå‚æ•°è®°å¿†ï¼‰<a class="headerlink" href="#parametric-memory" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p><strong>å®šä¹‰</strong>ï¼šå‚æ•°è®°å¿†æ˜¯æŒ‡éšå¼å­˜å‚¨åœ¨æ¨¡å‹å†…éƒ¨å‚æ•°ä¸­çš„çŸ¥è¯†ï¼Œé€šè¿‡é¢„è®­ç»ƒæˆ–åè®­ç»ƒè·å¾—ï¼Œå¹¶åœ¨æ¨ç†æ—¶é€šè¿‡å‰é¦ˆè®¡ç®—è®¿é—®ã€‚</p></li>
<li><p><strong>ä¼˜ç‚¹</strong>ï¼šèƒ½å¤Ÿå¿«é€Ÿã€æ— ä¸Šä¸‹æ–‡ä¾èµ–åœ°æ£€ç´¢äº‹å®å’Œå¸¸è¯†çŸ¥è¯†ï¼Œæ˜¯æ¨¡å‹çš„ä¸€ç§å³æ—¶ã€é•¿æœŸä¸”æŒä¹…çš„è®°å¿†å½¢å¼ã€‚</p></li>
<li><p><strong>ç¼ºç‚¹</strong>ï¼šç¼ºä¹é€æ˜æ€§ï¼Œéš¾ä»¥æ ¹æ®æ–°ç»éªŒæˆ–ä»»åŠ¡ä¸Šä¸‹æ–‡è¿›è¡Œé€‰æ‹©æ€§æ›´æ–°ã€‚</p></li>
<li><p><strong>å‚è€ƒæ–‡çŒ®</strong>ï¼šBerges et al.ï¼ˆ2024ï¼‰ã€Wang et al.ï¼ˆ2024cï¼‰ç­‰ã€‚</p></li>
</ul>
</section>
<section id="contextual-memory">
<h4>Contextual Memoryï¼ˆä¸Šä¸‹æ–‡è®°å¿†ï¼‰<a class="headerlink" href="#contextual-memory" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>ä¸Šä¸‹æ–‡è®°å¿†æ˜¯è¡¥å……æ¨¡å‹å‚æ•°çš„æ˜¾å¼å¤–éƒ¨ä¿¡æ¯ï¼Œåˆ†ä¸ºæ— ç»“æ„å’Œæœ‰ç»“æ„ä¸¤ç§å½¢å¼ï¼š</p>
<ul class="simple">
<li><p><strong>Unstructured Contextual Memoryï¼ˆæ— ç»“æ„ä¸Šä¸‹æ–‡è®°å¿†ï¼‰</strong></p>
<ul>
<li><p><strong>å®šä¹‰</strong>ï¼šä¸€ç§é€šç”¨çš„è®°å¿†ç³»ç»Ÿï¼Œå¯ä»¥è·¨å¤šç§è¾“å…¥ï¼ˆå¦‚æ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘ï¼‰å­˜å‚¨å’Œæ£€ç´¢ä¿¡æ¯ã€‚</p></li>
<li><p><strong>åŠŸèƒ½</strong>ï¼šæ”¯æŒå°†æ¨ç†è¿‡ç¨‹ä¸æ„ŸçŸ¥ä¿¡å·ç»“åˆï¼Œé›†æˆå¤šæ¨¡æ€ä¸Šä¸‹æ–‡ã€‚</p></li>
<li><p><strong>æ—¶é—´åˆ’åˆ†</strong>ï¼šåˆ†ä¸ºçŸ­æœŸè®°å¿†ï¼ˆå¦‚å½“å‰å¯¹è¯ä¸Šä¸‹æ–‡ï¼‰å’Œé•¿æœŸè®°å¿†ï¼ˆå¦‚è·¨ä¼šè¯çš„å¯¹è¯è®°å½•å’ŒæŒä¹…çŸ¥è¯†ï¼‰ã€‚</p></li>
<li><p><strong>å‚è€ƒæ–‡çŒ®</strong>ï¼šZhong et al.ï¼ˆ2024ï¼‰ã€Wang et al.ï¼ˆ2025aï¼‰ç­‰ã€‚</p></li>
</ul>
</li>
<li><p><strong>Structured Contextual Memoryï¼ˆç»“æ„åŒ–ä¸Šä¸‹æ–‡è®°å¿†ï¼‰</strong></p>
<ul>
<li><p><strong>å®šä¹‰</strong>ï¼šä»¥é¢„å®šä¹‰ã€å¯è§£é‡Šå½¢å¼ç»„ç»‡çš„è®°å¿†ï¼Œå¦‚çŸ¥è¯†å›¾ã€å…³ç³»è¡¨æˆ–æœ¬ä½“ã€‚</p></li>
<li><p><strong>åŠŸèƒ½</strong>ï¼šæ”¯æŒç¬¦å·æ¨ç†å’Œç²¾ç¡®æŸ¥è¯¢ï¼Œå¸¸ä¸é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„å…³è”èƒ½åŠ›äº’è¡¥ã€‚</p></li>
<li><p><strong>æ—¶é—´åˆ’åˆ†</strong>ï¼šå¯ä»¥æ˜¯çŸ­æœŸï¼ˆæ¨ç†æ—¶æ„å»ºçš„å±€éƒ¨è®°å¿†ï¼‰æˆ–é•¿æœŸï¼ˆè·¨ä¼šè¯çš„ç»“æ„åŒ–çŸ¥è¯†å­˜å‚¨ï¼‰ã€‚</p></li>
<li><p><strong>å‚è€ƒæ–‡çŒ®</strong>ï¼šOguz et al.ï¼ˆ2022ï¼‰ã€Lu et al.ï¼ˆ2023ï¼‰ç­‰ã€‚</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section id="memory-operations">
<h3>2.2 Memory Operationsï¼ˆè®°å¿†æ“ä½œï¼‰<a class="headerlink" href="#memory-operations" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>ä¸ºå®ç°åŠ¨æ€è®°å¿†ï¼ˆè€Œéé™æ€å­˜å‚¨ï¼‰ï¼ŒAIç³»ç»Ÿéœ€è¦è®°å¿†çš„ç”Ÿå‘½å‘¨æœŸæ“ä½œï¼Œè¿™äº›æ“ä½œå¯å½’çº³ä¸ºä¸¤å¤§ç±»ï¼š</p>
<ol class="arabic simple">
<li><p><strong>Memory Managementï¼ˆè®°å¿†ç®¡ç†ï¼‰</strong>ï¼šå†³å®šå¦‚ä½•å­˜å‚¨ã€ç»´æŠ¤å’Œåˆ é™¤è®°å¿†ã€‚</p></li>
<li><p><strong>Memory Utilizationï¼ˆè®°å¿†åˆ©ç”¨ï¼‰</strong>ï¼šå†³å®šå¦‚ä½•æ£€ç´¢å’Œå‹ç¼©è®°å¿†ä»¥ç”¨äºæ¨ç†ã€‚</p></li>
</ol>
</section>
<section id="memory-management">
<h3>2.3 Memory Managementï¼ˆè®°å¿†ç®¡ç†ï¼‰<a class="headerlink" href="#memory-management" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>è®°å¿†ç®¡ç†åŒ…å«å››ä¸ªæ ¸å¿ƒæ“ä½œï¼Œåˆ†åˆ«å¤„ç†è®°å¿†çš„å­˜å‚¨ã€æ›´æ–°ä¸åˆ é™¤ï¼š</p>
<section id="consolidation">
<h4>1. Consolidationï¼ˆè®°å¿†æ•´åˆï¼‰<a class="headerlink" href="#consolidation" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p><strong>åŠŸèƒ½</strong>ï¼šå°†çŸ­æœŸç»å†æ•´åˆä¸ºæŒä¹…è®°å¿†ï¼Œé€šå¸¸ç”¨äºæ„å»ºæ¨¡å‹å‚æ•°ã€çŸ¥è¯†å›¾æˆ–çŸ¥è¯†åº“ã€‚</p></li>
<li><p><strong>åº”ç”¨åœºæ™¯</strong>ï¼šæŒç»­å­¦ä¹ ã€ä¸ªæ€§åŒ–ã€è®°å¿†åº“æ„å»ºã€‚</p></li>
<li><p><strong>å…¬å¼è¡¨ç¤º</strong>ï¼š<br />
$<span class="math notranslate nohighlight">\(
\mathcal{M}_{t+\Delta_t} = \texttt{Consolidate}(\mathcal{M}_t, \mathcal{E}_{[t,t+\Delta_t]})
\)</span>$</p></li>
<li><p><strong>å‚è€ƒæ–‡çŒ®</strong>ï¼šSquire et al.ï¼ˆ2015ï¼‰ã€Wang et al.ï¼ˆ2024jï¼‰ç­‰ã€‚</p></li>
</ul>
</section>
<section id="indexing">
<h4>2. Indexingï¼ˆç´¢å¼•ï¼‰<a class="headerlink" href="#indexing" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p><strong>åŠŸèƒ½</strong>ï¼šæ„å»ºè¾…åŠ©ä»£ç ï¼ˆå¦‚å®ä½“ã€å±æ€§ã€è¡¨ç¤ºï¼‰ä½œä¸ºè®°å¿†è®¿é—®ç‚¹ï¼Œæå‡æ£€ç´¢æ•ˆç‡å’Œè¯­ä¹‰è¿è´¯æ€§ã€‚</p></li>
<li><p><strong>åº”ç”¨åœºæ™¯</strong>ï¼šæ”¯æŒç¬¦å·ã€ç¥ç»å’Œæ··åˆè®°å¿†ç³»ç»Ÿçš„è§„æ¨¡åŒ–æ£€ç´¢ã€‚</p></li>
<li><p><strong>å…¬å¼è¡¨ç¤º</strong>ï¼š<br />
$<span class="math notranslate nohighlight">\(
\mathcal{I}_t = \texttt{Index}(\mathcal{M}_t, \phi)
\)</span>$</p></li>
<li><p><strong>å‚è€ƒæ–‡çŒ®</strong>ï¼šMaekawa et al.ï¼ˆ2023ï¼‰ã€‚</p></li>
</ul>
</section>
<section id="updating">
<h4>3. Updatingï¼ˆæ›´æ–°ï¼‰<a class="headerlink" href="#updating" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p><strong>åŠŸèƒ½</strong>ï¼šé‡æ–°æ¿€æ´»æ—§è®°å¿†å¹¶ç”¨æ–°çŸ¥è¯†ä¸´æ—¶ä¿®æ”¹ï¼Œç»´æŠ¤è®°å¿†ä¸€è‡´æ€§ã€‚</p></li>
<li><p><strong>å®ç°æ–¹å¼</strong>ï¼š</p>
<ul>
<li><p>å‚æ•°è®°å¿†ï¼šå®šä½-ç¼–è¾‘æœºåˆ¶ã€‚</p></li>
<li><p>ä¸Šä¸‹æ–‡è®°å¿†ï¼šæ‘˜è¦ã€å‰ªææˆ–ç²¾ç‚¼ã€‚</p></li>
</ul>
</li>
<li><p><strong>å…¬å¼è¡¨ç¤º</strong>ï¼š<br />
$<span class="math notranslate nohighlight">\(
\mathcal{M}_{t+\Delta_t} = \texttt{Update}(\mathcal{M}_t, \mathcal{K}_{t+\Delta_t})
\)</span>$</p></li>
<li><p><strong>å‚è€ƒæ–‡çŒ®</strong>ï¼šKiley and Parksï¼ˆ2022ï¼‰ã€Bae et al.ï¼ˆ2022ï¼‰ç­‰ã€‚</p></li>
</ul>
</section>
<section id="forgetting">
<h4>4. Forgettingï¼ˆé—å¿˜ï¼‰<a class="headerlink" href="#forgetting" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p><strong>åŠŸèƒ½</strong>ï¼šé€‰æ‹©æ€§æŠ‘åˆ¶è¿‡æ—¶ã€æ— å…³æˆ–æœ‰å®³çš„è®°å¿†å†…å®¹ã€‚</p></li>
<li><p><strong>å®ç°æ–¹å¼</strong>ï¼š</p>
<ul>
<li><p>å‚æ•°è®°å¿†ï¼šä½¿ç”¨å»å­¦ä¹ æŠ€æœ¯ã€‚</p></li>
<li><p>ä¸Šä¸‹æ–‡è®°å¿†ï¼šæ—¶é—´åˆ é™¤æˆ–è¯­ä¹‰è¿‡æ»¤ã€‚</p></li>
</ul>
</li>
<li><p><strong>å…¬å¼è¡¨ç¤º</strong>ï¼š<br />
$<span class="math notranslate nohighlight">\(
\mathcal{M}_{t+\Delta_t} = \texttt{Forget}(\mathcal{M}_t, \mathcal{F})
\)</span>$</p></li>
<li><p><strong>å‚è€ƒæ–‡çŒ®</strong>ï¼šDavis and Zhongï¼ˆ2017ï¼‰ã€Wang et al.ï¼ˆ2009ï¼‰ç­‰ã€‚</p></li>
</ul>
</section>
<section id="id10">
<h4>é£é™©ä¸æŒ‘æˆ˜<a class="headerlink" href="#id10" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p>é—å¿˜å’Œæ›´æ–°æ“ä½œå¯èƒ½å¼•å…¥å®‰å…¨é£é™©ï¼Œæ¯”å¦‚è®°å¿†è¢«ç¯¡æ”¹æˆ–æ¯’åŒ–ï¼Œéœ€åœ¨ç¬¬6èŠ‚ä¸­è¿›ä¸€æ­¥è®¨è®ºã€‚</p></li>
</ul>
</section>
</section>
<section id="memory-utilization">
<h3>2.4 Memory Utilizationï¼ˆè®°å¿†åˆ©ç”¨ï¼‰<a class="headerlink" href="#memory-utilization" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>è®°å¿†åˆ©ç”¨æ¶‰åŠå¦‚ä½•åœ¨æ¨ç†ä¸­ä½¿ç”¨å·²å­˜å‚¨çš„è®°å¿†ï¼Œä¸»è¦åŒ…æ‹¬ä¸¤ä¸ªæ“ä½œï¼š</p>
<section id="retrieval">
<h4>1. Retrievalï¼ˆæ£€ç´¢ï¼‰<a class="headerlink" href="#retrieval" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p><strong>åŠŸèƒ½</strong>ï¼šæ ¹æ®è¾“å…¥æŸ¥è¯¢ä»è®°å¿†ä¸­è¯†åˆ«å¹¶è®¿é—®ç›¸å…³ä¿¡æ¯ï¼Œæ”¯æŒä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚å“åº”ç”Ÿæˆã€è§†è§‰å®šä½ã€æ„å›¾é¢„æµ‹ï¼‰ã€‚</p></li>
<li><p><strong>è¾“å…¥ç±»å‹</strong>ï¼šå¯åŒ…æ‹¬ç®€å•æŸ¥è¯¢ã€å¤šè½®å¯¹è¯ã€è§†è§‰å†…å®¹ç­‰ã€‚</p></li>
<li><p><strong>æ£€ç´¢æ¡ä»¶</strong>ï¼šé€šå¸¸ä½¿ç”¨ç›¸ä¼¼åº¦å‡½æ•° <code class="docutils literal notranslate"><span class="pre">sim()</span></code>ï¼Œé€‰å–ä¸æŸ¥è¯¢ç›¸ä¼¼åº¦é«˜äºé˜ˆå€¼ <span class="math notranslate nohighlight">\(\tau\)</span> çš„è®°å¿†ç‰‡æ®µã€‚</p></li>
<li><p><strong>å…¬å¼è¡¨ç¤º</strong>ï¼š<br />
$<span class="math notranslate nohighlight">\(
\texttt{Retrieve}(\mathcal{M}_t, \mathcal{Q}) = m_{\mathcal{Q}} \in \mathcal{M}_t \quad \text{with } \text{sim}(\mathcal{Q}, m_{\mathcal{Q}}) \geq \tau
\)</span>$</p></li>
<li><p><strong>å‚è€ƒæ–‡çŒ®</strong>ï¼šDu et al.ï¼ˆ2024ï¼‰ã€Wang et al.ï¼ˆ2025aï¼‰ç­‰ã€‚</p></li>
</ul>
</section>
<section id="compression">
<h4>2. Compressionï¼ˆå‹ç¼©ï¼‰<a class="headerlink" href="#compression" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p><strong>åŠŸèƒ½</strong>ï¼šåœ¨æ¨¡å‹è¾“å…¥çª—å£æœ‰é™çš„å‰æä¸‹ï¼Œé€šè¿‡å‹ç¼©ä¿ç•™å…³é”®ä¿¡æ¯ã€å»é™¤å†—ä½™ã€‚</p></li>
<li><p><strong>åˆ†ç±»</strong>ï¼š</p>
<ul>
<li><p><strong>Pre-input compressionï¼ˆè¾“å…¥å‰å‹ç¼©ï¼‰</strong>ï¼šç”¨äºæœªä½¿ç”¨æ£€ç´¢çš„é•¿ä¸Šä¸‹æ–‡æ¨¡å‹ã€‚</p></li>
<li><p><strong>Post-retrieval compressionï¼ˆæ£€ç´¢åå‹ç¼©ï¼‰</strong>ï¼šå‡å°‘æ£€ç´¢åˆ°çš„å†…å®¹ï¼Œå¯é€šè¿‡ä¸Šä¸‹æ–‡å‹ç¼©æˆ–å‚æ•°å‹ç¼©å®ç°ã€‚</p></li>
</ul>
</li>
<li><p><strong>å…¬å¼è¡¨ç¤º</strong>ï¼š<br />
$<span class="math notranslate nohighlight">\(
\mathcal{M}_t^{comp} = \texttt{Compress}(\mathcal{M}_t, \alpha)
\)</span>$</p></li>
<li><p><strong>å‚è€ƒæ–‡çŒ®</strong>ï¼šYu et al.ï¼ˆ2023ï¼‰ã€Xu et al.ï¼ˆ2024aï¼‰ç­‰ã€‚</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="id11">
<h3>æ€»ç»“<a class="headerlink" href="#id11" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>æœ¬ç« ç³»ç»Ÿåœ°ä»‹ç»äº†AIç³»ç»Ÿä¸­è®°å¿†çš„åŸºç¡€ç†è®ºå’Œæ“ä½œæœºåˆ¶ï¼Œæ¶µç›–è®°å¿†çš„åˆ†ç±»ï¼ˆå‚æ•°ä¸ä¸Šä¸‹æ–‡ï¼‰ã€è®°å¿†ç®¡ç†ï¼ˆæ•´åˆã€ç´¢å¼•ã€æ›´æ–°ã€é—å¿˜ï¼‰å’Œè®°å¿†åˆ©ç”¨ï¼ˆæ£€ç´¢ã€å‹ç¼©ï¼‰ã€‚é‡ç‚¹åœ¨äºç†è§£è®°å¿†çš„åŠ¨æ€ç®¡ç†æµç¨‹åŠå…¶åœ¨ä¸åŒä»»åŠ¡ä¸­çš„åº”ç”¨ï¼ŒåŒæ—¶æŒ‡å‡ºæ“ä½œä¸­å¯èƒ½å­˜åœ¨çš„é£é™©ã€‚</p>
</section>
</section>
<section id="from-operations-to-key-research-topics">
<h2>3 From Operations to Key Research Topics<a class="headerlink" href="#from-operations-to-key-research-topics" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/08/memory_rethinking_in_ai.png" /></p>
<p>Figure 2: Operation-driven key research topics in AI systems.</p>
<p>åˆ†æäº†ç°å®ç³»ç»Ÿä¸­å¦‚ä½•é€šè¿‡æ ¸å¿ƒæ“ä½œæ¥ç®¡ç†å’Œåˆ©ç”¨å†…å­˜ï¼Œå¹¶å›´ç»•å››ä¸ªå…³é”®ç ”ç©¶ä¸»é¢˜å±•å¼€è®¨è®ºï¼Œåˆ†åˆ«æ˜¯<strong>é•¿æœŸè®°å¿†ï¼ˆLong-term Memoryï¼‰<strong>å’Œ</strong>é•¿ä¸Šä¸‹æ–‡ï¼ˆLong-contextï¼‰</strong>ã€‚æ–‡ç« é€šè¿‡ <strong>ç›¸å¯¹å¼•ç”¨æŒ‡æ•°ï¼ˆRCIï¼‰</strong> è¯†åˆ«å‡ºå…·æœ‰å½±å“åŠ›çš„æˆæœï¼Œå¹¶å€ŸåŠ©å›¾ç¤ºå’Œè¡¨æ ¼å±•ç¤ºä¸åŒå†…å­˜ç±»å‹ä¸æ“ä½œä¹‹é—´çš„å…³ç³»ã€‚ä»¥ä¸‹æ˜¯å¯¹æœ¬ç« å†…å®¹çš„ç»“æ„åŒ–æ€»ç»“ã€‚</p>
<section id="long-term-memory">
<h3><strong>3.1 é•¿æœŸè®°å¿† (Long-term Memory)</strong><a class="headerlink" href="#long-term-memory" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/08/cPZPdy.jpg" /></p>
<p>Table 4:Datasets used for evaluating long-term memory. â€œMoâ€ denotes modality. â€œOpsâ€ denotes operability (placeholder). â€œDS Typeâ€ indicates dataset type (QA â€“ question answering, MS â€“ multi-session dialogue). â€œPerâ€ and â€œTRâ€ indicate whether persona and temporal reasoning are present.</p>
<section id="id12">
<h4><strong>æ ¸å¿ƒæ¦‚å¿µ</strong><a class="headerlink" href="#id12" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p><strong>é•¿æœŸè®°å¿†</strong> æŒ‡çš„æ˜¯æ™ºèƒ½ä½“ï¼ˆå¦‚AIæ¨¡å‹ï¼‰åœ¨ä¸ç¯å¢ƒäº¤äº’ï¼ˆå¦‚å¤šè½®å¯¹è¯ã€æµè§ˆæ¨¡å¼ã€å†³ç­–è·¯å¾„ï¼‰ä¸­è·å–çš„ä¿¡æ¯çš„æŒä¹…åŒ–å­˜å‚¨ã€‚å®ƒæ”¯æŒè®°å¿†ç®¡ç†ã€åˆ©ç”¨å’Œä¸ªæ€§åŒ–ç­‰èƒ½åŠ›ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿæ‰§è¡Œå¤æ‚ä»»åŠ¡ã€‚</p>
<p><strong>å…³é”®åŒºåˆ«</strong>ï¼šæœ¬èŠ‚è®¨è®ºçš„æ˜¯<strong>ä¸Šä¸‹æ–‡é•¿æœŸè®°å¿†</strong>ï¼ˆå¯ä»¥æ˜¯ç»“æ„åŒ–çš„æˆ–éç»“æ„åŒ–çš„ï¼‰ï¼Œå®ƒä¸é€šè¿‡æŒç»­å­¦ä¹ å­˜å‚¨åœ¨æ¨¡å‹æƒé‡ä¸­çš„<strong>å‚æ•°è®°å¿†</strong>ä¸åŒã€‚</p>
<hr class="docutils" />
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/08/wcKsi7.jpg" /></p>
<p>Table 9:Overview of methods for long-term memory in memory management and utilization. â€œTFâ€ (Training Free) denotes whether the method operates without additional gradient-based updates. â€œREâ€ (Retrieval Module) denotes whether the method needs Retrieval. â€œDSâ€ (Dialogue System) denotes whether the method aims for a dialogue task.</p>
</section>
<section id="management">
<h4><strong>3.1.1 ç®¡ç† (Management)</strong><a class="headerlink" href="#management" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>ç®¡ç†æ¶‰åŠå¯¹å·²è·å–ç»éªŒçš„<strong>å·©å›ºã€ç´¢å¼•ã€æ›´æ–°å’Œé—å¿˜</strong>ç­‰æ“ä½œã€‚</p>
<ul class="simple">
<li><p><strong>ä¸¤ç§å®ä¾‹åŒ–å½¢å¼</strong>ï¼š</p>
<ol class="arabic simple">
<li><p><strong>ç§¯ç´¯çš„å¤šè½®å¯¹è¯å†å²</strong>ã€‚</p></li>
<li><p><strong>è‡ªä¸»æ™ºèƒ½ä½“çš„é•¿æœŸè§‚å¯Ÿå’Œå†³ç­–</strong>ã€‚
è¿™äº›è®°å¿†é€šå¸¸ç”±å¤§è¯­è¨€æ¨¡å‹(LLM)ç¼–ç ï¼Œå¹¶å­˜å‚¨åœ¨å¤–éƒ¨çš„è®°å¿†åº“ä¸­ï¼Œä¾›æœªæ¥è®¿é—®å’Œé‡ç”¨ã€‚è®°å¿†ä¼šéšç€æ–°ä¿¡æ¯çš„åŠ å…¥è€Œæ›´æ–°ï¼Œå¹¶ä¼šä¿®å‰ªè¿‡æ—¶æˆ–æ— å…³çš„å†…å®¹ã€‚</p></li>
</ol>
</li>
<li><p><strong>å››ä¸ªå­æ“ä½œ</strong>ï¼š</p>
<ol class="arabic simple">
<li><p><strong>è®°å¿†å·©å›º (Memory Consolidation)</strong>ï¼šå°†çŸ­æœŸè®°å¿†è½¬åŒ–ä¸ºé•¿æœŸè®°å¿†çš„è¿‡ç¨‹ã€‚å¸¸ç”¨<strong>æ‘˜è¦æ€»ç»“</strong>æŠ€æœ¯æ¥ç”Ÿæˆéç»“æ„åŒ–çš„è®°å¿†è¡¨ç¤ºï¼ˆå¦‚MemoryBank, ChatGPT-RSumï¼‰ã€‚ä¹Ÿæœ‰å·¥ä½œåˆ©ç”¨LLMæç¤ºæ¥è¯†åˆ«å’Œç»“æ„åŒ–ç›¸å…³ä¿¡æ¯(Lu et al., 2023)ï¼Œæˆ–é€šè¿‡å»ºæ¨¡æ—¶é—´ç›¸å…³æ€§æ¥åŠ å¼ºè®°å¿†(MyAgent)ï¼Œç”šè‡³æ¨¡ä»¿äººç±»çš„æƒ…æ™¯è®°å¿†ï¼ˆä»€ä¹ˆ-å“ªé‡Œ-ä½•æ—¶ï¼‰æ¥åˆ†å±‚ç»„ç»‡çŸ¥è¯†ä»¥è¿›è¡Œè¡ŒåŠ¨è§„åˆ’(Park et al., 2025)ã€‚</p></li>
<li><p><strong>è®°å¿†ç´¢å¼• (Memory Indexing)</strong>ï¼šæ„å»ºè®°å¿†è¡¨ç¤ºä»¥æ”¯æŒé«˜æ•ˆå‡†ç¡®æ£€ç´¢çš„åŸºç¡€è¿‡ç¨‹ã€‚åˆ†ä¸ºä¸‰ç±»èŒƒå¼ï¼š</p>
<ul>
<li><p><strong>åŸºäºå›¾çš„æ–¹æ³•</strong>ï¼šå¦‚HippoRAGï¼Œæ„å»ºè½»é‡çº§çŸ¥è¯†å›¾è°±æ¥æ˜¾å¼æ­ç¤ºä¸åŒçŸ¥è¯†ç‰‡æ®µé—´çš„è”ç³»ã€‚</p></li>
<li><p><strong>ä¿¡å·å¢å¼ºçš„æ–¹æ³•</strong>ï¼šå¦‚LongMemEvalï¼Œç”¨æ—¶é—´æˆ³ã€äº‹å®å†…å®¹å’Œæ‘˜è¦æ¥å¢å¼ºè®°å¿†é”®ã€‚</p></li>
<li><p><strong>åŸºäºæ—¶é—´çº¿çš„æ–¹æ³•</strong>ï¼šå¦‚Theanineï¼Œæ²¿ç€æ¼”åŒ–çš„æ—¶é—´å’Œå› æœé“¾ç»„ç»‡è®°å¿†ï¼Œæ”¯æŒåŸºäºç›¸å…³æ€§å’Œæ—¶é—´çº¿çš„æ£€ç´¢ï¼Œå®ç°ç»ˆèº«å’ŒåŠ¨æ€ä¸ªæ€§åŒ–ã€‚</p></li>
</ul>
</li>
<li><p><strong>è®°å¿†æ›´æ–° (Memory Updating)</strong>ï¼šæŒ‡å¤–éƒ¨è®°å¿†ä¸ºæœªè§ä¿¡æ¯åˆ›å»ºæ–°æ¡ç›®ï¼Œæˆ–å°†æ–°å†…å®¹ä¸ç°æœ‰è®°å¿†è¡¨å¾é‡ç»„å’Œæ•´åˆçš„è¿‡ç¨‹ã€‚åˆ†ä¸ºä¸¤å¤§èŒƒå¼ï¼š</p>
<ul>
<li><p><strong>å†…åœ¨æ›´æ–° (Intrinsic Updating)</strong>ï¼šé€šè¿‡å†…éƒ¨æœºåˆ¶æ›´æ–°ï¼Œæ— å¤–éƒ¨åé¦ˆã€‚åŒ…æ‹¬é€‰æ‹©æ€§ç¼–è¾‘åˆ é™¤è¿‡æ—¶ä¿¡æ¯ã€é€’å½’æ‘˜è¦å‹ç¼©å¯¹è¯å†å²ã€è®°å¿†æ··åˆä¸ç²¾ç‚¼åˆå¹¶è¿‡å»å’Œç°åœ¨çš„è¡¨å¾ã€åŸºäºè¯æ®æ£€ç´¢å’ŒéªŒè¯çš„è‡ªæˆ‘åæ€å¼è®°å¿†æ¼”åŒ–ã€‚</p></li>
<li><p><strong>å¤–åœ¨æ›´æ–° (Extrinsic Updating)</strong>ï¼šä¾èµ–å¤–éƒ¨ä¿¡å·ï¼ˆç‰¹åˆ«æ˜¯ç”¨æˆ·åé¦ˆï¼‰æ›´æ–°ã€‚å¦‚å­˜å‚¨ç”¨æˆ·ä¿®æ­£åˆ°è®°å¿†ä¸­ä»¥å®ç°æŒç»­æ”¹è¿›ï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒã€‚</p></li>
</ul>
</li>
<li><p><strong>è®°å¿†é—å¿˜ (Memory Forgetting)</strong>ï¼šç§»é™¤å·²å·©å›ºçš„é•¿æœŸè®°å¿†è¡¨å¾çš„è¿‡ç¨‹ã€‚</p>
<ul>
<li><p><strong>è‡ªç„¶é—å¿˜</strong>ï¼šéµå¾ªè‰¾å®¾æµ©æ–¯é—å¿˜æ›²çº¿ï¼Œè®°å¿†ç—•è¿¹éšæ—¶é—´é€æ¸è¡°å‡ã€‚</p></li>
<li><p><strong>ä¸»åŠ¨é—å¿˜</strong>ï¼šæ•…æ„ä»è®°å¿†ç³»ç»Ÿä¸­ç§»é™¤ç‰¹å®šä¿¡æ¯ï¼ˆå¦‚å‡ºäºéšç§ã€å®‰å…¨ã€åˆè§„åŸå› ï¼‰ã€‚è¿™åœ¨å¤„ç†æ•æ„Ÿæˆ–æœ‰å®³å†…å®¹æ—¶å°¤ä¸ºé‡è¦(Chen et al., 2024b; Mitchell et al., 2022bç­‰)ã€‚</p></li>
</ul>
</li>
</ol>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="utilization">
<h4><strong>3.1.2 åˆ©ç”¨ (Utilization)</strong><a class="headerlink" href="#utilization" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>åˆ©ç”¨æŒ‡æ ¹æ®å½“å‰è¾“å…¥å’Œç›¸å…³è®°å¿†å†…å®¹ç”Ÿæˆå“åº”çš„è¿‡ç¨‹ï¼Œé€šå¸¸æ¶‰åŠè®°å¿†<strong>è·¯ç”±ã€æ•´åˆå’Œè¯»å–</strong>ã€‚</p>
<ul class="simple">
<li><p><strong>ä¸‰ä¸ªå­æ“ä½œ</strong>ï¼š</p>
<ol class="arabic simple">
<li><p><strong>è®°å¿†æ£€ç´¢ (Memory Retrieval)</strong>ï¼šæ ¹æ®ç»™å®šæŸ¥è¯¢é€‰æ‹©æœ€ç›¸å…³çš„è®°å¿†æ¡ç›®ã€‚åˆ†ä¸ºä¸‰ç±»èŒƒå¼ï¼š</p>
<ul>
<li><p><strong>ä»¥æŸ¥è¯¢ä¸ºä¸­å¿ƒ</strong>ï¼šæ”¹è¿›æŸ¥è¯¢ formulation å’Œé€‚åº”ï¼ˆå¦‚FLAREä¸­çš„å‰å‘æŸ¥è¯¢é‡å†™ï¼ŒIterCQRä¸­çš„è¿­ä»£ç²¾ç‚¼ï¼‰ã€‚</p></li>
<li><p><strong>ä»¥è®°å¿†ä¸ºä¸­å¿ƒ</strong>ï¼šå¢å¼ºè®°å¿†å€™é€‰çš„ç»„ç»‡å’Œæ’åºï¼ˆå¦‚æ›´å¥½çš„ç´¢å¼•ç­–ç•¥Wu et al., 2024aï¼Œé‡æ’åºæ–¹æ³•Du et al., 2024ï¼‰ã€‚</p></li>
<li><p><strong>ä»¥äº‹ä»¶ä¸ºä¸­å¿ƒ</strong>ï¼šåŸºäºæ—¶é—´å’Œå› æœç»“æ„æ£€ç´¢è®°å¿†ï¼ˆå¦‚LoCoMo, CC, MSCï¼‰ã€‚
å…¶ä»–æŠ€æœ¯å¦‚å¤šè·³å›¾éå†(GutiÃ©rrez et al., 2024)å’Œè®°å¿†å›¾æ¼”åŒ–(Qian et al., 2024)ä¹Ÿä¸°å¯Œäº†æ£€ç´¢è¿‡ç¨‹ã€‚</p></li>
</ul>
</li>
<li><p><strong>è®°å¿†æ•´åˆ (Memory Integration)</strong>ï¼šé€‰æ‹©æ€§åœ°å°†æ£€ç´¢åˆ°çš„è®°å¿†ä¸æ¨¡å‹ä¸Šä¸‹æ–‡ç»“åˆï¼Œä»¥åœ¨æ¨ç†è¿‡ç¨‹ä¸­å®ç°è¿è´¯æ¨ç†æˆ–å†³ç­–ã€‚æ•´åˆå¯èƒ½è·¨è¶Šå¤šä¸ªè®°å¿†æºå’Œæ¨¡æ€ã€‚åˆ†ä¸ºä¸¤ç§ç­–ç•¥ï¼š</p>
<ul>
<li><p><strong>é™æ€ä¸Šä¸‹æ–‡æ•´åˆ</strong>ï¼šåœ¨æ¨ç†æ—¶æ£€ç´¢å’Œç»„åˆé™æ€è®°å¿†æ¡ç›®ä»¥ä¸°å¯Œä¸Šä¸‹æ–‡å’Œæé«˜æ¨ç†ä¸€è‡´æ€§ï¼ˆå¦‚EWE, Optimus-1ï¼‰ã€‚</p></li>
<li><p><strong>åŠ¨æ€è®°å¿†æ¼”åŒ–</strong>ï¼šå¼ºè°ƒè®°å¿†åœ¨äº¤äº’è¿‡ç¨‹ä¸­å¢é•¿ã€é€‚åº”å’Œé‡æ„ï¼ˆå¦‚é€šè¿‡åŠ¨æ€é“¾æ¥æˆ–å—æ§è®°å¿†æ›´æ–°ï¼‰ï¼Œä¾‹å¦‚A-MEM, Synapse, R2I, SCMã€‚</p></li>
</ul>
</li>
<li><p><strong>è®°å¿†æ¥åœ°ç”Ÿæˆ (Memory Grounded Generation)</strong>ï¼šåˆ©ç”¨å·²æ•´åˆçš„æ£€ç´¢è®°å¿†å†…å®¹æ¥æŒ‡å¯¼å“åº”ç”Ÿæˆã€‚åˆ†ä¸ºä¸‰ç§æ–¹æ³•ï¼š</p>
<ul>
<li><p><strong>è‡ªæˆ‘åæ€æ¨ç†</strong>ï¼šæ£€ç´¢è‡ªæˆ‘ç”Ÿæˆæˆ–ç»“æ„åŒ–çš„è®°å¿†è½¨è¿¹æ¥æŒ‡å¯¼ä¸­é—´æ¨ç†æ­¥éª¤ï¼Œå¢å¼ºè§£ç è¿‡ç¨‹ä¸­çš„å¤šè·³æ¨ç†ï¼ˆå¦‚MoT, StructRAGï¼‰ã€‚</p></li>
<li><p><strong>åé¦ˆå¼•å¯¼ä¿®æ­£</strong>ï¼šåˆ©ç”¨åé¦ˆè®°å¿†æˆ–è®°å¿†ä¿¡æ¯çº¿ç´¢æ¥çº¦æŸç”Ÿæˆï¼Œé˜²æ­¢é‡å¤é”™è¯¯å’Œæé«˜è¾“å‡ºé²æ£’æ€§ï¼ˆå¦‚MemoRAG, Repairï¼‰ã€‚</p></li>
<li><p><strong>ä¸Šä¸‹æ–‡å¯¹é½çš„é•¿æœŸç”Ÿæˆ</strong>ï¼šå°†å‹ç¼©æˆ–æå–çš„è®°å¿†æ‘˜è¦æ•´åˆåˆ°ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œä»¥åœ¨é•¿å¯¹è¯æˆ–é•¿æ–‡æ¡£ä¸­ä¿æŒè¿è´¯æ€§ï¼ˆå¦‚COMEDY, MemoChat, ReadAgentï¼‰ã€‚</p></li>
</ul>
</li>
</ol>
</li>
</ul>
</section>
<hr class="docutils" />
<section id="personalization">
<h4><strong>3.1.3 ä¸ªæ€§åŒ– (Personalization)</strong><a class="headerlink" href="#personalization" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/08/KdPb9l.jpg" /></p>
<p>Table 8:Overview of methods for long-term memory in personalization. â€œTFâ€ (Training Free) denotes whether the method operates without additional gradient-based updates. â€œREâ€ (Retrieval Module) denotes whether the method needs Retrieval.</p>
<p>ä¸ªæ€§åŒ–æ˜¯é•¿æœŸè®°å¿†çš„å…³é”®ä½†å…·æœ‰æŒ‘æˆ˜æ€§çš„æ–¹é¢ï¼Œå—é™äºæ•°æ®ç¨€ç–æ€§ã€éšç§å’Œç”¨æˆ·åå¥½å˜åŒ–ã€‚å½“å‰æ–¹æ³•å¯åˆ†ä¸ºä¸¤ç±»ï¼š</p>
<ol class="arabic simple">
<li><p><strong>æ¨¡å‹çº§é€‚åº” (Model-Level Adaptation)</strong>ï¼šé€šè¿‡å¾®è°ƒæˆ–è½»é‡çº§æ›´æ–°å°†ç”¨æˆ·åå¥½ç¼–ç åˆ°æ¨¡å‹å‚æ•°ä¸­ã€‚</p>
<ul class="simple">
<li><p>ä¸€äº›æ–¹æ³•åœ¨æ½œåœ¨ç©ºé—´ä¸­åµŒå…¥ç”¨æˆ·ç‰¹å¾ï¼ˆå¦‚CLVä½¿ç”¨å¯¹æ¯”å­¦ä¹ èšç±»äººç‰©æè¿°æ¥æŒ‡å¯¼ç”Ÿæˆï¼‰ã€‚</p></li>
<li><p>å…¶ä»–é‡‡ç”¨å‚æ•°é«˜æ•ˆç­–ç•¥ï¼ˆå¦‚RECAPé€šè¿‡å‰ç¼€ç¼–ç å™¨æ³¨å…¥æ£€ç´¢åˆ°çš„ç”¨æˆ·å†å²ï¼ŒPer-Pesç»„è£…æ¨¡å—åŒ–é€‚é…å™¨æ¥åæ˜ ç”¨æˆ·è¡Œä¸ºï¼‰ã€‚</p></li>
<li><p>åœ¨ä¸“ä¸šé¢†åŸŸï¼ˆå¦‚åŒ»ç–—å¯¹è¯ï¼‰ï¼ŒMaLPå¼•å…¥äº†åŒè¿‡ç¨‹è®°å¿†æ¥å»ºæ¨¡çŸ­æœŸå’Œé•¿æœŸä¸ªæ€§åŒ–ã€‚</p></li>
</ul>
</li>
<li><p><strong>å¤–éƒ¨è®°å¿†å¢å¼º (External Memory Augmentation)</strong>ï¼šåœ¨æ¨ç†æ—¶ä»å¤–éƒ¨è®°å¿†ä¸­æ£€ç´¢ç”¨æˆ·ç‰¹å®šä¿¡æ¯æ¥ä¸ªæ€§åŒ–LLMã€‚åŸºäºè®°å¿†æ ¼å¼åˆ†ä¸ºï¼š</p>
<ul class="simple">
<li><p><strong>ç»“æ„åŒ–è®°å¿†</strong>ï¼šå¦‚ç”¨æˆ·æ¡£æ¡ˆæˆ–çŸ¥è¯†å›¾è°±ï¼ˆç”¨äºæ„å»ºä¸ªæ€§åŒ–æç¤ºLaMPï¼Œæˆ–ç”¨äºä¸ªæ€§åŒ–é—®ç­”PerKGQAï¼‰ã€‚</p></li>
<li><p><strong>éç»“æ„åŒ–è®°å¿†</strong>ï¼šå¦‚å¯¹è¯å†å²å’Œå™è¿°æ€§äººç‰©ï¼ˆæ£€ç´¢ä»¥ä¸°å¯Œç¨€ç–æ¡£æ¡ˆLAPDOGï¼Œå¹¶é€šè¿‡åŒé‡å­¦ä¹ ä¸è¾“å…¥ä¸Šä¸‹æ–‡å¯¹é½Fu et al., 2022ï¼‰ã€‚</p></li>
<li><p><strong>æ··åˆæ–¹æ³•</strong>ï¼šå¦‚SiliconFriendå’ŒLD-Agentï¼Œè·¨ä¼šè¯ç»´æŠ¤æŒä¹…è®°å¿†ã€‚</p></li>
<li><p><strong>å±€é™æ€§</strong>ï¼šè¿™äº›æ–¹æ³•é€šå¸¸å°†é•¿æœŸè®°å¿†è§†ä¸ºè¢«åŠ¨ç¼“å†²åŒºï¼Œå…¶ç”¨äºä¸»åŠ¨è§„åˆ’å’Œå†³ç­–çš„æ½œåŠ›å°šæœªè¢«å……åˆ†æ¢ç´¢ã€‚</p></li>
</ul>
</li>
</ol>
</section>
<hr class="docutils" />
<section id="discussion">
<h4><strong>3.1.4 è®¨è®º (Discussion)</strong><a class="headerlink" href="#discussion" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p><strong>è¯„ä¼°å±€é™</strong>ï¼šå½“å‰é•¿æœŸè®°å¿†çš„è¯„ä¼°å—é™äºé™æ€å‡è®¾ã€‚</p>
<ul>
<li><p><strong>åŸºäºçŸ¥è¯†çš„QA</strong>ä»»åŠ¡è¯„ä¼°æ¨¡å‹å¯¹äº‹å®çŸ¥è¯†çš„æ£€ç´¢å’Œæ¨ç†èƒ½åŠ›ï¼Œä½†é€šå¸¸å‡è®¾é™æ€è®°å¿†å†…å®¹ï¼Œå¿½ç•¥äº†æ›´æ–°ã€é€‰æ‹©æ€§ä¿ç•™å’Œæ—¶é—´è¿ç»­æ€§ç­‰åŠ¨æ€æ“ä½œã€‚</p></li>
<li><p><strong>å¤šè½®å¯¹è¯åŸºå‡†</strong>ï¼ˆå¦‚LoCoMo, LongMemEvalï¼‰æ›´å¥½åœ°åæ˜ äº†çœŸå®ä¸–ç•Œçš„è®°å¿†ä½¿ç”¨ï¼ˆè·¨ä¼šè¯æ£€ç´¢ã€è®°å¿†æ›´æ–°ã€äº‹ä»¶æ¨ç†ï¼‰ï¼Œä½†å¤§å¤šæ•°è¯„ä¼°ä»å°†å¯¹è¯å†å²è§†ä¸ºé™æ€ä¸Šä¸‹æ–‡ï¼Œ narrowly focusing on QA accuracy while overlooking dynamic memory operations such as indexing, consolidation, forgetting, or user-specific adaptation.</p></li>
</ul>
</li>
<li><p><strong>æ£€ç´¢ä¸ç”Ÿæˆçš„é”™é…</strong>ï¼šæ­ç¤ºäº†åˆ©ç”¨ç“¶é¢ˆã€‚</p>
<ul>
<li><p>æœ€æ–°æ¨¡å‹åœ¨æ£€ç´¢æŒ‡æ ‡ï¼ˆå¦‚Recall&#64;5ï¼‰ä¸Šè¡¨ç°ä¼˜å¼‚ï¼ˆ&gt;90%ï¼‰ï¼Œä½†ç”ŸæˆæŒ‡æ ‡ï¼ˆå¦‚F1ï¼‰å´è½åè¶…è¿‡30ä¸ªç™¾åˆ†ç‚¹ã€‚</p></li>
<li><p><strong>åŸå› </strong>ï¼šç´§å‡‘çš„è®°å¿†æ ¼å¼æ¯”å†—é•¿çš„æ¡ç›®æ›´åˆ©äºç”Ÿæˆï¼›è®°å¿†ä¸æŸ¥è¯¢ä¹‹é—´çš„æ—¶é—´è·ç¦»å¢åŠ ä¼šå¯¼è‡´ç”Ÿæˆè´¨é‡ä¸‹é™å³ä½¿æ£€ç´¢å‡†ç¡®ï¼›æ£€ç´¢æ›´å¤šé¡¹ç›®ä¼šå¼•å…¥å™ªå£°æŸå®³è§£ç ï¼›å¤šè¯­è¨€è¯„ä¼°ä¸­å­˜åœ¨è¯­è¨€å·®è·ï¼ˆè‹±è¯­ä¼˜äºä¸­æ–‡ï¼‰ã€‚</p></li>
<li><p><strong>ç»“è®º</strong>ï¼šå½“å‰ç³»ç»Ÿå¯ä»¥æ£€ç´¢ç›¸å…³è®°å¿†å†…å®¹ï¼Œä½†åœ¨æœ‰æ•ˆç»„ç»‡å’Œåˆ©ç”¨å®ƒè¿›è¡Œä¸‹æ¸¸ç”Ÿæˆä»»åŠ¡æ–¹é¢ä»ç„¶ä¸è¶³ã€‚</p></li>
</ul>
</li>
<li><p><strong>è®°å¿†æ“ä½œè¯„ä¼°ä¸è¶³</strong>ï¼šå½“å‰è¯„ä¼°ä¸»è¦å…³æ³¨æ£€ç´¢å‡†ç¡®æ€§å’Œç”Ÿæˆè´¨é‡ï¼Œä½†å¾ˆå¤§ç¨‹åº¦ä¸Šå¿½ç•¥äº†è®°å¿†ä½¿ç”¨çš„è¿‡ç¨‹æ–¹é¢ï¼ˆå¦‚å·©å›ºã€æ›´æ–°ã€é—å¿˜ã€é€‰æ‹©æ€§ä¿ç•™ï¼‰ã€‚éœ€è¦èƒ½å¤Ÿè¯„ä¼°è®°å¿†å¯é æ€§ã€æ—¶é—´é€‚åº”æ€§å’Œå¤šä¼šè¯å¯¹è¯ä¸€è‡´æ€§çš„ç»¼åˆåŸºå‡†ã€‚</p></li>
<li><p><strong>å‡ºç‰ˆè¶‹åŠ¿</strong>ï¼š</p>
<ul>
<li><p>æ£€ç´¢å’Œç”Ÿæˆåœ¨æ–‡çŒ®ä¸­å ä¸»å¯¼åœ°ä½ï¼ˆå°¤å…¶åœ¨NLPé¢†åŸŸï¼‰ã€‚</p></li>
<li><p>æ ¸å¿ƒæ“ä½œå¦‚å·©å›ºå’Œç´¢å¼•åœ¨MLä¸­å—åˆ°æ›´å¤šå…³æ³¨ï¼Œè€Œé—å¿˜ä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚</p></li>
<li><p>ä¸ªæ€§åŒ–ä¸»è¦é™äºNLPï¼ˆç”±äºå®é™…åº”ç”¨éœ€æ±‚ï¼‰ã€‚</p></li>
<li><p>å°±å¼•ç”¨å½±å“è€Œè¨€ï¼Œå·©å›ºã€æ£€ç´¢å’Œæ•´åˆèµ·ç€å…³é”®ä½œç”¨ï¼ˆç”±è®°å¿†æ„ŸçŸ¥å¾®è°ƒã€æ‘˜è¦ã€æ£€ç´¢å¢å¼ºç”Ÿæˆå’Œæç¤ºèåˆçš„è¿›æ­¥é©±åŠ¨ï¼‰ã€‚</p></li>
</ul>
</li>
<li><p><strong>æœªæ¥æ–¹å‘</strong>ï¼š</p>
<ol class="arabic simple">
<li><p>è®¾è®¡åŠ¨æ€ç»Ÿä¸€çš„åŸºå‡†ï¼Œè¯„ä¼°ä¸åŒè®°å¿†ç±»å‹ä¸Šçš„è®°å¿†æ“ä½œï¼Œå¹¶æ•æ‰è¶…è¶Šå¯¹è¯çš„é•¿æœŸæ—¶é—´åŠ¨æ€ã€‚</p></li>
<li><p>é€šè¿‡å¢å¼ºè®°å¿†æ ¼å¼åŒ–ã€æ§åˆ¶æ£€ç´¢ç²’åº¦å’Œå»ºæ¨¡æ—¶é—´å¯é æ€§æ¥è§£å†³æ£€ç´¢-ç”Ÿæˆè„±èŠ‚é—®é¢˜ã€‚</p></li>
<li><p>é€šè¿‡è·¨ä¼šè¯è®°å¿†é‡ç”¨å’Œè‡ªé€‚åº”ç”¨æˆ·å»ºæ¨¡ï¼Œæ¨è¿›ä¸ªæ€§åŒ–çš„ã€ä»¥è®°å¿†ä¸ºä¸­å¿ƒçš„æ™ºèƒ½ä½“ã€‚</p></li>
</ol>
</li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="long-context">
<h3><strong>3.2 é•¿ä¸Šä¸‹æ–‡ (Long-context)</strong><a class="headerlink" href="#long-context" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/08/JUm0mn.jpg" /></p>
<p>Table 5: Datasets for long-context memory evaluation.</p>
<p><strong>æ ¸å¿ƒå†…å®¹</strong>ï¼š æœ¬èŠ‚å¼€ç¯‡æŒ‡å‡ºï¼Œåœ¨ conversational searchï¼ˆä¼šè¯å¼æœç´¢ï¼‰ä¸­ï¼Œç®¡ç†æµ·é‡ã€å¤šæºçš„å¤–éƒ¨å†…å­˜ç»™â€œé•¿ä¸Šä¸‹æ–‡è¯­è¨€ç†è§£â€å¸¦æ¥äº†å·¨å¤§æŒ‘æˆ˜ã€‚å°½ç®¡æ¨¡å‹è®¾è®¡å’Œé•¿ä¸Šä¸‹æ–‡è®­ç»ƒçš„è¿›æ­¥å·²è®©å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰èƒ½å¤„ç†æ•°ç™¾ä¸‡ä¸ªè¾“å…¥tokenï¼Œä½†å¦‚ä½•åœ¨è¿™ç§è¶…é•¿ä¸Šä¸‹æ–‡ä¸­æœ‰æ•ˆç®¡ç†å†…å­˜ä»ç„¶æ˜¯ä¸€ä¸ªå¤æ‚çš„é—®é¢˜ã€‚</p>
<p>è¿™äº›æŒ‘æˆ˜ä¸»è¦åˆ†ä¸ºä¸¤æ–¹é¢ï¼š</p>
<ol class="arabic simple">
<li><p><strong>å‚æ•°æ•ˆç‡ (Parametric Efficiency)</strong>ï¼š ä¸“æ³¨äºä¼˜åŒ–<strong>KVç¼“å­˜</strong>ï¼ˆä¸€ç§å‚æ•°åŒ–å†…å­˜ï¼‰ï¼Œä»¥å®ç°é«˜æ•ˆçš„é•¿ä¸Šä¸‹æ–‡è§£ç ã€‚</p></li>
<li><p><strong>ä¸Šä¸‹æ–‡åˆ©ç”¨ (Contextual Utilization)</strong>ï¼š ä¸“æ³¨äºä¼˜åŒ–LLMsæœ¬èº«ï¼Œä»¥ç®¡ç†å„ç§<strong>å¤–éƒ¨å†…å­˜</strong>ï¼ˆä¸Šä¸‹æ–‡å†…å­˜ï¼‰ã€‚</p></li>
</ol>
<p>æœ¬èŠ‚å°†ç³»ç»Ÿå›é¡¾åº”å¯¹è¿™äº›æŒ‘æˆ˜çš„ç ”ç©¶å·¥ä½œã€‚ç›¸å…³æ•°æ®é›†å’Œé‡ç‚¹å·¥ä½œçš„æ€»ç»“è¯¦è§è®ºæ–‡ä¸­çš„è¡¨æ ¼ã€‚</p>
<p><strong>Figure 5</strong>ï¼š è¯¥å›¾å±•ç¤ºäº†æœ¬èŠ‚æ‰€è®¨è®ºçš„é‡ç‚¹è®ºæ–‡ï¼ˆRCI &gt; 1ï¼‰çš„å‘è¡¨ç»Ÿè®¡æƒ…å†µï¼Œåæ˜ äº†è¯¥é¢†åŸŸçš„ç ”ç©¶çƒ­åº¦å’Œå‘å±•è¶‹åŠ¿ã€‚</p>
<hr class="docutils" />
<section id="parametric-efficiency">
<h4><strong>3.2.1 å‚æ•°æ•ˆç‡ (Parametric Efficiency)</strong><a class="headerlink" href="#parametric-efficiency" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/08/IpsSDz.jpg" /></p>
<p>Table 10:Overview of methods for long-context memory in Parametric Efficiency. â€œTFâ€ (Training Free) denotes whether the method operates without additional gradient-based updates. â€œDFâ€ (Dropping Free) denotes whether the method able to maintain all the KV cache without dropping. [LINK]* indicates unofficial implementations.</p>
<p><strong>æ ¸å¿ƒå†…å®¹</strong>ï¼š ä¸ºäº†ç®¡ç†æµ·é‡å¤šæºå¤–éƒ¨å†…å­˜ï¼ŒLLMså¿…é¡»è¢«ä¼˜åŒ–ä»¥é«˜æ•ˆå¤„ç†é•¿ä¸Šä¸‹æ–‡ã€‚æœ¬å°èŠ‚è®¨è®ºä»å†…å­˜è§†è§’ä¼˜åŒ–é•¿ä¸Šä¸‹æ–‡å¤„ç†çš„æ–¹æ³•ï¼Œé‡ç‚¹æ˜¯<strong>é”®å€¼ç¼“å­˜ï¼ˆKV Cacheï¼‰ä¼˜åŒ–</strong>ã€‚</p>
<ul class="simple">
<li><p><strong>é—®é¢˜</strong>ï¼šKVç¼“å­˜é€šè¿‡å­˜å‚¨è¿‡å»çš„é”®å€¼å¯¹ä½œä¸ºå¤–éƒ¨å‚æ•°åŒ–å†…å­˜ï¼Œæ¥é¿å…é‡å¤è®¡ç®—ã€‚ä½†éšç€ä¸Šä¸‹æ–‡å˜é•¿ï¼Œå­˜å‚¨è¿™äº›å†…å­˜çš„éœ€æ±‚å‘ˆ<strong>äºŒæ¬¡æ–¹å¢é•¿</strong>ï¼Œéš¾ä»¥å¤„ç†æé•¿ä¸Šä¸‹æ–‡ã€‚</p></li>
</ul>
<section id="kv-kv-cache-dropping">
<h5><strong>KVç¼“å­˜ä¸¢å¼ƒ (KV Cache Dropping)</strong><a class="headerlink" href="#kv-kv-cache-dropping" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ul class="simple">
<li><p><strong>ç›®æ ‡</strong>ï¼šé€šè¿‡æ¶ˆé™¤ä¸å¿…è¦çš„KVç¼“å­˜æ¥å‡å°ç¼“å­˜å¤§å°ã€‚</p>
<ul>
<li><p><strong>é™æ€ä¸¢å¼ƒ</strong>ï¼š æŒ‰å›ºå®šæ¨¡å¼é€‰æ‹©è¦ä¸¢å¼ƒçš„ç¼“å­˜ã€‚</p>
<ul>
<li><p><em>ä¾‹å­</em>ï¼š StreamingLLM å’Œ LM-Infinite ä½¿ç”¨ä¸€ç§Î›å½¢ç¨€ç–æ¨¡å¼ï¼›LCKV åªä¿ç•™æœ€é¡¶å±‚çš„KVç¼“å­˜ã€‚</p></li>
</ul>
</li>
<li><p><strong>åŠ¨æ€ä¸¢å¼ƒ</strong>ï¼š æ›´çµæ´»ï¼Œæ ¹æ®<strong>æŸ¥è¯¢</strong>ï¼ˆå¦‚H2O, FastGenï¼‰æˆ–æ¨¡å‹åœ¨æ¨ç†æ—¶çš„<strong>è¡Œä¸º</strong>ï¼ˆå¦‚æ³¨æ„åŠ›æƒé‡ï¼ŒSnapKV, HeadKVï¼‰æ¥å†³å®šä¸¢å¼ƒå“ªäº›ç¼“å­˜ã€‚</p></li>
</ul>
</li>
<li><p><strong>åˆå¹¶æ³•</strong>ï¼š ç”±äºç›´æ¥ä¸¢å¼ƒå¯èƒ½å¯¼è‡´ä¿¡æ¯ä¸¢å¤±ï¼Œä¸€äº›æ–¹æ³•é€‰æ‹©<strong>åˆå¹¶</strong>ç›¸ä¼¼çš„KVç¼“å­˜ï¼ˆå¦‚MiniCache, InfiniPotï¼‰æˆ–ä½¿ç”¨ç‰¹æ®Štokenå­˜å‚¨ï¼ˆå¦‚Activation Beaconï¼‰ï¼Œè€Œä¸æ˜¯ç›´æ¥ä¸¢å¼ƒã€‚</p></li>
</ul>
</section>
<section id="kv-kv-cache-storing-optimization">
<h5><strong>KVç¼“å­˜å­˜å‚¨ä¼˜åŒ– (KV Cache Storing Optimization)</strong><a class="headerlink" href="#kv-kv-cache-storing-optimization" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ul class="simple">
<li><p><strong>ç›®æ ‡</strong>ï¼š è®¤è¯†åˆ°ä¸¢å¼ƒå¯èƒ½é€ æˆä¿¡æ¯æŸå¤±ï¼Œè½¬è€Œå…³æ³¨å¦‚ä½•ç”¨æ›´å°çš„ç©ºé—´å ç”¨ä¿å­˜å…¨éƒ¨KVç¼“å­˜ã€‚</p>
<ul>
<li><p><strong>æ–¹æ³•</strong>ï¼š å°†ä¸é‡è¦çš„ç¼“å­˜æ¡ç›®<strong>å‹ç¼©</strong>æˆä½ç»´è¡¨ç¤ºï¼ˆå¦‚LESS, Eigenï¼‰ï¼Œæˆ–å¯¹KVç¼“å­˜è¿›è¡Œ<strong>åŠ¨æ€é‡åŒ–</strong>ä»¥å‡å°‘å†…å­˜åˆ†é…ï¼ˆå¦‚FlexGen, Atom, KVQuantï¼‰ã€‚</p></li>
</ul>
</li>
<li><p><strong>ä¼˜ç¼ºç‚¹</strong>ï¼š ç›¸æ¯”ä¸¢å¼ƒæ³•ï¼Œæ€§èƒ½ä¸‹é™æ›´å°ï¼Œä½†ç”±äºå†…å­˜å¢é•¿çš„äºŒæ¬¡æ–¹ç‰¹æ€§ï¼Œä¼˜åŒ–ç©ºé—´ä»æœ‰é™ã€‚æœªæ¥éœ€æƒè¡¡<strong>å†…å­˜æˆæœ¬</strong>å’Œ<strong>æ€§èƒ½ä¸‹é™</strong>ã€‚</p></li>
</ul>
</section>
<section id="kv-kv-cache-selection">
<h5><strong>KVç¼“å­˜é€‰æ‹© (KV Cache Selection)</strong><a class="headerlink" href="#kv-kv-cache-selection" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ul class="simple">
<li><p><strong>ç›®æ ‡</strong>ï¼š <strong>é€‰æ‹©æ€§åŠ è½½</strong>æ‰€éœ€çš„KVç¼“å­˜æ¥åŠ é€Ÿæ¨ç†ï¼Œä¸“æ³¨äºKVç¼“å­˜çš„<strong>å†…å­˜æ£€ç´¢</strong>ã€‚</p>
<ul>
<li><p><strong>æ–¹æ³•</strong>ï¼š é‡‡ç”¨æŸ¥è¯¢æ„ŸçŸ¥çš„ç¼“å­˜é€‰æ‹©ï¼ˆå¦‚QUEST, TokenSelectï¼‰æˆ–è¿‘ä¼¼æœ€è¿‘é‚»ï¼ˆANNï¼‰æœç´¢ï¼ˆå¦‚RetrievalAttentionï¼‰æ¥æ£€ç´¢å…³é”®çš„KVç¼“å­˜ã€‚</p></li>
<li><p><strong>å¤–éƒ¨å­˜å‚¨</strong>ï¼š å°†KVç¼“å­˜å­˜å…¥å¤–éƒ¨å†…å­˜ï¼Œæ¨ç†æ—¶å†æ£€ç´¢ç›¸å…³éƒ¨åˆ†ï¼ˆå¦‚Memorizing Transformers, LongLLaMA, ReKVï¼‰ã€‚</p></li>
</ul>
</li>
<li><p><strong>ä¼˜åŠ¿</strong>ï¼š çµæ´»æ€§é«˜ï¼Œé¿å…äº†é©±é€ç¼“å­˜ï¼Œå¹¶èƒ½ä¸å­˜å‚¨ä¼˜åŒ–æŠ€æœ¯ç»“åˆã€‚</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="contextual-utilization">
<h4><strong>3.2.2 ä¸Šä¸‹æ–‡åˆ©ç”¨ (Contextual Utilization)</strong><a class="headerlink" href="#contextual-utilization" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/08/RESVhl.jpg" /></p>
<p>Table 11:Overview of methods for long-context memory in Contextual Utilization. â€œSMâ€ (Source Modal) denotes the source modality of contextual memory. â€œTMâ€ (Target Modal) denotes target modality (processed for selection / after compression) of contextual memory (T â€“ Text, G â€“ Graphs, P â€“ Parametric).</p>
<p><strong>æ ¸å¿ƒå†…å®¹</strong>ï¼š é™¤äº†ä¼˜åŒ–æ¨¡å‹æœ¬èº«è·å¾—é•¿ä¸Šä¸‹æ–‡èƒ½åŠ›ï¼Œä¼˜åŒ–<strong>ä¸Šä¸‹æ–‡å†…å­˜çš„åˆ©ç”¨</strong>æ˜¯å¦ä¸€å¤§æŒ‘æˆ˜ã€‚</p>
<section id="context-retrieval">
<h5><strong>ä¸Šä¸‹æ–‡æ£€ç´¢ (Context Retrieval)</strong><a class="headerlink" href="#context-retrieval" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ul class="simple">
<li><p><strong>ç›®æ ‡</strong>ï¼š å¢å¼ºLLMä»ä¸Šä¸‹æ–‡å†…å­˜ä¸­è¯†åˆ«å’Œå®šä½å…³é”®ä¿¡æ¯çš„èƒ½åŠ›ã€‚</p>
<ul>
<li><p><strong>å›¾æ–¹æ³•</strong>ï¼š å°†æ–‡æ¡£åˆ†è§£æˆå›¾ç»“æ„ä»¥æœ‰æ•ˆé€‰æ‹©ä¸Šä¸‹æ–‡ï¼ˆå¦‚CGSN, GraphReaderï¼‰ã€‚</p></li>
<li><p><strong>Tokençº§é€‰æ‹©</strong>ï¼š ä¿®å‰ªå’Œé€‰æ‹©æœ€é‡è¦çš„tokenï¼ˆå¦‚TRAMS, Selection-pï¼‰ã€‚</p></li>
<li><p><strong>ç‰‡æ®µçº§é€‰æ‹©</strong>ï¼š æ ¹æ®ä»»åŠ¡é‡è¦æ€§é€‰æ‹©ç›¸å…³ä¸Šä¸‹æ–‡ç‰‡æ®µï¼ˆå¦‚NBCE, FragRel, Sparse RAGï¼‰ã€‚</p></li>
<li><p><strong>è®­ç»ƒæ³•</strong>ï¼š ç”¨ä¸“é—¨æ•°æ®è®­ç»ƒLLMï¼Œæé«˜å…¶ä¸Šä¸‹æ–‡é€‰æ‹©èƒ½åŠ›ï¼ˆå¦‚Ziya-Reader, FILMï¼‰ã€‚</p></li>
<li><p><strong>å¤–éƒ¨å‘é‡ç¼“å­˜</strong>ï¼š å°†å¤–éƒ¨å†…å­˜ç¼–ç åˆ°å‘é‡ç©ºé—´å¹¶å­˜å‚¨ï¼Œæœ‰æ•ˆæ›´æ–°å’Œæ£€ç´¢ä»¥å®ç°é•¿æœŸè®°å¿†åˆ©ç”¨ï¼ˆå¦‚MemGPT, Neurocache, AWESOMEï¼‰ã€‚</p></li>
</ul>
</li>
</ul>
</section>
<section id="context-compression">
<h5><strong>ä¸Šä¸‹æ–‡å‹ç¼© (Context Compression)</strong><a class="headerlink" href="#context-compression" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ul class="simple">
<li><p><strong>ç›®æ ‡</strong>ï¼š åˆ©ç”¨å†…å­˜å‹ç¼©æ“ä½œä¼˜åŒ–ä¸Šä¸‹æ–‡å†…å­˜åˆ©ç”¨ï¼Œä¸»è¦åˆ†ä¸¤ç±»ï¼š</p>
<ul>
<li><p><strong>è½¯æç¤ºå‹ç¼©</strong>ï¼š å°†è¾“å…¥tokenå—å‹ç¼©æˆæ¨ç†é˜¶æ®µçš„è¿ç»­å‘é‡ï¼ˆå¦‚AutoCompressors, xRAGï¼‰ï¼Œæˆ–åœ¨è®­ç»ƒé˜¶æ®µå°†ä»»åŠ¡ç‰¹å®šçš„é•¿ä¸Šä¸‹æ–‡ç¼–ç åˆ°å¾®è°ƒæ¨¡å‹çš„å‚æ•°å†…å­˜ä¸­ï¼ˆå¦‚YOROï¼‰ã€‚</p></li>
<li><p><strong>ç¡¬æç¤ºå‹ç¼©</strong>ï¼š ç›´æ¥å°†é•¿è¾“å…¥å—å‹ç¼©æˆæ›´çŸ­çš„<strong>è‡ªç„¶è¯­è¨€</strong>å—ã€‚</p>
<ul>
<li><p><strong>ä¸¢å¼ƒæ³•</strong>ï¼š é€‰æ‹©æ€§ä¿®å‰ªä¿¡æ¯é‡å°‘çš„tokenï¼ˆå¦‚Selective Contextï¼‰æˆ–å—ï¼ˆå¦‚Semantic Compressionï¼‰ã€‚</p></li>
<li><p><strong>æ‘˜è¦æ³•</strong>ï¼š é€šè¿‡æŠ½è±¡å…³é”®ä¿¡æ¯æ¥å‹ç¼©é•¿è¾“å…¥ï¼ˆå¦‚RECOMP, LLMLinguaç³»åˆ—ï¼‰ã€‚</p></li>
<li><p><strong>æ··åˆæ³•</strong>ï¼š ç»“åˆä¸¢å¼ƒå’Œæ‘˜è¦ï¼ˆå¦‚TCRA-LLMï¼‰ã€‚</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="id13">
<h4><strong>3.2.3 è®¨è®º (Discussion)</strong><a class="headerlink" href="#id13" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<section id="lost-in-the-context">
<h5><strong>è¿·å¤±åœ¨ä¸Šä¸‹æ–‡ä¸­ (Lost in the Context)</strong><a class="headerlink" href="#lost-in-the-context" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ul class="simple">
<li><p>å°½ç®¡æ¨¡å‹å£°ç§°èƒ½å¤„ç†ç™¾ä¸‡çº§tokenï¼Œä½†åœ¨æ‰§è¡Œä»»åŠ¡ï¼ˆå¦‚é—®ç­”ï¼‰æ—¶ï¼ŒLLMsä»ä¼š<strong>ä¸¢å¤±ä¸Šä¸‹æ–‡ä¸­é—´ä½ç½®çš„å…³é”®ä¿¡æ¯</strong>ï¼ˆâ€œä¸­é—´è¿·å¤±â€é—®é¢˜ï¼‰ã€‚</p></li>
<li><p>åœ¨éœ€è¦åŸºäºä¸Šä¸‹æ–‡è¿›è¡Œæ¨ç†çš„å¤æ‚åœºæ™¯ä¸­ï¼ŒLLMsä¹Ÿéš¾ä»¥æœ‰æ•ˆèšåˆä¸åŒéƒ¨åˆ†çš„å†…å­˜ã€‚</p></li>
<li><p>æ­¤å¤–ï¼Œæ£€ç´¢åˆ°çš„æ— å…³ä¿¡æ¯ä¼šè¯¯å¯¼æ¨¡å‹ï¼ŒæŸå®³ç”Ÿæˆè´¨é‡ã€‚å› æ­¤ï¼Œæœ‰æ•ˆçš„ä¸Šä¸‹æ–‡åˆ©ç”¨ï¼ˆæ£€ç´¢ä¸å‹ç¼©ï¼‰æ˜¯è§£å†³è¿™äº›é™åˆ¶çš„å…³é”®ã€‚</p></li>
</ul>
</section>
<section id="trade-off-between-compression-rate-and-performance-drop">
<h5><strong>å‹ç¼©ç‡ä¸æ€§èƒ½ä¸‹é™çš„æƒè¡¡ (Trade-off between compression rate and performance drop)</strong><a class="headerlink" href="#trade-off-between-compression-rate-and-performance-drop" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ul class="simple">
<li><p>å‹ç¼©æ˜¯é•¿ä¸Šä¸‹æ–‡å†…å­˜ä¸­çš„ä¸»è¦æ“ä½œï¼Œç”¨äºå¹³è¡¡<strong>æ•ˆç‡</strong>ï¼ˆå‹ç¼©ç‡ï¼‰å’Œ<strong>æœ‰æ•ˆæ€§</strong>ï¼ˆæ€§èƒ½ä¸‹é™ï¼‰ã€‚</p></li>
<li><p><strong>ä¸åŒç­–ç•¥çš„ä¼˜åŠ£</strong>ï¼š</p>
<ul>
<li><p><strong>KVç¼“å­˜ä¸¢å¼ƒæ³•</strong>ï¼šå‹ç¼©ç‡é«˜ï¼Œä½†ä¿¡æ¯æŸå¤±å¤§ï¼Œæ€§èƒ½ä¸‹é™æ˜æ˜¾ã€‚</p></li>
<li><p><strong>KVç¼“å­˜å­˜å‚¨ä¼˜åŒ–æ³•</strong>ï¼šåœ¨æœ‰æ•ˆæ€§å’Œæ•ˆç‡é—´å–å¾—äº†æœ€ä½³æƒè¡¡ï¼ˆè§å›¾6ï¼‰ã€‚</p></li>
<li><p><strong>ä¸Šä¸‹æ–‡å†…å­˜å‹ç¼©æ³•</strong>ï¼šæ•ˆæœé€šå¸¸ä¸å¦‚å‚æ•°å†…å­˜å‹ç¼©ï¼ˆå¦‚LLMLingua2æ€§èƒ½ç›¸å¯¹è¾ƒå·®ï¼‰ã€‚</p></li>
</ul>
</li>
<li><p><strong>Figure 6</strong>ï¼š ç›´è§‚å±•ç¤ºäº†ä¸åŒå‹ç¼©æ–¹æ³•åœ¨å‹ç¼©ç‡å’Œæ€§èƒ½ï¼ˆåœ¨LongBenchåŸºå‡†ä¸Šçš„è¡¨ç°ï¼‰ä¹‹é—´çš„æƒè¡¡å…³ç³»ã€‚</p></li>
</ul>
</section>
<section id="publication-trending">
<h5><strong>å‘è¡¨è¶‹åŠ¿ (Publication Trending)</strong><a class="headerlink" href="#publication-trending" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ul class="simple">
<li><p><strong>NLPç¤¾åŒº</strong>æ›´å…³æ³¨<strong>ä¸Šä¸‹æ–‡å†…å­˜çš„åˆ©ç”¨</strong>ã€‚</p></li>
<li><p><strong>MLç¤¾åŒº</strong>æ›´ä¸“æ³¨äºé€šè¿‡<strong>å‚æ•°åŒ–å†…å­˜æé«˜æ•ˆç‡</strong>ã€‚</p></li>
<li><p><strong>KVç¼“å­˜å­˜å‚¨ä¼˜åŒ–</strong>æ˜¯å½“å‰è®¨è®ºçš„ç„¦ç‚¹ï¼Œå› ä¸ºå®ƒèƒ½å¹³è¡¡æ•ˆç‡ä¸æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸å…¶ä»–é•¿ä¸Šä¸‹æ–‡æ–¹æ³•å…¼å®¹ã€‚</p></li>
<li><p><strong>ä¸Šä¸‹æ–‡æ£€ç´¢</strong>å—åˆ°çš„å…³æ³¨ç›¸å¯¹è¾ƒå°‘ï¼Œéƒ¨åˆ†åŸå› æ˜¯å…¶ä¸â€œé•¿æœŸè®°å¿†â€ã€â€œå¤šæºè®°å¿†â€ç­‰ä¸»é¢˜æœ‰é‡å ã€‚</p></li>
<li><p><strong>æœªæ¥æ–¹å‘</strong>ï¼š åœ¨å¤æ‚ç¯å¢ƒï¼ˆå¦‚å¤šæºå†…å­˜ï¼‰ä¸­çš„ä¸Šä¸‹æ–‡åˆ©ç”¨ä»æ˜¯å…³é”®ä¸”ç¼ºä¹æœ‰å½±å“åŠ›å·¥ä½œçš„ç ”ç©¶æ–¹å‘ï¼Œå¯¹æ™ºèƒ½ä½“å‘å±•è‡³å…³é‡è¦ã€‚</p></li>
</ul>
<hr class="docutils" />
<p><strong>æ€»ç»“ä¸æœªæ¥æ–¹å‘</strong>ï¼š</p>
<ol class="arabic simple">
<li><p>åœ¨KVç¼“å­˜ä¼˜åŒ–ä¸­å¹³è¡¡<strong>å†…å­˜ä½¿ç”¨</strong>å’Œ<strong>æ€§èƒ½ä¸‹é™</strong>æ˜¯ä¸€ä¸ªé‡è¦çš„æœªæ¥ç ”ç©¶æ–¹å‘ã€‚</p></li>
<li><p>å¤æ‚ç¯å¢ƒä¸‹çš„<strong>ä¸Šä¸‹æ–‡åˆ©ç”¨</strong>æ˜¯æ¨åŠ¨æ™ºèƒ½ä½“å‘å±•çš„å…³é”®ç ”ç©¶æ–¹å‘ã€‚</p></li>
</ol>
</section>
</section>
</section>
<section id="parametric-memory-modification">
<h3><strong>3.3 Parametric Memory Modificationï¼ˆå‚æ•°åŒ–è®°å¿†ä¿®æ”¹ï¼‰</strong><a class="headerlink" href="#parametric-memory-modification" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/08/nfuEQy.jpg" /></p>
<p>Table 6: Datasets for parametric memory evaluation.</p>
<p><strong>æ ¸å¿ƒæ¦‚å¿µ</strong>ï¼š å‚æ•°åŒ–è®°å¿†æ˜¯æŒ‡ç¼–ç åœ¨LLMæ¨¡å‹å‚æ•°å†…éƒ¨çš„çŸ¥è¯†ã€‚ä¿®æ”¹è¿™äº›è®°å¿†å¯¹äºè®©æ¨¡å‹åŠ¨æ€é€‚åº”æ–°çŸ¥è¯†ã€çº æ­£é”™è¯¯æˆ–å¿˜è®°æ•æ„Ÿä¿¡æ¯è‡³å…³é‡è¦ã€‚</p>
<p><strong>ä¸»è¦æ–¹æ³•åˆ†ç±»</strong>ï¼š</p>
<ol class="arabic simple">
<li><p><strong>Editingï¼ˆç¼–è¾‘ï¼‰</strong>ï¼š å¯¹æ¨¡å‹å‚æ•°è¿›è¡Œ<strong>å±€éƒ¨ä¿®æ”¹</strong>ï¼Œæ— éœ€å®Œå…¨é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚</p></li>
<li><p><strong>Unlearningï¼ˆé—å¿˜/åå­¦ä¹ ï¼‰</strong>ï¼š <strong>é€‰æ‹©æ€§ç§»é™¤</strong>æ¨¡å‹ä¸­ä¸éœ€è¦çš„æˆ–æ•æ„Ÿçš„ä¿¡æ¯ã€‚</p></li>
<li><p><strong>Continual Learningï¼ˆæŒç»­å­¦ä¹ ï¼‰</strong>ï¼š <strong>é€æ­¥å¸æ”¶æ–°çŸ¥è¯†</strong>ï¼ŒåŒæ—¶é˜²æ­¢å¯¹æ—§çŸ¥è¯†çš„â€œç¾éš¾æ€§é—å¿˜â€ã€‚</p></li>
</ol>
<p>æœ¬èŠ‚å°†ç³»ç»Ÿå›é¡¾è¿™ä¸‰ç±»æ–¹æ³•ï¼Œå¹¶åœ¨åç»­å°èŠ‚ä¸­è¿›è¡Œè¯¦ç»†åˆ†æå’Œæ¯”è¾ƒã€‚ç›¸å…³æ•°æ®é›†å’Œæ–¹æ³•æ€»ç»“è§è®ºæ–‡ä¸­çš„è¡¨æ ¼ã€‚</p>
<hr class="docutils" />
<section id="editing">
<h4><strong>3.3.1 Editingï¼ˆç¼–è¾‘ï¼‰</strong><a class="headerlink" href="#editing" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/08/EcHKS4.jpg" /></p>
<p>Table 12:Overview of methods for parametric memory optimization in editing. â€œPRâ€ (Parametric Reserving) indicates whether the method avoids direct modification of the modelâ€™s internal weights. â€œTFâ€ (Training-Free) denotes whether the method operates without traditional iterative optimization. â€œBESâ€ (Batch Editing Support) reflects the methodâ€™s ability to handle multiple edits simultaneously. â€œSEOâ€ (Sequential Editing Optimization) specifies whether the method introduces mechanisms tailored for sequential Editing. â€œLMsâ€ lists the language models used for empirical evaluation.</p>
<p><strong>ç›®æ ‡</strong>ï¼š ä¸è¿›è¡Œå…¨æ¨¡å‹é‡è®­ç»ƒï¼Œæ›´æ–°å‚æ•°åŒ–è®°å¿†ä¸­çš„ç‰¹å®šçŸ¥è¯†ã€‚</p>
<p><strong>ä¸»è¦æŠ€æœ¯è·¯çº¿</strong>ï¼š</p>
<ol class="arabic simple">
<li><p><strong>ç›´æ¥ä¿®æ”¹æƒé‡ï¼ˆLocating-then-editingï¼‰</strong>ï¼š</p>
<ul class="simple">
<li><p><strong>ç­–ç•¥</strong>ï¼š å…ˆé€šè¿‡å½’å› æˆ–è¿½è¸ªæŠ€æœ¯<strong>å®šä½</strong>ç‰¹å®šçŸ¥è¯†å­˜å‚¨åœ¨æ¨¡å‹çš„å“ªäº›å‚æ•°ä¸­ï¼Œç„¶åç›´æ¥<strong>ä¿®æ”¹</strong>è¿™äº›è¢«è¯†åˆ«å‡ºçš„å‚æ•°ã€‚</p></li>
<li><p><strong>ä¾‹å­</strong>ï¼š Meng et al. (2022a, 2023) ç­‰äººçš„å·¥ä½œã€‚</p></li>
</ul>
</li>
<li><p><strong>å…ƒå­¦ä¹ ï¼ˆMeta-learningï¼‰</strong>ï¼š</p>
<ul class="simple">
<li><p><strong>ç­–ç•¥</strong>ï¼š è®­ç»ƒä¸€ä¸ªâ€œç¼–è¾‘å™¨â€ç½‘ç»œï¼Œè®©å®ƒå­¦ä¼š<strong>é¢„æµ‹</strong>åº”è¯¥å¦‚ä½•ä¿®æ”¹åŸæ¨¡å‹çš„æƒé‡æ‰èƒ½å®ç°ç›®æ ‡ç¼–è¾‘ã€‚è¿™ç§æ–¹æ³•æ›´å¿«é€Ÿã€é²æ£’ã€‚</p></li>
<li><p><strong>ä¾‹å­</strong>ï¼š De Cao et al. (2021), Mitchell et al. (2022a) ç­‰äººçš„å·¥ä½œã€‚</p></li>
</ul>
</li>
<li><p><strong>ä¸ä¿®æ”¹åŸå§‹æƒé‡çš„æ–¹æ³•</strong>ï¼š</p>
<ul class="simple">
<li><p><strong>åŸºäºæç¤ºï¼ˆPrompt-basedï¼‰</strong>ï¼š é€šè¿‡è®¾è®¡ç‰¹æ®Šçš„<strong>æç¤ºè¯ï¼ˆPromptï¼‰</strong> æˆ–ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰æ¥é—´æ¥åœ°å¼•å¯¼æ¨¡å‹è¾“å‡ºï¼Œä¸è§¦åŠ¨æ¨¡å‹æœ¬èº«ã€‚</p></li>
<li><p><strong>æ·»åŠ é¢å¤–å‚æ•°ï¼ˆAdditional-parameterï¼‰</strong>ï¼š åœ¨åŸå§‹æ¨¡å‹ä¹‹å¤–<strong>æ·»åŠ æ–°çš„ã€å¯è°ƒæ•´çš„å‚æ•°æ¨¡å—</strong>æ¥æ”¹å˜æ¨¡å‹è¡Œä¸ºï¼Œä¿æŒåŸæœ‰æƒé‡ä¸å˜ã€‚</p></li>
</ul>
</li>
</ol>
<p><strong>ç°çŠ¶</strong>ï¼š è¿™äº›æ–¹æ³•åœ¨æ•ˆç‡å’Œå¯æ‰©å±•æ€§ä¸Šå„æœ‰ä¸åŒï¼Œä½†ç›®å‰å¤§å¤šä¸“æ³¨äºå®ä½“çº§åˆ«ï¼ˆå¦‚ä¿®æ”¹æŸä¸ªåäººçš„å‡ºç”Ÿåœ°ï¼‰çš„ç¼–è¾‘ã€‚</p>
</section>
<hr class="docutils" />
<section id="unlearning">
<h4><strong>3.3.2 Unlearningï¼ˆé—å¿˜/åå­¦ä¹ ï¼‰</strong><a class="headerlink" href="#unlearning" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/08/GbvayO.jpg" /></p>
<p>Table 13:Overview of methods for parametric memory optimization in unlearning. â€œPRâ€ (Parametric Reserving) indicates whether the method avoids direct modification of the modelâ€™s internal weights. â€œTFâ€ (Training-Free) denotes whether the method operates without traditional iterative optimization. â€œBUSâ€ (Batch Unlearning Support) reflects the methodâ€™s ability to handle multiple edits simultaneously. â€œSUOâ€ (Sequential Unlearning Optimization) specifies whether the method introduces mechanisms tailored for sequential Editing. â€œLMsâ€ lists the language models used for empirical evaluation.</p>
<p><strong>ç›®æ ‡</strong>ï¼š é€‰æ‹©æ€§<strong>ç§»é™¤</strong>ç‰¹å®šè®°å¿†ï¼ŒåŒæ—¶ä¿ç•™å…¶ä»–æ— å…³çš„çŸ¥è¯†ã€‚</p>
<p><strong>ä¸»è¦æŠ€æœ¯è·¯çº¿</strong>ï¼š</p>
<ol class="arabic simple">
<li><p><strong>æ·»åŠ é¢å¤–å‚æ•°</strong>ï¼š æ·»åŠ æ–°çš„æ¨¡å—ï¼ˆå¦‚logitå·®å¼‚æ¨¡å—æˆ–â€œé—å¿˜å±‚â€ï¼‰æ¥è°ƒæ•´è¾“å‡ºï¼Œé¿å…é‡è®­ç»ƒæ•´ä¸ªæ¨¡å‹ã€‚</p></li>
<li><p><strong>åŸºäºæç¤º</strong>ï¼š é€šè¿‡æ“çºµè¾“å…¥æˆ–ä½¿ç”¨ICLæç¤ºä»å¤–éƒ¨è§¦å‘â€œé—å¿˜â€è¡Œä¸ºã€‚</p></li>
<li><p><strong>å®šä½åé—å¿˜ï¼ˆLocating-then-unlearningï¼‰</strong>ï¼š å…ˆå®šä½åˆ°éœ€è¦é—å¿˜çš„è®°å¿†æ‰€åœ¨çš„å‚æ•°ï¼Œç„¶åè¿›è¡Œé’ˆå¯¹æ€§çš„æ›´æ–°æˆ–å¤±æ´»ã€‚</p></li>
<li><p><strong>åŸºäºè®­ç»ƒç›®æ ‡</strong>ï¼š ä¿®æ”¹è®­ç»ƒæ—¶çš„æŸå¤±å‡½æ•°æˆ–ä¼˜åŒ–ç­–ç•¥ï¼Œæ˜ç¡®åœ°é¼“åŠ±æ¨¡å‹â€œå¿˜è®°â€ç‰¹å®šä¿¡æ¯ã€‚</p></li>
</ol>
<p><strong>æ ¸å¿ƒæŒ‘æˆ˜</strong>ï¼š åœ¨ç»™å®šæ˜ç¡®é—å¿˜ç›®æ ‡æ—¶ï¼Œç²¾ç¡®æ“¦é™¤ç›¸å…³è®°å¿†ï¼ŒåŒæ—¶ä¿ç•™éç›®æ ‡çŸ¥è¯†ï¼Œå¹³è¡¡æ•ˆç‡ä¸ç²¾åº¦ã€‚</p>
</section>
<hr class="docutils" />
<section id="continual-learning">
<h4><strong>3.3.3 Continual Learningï¼ˆæŒç»­å­¦ä¹ ï¼‰</strong><a class="headerlink" href="#continual-learning" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/08/oPp1Lp.jpg" /></p>
<p>Table 14:Overview of methods for parametric memory modification in continual learning. â€œTBâ€ denotes the task boundary whether exists. â€œTSâ€ denotes the task settings including TIL (Task Incremental Learning), CIL (Class Incremental Learning), DIL (Domain Incremental Learning), Task-Free.</p>
<p><strong>ç›®æ ‡</strong>ï¼š è®©æ¨¡å‹èƒ½å¤Ÿ<strong>æŒç»­åœ°å­¦ä¹ æ–°çŸ¥è¯†</strong>ï¼ˆå®ç°é•¿æœŸè®°å¿†ï¼‰ï¼ŒåŒæ—¶<strong>ç¼“è§£ç¾éš¾æ€§é—å¿˜</strong>ï¼ˆå³å­¦äº†æ–°çš„ï¼Œå¿˜äº†æ—§çš„ï¼‰ã€‚</p>
<p><strong>ä¸»è¦æŠ€æœ¯è·¯çº¿</strong>ï¼š</p>
<ol class="arabic simple">
<li><p><strong>åŸºäºæ­£åˆ™åŒ–ï¼ˆRegularization-basedï¼‰</strong>ï¼š</p>
<ul class="simple">
<li><p><strong>ç­–ç•¥</strong>ï¼š åœ¨æ›´æ–°æ¨¡å‹æ—¶<strong>çº¦æŸå¯¹é‡è¦æƒé‡çš„æ›´æ”¹</strong>ï¼Œä»¥ä¿æŠ¤å·²æœ‰çš„å…³é”®è®°å¿†ã€‚</p></li>
<li><p><strong>ä¾‹å­</strong>ï¼š EWC, TaSL, SELF-PARAM, POCL ç­‰æ–¹æ³•ã€‚</p></li>
</ul>
</li>
<li><p><strong>åŸºäºå›æ”¾ï¼ˆReplay-basedï¼‰</strong>ï¼š</p>
<ul class="simple">
<li><p><strong>ç­–ç•¥</strong>ï¼š åœ¨å­¦ä¹ æ–°çŸ¥è¯†æ—¶ï¼Œ<strong>é‡æ–°å¼•å…¥ä¸€éƒ¨åˆ†è¿‡å»çš„æ ·æœ¬ï¼ˆæ•°æ®ï¼‰</strong> æ¥â€œå¤ä¹ â€æ—§çŸ¥è¯†ï¼Œä»è€Œå¼ºåŒ–è®°å¿†ã€‚</p></li>
<li><p><strong>ä¾‹å­</strong>ï¼š DSI++ åˆ©ç”¨ç”Ÿæˆå¼è®°å¿†äº§ç”Ÿä¼ªæŸ¥è¯¢æ¥è¾…åŠ©å­¦ä¹ ã€‚</p></li>
</ul>
</li>
<li><p><strong>æ™ºèƒ½ä½“èŒƒå¼ï¼ˆAgent-basedï¼‰</strong>ï¼š</p>
<ul class="simple">
<li><p><strong>ç­–ç•¥</strong>ï¼š å°†æŒç»­å­¦ä¹ æ‰©å±•åˆ°äº¤äº’ç¯å¢ƒä¸­ï¼Œæ™ºèƒ½ä½“é€šè¿‡<strong>å®æ—¶ä½“éªŒ</strong>é€æ­¥è·å–å’Œå·©å›ºè®°å¿†ã€‚</p></li>
<li><p><strong>ä¾‹å­</strong>ï¼š LifeSpan Cognitive System (LSCS) ç ”ç©¶äº†å¦‚ä½•å°†å¤–éƒ¨è®°å¿†æŒç»­ç¼–ç åˆ°æ¨¡å‹å‚æ•°ä¸­ã€‚</p></li>
</ul>
</li>
</ol>
</section>
<hr class="docutils" />
<section id="id14">
<h4><strong>3.3.4 Discussionï¼ˆè®¨è®ºï¼‰</strong><a class="headerlink" href="#id14" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<section id="sota-solution-analysis">
<h5><strong>SOTA Solution Analysisï¼ˆé¡¶å°–æ–¹æ¡ˆåˆ†æï¼‰</strong><a class="headerlink" href="#sota-solution-analysis" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ul class="simple">
<li><p><strong>å®éªŒè®¾ç½®</strong>ï¼š ä½œè€…åœ¨å¸¸ç”¨çš„ç¼–è¾‘æ•°æ®é›†ï¼ˆCounterFact, ZsREï¼‰å’Œé—å¿˜æ•°æ®é›†ï¼ˆToFUï¼‰ä¸Šæµ‹è¯•äº†å„ç±»åˆ«çš„é¡¶å°–æ–¹æ³•ã€‚</p></li>
<li><p><strong>å…³é”®å‘ç°</strong>ï¼š</p>
<ul>
<li><p><strong>Prompt-basedæ–¹æ³•</strong>æ•´ä½“è¡¨ç°æœ€å¼ºã€‚</p></li>
<li><p><strong>Meta-learningæ–¹æ³•</strong>æ™®éè¡¨ç°ä¸å¦‚å…¶ä»–æ–¹æ³•ã€‚</p></li>
<li><p>æ‰€æœ‰æ–¹æ³•åœ¨ZsREæ•°æ®é›†ä¸Šçš„è¡¨ç°éƒ½æ¯”åœ¨CounterFactä¸Šå·®ï¼Œä¸»è¦åŸå› æ˜¯<strong>ç‰¹å¼‚æ€§ï¼ˆSpecificityï¼‰</strong> å¾—åˆ†ä½ï¼ˆå³ç¼–è¾‘ä¸å¤Ÿç²¾ç¡®ï¼Œå½±å“äº†æ— å…³å†…å®¹ï¼‰ã€‚</p></li>
<li><p>å¤§å¤šæ•°æ–¹æ³•åœ¨ToFUï¼ˆé—å¿˜ï¼‰åŸºå‡†ä¸Šå¾—åˆ†éƒ½å¾ˆé«˜ï¼Œä½œè€…è®¤ä¸ºè¿™ä¸ªåŸºå‡†<strong>å¯èƒ½ä¸å¤Ÿæœ‰æŒ‘æˆ˜æ€§</strong>ï¼Œéœ€è¦å¼€å‘æ›´éš¾çš„æ–°åŸºå‡†ã€‚</p></li>
</ul>
</li>
</ul>
</section>
<section id="scaling-challenges">
<h5><strong>Scaling Challengesï¼ˆæ‰©å±•æ€§æŒ‘æˆ˜ï¼‰</strong><a class="headerlink" href="#scaling-challenges" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ul class="simple">
<li><p><strong>ç¼–è¾‘æ¬¡æ•°</strong>ï¼š é™¤äº†MemoryLLMï¼Œå¤§å¤šæ•°æ–¹æ³•åªèƒ½é¡ºåºç¼–è¾‘1k-5kæ¬¡ï¼Œè¿œæœªè¾¾åˆ°å®é™…åº”ç”¨çš„éœ€æ±‚ã€‚é¡ºåºé—å¿˜çš„ç ”ç©¶æ›´æ˜¯ç¨€å°‘ã€‚</p></li>
<li><p><strong>æ¨¡å‹è§„æ¨¡</strong>ï¼š</p>
<ul>
<li><p><strong>éPromptç±»æ–¹æ³•</strong>ï¼ˆå¦‚ç›´æ¥æ”¹æƒé‡ï¼‰å¤§å¤šåœ¨<strong>ä¸­å°æ¨¡å‹ï¼ˆâ‰¤20Bå‚æ•°ï¼‰</strong> ä¸Šæµ‹è¯•ï¼Œå› ä¸ºè®¡ç®—æˆæœ¬é«˜ï¼Œéš¾ä»¥æ‰©å±•åˆ°è¶…å¤§æ¨¡å‹ã€‚</p></li>
<li><p><strong>Promptç±»æ–¹æ³•</strong>åˆ™æ›´å¸¸åœ¨<strong>å¤§æ¨¡å‹</strong>ä¸Šè¯„ä¼°ï¼Œå› ä¸ºå®ƒä»¬ä¾èµ–æ¨¡å‹å¼ºå¤§çš„æŒ‡ä»¤éµå¾ªå’Œä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›ã€‚</p></li>
</ul>
</li>
<li><p><strong>æ ¸å¿ƒé—®é¢˜</strong>ï¼š å¦‚ä½•å¹³è¡¡æ¨¡å‹å¤§å°ä¸ç¼–è¾‘/é—å¿˜çš„æœ‰æ•ˆæ€§å’Œæ•ˆç‡ï¼Œæ˜¯ä¸€ä¸ªäºŸå¾…è§£å†³çš„é—®é¢˜ã€‚</p></li>
</ul>
</section>
<section id="id15">
<h5><strong>Publication Trendingï¼ˆå‘è¡¨è¶‹åŠ¿ï¼‰</strong><a class="headerlink" href="#id15" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ul class="simple">
<li><p><strong>å…³æ³¨åº¦</strong>ï¼š <strong>Editingï¼ˆç¼–è¾‘ï¼‰</strong> é¢†åŸŸå—åˆ°çš„å…³æ³¨æœ€å¤šï¼Œå°¤å…¶æ˜¯â€œå®šä½åç¼–è¾‘â€å’Œâ€œæ·»åŠ å‚æ•°â€è¿™ä¸¤ç§æ–¹æ³•ã€‚</p></li>
<li><p><strong>ç¤¾åŒºå·®å¼‚</strong>ï¼š NLPç¤¾åŒºæ›´å…³æ³¨ç¼–è¾‘ï¼Œè€ŒMLç¤¾åŒºå¯¹ä¸‰è€…åˆ†å¸ƒæ›´å‡åŒ€ã€‚</p></li>
<li><p><strong>å½±å“åŠ›</strong>ï¼š â€œå®šä½åç¼–è¾‘â€é¢†åŸŸäº§ç”Ÿäº†å¤šç¯‡æå…·å½±å“åŠ›çš„è®ºæ–‡ï¼ˆRCIæ–¹å·®é«˜ï¼‰ã€‚</p></li>
<li><p><strong>ç ”ç©¶æ½œåŠ›</strong>ï¼š <strong>Unlearningï¼ˆé—å¿˜ï¼‰</strong> æ–¹æ³•è™½ç„¶æ•°é‡å°‘ï¼Œä½†å·²æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼›<strong>Continual Learningï¼ˆæŒç»­å­¦ä¹ ï¼‰</strong> åˆ™ç›¸å¯¹æ¢ç´¢ä¸è¶³ã€‚</p></li>
</ul>
</section>
<section id="id16">
<h5><strong>æ ¸å¿ƒæ€»ç»“ï¼ˆä½ çš„æ€»ç»“å¾ˆæ£’ï¼Œå®Œå…¨æ­£ç¡®ï¼‰</strong><a class="headerlink" href="#id16" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ul class="simple">
<li><p>å½“å‰ç¼–è¾‘æ–¹æ³•çš„<strong>ç²¾ç¡®æ€§ï¼ˆç‰¹å¼‚æ€§ï¼‰</strong> ä¸è¶³ã€‚</p></li>
<li><p>å½“å‰çš„é—å¿˜åŸºå‡†ï¼ˆå¦‚ToFUï¼‰<strong>å¤ªç®€å•</strong>ï¼Œæ— æ³•åæ˜ çœŸå®ä¸–ç•Œçš„æŒ‘æˆ˜ã€‚</p></li>
<li><p>æœªæ¥çš„æŒç»­å­¦ä¹ éœ€è¦é¿å…åœ¨äº¤äº’ä¸­<strong>è¦†ç›–</strong>æ¨¡å‹å‚æ•°ä¸­æŒä¹…çš„é•¿æœŸè®°å¿†ã€‚</p></li>
</ul>
</section>
</section>
</section>
<hr class="docutils" />
<section id="multi-source-memory">
<h3>3.4 å¤šæºè®°å¿† (Multi-source Memory)<a class="headerlink" href="#multi-source-memory" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/08/t5bdcd.jpg" /></p>
<p>Table 7:Datasets used for evaluating multi-source memory. â€œMoâ€ denotes data modality. â€œOpsâ€ indicates operations. â€œSrc#â€ = number of information sources per instance; â€œMod#â€ = number of modalities; â€œTaskâ€ = retrieval, fusion, reasoning, or conflict resolution.</p>
<p><strong>æœ¬èŠ‚æ ¸å¿ƒæ€æƒ³ï¼š</strong>
åœ¨ç°å®ä¸–ç•Œä¸­ï¼ŒAIç³»ç»Ÿéœ€è¦åŒæ—¶å¤„ç†å†…éƒ¨å‚æ•°å’Œå¤šç§å¤–éƒ¨çŸ¥è¯†ï¼ˆå¦‚æ•°æ®åº“ã€å›¾è¡¨ã€æ–‡æœ¬ã€éŸ³é¢‘ã€å›¾åƒã€è§†é¢‘ç­‰ï¼‰ã€‚å¤šæºè®°å¿†å°±æ˜¯ç ”ç©¶å¦‚ä½•è®©AIæœ‰æ•ˆåœ°æ•´åˆå’Œåˆ©ç”¨è¿™äº›ä¸åŒæ¥æºã€ä¸åŒæ ¼å¼çš„ä¿¡æ¯ã€‚æœ¬èŠ‚ä»ä¸¤ä¸ªç»´åº¦æ¢è®¨å…¶å…³é”®æŒ‘æˆ˜ï¼š<strong>è·¨æ–‡æœ¬æ•´åˆ</strong> å’Œ <strong>å¤šæ¨¡æ€åè°ƒ</strong>ã€‚</p>
<section id="cross-textual-integration">
<h4>3.4.1 è·¨æ–‡æœ¬æ•´åˆ (Cross-textual Integration)<a class="headerlink" href="#cross-textual-integration" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/08/tDnUQD.jpg" /></p>
<p>Table 15:Overview of methods for multi-source memory in cross-textual integration. â€œTFâ€ (Training Free) denotes whether the method operates without additional gradient-based updates. â€œSTsâ€ denotes the source types. â€œSNsâ€ denotes the source dataset names.</p>
<p><strong>æœ¬å°èŠ‚æ ¸å¿ƒæ€æƒ³ï¼š</strong> è®©AIèƒ½å¤Ÿä»å¤šä¸ªæ–‡æœ¬æ¥æºä¸­è¿›è¡Œæ·±åº¦æ¨ç†ï¼Œå¹¶è§£å†³ä¸åŒæ¥æºä¿¡æ¯ä¹‹é—´çš„å†²çªï¼Œä»è€Œç»™å‡ºæ›´å‡†ç¡®ã€æœ‰æ ¹æ®çš„å›ç­”ã€‚å®ƒåˆ†ä¸ºä¸¤ä¸ªå­éƒ¨åˆ†ï¼š<strong>æ¨ç†</strong> å’Œ <strong>å†²çª</strong>ã€‚</p>
<section id="reasoning">
<h5>æ¨ç† (Reasoning)<a class="headerlink" href="#reasoning" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ul class="simple">
<li><p><strong>ç›®æ ‡ï¼š</strong> æ•´åˆä¸åŒæ ¼å¼çš„è®°å¿†ï¼ˆå¦‚ç»“æ„åŒ–çš„æ•°æ®åº“å’Œéç»“æ„åŒ–çš„æ–‡æœ¬ï¼‰ï¼Œç”Ÿæˆåœ¨äº‹å®å’Œè¯­ä¹‰ä¸Šéƒ½ä¸€è‡´çš„å›ç­”ã€‚</p></li>
<li><p><strong>æ–¹æ³•åˆ†ç±»ï¼š</strong></p>
<ol class="arabic simple">
<li><p><strong>æ“ä½œç»“æ„åŒ–è®°å¿†ï¼š</strong> åƒæ“ä½œæ•°æ®åº“ä¸€æ ·ç²¾ç¡®åœ°ä½¿ç”¨ç¬¦å·åŒ–çš„è®°å¿†ï¼ˆä¾‹å¦‚ï¼šChatDB, Neurosymbolicï¼‰ã€‚</p></li>
<li><p><strong>åŠ¨æ€æ•´åˆå‚æ•°åŒ–è®°å¿†ï¼š</strong> çµæ´»åœ°æ•´åˆé’ˆå¯¹ç‰¹å®šé¢†åŸŸè®­ç»ƒçš„å†…éƒ¨æ¨¡å‹å‚æ•°ï¼ˆä¾‹å¦‚ï¼šEMATï¼‰ã€‚</p></li>
<li><p><strong>å¤šæ–‡æ¡£æ¨ç†ï¼š</strong> ä»å¤šä¸ªä¸åŒçš„æ–‡æ¡£æ¥æºä¸­è·å–ä¿¡æ¯è¿›è¡Œæ¨ç†ï¼ˆä¾‹å¦‚ï¼šDelTA, dynamic-MTï¼‰ã€‚</p></li>
<li><p><strong>å¼‚æ„çŸ¥è¯†æ•´åˆï¼š</strong> åŒæ—¶ä»ç»“æ„åŒ–å’Œéç»“æ„åŒ–æ¥æºä¸­æ£€ç´¢ä¿¡æ¯ï¼ˆä¾‹å¦‚ï¼šStructRAG, GoGï¼‰ã€‚</p></li>
</ol>
</li>
<li><p><strong>ç°å­˜æŒ‘æˆ˜ï¼š</strong> è™½ç„¶å·²æœ‰è¿›å±•ï¼Œä½†å¦‚ä½•å®ç°å¯¹<strong>å¼‚æ„</strong>ï¼ˆä¸åŒè´¨ï¼‰<strong>å¤šæº</strong>è®°å¿†çš„<strong>ç»Ÿä¸€æ¨ç†</strong>ä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚ç‰¹åˆ«æ˜¯å¦‚ä½•æœ‰æ•ˆæ•´åˆå†…éƒ¨å‚æ•°åŒ–è®°å¿†ä¸å¤–éƒ¨çŸ¥è¯†æºã€‚</p></li>
</ul>
</section>
<section id="conflict">
<h5>å†²çª (Conflict)<a class="headerlink" href="#conflict" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ul class="simple">
<li><p><strong>å®šä¹‰ï¼š</strong> æŒ‡åœ¨æ£€ç´¢å’Œæ¨ç†æ¥è‡ªä¸åŒè¡¨å¾çš„è®°å¿†æ—¶ï¼Œå‡ºç°çš„<strong>äº‹å®æˆ–è¯­ä¹‰ä¸Šçš„ä¸ä¸€è‡´</strong>ã€‚ä¾‹å¦‚ï¼Œå†…éƒ¨æ¨¡å‹è®°å¿†çš„çŸ¥è¯†ä¸å¤–éƒ¨æ£€ç´¢åˆ°çš„çŸ¥è¯†çŸ›ç›¾ï¼Œæˆ–è€…æ•°æ®åº“é‡Œçš„æ•°æ®å’Œæ–‡æœ¬æè¿°å¯¹ä¸ä¸Šã€‚</p></li>
<li><p><strong>å½“å‰ç ”ç©¶é‡ç‚¹ï¼š</strong> ä¸»è¦æ˜¯<strong>è¯†åˆ«å’Œå®šä½</strong>è¿™äº›ä¸ä¸€è‡´ã€‚</p>
<ul>
<li><p><strong>RKC-LLMï¼š</strong> æä¾›ä¸€ä¸ªè¯„ä¼°æ¡†æ¶ï¼Œç”¨æ¥æµ‹è¯•æ¨¡å‹å‘ç°ä¸Šä¸‹æ–‡çŸ›ç›¾çš„èƒ½åŠ›ã€‚</p></li>
<li><p><strong>BGC-KCï¼š</strong> æŒ‡å‡ºæ¨¡å‹æ›´å€¾å‘äºç›¸ä¿¡è‡ªå·±çš„å†…éƒ¨çŸ¥è¯†ï¼Œè€Œä¸æ˜¯æ£€ç´¢åˆ°çš„å†…å®¹ã€‚è¿™è¯´æ˜äº†æ ‡æ˜ä¿¡æ¯æ¥æºå’Œæ ¡å‡†ä¿¡ä»»çš„é‡è¦æ€§ã€‚</p></li>
</ul>
</li>
<li><p><strong>ç°å­˜æŒ‘æˆ˜ï¼š</strong> ç°æœ‰çš„å†²çªè§£å†³æ–¹æ³•å¤§å¤šå±€é™äºé™æ€åœºæ™¯æˆ–å•æºæ¨ç†ï¼Œè¿˜ä¸å¤Ÿå¼ºå¤§ã€‚</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="multi-modal-coordination">
<h4>3.4.2 å¤šæ¨¡æ€åè°ƒ (Multi-Modal Coordination)<a class="headerlink" href="#multi-modal-coordination" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/08/bAXAvT.jpg" /></p>
<p>Table 16:Overview of methods for multi-source memory in Multi-modal Coordination. â€œTFâ€ (Training Free) denotes whether the method operates without additional gradient-based updates. â€œDSâ€ (Dialogue System) denotes whether the method aims for a dialogue task. â€œMoâ€ denotes data modality (T â€“ Text, I â€“ Images, B â€“ Box (Position)).</p>
<p><strong>æœ¬å°èŠ‚æ ¸å¿ƒæ€æƒ³ï¼š</strong> å½“è®°å¿†ç³»ç»ŸåŒ…å«å¤šç§æ¨¡æ€ï¼ˆå¦‚æ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘ï¼‰æ—¶ï¼Œæ ¸å¿ƒæŒ‘æˆ˜åœ¨äºå¦‚ä½•<strong>èåˆ</strong>å’Œ<strong>æ£€ç´¢</strong>è¿™äº›ä¸åŒå½¢å¼çš„ä¿¡æ¯ã€‚</p>
<section id="fusion">
<h5>èåˆ (Fusion)<a class="headerlink" href="#fusion" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ul class="simple">
<li><p><strong>å®šä¹‰ï¼š</strong> å°†æ£€ç´¢åˆ°çš„ä¸åŒæ¨¡æ€çš„ä¿¡æ¯è¿›è¡Œå¯¹é½å’Œæ•´åˆã€‚</p></li>
<li><p><strong>æ–¹æ³•åˆ†ç±»ï¼š</strong></p>
<ol class="arabic simple">
<li><p><strong>ç»Ÿä¸€è¯­ä¹‰æŠ•å°„ï¼š</strong> å°†ä¸åŒæ¨¡æ€çš„ä¿¡æ¯ï¼ˆå¦‚å›¾ç‰‡ã€æ–‡å­—ï¼‰æ˜ å°„åˆ°åŒä¸€ä¸ªè¯­ä¹‰ç©ºé—´ä¸­è¿›è¡Œå¤„ç†ï¼ˆä¾‹å¦‚ï¼šUniTransSeR, PaLM-Eï¼‰ã€‚</p></li>
<li><p><strong>é•¿æœŸè·¨æ¨¡æ€è®°å¿†æ•´åˆï¼š</strong> å»ºç«‹æŒä¹…çš„è®°å¿†åº“ï¼Œé•¿æœŸç§¯ç´¯å’Œæ•´åˆå¤šæ¨¡æ€çŸ¥è¯†ï¼ˆä¾‹å¦‚ï¼šLifelongMemoryè®°å½•ç—…å†ï¼ŒMA-LMMç†è§£é•¿è§†é¢‘ï¼‰ã€‚</p></li>
</ol>
</li>
<li><p><strong>ç°å­˜æŒ‘æˆ˜ï¼š</strong> å½“å‰æ–¹æ³•åœ¨<strong>é•¿æœŸå¤šæ¨¡æ€è®°å¿†ç®¡ç†</strong>æ–¹é¢ä¸è¶³ï¼Œä¾‹å¦‚å¦‚ä½•åŠ¨æ€æ›´æ–°è®°å¿†å’Œä¿æŒä¸åŒæ¥æºé—´çš„ä¸€è‡´æ€§ã€‚</p></li>
</ul>
</section>
<section id="id17">
<h5>æ£€ç´¢ (Retrieval)<a class="headerlink" href="#id17" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ul class="simple">
<li><p><strong>å®šä¹‰ï¼š</strong> ä»å­˜å‚¨çš„è®°å¿†ä¸­è®¿é—®è·¨æ¨¡æ€çš„çŸ¥è¯†ã€‚</p></li>
<li><p><strong>ä¸»æµæ–¹æ³•ï¼š</strong> åŸºäº<strong>åµŒå…¥ç›¸ä¼¼åº¦è®¡ç®—</strong>ã€‚ä½¿ç”¨å¤šæ¨¡æ€æ¨¡å‹ï¼ˆå¦‚CLIP, QwenVLï¼‰å°†ä¸åŒæ¨¡æ€çš„å†…å®¹æŠ•å°„åˆ°å…±äº«çš„è¯­ä¹‰ç©ºé—´ï¼Œç„¶åè®¡ç®—å®ƒä»¬çš„å‘é‡ç›¸ä¼¼åº¦æ¥æ£€ç´¢ï¼ˆä¾‹å¦‚ï¼šVISTA, UniVL-DRï¼‰ã€‚</p></li>
<li><p><strong>è¿›é˜¶æ–¹æ³•ï¼š</strong> ä¸€äº›å·¥ä½œå¼€å§‹å¼•å…¥æ›´å¤šä¸Šä¸‹æ–‡ï¼Œä¾‹å¦‚IGSRåœ¨å¤šè½®å¯¹è¯ä¸­æ ¹æ®â€œæ„å›¾â€æ¥æ£€ç´¢è¡¨æƒ…åŒ…ã€‚</p></li>
<li><p><strong>ç°å­˜æŒ‘æˆ˜ï¼š</strong></p>
<ol class="arabic simple">
<li><p>å½“å‰æ–¹æ³•å¤§å¤šåœç•™åœ¨æµ…å±‚çš„ç›¸ä¼¼åº¦åŒ¹é…ï¼Œç¼ºä¹åŸºäºè®°å¿†çš„ã€å…·æœ‰<strong>æ¨ç†èƒ½åŠ›</strong>çš„æ£€ç´¢ã€‚</p></li>
<li><p>å¯¹<strong>éŸ³é¢‘</strong>å’Œ<strong>ä¼ æ„Ÿå™¨ä¿¡å·</strong>ç­‰æ¨¡æ€çš„æ¢ç´¢ä»ç„¶ä¸è¶³ï¼Œè€Œè¿™äº›å¯¹äºå…·èº«æ™ºèƒ½ï¼ˆå¦‚æœºå™¨äººï¼‰è‡³å…³é‡è¦ã€‚</p></li>
</ol>
</li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="id18">
<h4>3.4.3 è®¨è®º (Discussion)<a class="headerlink" href="#id18" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<p>æœ¬èŠ‚æ˜¯å¯¹å‰è¿°å†…å®¹çš„æ€»ç»“å’Œè¶‹åŠ¿åˆ†æã€‚</p>
<section id="trends-in-multi-source-memory-integration">
<h5>å¤šæºè®°å¿†æ•´åˆè¶‹åŠ¿ (Trends in Multi-Source Memory Integration)<a class="headerlink" href="#trends-in-multi-source-memory-integration" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ul class="simple">
<li><p><strong>æ€»ä½“è¶‹åŠ¿ï¼š</strong> é¢†åŸŸæ­£ä»<strong>é™æ€çš„æ£€ç´¢ç®¡é“</strong>è½¬å‘<strong>åŠ¨æ€çš„ã€å¯¹ä¸Šä¸‹æ–‡æ•æ„Ÿçš„è®°å¿†ç³»ç»Ÿ</strong>ï¼Œä»¥æ”¯æŒè·¨ä»»åŠ¡å’Œä¼šè¯çš„ã€åŸºäºæ—¶é—´çš„æ¨ç†ã€‚</p></li>
<li><p><strong>è·¨æ–‡æœ¬æ•´åˆè¶‹åŠ¿ï¼š</strong></p>
<ul>
<li><p><strong>æ—©æœŸï¼š</strong> ä½¿ç”¨ç¬¦å·è®°å¿†ï¼ˆå¦‚æ•°æ®åº“ï¼‰ï¼Œé€šè¿‡æ˜¾å¼æŸ¥è¯¢è®¿é—®ï¼Œ<strong>é€æ˜ä½†æ‰©å±•æ€§å·®</strong>ï¼ˆå¦‚ChatDBï¼‰ã€‚</p></li>
<li><p><strong>è¿‘æœŸï¼š</strong> ä½¿ç”¨éç»“æ„åŒ–è®°å¿†å’Œç¥ç»æ£€ç´¢ï¼Œç»“åˆæ³¨æ„åŠ›æœºåˆ¶å’Œæ€ç»´é“¾æ¨ç†ï¼Œä½†è®°å¿†ä»æ˜¯<strong>é™æ€çš„</strong>ï¼ˆå¦‚StructRAGï¼‰ã€‚</p></li>
<li><p><strong>æœ€æ–°ï¼š</strong> èµ°å‘<strong>æ¨ç†æ„ŸçŸ¥è®°å¿†</strong>ï¼Œä½¿ç”¨æ£€ç´¢-ç”Ÿæˆå¾ªç¯å’Œæ™ºèƒ½ä½“åä½œæ¥åŠ¨æ€æ¼”åŒ–è®°å¿†ï¼ˆå¦‚MATTER, GoGï¼‰ã€‚</p></li>
<li><p><strong>æ ¸å¿ƒæŒ‘æˆ˜ï¼š</strong> <strong>è§£å†³å†²çª</strong>ä»ç„¶æ˜¯å·¨å¤§éš¾é¢˜ï¼Œä¿¡æ¯åˆå¹¶ç¼ºä¹ä¸€è‡´æ€§æ£€æŸ¥å’Œæ¥æºæ ‡æ³¨ï¼Œå¯¼è‡´â€œå¹»è§‰â€å’Œäº‹å®æ¼‚ç§»ã€‚åˆæ­¥çš„è§£å†³æ–¹æ¡ˆï¼ˆå¦‚å¤šæ­¥å†²çªè§£å†³ï¼‰å¾ˆæœ‰å¸Œæœ›ä½†å°šéš¾æ‰©å±•ã€‚</p></li>
</ul>
</li>
<li><p><strong>å¤šæ¨¡æ€åè°ƒè¶‹åŠ¿ï¼š</strong></p>
<ul>
<li><p>åœ¨<strong>èåˆã€æ£€ç´¢å’Œæ—¶é—´å»ºæ¨¡</strong>ä¸‰ä¸ªç»´åº¦éƒ½æœ‰è¿›å±•ã€‚</p></li>
<li><p><strong>èåˆç­–ç•¥</strong>ä»è”åˆåµŒå…¥å‘å±•åˆ°æ›´ç²¾ç»†çš„æ ‡è¯†ç¬¦è®°å¿†å’Œè·¨æ¨¡æ€å›¾èåˆã€‚</p></li>
<li><p><strong>æ£€ç´¢æ–¹æ³•</strong>ä»é™æ€ç›¸ä¼¼åº¦å‘å±•åˆ°åŒ…å«æ—¶é—´ä¸Šä¸‹æ–‡çš„æ–¹æ³•ï¼ˆå¦‚æ—¶åºå›¾ï¼‰ã€‚</p></li>
<li><p><strong>å…³é”®å‘ç°ï¼š</strong> 60%çš„æ¨¡å‹éƒ½ç¼–ç äº†æ—¶é—´ä¿¡æ¯ï¼Œè¯´æ˜<strong>æ—¶é—´</strong>åœ¨é•¿æœŸä»»åŠ¡ä¸­æå…¶é‡è¦ã€‚</p></li>
<li><p><strong>æ“ä½œæ§åˆ¶</strong>å˜å¾—æ›´é‡è¦ï¼šæ—©æœŸçš„ç³»ç»Ÿåªå…³æ³¨æ£€ç´¢ï¼Œç°åœ¨çš„æ–°ç³»ç»Ÿï¼ˆå¦‚E-Agent, WorldMemï¼‰å¼ºè°ƒ<strong>è‡ªæˆ‘ç»´æŠ¤</strong>ï¼Œèƒ½æŒç»­åœ°<strong>æ›´æ–°ã€ç´¢å¼•ã€å‹ç¼©</strong>è®°å¿†å†…å®¹ï¼Œæ”¯æŒé•¿æœŸè§„åˆ’ã€‚</p></li>
</ul>
</li>
</ul>
</section>
<section id="publication-trend">
<h5>å‘è¡¨è¶‹åŠ¿ (Publication Trend)<a class="headerlink" href="#publication-trend" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ul class="simple">
<li><p><strong>è·¨æ–‡æœ¬æ¨ç†</strong>çš„ç ”ç©¶åœ¨æ•°é‡ä¸Šå ä¸»å¯¼ã€‚</p></li>
<li><p><strong>èåˆ</strong>ç ”ç©¶ï¼ˆå°¤å…¶æ˜¯åŸºäºCLIPçš„ï¼‰å…·æœ‰æœ€é«˜çš„å¼•ç”¨é‡å’Œå½±å“åŠ›ã€‚</p></li>
<li><p><strong>åŠ¨æ€æ£€ç´¢</strong>å’Œ<strong>å†²çªè§£å†³</strong>ä»ç„¶æ˜¯æ¢ç´¢ä¸è¶³çš„é¢†åŸŸã€‚</p></li>
</ul>
</section>
<section id="id19">
<h5>æœªæ¥æ–¹å‘ (éšå«åœ¨æ–‡æœ¬ä¸­çš„æ€»ç»“)<a class="headerlink" href="#id19" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h5>
<ol class="arabic simple">
<li><p><strong>å¼€å‘å†²çªæ„ŸçŸ¥ç³»ç»Ÿ</strong>ï¼šéœ€è¦èƒ½å¤Ÿæ˜ç¡®æ ‡æ³¨ä¿¡æ¯æ¥æºå¹¶è¿›è¡Œä¸€è‡´æ€§éªŒè¯çš„è®°å¿†ç³»ç»Ÿã€‚</p></li>
<li><p><strong>å‘å±•è‡ªæˆ‘ç»´æŠ¤æ¶æ„</strong>ï¼šæ”¯æŒå¯¹è®°å¿†è¿›è¡Œç´¢å¼•ã€æ›´æ–°å’Œå‹ç¼©ï¼Œä»¥å®ç°é•¿æœŸã€è·¨ä¼šè¯çš„è®°å¿†ã€‚</p></li>
<li><p><strong>å®ç°ç»Ÿä¸€æ¨ç†</strong>ï¼šå°†æ—¶é—´åŸºç¡€å’Œå¤šæ¨¡æ€åè°ƒæ•´åˆåˆ°ä¸€ä¸ªç»Ÿä¸€çš„è®°å¿†æ¨ç†æ¡†æ¶ä¸­ï¼Œä»¥åº”å¯¹ç°å®ä¸–ç•Œçš„é•¿æœŸä»»åŠ¡ã€‚</p></li>
</ol>
</section>
</section>
</section>
</section>
<section id="memory-in-practice">
<h2>4 Memory In Practice<a class="headerlink" href="#memory-in-practice" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<section id="applications">
<h3>4.1 Applicationsï¼ˆåº”ç”¨åœºæ™¯ï¼‰<a class="headerlink" href="#applications" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/08/sJczWo.jpg" /></p>
<p>Table 19: Application Layer-Level Tools for Memory Management and Utilization.</p>
<p>æœ¬èŠ‚ä¸»è¦ä»‹ç»<strong>åŸºäºè®°å¿†çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿ</strong>åœ¨å¤šä¸ªå®é™…åº”ç”¨åœºæ™¯ä¸­çš„åº”ç”¨ï¼ŒåŒ…æ‹¬<strong>çŸ¥è¯†æ¨ç†</strong>ã€<strong>ä¸ªæ€§åŒ–æœåŠ¡</strong>ã€<strong>ä»»åŠ¡å®Œæˆ</strong>å’Œ<strong>å¤šæ¨¡æ€äº¤äº’</strong>ã€‚è¿™äº›ç³»ç»Ÿé€šè¿‡<strong>å‚æ•°åŒ–è®°å¿†</strong>ã€<strong>ç»“æ„åŒ–è®°å¿†</strong>å’Œ<strong>éç»“æ„åŒ–è®°å¿†</strong>ç­‰å¤šç§å½¢å¼ï¼Œæ”¯æ’‘å¤æ‚ä»»åŠ¡çš„å®Œæˆã€‚</p>
<ul class="simple">
<li><p><strong>çŸ¥è¯†ä¸­å¿ƒå‹ç³»ç»Ÿ</strong>ï¼ˆKnowledge-centric systemsï¼‰å€ŸåŠ©<strong>å‚æ•°åŒ–è®°å¿†</strong>ï¼ˆparametric memoryï¼‰å°†é€šç”¨çŸ¥è¯†ç¼–ç è¿›æ¨¡å‹æƒé‡ä¸­ï¼Œå¹¿æ³›åº”ç”¨äºç¼–ç¨‹ã€åŒ»å­¦ã€é‡‘èå’Œæ³•å¾‹ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œé€šè¿‡æŒ‡ä»¤å¾®è°ƒï¼Œæ¨¡å‹å¯ä»¥æ‰§è¡Œç‰¹å®šé¢†åŸŸçš„æ¨ç†ä»»åŠ¡ã€‚</p></li>
<li><p><strong>ç”¨æˆ·ä¸­å¿ƒå‹ç³»ç»Ÿ</strong>ï¼ˆUser-centric systemsï¼‰ä¾èµ–<strong>æƒ…å¢ƒè®°å¿†</strong>ï¼ˆcontextual memoryï¼‰å»ºæ¨¡ç”¨æˆ·åå¥½å’Œè¡Œä¸ºå†å²ï¼Œå®ç°ä¸ªæ€§åŒ–å¯¹è¯å’Œè‡ªé€‚åº”æ•™å­¦ã€‚è¿™ç±»ç³»ç»Ÿéœ€è¦æŒç»­æ›´æ–°è®°å¿†ä»¥é€‚åº”ç”¨æˆ·çš„åŠ¨æ€éœ€æ±‚ã€‚</p></li>
<li><p><strong>ä»»åŠ¡å¯¼å‘å‹ç³»ç»Ÿ</strong>ï¼ˆTask-oriented agentsï¼‰ä½¿ç”¨<strong>ç»“æ„åŒ–è®°å¿†</strong>ï¼ˆå¦‚é”®å€¼å­˜å‚¨ã€å·¥ä½œæµå›¾ï¼‰æ¥ç»´æŠ¤å¯¹è¯è¿ç»­æ€§ï¼Œå¹¶æ”¯æŒé•¿æœŸæ¨ç†ï¼Œå¦‚é¡¹ç›®ç®¡ç†æˆ–è™šæ‹ŸåŠ©æ‰‹åœºæ™¯ã€‚</p></li>
<li><p><strong>å¤šæ¨¡æ€ç³»ç»Ÿ</strong>ï¼ˆMulti-modal systemsï¼‰èåˆè¯­è¨€ã€è§†è§‰ã€éŸ³é¢‘ç­‰æ¨¡æ€çš„<strong>å‚æ•°åŒ–è®°å¿†</strong>å’Œ<strong>æƒ…å¢ƒè®°å¿†</strong>ï¼Œåœ¨è‡ªåŠ¨é©¾é©¶å’ŒåŒ»ç–—å†³ç­–ç­‰å¤æ‚ç¯å¢ƒä¸­å®ç°è¿è´¯äº¤äº’ã€‚</p></li>
</ul>
<p><strong>é‡ç‚¹æ€»ç»“</strong>ï¼šè®°å¿†ç³»ç»Ÿä¸æ˜¯è¢«åŠ¨çš„å­˜å‚¨ï¼Œè€Œæ˜¯<strong>ä¸»åŠ¨çš„æ¨ç†ä¸é€‚åº”æœºåˆ¶</strong>ï¼Œå¯¹äºAIç³»ç»Ÿåœ¨å¤æ‚ä»»åŠ¡ä¸­çš„é•¿æœŸèƒœä»»åŠ›å’Œæ³›åŒ–èƒ½åŠ›è‡³å…³é‡è¦ã€‚</p>
</section>
<hr class="docutils" />
<section id="products">
<h3>4.2 Productsï¼ˆäº§å“åº”ç”¨ï¼‰<a class="headerlink" href="#products" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>æœ¬èŠ‚æ¢è®¨äº†<strong>è®°å¿†åœ¨å®é™…äº§å“ä¸­çš„ä½“ç°</strong>ã€‚é€šè¿‡ç»“åˆç”¨æˆ·å»ºæ¨¡å’Œç»“æ„åŒ–ä»»åŠ¡ç®¡ç†ï¼Œè®°å¿†å¢å¼ºäº†äº§å“åœ¨<strong>ä¸ªæ€§åŒ–</strong>ã€<strong>è¿è´¯æ€§</strong>å’Œ<strong>ä»»åŠ¡æ‰§è¡Œ</strong>æ–¹é¢çš„èƒ½åŠ›ã€‚</p>
<ul class="simple">
<li><p><strong>ç”¨æˆ·ä¸­å¿ƒå‹äº§å“</strong>ï¼ˆUser-centric productsï¼‰å¦‚ <strong>Replika</strong>ï¼ˆAIä¼´ä¾£ï¼‰ã€<strong>Amazon æ¨èç³»ç»Ÿ</strong>ã€<strong>Me.bot</strong>å’Œ <strong>Tencent ima.copilot</strong>ï¼Œåˆ©ç”¨æŒä¹…åŒ–ç”¨æˆ·æ¨¡å‹å®ç°æƒ…æ„Ÿè¿ç»­æ€§å’Œä¸ªæ€§åŒ–æ¨èã€‚</p></li>
<li><p><strong>ä»»åŠ¡å¯¼å‘å‹äº§å“</strong>ï¼ˆTask-oriented productsï¼‰å¦‚ <strong>ChatGPT</strong>ã€<strong>Grok</strong>ã€<strong>GitHub Copilot</strong>ã€<strong>Coze</strong> å’Œ <strong>CodeBuddy</strong>ï¼Œé€šè¿‡ç»“æ„åŒ–è®°å¿†ï¼ˆå¦‚å¯¹è¯å†å²å’Œä»»åŠ¡è¡¨ç¤ºï¼‰æ”¯æŒå¤šè½®å¯¹è¯å’Œé•¿æœŸä»»åŠ¡è§„åˆ’ã€‚</p></li>
</ul>
<p><strong>é‡ç‚¹æ€»ç»“</strong>ï¼šè¿™äº›äº§å“å±•ç¤ºäº†<strong>è®°å¿†æ¶æ„</strong>å¦‚ä½•åœ¨å®é™…ç³»ç»Ÿä¸­è¢«éƒ¨ç½²ï¼Œä»¥å®ç°ç”¨æˆ·é•¿æœŸä¸ªæ€§åŒ–ã€äº¤äº’è¿è´¯æ€§ä»¥åŠä»»åŠ¡è‡ªé€‚åº”æ‰§è¡Œï¼Œä½“ç°å‡ºè®°å¿†é›†æˆå¯¹<strong>ç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿå¯é æ€§</strong>çš„ç›´æ¥å½±å“ã€‚</p>
</section>
<hr class="docutils" />
<section id="tools">
<h3>4.3 Toolsï¼ˆå·¥å…·ä¸æ¡†æ¶ï¼‰<a class="headerlink" href="#tools" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>æœ¬èŠ‚ä»‹ç»äº†ä¸€ä¸ª<strong>åˆ†å±‚çš„è®°å¿†å¢å¼ºAIå·¥å…·ç”Ÿæ€ç³»ç»Ÿ</strong>ï¼Œæ¶µç›–åŸºç¡€ç»„ä»¶ã€æ¨¡å—åŒ–æ¡†æ¶å’Œè®°å¿†å±‚ç³»ç»Ÿï¼Œåˆ†åˆ«æ”¯æŒ<strong>é•¿æœŸä¸Šä¸‹æ–‡ç®¡ç†</strong>ã€<strong>ç”¨æˆ·å»ºæ¨¡</strong>ã€<strong>çŸ¥è¯†ä¿ç•™</strong>å’Œ<strong>è‡ªé€‚åº”è¡Œä¸º</strong>ã€‚</p>
<ul class="simple">
<li><p><strong>åŸºç¡€ç»„ä»¶</strong>ï¼ˆComponentsï¼‰ï¼š</p>
<ul>
<li><p>åŒ…æ‹¬å‘é‡æ•°æ®åº“ï¼ˆå¦‚ <strong>FAISS</strong>ï¼‰ã€å›¾æ•°æ®åº“ï¼ˆå¦‚ <strong>Neo4j</strong>ï¼‰å’Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ <strong>Llama</strong>ã€<strong>GPT-4</strong>ï¼‰ã€‚</p></li>
<li><p>æ£€ç´¢æœºåˆ¶ï¼ˆå¦‚ <strong>BM25</strong>ã€<strong>Contriever</strong>ã€<strong>OpenAI Embeddings</strong>ï¼‰ç”¨äºè¯­ä¹‰è®¿é—®å¤–éƒ¨è®°å¿†ã€‚</p></li>
<li><p><strong>é‡ç‚¹</strong>ï¼šè¿™äº›ç»„ä»¶æ˜¯æ„å»ºè®°å¿†èƒ½åŠ›çš„åŸºç¡€ï¼Œå¦‚è¯­ä¹‰ç›¸ä¼¼æ€§æœç´¢ã€é•¿æœŸä¸Šä¸‹æ–‡ç†è§£ç­‰ã€‚</p></li>
</ul>
</li>
<li><p><strong>æ¨¡å—åŒ–æ¡†æ¶</strong>ï¼ˆFrameworksï¼‰ï¼š</p>
<ul>
<li><p>æä¾›å¯é…ç½®çš„è®°å¿†æ“ä½œæ¥å£ï¼Œå¦‚ <strong>LlamaIndex</strong>ã€<strong>LangChain</strong>ã€<strong>Graphiti</strong>ã€<strong>Letta</strong> ç­‰ã€‚</p></li>
<li><p><strong>é‡ç‚¹</strong>ï¼šè¿™äº›æ¡†æ¶å°†å¤æ‚çš„è®°å¿†å¤„ç†æµç¨‹æ¨¡å—åŒ–ï¼Œæ”¯æŒå¼€å‘è€…æ„å»ºå¤šæ¨¡æ€ã€æŒä¹…åŒ–ã€å¯æ›´æ–°çš„è®°å¿†æ¨¡å—ã€‚</p></li>
</ul>
</li>
<li><p><strong>è®°å¿†å±‚ç³»ç»Ÿ</strong>ï¼ˆMemory Layer Systemsï¼‰ï¼š</p>
<ul>
<li><p>ä½œä¸ºâ€œè®°å¿†æœåŠ¡å±‚â€ï¼Œæä¾›è°ƒåº¦ã€æŒä¹…åŒ–å’Œç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼Œä¾‹å¦‚ <strong>Mem0</strong>ã€<strong>Zep</strong>ã€<strong>Memary</strong>ã€<strong>Memobase</strong>ã€‚</p></li>
<li><p><strong>é‡ç‚¹</strong>ï¼šè¿™ç±»ç³»ç»Ÿæ³¨é‡<strong>æ—¶é—´ä¸€è‡´æ€§</strong>ã€ä¼šè¯/è¯é¢˜ç´¢å¼•å’Œé«˜æ•ˆè®°å¿†æ£€ç´¢ï¼Œé€šå¸¸ç»“åˆç¬¦å·ä¸äºšç¬¦å·è®°å¿†è¡¨ç¤ºã€‚</p></li>
</ul>
</li>
</ul>
<p>æ›´å¤šè¯¦ç»†ä¿¡æ¯è§è¡¨ï¼šè¡¨ 17ï¼ˆç»„ä»¶ï¼‰ã€è¡¨ 18ï¼ˆæ¡†æ¶ï¼‰ã€è¡¨ 19ï¼ˆå†…å­˜å±‚ç³»ç»Ÿï¼‰å’Œè¡¨ 20ï¼ˆäº§å“ï¼‰ã€‚æ¯ä¸ªè¡¨éƒ½æè¿°äº†è¯¥å·¥å…·çš„é€‚ç”¨å†…å­˜ç±»å‹ã€æ”¯æŒçš„ä½œã€è¾“å…¥/è¾“å‡ºæ ¼å¼ã€æ ¸å¿ƒåŠŸèƒ½ã€ä½¿ç”¨åœºæ™¯å’Œæºç±»å‹ã€‚</p>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/08/rRTwxA.jpg" /></p>
<p>Table 17: Component-Level Tools for Memory Management and Utilization.</p>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/08/6Z5GNx.jpg" /></p>
<p>Table 18: Framework-Level Tools for Memory Management and Utilization.</p>
</section>
</section>
<hr class="docutils" />
<section id="id20">
<h2>æ€»ä½“æ€»ç»“ï¼š<a class="headerlink" href="#id20" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p>ç¬¬å››ç« ã€ŠMemory In Practiceã€‹ä»<strong>åº”ç”¨</strong>ã€<strong>äº§å“</strong>å’Œ<strong>å·¥å…·</strong>ä¸‰ä¸ªå±‚é¢ï¼Œç³»ç»Ÿæ€§åœ°å±•ç¤ºäº†è®°å¿†åœ¨AIç³»ç»Ÿä¸­çš„å®è·µè½åœ°ã€‚é‡ç‚¹åœ¨äºè¯´æ˜ï¼š</p>
<ul class="simple">
<li><p>è®°å¿†ä¸ä»…æ˜¯å­˜å‚¨ï¼Œæ›´æ˜¯<strong>æ¨ç†ã€è§„åˆ’ä¸é€‚åº”çš„å…³é”®ä½¿èƒ½è€…</strong>ï¼›</p></li>
<li><p>ä¸åŒç±»å‹çš„ç³»ç»Ÿï¼ˆçŸ¥è¯†å‹ã€ç”¨æˆ·å‹ã€ä»»åŠ¡å‹ã€å¤šæ¨¡æ€ï¼‰å¯¹è®°å¿†çš„éœ€æ±‚å„ä¸ç›¸åŒï¼›</p></li>
<li><p>å®é™…äº§å“ä¸­ï¼Œè®°å¿†ç³»ç»Ÿé€šè¿‡<strong>ç”¨æˆ·å»ºæ¨¡</strong>å’Œ<strong>ç»“æ„åŒ–ä»»åŠ¡ç®¡ç†</strong>æå‡ç”¨æˆ·ä½“éªŒï¼›</p></li>
<li><p>å¼€å‘å·¥å…·ä¸æ¡†æ¶çš„åˆ†å±‚ç”Ÿæ€ï¼Œæ”¯æŒäº†è®°å¿†åŠŸèƒ½çš„é«˜æ•ˆå®ç°ä¸æ‰©å±•ã€‚</p></li>
</ul>
<p>è¯¥ç« ä¸ºåç»­ç ”ç©¶å’Œç³»ç»Ÿæ„å»ºæä¾›äº†<strong>å®é™…å‚è€ƒ</strong>å’Œ<strong>åº”ç”¨æ–¹å‘</strong>ã€‚</p>
</section>
<section id="memory-in-humans-and-ai-systems">
<h2>5 Memory in Humans and AI Systems<a class="headerlink" href="#memory-in-humans-and-ai-systems" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p><img alt="" src="https://img.zhaoweiguo.com/uPic/2025/08/8V5w9L.jpg" /></p>
<p>Table 2: Key differences between human and agent memory across operational dimensions.</p>
<p>Figure 18:Prompt for evaluating article relevance to specific task definitions.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">System</span> <span class="n">Instruction</span><span class="p">:</span> <span class="n">Given</span> <span class="n">the</span> <span class="n">task</span> <span class="ow">and</span> <span class="n">the</span> <span class="n">abstract</span><span class="p">,</span> <span class="n">evaluate</span> <span class="n">the</span> <span class="n">relevance</span> <span class="n">of</span> <span class="n">the</span> <span class="n">abstract</span> <span class="n">to</span> <span class="n">the</span> <span class="n">task</span><span class="o">.</span>
<span class="n">Prompt</span> <span class="n">Template</span><span class="p">:</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">You are tasked with evaluating the relevance of a given article to a specific task definition.</span>
<span class="sd">Please read the following task definition, article title, and abstract carefully.</span>
<span class="sd">Based on the content, rate the relevance on a scale from 1 to 10,</span>
<span class="sd">where 1 means not relevant at all, and 10 means highly relevant.</span>
<span class="sd">Task Definition: {taskdef }</span>
<span class="sd">Article Title: {title}</span>
<span class="sd">Abstract: {abstract}</span>
<span class="sd">Please provide your rating in the format [[Rating]].</span>
<span class="sd">For example, if the relevance is high, you might respond with [[9]]. &quot;&quot;&quot;</span>
</pre></div>
</div>
<p>æœ¬èŠ‚æ¢è®¨äººç±»ä¸æ™ºèƒ½ä»£ç†ï¼ˆAIç³»ç»Ÿï¼‰ä¹‹é—´çš„è®°å¿†ç³»ç»Ÿï¼Œåˆ†æå…¶åŠŸèƒ½ç›¸ä¼¼æ€§ä¸ç»“æ„æ€§å·®å¼‚ã€‚è®°å¿†ç³»ç»Ÿçš„å…±åŒç›®æ ‡æ˜¯æ”¯æŒå­¦ä¹ ã€æ¨ç†ä¸å†³ç­–ï¼Œé€šè¿‡ç¼–ç å’Œæ£€ç´¢è¿‡å¾€ä¿¡æ¯å®ç°è¿™ä¸€ç›®æ ‡ã€‚å°½ç®¡äººç±»ä¸AIåˆ†åˆ«ä¾èµ–ç”Ÿç‰©ä½“å’Œå·¥ç¨‹æ¶æ„ï¼Œä½†å®ƒä»¬åœ¨åŠŸèƒ½ä¸Šå­˜åœ¨æ˜¾è‘—çš„ç›¸ä¼¼ä¹‹å¤„ã€‚</p>
<section id="id21">
<h3>åŠŸèƒ½ä¸Šçš„ç›¸ä¼¼æ€§<a class="headerlink" href="#id21" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ul class="simple">
<li><p><strong>å¤šæ—¶é—´å°ºåº¦æ“ä½œ</strong>ï¼šä¸¤è€…éƒ½å…·å¤‡çŸ­æœŸä¸é•¿æœŸè®°å¿†ç³»ç»Ÿã€‚äººç±»çš„è®°å¿†åˆ†ä¸ºå·¥ä½œè®°å¿†ã€æƒ…æ™¯è®°å¿†å’Œè¯­ä¹‰è®°å¿†ï¼›AIç³»ç»Ÿåˆ™é€šè¿‡çŸ­æœŸä¸Šä¸‹æ–‡çª—å£ä¸æŒä¹…çš„å¤–éƒ¨æˆ–å‚æ•°åŒ–å­˜å‚¨æ¨¡å—å®ç°ç±»ä¼¼åŠŸèƒ½ã€‚</p></li>
<li><p><strong>å…³è”ç»“æ„</strong>ï¼šä¸¤è€…éƒ½é‡‡ç”¨å…³è”æ€§ç»“æ„ä»¥æ”¯æŒä¿¡æ¯çš„æ£€ç´¢ä¸æ³›åŒ–ã€‚</p></li>
<li><p><strong>å¤šæ¨¡æ€è¾“å…¥æ•´åˆ</strong>ï¼šäººç±»å’ŒAIéƒ½èƒ½æ•´åˆè‡ªç„¶è¯­è¨€ã€è§†è§‰å’Œå¬è§‰ç­‰å¤šæ¨¡æ€è¾“å…¥ã€‚</p></li>
<li><p><strong>è®°å¿†ç³»ç»Ÿçš„ä¸å®Œç¾æ€§</strong>ï¼šä¸¤è€…éƒ½å­˜åœ¨å›å¿†é”™è¯¯æˆ–å¹²æ‰°ç°è±¡ã€‚</p></li>
</ul>
</section>
<section id="id22">
<h3>ç»“æ„ä¸æœºåˆ¶ä¸Šçš„å·®å¼‚<a class="headerlink" href="#id22" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>å°½ç®¡åŠŸèƒ½ç›¸ä¼¼ï¼Œäººç±»ä¸AIè®°å¿†åœ¨å®ç°æ–¹å¼ä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œè¿™äº›å·®å¼‚ä½“ç°åœ¨å­˜å‚¨ã€å·©å›ºã€ç´¢å¼•ã€æ£€ç´¢ã€æ›´æ–°ã€é—å¿˜ã€å‹ç¼©ç­‰æ“ä½œå±‚é¢ã€‚ä¸ºäº†ç³»ç»Ÿå‘ˆç°è¿™äº›å·®å¼‚ï¼Œæ–‡ä¸­é€šè¿‡<strong>è¡¨2</strong>ä»å¤šä¸ªç»´åº¦è¿›è¡Œå¯¹æ¯”ã€‚</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>å¯¹æ¯”ç»´åº¦</p></th>
<th class="head"><p>äººç±»è®°å¿†</p></th>
<th class="head"><p>ä»£ç†ï¼ˆAIï¼‰è®°å¿†</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>å­˜å‚¨</p></td>
<td><p>åˆ†å¸ƒå¼ã€äº’è¿çš„ç¥ç»ç³»ç»Ÿ</p></td>
<td><p>å‚æ•°åŒ–ã€æ¨¡å—åŒ–ã€ä¸Šä¸‹æ–‡ä¾èµ–</p></td>
</tr>
<tr class="row-odd"><td><p>å·©å›º</p></td>
<td><p>ç¼“æ…¢ã€ç”Ÿç‰©é©±åŠ¨ã€è¢«åŠ¨</p></td>
<td><p>å¿«é€Ÿã€æ˜¾å¼ã€ç­–ç•¥é©±åŠ¨ã€é€‰æ‹©æ€§</p></td>
</tr>
<tr class="row-even"><td><p>ç´¢å¼•</p></td>
<td><p>éšå¼ã€å…³è”ã€ç¨€ç–ç¼–ç </p></td>
<td><p>æ˜¾å¼ã€åŸºäºåµŒå…¥ã€ç¬¦å·æˆ–é”®å€¼æŸ¥æ‰¾</p></td>
</tr>
<tr class="row-odd"><td><p>æ›´æ–°</p></td>
<td><p>é—´æ¥ã€å†å·©å›ºã€æ˜“å‡ºé”™</p></td>
<td><p>ç²¾ç¡®ã€ç¼–ç¨‹åŒ–ã€æ”¯æŒå›æ»š/é—å¿˜</p></td>
</tr>
<tr class="row-even"><td><p>é—å¿˜</p></td>
<td><p>è¢«åŠ¨è¡°å‡æˆ–å¹²æ‰°</p></td>
<td><p>é€æ˜ã€å¯è¿½è¸ªã€ç­–ç•¥æ§åˆ¶</p></td>
</tr>
<tr class="row-odd"><td><p>æ£€ç´¢</p></td>
<td><p>å–å†³äºçº¿ç´¢/ä¸Šä¸‹æ–‡/æƒ…æ„Ÿï¼Œå…·æœ‰æƒ…æ„Ÿåå‘</p></td>
<td><p>åŸºäºå†…å®¹ã€å¯é‡å¤ã€ç›¸ä¼¼æ€§æˆ–æŸ¥è¯¢é©±åŠ¨</p></td>
</tr>
<tr class="row-even"><td><p>å‹ç¼©</p></td>
<td><p>éšå¼ã€åå‘æ˜¾è‘—æ€§å’Œé¢‘ç‡</p></td>
<td><p>æ˜¾å¼ã€å¯å®šåˆ¶ï¼ˆå¦‚é‡åŒ–ã€æ‘˜è¦ï¼‰</p></td>
</tr>
<tr class="row-odd"><td><p>æ‰€æœ‰</p></td>
<td><p>ä¸ªä½“åŒ–ã€ç§æœ‰</p></td>
<td><p>å¯å…±äº«ã€å¯å¤åˆ¶ã€å¯å¹¿æ’­</p></td>
</tr>
<tr class="row-even"><td><p>å®¹é‡</p></td>
<td><p>ç”Ÿç‰©é™åˆ¶</p></td>
<td><p>å¯æ‰©å±•ï¼Œä»…å—é™äºå­˜å‚¨ä¸è®¡ç®—èƒ½åŠ›</p></td>
</tr>
</tbody>
</table>
</section>
<section id="id23">
<h3>æ·±å±‚æ¬¡æŒ‘æˆ˜ä¸æœªæ¥æ–¹å‘<a class="headerlink" href="#id23" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>éšç€AIç³»ç»Ÿå˜å¾—æ„ˆå‘æŒä¹…ã€ä»£ç†å¯¼å‘å’Œè¡Œä¸ºå½±å“æ˜¾è‘—ï¼Œè®°å¿†ç³»ç»Ÿçš„è®¾è®¡é¢ä¸´æ›´å¤šæŒ‘æˆ˜ã€‚ä¾‹å¦‚ï¼š</p>
<ul class="simple">
<li><p><strong>è®°å¿†ç—•è¿¹é‡å¤ä½¿ç”¨å¸¦æ¥çš„è¡Œä¸ºåç§»</strong>ï¼šä»£ç†çš„å†…éƒ¨è®°å¿†é¢‘ç¹ä½¿ç”¨å¯èƒ½å¯¼è‡´è¡Œä¸ºè½¨è¿¹åå‘æŸä¸€æ–¹å‘ï¼Œå½¢æˆéšå¼çš„â€œèº«ä»½â€ã€‚</p></li>
<li><p><strong>ä¼˜åŒ–é©±åŠ¨çš„é—å¿˜ä¸å‹ç¼©é—®é¢˜</strong>ï¼šåœ¨äº¤äº’æˆ–å®‰å…¨å…³é”®åœºæ™¯ä¸­ï¼Œä½é¢‘ä½†æƒ…æ„Ÿæˆ–ç¤¾ä¼šæ˜¾è‘—çš„æ•°æ®å¯èƒ½è¢«é”™è¯¯åˆ é™¤ã€‚</p></li>
<li><p><strong>å†²çªè§£å†³æœºåˆ¶ç¼ºå¤±</strong>ï¼šå½“å‰ç³»ç»Ÿåœ¨å¤„ç†æ–°è¾“å…¥ä¸å·²æœ‰è®°å¿†å†²çªæ—¶ï¼Œä¾èµ–å¯å‘å¼æ–¹æ³•ï¼Œç¼ºä¹æ˜¾å¼ä»²è£æœºåˆ¶ã€‚</p></li>
<li><p><strong>é•¿æœŸè®°å¿†ç®¡ç†</strong>ï¼šéšç€ä»£ç†ä¸æ–­ç§¯ç´¯é•¿æœŸè®°å¿†ï¼Œè§£å†³è¿™äº›é—®é¢˜å¯¹äºç¡®ä¿AIç³»ç»Ÿçš„å¯¹é½æ€§ã€å¯è§£é‡Šæ€§å’Œé²æ£’æ€§å˜å¾—è‡³å…³é‡è¦ã€‚</p></li>
</ul>
<p><strong>æ€»ç»“</strong>ï¼šæœ¬ç« å¼ºè°ƒäº†äººç±»ä¸AIè®°å¿†ç³»ç»Ÿåœ¨åŠŸèƒ½ä¸Šçš„ç›¸ä¼¼æ€§ï¼ŒåŒæ—¶æ·±å…¥å‰–æå…¶ç»“æ„å·®å¼‚ï¼Œå¹¶æŒ‡å‡ºåœ¨AIç³»ç»Ÿå‘å±•è¿‡ç¨‹ä¸­ï¼Œè®¾è®¡æ›´å¯é ã€å¯æ§ä¸”ç¬¦åˆäººç±»ä»·å€¼è§‚çš„è®°å¿†æœºåˆ¶æ˜¯æœªæ¥ç ”ç©¶çš„é‡ç‚¹ã€‚</p>
</section>
</section>
<section id="open-challenges-and-future-directions">
<h2>6 Open Challenges and Future Directions<a class="headerlink" href="#open-challenges-and-future-directions" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p>æœ¬èŠ‚æ¦‚è¿°äº†æ ¸å¿ƒè®°å¿†ç›¸å…³ä¸»é¢˜ä¸­çš„å¼€æ”¾æ€§æŒ‘æˆ˜ï¼Œå¹¶æå‡ºäº†æœªæ¥çš„ç ”ç©¶æ–¹å‘ã€‚éšåï¼Œæˆ‘ä»¬æ¢è®¨äº†æ›´å¹¿æ³›çš„è§†è§’ï¼ŒåŒ…æ‹¬å—ç”Ÿç‰©å­¦å¯å‘çš„æ¨¡å‹ã€ç»ˆèº«å­¦ä¹ ã€å¤šæ™ºèƒ½ä½“è®°å¿†å’Œç»Ÿä¸€çš„è®°å¿†è¡¨ç¤ºæ–¹å¼ï¼Œè¿™äº›è¿›ä¸€æ­¥æ‹“å±•äº†è®°å¿†ç³»ç»Ÿçš„åŠŸèƒ½å’Œç†è®ºåŸºç¡€ã€‚è¿™äº›è®¨è®ºå…±åŒä¸ºæ¨è¿›å¯é ã€å¯è§£é‡Šä¸”é€‚åº”æ€§å¼ºçš„è®°å¿†ç³»ç»Ÿæä¾›äº†è·¯çº¿å›¾ã€‚</p>
<section id="id24">
<h3>6.1 ä¸“é¢˜æ–¹å‘<a class="headerlink" href="#id24" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>è®¾è®¡ä»¥è®°å¿†ä¸ºä¸­å¿ƒçš„AIç³»ç»Ÿéœ€è¦è§£å†³æ ¸å¿ƒé™åˆ¶å’Œæ–°å…´éœ€æ±‚ã€‚åœ¨RCIåˆ†æå’Œè¶‹åŠ¿çš„æŒ‡å¯¼ä¸‹ï¼Œæˆ‘ä»¬æ¦‚è¿°äº†æœªæ¥è®°å¿†ç ”ç©¶ä¸­çš„å…³é”®æŒ‘æˆ˜ã€‚</p>
<p><strong>ç»Ÿä¸€è¯„ä¼°çš„å¿…è¦æ€§</strong><br />
å½“å‰ç¼ºä¹å¯¹é•¿æœŸè®°å¿†ä¸­ä¸€è‡´æ€§ã€ä¸ªæ€§åŒ–å’Œæ—¶é—´æ¨ç†çš„ç»Ÿä¸€è¯„ä¼°ã€‚ç°æœ‰åŸºå‡†å¾ˆå°‘è¯„ä¼°åœ¨åŠ¨æ€ã€å¤šä¼šè¯è®¾ç½®ä¸­çš„è®°å¿†æ•´åˆã€æ›´æ–°ã€æ£€ç´¢å’Œé—å¿˜ç­‰æ ¸å¿ƒæ“ä½œã€‚è¿™ä¸€ç¼ºå£å¯¼è‡´äº†â€œæ£€ç´¢-ç”Ÿæˆä¸åŒ¹é…â€é—®é¢˜ï¼Œå³æ£€ç´¢åˆ°çš„å†…å®¹å¸¸å¸¸è¿‡æ—¶ã€æ— å…³æˆ–ä¸ä¸€è‡´ã€‚è§£å†³è¿™äº›é—®é¢˜éœ€è¦æ—¶é—´æ¨ç†èƒ½åŠ›ã€ç»“æ„æ„ŸçŸ¥ç”Ÿæˆä»¥åŠç¨³å¥çš„æ£€ç´¢ç³»ç»Ÿï¼ŒåŒæ—¶æ”¯æŒä¸ªæ€§åŒ–å¤ç”¨å’Œè·¨ä¼šè¯çš„è‡ªé€‚åº”è®°å¿†ç®¡ç†ã€‚</p>
<p><strong>é•¿ä¸Šä¸‹æ–‡å¤„ç†ï¼šæ•ˆç‡ä¸è¡¨è¾¾æ€§çš„å¹³è¡¡</strong><br />
æ‰©å±•è®°å¿†é•¿åº¦åŠ å‰§äº†è®¡ç®—æˆæœ¬ä¸å»ºæ¨¡ä¿çœŸåº¦ä¹‹é—´çš„æƒè¡¡ã€‚KVç¼“å­˜å‹ç¼©å’Œé‡å¤åˆ©ç”¨ç­‰æŠ€æœ¯å¯ä»¥æé«˜æ•ˆç‡ï¼Œä½†å¯èƒ½å¸¦æ¥ä¿¡æ¯ä¸¢å¤±æˆ–ä¸ç¨³å®šçš„é£é™©ã€‚å¦ä¸€æ–¹é¢ï¼Œå¤æ‚ç¯å¢ƒä¸­çš„æ¨ç†ï¼ˆå°¤å…¶æ˜¯åœ¨å¤šæºæˆ–å¤šæ¨¡æ€è®¾ç½®ä¸­ï¼‰éœ€è¦é€‰æ‹©æ€§ä¸Šä¸‹æ–‡æ•´åˆã€æºåŒºåˆ†å’Œæ³¨æ„åŠ›è°ƒæ§ã€‚æœªæ¥éœ€è¦æœºåˆ¶æ¥å¹³è¡¡ä¸Šä¸‹æ–‡å¸¦å®½ä¸ä»»åŠ¡ç›¸å…³æ€§åŠç¨³å®šæ€§ä¹‹é—´çš„å…³ç³»ã€‚</p>
<p><strong>å‚æ•°åŒ–è®°å¿†ä¿®æ”¹çš„ç ”ç©¶</strong><br />
å°½ç®¡å‚æ•°åŒ–è®°å¿†ä¿®æ”¹å‰æ™¯å¹¿é˜”ï¼Œä½†ä»éœ€è¿›ä¸€æ­¥ç ”ç©¶æå‡å…¶æ§åˆ¶æ€§ã€åˆ é™¤èƒ½åŠ›å’Œå¯æ‰©å±•æ€§ã€‚å½“å‰çš„ç¼–è¾‘æ–¹æ³•ç¼ºä¹ç‰¹å¼‚æ€§ï¼Œè€ŒåƒTOFUè¿™æ ·çš„â€œé—å¿˜â€åŸºå‡†è¿‡äºç®€å•ï¼Œéš¾ä»¥æ­ç¤ºçœŸå®é™åˆ¶ã€‚å¤§å¤šæ•°æ–¹æ³•éš¾ä»¥æ‰©å±•åˆ°æ•°åƒæ¬¡ä»¥ä¸Šçš„ç¼–è¾‘ï¼Œä¸”ä¸æ”¯æŒè¶…è¿‡20Bå‚æ•°çš„æ¨¡å‹ã€‚æ­¤å¤–ï¼Œç»ˆèº«å­¦ä¹ ç ”ç©¶ä»ä¸å……åˆ†ã€‚æœªæ¥çš„å·¥ä½œåº”å¼€å‘æ›´ç°å®çš„åŸºå‡†ï¼Œæé«˜æ•ˆç‡ï¼Œå¹¶å°†ç¼–è¾‘ã€é—å¿˜å’ŒæŒç»­å­¦ä¹ ç»Ÿä¸€åˆ°ä¸€ä¸ªæ¡†æ¶ä¸­ã€‚</p>
<p><strong>å¤šæºæ•´åˆï¼šä¸€è‡´æ€§ã€å‹ç¼©ä¸åè°ƒ</strong><br />
ç°ä»£æ™ºèƒ½ä½“ä¾èµ–å¼‚æ„è®°å¿†ï¼ˆç»“æ„åŒ–çŸ¥è¯†ã€éç»“æ„åŒ–å†å²å’Œå¤šæ¨¡æ€ä¿¡å·ï¼‰ï¼Œä½†é¢ä¸´å†—ä½™ã€ä¸ä¸€è‡´å’Œæ¥æºæ¨¡ç³Šçš„é—®é¢˜ã€‚è¿™äº›é—®é¢˜æºäºæ—¶é—´èŒƒå›´ä¸ä¸€è‡´ã€è¯­ä¹‰å†²çªå’Œå½’å±ç¼ºå¤±ï¼Œå°¤å…¶åœ¨è·¨æ¨¡æ€æ—¶æ›´ä¸ºä¸¥é‡ã€‚è§£å†³è¿™äº›é—®é¢˜éœ€è¦å†²çªè§£å†³ã€æ—¶é—´å®šä½å’Œæ¥æºè¿½è¸ªã€‚åœ¨å¤šä¼šè¯è®¾ç½®ä¸­ï¼Œé«˜æ•ˆçš„ç´¢å¼•å’Œå‹ç¼©å¯¹äºå¯æ‰©å±•æ€§å’Œå¯è§£é‡Šæ€§ä¹Ÿè‡³å…³é‡è¦ã€‚</p>
</section>
<section id="id25">
<h3>6.2 æ›´å¹¿æ³›çš„è§†è§’<a class="headerlink" href="#id25" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>é™¤äº†ä¸Šè¿°æ ¸å¿ƒä¸»é¢˜å¤–ï¼Œä¸€äº›æ›´å¹¿æ³›çš„è§†è§’æ­£åœ¨å…´èµ·ï¼Œè¿›ä¸€æ­¥ä¸°å¯Œäº†ä»¥è®°å¿†ä¸ºä¸­å¿ƒçš„AIç ”ç©¶é¢†åŸŸã€‚</p>
<p><strong>æ—¶ç©ºè®°å¿†</strong><br />
æ—¶ç©ºè®°å¿†ä¸ä»…æ•æ‰ä¿¡æ¯ä¹‹é—´çš„ç»“æ„å…³ç³»ï¼Œè¿˜æ•æ‰å…¶æ—¶é—´æ¼”åŒ–ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿé€‚åº”æ€§åœ°æ›´æ–°çŸ¥è¯†ï¼ŒåŒæ—¶ä¿ç•™å†å²ä¸Šä¸‹æ–‡ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªAIç³»ç»Ÿå¯ä»¥è®°å½•ç”¨æˆ·æ›¾ä¸å–œæ¬¢è¥¿å…°èŠ±ï¼Œä½†åŸºäºæœ€è¿‘çš„è´­ä¹°è¡Œä¸ºè°ƒæ•´è®°å¿†ã€‚é€šè¿‡ç»´æŠ¤å¯¹å†å²å’Œå½“å‰çŠ¶æ€çš„è®¿é—®ï¼Œæ—¶ç©ºè®°å¿†æ”¯æŒåŸºäºæ—¶é—´çš„æ¨ç†å’Œç»†è‡´çš„ä¸ªæ€§åŒ–ã€‚ç„¶è€Œï¼Œå¦‚ä½•é«˜æ•ˆåœ°ç®¡ç†å¹¶æ¨ç†é•¿æœŸæ—¶ç©ºè®°å¿†ä»ç„¶æ˜¯å…³é”®æŒ‘æˆ˜ã€‚</p>
<p><strong>å‚æ•°çŸ¥è¯†çš„æ£€ç´¢</strong><br />
å°½ç®¡æœ€è¿‘çš„ç ”ç©¶å£°ç§°å¯ä»¥å®šä½å¹¶ä¿®æ”¹ç‰¹å®šè¡¨ç¤ºï¼Œä½†å¦‚ä½•ä½¿æ¨¡å‹ä»è‡ªèº«å‚æ•°ä¸­é€‰æ‹©æ€§åœ°æ£€ç´¢çŸ¥è¯†ä»æ˜¯ä¸€ä¸ªå¼€æ”¾é—®é¢˜ã€‚å¦‚æœèƒ½é«˜æ•ˆåœ°æ£€ç´¢å’Œæ•´åˆæ½œåœ¨çŸ¥è¯†ï¼Œå°†æ˜¾è‘—æé«˜è®°å¿†åˆ©ç”¨ç‡ï¼Œå¹¶å‡å°‘å¯¹å¤–éƒ¨ç´¢å¼•å’Œè®°å¿†ç®¡ç†çš„ä¾èµ–ã€‚</p>
<p><strong>ç»ˆèº«å­¦ä¹ </strong><br />
æ™ºèƒ½ä½“éœ€è¦æŒç»­é›†æˆæ–°ä¿¡æ¯ï¼ŒåŒæ—¶ä¿ç•™æ—§çŸ¥è¯†ï¼Œå› æ­¤éœ€è¦å…·æœ‰ç¨³å®šæ€§å’Œå¯å¡‘æ€§çš„è®°å¿†ç³»ç»Ÿã€‚å‚æ•°è®°å¿†èƒ½ä½¿æ¨¡å‹åœ¨æƒé‡ä¸­è¿›è¡ŒçŸ¥è¯†é€‚åº”ï¼Œä½†å®¹æ˜“é—å¿˜ï¼›ç»“æ„åŒ–è®°å¿†ï¼ˆå¦‚çŸ¥è¯†å›¾è°±ã€è¡¨æ ¼ï¼‰æ”¯æŒæ¨¡å—åŒ–å’Œæœ‰é’ˆå¯¹æ€§çš„æ›´æ–°ã€‚è€Œéç»“æ„åŒ–è®°å¿†ï¼ˆå¦‚å‘é‡å­˜å‚¨ã€åŸå§‹å¯¹è¯å†å²ï¼‰æä¾›çµæ´»æ£€ç´¢ï¼Œä½†éœ€è¦åŠ¨æ€å‹ç¼©å’Œç›¸å…³æ€§è¿‡æ»¤ã€‚åœ¨æŒç»­å­¦ä¹ æ¡†æ¶ä¸‹æ•´åˆè¿™äº›è®°å¿†ç±»å‹ï¼Œå¹¶é‡‡ç”¨å·©å›ºã€é€‰æ‹©æ€§é—å¿˜å’Œäº¤é”™è®­ç»ƒç­‰æœºåˆ¶ï¼Œæ˜¯æ„å»ºå…·å¤‡é•¿æœŸè®°å¿†ç®¡ç†èƒ½åŠ›çš„è‡ªé€‚åº”ã€ä¸ªæ€§åŒ–ç»ˆèº«æ™ºèƒ½ä½“çš„å…³é”®ã€‚</p>
<p><strong>å—ç”Ÿç‰©å­¦å¯å‘çš„è®°å¿†è®¾è®¡</strong><br />
ç”Ÿç‰©ç³»ç»Ÿä¸­çš„è®°å¿†æœºåˆ¶ä¸ºæ„å»ºæ›´å…·å¼¹æ€§å’Œé€‚åº”æ€§çš„AIè®°å¿†æ¶æ„æä¾›äº†é‡è¦å¯ç¤ºã€‚å¤§è„‘é€šè¿‡äº’è¡¥å­¦ä¹ ç³»ç»Ÿï¼ˆæµ·é©¬ä½“è´Ÿè´£å¿«é€Ÿå˜åŒ–çš„äº‹ä»¶è®°å¿†ï¼Œçš®å±‚è´Ÿè´£æ…¢é€Ÿæ•´åˆçš„é•¿æœŸè®°å¿†ï¼‰æ¥åº”å¯¹ç¨³å®šæ€§å’Œå¯å¡‘æ€§ä¹‹é—´çš„çŸ›ç›¾ã€‚å—æ­¤å¯å‘ï¼ŒAIæ¨¡å‹è¶Šæ¥è¶Šå¤šåœ°é‡‡ç”¨åŒè®°å¿†æ¶æ„ã€çªè§¦å·©å›ºå’Œç»éªŒå›æ”¾æœºåˆ¶æ¥å‡å°‘é—å¿˜ã€‚è®¤çŸ¥æ¦‚å¿µå¦‚è®°å¿†å†å·©å›ºã€è®°å¿†å®¹é‡é™åˆ¶å’Œæ¨¡å—åŒ–çŸ¥è¯†ä¹Ÿä¸ºæ›´æ–°æ„ŸçŸ¥çš„å›å¿†ã€é«˜æ•ˆå­˜å‚¨å’Œä¸Šä¸‹æ–‡æ•æ„Ÿæ³›åŒ–æä¾›äº†ç­–ç•¥å‚è€ƒã€‚</p>
<p><strong>K-Lineç†è®ºä¸å±‚çº§è®°å¿†</strong><br />
Minskyæå‡ºçš„K-Lineç†è®ºæŒ‡å‡ºï¼Œå±‚çº§è®°å¿†ç»“æ„æ˜¯ç”Ÿç‰©è®¤çŸ¥çš„åŸºç¡€ï¼Œä½¿äººç±»èƒ½å¤Ÿé«˜æ•ˆåœ°åœ¨ä¸åŒæŠ½è±¡å±‚æ¬¡ä¸Šç»„ç»‡è®°å¿†ã€‚ä¾‹å¦‚ï¼Œå©´å„¿ä¼šå°†â€œè‹¹æœâ€å’Œâ€œé¦™è•‰â€å½’ç±»ä¸ºâ€œæ°´æœâ€æˆ–â€œé£Ÿç‰©â€ç­‰æ›´é«˜å±‚æ¬¡çš„ç±»åˆ«ã€‚åœ¨AIä¸­ï¼Œé‡‡ç”¨å±‚çº§ç»“æ„æ¥ç»„ç»‡è®°å¿†é¢ä¸´æ–°çš„æŒ‘æˆ˜ï¼Œéœ€è¦æ›´é«˜æ•ˆå’Œå¯æ‰©å±•çš„è®°å¿†ç®¡ç†æ–¹æ³•ã€‚</p>
<p><strong>ç»Ÿä¸€çš„è®°å¿†è¡¨ç¤º</strong><br />
å‚æ•°åŒ–è®°å¿†æä¾›ç´§å‡‘éšå¼çš„çŸ¥è¯†å­˜å‚¨ï¼Œè€Œå¤–éƒ¨è®°å¿†æä¾›æ˜¾å¼å¯è§£é‡Šçš„ä¿¡æ¯ã€‚ç»Ÿä¸€å®ƒä»¬çš„è¡¨ç¤ºç©ºé—´å¹¶å»ºç«‹è”åˆç´¢å¼•æœºåˆ¶ï¼Œå¯¹äºæœ‰æ•ˆçš„è®°å¿†æ•´åˆå’Œæ£€ç´¢è‡³å…³é‡è¦ã€‚æœªæ¥çš„ç ”ç©¶å¯èšç„¦äºå¼€å‘ç»Ÿä¸€çš„è®°å¿†è¡¨ç¤ºæ¡†æ¶ï¼Œæ”¯æŒè·¨æ¨¡æ€å’ŒçŸ¥è¯†å½¢å¼çš„å…±äº«ç´¢å¼•ã€æ··åˆå­˜å‚¨å’Œè®°å¿†æ“ä½œã€‚</p>
<p><strong>å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„è®°å¿†</strong><br />
åœ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­ï¼Œè®°å¿†ä¸ä»…æ˜¯ä¸ªäººçš„ï¼Œä¹Ÿæ˜¯åˆ†å¸ƒå¼çš„ã€‚æ™ºèƒ½ä½“éœ€è¦ç®¡ç†è‡ªèº«è®°å¿†ï¼ŒåŒæ—¶ä¸å…¶ä»–æ™ºèƒ½ä½“äº’åŠ¨å­¦ä¹ ã€‚è¿™å¸¦æ¥äº†ä¸€äº›ç‹¬ç‰¹æŒ‘æˆ˜ï¼Œå¦‚è®°å¿†å…±äº«ã€å¯¹é½ã€å†²çªè§£å†³å’Œä¸€è‡´æ€§ã€‚æœ‰æ•ˆçš„å¤šæ™ºèƒ½ä½“è®°å¿†ç³»ç»Ÿåº”æ”¯æŒä¸ªæ€§åŒ–ç»éªŒçš„æœ¬åœ°ä¿ç•™å’Œé€šè¿‡å…±äº«è®°å¿†ç©ºé—´æˆ–é€šä¿¡åè®®çš„å…¨å±€åè°ƒã€‚æœªæ¥çš„ç ”ç©¶æ–¹å‘å¯èƒ½åŒ…æ‹¬å»ä¸­å¿ƒåŒ–è®°å¿†æ¶æ„ã€è·¨æ™ºèƒ½ä½“è®°å¿†åŒæ­¥å’Œé›†ä½“è®°å¿†æ•´åˆï¼Œä»¥æ”¯æŒåä½œè§„åˆ’ã€æ¨ç†å’Œé•¿æœŸåè°ƒã€‚</p>
<p><strong>è®°å¿†å¨èƒä¸å®‰å…¨æ€§</strong><br />
å°½ç®¡è®°å¿†æ˜¾è‘—å¢å¼ºäº†å¤§è¯­è¨€æ¨¡å‹çš„å®ç”¨æ€§å’Œä¸ªæ€§åŒ–èƒ½åŠ›ï¼Œä½†å…¶ç®¡ç†ä»æ˜¯ä¸€ä¸ªå…³é”®çš„å®‰å…¨é—®é¢˜ã€‚è®°å¿†é€šå¸¸å­˜å‚¨æ•æ„Ÿå’Œæœºå¯†æ•°æ®ï¼Œä½¿å¾—æ·»åŠ æˆ–åˆ é™¤ä¿¡æ¯ç»éæ˜“äº‹ã€‚è¿‘æœŸç ”ç©¶æ­ç¤ºäº†è®°å¿†å¤„ç†ä¸­çš„ä¸¥é‡æ¼æ´ï¼Œå°¤å…¶æ˜¯åœ¨æ—¨åœ¨é€‰æ‹©æ€§åˆ é™¤æ•°æ®çš„â€œæœºå™¨é—å¿˜â€æŠ€æœ¯ä¸­ã€‚å¤šé¡¹ç ”ç©¶å·²è¯æ˜è¿™äº›æ–¹æ³•å®¹æ˜“å—åˆ°æ¶æ„æ”»å‡»ï¼Œå› æ­¤ï¼Œæ›´å®‰å…¨å’Œå¯é çš„è®°å¿†æ“ä½œæœºåˆ¶å˜å¾—å°¤ä¸ºé‡è¦ã€‚</p>
</section>
</section>
<section id="appendix-a-gpt-based-pipeline-selection">
<h2>Appendix A GPT-based Pipeline Selection<a class="headerlink" href="#appendix-a-gpt-based-pipeline-selection" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p>ä¸ºäº†åœ¨å¤§è§„æ¨¡ä¸Šè¿›è¡Œä¸æœ¬ç ”ç©¶åˆ†ç±»æ³•ç›¸ä¸€è‡´çš„ç›¸å…³æ€§è¿‡æ»¤ï¼Œä½œè€…è®¾è®¡äº†ä¸€æ¡åŸºäºGPTçš„è¯„åˆ†æµæ°´çº¿ã€‚å…¶ç›®çš„æ˜¯è¯„ä¼°è®ºæ–‡æ‘˜è¦ä¸é¢„å®šä¹‰ä»»åŠ¡å®šä¹‰ä¹‹é—´çš„åŒ¹é…ç¨‹åº¦ï¼ˆå¯å‚è€ƒè¡¨3ï¼‰ã€‚æ¯ç¯‡æ‘˜è¦éƒ½ä¼šä¸å…¶å¯¹åº”çš„ä»»åŠ¡å®šä¹‰é…å¯¹ï¼Œå¹¶ç”±æ¨¡å‹åœ¨1åˆ°10çš„è¯„åˆ†å°ºåº¦ä¸Šè¿›è¡Œè¯„åˆ†ï¼Œè¯„åˆ†â‰¥8çš„è®ºæ–‡è¢«è§†ä¸ºé«˜åº¦ç›¸å…³ï¼Œä»è€Œè¢«ä¿ç•™ä¸‹æ¥ä»¥è¿›è¡Œè¿›ä¸€æ­¥åˆ†æã€‚</p>
<p>åœ¨é€‰æ‹©è¯„åˆ†æ¨¡å‹æ—¶ï¼Œä½œè€…é‡‡ç”¨äº†GPT-4o-miniã€‚è¿™æ˜¯ç”±äºè¯¥æ¨¡å‹åœ¨æ€§èƒ½å’Œæ•ˆç‡ä¹‹é—´å–å¾—äº†è‰¯å¥½çš„å¹³è¡¡ã€‚å°½ç®¡GPT-4o-miniçš„æ¶æ„è¾ƒä¸ºè½»é‡ï¼Œä½†å®ƒè¡¨ç°å‡ºè‰²çš„é›¶æ ·æœ¬æ¨ç†èƒ½åŠ›ï¼Œä½¿å…¶åœ¨è¶…è¿‡3ä¸‡ç¯‡è®ºæ–‡çš„æ‘˜è¦å±‚é¢çš„ä¸»é¢˜ç›¸å…³æ€§ä¼°è®¡ä¸­æ—¢ç»æµåˆå‡†ç¡®ã€‚</p>
<p>æœ€åï¼Œç”¨äºè¯¥è¯„ä¼°è¿‡ç¨‹çš„å…·ä½“æç¤ºæ ¼å¼å¦‚å›¾18æ‰€ç¤ºã€‚</p>
<p>Table 3: Definitions and features of the five memory-centric evaluation topics.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Topic Name</p></th>
<th class="head"><p>Definition in Prompt</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Long-Term Memory</p></td>
<td><p><strong>Definition</strong>: Creating systems that ensure knowledge from past interactions remains accessible as new tasks emerge, maintaining continuity in multi-turn conversations. <br/><strong>Features</strong>: Memory retention, retrieval, and attributionâ€”preserving, accessing, and contextualizing memory to support coherent interaction.</p></td>
</tr>
<tr class="row-odd"><td><p>Long-Context</p></td>
<td><p><strong>Definition</strong>: Efficiently processing, interpreting, and utilizing very long input sequences without performance degradation. <br/><strong>Features</strong>: Optimized attention, context compression, and mitigation of the â€œlost-in-the-middleâ€ problem.</p></td>
</tr>
<tr class="row-even"><td><p>Parametric Memory Modification</p></td>
<td><p><strong>Definition</strong>: Managing and updating internal parameters to preserve accuracy, privacy, and adaptability without full retraining. <br/><strong>Features</strong>: Selective unlearning, precise model editing, distillation, and lifelong learning.</p></td>
</tr>
<tr class="row-odd"><td><p>Multi-Source</p></td>
<td><p>Definition: Integrating and harmonizing diverse data types into a unified framework while resolving inconsistencies. <br/><strong>Features</strong>: Multi-modal fusion, semantic consistency, conflict resolution, and redundancy removal.</p></td>
</tr>
<tr class="row-even"><td><p>Personalization*</p></td>
<td><p><strong>Definition</strong>: Building user-centric memory systems that adapt to individual preferences and history while preserving privacy. <br/><strong>Features</strong>: Privacy-aware profiling, consistent personalization, and long-term continuity.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>ä¸»é¢˜</p></th>
<th class="head"><p>å®šä¹‰ä¸ç‰¹å¾</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>é•¿æœŸè®°å¿†</strong></p></td>
<td><p>ç¡®ä¿è¿‡å»äº¤äº’çš„çŸ¥è¯†åœ¨æ–°ä»»åŠ¡ä¸­ä»å¯è®¿é—®ï¼Œæ”¯æŒè¿ç»­å¯¹è¯ã€‚ç‰¹å¾åŒ…æ‹¬è®°å¿†å­˜å‚¨ã€æ£€ç´¢å’Œå½’å› ã€‚</p></td>
</tr>
<tr class="row-odd"><td><p><strong>é•¿ä¸Šä¸‹æ–‡</strong></p></td>
<td><p>é«˜æ•ˆå¤„ç†é•¿è¾“å…¥åºåˆ—ï¼Œé˜²æ­¢æ€§èƒ½ä¸‹é™ã€‚ç‰¹å¾åŒ…æ‹¬ä¼˜åŒ–æ³¨æ„åŠ›ã€ä¸Šä¸‹æ–‡å‹ç¼©å’Œâ€œä¸­é—´ä¸¢å¤±â€é—®é¢˜ç¼“è§£ã€‚</p></td>
</tr>
<tr class="row-even"><td><p><strong>å‚æ•°ä¿®æ”¹</strong></p></td>
<td><p>é€šè¿‡æ›´æ–°æ¨¡å‹å†…éƒ¨å‚æ•°æ¥ä¿ç•™å‡†ç¡®æ€§ã€éšç§å’Œé€‚åº”æ€§ï¼Œæ— éœ€å®Œå…¨é‡è®­ç»ƒã€‚ç‰¹å¾åŒ…æ‹¬é€‰æ‹©æ€§é—å¿˜ã€ç²¾ç¡®ç¼–è¾‘ã€çŸ¥è¯†è’¸é¦ç­‰ã€‚</p></td>
</tr>
<tr class="row-odd"><td><p><strong>å¤šæºè®°å¿†</strong></p></td>
<td><p>æ•´åˆå¤šç§æ•°æ®ç±»å‹ï¼Œè§£å†³ä¸ä¸€è‡´é—®é¢˜ã€‚ç‰¹å¾åŒ…æ‹¬å¤šæ¨¡æ€èåˆã€è¯­ä¹‰ä¸€è‡´æ€§ã€å†²çªè§£å†³ç­‰ã€‚</p></td>
</tr>
<tr class="row-even"><td><p><strong>ä¸ªæ€§åŒ–</strong></p></td>
<td><p>æ„å»ºä»¥ç”¨æˆ·ä¸ºä¸­å¿ƒçš„è®°å¿†ç³»ç»Ÿï¼Œé€‚åº”ç”¨æˆ·åå¥½å’Œå†å²ï¼ŒåŒæ—¶ä¿éšœéšç§ã€‚ç‰¹å¾åŒ…æ‹¬éšç§æ•æ„Ÿçš„ç”¨æˆ·ç”»åƒå’Œé•¿æœŸä¸€è‡´æ€§ã€‚</p></td>
</tr>
</tbody>
</table>
</section>
<section id="appendix-b-relative-citation-index">
<h2>Appendix B Relative Citation Index<a class="headerlink" href="#appendix-b-relative-citation-index" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p>åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬é‡‡ç”¨ **ç›¸å¯¹å¼•ç”¨æŒ‡æ•°ï¼ˆRelative Citation Index, RCIï¼‰**æ¥è¯†åˆ«å…·æœ‰å½±å“åŠ›çš„è®ºæ–‡ã€‚è¯¥æŒ‡æ ‡çš„çµæ„Ÿæ¥æºäºRCRï¼ˆRelative Citation Ratioï¼‰ï¼Œæ—¨åœ¨é€šè¿‡è€ƒè™‘è®ºæ–‡çš„å‘è¡¨å¹´é™æ¥ä¼°è®¡å…¶é¢„æœŸå¼•ç”¨æ¬¡æ•°ï¼Œä»è€Œé¿å…å› å‘è¡¨æ—¶é—´ä¸åŒè€Œå¯¼è‡´çš„åŸå§‹å¼•ç”¨æ¬¡æ•°åå·®ã€‚</p>
<hr class="docutils" />
<section id="id26">
<h3>ä¸€ã€è®ºæ–‡çš„â€œå¹´é¾„â€å®šä¹‰<a class="headerlink" href="#id26" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>è®ºæ–‡çš„â€œå¹´é¾„â€ <span class="math notranslate nohighlight">\(A_i\)</span> å®šä¹‰ä¸ºï¼š</p>
<div class="math notranslate nohighlight">
\[
A_i = T - \text{Year}_i \quad \text{(å…¬å¼ 7)}
\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(T\)</span> æ˜¯å¼•ç”¨æ•°æ®æ”¶é›†çš„æ—¥æœŸï¼ˆæœ¬ç ”ç©¶ä¸­ä¸º 2025 å¹´ 4 æœˆ 20 æ—¥ï¼‰ï¼›</p></li>
<li><p><span class="math notranslate nohighlight">\(\text{Year}_i\)</span> æ˜¯è®ºæ–‡ <span class="math notranslate nohighlight">\(i\)</span> çš„é¦–æ¬¡å‘è¡¨å¹´ä»½ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="id27">
<h3>äºŒã€æ„å»ºå¼•ç”¨â€“å¹´é¾„å…³ç³»æ¨¡å‹<a class="headerlink" href="#id27" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>ä¸ºäº†å»ºæ¨¡å¼•ç”¨æ¬¡æ•° <span class="math notranslate nohighlight">\(C_i\)</span> ä¸è®ºæ–‡â€œå¹´é¾„â€ <span class="math notranslate nohighlight">\(A_i\)</span> ä¹‹é—´çš„å…³ç³»ï¼Œç ”ç©¶å°è¯•äº†ä¸‰ç§æ¨¡å‹ï¼š</p>
<ol class="arabic simple">
<li><p><strong>çº¿æ€§æ¨¡å‹</strong>ï¼ˆLinearï¼‰ï¼š
$<span class="math notranslate nohighlight">\(
C_i = \beta + \alpha A_i \quad \text{(å…¬å¼ 8)}
\)</span>$</p></li>
<li><p><strong>æŒ‡æ•°æ¨¡å‹</strong>ï¼ˆExponentialï¼‰ï¼š
$<span class="math notranslate nohighlight">\(
C_i = \exp(\beta + \alpha A_i) \quad \text{(å…¬å¼ 9)}
\)</span>$</p></li>
<li><p><strong>å¯¹æ•°â€“å¯¹æ•°å›å½’æ¨¡å‹</strong>ï¼ˆLog-Logï¼‰ï¼š
$<span class="math notranslate nohighlight">\(
\log(C_i + 1) = \beta + \alpha \log A_i + \epsilon_i \quad \text{(å…¬å¼ 10)}
\)</span>$</p></li>
</ol>
<p>å…¶ä¸­ï¼Œ<span class="math notranslate nohighlight">\(\beta\)</span> å’Œ <span class="math notranslate nohighlight">\(\alpha\)</span> ä¸ºæ¨¡å‹å‚æ•°ï¼Œ<span class="math notranslate nohighlight">\(\epsilon_i\)</span> ä¸ºè¯¯å·®é¡¹ã€‚</p>
</section>
<hr class="docutils" />
<section id="id28">
<h3>ä¸‰ã€æ•°æ®æ”¶é›†ä¸é¢„å¤„ç†<a class="headerlink" href="#id28" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>ç ”ç©¶æ”¶é›†äº† 2022 è‡³ 2025 å¹´é—´é¡¶çº§ NLP å’Œ ML ä¼šè®®ï¼ˆACLã€NAACLã€EMNLPã€NeurIPSã€ICMLã€ICLRï¼‰çš„è®ºæ–‡æ•°æ®ï¼Œå…±è®¡ 3,932 ç¯‡æœ‰æ•ˆè®ºæ–‡ã€‚ä¸ºäº†å‡å°‘ä¸åŒç ”ç©¶é¢†åŸŸçš„åå·®ï¼Œä½¿ç”¨ GPT è¯„ä¼°è®ºæ–‡ä¸æœ¬ç ”ç©¶ä¸­å››ä¸ªæŒ‘æˆ˜çš„å…³è”æ€§ï¼Œä»…ä¿ç•™è¯„åˆ† <strong>8 åˆ†åŠä»¥ä¸Š</strong> çš„è®ºæ–‡ã€‚</p>
<p>è®ºæ–‡çš„å‘è¡¨æ—¥æœŸä¿¡æ¯æ¥è‡ª Semantic Scholar APIï¼Œè‹¥ç¼ºå¤±åˆ™ä½¿ç”¨ä¼šè®®ç¬¬ä¸€å¤©ä½œä¸ºå‘è¡¨æ—¥æœŸã€‚</p>
</section>
<hr class="docutils" />
<section id="id29">
<h3>å››ã€æ¨¡å‹é€‰æ‹©ä¸ç»“æœ<a class="headerlink" href="#id29" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>é€šè¿‡æ‹Ÿåˆæ‰€æœ‰è®ºæ–‡çš„å¼•ç”¨æ¬¡æ•°ä¸â€œå¹´é¾„â€å…³ç³»ï¼Œå‘ç° <strong>å¯¹æ•°â€“å¯¹æ•°å›å½’æ¨¡å‹</strong>ï¼ˆLog-Logï¼‰è¡¨ç°æœ€ä¼˜ï¼š</p>
<ul class="simple">
<li><p>æ‹Ÿåˆæ•ˆæœæœ€ä½³ï¼Œå‡ ä¹å®Œç¾åœ°åæ˜ äº†å¼•ç”¨ä¸­ä½æ•°éšæ—¶é—´çš„å˜åŒ–ï¼›</p></li>
<li><p>è¯¥æ¨¡å‹ä¿è¯è®ºæ–‡åˆšå‘è¡¨æ—¶é¢„æœŸå¼•ç”¨ä¸º 0ï¼Œç¬¦åˆç›´è§‰ã€‚</p></li>
</ul>
<p>æœ€ç»ˆä¼°è®¡çš„æ¨¡å‹å‚æ•°ä¸ºï¼š</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\hat{\beta} = 1.878\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{\alpha} = 1.297\)</span></p></li>
</ul>
<p>ç”±æ­¤å¯è®¡ç®—ä»»æ„è®ºæ–‡ <span class="math notranslate nohighlight">\(i\)</span> çš„<strong>é¢„æœŸå¼•ç”¨æ¬¡æ•°</strong>ï¼ˆå…¬å¼ 11ï¼‰ï¼š</p>
<div class="math notranslate nohighlight">
\[
\hat{C_i} = \exp(\hat{\beta}) A_i^{\hat{\alpha}} \quad \text{(å…¬å¼ 11)}
\]</div>
</section>
<hr class="docutils" />
<section id="rci">
<h3>äº”ã€ç›¸å¯¹å¼•ç”¨æŒ‡æ•°ï¼ˆRCIï¼‰çš„è®¡ç®—<a class="headerlink" href="#rci" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>ç›¸å¯¹å¼•ç”¨æŒ‡æ•°ï¼ˆRCIï¼‰å®šä¹‰ä¸ºå®é™…å¼•ç”¨æ¬¡æ•°ä¸é¢„æœŸå¼•ç”¨æ¬¡æ•°çš„æ¯”å€¼ï¼ˆå…¬å¼ 12ï¼‰ï¼š</p>
<div class="math notranslate nohighlight">
\[
RCI_i = \frac{C_i}{\hat{C_i}} \quad \text{(å…¬å¼ 12)}
\]</div>
<ul class="simple">
<li><p>è‹¥ <span class="math notranslate nohighlight">\(RCI_i \geq 1\)</span>ï¼Œè¡¨ç¤ºè®ºæ–‡æ¯”é¢„æœŸå¼•ç”¨æ¬¡æ•°æ›´é«˜ï¼Œè®¤ä¸ºå…¶å½±å“åŠ›è¾ƒå¤§ï¼›</p></li>
<li><p>æœ¬ç ”ç©¶é‡ç‚¹å…³æ³¨ <span class="math notranslate nohighlight">\(RCI \geq 1\)</span> çš„è®ºæ–‡ã€‚</p></li>
</ul>
<p>å›¾ 15 å±•ç¤ºäº†ä¸åŒâ€œå¹´é¾„â€è®ºæ–‡çš„å¼•ç”¨åˆ†å¸ƒï¼Œçº¢è‰²æ›²çº¿è¡¨ç¤ºæ¨¡å‹é¢„æµ‹çš„å¼•ç”¨ä¸­ä½æ•°ã€‚RCI å¤§äºç­‰äº 1 çš„è®ºæ–‡ä½äºä¸­ä½æ•°ä»¥ä¸Šï¼Œå…¶å½±å“åŠ›æ›´é«˜ã€‚</p>
</section>
<hr class="docutils" />
<section id="id30">
<h3>å…­ã€RCI ä¸ç ”ç©¶è¶‹åŠ¿åˆ†æ<a class="headerlink" href="#id30" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>ç»“åˆ RCI æŒ‡æ•°ä¸è®ºæ–‡å‘è¡¨æ•°é‡çš„å˜åŒ–è¶‹åŠ¿ï¼Œç ”ç©¶è¿›ä¸€æ­¥åˆ†æäº†ä¸åŒâ€œè®°å¿†ç›¸å…³â€ç ”ç©¶ä¸»é¢˜çš„å‘å±•åŠ¨æ€ï¼ˆè§å›¾ 16 å’Œ 17ï¼‰ã€‚</p>
<section id="id31">
<h4>å›¾ 16ï¼šå„ä¸»é¢˜çš„ä¸­ä½ RCI åˆ†å¸ƒ<a class="headerlink" href="#id31" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p>2023 å¹´æ˜¯å…³é”®è½¬æŠ˜ç‚¹ï¼Œéšç€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å…´èµ·ï¼Œ<strong>é•¿ä¸Šä¸‹æ–‡ï¼ˆlong-contextï¼‰</strong> å’Œ <strong>å‚æ•°åŒ–è®°å¿†ï¼ˆparametric memoryï¼‰</strong> çš„è®ºæ–‡æ•°é‡å’Œè´¨é‡åŒæ—¶æå‡ï¼Œè¡¨æ˜ LLM æ¨åŠ¨äº†è¿™ä¸¤ä¸ªé¢†åŸŸçš„è¿…é€Ÿå‘å±•ã€‚</p></li>
<li><p>ç›¸æ¯”ä¹‹ä¸‹ï¼Œ<strong>é•¿æœŸè®°å¿†ï¼ˆlong-term memoryï¼‰</strong> å’Œ <strong>å¤šæºè®°å¿†ï¼ˆmulti-source memoryï¼‰</strong> çš„å½±å“åŠ›è¾ƒä¸ºç¨³å®šï¼Œæœªå‡ºç°çªç ´æ€§è¿›å±•ã€‚</p></li>
</ul>
</section>
<section id="id32">
<h4>å›¾ 17ï¼šå„ä¸»é¢˜çš„è®ºæ–‡æ•°é‡ä¸ RCI è¶‹åŠ¿<a class="headerlink" href="#id32" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p>æ‰€æœ‰ä¸»é¢˜çš„è®ºæ–‡æ•°é‡å‡æ˜¾è‘—å¢é•¿ï¼Œå…¶ä¸­â€œé•¿ä¸Šä¸‹æ–‡â€ä» 2022 å¹´å‰çš„æœ€å°‘ä¸»é¢˜ä¹‹ä¸€ï¼Œæˆé•¿ä¸º 2024 å¹´çš„æœ€çƒ­é—¨ä¸»é¢˜ã€‚</p></li>
<li><p><strong>é•¿æœŸè®°å¿†</strong> çš„ RCI é€æ­¥ä¸Šå‡ï¼Œåæ˜ å…¶ç ”ç©¶ä»·å€¼ä¸æ–­æå‡ï¼›</p></li>
<li><p>å…¶ä»–ä¸»é¢˜åœ¨ 2023 å¹´åçš„ RCI ä¸­ä½æ•°æœ‰æ‰€ä¸‹é™ï¼Œä½†æ•´ä½“å½±å“åŠ›ä»ç»´æŒåœ¨è¾ƒé«˜æ°´å¹³ã€‚</p></li>
</ul>
<p>è¿™äº›è¶‹åŠ¿è¡¨æ˜ï¼Œ<strong>å¤§æ¨¡å‹çš„å‡ºç°æ˜¾è‘—æ¨åŠ¨äº†è®°å¿†ç›¸å…³ç ”ç©¶çš„è¿›å±•ï¼Œå°¤å…¶æ˜¯åœ¨é•¿ä¸Šä¸‹æ–‡å’Œå‚æ•°åŒ–è®°å¿†é¢†åŸŸ</strong>ã€‚</p>
</section>
</section>
<hr class="docutils" />
<section id="id33">
<h3>æ€»ç»“<a class="headerlink" href="#id33" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>æœ¬é™„å½•è¯¦ç»†ä»‹ç»äº†å¦‚ä½•é€šè¿‡æ„å»º <strong>ç›¸å¯¹å¼•ç”¨æŒ‡æ•°ï¼ˆRCIï¼‰<strong>æ¥è¡¡é‡è®ºæ–‡çš„å½±å“åŠ›ï¼Œé‡ç‚¹æ¨¡å‹é€‰æ‹©ä¸º</strong>å¯¹æ•°â€“å¯¹æ•°å›å½’æ¨¡å‹</strong>ï¼Œå¹¶ç»“åˆè®ºæ–‡å‘è¡¨è¶‹åŠ¿åˆ†æäº†ä¸åŒâ€œè®°å¿†â€ç ”ç©¶ä¸»é¢˜çš„å‘å±•è½¨è¿¹ã€‚ç ”ç©¶å‘ç°ï¼Œå¤§è¯­è¨€æ¨¡å‹çš„å…´èµ·å¯¹<strong>é•¿ä¸Šä¸‹æ–‡</strong>å’Œ<strong>å‚æ•°åŒ–è®°å¿†</strong>é¢†åŸŸçš„å½±å“æœ€ä¸ºæ˜¾è‘—ï¼Œè€Œå…¶ä»–é¢†åŸŸåˆ™ä¿æŒäº†ç›¸å¯¹ç¨³å®šçš„å½±å“åŠ›ã€‚</p>
</section>
</section>
<section id="appendix-c-chord-analysis-of-interactions-among-memory-types-operations-topics-and-venues">
<h2>Appendix C Chord Analysis of Interactions Among Memory Types, Operations, Topics, and Venues<a class="headerlink" href="#appendix-c-chord-analysis-of-interactions-among-memory-types-operations-topics-and-venues" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h2>
<p>æœ¬æ–‡é€šè¿‡**å¼¦çŠ¶å›¾ï¼ˆChord diagramï¼‰**çš„æ–¹å¼ï¼Œä»ä¸¤ä¸ªè§’åº¦å¯¹è®°å¿†ç ”ç©¶è¿›è¡Œäº†åˆ†æï¼š</p>
<ol class="arabic simple">
<li><p><strong>è®°å¿†ç±»å‹ã€æ“ä½œä¸ç ”ç©¶ä¸»é¢˜ä¹‹é—´çš„äº¤äº’å…³ç³»</strong>ï¼›</p></li>
<li><p><strong>è¿™äº›äº¤äº’åœ¨ä¸»è¦æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰å’Œè‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä¼šè®®ä¸­çš„åˆ†å¸ƒæƒ…å†µ</strong>ã€‚</p></li>
</ol>
<hr class="docutils" />
<section id="c-1">
<h3>C.1 è®°å¿†ç±»å‹ã€æ“ä½œä¸ä¸»é¢˜ä¹‹é—´çš„äº¤äº’åˆ†æ<a class="headerlink" href="#c-1" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>ä½œè€…ä» <strong>132 ç¯‡ RCI â‰¥ 1 çš„æ–¹æ³•ç±»è®ºæ–‡</strong> ä¸­æå–æ•°æ®ï¼Œç”Ÿæˆäº†æœ€ç»ˆçš„å¼¦çŠ¶å›¾ï¼ˆå›¾19ï¼‰ï¼Œç›´è§‚å±•ç¤ºäº†ä¸åŒç±»å‹ã€æ“ä½œä¸ç ”ç©¶ä¸»é¢˜ä¹‹é—´çš„è”ç³»ã€‚</p>
<section id="memory-types">
<h4>1. <strong>è®°å¿†ç±»å‹è§†è§’ï¼ˆMemory Typesï¼‰</strong><a class="headerlink" href="#memory-types" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p><strong>ç ”ç©¶é‡ç‚¹</strong>ï¼šå½“å‰ç ”ç©¶ä¸»è¦é›†ä¸­äº <strong>å‚æ•°è®°å¿†ï¼ˆparametric memoryï¼‰</strong> å’Œ <strong>ä¸Šä¸‹æ–‡éç»“æ„åŒ–è®°å¿†ï¼ˆcontextual unstructured memoryï¼‰</strong>ï¼Œç‰¹åˆ«æ˜¯è¿™å‡ ä¸ªæ“ä½œï¼š<strong>å‹ç¼©ï¼ˆcompressionï¼‰ã€æ£€ç´¢ï¼ˆretrievalï¼‰ã€é—å¿˜ï¼ˆforgettingï¼‰å’Œæ›´æ–°ï¼ˆupdatingï¼‰</strong>ã€‚</p></li>
<li><p><strong>ç›¸å¯¹å†·é—¨é¢†åŸŸ</strong>ï¼š<strong>ä¸Šä¸‹æ–‡ç»“æ„åŒ–è®°å¿†ï¼ˆcontextual structured memoryï¼‰</strong> ç ”ç©¶è¾ƒå°‘ï¼Œå¯èƒ½æ˜¯å› ä¸ºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ›´æ“…é•¿å¤„ç†<strong>åºåˆ—æ–‡æœ¬</strong>ï¼Œå¯¹ç»“æ„åŒ–è¾“å…¥çš„å¤„ç†æ•ˆæœè¾ƒå·®ã€‚</p></li>
</ul>
</section>
<section id="operations">
<h4>2. <strong>æ“ä½œè§†è§’ï¼ˆOperationsï¼‰</strong><a class="headerlink" href="#operations" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p><strong>ç ”ç©¶çƒ­ç‚¹</strong>ï¼š<strong>å‹ç¼©</strong>ä¸<strong>æ£€ç´¢</strong>æ˜¯æœ€å¸¸ç ”ç©¶çš„æ“ä½œï¼Œå®ƒä»¬æ˜¯å¤§å¤šæ•°ç ”ç©¶ä¸­ä½¿ç”¨è®°å¿†çš„åŸºç¡€æ“ä½œã€‚</p></li>
<li><p><strong>è¾ƒå†·é—¨æ“ä½œ</strong>ï¼š<strong>ç´¢å¼•ï¼ˆindexingï¼‰</strong> å…³æ³¨è¾ƒå°‘ï¼Œè¿™å¯èƒ½æ˜¯å› ä¸ºç›®å‰ç ”ç©¶å¤§å¤šèšç„¦åœ¨<strong>å¦‚ä½•ä½¿ç”¨è®°å¿†</strong>ï¼Œè€Œé<strong>å¦‚ä½•é«˜æ•ˆç»„ç»‡è®°å¿†</strong>ã€‚</p></li>
<li><p><strong>æ•´åˆï¼ˆconsolidationï¼‰</strong>ï¼šå¤šæŒ‡é€šè¿‡è®­ç»ƒå°†çŸ¥è¯†å­˜å‚¨åˆ°æ¨¡å‹å‚æ•°ä¸­ï¼Œæˆ–è€…å°†çŸ¥è¯†è½¬åŒ–ä¸ºå›ºå®šæ ¼å¼çš„å¤–éƒ¨è®°å¿†ã€‚</p></li>
<li><p><strong>æ›´æ–°ä¸é—å¿˜</strong>ï¼šä¸»è¦ä¸<strong>å‚æ•°è°ƒæ•´</strong>å’Œ<strong>çŸ¥è¯†åˆ é™¤</strong>ç›¸å…³ï¼Œå°¤å…¶æ˜¯å‚æ•°è®°å¿†ä¸­ã€‚è¿™äº›æ–¹å‘çš„ç›®æ ‡æ˜¯åŸºäºå¤–éƒ¨è¾“å…¥å¢é‡åœ°ä¿®æ”¹æ¨¡å‹å‚æ•°ï¼Œä½†ç”±äºæ¨¡å‹å†…éƒ¨çš„â€œé»‘ç®±â€æ€§è´¨ï¼Œç›¸å…³ç ”ç©¶ä»å¤„äºæ—©æœŸæ¢ç´¢é˜¶æ®µã€‚</p></li>
</ul>
</section>
<section id="topics">
<h4>3. <strong>ä¸»é¢˜è§†è§’ï¼ˆTopicsï¼‰</strong><a class="headerlink" href="#topics" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p><strong>å‚æ•°ä¿®æ”¹</strong>ï¼šä¸»è¦é›†ä¸­åœ¨<strong>å‚æ•°è®°å¿†</strong>ï¼Œæœ‰äº›ç ”ç©¶å°è¯•é€šè¿‡<strong>æŒç»­å­¦ä¹ ï¼ˆcontinual learningï¼‰</strong> æ¥è°ƒæ•´å‚æ•°ã€‚</p></li>
<li><p><strong>é•¿ä¸Šä¸‹æ–‡</strong>ï¼šä¸»è¦æ¶‰åŠ<strong>éç»“æ„åŒ–è®°å¿†</strong>ä¸­çš„<strong>å‹ç¼©ä¸æ£€ç´¢</strong>ï¼Œéƒ¨åˆ†ç ”ç©¶ä½¿ç”¨äº†<strong>é”®å€¼ç¼“å­˜ï¼ˆkey-value cachesï¼‰</strong> ç­‰å‚æ•°åŒ–å½¢å¼ã€‚</p></li>
<li><p><strong>é•¿æœŸè®°å¿†</strong>ï¼šä¹Ÿé›†ä¸­åœ¨<strong>éç»“æ„åŒ–è®°å¿†</strong>ï¼Œå°¤å…¶æ˜¯<strong>æ•´åˆã€å‹ç¼©ä¸æ£€ç´¢</strong>ã€‚</p></li>
<li><p><strong>å¤šæºè®°å¿†</strong>ï¼šç ”ç©¶è¾ƒå°‘ï¼Œä¸”é€šå¸¸æ¶‰åŠ<strong>ç»“æ„åŒ–ä¸éç»“æ„åŒ–ä¿¡æ¯çš„æ•´åˆ</strong>ã€‚ç„¶è€Œï¼Œå¤šæºè®°å¿†é¢ä¸´<strong>å¼‚æ„ä¿¡æ¯å†²çª</strong>çš„æŒ‘æˆ˜ï¼Œç›®å‰ä»ç¼ºä¹æœ‰æ•ˆçš„æ•´åˆç­–ç•¥ã€‚</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="id34">
<h3>æ€»ç»“ä¸ç ”ç©¶æ–¹å‘<a class="headerlink" href="#id34" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<ol class="arabic simple">
<li><p><strong>ç»“æ„åŒ–è®°å¿†ä¸éç»“æ„åŒ–è®°å¿†çš„ç»“åˆ</strong>ï¼šå½“å‰å¯¹<strong>ä¸Šä¸‹æ–‡ç»“æ„åŒ–è®°å¿†</strong>çš„ç ”ç©¶è¾ƒå°‘ï¼Œæœªæ¥å¯ä»¥æ¢ç´¢å¦‚ä½•å°†å…¶ä¸éç»“æ„åŒ–è®°å¿†ç»“åˆï¼Œå®ç°æ›´å®Œæ•´çš„è®°å¿†æ“ä½œã€‚</p></li>
<li><p><strong>å¤šæºè®°å¿†çš„æ•´åˆ</strong>ï¼šå°½ç®¡æŒ‘æˆ˜è¾ƒå¤§ï¼ˆå¦‚å¼‚æ„æ¥æºå¼•å‘çš„è®°å¿†å†²çªï¼‰ï¼Œä½†<strong>è®¾è®¡é²æ£’ä¸”ä¸€è‡´çš„å¤šæºè®°å¿†æ•´åˆç­–ç•¥</strong>æ˜¯ä¸€ä¸ªæœ‰å‰æ™¯çš„ç ”ç©¶æ–¹å‘ã€‚</p></li>
<li><p><strong>ç´¢å¼•æœºåˆ¶çš„æ¢ç´¢</strong>ï¼šè™½ç„¶ç´¢å¼•åœ¨ä¼ ç»Ÿæ•°æ®åº“ç³»ç»Ÿä¸­ç ”ç©¶å¹¿æ³›ï¼Œä½†åœ¨<strong>åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ™ºèƒ½ä½“ä¸­</strong>ï¼Œç›¸å…³ç ”ç©¶ä»ç„¶å¾ˆå°‘ã€‚ç”±äºè®°å¿†ç±»å‹çš„å¤æ‚æ€§ä¸å¯¹<strong>å‘é‡åŒ–æˆ–ç¨€ç–æ£€ç´¢æ–¹æ³•</strong>çš„éœ€æ±‚ï¼Œ<strong>éœ€è¦ä¸ºLLMæ¨ç†å’Œäº¤äº’è®¾è®¡æ–°çš„ç´¢å¼•æ–¹æ³•</strong>ã€‚</p></li>
</ol>
<hr class="docutils" />
<p>æ­¤é™„å½•ç« èŠ‚é€šè¿‡å¼¦çŠ¶å›¾å±•ç¤ºäº†å½“å‰è®°å¿†ç ”ç©¶çš„æ ¸å¿ƒæ–¹å‘ä¸æ½œåœ¨çš„ç ”ç©¶ç©ºç™½ï¼Œä¸ºè¿›ä¸€æ­¥æ¢ç´¢è®°å¿†æœºåˆ¶æä¾›äº†æ¸…æ™°çš„è·¯çº¿å›¾ã€‚</p>
</section>
<section id="c-2-memory-interactions-across-conference-venues">
<h3>C.2 Memory Interactions Across Conference Venues<a class="headerlink" href="#c-2-memory-interactions-across-conference-venues" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h3>
<p>æœ¬èŠ‚å†…å®¹ä¸»è¦æ¢è®¨äº†<strong>ä¸åŒä¼šè®®é¢†åŸŸä¸­è®°å¿†æ“ä½œä¸ä¸»é¢˜çš„äº¤äº’æƒ…å†µ</strong>ï¼Œå¹¶ç»“åˆä¼šè®®è®ºæ–‡ã€æ•°æ®é›†å’Œæ–¹æ³•å¯¹è®°å¿†ç³»ç»Ÿçš„è¿è¡Œã€å‘å±•è¶‹åŠ¿ä»¥åŠæ½œåœ¨çš„ç ”ç©¶æ–¹å‘è¿›è¡Œäº†åˆ†æã€‚</p>
<hr class="docutils" />
<section id="id35">
<h4>1. <strong>ä¸åŒä¼šè®®ä¸­çš„æ“ä½œåˆ†å¸ƒ</strong><a class="headerlink" href="#id35" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p><strong>MLä¼šè®®ï¼ˆå¦‚ ICLRã€ICMLã€NeurIPSï¼‰<strong>æ›´å…³æ³¨</strong>å‹ç¼©ï¼ˆCompressionï¼‰ã€é—å¿˜ï¼ˆForgettingï¼‰ã€æ›´æ–°ï¼ˆUpdatingï¼‰<strong>ç­‰æ“ä½œï¼Œè¿™äº›æ“ä½œæ›´å¤šå¤„äº</strong>ç†è®ºæ¢ç´¢é˜¶æ®µ</strong>ï¼Œå°šæœªå¹¿æ³›åº”ç”¨äºå®é™…ç³»ç»Ÿã€‚</p></li>
<li><p><strong>NLPä¼šè®®ï¼ˆå¦‚ ACLã€EMNLPã€NAACLï¼‰<strong>æ›´ä¾§é‡äº</strong>æ£€ç´¢ï¼ˆRetrievalï¼‰å’Œå·©å›ºï¼ˆConsolidationï¼‰</strong>ï¼Œè¿™äº›æ“ä½œæ›´åå‘<strong>å®é™…åº”ç”¨</strong>ã€‚</p></li>
<li><p><strong>ç´¢å¼•ï¼ˆIndexingï¼‰<strong>åœ¨MLå’ŒNLPä¼šè®®ä¸­éƒ½è¾ƒä¸ºå°‘è§ï¼Œå¯èƒ½æ˜¯å› ä¸ºå…¶ä¸</strong>æ£€ç´¢</strong>é«˜åº¦ç›¸å…³ï¼Œä¸”å½“å‰å¤šé‡‡ç”¨<strong>å‘é‡ç´¢å¼•æ–¹æ³•</strong>ï¼Œç¼ºä¹åˆ›æ–°æ€§ã€‚</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="id36">
<h4>2. <strong>ä¸åŒä¼šè®®ä¸­çš„ä¸»é¢˜åˆ†å¸ƒ</strong><a class="headerlink" href="#id36" title="æ­¤æ ‡é¢˜çš„æ°¸ä¹…é“¾æ¥">Â¶</a></h4>
<ul class="simple">
<li><p><strong>é•¿æœŸè®°å¿†ï¼ˆLong-Term Memoryï¼‰<strong>æ›´å¸¸å‡ºç°åœ¨</strong>NLPä¼šè®®</strong>ä¸Šï¼Œè¿™å¯èƒ½ä¸NLPæ›´æ³¨é‡<strong>ç”¨æˆ·å¯¹è¯çš„å»¶ç»­æ€§</strong>æœ‰å…³ã€‚</p></li>
<li><p><strong>é•¿ä¸Šä¸‹æ–‡ï¼ˆLong-Contextï¼‰<strong>æ›´å¸¸è§äº</strong>MLä¼šè®®</strong>ï¼Œå¼ºè°ƒ<strong>å¤„ç†é•¿è¾“å…¥åºåˆ—</strong>åŠ<strong>ä¸­é—´è¯­ä¹‰ä¸¢å¤±</strong>çš„é—®é¢˜ã€‚</p></li>
<li><p><strong>å‚æ•°ä¿®æ”¹ï¼ˆParametric Memory Modificationï¼‰<strong>åœ¨</strong>MLä¼šè®®</strong>ä¸­å‡ºç°é¢‘ç‡è¾ƒé«˜ã€‚</p></li>
<li><p><strong>å¤šæºè®°å¿†ï¼ˆMulti-Source Memoryï¼‰<strong>åœ¨</strong>NLPä¼šè®®</strong>ä¸­æ›´å¸¸è§ï¼Œåæ˜ äº†<strong>å®é™…ç³»ç»Ÿä¸­å¤šæ•°æ®æºæ•´åˆçš„æŒ‘æˆ˜</strong>ã€‚</p></li>
</ul>
</section>
</section>
</section>
</section>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="2505.22101_MemOS.html" class="btn btn-neutral float-right" title="2505.22101_MemOS: An Operating System for Memory-Augmented Generation (MAG) in LLM (Short Version)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="2504.19413_Mem0.html" class="btn btn-neutral" title="2504.19413_â‡ï¸Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>
  
  <div id="gitalk-container"></div>
  <div role="contentinfo">
    <p>
        &copy; Copyright 2010-2025, æ–°æºª-gordon.

    </p>
  </div>
  <div>å¤‡æ¡ˆå· <a href="http://www.beian.miit.gov.cn">äº¬ICPå¤‡16018553å·</a></div><div>Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a></div>. 


</footer>

<script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?042289284b8eb33866001347a3e0b129";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
</script>     
        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'V2025.09',
            LANGUAGE:'zh-CN',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="../../_static/sphinx_highlight.js"></script>
      <script type="text/javascript" src="../../_static/clipboard.min.js"></script>
      <script type="text/javascript" src="../../_static/copybutton.js"></script>
      <script type="text/javascript" src="../../_static/translations.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script type="text/javascript" src="../../None"></script>
      <script type="text/javascript" src="https://fastly.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  

  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });


      // var gitalk = new Gitalk({
      //         clientID: '565177626b5d46427009',
      //         clientSecret: 'b2a36e67e1d2a73e43667f46d571c2624f8e1026',
      //         repo: 'knowledge',
      //         owner: 'zhaoweiguo',
      //         admin: ['zhaoweiguo'],
      //         id: location.pathname,      // Ensure uniqueness and length less than 50
      //         distractionFreeMode: false  // Facebook-like distraction free mode
      //       })
      // gitalk.render('gitalk-container')

  </script>


<script type="text/javascript" src="../../_static/js/table-of-contents-sidebar.js"></script>
<!-- <script type="text/javascript" src="https://table-of-contents-sidebar.github.io/table-of-contents-sidebar-lib/table-of-contents-sidebar.js"></script> -->
<script type="text/javascript">
    window.onload = function(e){
        TableOfContents.init({
            basePath: "https://table-of-contents-sidebar.github.io/table-of-contents-sidebar-lib/",
            querySelector: "body" // or other css querySelector
        });
    }
</script> 

</body>
</html>