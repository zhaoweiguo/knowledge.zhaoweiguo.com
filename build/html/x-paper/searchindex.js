Search.setIndex({"docnames": ["0normal", "0normals/normal", "0normals/website", "Agent", "Agents/AGIs/1905.10985_AI-GA", "Agents/AGIs/2408.06292_AI-Scientist", "Agents/Agent_Visions/2108.03353_Screen2Words", "Agents/Agent_Visions/2209.08199_ScreenQA", "Agents/Agent_Visions/2212.06817_RT-1", "Agents/Agent_Visions/2312.13771_AppAgent", "Agents/Agent_Visions/2401.10935_SeeClick", "Agents/Agent_Visions/2402.04615_ScreenAI", "Agents/Agent_Visions/2402.07939_UFO", "Agents/Agent_Visions/2403.16971_AIOS", "Agents/Agent_Visions/2406.01014_Mobile-Agent-v2", "Agents/Agent_Visions/2411.02059_TableGPT2", "Agents/Agent_Visions/2501.11733_Mobile-Agent-E", "Agents/Agent_Visions/2501.12326_UI-TARS", "Agents/Agent_Visions/2502.14282_PC-Agent", "Agents/Agent_Visions/2504.14603_UFO2", "Agents/Agent_normals/2210.03629_ReAct", "Agents/Agent_normals/2303.08268_Chat-with-the-Environment", "Agents/Agent_normals/2303.11366_Reflexion", "Agents/Agent_normals/2303.16434_TaskMatrix.AI", "Agents/Agent_normals/2304.03442_Generative-Agents", "Agents/Agent_normals/2307.07924_ChatDev", "Agents/Agent_normals/2308.00352_MetaGPT", "Agents/Agent_normals/2308.04026_AgentSims", "Agents/Agent_normals/2308.08155_AutoGen", "Agents/Agent_normals/2308.10848_AgentVerse", "Agents/Agent_normals/2310.06117_Step-Back", "Agents/Agent_normals/2402.18679_MetaGPT_DI", "Agents/Agent_normals/2407.07061_IoA", "Agents/Agent_normals/2408.08435_ADAS", "Agents/Agent_normals/2410.10762_AFlow", "Agents/Agent_normals/2410.17238_SELA", "Agents/Agent_normals/2410.21012_FACT", "Agents/Agent_normals/2504.01990_foundation-agents", "Agents/Agent_normals/2506.12508_AgentOrchestra", "Agents/Memorys/2505.22101_MemOS", "Agents/Tools/2205.00445_MRKL", "Agents/Tools/2302.04761_Toolformer", "Agents/Tools/2303.17580_HuggingGPT", "Agents/Tools/2307.16789_ToolLLM", "Benchmarking", "Benchmarkings/DS_Agents/2312.14033_T-Eval", "Benchmarkings/DS_Agents/2406.12045_\u03c4-bench", "Benchmarkings/DS_Agents/2506.07982_\ud835\udf0f\u00b2-Bench", "Benchmarkings/DS_Codes/2107.03374_HumanEval", "Benchmarkings/DS_Codes/2108.07732_MBPP", "Benchmarkings/DS_Codes/2310.06770_SWE-bench", "Benchmarkings/DS_Codes/2402.16694_HumanEval-XL", "Benchmarkings/DS_Codes/2403.07974_LiveCodeBench", "Benchmarkings/DS_Codes/2407.10499_CIBench", "Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal", "Benchmarkings/DS_Codes/2410.06992_SWE-Bench+", "Benchmarkings/DS_Codes/2501.01257_CodeForces", "Benchmarkings/DS_Images/2306.13394_MME", "Benchmarkings/DS_Images/2307.06281_MMBench", "Benchmarkings/DS_Images/2307.16125_SEED-Bench", "Benchmarkings/DS_Images/2311.12793_ShareGPT4V", "Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image", "Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval", "Benchmarkings/DS_LongCtxs/2402.17753_LoCoMo", "Benchmarkings/DS_LongCtxs/2404.06654_RULER", "Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench", "Benchmarkings/DS_Maths/2103.03874_MATH", "Benchmarkings/DS_Maths/2110.14168_GSM8K", "Benchmarkings/DS_Maths/2405.12209_MathBench", "Benchmarkings/DS_QAs/1809.09600_HotpotQA", "Benchmarkings/DS_QAs/2109.07958_TruthfulQA", "Benchmarkings/DS_QAs/2311.12022_GPQA", "Benchmarkings/DS_QAs/2411.04368_SimpleQA", "Benchmarkings/Datasets/0normal", "Benchmarkings/Datasets/2009.03300_MMLU", "Benchmarkings/Datasets/2305.08322_C-Eval", "Benchmarkings/Datasets/2306.09212_CMMLU", "Benchmarkings/Datasets/2307.15020_SuperCLUE", "Benchmarkings/Datasets/2311.12983_GAIA", "Benchmarkings/Datasets/2404.07972_OSWorld", "Benchmarkings/Datasets/2501.14249_HLE", "Benchmarkings/Standards/02xx.xxxxx_BLEU", "Benchmarkings/Standards/0401.xxxxx_ROUGE", "Benchmarkings/Standards/1803.01937_ROUGE2", "Benchmarkings/Standards/1804.08771_SacreBLEU", "Benchmarkings/Standards/2306.05685_LLM-as-a-Judge", "LLM", "LLM_tech", "LLM_techs/FineTunes/2101.00190_Prefix-Tuning", "LLM_techs/FineTunes/2103.10385_p-tuning", "LLM_techs/FineTunes/2104.08691_Prompt_Tuning", "LLM_techs/FineTunes/2106.09685_LoRA", "LLM_techs/FineTunes/2401.01335_Self-Play", "LLM_techs/FineTunes/2402.09353_DoRA", "LLM_techs/FineTunes/2402.12354_LoRA+", "LLM_techs/FineTunes/2403.03507_GaLore", "LLM_techs/FineTunes/2403.13372_LlamaFactory", "LLM_techs/Frameworks/1712.05889_Ray", "LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO", "LLM_techs/Frameworks/19XX_PyTorch", "LLM_techs/Frameworks/20XX_Transformers", "LLM_techs/Frameworks/2210.XX_Ray_v2", "LLM_techs/Frameworks/2309.06180_vLLM", "LLM_techs/Parallelism/1701.06538_MoE", "LLM_techs/Parallelism/1806.03377_PipeDream", "LLM_techs/Parallelism/1811.06965_GPipe", "LLM_techs/Parallelism/1909.08053_Megatron-LM", "LLM_techs/Parallelism/1910_PipeDream2", "LLM_techs/Parallelism/2006.09503_PipeDream-2BW", "LLM_techs/Parallelism/2006.15704DataParallel", "LLM_techs/Parallelism/2006.16668_GShard", "LLM_techs/Parallelism/2104.04473_Megatron-LM2", "LLM_techs/Parallelism/2205.14135_FlashAttention", "LLM_techs/Parallelism/2307.08691_FlashAttention2", "LLM_techs/Parallelism/normal", "LLM_techs/Quantizations/0normal", "LLM_techs/Quantizations/2110.02861_bitsandbytes", "LLM_techs/Quantizations/2206.01861_ZeroQuant", "LLM_techs/Quantizations/2206.09557_LUT-GEMM", "LLM_techs/Quantizations/2208.07339_LLM.int8", "LLM_techs/Quantizations/2209.05433_FP8", "LLM_techs/Quantizations/2210.17323_GPTQ", "LLM_techs/Quantizations/2211.10438_SmoothQuant", "LLM_techs/Quantizations/2305.14314_QLoRA", "LLM_techs/Quantizations/2306.00978_AWQ", "LLM_techs/Quantizations/2309.05516_AutoRound", "LLM_techs/RLs/1703.03864_EvolutionStrategies", "LLM_techs/RLs/2504.02495_DeepSeek_GRM", "LLM_techs/RLs/2504.13958_ToolRL", "LLM_techs/Securitys/2312.06674_Llama_Guard", "LLM_techs/others/2203.02155_InstructGPT", "LLM_techs/others/2305.20050_LetsVerifyStepbyStep", "LLM_techs/others/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally", "LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning", "LLMs/LLMAudio/2005.08100_Conformer", "LLMs/LLMAudio/2106.07447_HuBERT", "LLMs/LLMAudio/2112.02418_YourTTS", "LLMs/LLMAudio/2212.04356_whisper", "LLMs/LLMAudio/2301.02111_Vall-E", "LLMs/LLMAudio/2303.03926_VALL-E_X", "LLMs/LLMAudio/2406.05370_VALL-E2", "LLMs/LLMAudio/2407.05407_CosyVoice", "LLMs/LLMAudio/2407.10759_Qwen2-Audio", "LLMs/LLMAudio/2410.00037_Moshi", "LLMs/LLMAudio/2412.10117_CosyVoice2", "LLMs/LLMAudio/2501.06282_MinMo", "LLMs/LLMAudio/2505.02707_Voila", "LLMs/LLMAudio/2505.17589_CosyVoice3", "LLMs/LLMCommercials/2303.08774_GPT4", "LLMs/LLMCommercials/2312.11805_Gemini", "LLMs/LLMCommercials/2403.05530_Gemini1.5", "LLMs/LLMCommercials/2406.02430_Seed-TTS", "LLMs/LLMCommercials/2407.04675_Seed-ASR", "LLMs/LLMCommercials/2503.20020_Gemini2", "LLMs/LLMCommercials/2504.xxxxx_Seed-Thinking-v1.5", "LLMs/LLMCommercials/2505.07062_Seed1.5-VL", "LLMs/LLMMoEs/2408.15664_AUXILIARY-LOSS-FREE_LB", "LLMs/LLMMoEs/2410.07490_MoDEM", "LLMs/LLMMultimodals/2112.15093_CTR", "LLMs/LLMMultimodals/2304.08485_LLaVA", "LLMs/LLMMultimodals/2308.12966_Qwen-VL", "LLMs/LLMMultimodals/2310.03744_LLaVA2", "LLMs/LLMMultimodals/2312.07533_VILA", "LLMs/LLMMultimodals/2403.05525_DeepSeek-VL", "LLMs/LLMMultimodals/2408.01800_MiniCPM-V", "LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo", "LLMs/LLMMultimodals/2410.13848_Janus", "LLMs/LLMMultimodals/2411.00774_Freeze-Omni", "LLMs/LLMMultimodals/2412.04468_NVILA", "LLMs/LLMMultimodals/2502.13923_Qwen2.5-VL", "LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni", "LLMs/LLMMultimodals/2506.13642_Stream-Omni", "LLMs/LLMMultimodals/2506.13642_Stream-Omni2", "LLMs/LLMVideos/2301.12597_BLIP-2", "LLMs/LLMVideos/2308.01390_OpenFlamingo", "LLMs/LLM_NLPs/1810.04805_BERT", "LLMs/LLM_NLPs/18_GPT1", "LLMs/LLM_NLPs/19_GPT2", "LLMs/LLM_NLPs/2012.00413_CPM", "LLMs/LLM_NLPs/2302.13971_LLaMA", "LLMs/LLM_NLPs/2307.09288_Llama2", "LLMs/LLM_NLPs/2309.16609_Qwen", "LLMs/LLM_NLPs/2310.19341_Skywork", "LLMs/LLM_NLPs/2401.14196_DeepSeek-Coder", "LLMs/LLM_NLPs/2404.06395_MiniCPM", "LLMs/LLM_NLPs/2405.04434_DeepSeek-V2", "LLMs/LLM_NLPs/2406.12793_ChatGLM", "LLMs/LLM_NLPs/2407.10671_Qwen2", "LLMs/LLM_NLPs/2412.15115_Qwen2.5", "LLMs/LLM_NLPs/2505.09388_Qwen3", "ML", "MLs/MLVisions/1506.02640_YOLO", "MLs/MLVisions/1612.08242_YOLO9000", "MLs/MLVisions/1804.02767_YOLOv3", "MLs/MLVisions/2004.10934_YOLOv4", "MLs/MLVisions/2205.00159_SVTR", "MLs/MLVisions/2207.02696_YOLOv7", "MLs/MLVisions/2303.05499_GroundingDINO", "MLs/MLVisions/2304.08485_VisualInstructionTuning", "MLs/MLVisions/2402.13616_YOLOv9", "MLs/MLVisions/2405.14458_YOLOv10", "MLs/MLVisions/2411.15858_SVTRv2", "MLs/ML_normals/2112.09332_WebGPT", "MLs/ML_normals/2203.11147_GopherCite", "MLs/ML_normals/2304.09848_Generative_Search", "MLs/ML_normals/2305.14251_FActScore", "MLs/ML_normals/2305.14627_ALCE", "MLs/ML_normals/2307.02185_Citation", "MLs/ML_normals/2307.16883_HAGRID", "RAG", "RAGs/2005.11401_RAG_for_KI_NLP_task", "RAGs/2312.10997_RAG_for_LLM", "RAGs/2401.15884_CRAG", "RAGs/2403.14403_Adaptive-RAG", "RAGs/2404.16130_GraphRAG", "RAGs/2405.16506_GRAG", "RAGs/2406.13213_Multi-Meta-RAG", "RAGs/2410.05779_LightRAG", "RAGs/2410.10450_KBLaM", "RAGs/2504.03137_LightPROF", "RAGs/graphrag", "index", "other", "others/3D/2003.08934_NeRF", "others/3D/2203.08586_VanishingPointEstimation", "others/3D/2312.14132_DUSt3R", "others/3D/2406.09756_MASt3R", "others/3D/2412.09401_SLAM3R", "others/3D/2412.12392_MASt3R-SLAM", "others/3D/2503.11651_VGGT", "others/DataSets/1811.10959v3_Dataset_Distillation", "others/DataSets/2502.20653_Dataset_Distillation", "others/DataSets/normal", "others/others/A PAINLESS GUIDE TO CRC ERROR DETECTION ALGORITHMS", "others/others/Distributed Representations of Sentences and Documents", "paper_pool", "zzz_paper_pools/2305.16300", "zzz_paper_pools/2311.18743_AlignBench", "zzz_paper_pools/2401.15391_MultiHop-RAG", "zzz_paper_pools/2405.16506_GRAG", "zzz_paper_pools/2407.01178_Memory3", "zzz_paper_pools/2505.14683", "zzz_paper_pools/2507.03724_MemOS"], "filenames": ["0normal.rst", "0normals/normal.rst", "0normals/website.md", "Agent.rst", "Agents/AGIs/1905.10985_AI-GA.rst", "Agents/AGIs/2408.06292_AI-Scientist.rst", "Agents/Agent_Visions/2108.03353_Screen2Words.md", "Agents/Agent_Visions/2209.08199_ScreenQA.rst", "Agents/Agent_Visions/2212.06817_RT-1.rst", "Agents/Agent_Visions/2312.13771_AppAgent.rst", "Agents/Agent_Visions/2401.10935_SeeClick.rst", "Agents/Agent_Visions/2402.04615_ScreenAI.rst", "Agents/Agent_Visions/2402.07939_UFO.md", "Agents/Agent_Visions/2403.16971_AIOS.md", "Agents/Agent_Visions/2406.01014_Mobile-Agent-v2.rst", "Agents/Agent_Visions/2411.02059_TableGPT2.rst", "Agents/Agent_Visions/2501.11733_Mobile-Agent-E.md", "Agents/Agent_Visions/2501.12326_UI-TARS.rst", "Agents/Agent_Visions/2502.14282_PC-Agent.md", "Agents/Agent_Visions/2504.14603_UFO2.md", "Agents/Agent_normals/2210.03629_ReAct.rst", "Agents/Agent_normals/2303.08268_Chat-with-the-Environment.rst", "Agents/Agent_normals/2303.11366_Reflexion.rst", "Agents/Agent_normals/2303.16434_TaskMatrix.AI.rst", "Agents/Agent_normals/2304.03442_Generative-Agents.rst", "Agents/Agent_normals/2307.07924_ChatDev.rst", "Agents/Agent_normals/2308.00352_MetaGPT.rst", "Agents/Agent_normals/2308.04026_AgentSims.rst", "Agents/Agent_normals/2308.08155_AutoGen.rst", "Agents/Agent_normals/2308.10848_AgentVerse.rst", "Agents/Agent_normals/2310.06117_Step-Back.rst", "Agents/Agent_normals/2402.18679_MetaGPT_DI.rst", "Agents/Agent_normals/2407.07061_IoA.rst", "Agents/Agent_normals/2408.08435_ADAS.rst", "Agents/Agent_normals/2410.10762_AFlow.rst", "Agents/Agent_normals/2410.17238_SELA.rst", "Agents/Agent_normals/2410.21012_FACT.rst", "Agents/Agent_normals/2504.01990_foundation-agents.md", "Agents/Agent_normals/2506.12508_AgentOrchestra.md", "Agents/Memorys/2505.22101_MemOS.md", "Agents/Tools/2205.00445_MRKL.rst", "Agents/Tools/2302.04761_Toolformer.md", "Agents/Tools/2303.17580_HuggingGPT.rst", "Agents/Tools/2307.16789_ToolLLM.md", "Benchmarking.rst", "Benchmarkings/DS_Agents/2312.14033_T-Eval.md", "Benchmarkings/DS_Agents/2406.12045_\u03c4-bench.md", "Benchmarkings/DS_Agents/2506.07982_\ud835\udf0f\u00b2-Bench.md", "Benchmarkings/DS_Codes/2107.03374_HumanEval.md", "Benchmarkings/DS_Codes/2108.07732_MBPP.md", "Benchmarkings/DS_Codes/2310.06770_SWE-bench.md", "Benchmarkings/DS_Codes/2402.16694_HumanEval-XL.md", "Benchmarkings/DS_Codes/2403.07974_LiveCodeBench.md", "Benchmarkings/DS_Codes/2407.10499_CIBench.md", "Benchmarkings/DS_Codes/2410.03859_SWE-bench-Multimodal.md", "Benchmarkings/DS_Codes/2410.06992_SWE-Bench+.md", "Benchmarkings/DS_Codes/2501.01257_CodeForces.md", "Benchmarkings/DS_Images/2306.13394_MME.md", "Benchmarkings/DS_Images/2307.06281_MMBench.md", "Benchmarkings/DS_Images/2307.16125_SEED-Bench.md", "Benchmarkings/DS_Images/2311.12793_ShareGPT4V.md", "Benchmarkings/DS_Images/2506.18095_ShareGPT-4o-Image.md", "Benchmarkings/DS_LongCtxs/2402.05136_LV-Eval.md", "Benchmarkings/DS_LongCtxs/2402.17753_LoCoMo.md", "Benchmarkings/DS_LongCtxs/2404.06654_RULER.md", "Benchmarkings/DS_LongCtxs/2407.11963_NeedleBench.md", "Benchmarkings/DS_Maths/2103.03874_MATH.md", "Benchmarkings/DS_Maths/2110.14168_GSM8K.md", "Benchmarkings/DS_Maths/2405.12209_MathBench.md", "Benchmarkings/DS_QAs/1809.09600_HotpotQA.md", "Benchmarkings/DS_QAs/2109.07958_TruthfulQA.md", "Benchmarkings/DS_QAs/2311.12022_GPQA.md", "Benchmarkings/DS_QAs/2411.04368_SimpleQA.md", "Benchmarkings/Datasets/0normal.md", "Benchmarkings/Datasets/2009.03300_MMLU.md", "Benchmarkings/Datasets/2305.08322_C-Eval.md", "Benchmarkings/Datasets/2306.09212_CMMLU.md", "Benchmarkings/Datasets/2307.15020_SuperCLUE.md", "Benchmarkings/Datasets/2311.12983_GAIA.md", "Benchmarkings/Datasets/2404.07972_OSWorld.rst", "Benchmarkings/Datasets/2501.14249_HLE.md", "Benchmarkings/Standards/02xx.xxxxx_BLEU.md", "Benchmarkings/Standards/0401.xxxxx_ROUGE.md", "Benchmarkings/Standards/1803.01937_ROUGE2.md", "Benchmarkings/Standards/1804.08771_SacreBLEU.md", "Benchmarkings/Standards/2306.05685_LLM-as-a-Judge.md", "LLM.rst", "LLM_tech.rst", "LLM_techs/FineTunes/2101.00190_Prefix-Tuning.rst", "LLM_techs/FineTunes/2103.10385_p-tuning.rst", "LLM_techs/FineTunes/2104.08691_Prompt_Tuning.md", "LLM_techs/FineTunes/2106.09685_LoRA.rst", "LLM_techs/FineTunes/2401.01335_Self-Play.rst", "LLM_techs/FineTunes/2402.09353_DoRA.rst", "LLM_techs/FineTunes/2402.12354_LoRA+.rst", "LLM_techs/FineTunes/2403.03507_GaLore.rst", "LLM_techs/FineTunes/2403.13372_LlamaFactory.rst", "LLM_techs/Frameworks/1712.05889_Ray.rst", "LLM_techs/Frameworks/1910.02054_DeepSpeed_ZeRO.rst", "LLM_techs/Frameworks/19XX_PyTorch.rst", "LLM_techs/Frameworks/20XX_Transformers.rst", "LLM_techs/Frameworks/2210.XX_Ray_v2.rst", "LLM_techs/Frameworks/2309.06180_vLLM.rst", "LLM_techs/Parallelism/1701.06538_MoE.rst", "LLM_techs/Parallelism/1806.03377_PipeDream.rst", "LLM_techs/Parallelism/1811.06965_GPipe.rst", "LLM_techs/Parallelism/1909.08053_Megatron-LM.rst", "LLM_techs/Parallelism/1910_PipeDream2.rst", "LLM_techs/Parallelism/2006.09503_PipeDream-2BW.rst", "LLM_techs/Parallelism/2006.15704DataParallel.rst", "LLM_techs/Parallelism/2006.16668_GShard.rst", "LLM_techs/Parallelism/2104.04473_Megatron-LM2.rst", "LLM_techs/Parallelism/2205.14135_FlashAttention.rst", "LLM_techs/Parallelism/2307.08691_FlashAttention2.rst", "LLM_techs/Parallelism/normal.rst", "LLM_techs/Quantizations/0normal.md", "LLM_techs/Quantizations/2110.02861_bitsandbytes.md", "LLM_techs/Quantizations/2206.01861_ZeroQuant.md", "LLM_techs/Quantizations/2206.09557_LUT-GEMM.md", "LLM_techs/Quantizations/2208.07339_LLM.int8.md", "LLM_techs/Quantizations/2209.05433_FP8.md", "LLM_techs/Quantizations/2210.17323_GPTQ.md", "LLM_techs/Quantizations/2211.10438_SmoothQuant.md", "LLM_techs/Quantizations/2305.14314_QLoRA.md", "LLM_techs/Quantizations/2306.00978_AWQ.md", "LLM_techs/Quantizations/2309.05516_AutoRound.md", "LLM_techs/RLs/1703.03864_EvolutionStrategies.md", "LLM_techs/RLs/2504.02495_DeepSeek_GRM.rst", "LLM_techs/RLs/2504.13958_ToolRL.md", "LLM_techs/Securitys/2312.06674_Llama_Guard.md", "LLM_techs/others/2203.02155_InstructGPT.rst", "LLM_techs/others/2305.20050_LetsVerifyStepbyStep.rst", "LLM_techs/others/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.rst", "LLM_techs/others/2412.14135_Scaling_of_Search_and_Learning.rst", "LLMs/LLMAudio/2005.08100_Conformer.md", "LLMs/LLMAudio/2106.07447_HuBERT.md", "LLMs/LLMAudio/2112.02418_YourTTS.md", "LLMs/LLMAudio/2212.04356_whisper.md", "LLMs/LLMAudio/2301.02111_Vall-E.md", "LLMs/LLMAudio/2303.03926_VALL-E_X.md", "LLMs/LLMAudio/2406.05370_VALL-E2.md", "LLMs/LLMAudio/2407.05407_CosyVoice.md", "LLMs/LLMAudio/2407.10759_Qwen2-Audio.md", "LLMs/LLMAudio/2410.00037_Moshi.md", "LLMs/LLMAudio/2412.10117_CosyVoice2.md", "LLMs/LLMAudio/2501.06282_MinMo.md", "LLMs/LLMAudio/2505.02707_Voila.md", "LLMs/LLMAudio/2505.17589_CosyVoice3.md", "LLMs/LLMCommercials/2303.08774_GPT4.md", "LLMs/LLMCommercials/2312.11805_Gemini.md", "LLMs/LLMCommercials/2403.05530_Gemini1.5.md", "LLMs/LLMCommercials/2406.02430_Seed-TTS.md", "LLMs/LLMCommercials/2407.04675_Seed-ASR.md", "LLMs/LLMCommercials/2503.20020_Gemini2.md", "LLMs/LLMCommercials/2504.xxxxx_Seed-Thinking-v1.5.md", "LLMs/LLMCommercials/2505.07062_Seed1.5-VL.md", "LLMs/LLMMoEs/2408.15664_AUXILIARY-LOSS-FREE_LB.rst", "LLMs/LLMMoEs/2410.07490_MoDEM.rst", "LLMs/LLMMultimodals/2112.15093_CTR.md", "LLMs/LLMMultimodals/2304.08485_LLaVA.md", "LLMs/LLMMultimodals/2308.12966_Qwen-VL.rst", "LLMs/LLMMultimodals/2310.03744_LLaVA2.md", "LLMs/LLMMultimodals/2312.07533_VILA.md", "LLMs/LLMMultimodals/2403.05525_DeepSeek-VL.md", "LLMs/LLMMultimodals/2408.01800_MiniCPM-V.md", "LLMs/LLMMultimodals/2409.17146_Molmo_and_PixMo.md", "LLMs/LLMMultimodals/2410.13848_Janus.md", "LLMs/LLMMultimodals/2411.00774_Freeze-Omni.md", "LLMs/LLMMultimodals/2412.04468_NVILA.md", "LLMs/LLMMultimodals/2502.13923_Qwen2.5-VL.md", "LLMs/LLMMultimodals/2503.20215_Qwen2.5-Omni.md", "LLMs/LLMMultimodals/2506.13642_Stream-Omni.md", "LLMs/LLMMultimodals/2506.13642_Stream-Omni2.md", "LLMs/LLMVideos/2301.12597_BLIP-2.md", "LLMs/LLMVideos/2308.01390_OpenFlamingo.md", "LLMs/LLM_NLPs/1810.04805_BERT.rst", "LLMs/LLM_NLPs/18_GPT1.rst", "LLMs/LLM_NLPs/19_GPT2.rst", "LLMs/LLM_NLPs/2012.00413_CPM.md", "LLMs/LLM_NLPs/2302.13971_LLaMA.md", "LLMs/LLM_NLPs/2307.09288_Llama2.md", "LLMs/LLM_NLPs/2309.16609_Qwen.md", "LLMs/LLM_NLPs/2310.19341_Skywork.md", "LLMs/LLM_NLPs/2401.14196_DeepSeek-Coder.md", "LLMs/LLM_NLPs/2404.06395_MiniCPM.rst", "LLMs/LLM_NLPs/2405.04434_DeepSeek-V2.md", "LLMs/LLM_NLPs/2406.12793_ChatGLM.md", "LLMs/LLM_NLPs/2407.10671_Qwen2.md", "LLMs/LLM_NLPs/2412.15115_Qwen2.5.md", "LLMs/LLM_NLPs/2505.09388_Qwen3.md", "ML.rst", "MLs/MLVisions/1506.02640_YOLO.rst", "MLs/MLVisions/1612.08242_YOLO9000.rst", "MLs/MLVisions/1804.02767_YOLOv3.rst", "MLs/MLVisions/2004.10934_YOLOv4.rst", "MLs/MLVisions/2205.00159_SVTR.md", "MLs/MLVisions/2207.02696_YOLOv7.rst", "MLs/MLVisions/2303.05499_GroundingDINO.rst", "MLs/MLVisions/2304.08485_VisualInstructionTuning.rst", "MLs/MLVisions/2402.13616_YOLOv9.rst", "MLs/MLVisions/2405.14458_YOLOv10.rst", "MLs/MLVisions/2411.15858_SVTRv2.md", "MLs/ML_normals/2112.09332_WebGPT.rst", "MLs/ML_normals/2203.11147_GopherCite.rst", "MLs/ML_normals/2304.09848_Generative_Search.rst", "MLs/ML_normals/2305.14251_FActScore.md", "MLs/ML_normals/2305.14627_ALCE.rst", "MLs/ML_normals/2307.02185_Citation.rst", "MLs/ML_normals/2307.16883_HAGRID.rst", "RAG.rst", "RAGs/2005.11401_RAG_for_KI_NLP_task.md", "RAGs/2312.10997_RAG_for_LLM.rst", "RAGs/2401.15884_CRAG.rst", "RAGs/2403.14403_Adaptive-RAG.rst", "RAGs/2404.16130_GraphRAG.md", "RAGs/2405.16506_GRAG.rst", "RAGs/2406.13213_Multi-Meta-RAG.rst", "RAGs/2410.05779_LightRAG.md", "RAGs/2410.10450_KBLaM.rst", "RAGs/2504.03137_LightPROF.rst", "RAGs/graphrag.rst", "index.rst", "other.rst", "others/3D/2003.08934_NeRF.md", "others/3D/2203.08586_VanishingPointEstimation.md", "others/3D/2312.14132_DUSt3R.md", "others/3D/2406.09756_MASt3R.md", "others/3D/2412.09401_SLAM3R.md", "others/3D/2412.12392_MASt3R-SLAM.md", "others/3D/2503.11651_VGGT.md", "others/DataSets/1811.10959v3_Dataset_Distillation.rst", "others/DataSets/2502.20653_Dataset_Distillation.rst", "others/DataSets/normal.rst", "others/others/A PAINLESS GUIDE TO CRC ERROR DETECTION ALGORITHMS.rst", "others/others/Distributed Representations of Sentences and Documents.rst", "paper_pool.rst", "zzz_paper_pools/2305.16300.md", "zzz_paper_pools/2311.18743_AlignBench.md", "zzz_paper_pools/2401.15391_MultiHop-RAG.md", "zzz_paper_pools/2405.16506_GRAG.md", "zzz_paper_pools/2407.01178_Memory3.md", "zzz_paper_pools/2505.14683.md", "zzz_paper_pools/2507.03724_MemOS.md"], "titles": ["\u901a\u7528", "\u901a\u7528", "\u5b66\u672f\u7f51\u7ad9", "AI Agent", "1905.10985_AI-GA: AI-generating algorithms, an alternate paradigm for producing general artificial intelligence", "2408.06292_The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery", "2108.03353_ Screen2Words: Automatic Mobile UI Summarization with Multimodal Learning", "2209.08199_ScreenQA: Large-Scale Question-Answer Pairs over Mobile App Screenshots", "2212.06817_RT-1: ROBOTICS TRANSFORMER FOR REAL-WORLD CONTROL AT SCALE", "2312.13771_AppAgent: Multimodal Agents as Smartphone Users", "2401.10935_SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents", "2402.04615_ScreenAI: A Vision-Language Model for UI and Infographics Understanding", "2402.07939_UFO: A UI-Focused Agent for Windows OS Interaction", "2403.16971_AIOS: LLM Agent Operating System", "2406.01014_Mobile-Agent-v2: Mobile Device Operation Assistant with Effective Navigation via Multi-Agent Collaboration", "2411.02059_TableGPT2: A Large Multimodal Model with Tabular Data Integration", "2501.11733_Mobile-Agent-E: Self-Evolving Mobile Assistant for Complex Tasks", "2501.12326_UI-TARS: Pioneering Automated GUI Interaction with Native Agents", "2502.14282_PC-Agent: A Hierarchical Multi-Agent Collaboration Framework for Complex Task Automation on PC", "2504.14603_UFO2: The Desktop AgentOS", "2210.03629_ReAct", "2303.08268_Chat-with-the-Environment", "2303.11366_Reflexion: Language Agents with Verbal Reinforcement Learning", "2303.16434_TaskMatrix.AI", "2304.03442_Generative-Agents", "2307.07924_ChatDev: Communicative Agents for Software Development", "2308.00352_MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework", "2308.04026_AgentSims: An Open-Source Sandbox for Large Language Model Evaluation", "2308.08155_AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation", "2308.10848_AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors", "2310.06117_Step-Back: Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models", "2402.18679_MetaGPT_DI: Data Interpreter: An LLM Agent For Data Science", "2407.07061_IoA: Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence", "2408.08435_ADAS: Automated Design of Agentic Systems", "2408.08435_ADAS: Automating Agentic Workflow Generation", "2410.17238_SELA: Tree-Search Enhanced LLM Agents for Automated Machine Learning", "2410.21012_FACT: Examining the Effectiveness of Iterative Context Rewriting for Multi-fact Retrieval", "2504.01990_Advances and Challenges in Foundation Agents", "2506.12508_AgentOrchestra: A Hierarchical Multi-Agent Framework for General-Purpose Task Solving", "2505.22101_MemOS: An Operating System for Memory-Augmented Generation (MAG) in LLM (Short Version)", "2205.00445_MRKL", "2302.04761_Toolformer: Language Models Can Teach Themselves to Use Tools", "2303.17580_HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face", "2307.16789_ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs", "\u8bc4\u6d4b\u57fa\u51c6", "2312.14033_T-Eval: Evaluating the Tool Utilization Capability of Large Language Models Step by Step", "2406.12045_\u03c4-bench: A Benchmark for Tool-Agent-User", "2506.07982_\ud835\udf0f\u00b2-Bench: Evaluating Conversational Agents in a Dual-Control Environment", "2107.03374_HumanEval: Evaluating Large Language Models Trained on Code", "2108.07732_MBPP: Program Synthesis with Large Language Models", "2310.06770_SWE-bench: Can Language Models Resolve Real-World GitHub Issues?", "2402.16694_HumanEval-XL: A Multilingual Code Generation Benchmark for Cross-lingual Natural Language Generalization", "2403.07974_LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code", "2407.10499_CIBench: Evaluating Your LLMs with a Code Interpreter Plugin", "2410.03859_SWE-bench-Multimodal: Do AI Systems Generalize to Visual Software Domains?", "2410.06992_SWE-Bench+: Enhanced Coding Benchmark for LLMs", "2501.01257_CodeForces: Benchmarking Competition-level Code Generation of LLMs on CodeForces", "2306.13394_MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models", "2307.06281_MMBench: Is Your Multi-modal Model an All-around Player?", "2307.16125_SEED-Bench: Benchmarking Multimodal LLMs with Generative Comprehension", "2311.12793_ShareGPT4V: Improving Large Multi-Modal Models with Better Captions", "2506.18095_ShareGPT-4o-Image: Aligning Multimodal Models with GPT-4o-Level Image Generation", "2402.05136_LV-Eval: A Balanced Long-Context Benchmark with 5 Length Levels Up to 256K", "2402.17753_LoCoMo: Evaluating Very Long-Term Conversational Memory of LLM Agents", "2404.06654_RULER: What\u2019s the Real Context Size of Your Long-Context Language Models?", "2407.11963_NeedleBench: Can LLMs Do Retrieval and Reasoning in Information-Dense Context", "2103.03874_MATH: Measuring Mathematical Problem Solving With the MATH Dataset", "2110.14168_GSM8K: Training Verifiers to Solve Math Word Problems", "2405.12209_MathBench: Evaluating the Theory and Application Proficiency of LLMs with a Hierarchical Mathematics Benchmark", "1809.09600_HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering", "2109.07958_TruthfulQA: Measuring How Models Mimic Human Falsehoods", "2311.12022_GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark", "2411.04368_SimpleQA: Measuring short-form factuality in large language models", "\u901a\u7528", "2009.03300_MMLU: Measuring Massive Multitask Language Understanding", "2305.08322_C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models", "2306.09212_CMMLU: Measuring massive multitask language understanding in Chinese", "2307.15020_SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark", "2311.12983_GAIA: a benchmark for General AI Assistants", "2404.07972_OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments", "2501.14249_HLE: Humanity\u2019s Last Exam", "02xx.xxxxx_BLEU: a Method for Automatic Evaluation of Machine Translation", "0401.xxxxx_ROUGE: A Package for Automatic Evaluation of Summaries", "1803.01937_ROUGE2.0: Updated and Improved Measures for Evaluation of Summarization Tasks", "1804.08771_SacreBLEU: A Call for Clarity in Reporting BLEU Scores", "2306.05685_Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena", "LLM \u6a21\u578b", "LLM \u5468\u8fb9\u6280\u672f", "2101.00190_Prefix-Tuning: Optimizing Continuous Prompts for Generation", "2103.10385_p-tuning: GPT Understands, Too", "2104.08691_Prompt Tuning: The Power of Scale for Parameter-Efficient Prompt Tuning", "2106.09685_LoRA: Low-Rank Adaptation of Large Language Models", "2401.01335_Self-Play: Fine-Tuning Converts Weak Language Models to Strong Language Models", "2402.09353_DoRA: Weight-Decomposed Low-Rank Adaptation", "2402.12354_LoRA+: Efficient Low Rank Adaptation of Large Models", "2403.03507_GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection", "2403.13372_LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models", "1712.05889_Ray: A Distributed Framework for Emerging AI Applications", "1910.02054_DeepSpeed_ZeRO: Memory Optimizations Toward Training Trillion Parameter Models", "PyTorch: An Imperative Style, High-Performance Deep Learning Library", "Transformers: State-of-the-Art Natural Language Processing", "2210.XX_Ray v2 Architecture", "2309.06180_vLLM: Efficient Memory Management for Large Language Model Serving with PagedAttention", "1701.06538_MoE: Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer", "1806.03377_PipeDream: Fast and Efficient Pipeline Parallel DNN Training", "1811.06965_GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism", "1909.08053_Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism", "19xx_PipeDream: Generalized Pipeline Parallelism for DNN Training", "2006.09503_PipeDream-2BW: Memory-Efficient Pipeline-Parallel DNN Training", "2006.15704_PyTorch Distributed: Experiences on Accelerating Data Parallel Training", "2006.16668_GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding", "2104.04473_Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM", "2205.14135_FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness", "2307.08691_FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning", "\u901a\u7528", "\u901a\u7528", "2110.02861_bitsandbytes: 8-bit Optimizers via Block-wise Quantization", "2206.01861_ZeroQuant: Efficient and Affordable Post-Training Quantization for Large-Scale Transformers", "2206.09557_LUT-GEMM: Quantized Matrix Multiplication based on LUTs for Efficient Inference in Large-Scale Generative Language Models", "2208.07339_LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale", "2209.05433_FP8: FP8 Formats For Deep Learning", "2210.17323_GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers", "2211.10438_SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models", "2305.14314_QLoRA: Efficient Finetuning of Quantized LLMs", "2306.00978_AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration", "2309.05516_AutoRound: Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs", "1703.03864_Evolution Strategies: as a Scalable Alternative to Reinforcement Learning", "2504.02495_DeepSeek-GRM: Inference-Time Scaling for Generalist Reward Modeling", "2504.13958_ToolRL: Reward is All Tool Learning Needs", "2312.06674_Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations", "2203.02155_Training language models to follow instructions with human feedback(InstructGPT)", "2305.20050_Let\u2019s Verify Step by Step", "2408.03314_Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters", "2412.14135_Scaling of Search and Learning: A Roadmap to Reproduce o1 from Reinforcement Learning Perspective", "2005.08100_Conformer: Convolution-augmented Transformer for Speech Recognition", "2106.07447_HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units", "2112.02418_YourTTS: Towards Zero-Shot Multi-Speaker TTS and Zero-Shot Voice Conversion for everyone", "2212.04356_whisper: Robust Speech Recognition via Large-Scale Weak Supervision", "2301.02111_Vall-E: Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers", "2303.03926_VALL-E_X: Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural Codec Language Modeling", "2406.05370_VALL-E2: Neural Codec Language Models are Human Parity Zero-Shot Text to Speech Synthesizers", "2407.05407_CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens", "2407.10759_Qwen2-Audio Technical Report", "2410.00037_Moshi: a speech-text foundation model for real-time dialogue", "2412.10117_CosyVoice2: Scalable Streaming Speech Synthesis with Large Language Models", "2501.06282_MinMo: A Multimodal Large Language Model for Seamless Voice Interaction", "2505.02707_Voila: Voice-Language Foundation Models for Real-Time Autonomous Interaction and Voice Role-Play", "2505.17589_CosyVoice3: Towards In-the-wild Speech Generation via Scaling-up and Post-training", "2303.08774_GPT-4 Technical Report", "2312.11805_Gemini: A Family of Highly Capable Multimodal Models", "2403.05530_Gemini1.5: Unlocking multimodal understanding across millions of tokens of context", "2406.02430_Seed-TTS: A Family of High-Quality Versatile Speech Generation Models", "2407.04675_Seed-ASR: Understanding Diverse Speech and Contexts with LLM-based Speech Recognition", "2503.20020_Gemini2: Gemini Robotics: Bringing AI into the Physical World", "2504.xxxxx_Seed-Thinking-v1.5: Advancing Superb Reasoning Models with Reinforcement Learning", "2505.07062_Seed1.5-VL Technical Report", "2408.15664_AUXILIARY-LOSS-FREE LOAD BALANCING STRATEGY FOR MIXTURE-OF-EXPERTS", "2410.07490_MoDEM: Mixture of Domain Expert Models", "2112.15093_CTR: Benchmarking Chinese Text Recognition: Datasets, Baselines, and an Empirical Study", "2304.08485_LLaVA: Visual Instruction Tuning", "2308.12966_Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond", "2310.03744_LLaVA2: Improved Baselines with Visual Instruction Tuning", "2312.07533_VILA: On Pre-training for Visual Language Models", "2403.05525_DeepSeek-VL: Towards Real-World Vision-Language Understanding", "2408.01800_MiniCPM-V: A GPT-4V Level MLLM on Your Phone", "2409.17146_Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Vision-Language Models", "2410.13848_Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation", "2411.00774_Freeze-Omni: A Smart and Low Latency Speech-to-speech Dialogue Model with Frozen LLM", "2412.04468_NVILA: Efficient Frontier Visual Language Models", "2502.13923_Qwen2.5-VL", "2503.20215_Qwen2.5-Omni Technical Report", "2506.13642_Stream-Omni: Simultaneous Multimodal Interactions with Large Language-Vision-Speech Model", "2506.13642_Stream-Omni: Simultaneous Multimodal Interactions with Large Language-Vision-Speech Model", "2301.12597_BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models", "2308.01390_OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models", "1810.04805_BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "18xx_GPT1: Improving Language Understanding by Generative Pre-Training", "19xx_GPT2: Language Models are Unsupervised Multitask Learners", "2012.00413_CPM: A Large-scale Generative Chinese Pre-trained Language Model", "2302.13971_LLaMA: Open and Efficient Foundation Language Models", "2307.09288_Llama 2: Open Foundation and Fine-Tuned Chat Models", "2309.16609_Qwen Technical Report", "2310.19341_Skywork: A More Open Bilingual Foundation Model", "2401.14196_DeepSeek-Coder: When the Large Language Model Meets Programming \u2013 The Rise of Code Intelligence", "2404.06395_MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies", "2405.04434_DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model", "2406.12793_ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools", "2407.10671_Qwen2 Technical Report", "2412.15115_Qwen2.5", "2505.09388_Qwen3", "\u673a\u5668\u5b66\u4e60", "1506.02640_You Only Look Once: Unified, Real-Time Object Detection", "1612.08242_YOLO9000: Better, Faster, Stronger", "1804.02767_YOLOv3", "2004.10934_YOLOv4: Optimal Speed and Accuracy of Object Detection", "2205.00159_SVTR: Scene Text Recognition with a Single Visual Model", "2207.02696_YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors", "Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection", "2304.08485_Visual Instruction Tuning", "2402.13616_YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information", "2405.14458_YOLOv10: Real-Time End-to-End Object Detection", "2411.15858_SVTRv2: CTC Beats Encoder-Decoder Models in Scene Text Recognition", "2112.09332_WebGPT: Browser-assisted question-answering with human feedback", "2203.11147_GopherCite: Teaching language models to support answers with verified quotes", "2304.09848_Generative_Search: Evaluating Verifiability in Generative Search Engines", "2305.14251_FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation", "2305.14627_ALCE: Enabling Large Language Models to Generate Text with Citations", "2307.02185_Citation: A Key to Building Responsible and Accountable Large Language Models", "2307.16883_HAGRID: A Human-LLM Collaborative Dataset for Generative Information-Seeking with Attribution", "RAG", "2005.11401_Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks", "2312.10997_Retrieval-Augmented Generation for Large Language Models: A Survey", "2401.15884_CRAG: Corrective Retrieval Augmented Generation", "2403.14403_Adaptive-RAG", "2404.16130_GraphRAG: From Local to Global: A GraphRAG Approach to Query-Focused Summarization", "2405.16506_GRAG: Graph Retrieval-Augmented Generation", "2406.13213_Multi-Meta-RAG: Improving RAG for Multi-Hop Queries using Database Filtering with LLM-Extracted Metadata", "2410.05779_LightRAG: Simple and Fast Retrieval-Augmented Generation", "2410.10450_KBLaM: Knowledge Base augmented Language Model", "2504.03137_LightPROF: A Lightweight Reasoning Framework for Large Language Model on Knowledge Graph", "GraphRAG \u5b98\u65b9\u6587\u6863", "\u8bba\u6587", "\u5176\u4ed6", "2003.08934_NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis", "2203.08586: Deep vanishing point detection: Geometric priors make dataset variations vanish", "2312.14132_DUSt3R: Geometric 3D Vision Made Easy", "2406.09756_MASt3R: Grounding Image Matching in 3D with MASt3R", "2412.09401_SLAM3R: Real-Time Dense Scene Reconstruction from Monocular RGB Videos", "2412.12392_MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors", "2503.11651_VGGT: Visual Geometry Grounded Transformer", "1811.10959v3_Dataset Distillation", "2502.20653_Dataset Distillation with Neural Characteristic Function: A Minmax Perspective", "\u901a\u7528", "A PAINLESS GUIDE TO CRC ERROR DETECTION ALGORITHMS", "Distributed Representations of Sentences and Documents", "\u8bba\u6587\u6c60", "2305.16300_Random-Access Infinite Context Length for Transformers", "2311.18743_AlignBench: Benchmarking Chinese Alignment of Large Language Models", "2401.15391_MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries", "2405.16506_GRAG: Graph Retrieval-Augmented Generation", "2407.01178_Memory3: Language Modeling with Explicit Memory", "2505.14683_Emerging Properties in Unified Multimodal Pretraining", "MemOS: A Memory OS for AI System"], "terms": {"https": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242], "www": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 14, 15, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 40, 42, 44, 50, 54, 79, 82, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 127, 130, 131, 132, 133, 140, 156, 157, 160, 175, 176, 177, 184, 190, 191, 192, 193, 194, 196, 197, 198, 199, 200, 202, 203, 204, 206, 207, 208, 209, 211, 212, 213, 215, 216, 218, 219, 220, 221, 222, 230, 231, 232, 233, 234, 235], "zhaoweiguo": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 14, 15, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 40, 41, 42, 44, 79, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 127, 130, 131, 132, 133, 156, 157, 160, 175, 176, 177, 184, 190, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 209, 211, 212, 213, 215, 216, 218, 219, 220, 221, 222, 230, 231, 232, 233, 234, 235], "com": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 70, 71, 72, 74, 75, 79, 80, 82, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 121, 122, 123, 124, 125, 127, 128, 130, 131, 132, 133, 136, 137, 138, 139, 140, 141, 142, 143, 144, 146, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 167, 168, 169, 170, 171, 174, 175, 176, 177, 178, 181, 182, 183, 184, 185, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 237, 242], "citat": [1, 11, 130, 190, 203, 204, 207, 208], "googl": [1, 6, 7, 8, 10, 11, 16, 24, 30, 36, 44, 46, 52, 65, 69, 79, 101, 103, 105, 110, 115, 130, 132, 146, 149, 152, 168, 169, 175, 195, 204, 210, 211, 212, 224, 226, 227, 238], "scholar": [1, 5, 16, 97, 130, 210, 211, 224, 226, 227], "semant": [1, 5, 13, 39, 86, 133, 139, 162, 176, 211, 214], "web": [1, 3, 7, 10, 16, 17, 54, 78, 79, 96, 101, 143, 145, 167, 171, 172, 201, 202, 207, 211, 212], "of": [1, 3, 4, 5, 6, 14, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 35, 38, 39, 40, 41, 42, 43, 44, 47, 51, 53, 54, 57, 60, 61, 62, 67, 71, 77, 80, 86, 87, 88, 89, 97, 104, 106, 107, 108, 111, 113, 115, 116, 117, 119, 124, 130, 131, 132, 137, 138, 139, 140, 141, 142, 144, 145, 146, 154, 159, 161, 162, 164, 168, 169, 173, 176, 178, 181, 182, 187, 188, 189, 190, 191, 192, 193, 197, 199, 200, 202, 203, 204, 206, 207, 208, 212, 213, 214, 216, 217, 219, 221, 222, 223, 224, 225, 226, 228, 229, 231, 233, 235, 240, 241], "scienc": [1, 3, 4, 33, 53, 60, 75, 76, 82, 118, 130, 149, 159, 171, 189, 242], "impact": [1, 11, 16, 137, 138, 200, 208, 214, 224, 226], "factor": [1, 122, 133, 206, 214, 218], "neurip": [1, 79, 99, 112], "iclr": [1, 79], "cvpr": [1, 229], "transform": [1, 3, 5, 6, 11, 19, 39, 48, 49, 58, 60, 62, 64, 67, 75, 76, 77, 79, 86, 87, 88, 91, 96, 105, 112, 113, 115, 116, 118, 120, 123, 125, 135, 137, 138, 139, 140, 144, 145, 146, 149, 151, 155, 160, 162, 165, 166, 167, 169, 170, 171, 172, 173, 177, 181, 182, 187, 188, 195, 196, 197, 199, 201, 207, 208, 211, 218, 219, 221, 222, 223, 225, 227, 235, 240, 242], "openai": [1, 14, 19, 27, 43, 45, 46, 47, 48, 50, 51, 56, 63, 65, 66, 67, 70, 71, 72, 74, 76, 78, 85, 126, 127, 130, 133, 137, 148, 155, 160, 165, 167, 168, 170, 176, 177, 181, 188, 189, 202, 214, 218, 242], "deepmind": [1, 8, 11, 24, 30, 132, 149, 174, 203], "ai": [2, 6, 7, 8, 10, 11, 12, 14, 17, 19, 29, 32, 33, 38, 39, 40, 41, 43, 44, 45, 46, 48, 50, 53, 56, 57, 58, 59, 60, 61, 62, 65, 67, 68, 69, 70, 72, 74, 75, 76, 79, 80, 85, 86, 87, 96, 115, 116, 119, 123, 124, 127, 130, 131, 132, 136, 137, 138, 140, 143, 149, 151, 155, 159, 161, 163, 164, 165, 166, 168, 173, 174, 175, 181, 182, 183, 185, 187, 197, 214, 218, 220, 221, 230, 235, 237, 238], "springer": 2, "ieee": [2, 120], "semanticscholar": 2, "org": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 89, 90, 92, 94, 95, 96, 97, 98, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 166, 167, 168, 169, 170, 171, 173, 174, 175, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 223, 224, 225, 226, 227, 228, 229, 230, 231, 234, 236, 237, 238, 239, 240, 241, 242], "webofsci": 2, "xueshu": 2, "baidu": [2, 51], "doi": [2, 81, 107, 115], "se": 2, "http": [2, 8, 10, 23, 43, 82, 101, 105, 204], "rs": [2, 65], "open": [2, 3, 7, 8, 13, 14, 16, 18, 28, 31, 44, 45, 53, 54, 58, 63, 65, 71, 86, 96, 123, 130, 143, 146, 164, 170, 172, 181, 187, 189, 190, 203, 204, 208, 213, 214], "access": [2, 7, 11, 17, 18, 19, 24, 47, 75, 79, 112, 124, 208, 221, 235], "oa": [2, 224], "emnlp": [2, 100], "nlp": [2, 8, 27, 40, 50, 51, 56, 60, 67, 70, 74, 75, 77, 84, 91, 98, 105, 106, 112, 116, 117, 135, 137, 143, 159, 175, 176, 178, 182, 202, 209, 211, 219, 221, 229, 237, 242], "associ": [2, 11, 191, 204, 214, 225], "for": [2, 3, 5, 6, 7, 13, 14, 17, 21, 22, 24, 28, 29, 33, 34, 40, 41, 42, 44, 47, 60, 62, 71, 74, 80, 85, 86, 87, 89, 91, 96, 98, 101, 104, 105, 106, 111, 112, 113, 115, 131, 139, 142, 152, 161, 164, 168, 170, 176, 178, 184, 187, 189, 190, 192, 194, 195, 199, 200, 201, 203, 204, 205, 206, 207, 209, 212, 213, 214, 221, 222, 225, 226, 228, 229, 231, 232, 233, 235, 240], "comput": [2, 4, 8, 13, 16, 17, 22, 24, 28, 44, 48, 87, 104, 105, 106, 107, 111, 112, 113, 116, 119, 122, 130, 159, 164, 169, 175, 184, 200, 205, 213, 218, 224, 225, 232], "linguist": [2, 22, 25, 40, 143, 201], "naacl": 2, "cole": 2, "1965": 2, "ijcnlp": 2, "llm": [2, 3, 5, 7, 9, 10, 16, 17, 19, 21, 22, 24, 25, 26, 27, 32, 33, 34, 36, 38, 40, 41, 42, 44, 45, 49, 51, 53, 54, 55, 56, 61, 62, 65, 68, 71, 72, 75, 76, 78, 80, 96, 121, 123, 125, 127, 133, 141, 143, 144, 145, 146, 147, 155, 160, 161, 164, 165, 168, 169, 170, 171, 172, 173, 184, 187, 188, 189, 190, 205, 209, 217, 220, 221, 229, 237, 238, 239], "2023": [2, 7, 10, 11, 16, 17, 21, 23, 26, 27, 33, 50, 52, 54, 55, 56, 63, 72, 77, 85, 96, 127, 133, 143, 160, 170, 174, 181, 182, 184, 214, 218, 237, 238], "2022": [2, 7, 8, 10, 11, 33, 45, 50, 54, 56, 96, 102, 112, 115, 127, 130, 137, 143, 170, 218], "machin": [2, 3, 4, 5, 8, 31, 32, 33, 42, 44, 48, 53, 79, 101, 102, 107, 115, 116, 175, 211, 240], "translat": [2, 11, 41, 44, 48, 57, 102, 116, 130, 142, 170, 175, 188, 211, 225, 229], "summar": [2, 3, 10, 11, 16, 42, 44, 82, 88, 118, 130, 149, 206, 209, 211, 221], "bleu": [2, 44, 48, 59, 63, 69, 77, 85, 120, 139, 149, 173, 211, 242], "roug": [2, 7, 53, 59, 63, 69, 77, 85, 211, 214, 242], "gpt": [2, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 22, 34, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 67, 68, 71, 72, 74, 76, 78, 79, 85, 86, 87, 88, 90, 91, 96, 98, 106, 108, 112, 113, 115, 116, 118, 119, 120, 121, 122, 123, 124, 127, 133, 137, 138, 143, 145, 146, 147, 148, 149, 152, 155, 161, 165, 166, 167, 168, 169, 170, 171, 172, 174, 178, 181, 187, 188, 189, 202, 205, 208, 211, 214, 217, 219, 220, 229, 236, 237, 240, 241], "preprint": 2, "ginsparg": 2, "1991": 2, "lanl": 2, "1999": [2, 32, 226], "2015": [2, 175, 195, 230], "100": [2, 8, 10, 12, 24, 48, 49, 50, 52, 54, 56, 59, 61, 64, 65, 67, 68, 69, 70, 74, 80, 82, 85, 87, 97, 101, 105, 119, 122, 124, 130, 133, 135, 136, 143, 146, 147, 151, 155, 160, 165, 170, 188, 195, 201, 211, 214, 217, 218, 223, 225, 226, 229, 230, 231, 236, 241], "8000": [2, 182], "250": [2, 13, 17, 69, 70, 76, 81, 124, 143, 236], "2004": [2, 82, 190, 226], "net": [2, 39, 54, 66, 71, 72, 74, 79, 134, 170, 233, 242], "wanfangdata": 2, "cn": [2, 58, 65, 74, 155, 170, 182, 197], "index": [2, 45, 79, 127, 143, 214, 233], "html": [2, 10, 17, 43, 50, 52, 54, 56, 65, 75, 79, 85, 99, 112, 128, 130, 133, 155, 157, 160, 165, 168, 169, 182, 212, 225], "2210": [3, 87], "03629_react": 3, "2303": [3, 86, 197], "08268_chat": 3, "with": [3, 4, 7, 10, 11, 18, 19, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 40, 41, 43, 44, 45, 46, 47, 56, 64, 65, 70, 75, 78, 79, 86, 87, 88, 89, 90, 91, 96, 97, 101, 104, 105, 106, 107, 111, 116, 118, 119, 120, 122, 132, 133, 138, 159, 160, 164, 165, 168, 170, 175, 178, 181, 189, 190, 192, 196, 199, 200, 204, 205, 207, 209, 211, 212, 213, 214, 221, 222, 224, 227, 229, 232, 235, 236], "the": [3, 4, 5, 6, 7, 11, 14, 16, 17, 18, 20, 22, 24, 25, 27, 28, 29, 31, 32, 33, 34, 35, 39, 40, 41, 42, 43, 44, 46, 47, 50, 52, 53, 56, 57, 60, 61, 62, 67, 71, 72, 74, 78, 79, 80, 82, 85, 86, 87, 88, 89, 91, 96, 97, 101, 102, 104, 106, 107, 108, 111, 112, 113, 115, 117, 118, 119, 120, 122, 124, 127, 131, 135, 137, 138, 139, 140, 141, 142, 144, 145, 146, 151, 152, 154, 158, 159, 160, 161, 162, 164, 167, 168, 169, 170, 173, 176, 178, 181, 182, 187, 188, 189, 190, 191, 192, 193, 194, 197, 199, 200, 202, 203, 204, 205, 206, 207, 208, 211, 212, 213, 214, 216, 219, 223, 224, 225, 227, 228, 229, 230, 231, 232, 238, 240], "environ": [3, 4, 18, 20, 22, 24, 27, 32, 44, 97, 202, 211, 218], "11366_reflexion": 3, "languag": [3, 5, 6, 7, 8, 14, 20, 21, 24, 25, 26, 28, 29, 31, 32, 33, 36, 40, 42, 44, 47, 54, 58, 75, 79, 84, 86, 87, 88, 89, 90, 113, 116, 120, 127, 147, 151, 152, 159, 167, 169, 170, 181, 190, 195, 197, 205, 208, 209, 212, 213, 216, 221, 235], "verbal": 3, "reinforc": [3, 86, 87, 97, 130, 151, 152, 189, 203], "learn": [3, 4, 5, 7, 11, 16, 25, 31, 33, 42, 43, 48, 53, 74, 79, 86, 87, 88, 90, 96, 112, 115, 130, 131, 139, 152, 169, 170, 173, 174, 176, 178, 184, 189, 190, 191, 202, 203, 211, 214, 218, 219, 223, 226, 230, 240], "16434_taskmatrix": 3, "2304": [3, 86, 130, 165, 190], "03442_gener": 3, "2307": [3, 44, 86, 87, 190], "07924_chatdev": 3, "communic": [3, 5, 18, 24, 32, 47, 104, 106, 107, 111, 113], "softwar": [3, 18, 24, 26, 44, 55, 120, 136, 218], "develop": [3, 5, 6, 13, 28, 32, 33, 45, 75, 79, 124, 152, 175, 181, 184, 189, 199, 204, 206, 207, 208, 211, 218], "2308": [3, 86], "00352_metagpt": 3, "meta": [3, 4, 33, 41, 46, 52, 54, 62, 76, 78, 133, 187, 209, 221], "program": [3, 25, 28, 33, 44, 50, 86, 105, 107], "multi": [3, 6, 7, 12, 25, 32, 44, 45, 52, 80, 82, 84, 86, 87, 111, 112, 133, 134, 152, 165, 195, 209, 213, 214, 218, 219, 221, 226, 228, 235, 237], "collabor": [3, 16, 25, 37, 145, 187, 190], "framework": [3, 5, 10, 22, 25, 28, 29, 32, 33, 34, 35, 40, 45, 50, 63, 65, 75, 86, 158, 164, 169, 209, 211, 213, 221, 228], "04026_agentsim": 3, "an": [3, 5, 7, 8, 11, 13, 16, 17, 18, 20, 21, 22, 24, 26, 28, 29, 32, 33, 34, 35, 36, 40, 42, 43, 44, 45, 46, 47, 50, 53, 60, 61, 63, 78, 79, 81, 86, 87, 89, 91, 97, 104, 105, 106, 107, 118, 120, 125, 127, 130, 138, 139, 140, 141, 143, 144, 151, 161, 164, 165, 170, 175, 184, 189, 191, 197, 199, 201, 203, 205, 206, 208, 212, 214, 216, 218, 223, 225, 226, 227, 228, 229, 230], "sourc": [3, 5, 22, 28, 31, 40, 50, 54, 58, 68, 79, 86, 137, 139, 145, 162, 164, 181, 189, 204, 205, 206, 207, 208, 214, 216, 218], "sandbox": [3, 24, 47], "larg": [3, 5, 6, 14, 21, 22, 24, 25, 26, 29, 31, 32, 36, 40, 42, 44, 58, 61, 75, 86, 87, 88, 90, 96, 101, 106, 112, 116, 130, 134, 135, 142, 143, 147, 151, 152, 158, 159, 160, 166, 169, 170, 175, 176, 184, 190, 194, 195, 199, 203, 205, 208, 209, 212, 213, 216, 218, 221, 225, 226, 228, 229, 230, 232, 235, 238], "model": [3, 5, 7, 14, 18, 20, 21, 22, 23, 24, 25, 26, 29, 31, 32, 33, 34, 35, 36, 40, 42, 44, 47, 63, 71, 74, 79, 80, 86, 87, 88, 89, 90, 105, 113, 114, 116, 119, 120, 123, 155, 159, 170, 175, 176, 189, 190, 191, 192, 194, 197, 199, 200, 202, 205, 208, 209, 212, 213, 216, 220, 221, 226, 227, 229, 230, 232, 235, 238], "evalu": [3, 5, 6, 11, 18, 22, 24, 29, 31, 33, 34, 35, 43, 44, 64, 79, 84, 96, 105, 127, 133, 142, 145, 164, 190, 191, 197, 202, 203, 206, 208, 212, 230, 231, 238], "08155_autogen": 3, "enabl": [3, 5, 11, 24, 29, 33, 34, 35, 36, 39, 47, 105, 106, 112, 120, 132, 138, 143, 146, 165, 169, 189, 190, 211, 216, 218], "next": [3, 16, 24, 29, 32, 33, 54, 79, 97, 130, 164, 166, 170, 174, 175, 181, 208, 227, 233, 236, 241], "gen": [3, 164, 166], "applic": [3, 7, 10, 11, 12, 13, 14, 18, 24, 44, 61, 75, 79, 87, 106, 113, 124, 138, 168, 184, 194, 211, 216, 226, 229], "via": [3, 8, 25, 39, 41, 47, 60, 61, 75, 86, 87, 105, 127, 130, 146, 203, 205, 214, 216, 218, 225, 228], "convers": [3, 24, 44, 54, 86, 87, 96, 127, 130, 146, 151, 159, 178], "10848_agentvers": 3, "facilit": [3, 13, 25, 32, 35, 79, 96, 160, 169, 178, 199], "and": [3, 4, 5, 6, 14, 18, 20, 22, 25, 26, 27, 28, 30, 31, 33, 34, 36, 39, 40, 41, 43, 44, 45, 46, 47, 50, 56, 57, 60, 62, 63, 71, 74, 80, 82, 84, 86, 87, 88, 89, 90, 91, 108, 111, 116, 120, 125, 131, 132, 139, 140, 141, 142, 159, 161, 162, 164, 168, 169, 170, 176, 177, 178, 181, 184, 187, 189, 190, 191, 192, 196, 197, 199, 200, 202, 203, 204, 205, 206, 208, 209, 212, 213, 216, 219, 221, 222, 223, 231, 232, 233], "explor": [3, 18, 33, 34, 35, 39, 79, 90, 132, 184, 200, 207, 211, 229], "emerg": [3, 24, 39, 87, 200, 206, 211, 213], "behavior": [3, 8, 17, 24, 28, 39, 127, 130, 189, 202, 223, 242], "2310": [3, 44, 86], "06117_step": 3, "back": [3, 10, 16, 31, 48, 105, 112, 130, 188, 226], "take": [3, 5, 10, 22, 79, 96, 104, 107, 108, 113, 130, 139, 214, 218, 225, 227, 228], "step": [3, 10, 11, 12, 14, 16, 17, 18, 32, 33, 42, 44, 53, 61, 68, 78, 79, 87, 88, 97, 101, 118, 121, 125, 127, 130, 132, 133, 134, 140, 141, 143, 158, 162, 165, 175, 211, 213, 214, 218, 219, 226, 227, 233], "evok": 3, "reason": [3, 7, 13, 16, 20, 22, 29, 31, 33, 40, 42, 43, 44, 46, 47, 53, 57, 58, 63, 69, 75, 78, 79, 86, 111, 127, 149, 159, 162, 170, 176, 209, 211, 214, 216, 218, 221, 226], "abstract": [3, 99], "in": [3, 4, 5, 6, 7, 8, 13, 14, 18, 20, 22, 24, 25, 27, 28, 29, 31, 32, 33, 34, 36, 40, 41, 44, 45, 46, 52, 53, 54, 56, 58, 60, 61, 62, 63, 67, 69, 70, 71, 74, 75, 78, 80, 82, 86, 87, 88, 89, 90, 91, 96, 101, 105, 107, 108, 111, 112, 113, 115, 122, 124, 125, 127, 130, 131, 132, 135, 137, 139, 143, 144, 145, 146, 158, 159, 160, 162, 164, 165, 167, 168, 169, 170, 171, 174, 175, 176, 178, 182, 184, 187, 189, 190, 191, 192, 193, 195, 196, 197, 199, 200, 202, 203, 206, 207, 208, 212, 213, 214, 216, 218, 219, 221, 222, 223, 224, 225, 227, 228, 229, 230, 231, 232, 233, 235, 239, 240], "2402": [3, 44, 87, 190], "18679_metagpt_di": 3, "data": [3, 6, 14, 17, 43, 47, 53, 61, 62, 74, 76, 86, 87, 88, 91, 97, 101, 105, 107, 111, 114, 127, 137, 139, 155, 158, 162, 164, 176, 178, 184, 187, 188, 192, 194, 197, 199, 200, 211, 214, 218, 224, 229, 231, 232], "interpret": [3, 13, 44, 48, 68, 78, 218, 224], "2407": [3, 44, 86, 221, 235], "07061_ioa": 3, "internet": [3, 58, 79, 218], "weav": 3, "heterogen": [3, 39, 97, 101], "intellig": [3, 5, 33, 35, 37, 42, 50, 53, 54, 62, 86, 241], "2408": [3, 86, 87], "08435_ada": 3, "autom": [3, 7, 11, 12, 26, 104, 107, 187, 205, 218, 226], "design": [3, 4, 5, 11, 13, 14, 25, 31, 32, 40, 61, 62, 65, 96, 130, 140, 143, 160, 165, 169, 175, 193, 199, 200, 211, 212, 218, 228, 232], "system": [3, 18, 25, 26, 27, 29, 35, 37, 40, 41, 44, 46, 52, 75, 96, 107, 124, 127, 138, 139, 145, 159, 191, 192, 204, 206, 207, 211, 213, 218, 221, 227, 228, 235, 237], "workflow": [3, 17, 18, 25, 26, 79, 101, 119], "generat": [3, 5, 6, 14, 16, 20, 22, 26, 32, 36, 42, 44, 45, 49, 54, 55, 60, 67, 86, 87, 89, 96, 97, 104, 113, 124, 130, 132, 133, 135, 139, 140, 146, 161, 162, 164, 165, 167, 172, 190, 200, 203, 209, 216, 220, 221, 223, 233, 235, 240, 242], "2410": [3, 34, 44, 86, 209, 221], "17238_sela": 3, "tree": [3, 17, 18, 24, 34, 54, 57, 61, 79, 85, 97, 130, 132, 211, 219, 226, 228, 239], "search": [3, 10, 13, 16, 18, 33, 34, 41, 78, 79, 87, 89, 132, 136, 137, 152, 173, 174, 190, 202, 203, 206, 208, 211, 212, 214, 219, 220, 226], "enhanc": [3, 13, 14, 29, 31, 36, 44, 53, 61, 79, 85, 96, 164, 197, 200, 207, 211, 213, 218, 226, 229, 231], "21012_fact": 3, "examin": [3, 50, 96, 211], "effect": [3, 4, 8, 24, 28, 29, 31, 32, 33, 34, 35, 61, 65, 78, 87, 89, 90, 96, 124, 162, 174, 175, 176, 189, 197, 200, 214, 218, 225, 227, 231], "iter": [3, 5, 16, 17, 29, 33, 34, 35, 102, 111, 132, 135, 158, 213, 226, 227, 229, 233], "context": [3, 16, 20, 22, 39, 44, 46, 50, 53, 61, 63, 75, 85, 86, 89, 96, 112, 122, 124, 127, 130, 139, 143, 144, 149, 159, 161, 162, 170, 174, 175, 184, 187, 201, 206, 208, 218, 219, 221, 235, 240, 242], "rewrit": [3, 7, 130, 164, 211], "fact": [3, 62, 69, 130, 133, 168, 199, 203, 205, 211, 238], "retriev": [3, 7, 16, 32, 39, 43, 44, 54, 79, 173, 205, 206, 208, 209, 213, 214, 216, 218, 221, 226, 228, 235], "2504": [3, 86, 87, 209, 221], "01990_advanc": 3, "challeng": [3, 4, 5, 14, 16, 17, 22, 32, 34, 35, 36, 40, 42, 46, 75, 79, 80, 96, 97, 111, 112, 176, 178, 201, 206, 207, 211, 226, 229, 232], "foundat": [3, 11, 23, 33, 44, 76, 79, 86, 127, 160, 184, 207, 211, 227], "2506": [3, 44, 86], "12508_agentorchestra": 3, "hierarch": [3, 16, 31, 44, 138, 195, 211, 214, 236], "general": [3, 5, 10, 16, 29, 32, 33, 36, 42, 44, 60, 87, 89, 91, 108, 127, 130, 155, 162, 164, 169, 170, 175, 176, 182, 191, 197, 199, 201, 214, 223, 224, 227, 229, 237], "purpos": [3, 33, 36, 61, 75, 79, 96, 175, 218], "task": [3, 4, 5, 13, 14, 17, 20, 21, 22, 23, 25, 26, 27, 28, 29, 31, 33, 34, 35, 36, 40, 41, 44, 46, 47, 52, 54, 61, 62, 75, 76, 82, 88, 89, 90, 91, 96, 111, 116, 120, 127, 130, 133, 137, 138, 139, 161, 169, 170, 178, 189, 192, 194, 199, 202, 206, 209, 212, 213, 214, 218, 221, 225, 226, 229], "solv": [3, 8, 13, 20, 25, 26, 27, 28, 29, 31, 33, 34, 41, 44, 46, 50, 53, 54, 75, 211], "2108": [3, 44], "03353_": 3, "screen2word": 3, "automat": [3, 4, 5, 10, 16, 33, 44, 77, 87, 137, 142, 170, 187, 206, 208, 213, 218], "mobil": [3, 8, 10, 11, 79, 169], "ui": [3, 9, 10, 14, 19, 54, 79, 96, 101, 155, 169, 241], "multimod": [3, 11, 21, 44, 86, 143, 160, 164, 169, 173, 174, 181, 221, 235], "2209": [3, 68, 87], "08199_screenqa": 3, "scale": [3, 6, 11, 41, 61, 70, 75, 86, 87, 91, 97, 98, 105, 106, 113, 115, 116, 124, 130, 143, 155, 160, 161, 169, 184, 194, 195, 196, 200, 212, 225, 228, 229], "question": [3, 13, 20, 27, 28, 44, 53, 57, 58, 62, 72, 75, 80, 85, 127, 130, 133, 145, 155, 159, 161, 167, 169, 170, 171, 172, 174, 175, 176, 190, 203, 204, 206, 211, 213, 214, 216, 219, 220, 238], "answer": [3, 28, 33, 43, 44, 53, 55, 57, 58, 62, 68, 71, 72, 75, 76, 78, 85, 130, 132, 145, 159, 161, 162, 167, 169, 170, 174, 175, 176, 190, 204, 206, 211, 213, 216, 218, 219], "pair": [3, 11, 17, 62, 96, 102, 130, 133, 162, 175, 187, 214, 217, 218, 226, 229, 237, 240], "over": [3, 8, 11, 14, 16, 22, 24, 34, 46, 48, 61, 79, 80, 105, 112, 123, 143, 162, 192, 200, 214, 216, 218], "app": [3, 6, 10, 12, 13, 14, 16, 17, 18, 49, 51, 52, 56, 149, 155, 218], "screenshot": [3, 6, 10, 11, 17, 24, 79, 131], "2212": [3, 86], "06817_rt": 3, "robot": [3, 78, 79, 86, 168], "real": [3, 7, 10, 16, 17, 29, 31, 44, 47, 86, 107, 130, 160, 170, 190, 192, 214, 218, 222, 229, 231], "world": [3, 5, 7, 10, 16, 18, 24, 29, 31, 41, 44, 47, 77, 79, 86, 130, 155, 160, 218, 225, 226, 227, 229], "control": [3, 13, 24, 33, 39, 42, 44, 53, 64, 79, 211, 218, 242], "at": [3, 4, 5, 11, 16, 18, 19, 22, 24, 26, 33, 34, 36, 41, 43, 50, 62, 75, 79, 87, 88, 97, 101, 102, 104, 105, 107, 111, 115, 122, 124, 127, 130, 132, 133, 141, 143, 144, 169, 175, 177, 178, 191, 192, 193, 194, 195, 206, 211, 212, 213, 214, 216, 218, 223, 224, 225, 226, 227, 228, 229, 233, 238], "2312": [3, 44, 86, 87, 153, 209, 221, 222], "13771_appag": 3, "as": [3, 4, 5, 7, 11, 13, 14, 16, 18, 22, 24, 25, 28, 29, 32, 33, 34, 35, 39, 40, 41, 42, 44, 47, 50, 61, 71, 75, 77, 79, 87, 88, 90, 91, 96, 101, 102, 106, 107, 108, 111, 113, 116, 119, 120, 127, 130, 133, 137, 139, 143, 144, 145, 146, 155, 159, 160, 162, 169, 170, 175, 176, 178, 181, 184, 191, 193, 194, 196, 197, 200, 201, 204, 206, 207, 208, 211, 212, 213, 214, 217, 218, 222, 224, 225, 226, 227, 229, 230, 231, 237, 242], "smartphon": 3, "user": [3, 6, 14, 16, 17, 24, 39, 42, 44, 79, 85, 127, 143, 145, 146, 170, 181, 202, 203, 204, 211, 213, 214, 218, 226], "2401": [3, 86, 87, 209, 221, 235], "10935_seeclick": 3, "har": [3, 76, 125, 211], "gui": [3, 18, 27, 79], "ground": [3, 7, 14, 79, 127, 130, 133, 140, 160, 169, 170, 190, 199, 214, 218, 222, 223, 225, 228, 238], "advanc": [3, 14, 32, 37, 75, 79, 86, 96, 106, 164, 169, 200, 206, 240, 242], "visual": [3, 5, 6, 7, 11, 14, 17, 21, 44, 50, 61, 78, 79, 86, 133, 169, 170, 173, 177, 190, 211, 222, 223, 228], "04615_screenai": 3, "vision": [3, 7, 8, 12, 42, 58, 60, 79, 86, 116, 155, 159, 166, 173, 175, 195, 197, 221, 222, 226, 227, 229], "infograph": [3, 7, 61], "understand": [3, 4, 7, 18, 29, 42, 44, 71, 86, 87, 113, 130, 146, 165, 169, 170, 178, 204, 206, 211, 214], "07939_ufo": 3, "focus": [3, 6, 7, 11, 14, 61, 75, 79, 96, 164, 170, 184, 189, 199, 208, 209, 211, 212, 221], "window": [3, 10, 17, 18, 19, 39, 66, 71, 72, 74, 79, 155, 169, 170, 218, 219], "os": [3, 13, 17, 19, 39, 79, 101, 221, 235], "interact": [3, 10, 18, 21, 22, 24, 27, 28, 29, 42, 47, 53, 56, 79, 86, 97, 101, 133, 160, 227, 229], "2403": [3, 44, 86, 87, 209, 221], "16971_aio": 3, "oper": [3, 26, 28, 34, 96, 97, 101, 106, 107, 111, 112, 113, 120, 122, 124, 125, 194, 195, 199, 218, 225, 226, 228, 233], "2406": [3, 44, 86, 209, 221, 222], "01014_mobil": 3, "v2": [3, 10, 16, 17, 19, 56, 58, 59, 65, 86, 87, 115, 116, 120, 123, 125, 127, 137, 155, 161, 164, 172, 175, 182, 226, 227, 239], "devic": [3, 13, 32, 79, 96, 105, 111, 119, 169, 218], "assist": [3, 7, 11, 25, 32, 44, 61, 79, 85, 123, 127, 130, 133, 146, 170, 181, 190, 214], "navig": [3, 16, 79, 130, 168, 202], "2411": [3, 44, 86, 190], "02059_tablegpt2": 3, "tabular": 3, "integr": [3, 25, 31, 32, 61, 79, 96, 104, 127, 169, 201, 211, 217, 218, 227, 241], "2501": [3, 44, 86], "11733_mobil": 3, "self": [3, 8, 11, 22, 24, 33, 41, 69, 85, 86, 96, 97, 101, 102, 106, 112, 123, 133, 134, 137, 143, 152, 155, 175, 177, 181, 194, 195, 201, 203, 211, 225, 229, 236, 241], "evolv": [3, 24, 39, 242], "complex": [3, 4, 25, 26, 28, 31, 32, 33, 34, 35, 46, 58, 61, 79, 120, 127, 158, 159, 207, 211, 213, 226, 230, 231, 232], "12326_ui": 3, "tar": [3, 74, 155], "pioneer": 3, "nativ": [3, 19, 106, 155], "2502": [3, 86, 222], "14282_pc": 3, "on": [3, 4, 5, 6, 7, 8, 11, 12, 14, 16, 22, 24, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 42, 44, 46, 47, 52, 53, 57, 61, 64, 71, 74, 79, 80, 86, 87, 89, 90, 91, 96, 97, 101, 102, 104, 105, 106, 112, 113, 115, 116, 120, 121, 131, 132, 133, 137, 138, 145, 151, 152, 158, 159, 160, 161, 165, 167, 169, 170, 175, 176, 178, 181, 184, 187, 189, 191, 192, 193, 194, 196, 197, 199, 200, 201, 202, 203, 204, 206, 207, 208, 209, 211, 212, 213, 214, 216, 218, 221, 223, 225, 226, 228, 229, 230], "pc": [3, 16, 19, 63], "14603_ufo2": 3, "desktop": [3, 11, 79], "agento": 3, "2505": [3, 86, 221, 235], "22101_memo": 3, "memori": [3, 8, 14, 16, 22, 27, 44, 48, 79, 87, 91, 96, 105, 106, 111, 113, 116, 120, 124, 133, 164, 218, 221, 235], "augment": [3, 10, 31, 32, 54, 86, 127, 165, 194, 200, 205, 209, 213, 214, 216, 221, 233, 235], "mag": 3, "short": [3, 16, 17, 22, 34, 44, 62, 64, 79, 82, 85, 130, 136, 162, 174, 212, 214, 218, 227], "version": [3, 33, 47, 50, 61, 78, 107, 108, 137, 181, 191, 232, 242], "2205": [3, 87, 190], "00445_mrkl": 3, "2302": [3, 86], "04761_toolform": 3, "can": [3, 4, 5, 11, 16, 24, 26, 27, 28, 29, 31, 32, 33, 40, 42, 44, 47, 74, 79, 87, 89, 90, 91, 97, 101, 102, 105, 106, 111, 113, 118, 120, 124, 130, 133, 139, 145, 161, 162, 175, 176, 187, 189, 191, 192, 197, 199, 202, 203, 206, 212, 213, 214, 216, 218, 223, 225, 226, 228, 229, 230, 232], "teach": [3, 33, 190, 206], "themselv": [3, 4, 211], "to": [3, 4, 5, 6, 7, 10, 13, 14, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50, 53, 57, 60, 63, 65, 71, 72, 75, 77, 78, 79, 80, 85, 86, 87, 88, 89, 90, 91, 96, 97, 101, 104, 105, 106, 107, 108, 111, 112, 113, 115, 119, 120, 122, 123, 124, 125, 131, 136, 142, 143, 151, 158, 159, 160, 161, 162, 164, 165, 166, 168, 169, 170, 175, 176, 177, 178, 181, 184, 187, 190, 191, 192, 193, 194, 196, 197, 201, 202, 204, 205, 208, 209, 211, 212, 213, 216, 218, 221, 222, 223, 227, 228, 229, 230, 231, 232], "use": [3, 5, 7, 8, 11, 16, 17, 18, 21, 22, 24, 25, 27, 28, 33, 34, 42, 43, 50, 52, 53, 60, 61, 74, 78, 79, 87, 90, 91, 96, 97, 101, 104, 107, 112, 113, 116, 119, 120, 122, 123, 124, 127, 130, 131, 132, 133, 137, 138, 143, 144, 146, 147, 158, 159, 160, 162, 164, 165, 166, 167, 168, 175, 176, 177, 181, 187, 189, 190, 192, 194, 196, 201, 202, 203, 205, 206, 208, 209, 211, 214, 218, 221, 223, 224, 225, 226, 227, 228, 231, 233], "17580_hugginggpt": 3, "chatgpt": [3, 8, 10, 23, 27, 43, 45, 50, 53, 56, 59, 60, 68, 72, 76, 78, 85, 123, 130, 141, 143, 146, 159, 164, 172, 174, 181, 187, 205, 211, 219, 237, 238], "its": [3, 4, 5, 7, 16, 17, 22, 29, 32, 34, 41, 47, 75, 79, 97, 101, 102, 106, 113, 115, 139, 143, 165, 166, 177, 181, 204, 206, 207, 214, 218, 219, 226, 227, 228, 232], "friend": [3, 96, 130], "hug": [3, 62, 96, 119, 123, 181, 188, 189, 240], "face": [3, 32, 62, 96, 119, 123, 181, 188, 189, 211, 240], "16789_toolllm": 3, "master": [3, 97, 158], "16000": 3, "api": [3, 12, 13, 16, 17, 20, 22, 27, 39, 40, 41, 47, 48, 50, 52, 54, 56, 58, 63, 64, 70, 75, 77, 78, 79, 85, 97, 102, 142, 149, 155, 165, 181, 182, 188, 202, 211, 217, 237, 238, 242], "1905": 3, "10985_ai": 3, "ga": 3, "algorithm": [3, 13, 22, 33, 56, 104, 133, 171, 212, 214, 222, 225, 226, 230, 240, 242], "altern": [3, 87, 88, 133, 184, 211, 229, 230], "paradigm": [3, 25, 26, 27, 91, 127, 146, 200, 211, 225, 226, 231], "produc": [3, 5, 22, 24, 33, 50, 70, 130, 139, 143, 146, 164, 175, 203, 214, 223, 227, 228], "artifici": [3, 5, 42, 53, 62], "06292_the": 3, "scientist": [3, 218], "toward": [3, 32, 33, 42, 79, 86, 87, 175, 207, 211, 226], "fulli": [3, 34, 89, 101, 106, 127, 204, 225, 230], "end": [3, 8, 17, 18, 24, 39, 44, 45, 47, 50, 53, 75, 81, 82, 90, 97, 105, 106, 112, 113, 122, 127, 137, 138, 141, 143, 145, 165, 170, 172, 190, 191, 204, 206, 208, 211, 212, 225, 227, 228, 233], "scientif": [3, 4, 218], "discoveri": [3, 33, 214], "arxiv": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 83, 84, 85, 88, 89, 90, 92, 94, 95, 96, 97, 98, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 166, 167, 168, 169, 170, 171, 173, 174, 175, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 223, 224, 225, 226, 227, 228, 229, 230, 231, 234, 236, 237, 238, 239, 240, 241, 242], "abs": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 83, 84, 85, 88, 89, 90, 92, 94, 95, 96, 97, 98, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 115, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 155, 158, 159, 160, 161, 162, 164, 165, 166, 167, 169, 170, 171, 173, 174, 175, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 207, 208, 210, 211, 213, 214, 215, 216, 217, 218, 219, 223, 224, 227, 228, 229, 230, 231, 236, 237, 238, 239, 240, 241, 242], "10985": 4, "perhap": 4, "most": [4, 5, 6, 7, 8, 16, 32, 61, 70, 75, 97, 127, 137, 138, 199, 203, 206, 211, 213, 214, 218, 227], "ambiti": 4, "quest": 4, "human": [4, 5, 6, 8, 11, 22, 24, 26, 28, 29, 31, 33, 34, 39, 44, 45, 48, 55, 75, 76, 82, 86, 87, 96, 127, 146, 159, 164, 165, 187, 190, 197, 203, 204, 205, 206, 214], "histori": [4, 14, 19, 33, 47, 75, 79, 130], "is": [4, 5, 6, 7, 8, 10, 11, 14, 16, 18, 21, 22, 24, 25, 27, 28, 29, 32, 33, 39, 40, 41, 42, 43, 44, 45, 47, 50, 52, 53, 57, 61, 62, 65, 68, 69, 71, 72, 74, 75, 78, 79, 80, 81, 85, 87, 88, 89, 90, 91, 96, 97, 101, 104, 105, 106, 107, 108, 111, 112, 113, 116, 119, 120, 121, 122, 124, 127, 130, 131, 133, 137, 138, 139, 140, 141, 143, 144, 145, 147, 158, 159, 160, 164, 165, 167, 168, 169, 170, 175, 176, 177, 178, 191, 192, 193, 194, 195, 197, 199, 200, 201, 202, 203, 204, 205, 206, 208, 211, 212, 213, 214, 216, 218, 219, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233], "creation": [4, 16, 71, 138], "which": [4, 5, 7, 8, 11, 14, 16, 18, 25, 33, 36, 41, 42, 43, 75, 79, 85, 88, 91, 96, 97, 101, 104, 105, 106, 107, 116, 119, 120, 127, 130, 132, 133, 137, 138, 139, 140, 143, 162, 164, 167, 168, 175, 178, 181, 184, 194, 195, 197, 200, 201, 202, 203, 206, 208, 211, 212, 213, 214, 216, 218, 224, 225, 226, 227, 229, 238], "rough": [4, 62, 107], "mean": [4, 58, 69, 127, 130, 133, 141, 151, 152, 165, 197, 201, 206, 214, 218, 226, 231, 238], "that": [4, 5, 6, 8, 11, 14, 16, 19, 22, 24, 25, 27, 28, 29, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 45, 47, 50, 52, 57, 58, 60, 61, 71, 79, 88, 89, 90, 96, 97, 98, 101, 102, 104, 106, 107, 111, 112, 113, 120, 121, 124, 125, 127, 130, 137, 140, 142, 146, 158, 159, 164, 165, 168, 175, 176, 177, 178, 181, 184, 187, 192, 193, 194, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 212, 213, 214, 216, 218, 223, 225, 226, 227, 228, 230, 232], "smart": [4, 86], "or": [4, 5, 11, 16, 18, 22, 24, 27, 28, 33, 36, 40, 41, 43, 53, 57, 58, 61, 69, 70, 71, 78, 79, 91, 96, 97, 101, 106, 111, 113, 116, 118, 120, 127, 130, 133, 135, 137, 143, 158, 160, 168, 170, 175, 194, 195, 196, 197, 201, 203, 206, 207, 213, 214, 218, 223, 224, 225, 226, 228, 238], "smarter": 4, "than": [4, 5, 7, 16, 26, 29, 41, 61, 65, 75, 85, 87, 91, 97, 105, 112, 113, 122, 124, 138, 143, 162, 168, 184, 192, 193, 199, 200, 205, 214, 218, 225, 226, 229], "domin": [4, 124], "approach": [4, 5, 6, 16, 19, 31, 33, 35, 36, 40, 90, 96, 106, 107, 111, 135, 176, 184, 191, 192, 203, 206, 209, 212, 213, 218, 221, 226, 227, 228, 231, 232], "communiti": [4, 5, 27, 42, 218, 220], "attempt": [4, 16, 33, 101, 112, 132, 230], "discov": [4, 5, 33, 35], "each": [4, 5, 6, 7, 11, 14, 16, 24, 25, 28, 33, 35, 39, 41, 42, 50, 53, 57, 61, 71, 74, 75, 76, 79, 81, 88, 91, 97, 102, 104, 105, 106, 107, 112, 113, 127, 131, 132, 137, 143, 145, 158, 160, 162, 164, 165, 168, 176, 187, 195, 206, 211, 214, 218, 224, 225, 226, 227, 232, 233], "piec": [4, 62, 205, 218], "requir": [4, 13, 14, 16, 18, 22, 25, 29, 31, 32, 34, 36, 41, 46, 53, 65, 75, 79, 88, 91, 96, 105, 106, 107, 111, 112, 118, 120, 127, 130, 133, 139, 161, 176, 194, 199, 206, 211, 216, 224, 225, 227, 229], "implicit": [4, 39, 223], "assumpt": [4, 214, 228], "some": [4, 11, 14, 16, 29, 34, 40, 74, 75, 79, 120, 127, 130, 132, 158, 193, 194, 205, 206, 218], "futur": [4, 22, 24, 41, 97, 101, 130, 184, 206, 207, 219], "group": [4, 13, 16, 18, 29, 32, 50, 69, 80, 115, 117, 118, 119, 122, 124, 145, 147, 151, 167, 184, 187, 201, 214], "will": [4, 13, 16, 34, 50, 61, 79, 97, 101, 130, 138, 199, 206, 214, 226, 230, 233], "complet": [4, 7, 12, 13, 14, 16, 21, 23, 24, 27, 33, 46, 49, 50, 61, 67, 75, 78, 79, 96, 102, 127, 130, 133, 167, 199, 206, 214, 223, 225, 226, 227, 228], "herculean": 4, "figur": [4, 6, 7, 8, 10, 11, 13, 16, 17, 18, 19, 22, 24, 25, 27, 28, 29, 30, 32, 33, 38, 39, 41, 43, 45, 46, 47, 50, 52, 53, 54, 55, 57, 58, 60, 61, 63, 65, 67, 70, 71, 78, 79, 80, 85, 88, 89, 91, 96, 97, 102, 104, 105, 106, 107, 108, 112, 113, 117, 118, 119, 122, 123, 124, 125, 127, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 151, 152, 155, 158, 159, 161, 162, 164, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 181, 189, 195, 199, 201, 203, 204, 206, 211, 214, 218, 219, 223, 224, 225, 226, 227, 228, 229, 230, 231], "out": [4, 8, 14, 16, 24, 46, 47, 53, 119, 130, 133, 146, 155, 175, 176, 195, 211, 212, 214, 216, 229, 233], "how": [4, 13, 16, 22, 25, 27, 33, 40, 41, 43, 44, 50, 101, 111, 130, 133, 199, 206, 212, 214, 218, 223], "combin": [4, 8, 19, 28, 33, 40, 79, 96, 104, 132, 138, 143, 171, 189, 194, 218, 224], "all": [4, 7, 8, 11, 14, 18, 27, 35, 36, 44, 46, 50, 57, 65, 74, 75, 77, 80, 85, 86, 87, 88, 90, 91, 96, 97, 104, 106, 112, 116, 119, 122, 127, 130, 133, 137, 158, 159, 165, 167, 168, 175, 176, 191, 196, 197, 201, 203, 204, 206, 213, 214, 218, 225, 226, 228, 229], "those": [4, 24, 143, 202, 214, 223], "into": [4, 5, 6, 8, 13, 16, 18, 22, 24, 26, 29, 39, 41, 45, 61, 80, 86, 91, 96, 101, 102, 104, 105, 107, 119, 124, 130, 133, 137, 143, 161, 165, 167, 169, 176, 189, 197, 199, 205, 211, 213, 214, 223, 226, 227, 229, 230, 232, 233], "think": [4, 17, 68, 75, 79, 86, 130, 155, 162, 214, 218], "call": [4, 13, 16, 19, 31, 41, 43, 44, 45, 46, 47, 53, 61, 88, 96, 97, 101, 130, 138, 175, 197, 216, 230, 233], "this": [4, 5, 7, 8, 11, 14, 16, 24, 25, 26, 31, 33, 34, 35, 36, 40, 41, 42, 46, 50, 60, 61, 71, 75, 79, 88, 90, 96, 97, 101, 105, 106, 107, 111, 112, 113, 119, 120, 130, 132, 133, 137, 143, 145, 160, 161, 165, 168, 175, 176, 178, 184, 189, 192, 193, 197, 199, 200, 202, 203, 204, 205, 206, 207, 208, 211, 212, 213, 214, 216, 218, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233], "manual": [4, 34, 54, 57, 89, 130, 137, 218, 220], "paper": [4, 5, 8, 16, 24, 25, 36, 41, 61, 75, 88, 97, 98, 99, 107, 111, 112, 120, 130, 137, 145, 163, 183, 185, 197, 199, 205, 207, 208, 211, 218, 225, 230], "describ": [4, 5, 11, 24, 29, 40, 61, 75, 97, 130, 143, 214, 218, 227], "anoth": [4, 7, 11, 47, 71, 96, 119, 139, 206, 214], "excit": [4, 33, 206], "path": [4, 39, 45, 112, 119, 141, 144, 166, 189, 199], "ultim": [4, 188], "may": [4, 14, 52, 101, 204, 206, 214, 218, 231], "be": [4, 5, 7, 8, 11, 13, 14, 16, 18, 24, 26, 28, 31, 33, 34, 40, 47, 50, 53, 61, 79, 87, 89, 90, 97, 101, 106, 111, 112, 113, 120, 124, 127, 130, 133, 137, 138, 139, 145, 165, 175, 176, 178, 189, 191, 199, 202, 203, 206, 212, 214, 218, 224, 226, 228, 232, 233], "more": [4, 8, 10, 11, 14, 16, 25, 26, 33, 35, 36, 41, 61, 65, 70, 71, 79, 86, 87, 90, 105, 120, 124, 127, 130, 135, 169, 191, 192, 193, 205, 207, 211, 214, 218, 225, 226, 229, 233], "success": [4, 8, 12, 14, 18, 36, 45, 50, 226, 229], "it": [4, 5, 6, 7, 8, 14, 16, 22, 24, 31, 33, 40, 46, 47, 50, 57, 61, 79, 88, 96, 97, 101, 111, 112, 113, 116, 122, 127, 130, 159, 160, 162, 168, 174, 175, 176, 177, 188, 189, 191, 192, 193, 195, 197, 199, 200, 202, 203, 206, 211, 212, 214, 216, 218, 223, 225, 226, 227, 229, 230, 233], "base": [4, 5, 6, 7, 8, 10, 11, 13, 14, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 39, 40, 42, 47, 53, 54, 61, 62, 63, 64, 79, 86, 87, 96, 97, 106, 117, 121, 124, 130, 132, 133, 135, 137, 138, 139, 146, 147, 159, 162, 165, 169, 170, 171, 181, 182, 189, 191, 195, 196, 197, 199, 201, 202, 206, 208, 209, 211, 212, 213, 214, 221, 223, 225, 228, 229, 231, 236, 238, 239], "clear": [4, 16, 61, 71, 75, 127, 177, 211, 214], "trend": [4, 16, 75, 211], "hand": [4, 33, 41, 211, 225], "solut": [4, 25, 26, 27, 31, 33, 35, 45, 46, 47, 50, 96, 97, 131, 133, 155, 197, 211, 218], "eventu": [4, 33, 227], "are": [4, 7, 8, 11, 13, 14, 16, 18, 22, 24, 25, 26, 27, 28, 32, 33, 34, 36, 40, 42, 45, 50, 53, 57, 58, 61, 62, 67, 69, 70, 74, 75, 79, 86, 90, 97, 101, 102, 105, 106, 108, 112, 113, 119, 122, 124, 125, 127, 130, 133, 137, 141, 142, 143, 144, 145, 147, 155, 158, 159, 161, 162, 164, 165, 167, 168, 169, 175, 176, 178, 181, 184, 187, 189, 194, 195, 199, 201, 202, 203, 204, 205, 206, 208, 211, 212, 213, 214, 216, 218, 224, 225, 226, 227, 228, 232, 238], "replac": [4, 33, 62, 79, 137, 175, 211], "by": [4, 5, 7, 11, 12, 13, 14, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 40, 42, 43, 44, 47, 49, 50, 57, 58, 60, 61, 63, 68, 69, 75, 85, 86, 87, 88, 89, 90, 91, 96, 97, 101, 104, 105, 106, 107, 111, 112, 120, 123, 124, 127, 130, 132, 133, 137, 145, 146, 147, 160, 161, 162, 164, 165, 169, 170, 175, 187, 189, 191, 193, 195, 196, 197, 199, 201, 202, 203, 204, 205, 206, 211, 212, 214, 218, 223, 224, 226, 228, 229, 231, 233, 234], "idea": [4, 5, 33, 122, 130, 197, 218, 230], "creat": [4, 16, 18, 33, 53, 61, 79, 97, 101, 130, 137, 175, 227, 230], "three": [4, 5, 6, 7, 8, 11, 14, 16, 18, 29, 31, 33, 39, 43, 52, 63, 67, 71, 79, 102, 104, 118, 127, 130, 133, 142, 159, 165, 166, 167, 193, 195, 197, 201, 206, 211, 218, 219], "pillar": 4, "essenti": [4, 6, 36, 40, 211, 226, 232], "architectur": [4, 6, 8, 14, 19, 27, 38, 39, 40, 87, 91, 96, 104, 105, 106, 115, 137, 141, 166, 170, 175, 176, 181, 187, 191, 199, 200, 219, 225, 227], "argu": [4, 8, 112], "either": [4, 8, 40, 58, 71, 79, 101, 113, 133, 213, 214, 226], "could": [4, 42, 79, 97, 127, 130, 178, 206, 207, 214, 218, 226], "first": [4, 5, 6, 7, 11, 16, 18, 45, 53, 71, 79, 104, 107, 112, 119, 130, 132, 137, 138, 144, 162, 192, 200, 201, 206, 208, 218, 225, 227, 229], "both": [4, 7, 13, 16, 20, 28, 41, 45, 57, 61, 62, 69, 75, 89, 97, 105, 113, 119, 121, 132, 133, 143, 146, 160, 164, 169, 175, 184, 189, 191, 192, 196, 200, 201, 207, 214, 218, 223, 226, 227], "worthwhil": 4, "irrespect": 4, "fastest": [4, 201], "becaus": [4, 101, 138, 203, 205, 214, 233], "promis": [4, 8, 33, 35, 113, 130, 206, 211, 213], "yet": [4, 16, 33, 36, 90, 207, 213, 224, 225], "ml": [4, 97, 104, 221], "current": [4, 14, 16, 18, 24, 29, 78, 79, 101, 138, 159, 164, 206, 208, 211, 228], "commit": [4, 50], "our": [4, 5, 6, 8, 10, 11, 17, 18, 24, 26, 29, 33, 35, 36, 43, 53, 57, 63, 65, 71, 79, 89, 90, 91, 96, 97, 98, 104, 106, 107, 111, 117, 118, 127, 130, 132, 137, 141, 143, 145, 158, 159, 160, 162, 164, 166, 176, 178, 181, 184, 191, 192, 195, 200, 201, 202, 203, 204, 206, 208, 213, 218, 219, 223, 224, 225, 227, 228, 229, 230, 231, 237], "should": [4, 7, 10, 11, 53, 61, 79, 127, 130, 204, 207, 214, 218], "increas": [4, 14, 22, 31, 105, 106, 107, 113, 137, 143, 226, 228], "research": [4, 5, 6, 7, 8, 11, 13, 16, 24, 27, 28, 33, 34, 41, 46, 47, 63, 75, 79, 81, 82, 84, 98, 102, 104, 107, 108, 116, 119, 130, 140, 159, 161, 175, 176, 184, 197, 200, 204, 207, 211, 212, 218, 223, 225, 226, 230, 240, 242], "invest": [4, 33], "encourag": [4, 11, 25, 75, 218], "such": [4, 18, 25, 33, 41, 75, 78, 79, 101, 111, 120, 138, 139, 146, 159, 169, 170, 175, 176, 178, 181, 194, 197, 205, 206, 207, 211, 213, 214, 218, 223, 224, 225], "work": [4, 11, 14, 24, 25, 26, 33, 87, 90, 105, 106, 160, 191, 192, 197, 200, 203, 206, 213], "also": [4, 7, 11, 16, 22, 28, 32, 40, 41, 75, 79, 89, 91, 96, 101, 112, 120, 130, 132, 133, 160, 175, 181, 184, 193, 197, 203, 205, 206, 211, 213, 214, 218, 225], "discuss": [4, 29, 40], "specif": [4, 8, 11, 18, 22, 25, 27, 31, 34, 42, 46, 60, 61, 65, 76, 79, 88, 90, 101, 127, 133, 145, 147, 175, 181, 184, 203, 211, 212, 214, 216, 217, 218, 224, 226, 240], "safeti": [4, 10, 13, 79, 80, 187, 203, 214, 218], "ethic": [4, 207], "consider": [4, 200, 206], "inher": [4, 40, 130, 213], "interest": [4, 16, 27, 33, 184, 206, 214, 225, 226], "condit": [4, 8, 22, 24, 87, 90, 132, 136, 140, 143, 144, 147, 151, 175, 214, 218], "simpl": [4, 26, 33, 41, 66, 71, 72, 74, 90, 106, 127, 130, 165, 175, 209, 213, 218, 221, 225, 228, 233], "happen": [4, 16, 130, 177], "earth": [4, 130], "where": [4, 5, 6, 8, 10, 11, 13, 16, 24, 27, 32, 33, 34, 36, 41, 45, 46, 47, 79, 90, 101, 102, 113, 130, 137, 141, 144, 159, 160, 162, 175, 189, 191, 201, 214, 218, 224, 225, 226, 231, 232], "darwinian": 4, "evolut": [4, 39, 187], "pursuit": 4, "gas": [4, 214], "consid": [4, 6, 14, 42, 52, 61, 97, 101, 130, 162, 206, 230], "new": [4, 5, 10, 16, 18, 24, 27, 33, 40, 41, 42, 46, 53, 61, 79, 97, 106, 111, 112, 113, 121, 130, 159, 160, 175, 190, 191, 193, 194, 197, 199, 200, 201, 205, 208, 216, 218, 223, 225, 227, 228, 233], "grand": [4, 5], "06292": 5, "chris": 5, "lu": [5, 23, 31, 33], "cong": 5, "robert": 5, "tjarko": 5, "lang": 5, "jakob": 5, "foerster": 5, "jeff": [5, 33, 202], "clune": [5, 33], "david": [5, 226], "ha": 5, "sakana": 5, "flair": 5, "vector": [5, 33, 47, 88, 102, 119, 133, 141, 143, 211, 218, 226, 229, 234, 242], "cifar": [5, 33, 69, 231], "chair": [5, 33, 214], "one": [5, 8, 16, 24, 27, 29, 33, 40, 49, 52, 61, 71, 75, 79, 88, 90, 97, 102, 104, 107, 113, 119, 121, 122, 127, 130, 132, 135, 159, 175, 191, 203, 206, 213, 214, 218, 223, 225, 226, 230, 233], "agent": [5, 7, 15, 21, 27, 42, 45, 52, 53, 55, 97, 101, 155, 165, 169, 188, 189, 221, 238], "capabl": [5, 8, 14, 24, 29, 32, 42, 44, 52, 75, 79, 86, 96, 112, 133, 139, 145, 162, 164, 165, 169, 170, 184, 187, 200, 208, 211, 214, 228, 241], "conduct": [5, 22, 35, 42, 53, 195, 203, 204, 205], "knowledg": [5, 8, 16, 33, 39, 40, 63, 64, 68, 75, 79, 118, 143, 158, 178, 205, 209, 211, 212, 213, 214, 216, 217, 220, 221, 224, 230], "while": [5, 8, 10, 11, 16, 22, 24, 35, 42, 46, 47, 50, 79, 96, 106, 107, 112, 113, 116, 122, 130, 131, 132, 133, 143, 147, 164, 168, 170, 176, 184, 191, 192, 194, 197, 202, 206, 216, 218, 226, 227, 228, 229, 231, 233], "frontier": [5, 86], "have": [5, 11, 14, 16, 18, 22, 29, 31, 34, 35, 40, 42, 47, 53, 71, 75, 79, 91, 97, 102, 111, 112, 113, 130, 137, 168, 169, 175, 178, 181, 187, 192, 200, 205, 206, 211, 213, 214, 218, 226, 228, 233], "alreadi": [5, 16, 26, 226, 227], "been": [5, 8, 11, 18, 22, 26, 89, 111, 113, 125, 165, 175, 184, 189, 211, 214], "aid": [5, 203], "brainstorm": [5, 130], "write": [5, 11, 16, 18, 24, 53, 79, 101, 102, 112, 113, 130, 189, 206, 211, 214, 237, 240], "code": [5, 13, 18, 22, 25, 27, 28, 29, 31, 32, 33, 34, 44, 50, 54, 57, 78, 79, 86, 96, 97, 113, 130, 136, 137, 138, 140, 141, 165, 169, 170, 178, 189, 197, 211, 213, 216, 233, 240], "predict": [5, 10, 41, 50, 79, 86, 133, 137, 140, 143, 145, 159, 160, 174, 175, 181, 191, 192, 199, 202, 213, 223, 224, 225, 228, 236, 241], "they": [5, 22, 24, 27, 28, 32, 35, 36, 40, 41, 42, 71, 75, 79, 97, 113, 130, 133, 165, 175, 212, 213, 214, 218, 225, 226], "still": [5, 8, 14, 34, 75, 101, 113, 122, 127, 130, 178, 191, 192, 193, 201, 206, 211, 229], "onli": [5, 7, 8, 10, 11, 20, 24, 46, 47, 49, 53, 61, 65, 75, 79, 80, 88, 89, 91, 97, 107, 113, 118, 120, 124, 125, 127, 133, 138, 141, 144, 147, 158, 159, 160, 162, 164, 165, 168, 175, 176, 184, 190, 192, 194, 196, 199, 201, 203, 204, 205, 206, 212, 213, 214, 218, 224, 225, 226, 228, 230], "small": [5, 8, 24, 62, 79, 86, 88, 96, 97, 101, 113, 122, 194, 195, 201, 211, 218, 230], "part": [5, 29, 43, 70, 83, 97, 127, 137, 143, 164, 175, 203, 211, 214, 218], "process": [5, 8, 16, 17, 18, 22, 25, 29, 32, 35, 36, 40, 43, 45, 47, 53, 60, 75, 79, 87, 91, 96, 101, 106, 115, 119, 120, 127, 131, 132, 137, 142, 162, 167, 169, 170, 175, 176, 191, 200, 213, 214, 218, 226, 227, 229, 232], "present": [5, 8, 16, 27, 33, 42, 52, 85, 96, 97, 106, 164, 184, 191, 193, 197, 200, 218, 223, 227, 228, 229, 233], "comprehens": [5, 11, 17, 24, 25, 44, 53, 63, 65, 75, 79, 127, 169, 170, 197, 200, 204, 207, 211, 217, 218], "perform": [5, 11, 14, 16, 18, 22, 25, 31, 33, 35, 36, 41, 43, 56, 61, 87, 88, 89, 90, 91, 96, 97, 102, 106, 111, 113, 115, 122, 124, 125, 127, 130, 139, 145, 146, 147, 152, 159, 161, 162, 164, 169, 175, 176, 178, 181, 184, 187, 188, 189, 191, 193, 197, 200, 202, 203, 212, 214, 216, 218, 225, 228, 229, 230, 236], "independ": [5, 91, 102, 132, 161, 218], "their": [5, 6, 8, 11, 14, 16, 22, 25, 27, 29, 31, 32, 33, 35, 42, 45, 53, 61, 71, 75, 79, 101, 104, 123, 130, 137, 164, 165, 169, 184, 200, 202, 203, 204, 206, 214, 218, 226], "find": [5, 16, 33, 36, 79, 88, 90, 124, 137, 162, 204, 205, 214, 218, 224, 228], "we": [5, 6, 11, 13, 14, 16, 17, 18, 20, 22, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 40, 41, 42, 43, 45, 47, 50, 52, 60, 63, 71, 79, 88, 89, 90, 91, 96, 97, 101, 104, 105, 106, 107, 111, 112, 113, 116, 120, 122, 124, 127, 130, 132, 133, 137, 143, 146, 159, 160, 161, 162, 164, 165, 166, 169, 175, 176, 178, 181, 184, 187, 189, 191, 192, 193, 194, 196, 197, 199, 200, 202, 203, 204, 205, 206, 207, 208, 212, 213, 216, 218, 223, 224, 225, 226, 227, 228, 229, 230, 231], "introduc": [5, 11, 16, 24, 25, 26, 31, 32, 35, 41, 52, 75, 79, 96, 108, 124, 133, 137, 160, 169, 175, 184, 192, 197, 200, 205, 208, 211, 216, 218, 225, 226, 227, 228], "novel": [5, 6, 16, 22, 24, 32, 33, 35, 36, 89, 111, 159, 192, 197, 206, 207, 213, 223, 225, 227, 229], "execut": [5, 14, 25, 29, 31, 34, 39, 42, 45, 53, 79, 97, 107, 108, 187, 214, 233], "experi": [5, 22, 24, 29, 31, 32, 33, 34, 36, 87, 102, 175, 178, 184, 200, 206, 212, 230], "result": [5, 14, 25, 26, 33, 35, 36, 41, 42, 45, 56, 57, 60, 76, 89, 97, 101, 104, 106, 111, 112, 113, 119, 142, 145, 146, 154, 158, 160, 164, 167, 169, 175, 194, 199, 200, 204, 206, 208, 212, 216, 224], "full": [5, 7, 8, 11, 22, 55, 70, 71, 75, 88, 90, 91, 96, 130, 132, 134, 137, 143, 144, 145, 170, 191, 226, 227, 228, 242], "then": [5, 6, 8, 11, 16, 22, 53, 60, 71, 79, 85, 101, 107, 119, 127, 130, 132, 137, 139, 167, 181, 189, 201, 202, 211, 212, 218, 224, 225, 227, 228, 229, 242], "run": [5, 75, 79, 81, 96, 98, 101, 130, 192, 193, 227, 229], "simul": [5, 22, 24, 27, 32, 46, 75, 79, 97, 133], "review": [5, 7, 16, 211], "principl": [5, 30, 112, 124], "repeat": [5, 162, 214, 218, 226, 229], "fashion": [5, 164, 218], "act": [5, 20, 42, 46, 242], "like": [5, 7, 11, 16, 24, 26, 27, 32, 39, 47, 61, 75, 79, 96, 106, 122, 130, 138, 162, 165, 191, 192, 195, 211, 218, 233], "demonstr": [5, 8, 16, 24, 25, 28, 29, 31, 32, 33, 34, 35, 36, 41, 71, 80, 97, 98, 106, 120, 130, 141, 144, 145, 160, 169, 175, 176, 178, 184, 187, 202, 205, 206, 216, 218, 227, 229], "versatil": [5, 86, 124, 195, 211, 226], "appli": [5, 11, 14, 50, 88, 101, 105, 119, 130, 132, 164, 178, 189, 211, 218, 224, 226, 227], "distinct": [5, 7, 158, 177, 211], "subfield": 5, "diffus": [5, 61, 144, 147, 161, 170, 226, 229, 241], "dynam": [5, 19, 24, 29, 31, 32, 107, 122, 146, 155, 168, 174, 184, 204, 211, 213, 214, 218, 229, 242], "implement": [5, 29, 40, 47, 96, 97, 106, 120, 124, 127, 137, 159, 160, 169, 189, 207, 216, 218, 219], "cost": [5, 34, 54, 90, 113, 133, 168, 184, 200, 205, 214, 224, 232], "less": [5, 36, 91, 175, 191, 200, 205, 224, 229], "15": [5, 7, 8, 17, 18, 19, 45, 47, 48, 49, 50, 53, 54, 55, 58, 63, 64, 69, 70, 72, 74, 76, 77, 78, 79, 81, 84, 98, 106, 112, 119, 120, 123, 130, 137, 143, 144, 145, 147, 151, 152, 158, 159, 165, 170, 175, 181, 188, 189, 201, 214, 218, 225, 226, 228, 229, 238, 239, 240, 241], "per": [5, 19, 55, 97, 101, 108, 111, 113, 115, 122, 124, 165, 191, 227, 228, 230], "valid": [5, 11, 70, 71, 96, 192, 213, 226], "show": [5, 6, 11, 16, 20, 24, 33, 39, 41, 43, 47, 50, 56, 60, 75, 79, 90, 97, 101, 104, 106, 107, 111, 112, 130, 133, 137, 159, 162, 164, 166, 168, 175, 199, 200, 203, 206, 212, 213, 218, 223, 224, 225, 226, 227, 229, 230], "achiev": [5, 11, 12, 14, 22, 32, 34, 35, 41, 42, 79, 106, 111, 112, 120, 124, 127, 130, 161, 168, 175, 176, 178, 191, 193, 194, 197, 199, 200, 201, 205, 218, 225, 227, 228, 229, 230], "near": [5, 8, 16, 113, 225, 226], "score": [5, 7, 10, 16, 22, 24, 44, 45, 53, 56, 63, 70, 75, 78, 82, 83, 112, 127, 131, 132, 139, 145, 147, 151, 168, 175, 189, 205, 211, 214, 239], "exceed": [5, 90, 116], "accept": [5, 229], "threshold": [5, 119, 214, 227], "top": [5, 7, 8, 10, 11, 16, 18, 28, 48, 51, 57, 58, 63, 75, 84, 88, 105, 113, 119, 132, 140, 143, 145, 158, 159, 161, 165, 170, 171, 172, 189, 201, 211, 214, 216, 218, 225, 226, 229, 233, 236, 238, 239, 240, 242], "confer": [5, 61, 79, 90, 112, 214], "judg": [5, 44, 70, 77, 127, 133, 155, 214, 237, 242], "signifi": 5, "begin": [5, 81, 82, 106, 112, 127, 137, 143, 214, 218, 225, 228, 231, 233], "era": [5, 40, 208], "bring": [5, 8, 86, 113, 130, 200, 207], "benefit": [5, 33, 90, 207, 214, 218], "entir": [5, 7, 106, 112, 122, 133], "itself": [5, 61, 204], "us": [5, 33, 58, 74, 82, 98, 111, 140, 206, 218, 225], "closer": 5, "endless": 5, "afford": [5, 87], "creativ": [5, 11, 130, 189], "innov": [5, 26, 35, 218], "unleash": 5, "problem": [5, 8, 13, 16, 26, 27, 29, 31, 33, 34, 44, 50, 53, 75, 112, 113, 131, 133, 170, 191, 194, 207, 211, 218, 224, 225, 231], "url": [5, 21, 23, 26, 34, 43, 79, 155, 178, 193, 204, 213, 216], "github": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 24, 29, 32, 33, 35, 37, 39, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 70, 71, 72, 74, 75, 76, 79, 80, 85, 95, 102, 106, 107, 117, 118, 119, 121, 122, 123, 124, 125, 136, 137, 138, 139, 141, 142, 143, 144, 145, 146, 147, 151, 154, 158, 159, 160, 161, 162, 163, 164, 166, 167, 168, 169, 170, 171, 174, 175, 177, 178, 181, 182, 183, 184, 185, 187, 188, 189, 194, 195, 196, 197, 198, 199, 200, 201, 211, 214, 217, 218, 220, 224, 225, 226, 227, 228, 229, 237, 240, 242], "sakanaai": 5, "experiment": [5, 14, 35, 75, 164, 184, 224], "up": [5, 7, 18, 24, 43, 44, 79, 85, 86, 105, 106, 113, 130, 134, 139, 184, 195, 202, 211, 214, 226, 227, 228, 229], "latex": [5, 75, 76, 155, 165, 166], "03353": 6, "univers": [6, 8, 10, 16, 35, 38, 39, 43, 45, 47, 48, 50, 51, 53, 54, 55, 57, 58, 61, 62, 63, 65, 69, 70, 71, 74, 77, 79, 82, 85, 102, 103, 104, 107, 108, 112, 116, 118, 119, 123, 159, 161, 165, 166, 167, 168, 171, 194, 217, 224, 225, 226, 240, 242], "toronto": [6, 47], "interfac": [6, 7, 17, 39, 42, 77, 97, 131, 160], "112": [6, 69, 158, 201], "000": [6, 7, 10, 43, 50, 59, 61, 63, 67, 69, 83, 91, 102, 135, 138, 141, 143, 144, 147, 155, 158, 167, 171, 172, 175, 184, 187, 217, 230, 233, 236], "22": [6, 8, 16, 50, 51, 52, 55, 60, 61, 63, 70, 75, 76, 79, 85, 105, 125, 137, 141, 155, 160, 165, 188, 189, 193, 195, 214, 229, 238, 240], "encapsul": [6, 60, 212], "inform": [6, 7, 11, 16, 18, 21, 36, 44, 46, 60, 61, 63, 79, 82, 121, 127, 161, 167, 190, 204, 205, 206, 211, 212, 214, 216, 218, 225, 227, 231, 232], "screen": [6, 7, 10, 16, 79], "coher": [6, 24, 26, 61, 211], "phrase": [6, 7, 62, 211], "collect": [6, 7, 10, 45, 60, 76, 101, 131, 137, 149, 158, 164, 165, 187, 202, 204, 206, 208, 213, 216, 218, 225, 227, 239], "consist": [6, 17, 24, 32, 33, 50, 53, 57, 65, 75, 80, 85, 91, 97, 120, 133, 137, 140, 141, 144, 146, 147, 151, 159, 160, 162, 164, 165, 170, 200, 211, 225, 227, 228], "annot": [6, 12, 17, 45, 79, 107, 165, 187, 208, 224, 229], "417": 6, "android": [6, 7, 17, 19, 155, 169], "set": [6, 8, 11, 14, 17, 18, 34, 47, 52, 54, 61, 71, 75, 79, 88, 89, 122, 130, 137, 145, 151, 152, 158, 159, 160, 167, 175, 178, 190, 192, 201, 202, 204, 205, 206, 213, 214, 216, 223, 224, 225, 229, 230], "deep": [6, 25, 86, 87, 112, 115, 184, 199, 222, 223, 229], "leverag": [6, 11, 13, 16, 24, 29, 33, 35, 42, 88, 96, 140, 211, 218, 225], "modal": [6, 8, 14, 42, 44, 75, 80, 133, 143, 155, 170, 172, 197, 214], "carri": [6, 195], "outperform": [6, 16, 29, 32, 33, 34, 75, 88, 90, 162, 176, 191, 192, 196, 229], "heurist": [6, 58, 133], "baselin": [6, 10, 22, 31, 32, 33, 34, 35, 78, 86, 106, 112, 113, 122, 127, 139, 145, 147, 168, 189, 203, 213, 218, 226, 228, 229], "abl": [6, 21, 79, 105, 139, 162, 184, 202, 203, 206, 223, 226], "accur": [6, 33, 87, 127, 137, 193, 195, 204, 206, 218, 227, 228], "summari": [6, 11, 12, 16, 44, 50, 63, 104, 130, 142, 145, 206, 211, 225], "085": 6, "resnet": [6, 8, 121, 158, 192], "rico": [6, 7, 10, 17], "exampl": [6, 8, 10, 13, 17, 18, 20, 22, 23, 24, 28, 29, 32, 33, 41, 45, 46, 47, 50, 61, 63, 69, 77, 88, 89, 90, 91, 97, 101, 102, 104, 105, 107, 127, 130, 137, 141, 144, 145, 159, 160, 162, 168, 189, 200, 204, 206, 216, 218, 223, 225, 226, 227, 230, 233], "area": [6, 7, 18, 33, 61, 68, 75, 207, 218, 226], "orang": [6, 8, 16, 18, 79, 89, 223, 226], "rectangl": 6, "indic": [6, 10, 14, 16, 39, 79, 80, 97, 101, 104, 107, 108, 127, 130, 131, 133, 141, 144, 158, 165, 166, 214, 218, 224, 227, 242], "label": [6, 90, 97, 103, 106, 109, 110, 111, 135, 137, 155, 165, 175, 176, 192, 213, 231], "influenti": 6, "overlay": 6, "deepest": 6, "color": [6, 13, 16, 57, 61, 79, 107, 133, 161, 214, 223, 224, 225, 226, 227, 229], "repres": [6, 7, 10, 11, 13, 16, 18, 24, 32, 33, 34, 35, 56, 75, 102, 104, 106, 107, 127, 133, 137, 143, 152, 158, 165, 189, 211, 214, 218, 222, 224], "place": [6, 8, 130, 165, 214, 218], "import": [6, 16, 22, 24, 33, 61, 79, 91, 113, 119, 127, 130, 138, 175, 177, 184, 199, 206, 214, 225], "when": [6, 10, 11, 14, 21, 33, 41, 42, 75, 79, 86, 96, 98, 101, 102, 104, 106, 113, 122, 130, 143, 161, 162, 191, 193, 199, 201, 203, 204, 206, 211, 214, 225, 226, 228, 230], "sca": [6, 17], "view": [6, 7, 10, 29, 141, 162, 222, 226, 227, 228], "hierarchi": [6, 7, 16, 43, 113, 240], "85": [6, 7, 14, 16, 49, 52, 61, 64, 69, 85, 119, 122, 130, 139, 143, 145, 149, 159, 174, 189, 241], "10": [6, 7, 8, 9, 10, 11, 12, 16, 17, 19, 20, 24, 43, 45, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 60, 61, 63, 64, 67, 69, 70, 72, 75, 76, 77, 79, 81, 82, 84, 85, 91, 97, 104, 106, 107, 111, 112, 113, 115, 116, 117, 127, 130, 132, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 151, 152, 158, 164, 165, 166, 174, 175, 181, 182, 184, 187, 189, 201, 214, 218, 223, 225, 226, 227, 229, 230, 231, 233, 236, 237, 238, 239, 240, 241], "sfa": 6, "66": [6, 49, 63, 71, 75, 106, 117, 139, 146, 160, 161, 229], "iou": [6, 7, 11, 19, 155, 193], "74": [6, 47, 55, 58, 69, 71, 76, 79, 119, 149, 152, 158, 162, 170, 204, 229, 238], "encod": [6, 8, 10, 11, 26, 51, 86, 89, 97, 106, 117, 120, 137, 138, 139, 141, 144, 145, 147, 160, 161, 167, 172, 175, 187, 190, 195, 211, 218, 219, 224, 225, 226, 228, 236, 239, 240], "decod": [6, 8, 11, 49, 50, 51, 65, 96, 106, 117, 137, 138, 139, 140, 141, 144, 146, 158, 161, 164, 167, 168, 169, 176, 190, 195, 197, 218, 225, 226, 227, 228], "vaswani": [6, 106], "et": [6, 7, 8, 10, 11, 16, 17, 18, 20, 27, 32, 33, 45, 49, 50, 52, 63, 67, 77, 96, 102, 113, 122, 127, 130, 133, 138, 143, 151, 170, 181, 184, 195, 202, 214, 218, 226, 237], "al": [6, 7, 8, 10, 11, 16, 17, 18, 20, 27, 32, 33, 36, 45, 49, 50, 52, 63, 67, 77, 96, 102, 113, 122, 127, 130, 133, 138, 143, 151, 170, 181, 184, 195, 202, 214, 218, 226, 237], "2017": [6, 7, 10, 40, 69, 73, 79, 84, 106, 115, 130, 143, 226], "input": [6, 16, 18, 22, 28, 39, 45, 53, 61, 87, 96, 104, 105, 106, 107, 112, 119, 122, 127, 140, 143, 145, 146, 159, 162, 164, 169, 175, 184, 189, 197, 199, 211, 214, 218, 223, 224, 225, 226, 227, 229], "includ": [6, 7, 11, 16, 33, 41, 57, 61, 65, 71, 75, 79, 89, 127, 133, 137, 146, 160, 161, 164, 165, 169, 170, 175, 184, 191, 194, 197, 206, 207, 211, 213, 214, 218, 219, 229], "structur": [6, 10, 11, 17, 25, 31, 32, 34, 39, 53, 61, 75, 96, 127, 138, 158, 164, 176, 211, 214, 218, 227, 228], "text": [6, 7, 10, 11, 13, 14, 16, 17, 18, 22, 36, 43, 46, 50, 53, 56, 57, 58, 72, 79, 80, 82, 86, 88, 90, 96, 102, 106, 107, 112, 113, 122, 123, 125, 127, 130, 133, 136, 139, 142, 151, 152, 155, 159, 162, 165, 167, 169, 173, 175, 176, 190, 202, 208, 211, 212, 214, 218, 219, 225, 226, 227, 228, 229, 238, 240], "descript": [6, 8, 11, 14, 33, 39, 42, 53, 60, 61, 104, 130, 145, 159, 160, 214, 218, 225, 226, 242], "fuse": [6, 24, 102, 117, 197, 219, 227], "particip": [6, 56, 70], "late": [6, 16, 137], "fusion": [6, 117, 124, 171, 197], "todo": [6, 101, 112], "08199": 7, "googlescholar": [7, 8, 10, 11, 17], "star": [7, 8, 10, 11, 17, 130, 218, 227, 229], "28": [7, 18, 48, 50, 69, 79, 101, 119, 137, 152, 155, 160, 169, 182, 193, 224, 227], "screen_qa": [7, 11], "86k": 7, "zero": [7, 8, 41, 43, 46, 52, 58, 70, 74, 75, 76, 77, 78, 86, 96, 101, 115, 119, 122, 123, 125, 142, 144, 155, 158, 160, 170, 173, 178, 181, 182, 187, 197, 218, 219, 225, 226, 229, 233], "shot": [7, 8, 11, 41, 43, 46, 48, 49, 52, 53, 58, 70, 74, 76, 77, 78, 86, 89, 90, 119, 121, 122, 125, 130, 142, 143, 144, 155, 158, 159, 160, 162, 170, 173, 174, 178, 181, 182, 187, 197, 218, 219, 225, 226, 240], "benchmark": [7, 18, 19, 22, 26, 27, 32, 34, 44, 53, 65, 86, 112, 137, 142, 145, 152, 160, 162, 164, 168, 170, 176, 181, 187, 189, 197, 201, 206, 214, 216, 221, 226, 228, 229, 235], "content": [7, 14, 16, 18, 65, 79, 82, 96, 127, 130, 138, 144, 147, 149, 170, 207, 211, 214, 218, 225], "86": [7, 14, 16, 19, 31, 45, 174, 175], "bound": [7, 10, 11, 18, 69, 98, 102, 112, 113, 124, 159, 191, 224], "box": [7, 10, 11, 18, 65, 88, 101, 107, 112, 127, 130, 147, 158, 159, 160, 191, 208, 218], "weight": [7, 22, 39, 74, 75, 86, 87, 90, 91, 96, 104, 106, 108, 117, 118, 119, 121, 127, 132, 145, 182, 188, 194, 196, 199, 218, 225, 226, 228, 240], "proprietari": [7, 165, 187, 208], "fine": [7, 16, 17, 22, 41, 49, 57, 79, 86, 87, 88, 91, 97, 102, 120, 125, 127, 130, 137, 139, 141, 143, 152, 162, 164, 169, 181, 189, 190, 202, 218, 223, 228, 230, 241], "tune": [7, 13, 22, 41, 43, 49, 65, 79, 86, 87, 91, 120, 123, 125, 130, 137, 139, 143, 152, 162, 164, 169, 173, 181, 189, 190, 202, 230, 241], "transfer": [7, 8, 11, 33, 47, 49, 61, 74, 90, 101, 176, 197], "four": [7, 29, 54, 74, 75, 84, 104, 105, 107, 146, 158, 165, 204, 212], "correspond": [7, 11, 18, 50, 57, 97, 106, 127, 137, 138, 143, 146, 160, 161, 206, 214, 225, 226, 227, 228, 229, 233], "section": [7, 71, 75, 97, 130, 137, 143, 145, 168, 214, 230], "sqa": [7, 145], "long": [7, 14, 16, 18, 22, 36, 39, 44, 46, 56, 70, 79, 96, 107, 108, 111, 112, 113, 127, 133, 149, 169, 187, 190, 195, 201, 202, 206, 212, 218, 225], "there": [7, 16, 33, 42, 79, 81, 97, 101, 106, 112, 122, 127, 130, 137, 175, 194, 206, 211, 213, 214, 224, 225], "comment": [7, 16, 49], "uic": 7, "bb": 7, "coordin": [7, 11, 17, 24, 79, 96, 169, 223, 225, 227, 229], "green": [7, 8, 10, 16, 50, 65, 79, 107, 108, 131, 133, 159, 165, 201, 226], "high": [7, 8, 16, 17, 19, 24, 32, 40, 45, 60, 61, 67, 68, 75, 80, 86, 87, 97, 112, 113, 115, 121, 127, 131, 133, 158, 162, 164, 165, 166, 169, 170, 203, 204, 206, 214, 217, 218, 227, 229, 230], "low": [7, 16, 17, 35, 50, 67, 75, 80, 86, 87, 88, 96, 97, 112, 113, 118, 124, 131, 146, 165, 166, 200, 204, 211, 214, 217, 218, 226, 227, 228], "temperatur": [7, 11, 49, 56, 63, 67, 79, 143, 189, 218, 237], "two": [7, 8, 10, 11, 14, 16, 18, 24, 30, 41, 57, 61, 62, 65, 85, 97, 102, 105, 107, 111, 125, 131, 132, 133, 137, 139, 146, 159, 160, 162, 165, 208, 214, 218, 223, 224, 225, 226, 227, 228, 229], "saturday": 7, "relev": [7, 16, 24, 43, 63, 90, 127, 211, 212, 213, 214, 216, 218, 227], "lack": [7, 14, 64, 75, 79, 127, 200, 206, 208, 211], "vlm": [7, 11, 17, 58, 96, 124, 155, 168, 241], "mllm": [7, 14, 18, 57, 61, 86, 166, 167], "vhs": 7, "66k": 7, "984": 7, "3k": [7, 67, 85, 165], "27": [7, 12, 18, 19, 50, 55, 69, 77, 79, 107, 130, 134, 137, 139, 155, 238, 242], "tabl": [7, 8, 11, 12, 16, 17, 18, 19, 43, 45, 47, 48, 50, 53, 54, 56, 57, 58, 60, 61, 62, 64, 71, 74, 75, 76, 78, 79, 80, 82, 83, 84, 88, 96, 97, 98, 101, 102, 104, 105, 106, 116, 119, 120, 122, 127, 130, 133, 137, 138, 139, 141, 142, 143, 144, 145, 146, 147, 152, 154, 158, 159, 160, 161, 162, 164, 165, 167, 168, 169, 170, 171, 181, 187, 188, 189, 211, 214, 218, 226, 229], "remain": [7, 8, 22, 24, 61, 75, 96, 119, 160, 208, 226, 227], "suitabl": [7, 61, 211, 213], "due": [7, 8, 14, 16, 26, 31, 32, 75, 105, 106, 111, 113, 133, 162, 175, 178, 214], "divers": [7, 17, 18, 22, 25, 26, 28, 32, 33, 34, 35, 44, 53, 75, 79, 80, 86, 116, 176, 184, 204, 206, 211, 217, 218], "establish": [7, 24, 25, 207, 227, 231], "presenc": 7, "field": [7, 8, 31, 75, 200, 222, 229], "although": [7, 14, 16, 40, 176, 212], "aitw": [7, 17], "larger": [7, 11, 41, 91, 105, 124], "sampl": [7, 11, 22, 45, 48, 49, 52, 67, 70, 80, 122, 127, 130, 132, 133, 140, 143, 145, 146, 158, 160, 162, 165, 187, 202, 224, 225, 226, 227, 237], "method": [7, 20, 22, 27, 33, 34, 36, 39, 44, 89, 90, 96, 97, 111, 112, 121, 123, 124, 125, 127, 132, 140, 158, 162, 167, 191, 192, 199, 211, 213, 216, 218, 223, 230, 231, 232], "85k": [7, 43], "comparison": [7, 12, 20, 43, 56, 69, 79, 85, 90, 96, 118, 130, 138, 139, 145, 147, 152, 162, 165, 169, 171, 189, 199, 211, 218, 223, 226, 229, 231, 238], "largest": [7, 70, 178, 226], "qa": [7, 11, 17, 27, 36, 45, 63, 69, 70, 77, 85, 130, 143, 145, 149, 155, 159, 164, 165, 167, 169, 170, 203, 211, 213, 218, 221, 238, 240], "rather": [7, 75, 138, 162, 214, 218, 233], "crop": [7, 165], "region": [7, 218, 226], "websrc": [7, 11, 17], "better": [7, 22, 33, 44, 75, 85, 87, 88, 91, 97, 112, 127, 130, 160, 162, 169, 177, 190, 193, 199, 204, 206, 208, 211, 214, 216, 218, 225, 229], "unanswer": [7, 218], "complexqa": 7, "complement": [7, 40, 61, 212], "count": [7, 11, 57, 71, 79, 81, 174], "arithmet": [7, 41, 68, 115, 122, 124], "not": [7, 8, 11, 13, 14, 16, 22, 47, 53, 61, 65, 75, 79, 80, 89, 101, 105, 106, 107, 108, 112, 113, 119, 120, 122, 124, 127, 130, 137, 139, 142, 159, 160, 166, 170, 178, 184, 192, 203, 204, 206, 211, 213, 214, 216, 218, 224, 225, 226, 227, 228, 229, 230, 231, 233], "exhaust": [7, 225, 233], "space": [7, 8, 14, 24, 33, 34, 39, 47, 61, 88, 96, 127, 130, 218, 224, 225, 231], "constraint": [7, 106, 225], "document": [7, 11, 14, 18, 19, 39, 46, 62, 82, 101, 112, 165, 169, 175, 176, 203, 206, 211, 212, 214, 216, 218, 220, 222], "close": [7, 16, 49, 50, 68, 71, 79, 90, 113, 127, 130, 137, 165, 197, 226, 230], "domain": [7, 11, 17, 20, 26, 28, 33, 34, 42, 44, 49, 63, 71, 75, 79, 86, 90, 91, 96, 127, 133, 152, 169, 182, 184, 211, 213, 214, 216, 226, 230, 231], "widget": [7, 10, 137], "deka": [7, 10], "li": [7, 10, 11, 21, 31, 52, 90, 96, 127, 170, 174, 217], "2020b": [7, 20, 137], "refer": [7, 10, 11, 14, 85, 89, 96, 127, 133, 137, 151, 159, 170, 197, 202, 206, 207, 214, 225, 227, 228, 240], "express": [7, 11, 61, 97, 170, 197, 225], "wu": [7, 23, 26, 31, 155, 170, 202, 218], "bai": [7, 10, 65, 75, 120, 170, 181], "2021": [7, 8, 41, 49, 50, 52, 56, 90, 96, 122, 130, 137, 143, 184, 195, 202], "action": [7, 8, 10, 16, 22, 24, 29, 34, 47, 133, 155, 212, 218], "motif": [7, 11], "visualwebarena": 7, "wild": [7, 60, 86, 159, 170, 225, 227, 228, 229], "ocr": [7, 10, 11, 14, 16, 17, 18, 54, 57, 58, 59, 63, 76, 149, 160, 161, 162, 164, 165, 168, 169, 170, 201], "docvqa": [7, 11, 149, 155, 160, 165, 170], "mathew": 7, "textvqa": [7, 58, 149, 155, 160, 161, 162, 165, 170, 171, 172, 174], "singh": 7, "2019": [7, 49, 50, 52, 54, 79, 96, 99, 106, 107, 130, 137, 143, 195, 214], "kahou": 7, "span": [7, 42, 75, 79, 130, 135, 206, 214], "squad": [7, 11, 64, 69, 77, 130, 175, 211], "hop": [7, 44, 63, 209, 211, 215, 218, 219, 221, 235, 239], "truth": [7, 10, 14, 85, 127, 130, 140, 199, 223, 225, 226, 228, 229, 238], "a_i": [7, 17, 201], "avg": [7, 54, 165, 170], "frac": [7, 46, 56, 72, 73, 81, 82, 102, 107, 112, 122, 125, 155, 195, 201, 218, 224, 225, 226, 227, 228, 237], "sum_": [7, 81, 82, 130, 166, 201, 218, 219, 223, 224, 225, 226, 227, 228, 229], "max_": [7, 82, 218, 219, 239], "left": [7, 10, 28, 43, 46, 65, 79, 81, 82, 98, 106, 107, 112, 113, 117, 122, 124, 125, 130, 131, 132, 133, 143, 165, 168, 175, 176, 201, 206, 211, 218, 224, 225, 226, 228, 229, 233, 239], "g_": [7, 218, 225, 227], "right": [7, 10, 24, 28, 43, 46, 47, 79, 81, 82, 98, 106, 107, 112, 113, 117, 122, 124, 125, 130, 131, 132, 133, 143, 165, 168, 171, 175, 176, 177, 201, 206, 211, 218, 224, 225, 226, 228, 229, 239], "math": [7, 33, 44, 53, 56, 120, 127, 131, 146, 149, 170, 189, 211, 236, 237, 240], "no": [7, 16, 47, 54, 57, 59, 61, 69, 79, 91, 104, 107, 113, 116, 130, 155, 159, 164, 174, 204, 213, 224, 225, 228, 229, 240], "exact": [7, 8, 53, 58, 61, 87, 97, 130, 206, 238], "match": [7, 10, 47, 58, 90, 98, 116, 120, 137, 145, 147, 151, 155, 170, 173, 201, 222, 229, 231, 238], "em": [7, 65, 69, 211, 224, 238], "f1": [7, 10, 11, 62, 63, 69, 77, 82, 84, 145, 152, 175, 211, 237, 238, 239, 242], "siri": [7, 143, 146], "intersect": [7, 11, 224], "union": [7, 11, 204], "ss": [7, 16, 32, 136, 144, 147, 214], "stage": [7, 29, 39, 50, 107, 122, 124, 137, 139, 141, 142, 144, 147, 152, 160, 161, 166, 167, 168, 169, 194, 195, 201, 211, 227, 241], "split": [7, 11, 29, 104, 105, 106, 137, 158, 161, 211], "prefilt": 7, "5000": [7, 69, 80, 147, 155, 162], "oct": 7, "2024": [7, 14, 17, 18, 33, 41, 52, 54, 56, 58, 68, 96, 118, 127, 133, 141, 164, 170, 184, 214, 215, 217, 218], "vs": [7, 8, 16, 17, 18, 19, 39, 47, 54, 58, 62, 67, 68, 69, 77, 79, 80, 85, 97, 101, 104, 124, 127, 130, 132, 139, 143, 144, 145, 147, 149, 162, 165, 166, 172, 206, 214, 226, 237, 242], "palm": [7, 11, 57, 60, 149, 159, 181, 237, 238], "few": [7, 11, 16, 27, 41, 49, 52, 53, 58, 74, 76, 78, 89, 90, 106, 122, 130, 159, 160, 161, 162, 175, 178, 182, 187, 218, 219, 224, 225, 226, 230, 240], "categori": [7, 65, 75, 80, 130, 159, 184, 192, 197, 213, 230], "distribut": [7, 32, 54, 74, 75, 79, 87, 96, 101, 105, 106, 111, 113, 122, 124, 133, 155, 160, 162, 222, 223, 230, 231], "see": [7, 11, 16, 71, 75, 79, 101, 130, 143, 225, 226], "appendix": [7, 11], "35": [7, 15, 18, 46, 50, 54, 56, 61, 63, 79, 85, 117, 119, 136, 137, 139, 147, 152, 165, 187, 201, 226, 227, 229, 236, 239, 240], "352": 7, "80": [7, 12, 13, 14, 22, 35, 43, 49, 54, 56, 58, 61, 64, 68, 70, 71, 72, 76, 77, 79, 85, 131, 134, 135, 137, 138, 139, 141, 145, 160, 174, 175, 182, 203, 214, 229, 230, 240, 241], "83": [7, 8, 14, 49, 54, 55, 58, 105, 106, 143, 164, 175, 214], "47": [7, 47, 50, 54, 55, 119, 151, 152, 155, 165, 214, 229], "5k": [7, 54, 62, 67, 70], "84": [7, 14, 43, 79, 105, 122, 152, 187, 229], "51": [7, 8, 11, 19, 76, 118, 147, 152, 193, 204, 214, 225, 226, 240], "49": [7, 8, 10, 15, 19, 43, 47, 55, 70, 119, 139, 158, 182, 227, 238], "48": [7, 8, 55, 70, 77, 132, 135, 159, 187, 201, 229], "webview": 7, "canva": 7, "18": [7, 8, 18, 47, 52, 54, 55, 58, 59, 63, 64, 68, 69, 70, 72, 97, 102, 120, 137, 143, 147, 152, 158, 188, 241], "fuyu": [7, 10], "8b": [7, 13, 49, 52, 53, 62, 64, 65, 105, 145, 149, 164, 166, 168, 171, 172, 181, 188, 189, 218, 219], "gemini": [7, 11, 16, 18, 19, 46, 52, 58, 61, 64, 65, 79, 86, 142, 155, 164, 165, 168, 169, 189, 241], "flash": [7, 50, 64, 96, 151, 170, 181, 182, 229, 240], "pro": [7, 16, 17, 52, 58, 61, 64, 65, 79, 142, 149, 155, 164, 165, 169, 170, 189, 241], "4o": [7, 13, 16, 17, 18, 19, 34, 44, 52, 53, 54, 55, 62, 65, 68, 72, 127, 145, 146, 155, 165, 167, 168, 169, 170, 171, 172, 187, 188, 189, 217, 241], "screenai": [7, 11], "5b": [7, 11, 56, 65, 98, 144, 147, 152, 155, 160, 174, 187, 188, 240, 241], "paligemma": [7, 164], "3b": [7, 52, 56, 58, 67, 98, 117, 130, 143, 166, 169, 174, 188, 189, 195], "cdl": 7, "vqa": [7, 11, 58, 59, 60, 155, 160, 161, 165, 166, 169, 170, 172, 174], "local": [7, 16, 75, 86, 97, 101, 155, 168, 169, 191, 195, 201, 206, 209, 220, 221, 228, 236], "rich": [7, 146, 214], "layout": [7, 61, 214], "canon": [7, 229], "look": [7, 79, 190, 193, 233], "composit": [7, 17, 29, 61, 105, 169, 223], "imag": [7, 11, 14, 44, 57, 58, 60, 79, 86, 96, 113, 120, 159, 161, 162, 164, 166, 168, 169, 172, 191, 201, 211, 222, 223, 224, 225, 227, 228, 229, 230], "trace": [7, 78, 102], "scroll": [7, 12, 18], "platform": [7, 17, 32, 218], "ios": [7, 10], "main": [7, 16, 33, 45, 54, 56, 61, 62, 65, 71, 79, 85, 113, 122, 127, 143, 182, 197, 206, 211, 225, 233], "visaulwebbench": 7, "webqa": 7, "decis": [7, 14, 16, 22, 28, 29, 43, 47, 214], "make": [7, 14, 16, 22, 24, 28, 29, 43, 61, 79, 88, 101, 111, 112, 130, 133, 140, 169, 176, 191, 193, 202, 203, 205, 206, 211, 214, 218, 222, 225, 226, 228, 229], "privaci": [7, 10, 13], "fair": [7, 52, 127], "896": [7, 63, 168], "support": [7, 13, 24, 27, 28, 47, 61, 69, 75, 79, 96, 97, 124, 127, 139, 165, 169, 170, 189, 190, 202, 204, 205, 206, 208, 214, 216, 218, 227], "overlaid": 7, "class": [7, 8, 11, 51, 101, 191, 192, 230], "name": [7, 8, 11, 16, 18, 19, 24, 33, 43, 50, 52, 53, 61, 79, 119, 130, 160, 181, 197, 199, 206, 214, 218, 225], "charact": [7, 57, 60, 130, 145, 147, 195, 201, 218], "print": [7, 49], "determin": [7, 29, 33, 61, 85, 101, 132, 211], "whether": [7, 79, 127, 130, 175, 187, 206, 211], "occlud": [7, 201], "ghost": [7, 223], "90": [7, 16, 49, 56, 68, 70, 71, 76, 80, 82, 106, 107, 117, 133, 149, 152, 159, 165, 168, 174, 203, 225, 226, 240], "95": [7, 31, 33, 38, 48, 51, 52, 56, 60, 67, 70, 76, 81, 104, 119, 143, 155, 225, 237, 241], "inter": [7, 18, 104, 195], "agreement": 7, "97": [7, 8, 16, 49, 55, 69, 149, 159, 160, 225], "templat": [7, 39, 53, 61, 79, 220], "give": [7, 43, 71, 79, 130, 214, 216, 218, 228], "below": [7, 10, 11, 16, 50, 79, 130, 214], "list": [7, 8, 11, 18, 45, 61, 75, 79, 101, 119, 127, 130, 164, 214, 218], "various": [7, 10, 11, 17, 22, 25, 26, 28, 31, 36, 42, 52, 53, 60, 62, 75, 78, 79, 89, 96, 118, 124, 138, 139, 145, 164, 171, 178, 192, 199, 200, 205, 212, 213, 216, 218, 225, 228, 230, 232, 233], "way": [7, 11, 22, 32, 33, 40, 41, 42, 88, 89, 101, 211, 218], "rephras": [7, 11, 130], "possibl": [7, 11, 24, 29, 33, 47, 79, 105, 113, 127, 214, 218, 230], "without": [7, 11, 16, 41, 50, 53, 61, 96, 105, 108, 116, 118, 122, 127, 161, 165, 168, 175, 184, 189, 196, 197, 203, 214, 218, 225, 227, 228, 229, 240], "extra": [7, 11, 61, 218], "word": [7, 11, 12, 18, 19, 44, 62, 69, 75, 79, 82, 89, 106, 116, 130, 145, 151, 175, 195, 201, 206, 218, 226, 233, 236], "from": [7, 10, 11, 16, 21, 22, 24, 25, 27, 28, 31, 33, 36, 37, 39, 41, 45, 46, 50, 53, 54, 57, 58, 60, 61, 62, 67, 75, 79, 85, 86, 87, 88, 90, 96, 97, 101, 102, 105, 119, 120, 122, 124, 132, 137, 138, 139, 143, 145, 151, 158, 160, 161, 162, 164, 167, 169, 170, 177, 184, 189, 191, 192, 196, 197, 199, 200, 201, 202, 203, 204, 205, 206, 209, 211, 212, 213, 216, 218, 221, 222, 223, 224, 226, 228, 230, 231, 234], "provid": [7, 10, 11, 16, 22, 32, 33, 45, 50, 53, 61, 72, 75, 79, 90, 91, 96, 98, 101, 104, 111, 127, 141, 161, 187, 199, 203, 206, 211, 214, 218, 225, 229], "element": [7, 10, 18, 40, 61, 79, 216, 218], "output": [7, 8, 10, 11, 16, 22, 33, 53, 61, 79, 84, 87, 96, 104, 107, 112, 113, 119, 125, 127, 130, 145, 146, 151, 174, 175, 184, 189, 206, 214, 223, 225, 229], "squar": [7, 11, 165, 228], "bracket": [7, 11, 218], "now": [7, 11, 61, 79, 184, 218, 233], "your": [7, 11, 16, 33, 44, 61, 72, 79, 86, 127, 214, 218], "turn": [7, 11, 25, 63, 130, 141, 143, 159, 165], "sentenc": [7, 8, 11, 19, 43, 45, 61, 127, 130, 175, 204, 206, 211, 214, 218, 222], "singl": [7, 10, 14, 16, 18, 24, 29, 32, 36, 45, 50, 58, 61, 63, 64, 69, 77, 79, 82, 85, 89, 97, 105, 106, 107, 108, 113, 127, 137, 140, 143, 162, 165, 168, 170, 175, 190, 191, 201, 203, 211, 213, 214, 218, 225, 230, 238], "here": [7, 11, 13, 24, 26, 50, 72, 75, 78, 79, 80, 101, 104, 107, 130, 159, 165, 218, 223, 224], "what": [7, 10, 11, 16, 25, 41, 44, 105, 130, 177, 190, 206, 214, 218, 238], "gender": [7, 11], "male": [7, 11], "multipl": [7, 18, 25, 28, 33, 35, 36, 40, 43, 45, 46, 50, 59, 75, 77, 79, 87, 90, 97, 105, 108, 112, 127, 133, 137, 155, 160, 162, 164, 170, 195, 199, 203, 206, 211, 213, 214, 216, 218, 224, 225], "jon": [7, 11], "brown": [7, 8, 11, 27, 102, 130, 133, 138, 202], "contain": [7, 8, 18, 50, 53, 62, 71, 75, 101, 104, 119, 130, 133, 162, 181, 204, 205, 206, 233], "procedur": [7, 16, 26, 60, 67, 136, 166, 203, 223], "outlin": [7, 130, 207, 218], "06817": 8, "1063": 8, "everyday": 8, "brain": [8, 37, 77, 121], "team": [8, 56, 145, 147, 151, 152, 154, 155, 164, 182], "agnost": [8, 176], "dataset": [8, 34, 35, 44, 55, 58, 61, 62, 68, 74, 75, 78, 86, 96, 101, 106, 159, 160, 164, 175, 181, 189, 190, 191, 192, 194, 196, 199, 202, 203, 206, 211, 212, 213, 214, 218, 219, 222, 223, 225, 226, 230, 231], "modern": [8, 40, 61], "downstream": [8, 41, 88, 90, 91, 96, 175, 178, 189], "level": [8, 16, 18, 24, 40, 44, 67, 78, 80, 86, 97, 101, 107, 112, 127, 133, 165, 166, 170, 175, 201, 211, 213, 214, 226, 233, 237], "has": [8, 11, 16, 26, 32, 34, 53, 89, 97, 104, 105, 107, 113, 124, 125, 127, 130, 145, 162, 165, 175, 184, 187, 189, 196, 199, 200, 211, 214, 218, 224, 233], "other": [8, 11, 24, 28, 33, 42, 53, 54, 56, 71, 75, 90, 101, 111, 127, 130, 133, 134, 135, 137, 138, 143, 152, 165, 170, 189, 191, 196, 200, 204, 211, 214, 218], "natur": [8, 14, 24, 25, 28, 40, 44, 47, 61, 75, 79, 87, 88, 89, 91, 106, 144, 159, 175, 176, 191, 203, 208, 211, 214, 218], "speech": [8, 42, 83, 86, 136, 142], "recognit": [8, 14, 17, 57, 86, 142, 147, 160, 164, 170, 190], "shown": [8, 16, 29, 35, 50, 101, 108, 165, 189, 199, 214, 218, 227, 228, 229], "particular": [8, 75, 91, 113, 184, 211, 216, 218, 232, 233], "critic": [8, 24, 36, 106, 133, 155, 211], "difficulti": [8, 45, 75], "key": [8, 16, 18, 33, 42, 47, 61, 64, 79, 81, 97, 101, 102, 113, 130, 133, 155, 164, 190, 197, 212, 214, 217, 218, 227, 229, 236, 239, 240], "lie": [8, 70], "train": [8, 14, 16, 22, 39, 41, 44, 60, 61, 79, 86, 87, 88, 89, 91, 96, 97, 112, 113, 116, 119, 124, 125, 127, 130, 132, 135, 136, 137, 141, 151, 158, 166, 167, 190, 192, 193, 194, 196, 199, 200, 201, 202, 203, 211, 213, 218, 224, 228, 230, 232, 236, 242], "capac": [8, 27, 28, 75, 111, 160, 178], "absorb": 8, "dub": [8, 40, 200], "exhibit": [8, 31, 41, 42, 184, 212, 223], "scalabl": [8, 32, 34, 71, 79, 86, 87, 97, 127], "properti": [8, 120, 207, 218, 221, 235], "verifi": [8, 16, 26, 31, 44, 45, 87, 127, 133, 155, 161, 190, 199, 206, 207], "studi": [8, 11, 16, 22, 25, 28, 31, 86, 89, 111, 125, 127, 130, 137, 143, 162, 164, 176, 184], "abil": [8, 24, 27, 31, 32, 41, 42, 45, 46, 62, 75, 79, 90, 120, 160, 189, 206, 211, 227], "function": [8, 13, 14, 18, 33, 41, 42, 46, 47, 61, 79, 97, 101, 105, 130, 133, 169, 199, 211, 222, 223, 240], "size": [8, 10, 11, 44, 56, 67, 70, 75, 85, 90, 97, 104, 105, 106, 107, 112, 113, 115, 117, 118, 122, 140, 143, 161, 167, 168, 169, 175, 181, 187, 201, 214, 218, 219, 224, 225, 226], "project": [8, 26, 87, 96, 102, 130, 137, 140, 172, 195, 218, 224, 225, 229, 236, 242], "websit": [8, 17, 39, 137, 218, 242], "video": [8, 16, 59, 104, 113, 133, 137, 168, 169, 211, 222, 225, 228, 229], "found": [8, 25, 26, 145, 203, 216, 218, 228], "transformer1": 8, "io": [8, 9, 15, 19, 52, 54, 56, 60, 63, 65, 79, 87, 96, 101, 107, 113, 136, 141, 142, 144, 145, 147, 151, 159, 161, 167, 177, 220, 228], "demo": [8, 100, 143, 147, 168, 229], "clip": [8, 60, 81, 125, 130, 133, 155, 159, 161, 162, 165, 166, 169, 171, 172, 173, 174, 227, 229, 241], "13": [8, 10, 11, 16, 24, 28, 45, 50, 51, 52, 53, 54, 58, 59, 62, 63, 64, 68, 69, 70, 72, 75, 76, 79, 80, 115, 119, 124, 135, 137, 142, 147, 152, 174, 187, 188, 189, 205, 226, 229, 237, 240], "17": [8, 19, 49, 50, 52, 53, 54, 58, 64, 69, 70, 76, 79, 82, 83, 84, 119, 120, 134, 137, 145, 147, 158, 162, 164, 182, 229, 233, 237, 241], "700": [8, 10, 143, 171], "3hz": 8, "25": [8, 11, 16, 18, 24, 38, 46, 47, 50, 54, 57, 58, 63, 67, 69, 71, 75, 76, 78, 82, 98, 104, 113, 119, 121, 123, 137, 144, 147, 151, 152, 161, 164, 166, 168, 184, 195, 200, 201, 214, 223, 225, 226, 229, 240], "36": [8, 46, 55, 58, 63, 69, 79, 137, 139, 164, 165, 189, 238], "50": [8, 9, 10, 11, 12, 19, 45, 46, 47, 49, 50, 53, 54, 56, 57, 59, 61, 63, 65, 71, 72, 75, 76, 77, 79, 80, 82, 101, 106, 113, 117, 119, 121, 124, 135, 141, 143, 149, 152, 155, 158, 160, 161, 168, 169, 175, 182, 187, 193, 195, 206, 214, 218, 225, 226, 227, 229, 231, 236, 237, 240, 241], "saycan": [8, 22], "polici": [8, 101, 127, 130, 164, 189, 214, 242], "sequenc": [8, 14, 16, 18, 24, 26, 34, 49, 105, 112, 113, 132, 137, 139, 140, 141, 159, 165, 166, 169, 172, 176, 195, 218, 225, 228], "gato": 8, "grasp": 8, "130k": 8, "episod": [8, 10, 16, 22, 130, 137], "reward": [8, 16, 22, 46, 47, 87, 89, 130, 132, 151, 155, 181, 189, 202], "_h": 8, "y_k": 8, "attent": [8, 24, 39, 50, 64, 65, 69, 87, 96, 102, 105, 117, 134, 151, 166, 169, 170, 174, 175, 177, 178, 181, 182, 184, 187, 195, 201, 214, 225, 226, 227, 229, 239, 240], "x_t": [8, 144], "a_t": [8, 79, 133, 219], "imit": [8, 70, 202, 240], "clone": [8, 17, 202], "negat": [8, 16, 29, 67, 130, 133, 140, 211, 214], "log": [8, 43, 48, 50, 59, 81, 84, 101, 139, 140, 155, 166, 170, 218, 219, 225, 226, 229, 242], "likelihood": [8, 59, 140, 219], "classroom": 8, "offic": [8, 19, 79, 225, 227], "kitchen": [8, 59, 225], "realist": [8, 64, 79, 98, 133, 224, 225], "kitchen1": 8, "rest": [8, 11, 43, 101, 218], "kitchen2": 8, "manipul": 8, "throughout": [8, 36], "skill": [8, 25, 75, 127, 165], "expand": [8, 79, 127, 188, 211], "pick": [8, 45, 225], "verb": [8, 214, 220], "noun": [8, 69], "upright": 8, "coke": 8, "appl": [8, 130, 146, 168, 175, 218], "drawer": 8, "imagenet": [8, 104, 105, 120, 155, 166, 175, 192, 229, 230], "film": [8, 130], "featur": [8, 11, 53, 54, 75, 96, 141, 143, 144, 161, 165, 166, 167, 170, 189, 194, 195, 197, 199, 218, 224, 225, 228, 231], "wise": [8, 10, 75, 79, 87, 112, 115, 117, 118, 119, 121, 122, 124, 125, 152, 165, 167, 170, 195, 199, 229, 231, 237, 241], "linear": [8, 68, 105, 112, 113, 122, 134, 176, 195, 218, 219, 225, 226, 236], "modul": [8, 14, 33, 39, 40, 98, 119, 134, 141, 144, 145, 147, 152, 166, 174, 218, 219, 229], "learner": [8, 86], "roll": [8, 155, 214], "pitch": [8, 119, 206], "yaw": 8, "efficientnet": 8, "b3": 8, "9x9x512": 8, "tokenlearn": 8, "81": [8, 49, 80, 85, 117, 119, 143, 155, 165, 238], "diagram": [8, 22, 57, 61, 67, 130, 136, 141, 144, 165, 166, 171, 203, 228], "embed": [8, 11, 43, 89, 106, 116, 117, 133, 136, 138, 140, 141, 143, 144, 145, 146, 161, 165, 167, 169, 170, 175, 184, 201, 214, 218, 229, 231, 238], "pre": [8, 11, 17, 39, 60, 79, 86, 87, 91, 96, 134, 139, 145, 151, 168, 170, 181, 190, 196, 199, 211, 218, 230, 241], "layer": [8, 13, 32, 39, 87, 91, 96, 102, 105, 106, 107, 113, 114, 116, 121, 122, 130, 134, 138, 146, 164, 171, 172, 175, 176, 184, 199, 229], "reduc": [8, 16, 26, 91, 96, 105, 106, 112, 113, 120, 124, 200, 211, 214, 218, 220, 224, 232], "fed": [8, 11, 143, 162, 169, 214, 227], "300x300": 8, "256": [8, 60, 65, 112, 123, 124, 135, 138, 143, 155, 160, 161, 165, 195, 211, 223, 224, 225, 233, 238], "bin": [8, 101, 224, 236], "16m": 8, "26": [8, 19, 49, 50, 52, 58, 61, 71, 75, 79, 80, 102, 135, 137, 147, 178, 195, 197, 205, 215, 227, 229, 238], "mbconv": 8, "19m": 8, "100ms": [8, 101, 145], "33hz": 8, "33": [8, 49, 51, 53, 55, 68, 72, 85, 98, 116, 125, 137, 165, 229, 238, 239], "744": 8, "togeth": [8, 11, 24, 26, 64, 211, 224, 227], "seen": [8, 90, 107, 158, 225], "unseen": [8, 16, 88, 216, 225, 229], "robust": [8, 33, 64, 75, 79, 86, 90, 212, 225, 226, 228], "200": [8, 16, 57, 62, 69, 79, 82, 117, 124, 125, 130, 135, 139, 141, 143, 144, 155, 164, 165, 167, 169, 192, 218, 226, 227, 229], "21": [8, 9, 41, 47, 58, 69, 70, 75, 76, 85, 105, 119, 130, 137, 141, 152, 155, 160, 165, 195, 217, 224, 229, 240], "30": [8, 10, 14, 18, 43, 48, 49, 50, 54, 55, 56, 57, 58, 63, 64, 67, 69, 71, 77, 78, 79, 82, 98, 101, 106, 117, 120, 134, 137, 139, 140, 141, 143, 144, 147, 149, 155, 159, 164, 166, 169, 172, 174, 187, 189, 196, 223, 225, 226, 229, 237, 238, 241], "reed": 8, "bc": [8, 133], "jang": 8, "xl": [8, 44, 48, 62, 140, 196, 236, 241], "32": [8, 10, 15, 16, 18, 45, 48, 50, 53, 55, 56, 62, 63, 64, 65, 67, 69, 77, 97, 98, 102, 105, 107, 113, 118, 119, 123, 124, 127, 130, 134, 135, 137, 139, 143, 149, 152, 155, 165, 166, 168, 170, 171, 172, 173, 174, 175, 182, 188, 189, 195, 201, 218, 224, 229, 233, 236, 238, 240], "76": [8, 16, 18, 55, 69, 71, 106, 165, 172, 192, 229], "24": [8, 10, 11, 18, 43, 46, 53, 54, 55, 56, 57, 62, 63, 69, 72, 74, 79, 80, 135, 137, 138, 139, 149, 152, 155, 160, 165, 169, 174, 189, 201, 226, 229, 233, 240], "59": [8, 11, 14, 48, 49, 55, 63, 166, 229], "l1": [8, 123, 144, 195, 227], "l2": [8, 113, 123, 195, 225, 229, 242], "l3": [8, 52, 195], "23": [8, 15, 18, 45, 46, 51, 53, 76, 79, 115, 119, 134, 137, 144, 158, 166, 171, 172, 214, 229, 233, 236, 240], "87": [8, 43, 63, 68, 70, 85, 143, 166], "kuka": 8, "iiwa": 8, "eval": [8, 44, 48, 55, 64, 66, 67, 71, 72, 74, 76, 77, 79, 125, 159, 181, 187, 188, 189, 240], "39": [8, 71, 106, 135, 152, 182, 214, 229], "67": [8, 55, 58, 76, 117, 119, 122, 192, 203, 229], "37": [8, 48, 50, 54, 55, 59, 63, 64, 71, 122, 123, 133, 137, 151, 195, 214, 229, 236], "75": [8, 14, 16, 55, 68, 69, 79, 82, 85, 116, 118, 119, 120, 122, 161, 165, 195, 214, 229, 240], "dexter": 8, "280ms": 8, "jitter": [8, 229], "vr": 8, "6d": 8, "checkpoint": [8, 10, 96, 97, 105, 106, 107, 123, 130, 164, 182, 226, 229], "sim": [8, 24, 127, 136, 140, 147, 151, 155, 170, 228, 229, 230], "lee": [8, 170], "551": [8, 196], "retinagan": 8, "53": [8, 16, 43, 54, 59, 68, 75, 76, 119, 139, 147, 149, 159, 166, 196], "distractor": [8, 64, 69], "background": [8, 61, 130, 131, 158], "these": [8, 11, 14, 22, 24, 25, 29, 32, 34, 35, 40, 53, 58, 61, 75, 96, 97, 101, 102, 104, 107, 111, 113, 119, 130, 133, 137, 165, 170, 175, 176, 204, 206, 207, 211, 214, 218, 223, 224, 225, 226, 230], "sec": [8, 97, 136, 225, 227], "exclud": [8, 144, 187], "total": [8, 18, 57, 75, 106, 113, 116, 145, 160, 187, 226, 229], "dure": [8, 16, 29, 31, 36, 39, 43, 50, 60, 75, 88, 96, 101, 104, 127, 133, 140, 143, 160, 168, 175, 176, 189, 201, 214, 225, 233], "were": [8, 24, 50, 75, 79, 88, 101, 105, 116, 226], "counter": 8, "rice": [8, 174], "chip": [8, 70, 112, 164], "bag": [8, 143, 190, 226], "middl": [8, 28, 36, 64, 68, 75, 124, 168, 204, 211, 218, 225, 229, 240], "redbul": 8, "7up": 8, "bottom": [8, 18, 28, 79, 84, 88, 143, 159, 165, 171, 172, 201, 218, 225, 226, 228, 229], "move": [8, 74, 79], "bowl": 8, "blue": [8, 10, 13, 61, 89, 101, 106, 108, 112, 130, 143, 160, 165, 218, 223, 224, 226], "plastic": [8, 242], "bottl": 8, "pepsi": 8, "spong": 8, "jalapeno": 8, "water": [8, 218, 223], "rxbar": 8, "blueberri": 8, "chocol": [8, 70], "white": [8, 218], "knock": 8, "12": [8, 10, 11, 16, 18, 19, 24, 45, 49, 50, 51, 52, 53, 54, 55, 58, 59, 62, 63, 67, 72, 75, 76, 77, 79, 82, 96, 98, 102, 104, 118, 119, 122, 123, 130, 135, 137, 138, 143, 145, 147, 152, 158, 159, 161, 162, 164, 165, 166, 170, 174, 176, 182, 187, 189, 195, 201, 214, 218, 223, 226, 227, 229, 236, 238, 240], "would": [8, 79, 205, 214, 218], "you": [8, 11, 16, 33, 50, 53, 61, 79, 127, 130, 190, 211, 214, 218], "put": [8, 101], "energi": [8, 214], "bar": [8, 16, 47, 101, 225, 226], "me": [8, 16, 39, 79, 130, 218, 242], "lime": 8, "soda": 8, "throw": [8, 24], "away": [8, 218], "tea": 8, "item": [8, 16, 61, 79], "multigrain": 8, "far": [8, 191, 233], "trash": [8, 130], "spill": 8, "my": [8, 16, 79, 130, 175, 218], "someth": [8, 70], "help": [8, 16, 24, 25, 70, 85, 130, 133, 168, 172, 204, 206, 214, 218], "clean": [8, 61, 134, 135, 137, 140, 143, 144, 152, 160, 170, 214], "just": [8, 41, 61, 65, 175, 192, 214, 230, 233], "drink": 8, "snack": 8, "recov": [8, 16, 223, 227, 229], "fruit": 8, "lunch": 8, "appag": [9, 14, 16], "offici": [9, 137, 164], "13771": 9, "mnotgod96": 9, "llms": [9, 10, 13, 15, 16, 20, 21, 22, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 47, 49, 52, 57, 58, 60, 61, 62, 63, 64, 75, 76, 77, 80, 87, 96, 131, 132, 133, 146, 164, 173, 182, 184, 187, 206, 207, 208, 211, 212, 213, 216, 217, 218, 219, 237, 238, 240], "tap": [9, 14, 16, 17, 229], "swipe": [9, 10, 14], "1s": 9, "10935": 10, "nanj": [10, 167], "shanghai": [10, 39, 62, 65, 240, 242], "laboratori": [10, 45, 53, 58, 60, 62, 65], "122": 10, "njucckevin": 10, "dom": [10, 11, 17, 54, 79], "viewhierarchi": 10, "pure": [10, 160, 169, 170], "maco": [10, 19, 79], "lvlm": [10, 58, 59, 160], "600": [10, 17, 77, 119, 124, 141, 144, 145, 214, 226], "1200": [10, 214, 226], "select": [10, 18, 29, 32, 34, 35, 42, 53, 58, 61, 79, 85, 101, 127, 132, 133, 137, 187, 197, 211, 212, 213, 216, 227, 228], "target": [10, 11, 18, 33, 39, 89, 137, 138, 139, 140, 165, 199, 201, 214, 218, 228, 229], "occasion": 10, "employ": [10, 19, 28, 34, 45, 60, 89, 97, 138, 144, 184, 201], "methodolog": [10, 79], "locat": [10, 16, 18, 62, 69, 79, 101, 214, 218, 223, 224, 229], "sole": [10, 212], "reli": [10, 32, 34, 120, 206, 212, 218, 224], "shi": [10, 195], "liu": [10, 23, 27, 31, 96, 130, 159, 161, 198, 204, 214], "gur": 10, "burn": 10, "centric": [10, 160], "prompt": [10, 13, 14, 17, 20, 22, 24, 26, 30, 34, 39, 45, 48, 49, 52, 63, 72, 77, 87, 89, 96, 102, 123, 132, 133, 139, 140, 142, 149, 159, 160, 162, 165, 167, 187, 211, 236, 242], "zheng": [10, 26, 31, 51, 96, 184, 215, 237], "kim": [10, 202], "deng": 10, "4v": [10, 12, 14, 16, 18, 19, 53, 57, 58, 60, 79, 86, 161, 165, 171, 172], "shaw": 10, "zhan": 10, "hong": [10, 26, 31, 58, 61, 62, 96, 166, 217], "zhu": [10, 227], "ye": 10, "vit": [10, 11, 60, 136, 155, 159, 160, 161, 162, 164, 165, 166, 168, 169, 170, 173, 174, 195, 196, 225, 226, 227, 229, 241], "wang": [10, 14, 16, 23, 26, 27, 31, 33, 51, 96, 127, 137, 143], "chen": [10, 26, 27, 31, 49, 50, 52, 60, 96, 137, 143, 206, 207, 215, 241], "overview": [10, 13, 16, 18, 19, 21, 27, 33, 39, 45, 52, 53, 55, 60, 61, 76, 79, 102, 118, 130, 133, 137, 138, 140, 141, 142, 144, 151, 164, 201, 212, 214, 218, 223, 224, 226, 227, 228, 229], "depict": [10, 136, 145, 229], "across": [10, 12, 13, 16, 19, 22, 25, 29, 33, 34, 35, 36, 41, 50, 54, 56, 75, 80, 84, 86, 105, 106, 107, 111, 113, 147, 165, 168, 169, 189, 200, 204, 214, 223, 227, 228], "type": [10, 14, 16, 18, 19, 22, 39, 49, 61, 69, 79, 101, 102, 105, 111, 123, 130, 133, 159, 189, 211, 214, 218], "instruct": [10, 11, 13, 14, 17, 18, 21, 25, 33, 34, 41, 47, 53, 62, 68, 79, 85, 86, 87, 96, 127, 146, 155, 160, 164, 167, 170, 172, 173, 174, 181, 189, 190, 206, 219, 240], "display": [10, 16, 53, 229], "adapt": [10, 11, 31, 32, 39, 50, 59, 87, 96, 125, 127, 132, 133, 138, 160, 167, 170, 184, 196, 213, 218, 219, 224], "play": [10, 22, 86, 87, 96, 130, 138, 212, 225, 228], "1000": [10, 16, 46, 48, 51, 52, 53, 56, 69, 72, 80, 98, 104, 119, 130, 134, 143, 144, 145, 151, 155, 165, 226, 233], "token": [10, 14, 17, 41, 43, 48, 49, 50, 56, 60, 61, 62, 63, 64, 65, 67, 68, 69, 79, 81, 85, 86, 88, 96, 102, 112, 117, 118, 119, 122, 124, 127, 130, 133, 137, 138, 139, 140, 142, 145, 149, 151, 155, 159, 160, 161, 162, 165, 167, 168, 169, 170, 172, 174, 175, 176, 177, 184, 189, 195, 201, 211, 214, 217, 219, 225, 227, 228, 229, 238, 239, 241], "p0": 10, "p999": 10, "click": [10, 11, 12, 17, 18, 79], "40": [10, 19, 47, 49, 50, 53, 57, 59, 76, 112, 113, 119, 130, 135, 139, 140, 143, 149, 152, 158, 166, 167, 174, 182, 192, 195, 201, 214, 226, 228, 229, 240], "joni": 10, "if": [10, 16, 29, 50, 53, 61, 71, 79, 81, 88, 97, 101, 104, 119, 127, 130, 143, 205, 206, 212, 214, 218, 226, 228, 233], "want": [10, 16, 24, 79, 130, 190], "album": 10, "common": [10, 34, 69, 70, 96, 136, 137, 142, 158, 160, 170, 211, 214, 218, 225], "crawl": [10, 54, 70, 160], "titl": [10, 16, 18, 61, 130, 206, 214], "webpag": 10, "caption": [10, 11, 17, 44, 58, 63, 137, 149, 155, 159, 162, 164, 165, 166, 172, 173, 174], "2020": [10, 27, 48, 49, 77, 96, 100, 102, 115, 127, 130, 137, 138, 143, 202], "llava": [10, 57, 58, 59, 60, 61, 159, 162, 164, 165, 166, 168, 171, 172, 174, 198, 218, 241], "qwen": [10, 14, 15, 16, 17, 45, 52, 53, 56, 57, 58, 60, 62, 65, 68, 79, 142, 145, 147, 152, 155, 160, 161, 164, 166, 169, 170, 171, 172, 182, 187, 188, 189, 237, 240], "vl": [10, 14, 16, 17, 18, 57, 58, 60, 86, 159, 161, 164, 165, 166, 168, 170, 171, 172, 181, 187, 189, 241], "448": [10, 71, 120, 164, 168], "lora": [10, 39, 50, 58, 91, 96, 123, 145, 162, 168, 181, 239, 242], "epoch": [10, 61, 67, 85, 104, 107, 130, 165, 166, 175, 188, 195, 201, 219, 226], "webarena": [10, 79], "minigpt": [10, 57, 58, 59, 60, 161, 164], "cogag": [10, 12, 19, 79], "accuraci": [10, 11, 14, 16, 22, 53, 57, 71, 74, 75, 79, 104, 106, 111, 112, 120, 122, 127, 145, 151, 158, 159, 165, 167, 168, 175, 190, 195, 196, 200, 201, 202, 211, 212, 213, 218, 224, 225, 226, 227, 228, 230, 239], "2800": [10, 203], "webgum": 10, "webn": 10, "t5": [10, 11, 48, 59, 60, 70, 90, 98, 116, 117, 123, 159, 173, 181, 233], "pix2act": 10, "20": [10, 15, 18, 19, 29, 35, 45, 46, 47, 48, 49, 50, 53, 54, 56, 57, 58, 63, 67, 68, 69, 70, 74, 76, 79, 85, 97, 102, 108, 113, 117, 119, 124, 136, 137, 139, 141, 143, 144, 145, 149, 151, 152, 161, 162, 174, 182, 189, 201, 211, 214, 218, 225, 227, 228, 229, 231, 239, 240], "30k": [10, 60, 166, 174], "71": [10, 45, 49, 61, 68, 76, 130, 165, 214, 229], "clickacc": 10, "137": [10, 11], "2000": [10, 46, 52, 57, 73, 130, 143, 151, 152, 182, 241], "drag": [10, 18], "doubl": [10, 16, 18, 79, 191], "issu": [10, 44, 46, 54, 79, 111, 113, 127, 199, 206, 207, 214, 218, 224, 225], "bias": [10, 48, 117, 119, 127, 137, 145, 175, 181, 188, 189, 213, 214, 226, 229], "mitig": [10, 29, 48, 130, 207], "chat": [10, 21, 25, 26, 28, 32, 45, 53, 57, 58, 60, 62, 63, 64, 65, 70, 76, 86, 96, 130, 142, 143, 144, 160, 164, 166, 170, 181, 182, 184, 188, 189, 204, 219, 237], "text_2_point": 10, "text_2_bbox": 10, "down": [10, 18, 26, 31, 71, 79, 96, 130, 143, 147, 165, 211, 214], "point_2_text": 10, "bbox_2_text": 10, "77": [10, 11, 14, 48, 58, 130, 136, 155, 160, 239], "continu": [10, 17, 39, 53, 87, 89, 97, 120, 132, 133, 136, 138, 140, 151, 184, 211, 218, 223, 226, 241, 242], "adamw": [10, 136, 137, 140, 143, 155, 165, 167, 168, 173, 174, 181, 182, 195, 201, 218, 225, 229, 236, 239, 240, 241], "3e": [10, 135, 175, 195], "cosin": [10, 130, 141, 161, 165, 168, 184, 195, 219, 225, 226, 229, 240], "anneal": [10, 17, 219], "batch": [10, 67, 85, 97, 105, 113, 117, 118, 122, 143, 161, 165, 168, 175, 189, 194, 195, 201, 218, 219, 225, 229], "64": [10, 43, 47, 58, 65, 68, 71, 79, 98, 102, 112, 113, 119, 130, 136, 137, 141, 144, 164, 165, 174, 182, 187, 195, 201, 214, 223, 225, 226, 228, 229, 240], "nvidia": [10, 16, 19, 50, 63, 64, 96, 98, 102, 104, 106, 113, 115, 117, 118, 120, 121, 122, 123, 124, 137, 162, 164, 168, 182, 227, 229, 231, 239], "a100": [10, 19, 50, 60, 64, 75, 85, 102, 112, 113, 115, 116, 117, 118, 121, 122, 159, 161, 166, 171, 172, 173, 174, 196, 218, 229], "gpu": [10, 13, 16, 48, 50, 60, 61, 64, 76, 85, 87, 91, 96, 97, 98, 101, 102, 105, 106, 107, 113, 115, 116, 117, 119, 121, 122, 123, 124, 133, 135, 139, 140, 141, 143, 145, 155, 164, 165, 166, 167, 168, 169, 171, 172, 173, 174, 182, 189, 195, 196, 201, 218, 223, 227, 229, 231, 236, 239, 240], "makesens": 10, "bimant": 10, "icon": [10, 11, 14, 16, 79], "do": [10, 11, 16, 44, 53, 61, 75, 79, 112, 113, 130, 137, 206, 214, 218, 224, 226, 228, 229, 230], "need": [10, 11, 16, 36, 46, 47, 50, 78, 79, 87, 88, 96, 97, 101, 127, 132, 175, 205, 218, 224, 230, 232], "yang": [10, 20, 23, 31, 170, 214], "point": [10, 50, 61, 74, 75, 96, 107, 112, 115, 119, 120, 127, 130, 155, 175, 211, 214, 222, 223, 227, 228, 230, 231, 233, 237], "bbox": [10, 155], "dash": [10, 107, 141, 143, 144, 147], "red": [10, 11, 13, 50, 67, 79, 88, 89, 112, 130, 131, 133, 158, 201, 218, 226], "pointer": [10, 104], "correct": [10, 14, 16, 33, 55, 68, 71, 79, 127, 131, 133, 137, 162, 164, 201, 203, 206, 209, 216, 218, 221, 229, 230], "incorrect": [10, 16, 53, 127, 131, 133], "valu": [10, 18, 22, 53, 64, 74, 81, 96, 97, 101, 102, 113, 119, 120, 127, 130, 133, 214, 217, 218, 223, 226, 227, 233, 236, 240], "direct": [10, 16, 17, 33, 39, 50, 79, 96, 101, 107, 125, 130, 138, 142, 143, 145, 170, 191, 204, 206, 211, 214, 223, 226, 231, 233], "press": [10, 79, 133, 214], "home": [10, 14, 39, 130, 218], "enter": [10, 16, 79], "11": [10, 11, 16, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 60, 62, 63, 64, 75, 76, 77, 82, 85, 104, 120, 125, 130, 135, 137, 143, 145, 147, 152, 161, 165, 171, 172, 174, 175, 182, 189, 195, 226, 227, 229, 233, 238, 240], "action_typ": 10, "instal": [10, 101, 205], "googleapp": 10, "webshop": [10, 20], "fail": [10, 16, 19, 43, 50, 54, 79, 101, 120, 162, 213, 223, 229], "dump": 10, "1920": [10, 79], "12000": [10, 174], "1920x1080": 10, "ele": 10, "acc": [10, 11, 56, 59, 68, 155, 158, 227, 239], "op": 10, "04615": 11, "pali": [11, 149], "pathway": [11, 35, 149], "pix2struct": 11, "patch": [11, 50, 55, 96, 155, 165, 169, 170, 174, 229], "ablat": [11, 14, 22, 24, 90, 116, 125, 127, 159, 164, 224, 226], "paramet": [11, 34, 43, 45, 53, 58, 87, 88, 91, 96, 97, 104, 105, 107, 111, 119, 130, 145, 160, 166, 168, 175, 178, 181, 184, 187, 189, 199, 200, 203, 218, 226, 227, 228, 229, 242], "sota": [11, 17, 43, 46, 52, 60, 98, 106, 134, 135, 136, 145, 151, 155, 159, 161, 166, 169, 170, 173, 174, 195, 224, 225, 226, 228, 229, 238, 240], "state": [11, 16, 17, 18, 19, 22, 29, 32, 33, 34, 39, 47, 61, 79, 86, 87, 97, 101, 104, 106, 107, 111, 119, 127, 130, 133, 141, 144, 154, 162, 167, 169, 173, 175, 176, 182, 190, 191, 192, 194, 199, 200, 205, 206, 211, 214, 225, 226, 228, 229, 242], "art": [11, 16, 17, 22, 32, 33, 34, 79, 86, 87, 106, 111, 130, 154, 158, 162, 169, 173, 175, 176, 182, 190, 191, 192, 194, 199, 200, 205, 206, 211, 218, 225, 226, 228, 229], "multipag": 11, "best": [11, 16, 41, 56, 61, 70, 72, 79, 107, 127, 130, 132, 133, 145, 147, 152, 162, 164, 175, 178, 189, 201, 202, 205, 206, 225, 226], "chartqa": [11, 149, 155, 160, 165, 170], "infographicvqa": [11, 149, 155], "overal": [11, 34, 35, 56, 58, 61, 127, 139, 145, 146, 164, 170, 175, 181, 203, 211, 212, 213, 214, 216, 217, 218, 225, 231], "follow": [11, 13, 16, 18, 25, 27, 31, 34, 46, 47, 53, 57, 61, 72, 75, 79, 85, 87, 101, 124, 137, 158, 164, 165, 176, 195, 206, 208, 211, 214, 218, 227, 228], "consum": [11, 96, 205], "autoregress": [11, 61, 86, 139, 141, 144, 151, 160, 167], "final": [11, 16, 43, 45, 90, 104, 119, 132, 165, 167, 191, 192, 205, 211, 214, 225, 229], "illustr": [11, 13, 16, 17, 18, 29, 30, 32, 33, 60, 102, 106, 117, 119, 125, 127, 139, 143, 144, 147, 159, 170, 195, 201, 219, 226, 227, 229, 231], "grid": [11, 61, 161, 225], "aspect": [11, 127, 133, 164, 165, 201, 214, 229], "ratio": [11, 61, 130, 164, 165, 184, 201, 225, 229], "shape": [11, 130, 195, 214, 218], "6b": [11, 45, 48, 56, 58, 62, 64, 67, 68, 70, 76, 77, 117, 119, 130, 152, 155, 160, 188, 189, 240], "46": [11, 18, 48, 51, 55, 61, 71, 76, 137, 166, 200, 214, 229, 240], "detect": [11, 14, 133, 137, 147, 161, 170, 190, 192, 193, 199, 222, 225, 226], "generalist": [11, 79, 87, 160], "flamingo": [11, 57, 58, 59, 159, 162, 164, 173, 174], "ofa": [11, 217], "unitab": 11, "pix2seq": [11, 164], "layoutlmv3": 11, "donut": 11, "udop": 11, "matcha": [11, 21], "spotlight": [11, 214], "vut": 11, "uibert": 11, "docllm": 11, "mt5": [11, 76], "multilingu": [11, 44, 50, 54, 86, 145, 149, 152, 160, 187], "pad": [11, 102, 123, 143, 165, 201], "variant": [11, 184, 224], "detail": [11, 12, 16, 22, 25, 34, 71, 120, 127, 137, 141, 147, 159, 162, 164, 167, 184, 206, 211, 214, 218, 223], "among": [11, 16, 25, 29, 31, 32, 39, 56, 75, 101, 122, 127, 189, 196, 214, 226], "670m": 11, "2b": [11, 51, 152, 160, 164, 174, 184, 240], "unimod": 11, "ul2": 11, "detr": [11, 196, 200], "pipelin": [11, 32, 50, 67, 71, 87, 106, 111, 120, 137, 138, 151, 160, 182, 189, 191, 203, 211, 214, 218, 225, 226, 242], "relat": [11, 13, 24, 134, 170, 206, 211], "option": [11, 16, 34, 79, 83, 155, 214], "rater": 11, "pictogram": 11, "button": [11, 12, 79], "sunkara": 11, "engin": [11, 26, 41, 55, 75, 78, 79, 97, 133, 169, 175, 189, 190, 203, 206, 208, 211, 214, 220], "mask": [11, 86, 89, 112, 124, 141, 143, 144, 155, 166, 170, 173, 175, 177, 187, 196, 201, 218, 240], "last": [11, 44, 60, 113, 127, 133, 137, 193, 195, 206, 218, 224, 233], "coupl": [11, 212], "breakdown": [11, 12, 16, 19, 24], "chart": [11, 54, 61, 165], "webli": 11, "analysi": [11, 22, 75, 115, 124, 133, 147, 184, 187, 203, 205, 226], "doc": [11, 39, 50, 101, 149, 201], "assum": [11, 79, 104, 107, 108, 194], "reader": [11, 75, 214, 236], "familiar": [11, 33], "but": [11, 16, 22, 34, 47, 53, 70, 75, 79, 88, 89, 107, 108, 112, 120, 122, 124, 127, 170, 184, 191, 192, 193, 203, 204, 206, 211, 214, 218, 225, 230, 231], "extract": [11, 50, 127, 130, 161, 165, 187, 199, 206, 209, 211, 218, 221], "fix": [11, 35, 50, 105, 137, 167, 201, 218, 223, 228, 230], "uis": 11, "supervis": [11, 17, 41, 86, 89, 130, 131, 132, 143, 152, 155, 158, 164, 169, 181, 224, 241], "posit": [11, 16, 18, 29, 57, 64, 67, 79, 102, 134, 160, 161, 169, 170, 177, 207, 214, 233, 240], "public": [11, 62, 75, 127, 145, 168, 178, 205, 208, 214, 226], "along": [11, 25, 75, 106, 108, 113, 143, 169, 200, 204, 206, 207, 223, 226], "unifi": [11, 25, 39, 79, 86, 87, 97, 123, 170, 189, 190, 221, 225, 235], "compat": [11, 122], "represent": [11, 32, 34, 48, 86, 96, 122, 133, 143, 149, 151, 170, 175, 191, 218, 219, 222, 224, 225], "well": [11, 24, 35, 61, 71, 75, 113, 120, 125, 127, 196, 197, 213, 214, 225, 227], "justifi": 11, "choic": [11, 16, 59, 75, 130, 155, 165, 211, 218], "techniqu": [11, 31, 33, 39, 106, 111, 164, 181, 211, 223, 232], "competit": [11, 41, 44, 90, 96, 116, 200], "number": [11, 16, 40, 50, 56, 60, 61, 62, 64, 69, 71, 72, 75, 79, 90, 91, 104, 105, 107, 108, 111, 112, 113, 127, 130, 137, 158, 159, 168, 175, 194, 200, 206, 214, 218, 224, 226, 228, 230], "note": [11, 16, 41, 57, 88, 97, 102, 125, 130, 140, 142, 159, 164, 181, 205, 214, 218, 225, 227, 233], "further": [11, 16, 29, 33, 45, 106, 130, 137, 146, 169, 184, 189, 200, 204, 206, 207, 211, 218, 224, 225, 229], "bridg": [11, 25, 69, 238], "gap": [11, 89, 90, 133, 143], "order": [11, 16, 18, 29, 61, 75, 121, 124, 127, 160, 201, 214, 228], "magnitud": [11, 96, 122, 124], "releas": [11, 53, 101, 137, 152, 178, 181, 214], "object": [11, 14, 24, 33, 67, 75, 116, 137, 151, 164, 169, 170, 174, 176, 190, 192, 199, 214, 218, 223, 240], "plain": [11, 96, 101, 130], "cider": [11, 59, 162, 173, 174], "stanford": [11, 54, 69, 83, 85, 102, 104, 107, 108, 112, 234], "relax": [11, 225], "anl": 11, "averag": [11, 34, 50, 60, 74, 78, 122, 145, 204, 214, 218, 225, 226, 238], "normal": [11, 101, 105, 106, 117, 119, 141, 158, 168, 169, 177, 194, 195, 201, 224, 225, 228], "levenshtein": 11, "similar": [11, 22, 75, 90, 96, 106, 144, 147, 151, 158, 160, 162, 170, 176, 181, 193, 200, 211, 214, 218, 226, 227, 229, 231], "quantiz": [11, 87, 96, 119, 141, 144, 151, 168, 226, 240, 241], "between": [11, 16, 18, 29, 56, 72, 85, 89, 97, 111, 112, 127, 130, 133, 137, 138, 139, 145, 147, 160, 177, 200, 201, 206, 207, 211, 213, 214, 218, 223, 224, 225, 226, 228, 229, 230], "999": 11, "31": [11, 49, 50, 51, 53, 55, 72, 76, 98, 136, 152, 164, 214, 229, 238, 240], "113": [11, 69], "speak": [11, 32, 86, 141, 214], "json": [11, 16, 45, 47, 50, 58, 72, 161, 169, 171, 172, 182, 188, 214, 217, 218], "isn": 11, "given": [11, 22, 29, 33, 45, 47, 61, 89, 119, 127, 130, 143, 151, 162, 184, 203, 204, 206, 214, 218, 225, 226, 227, 228, 229, 230], "regard": [11, 47, 184], "them": [11, 24, 28, 29, 33, 41, 45, 79, 97, 112, 127, 130, 161, 187, 194, 206, 211, 212, 218, 226, 227], "necessari": [11, 22, 45, 53, 75, 127, 211], "capit": [11, 89, 130, 214, 218, 219], "letter": [11, 130, 218], "sometim": 11, "num_sampl": 11, "alway": [11, 206, 216], "start": [11, 18, 24, 50, 79, 130, 137, 141, 160, 165, 224, 226, 233], "same": [11, 50, 56, 61, 71, 101, 102, 105, 107, 120, 127, 130, 131, 139, 162, 175, 200, 214, 218, 225, 226, 227], "indirect": [11, 214, 240], "imper": [11, 87], "tens": 11, "instead": [11, 14, 22, 113, 191, 211, 214, 230], "highlight": [11, 16, 50, 54, 67, 75, 79, 104, 107, 164, 206, 211, 224, 226], "01": [11, 26, 39, 65, 102, 118, 143, 174, 229, 240], "25th": 11, "januari": 11, "percentag": [11, 74, 158, 205], "humid": 11, "65": [11, 35, 49, 71, 77, 85, 117, 119, 134, 143, 149, 162, 165, 188, 194, 226], "status": [11, 47], "hr": 11, "clock": [11, 18, 112], "degre": [11, 212, 214, 229], "fahrenheit": 11, "interv": [11, 18, 79], "durat": [11, 136], "00": [11, 24, 77, 139, 214, 233, 237], "34": [11, 20, 47, 50, 52, 53, 56, 63, 69, 71, 74, 85, 96, 118, 155, 158, 214, 219, 226, 229], "second": [11, 16, 39, 79, 97, 107, 121, 130, 147, 162, 189, 191, 226, 227, 228, 229, 242], "minut": [11, 81], "hour": [11, 16, 81], "14": [11, 21, 45, 47, 53, 55, 57, 58, 61, 63, 70, 74, 80, 84, 85, 102, 117, 120, 132, 137, 145, 147, 158, 159, 160, 161, 164, 165, 169, 170, 173, 174, 189, 201, 226, 229, 238, 240, 241], "sa": [11, 32, 147, 158, 229], "googleresearch": 11, "screen_annot": 11, "07939": 12, "microsoft": [12, 19, 28, 42, 82, 91, 98, 104, 107, 108, 117, 137, 138, 139, 140, 159, 161, 202, 214, 218, 220], "94": [12, 45, 55, 70, 72, 79, 149, 152, 201, 217, 229, 230], "2025": [12, 19, 39, 41, 43, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 69, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 102, 117, 127, 130, 134, 135, 137, 138, 141, 143, 144, 151, 152, 155, 166, 170, 182, 201, 210, 211, 214, 217, 224, 226, 227, 236, 240, 242], "06": [12, 19, 71, 74, 78, 79, 80, 102, 117, 118, 137, 138, 141, 143, 144, 229], "agi": [12, 39, 78, 80, 133, 142, 170, 181, 188, 189, 221, 242], "lam": [12, 19], "autogpt": [12, 17, 78, 211, 238], "taskweav": 12, "python": [12, 19, 46, 48, 50, 51, 52, 54, 56, 63, 67, 79, 84, 97, 101, 102, 112, 149, 181, 234, 240], "langchain": [12, 13, 17, 78, 159, 181, 214], "autogen": [12, 13, 28, 32, 242], "metagpt": [12, 13, 26, 32, 35], "autoag": 12, "mobileag": [12, 14, 16, 18], "pywinauto": [12, 18, 79], "edit": [12, 18, 39, 79, 138, 158, 241], "menuitem": 12, "settext": 12, "gettext": 12, "hard": [12, 32, 47, 52, 69, 127, 144, 155, 158, 170, 187, 189, 219, 225, 226, 239], "soft": [12, 34, 61, 90, 218, 219], "windowsbench": 12, "outlook": [12, 19], "edg": [12, 34, 96, 97, 167, 214, 217, 223, 226, 228], "rate": [12, 14, 16, 18, 35, 45, 53, 54, 97, 102, 127, 130, 145, 147, 151, 164, 165, 175, 184, 205, 214, 226, 238], "adob": 12, "acrobat": 12, "ppt": [12, 18, 19, 228], "powerpoint": 12, "win32": 12, "16971": 13, "agiresearch": 13, "motiv": [13, 120, 204], "travel": [13, 16, 18, 130, 206], "non": [13, 39, 70, 71, 96, 101, 102, 113, 133, 139, 143, 144, 164, 167, 174, 184, 189, 200, 205, 207, 211, 213, 218, 223, 228, 229], "servic": [13, 47, 137, 218], "react": [13, 17, 19, 20, 22, 45, 46, 53, 68, 181], "reflexion": [13, 22, 43], "mind2web": [13, 17, 79, 155], "oom": [13, 98, 101, 182], "primit": [13, 97], "respons": [13, 25, 39, 42, 45, 47, 58, 63, 96, 101, 127, 130, 132, 146, 159, 164, 170, 172, 187, 190, 201, 203, 204, 213, 214, 216, 218, 238], "isol": 13, "differ": [13, 16, 17, 22, 28, 29, 32, 33, 41, 42, 50, 52, 56, 80, 96, 101, 102, 104, 105, 108, 111, 113, 122, 123, 130, 132, 133, 137, 143, 146, 147, 160, 162, 164, 165, 167, 169, 176, 192, 206, 211, 212, 213, 214, 218, 223, 224, 225, 226, 227, 228, 231], "resourc": [13, 39, 113, 120, 137, 184, 232], "serv": [13, 16, 19, 28, 39, 40, 42, 61, 79, 87, 90, 97, 101, 137, 204, 208, 211, 214], "hardwar": [13, 75, 96, 124, 218, 224], "physic": [13, 74, 75, 86, 218, 223], "cpu": [13, 79, 97, 98, 101, 102, 104, 113, 115, 117, 122, 123, 124, 164, 242], "queri": [13, 16, 32, 45, 58, 102, 113, 127, 130, 145, 151, 169, 173, 184, 187, 197, 204, 209, 212, 213, 217, 218, 221, 227, 228, 229, 235, 237], "decompos": [13, 16, 18, 45, 87, 119, 212], "dispatch": 13, "omit": [13, 16, 20, 189], "wrapper": 13, "claud": [13, 15, 16, 17, 18, 19, 43, 46, 47, 50, 52, 54, 56, 65, 68, 72, 77, 79, 85, 155, 164, 165, 169, 187, 189, 238], "ollama": 13, "vllm": [13, 52, 64, 65, 155, 242], "llm_gener": 13, "fifo": [13, 101, 167], "rr": [13, 58, 107], "interrupt": 13, "logit": [13, 61, 67, 105, 106, 133, 143, 166, 189, 214], "beam": [13, 132, 133, 137, 152, 173, 174, 211, 219], "ua057": 13, "weather": [13, 40], "pari": [13, 119, 214, 219], "ram": [13, 16, 101, 211, 214, 240], "trie": 13, "lru": [13, 39, 97, 101], "send": [13, 101, 167, 218], "simplic": [13, 104, 107, 133], "sent": [13, 71, 167], "hashmap": [13, 101], "privileg": 13, "rq2": 13, "rq3": 13, "mini": [13, 47, 56, 65, 72, 80, 105, 145, 155, 164, 165, 170, 171, 172, 188, 189, 194, 217], "llama": [13, 15, 43, 46, 47, 52, 53, 56, 58, 59, 62, 63, 65, 68, 76, 79, 85, 96, 115, 118, 122, 123, 124, 125, 133, 143, 155, 161, 162, 164, 167, 171, 172, 174, 181, 187, 188, 189, 211, 219, 236, 238, 239, 240], "mistral": [13, 46, 52, 53, 56, 63, 64, 65, 68, 122, 125, 143, 187, 188, 219], "7b": [13, 43, 45, 46, 50, 51, 52, 53, 56, 58, 61, 62, 63, 64, 65, 68, 70, 76, 77, 85, 118, 119, 123, 124, 125, 142, 143, 145, 152, 159, 160, 162, 164, 165, 166, 167, 168, 169, 170, 181, 184, 187, 188, 189, 211, 219, 236, 239, 240, 241], "float16": [13, 96, 119], "round": [13, 16, 36, 43, 45, 87, 117, 122, 127, 214, 218], "robin": 13, "humanev": [13, 22, 50, 52, 53, 54, 55, 56, 76, 146, 149, 170, 181, 187, 188], "mint": [13, 17, 53], "gaia": [13, 38], "swe": 13, "bench": [13, 44, 53, 56, 60, 61, 62, 75, 77, 127, 142, 145, 147, 159, 161, 166, 170, 172, 181, 187, 188, 225, 237, 240, 241], "lite": [13, 127, 165], "bug": [13, 48, 50, 54], "effici": [13, 14, 16, 22, 26, 29, 31, 34, 79, 86, 87, 88, 97, 98, 106, 111, 113, 120, 121, 124, 133, 169, 184, 189, 195, 199, 200, 213, 214, 218, 219, 224, 226, 228], "optim": [13, 17, 31, 34, 35, 87, 89, 104, 107, 112, 113, 120, 121, 127, 130, 133, 142, 164, 169, 181, 184, 187, 188, 190, 191, 200, 202, 212, 218, 219, 227, 228, 229, 231], "01014": 14, "plug": [14, 16, 18, 212, 225, 226, 228], "format": [14, 47, 50, 53, 61, 64, 72, 75, 76, 87, 115, 118, 124, 127, 132, 137, 158, 169, 214, 216, 218], "becom": [14, 90, 91, 130, 211, 224], "popular": [14, 16, 96, 204], "scenario": [14, 16, 18, 29, 31, 36, 47, 101, 184, 201, 211, 232], "mllms": [14, 57, 59], "constrain": [14, 27, 105, 161], "through": [14, 18, 21, 22, 24, 25, 26, 31, 32, 33, 34, 36, 46, 61, 79, 90, 96, 98, 101, 112, 113, 125, 130, 133, 167, 189, 199, 211, 227, 232], "tool": [14, 16, 18, 24, 27, 28, 29, 31, 33, 43, 44, 47, 53, 75, 78, 86, 87, 96, 127, 164, 204, 206, 218, 221], "invoc": [14, 97], "gradual": [14, 138, 211], "being": [14, 127, 130, 214], "howev": [14, 16, 22, 25, 26, 29, 31, 32, 33, 34, 61, 79, 88, 89, 96, 101, 106, 111, 113, 178, 200, 203, 204, 206, 213, 216, 218, 233], "major": [14, 32, 85, 96, 113, 194, 206], "progress": [14, 16, 18, 26, 29, 33, 36, 75, 111, 200, 211, 228], "signific": [14, 22, 29, 31, 34, 35, 75, 79, 111, 113, 124, 137, 169, 176, 192, 212, 214, 226], "complic": [14, 26, 42, 158], "under": [14, 16, 47, 74, 79, 89, 101, 105, 124, 127, 143, 159, 160, 162, 171, 200, 218, 225, 227], "exist": [14, 19, 26, 27, 32, 34, 42, 57, 79, 96, 97, 111, 112, 127, 160, 165, 191, 199, 204, 206, 211, 218, 224], "interleav": [14, 111, 169, 170], "limit": [14, 32, 34, 35, 36, 40, 79, 97, 105, 111, 162, 170, 200, 211, 212, 232], "address": [14, 16, 32, 34, 36, 75, 79, 97, 112, 113, 127, 178, 211, 213, 214, 218, 224], "propos": [14, 16, 18, 22, 29, 32, 33, 46, 52, 63, 74, 88, 89, 90, 91, 96, 111, 112, 113, 118, 120, 124, 127, 133, 140, 141, 167, 192, 195, 197, 199, 206, 207, 211, 212, 213, 218, 219, 225, 226, 227, 228], "compris": [14, 39, 176, 226], "plan": [14, 16, 18, 27, 31, 38, 42, 47, 199, 211, 214], "reflect": [14, 16, 22, 33, 61, 75, 79, 133, 211, 223], "retain": [14, 132, 201], "unit": [14, 18, 39, 86, 104, 107, 113, 115, 124, 130, 134, 167, 171, 172, 211, 214, 224, 226, 228], "updat": [14, 16, 22, 24, 29, 33, 44, 79, 88, 96, 97, 104, 133, 166, 193, 199, 211, 218, 228], "addit": [14, 40, 52, 53, 91, 96, 113, 118, 161, 165, 181, 184, 189, 199, 206, 211, 218, 233], "erron": [14, 16], "observ": [14, 16, 17, 18, 22, 24, 33, 47, 63, 113, 116, 122, 124, 175, 223], "outcom": [14, 16, 29, 127, 131, 132, 200, 213, 225], "handl": [14, 42, 47, 97, 104, 123, 143, 146, 169, 189, 213, 225], "ani": [14, 16, 33, 53, 61, 90, 101, 112, 127, 130, 161, 196, 197, 203, 206, 211, 214, 218, 223, 226, 227], "mistak": [14, 33, 71, 130, 131], "accord": [14, 18, 42, 132, 167, 201, 214, 218], "improv": [14, 16, 22, 25, 29, 31, 33, 34, 35, 36, 41, 44, 75, 86, 89, 97, 111, 113, 122, 123, 124, 130, 133, 137, 159, 175, 181, 189, 192, 194, 200, 203, 204, 206, 209, 212, 218, 221, 224, 237], "compar": [14, 16, 31, 33, 35, 75, 88, 90, 91, 96, 104, 106, 111, 112, 113, 120, 124, 127, 132, 151, 160, 161, 162, 168, 181, 191, 193, 200, 201, 206, 211, 213, 224, 226, 227, 230, 231], "zhang": [14, 16, 18, 26, 31, 96, 102, 204, 215], "2023a": [14, 27, 96, 102], "xml": [14, 16, 79, 84, 182], "x1": [14, 18, 50, 64, 140, 233], "y1": [14, 18, 50], "x2": [14, 18, 64, 233], "y2": [14, 18, 135], "stop": [14, 16, 18, 46, 47, 48, 82, 101, 159, 211, 225], "percept": [14, 16, 21, 58, 214, 242], "convnextvit": [14, 16], "groundingdino": [14, 16, 197], "snapshot_download": 14, "modelscop": [14, 170, 197], "revis": [14, 16, 71, 132], "v1": [14, 16, 58, 60, 62, 75, 77, 85, 86, 101, 125, 161, 170, 175, 226, 238], "int4": [14, 75, 117, 121, 122, 123, 124, 125], "basic": [14, 41, 46, 75, 127, 130, 164], "sr": [14, 18, 19], "cr": [14, 62], "da": [14, 18, 130, 155], "63": [14, 49, 55, 106, 112, 134, 229, 237, 240], "58": [14, 19, 54, 63, 69, 70, 85, 118, 174, 205, 214, 229, 237], "29": [14, 23, 49, 50, 69, 76, 137, 155, 159, 189, 240], "43": [14, 18, 51, 54, 70, 79, 119, 124, 136, 137, 155, 169, 194, 214], "42": [14, 38, 50, 69, 70, 75, 79, 119, 122, 123, 137, 139, 152, 166, 174, 182, 229, 237, 238, 240], "45": [14, 16, 49, 55, 61, 65, 69, 123, 130, 136, 137, 152, 164, 165, 182, 191, 225, 226, 229, 240], "72": [14, 55, 79, 113, 130, 131, 165, 174, 214, 229], "69": [14, 16, 46, 54, 77, 149, 152, 166, 202, 214, 227, 229], "89": [14, 69, 70, 74, 106, 119, 149, 174, 184, 187, 229, 238], "54": [14, 56, 76, 97, 117, 119, 139, 173, 227, 229, 230], "88": [14, 52, 58, 76, 79, 117, 119, 174, 229, 238], "93": [14, 54, 65, 68, 69, 158, 169, 172, 175, 176, 226], "61": [14, 55, 112, 119, 136, 155, 166, 229], "82": [14, 38, 55, 63, 69, 105, 117, 119, 155, 165, 172, 182, 214, 229, 241], "fulfil": [14, 31, 127], "proport": [14, 97, 158, 165, 204, 214], "noteworthi": [14, 214], "metric": [14, 27, 84, 101, 193, 205, 206, 211, 226, 228], "ra": [14, 16, 18, 211], "02059": 15, "tablegpt": 15, "gpts": 15, "tablegpt2": 15, "593": 15, "236": 15, "70": [15, 19, 48, 51, 57, 63, 76, 80, 82, 85, 101, 122, 143, 151, 155, 158, 171, 172, 181, 189, 214, 225, 229, 240], "720": [15, 226], "11733": 16, "git": [16, 18, 50], "illinoi": 16, "urbana": 16, "champaign": 16, "alibaba": [16, 18, 141, 144, 145, 147], "lmm": [16, 38, 60, 159, 161, 171, 172], "subgoal": 16, "perceptor": 16, "reflector": 16, "notetak": 16, "2024b": [16, 96, 127, 133, 170], "disentangl": [16, 151, 170], "dedic": [16, 24], "equip": [16, 75, 78, 228], "newli": [16, 52], "reusabl": 16, "past": [16, 24, 43, 74, 79, 200], "satisfact": 16, "sss": 16, "mathcal": [16, 18, 69, 127, 166, 201, 217, 218, 219, 225, 226, 227, 228, 229, 230, 231, 239], "involv": [16, 26, 40, 75, 96, 101, 119, 175, 211, 214, 218, 227], "loop": [16, 28, 101, 112, 208, 227, 233], "contribut": [16, 24, 25, 50, 130, 203, 224], "term": [16, 22, 24, 39, 44, 97, 127, 130, 133, 145, 147, 160, 195, 218, 226, 228], "track": [16, 36, 101, 218], "feedback": [16, 22, 29, 31, 34, 35, 71, 87, 127, 131, 133, 164, 187, 190], "aggreg": [16, 97, 101, 127, 199, 227, 228], "infer": [16, 22, 34, 39, 43, 49, 75, 87, 91, 132, 133, 136, 141, 144, 167, 168, 169, 175, 200, 201, 211, 212, 218, 238], "chang": [16, 24, 46, 50, 61, 63, 70, 89, 106, 113, 176, 193, 199, 207, 214, 218, 223, 224, 225, 226], "s_t": [16, 133], "w_p": 16, "w_s": [16, 143], "w_g": 16, "w_n": [16, 81], "ls": [16, 218], "wef": 16, "w_v": 16, "concret": [16, 22, 70], "a_": [16, 17, 106, 143, 219], "es": [16, 97, 152], "w_a": 16, "w_e": 16, "t_f": [16, 223], "rubric": 16, "intens": [16, 122, 124, 209, 211, 221], "horizon": [16, 127], "aa": [16, 229], "termin": [16, 160], "te": 16, "60": [16, 45, 46, 49, 52, 56, 57, 58, 68, 69, 71, 75, 76, 77, 79, 97, 105, 119, 135, 138, 140, 149, 155, 161, 164, 182, 214, 217, 230, 239, 240], "96": [16, 50, 52, 70, 81, 124, 143, 164, 195, 201], "68": [16, 69, 78, 119, 135, 137, 147, 159, 172, 195], "73": [16, 55, 63, 71, 113, 119, 152, 229], "52": [16, 45, 52, 61, 75, 76, 111, 117, 152, 155, 166, 181, 182, 197, 214, 229], "evo": 16, "backbon": [16, 58, 143, 146, 165, 195], "sonnet": [16, 47, 54, 65, 155, 165, 169, 188], "dbnet": 16, "plus": [16, 58, 64, 68, 188], "case": [16, 52, 75, 81, 82, 84, 105, 113, 120, 130, 132, 137, 143, 218, 223, 225, 226, 228], "subsequ": [16, 22, 88, 97, 169, 211, 226, 231], "time": [16, 17, 18, 22, 24, 31, 43, 61, 78, 79, 86, 87, 88, 91, 97, 102, 104, 106, 107, 108, 111, 112, 113, 116, 119, 130, 133, 136, 138, 164, 168, 170, 175, 190, 192, 193, 195, 201, 202, 203, 205, 206, 214, 218, 222, 224, 225, 226, 229, 240], "overhead": [16, 97, 102, 104, 105, 107, 200, 213, 218], "tap_type_and_ent": 16, "uniqu": [16, 25, 62, 207, 228], "ert": 16, "ers": 16, "opus": [16, 46, 50, 52, 68, 187], "sight": 16, "poor": [16, 75, 97, 216], "lmms": [16, 60, 171, 172], "refin": [16, 17, 29, 33, 34, 35, 36, 45, 79, 127, 133, 201, 211, 225, 226, 228, 229], "persona": [16, 214], "invok": [16, 18, 34, 97, 101], "2024a": [16, 133, 170], "walmart": 16, "sale": 16, "ribey": 16, "steak": 16, "intend": [16, 61], "fresh": [16, 35], "rais": [16, 212, 226], "unchang": [16, 175, 218], "rectifi": [16, 241], "after": [16, 35, 45, 50, 56, 71, 97, 122, 125, 130, 137, 165, 167, 189, 206, 225, 226, 228, 230, 233], "consecut": 16, "identifi": [16, 24, 31, 36, 62, 131, 207, 214, 242], "misus": 16, "invalid": 16, "switch": [16, 136, 169, 189, 224], "request": [16, 42, 46, 47, 50, 54, 55, 97, 101, 102, 213, 218], "switch_app": 16, "realiz": [16, 42, 176, 240], "avail": [16, 34, 42, 75, 101, 104, 107, 137, 178, 205, 208, 213, 216], "phone": [16, 47, 86, 135], "imperfect": 16, "abov": [16, 27, 50, 79, 130, 143, 214, 224, 233], "search_location_in_map": 16, "unnecessari": [16, 113, 127, 213, 214], "switch_app_and_search": 16, "desir": [16, 29, 130], "befor": [16, 25, 33, 45, 79, 101, 122, 127, 144, 160, 165, 211], "id": [16, 46, 47, 50, 52, 63, 101, 104, 107, 108, 130, 137, 140, 152, 160, 166, 170, 214, 242], "restaur": [16, 218], "recommend": [16, 43, 211], "1_late_night_korean_food": 16, "map": [16, 69, 122, 149, 169, 191, 192, 193, 201, 214, 218, 220, 225, 227, 228, 229, 236, 238], "night": [16, 226], "korean": 16, "il": 16, "beyond": [16, 52, 74, 86, 97, 112, 228, 229], "9pm": 16, "1_nearest_bakeri": 16, "get": [16, 79, 97, 101, 104, 107, 113, 130, 133, 192, 216, 218, 226], "nearest": [16, 125, 225, 226], "bakeri": 16, "higher": [16, 24, 75, 91, 112, 113, 127, 143, 151, 161, 184, 196, 218, 227, 233], "rout": [16, 32, 211], "1_thai_duck": 16, "thai": 16, "duck": 16, "cuisin": 16, "custom": [16, 58, 79, 96, 130, 195, 211], "compil": [16, 22, 106, 112, 137, 164], "1_bakery_birthday_cak": 16, "within": [16, 22, 29, 32, 33, 39, 56, 62, 75, 107, 113, 127, 132, 206, 214, 227, 231], "10min": 16, "drive": 16, "doe": [16, 47, 69, 106, 108, 112, 127, 130, 139, 166, 214, 218, 227, 238], "birthday": 16, "cake": 16, "1_chinese_ohar": 16, "chines": [16, 44, 58, 61, 62, 86, 152, 160, 164, 171, 195, 221, 235], "chicago": [16, 50], "hare": 16, "airport": 16, "check": [16, 18, 47, 76, 130, 203, 211, 228], "recent": [16, 22, 24, 34, 90, 106, 175, 178, 203, 205, 208, 228], "post": [16, 39, 79, 86, 87, 124, 125, 127, 132, 151, 200, 211, 217], "about": [16, 47, 130, 212, 214, 218, 225, 233], "signatur": 16, "dish": 16, "2_segment_anything_cit": 16, "chrome": [16, 18, 54, 79], "cite": [16, 127, 130, 145, 203, 204, 206, 214], "segment": [16, 137, 167, 224], "anyth": [16, 79, 214], "2_llm_agents_survey": 16, "least": [16, 97, 175, 206, 228], "survey": [16, 111, 209, 221], "add": [16, 18, 61, 97, 101, 160, 214, 218, 224], "2_recipes_chines": 16, "youtub": [16, 79, 104, 137, 225, 226, 238], "onion": 16, "beef": 16, "potato": [16, 67, 155], "refriger": 16, "style": [16, 61, 87, 113, 134, 141, 147, 208, 214, 218], "recip": [16, 96, 137, 175], "ingredi": 16, "prepar": 16, "tutori": 16, "2_mcdonalds_d": 16, "mcdonald": 16, "deal": [16, 164, 213], "spici": 16, "mccrispi": 16, "so": [16, 24, 56, 61, 79, 101, 107, 124, 130, 165, 199, 202, 214, 223, 228, 233], "pay": 16, "myself": 16, "pickup": 16, "2_headphones_review": 16, "amazon": [16, 69, 74, 84, 146, 211], "bose": 16, "qc45": 16, "headphon": 16, "sentiment": [16, 130, 211], "onlin": [16, 28, 113, 127, 155, 187, 226], "shop": 16, "3_oled_tv": 16, "buy": [16, 130], "55": [16, 18, 34, 46, 54, 55, 76, 77, 102, 119, 149, 152, 165, 182, 196, 229, 241], "inch": 16, "4k": [16, 62, 63, 64, 65, 79, 112, 165, 188], "ole": 16, "tv": 16, "3_laptop_nvidia_gpu": 16, "laptop": 16, "8gb": [16, 19, 98, 116, 124], "3_ninja_air_fry": 16, "price": 16, "ninja": 16, "air": [16, 101, 142, 145, 147], "fryer": 16, "qt": 16, "3_walmart_sale_item": 16, "toilet": 16, "3_nintendo_switch_joy_con": 16, "brand": [16, 218], "nintendo": 16, "joy": 16, "con": 16, "pleas": [16, 50, 53, 57, 61, 72, 79, 127, 130, 218, 225], "cheapest": 16, "cart": 16, "4_x_black_myth_wukong": 16, "game": [16, 20, 22, 24, 25, 115, 182, 218], "black": [16, 165, 208], "myth": [16, 70, 218], "wukong": 16, "4_x_trending_new": 16, "news": [16, 116, 130, 214, 238], "read": [16, 78, 86, 101, 102, 112, 113, 130, 201, 206, 211, 233, 240], "4_watercolor_painting_tutori": 16, "lemon8": 16, "paint": [16, 24, 229], "watercolor": 16, "creator": 16, "account": [16, 75, 112, 113, 190], "4_movie_trend": 16, "fandango": 16, "movi": [16, 130, 182], "theater": 16, "highest": [16, 133, 168, 189, 196, 202, 214], "showtim": 16, "4_horror_movie_review": 16, "latest": [16, 65, 155, 214, 229], "horror": 16, "5_cheap_flights_newyork": 16, "book": [16, 71, 116, 130, 143, 203], "trip": 16, "flight": [16, 46, 175], "york": [16, 55, 71], "citi": [16, 79, 130], "month": [16, 74, 206], "5_things_to_do_la": 16, "tripadvisor": 16, "suggest": [16, 25, 27, 71, 133, 214, 218], "thing": [16, 79, 130], "la": 16, "attract": [16, 214], "save": [16, 18, 53, 101, 113, 119, 224], "5_palo_alto_tour": 16, "day": [16, 24, 75, 130, 206, 226], "itinerari": 16, "palo": 16, "alto": 16, "ca": 16, "choos": [16, 61, 162, 175], "dine": 16, "keep": [16, 24, 88, 124, 175, 206, 218, 230], "mind": 16, "don": [16, 79, 130, 137, 192, 193, 214], "seafood": 16, "love": [16, 130], "museum": [16, 229], "5_local_food_chicago": 16, "must": [16, 50, 61, 202], "tri": [16, 55, 79, 130, 206], "5_hotel_champaign": 16, "hotel": [16, 218], "queen": 16, "bed": 16, "sure": [16, 130, 218], "street": 16, "12326": 17, "byted": [17, 151, 152, 154, 155], "decomposit": [17, 18, 91, 102, 112, 119, 133, 238], "mileston": 17, "odyssey": 17, "osworld": [17, 18, 19, 155], "screenspot": [17, 155, 169], "screenqa": 17, "mm2web": 17, "visualwebbench": 17, "androidcontrol": 17, "autonom": [17, 24, 25, 29, 35, 42, 79, 86, 158, 211], "handcraft": [17, 226], "dens": [17, 18, 44, 112, 165, 174, 188, 189, 218, 222, 229, 238, 241], "mark": [17, 57, 79, 122, 133, 160, 161, 162, 164], "6600": 17, "trial": [17, 22, 133], "error": [17, 22, 26, 31, 45, 79, 124, 127, 133, 137, 145, 147, 151, 161, 191, 205, 222, 225, 226, 228, 242], "graphic": 17, "rpa": 17, "awm": 17, "mobileexpert": 17, "anthrop": [17, 19, 46, 52, 65, 70, 75, 123, 168, 181], "aguvi": 17, "showui": 17, "atlas": [17, 214], "octopus": 17, "vlms": [17, 58, 79, 146, 155, 165, 168, 174], "distil": [17, 22, 65, 118, 143, 151, 165, 168, 222], "cv": [17, 116, 135], "iconnet": 17, "dino": [17, 190, 196, 229], "seeact": 17, "uground": 17, "oscar": 17, "a11i": [17, 18, 54, 79], "cli": [17, 79, 101], "atom": [17, 190], "chain": [17, 18, 20, 22, 25, 26, 33, 52, 56, 58, 68, 78, 85, 127, 132, 133, 143, 155, 162, 169, 189, 211, 218, 219, 237, 242], "cot": [17, 19, 20, 33, 43, 45, 52, 56, 57, 68, 75, 85, 127, 133, 159, 162, 169, 181, 211, 219, 237, 241], "copilot": [17, 48], "cradl": [17, 18], "song": [17, 23], "icl": [17, 57, 144, 151, 162, 170, 211], "offlin": [17, 122, 127, 226, 227], "browsergym": 17, "o_i": [17, 112], "o_1": 17, "a_1": [17, 106], "o_2": 17, "a_2": [17, 106], "o_": [17, 79], "t_i": [17, 219, 223, 229], "yao": [17, 20, 27, 45, 50], "32k": [17, 50, 54, 62, 64, 65, 105, 113, 139, 140, 149, 170, 188, 189, 214, 236, 241], "t_": [17, 223], "som": [17, 18, 79], "transit": [17, 19, 32, 47, 133], "hotkey": [17, 79], "rightclick": 17, "longpress": 17, "pressback": 17, "finish": [17, 19, 43, 75, 79, 101, 214, 233], "callus": 17, "mm": [17, 60, 63, 120, 159, 166, 170, 226, 241], "guiact": 17, "1480": 17, "110": [17, 120, 144, 167, 211, 225], "submit": [17, 80, 97, 101, 130], "seeclick": 17, "multiui": 17, "omnicorpus": [17, 241], "fasttext": [17, 143, 158], "510": 17, "pattern": [17, 24, 28, 89, 127, 143, 158, 195], "actr": 17, "t_n": [17, 223, 239], "t_1": 17, "t_2": 17, "o_n": 17, "a_n": 17, "m_n": 17, "_raw": 17, "_filter": 17, "finetun": [17, 87, 170, 189, 226, 229], "m_": [17, 112, 218], "sft": [17, 75, 76, 96, 132, 133, 145, 149, 169, 184, 188, 189, 237, 241], "prefer": [17, 61, 96, 127, 130, 133, 142, 164, 181, 187, 202, 203], "s_": [17, 69, 79, 82, 112, 127, 226], "p_": [17, 81, 82, 127, 166, 170, 218, 219, 239], "500": [17, 43, 45, 46, 49, 52, 55, 56, 60, 64, 67, 80, 81, 97, 102, 135, 147, 155, 158, 189, 205, 217, 218, 237], "phase": [17, 25, 39, 43, 102, 107, 118, 133, 158, 164, 197, 231], "suboptim": [17, 35, 113, 133, 200], "72b": [17, 45, 53, 56, 62, 64, 65, 68, 155, 165, 169, 187, 188, 189, 242], "14282": 18, "intra": [18, 104, 106, 114, 195], "apm": 18, "winrar": 18, "subtask": [18, 25, 26, 42, 57, 64], "manag": [18, 19, 24, 32, 39, 42, 79, 87, 97, 218], "ufo": [18, 19], "line": [18, 26, 27, 50, 61, 64, 79, 97, 127, 133, 141, 143, 144, 165, 204, 224], "denot": [18, 60, 88, 119, 127, 141, 147, 158, 165, 187, 195, 201, 211, 224, 226, 227, 231], "purpl": [18, 106, 165], "ma": [18, 56], "pa": [18, 98], "_i": [18, 112, 201, 219, 223, 225, 227, 228, 229], "rho": [18, 224, 228], "adopt": [18, 40, 102, 118, 166], "obtain": [18, 22, 78, 88, 122, 127, 133, 175, 199, 202, 205, 213, 225, 226, 227], "intent": [18, 46, 130], "util": [18, 25, 26, 29, 44, 60, 96, 105, 108, 113, 132, 133, 199, 201, 211, 212], "precis": [18, 31, 53, 63, 79, 84, 96, 98, 119, 122, 123, 124, 165, 169, 190, 204, 206, 211, 218, 226, 238], "excel": [18, 19, 41, 78, 79, 184], "hub": [18, 43, 96, 240], "thought": [18, 20, 22, 33, 43, 45, 52, 56, 58, 61, 68, 78, 85, 127, 133, 155, 162, 169, 189, 218, 219, 237], "inner": [18, 158], "monologu": 18, "pyautogui": [18, 79], "windowsagentarena": 18, "79": [18, 49, 50, 58, 68, 69, 130, 165, 172, 229, 239], "notepad": 18, "ssr": 18, "file": [18, 23, 50, 53, 78, 79, 137, 211], "calcul": [18, 40, 41, 50, 57, 144, 199, 204], "travel_plan": 18, "destin": 18, "februari": [18, 24], "popul": [18, 24], "china": [18, 39, 43, 45, 60, 76, 218, 240, 242], "india": 18, "respect": [18, 57, 125, 130, 158, 167, 168, 184, 189, 195, 201, 203, 214, 224, 226], "spreadsheet": 18, "countri": 18, "column": [18, 60, 61, 65, 79, 106, 113, 119, 143, 165, 214, 226], "descend": [18, 214], "test_doc1": 18, "bold": [18, 57, 61, 127, 162, 164, 189, 214], "paragraph": [18, 69, 214, 234], "5x": 18, "qwen2": [18, 62, 64, 65, 142, 144, 145, 165, 167, 168, 170, 171, 172, 189, 241, 242], "56": [18, 47, 49, 63, 69, 85, 117, 119, 122, 139, 152, 182, 196, 202, 225, 229, 236, 238], "41": [18, 47, 55, 63, 69, 77, 118, 130, 166, 214, 226, 229], "agash": 18, "44": [18, 49, 50, 60, 65, 69, 76, 119, 139, 147, 158, 192, 201, 229, 240, 241], "build": [18, 27, 28, 33, 35, 79, 190, 206, 208, 218, 226, 242], "sheet": 18, "defin": [18, 28, 32, 33, 40, 130, 136, 224, 229], "mous": [18, 79], "twice": [18, 107, 108, 116], "acquir": [18, 101, 218], "page": [18, 79, 151, 228], "shortcut": 18, "ctrl": [18, 70, 79], "met": [18, 184], "14603": 19, "keyword": [19, 62, 130, 143, 223, 234], "uipath": 19, "power": [19, 24, 25, 33, 42, 87, 120, 133, 139, 169, 175, 211, 225], "shell": 19, "plane": [19, 97, 130, 224, 229, 231], "fsm": 19, "assign": [19, 24, 26, 104, 107, 135, 200], "pend": [19, 101], "sdk": [19, 101], "uia": 19, "omnipars": 19, "puppet": [19, 54], "harmon": 19, "static": [19, 75, 112, 122, 212, 225, 229], "rag": [19, 32, 39, 54, 55, 63, 189, 212, 215, 218, 221, 235, 239, 242], "rdp": 19, "pipe": 19, "amd": [19, 96], "ryzen": 19, "waa": 19, "154": [19, 118], "navi": 19, "omniag": 19, "acs": 19, "o1": [19, 56, 72, 87, 122, 155, 188], "libreoffic": [19, 79], "linux": [19, 239], "spi": [19, 79], "aio": [19, 221], "ge": [19, 218], "mei": 19, "rama": 19, "autoo": 19, "03629": 20, "synerg": 20, "shunyu": 20, "jeffrey": 20, "zhao": [20, 21, 96, 130, 133, 215], "dian": 20, "yu": [20, 23, 102, 206], "nan": [20, 23, 120], "du": [20, 33], "izhak": 20, "shafran": 20, "karthik": [20, 176], "narasimhan": [20, 176], "yuan": [20, 52], "cao": 20, "hotpotqa": [20, 22, 62, 64, 69, 211, 214, 238], "fever": [20, 211, 238], "alfworld": 20, "standard": [20, 26, 39, 52, 61, 75, 84, 96, 119, 125, 130, 165, 192, 218, 225, 226, 230, 233], "2018": [20, 62, 84, 96, 106, 130, 133, 137, 143], "shridharet": 20, "trajectori": [20, 22, 46, 47, 228], "obs": 20, "03": [21, 23, 48, 85, 130, 139, 161, 211, 225, 229, 237], "08268": 21, "xufeng": 21, "mengdi": 21, "cornelius": 21, "weber": 21, "muhammad": [21, 206], "burhan": 21, "hafez": 21, "stefan": 21, "wermter": 21, "perceiv": [21, 160, 164, 174], "passiv": 21, "insuffici": 21, "11366": 22, "extern": [22, 39, 40, 41, 53, 101, 102, 149, 211, 213, 216, 218, 241], "goal": [22, 33, 61, 214, 218, 225], "driven": [22, 25, 200], "quick": [22, 230], "tradit": [22, 35, 133, 137, 146, 211, 216], "extens": [22, 32, 33, 35, 79, 96, 178, 184, 200, 205, 212], "expens": [22, 91, 96, 111, 184, 218, 224], "signal": [22, 90, 127, 133, 138], "maintain": [22, 24, 33, 75, 108, 112, 120, 162, 218, 232], "own": [22, 32, 47, 86, 101, 115, 146, 232], "buffer": [22, 101, 104, 133, 229], "induc": 22, "flexibl": [22, 28, 32, 40, 96, 97, 127, 211], "enough": [22, 101, 127, 199], "incorpor": [22, 26, 41, 61, 90, 96, 169, 207, 211, 213, 214, 224], "scalar": [22, 67, 127], "free": [22, 44, 57, 79, 86, 102, 125, 127, 141, 144, 155, 200, 227, 241], "form": [22, 24, 28, 39, 44, 70, 167, 190, 202, 206, 211, 212, 214, 218, 224], "intern": [22, 45, 61, 102, 107, 136, 214], "sequenti": [22, 29, 32, 105, 119, 132, 158, 164, 211, 225, 229], "91": [22, 49, 58, 61, 159, 195, 229, 240, 242], "pass": [22, 36, 38, 41, 48, 50, 51, 52, 54, 97, 101, 106, 107, 108, 133, 181, 225, 236], "surpass": [22, 196, 226], "previous": [22, 26, 33, 61, 79, 132, 133, 138, 139, 171, 175, 176, 181, 197, 201, 211, 214, 216], "insight": [22, 24, 79, 96, 214, 218], "affect": [22, 127, 218], "toolform": [22, 33, 41, 78, 211, 240], "hugginggpt": [22, 42], "ener": 22, "webgpt": [22, 70, 78, 202, 211, 240], "actor": [22, 133, 155], "built": [22, 61, 62, 96, 130, 138, 165, 208], "upon": [22, 25, 61, 79, 127, 176, 226], "compon": [22, 24, 32, 33, 58, 96, 127, 143, 161, 164, 165, 169, 195, 200, 207, 211, 217, 218, 219], "crucial": [22, 36, 207, 214, 219], "role": [22, 25, 26, 86, 96, 138, 160, 214], "assess": [22, 29, 62, 75, 79, 132, 176, 212], "qualiti": [22, 33, 35, 45, 53, 60, 71, 76, 86, 91, 112, 144, 169, 202, 203, 205, 206, 211, 212, 214, 218, 227, 229], "instanti": [22, 24, 79], "valuabl": [22, 79, 218, 224], "core": [22, 24, 39, 41, 61, 66, 71, 72, 74, 101, 113, 115, 117, 118, 122, 155, 211, 225], "notion": [22, 24], "rememb": [22, 24], "grain": [22, 57, 97, 102, 127, 141, 144, 160, 169, 190, 195], "recal": [22, 62, 63, 84, 165, 204, 206, 211, 238, 239], "d1": [22, 82, 195, 211], "d2": [22, 82, 195, 211], "d3": [22, 195], "gt": [22, 130, 225, 226, 227, 229], "16434": 23, "taskmatrix": 23, "connect": [23, 34, 42, 50, 79, 106, 107, 165, 167, 194, 226], "million": [23, 69, 86, 97, 170], "yaobo": 23, "liang": [23, 31, 90, 130, 204, 215], "chenfei": 23, "ting": 23, "wenshan": 23, "yan": 23, "xia": 23, "ou": 23, "shuai": 23, "lei": [23, 215], "ji": 23, "shaoguang": 23, "mao": 23, "yun": 23, "linjun": 23, "shou": 23, "ming": 23, "gong": [23, 174], "duan": 23, "mcfm": 23, "open_local_fil": 23, "file_path": 23, "string": [23, 45, 71, 160, 201, 214, 218], "mode": [23, 28, 79, 226], "oserror": 23, "txt": [23, 78, 159, 233], "close_local_fil": 23, "03442": 24, "believ": [24, 204, 218, 226], "proxi": [24, 101, 133], "empow": [24, 29, 42], "rang": [24, 28, 41, 42, 56, 75, 79, 89, 96, 111, 112, 130, 160, 161, 170, 175, 176, 189, 196, 213, 214, 218], "immers": 24, "rehears": 24, "interperson": 24, "prototyp": 24, "wake": 24, "cook": 24, "breakfast": [24, 59, 155], "head": [24, 67, 96, 105, 112, 113, 133, 134, 162, 195, 201, 218, 219, 225, 227, 236], "artist": [24, 201, 218], "author": [24, 145], "opinion": [24, 151, 214, 238], "notic": [24, 127, 200], "initi": [24, 33, 34, 45, 71, 79, 85, 96, 101, 211, 226, 228], "extend": [24, 36, 71, 96, 112, 132, 169, 226], "store": [24, 88, 102, 113, 175, 211, 218, 242], "record": [24, 31, 104, 112, 137, 160, 197, 214], "synthes": [24, 86, 139, 145, 206, 214, 218, 223, 229, 230, 231], "inspir": [24, 29, 32, 33, 37, 88], "town": 24, "twenti": 24, "five": [24, 33, 75, 76, 130, 145], "individu": [24, 29, 50, 214, 224], "social": [24, 25, 29, 75, 76, 130, 159, 218], "specifi": [24, 33, 50, 79, 122, 137, 197], "valentin": 24, "parti": [24, 32], "spread": [24, 101], "invit": 24, "acquaint": 24, "ask": [24, 79, 130, 202, 208, 211, 216], "date": [24, 69, 206, 211], "joonspk": 24, "generative_ag": 24, "simulacra": 24, "circumst": 24, "supplement": 24, "longer": [24, 112, 113, 143, 224], "recurs": 24, "causal": [24, 144, 166, 187, 218, 236, 240], "aris": 24, "improp": 24, "stream": [24, 86, 113, 146, 147, 167, 170], "isabella": 24, "rodriguez": 24, "maria": [24, 65], "lopez": 24, "recenc": 24, "event": [24, 61, 69, 101, 147, 169, 170, 211, 214], "moment": [24, 169, 231], "ago": 24, "morn": [24, 81, 158], "sphere": [24, 130], "distinguish": [24, 133, 226], "mundan": 24, "situat": 24, "99": [24, 62, 68, 73, 81, 85, 119, 123, 143, 144, 145, 230], "150": [24, 79, 155], "klaus": 24, "mueller": 24, "leaf": 24, "node": [24, 34, 54, 97, 111, 123, 133, 214, 220, 226], "deriv": [24, 25, 43, 62, 79, 130, 138, 139, 184, 214, 226], "he": [24, 81, 130, 175, 206, 214, 230], "his": [24, 130, 206], "dialogu": [24, 25, 26, 85, 86, 160, 170], "eddi": 24, "lin": [24, 26, 27, 31, 60, 82, 96, 143], "age": [24, 238], "19": [24, 46, 47, 49, 52, 53, 54, 55, 58, 59, 63, 68, 69, 70, 73, 85, 102, 115, 117, 119, 135, 136, 137, 147, 160, 174, 192, 214, 229, 236], "innat": 24, "trait": [24, 204], "tuesday": [24, 214], "woke": 24, "routin": 24, "am": [24, 101, 130, 146, 218], "got": [24, 219], "readi": [24, 101], "sleep": [24, 79, 130, 218], "around": [24, 44, 53, 79, 113, 211, 214], "pm": 24, "today": [24, 130, 199], "wednesday": [24, 214], "broad": [24, 29, 74, 75, 160, 161], "stroke": [24, 195], "07924": 25, "modelbest": [25, 184], "inc": [25, 43, 51, 63, 64, 182, 184, 240], "chatdev": [25, 32], "necessit": [25, 88], "cooper": [25, 29], "member": 25, "numer": [25, 42, 53, 57, 79, 127, 137, 214], "waterfal": 25, "test": [25, 27, 33, 46, 47, 55, 58, 75, 87, 133, 134, 135, 137, 140, 143, 144, 145, 147, 152, 158, 164, 170, 175, 176, 178, 187, 194, 223, 226, 229, 230], "lead": [25, 75, 89, 96, 105, 107, 111, 214, 216, 226], "technic": [25, 40, 75, 86, 178, 214, 218], "inconsist": [25, 26, 31], "fragment": [25, 102, 211], "ineffect": 25, "special": [25, 79, 96, 97, 113, 137, 160, 165, 211, 218, 226], "guid": [25, 30, 39, 85, 133, 197, 207, 222], "dehallucin": 25, "activ": [25, 39, 87, 88, 96, 102, 104, 105, 106, 107, 117, 118, 122, 131, 137, 169, 187, 194, 214, 242], "advantag": [25, 133, 175, 218, 230, 232], "prove": [25, 89], "debug": 25, "receiv": [25, 42, 89, 101, 170], "preliminari": [25, 89], "gomoku": 25, "engag": [25, 29, 53, 206], "seri": [25, 101, 160, 164, 181, 189, 195, 200, 205], "craft": [25, 29, 60, 61, 176], "seek": [25, 190, 204, 206], "instructor": 25, "deliv": [25, 168], "formal": [25, 61, 130, 145, 218], "00352": 26, "08": [26, 39, 41, 51, 55, 137, 151, 152, 225], "sirui": [26, 31], "mingchen": [26, 31], "zhuge": [26, 31], "jonathan": 26, "xiawu": [26, 31], "yuheng": [26, 31], "cheng": [26, 31], "ceyao": 26, "jinlin": [26, 31], "zili": 26, "steven": [26, 130], "ka": 26, "shing": 26, "yau": 26, "zijuan": 26, "liyang": 26, "zhou": [26, 31], "chenyu": 26, "ran": [26, 101], "lingfeng": 26, "xiao": [26, 133], "chenglin": [26, 31], "rgen": 26, "schmidhub": 26, "remark": [26, 31, 34, 41, 90, 197], "made": [26, 33, 71, 133, 193, 222], "societi": 26, "logic": [26, 31, 34, 58, 75, 127, 133], "cascad": [26, 138, 196], "hallucin": [26, 53, 57, 63, 72, 80, 130, 131, 133, 152, 164, 165, 170, 203, 206, 211, 212, 218, 238], "caus": [26, 113, 201, 206, 214], "naiv": [26, 105, 111, 127, 216, 226], "sop": 26, "streamlin": 26, "thus": [26, 113, 124, 132, 159, 181], "allow": [26, 28, 33, 35, 47, 79, 88, 96, 101, 105, 111, 137, 143, 146, 161, 175, 177, 192, 202, 206, 211, 216, 218, 224, 225, 226], "expertis": [26, 31, 71], "intermedi": [26, 33, 70, 79, 105, 107, 141, 144, 187, 214, 224], "assembl": [26, 214], "break": [26, 31, 50, 71, 96, 143, 155, 165, 187, 205, 211], "mani": [26, 28, 50, 130, 137, 175, 178, 196, 214, 218, 225, 226], "04026": 27, "agentsim": 27, "prevail": 27, "suffer": 27, "shortcom": [27, 204], "vulner": 27, "unobject": 27, "easi": [27, 47, 52, 69, 146, 168, 222], "infrastructur": [27, 28, 39, 75, 218], "disciplin": [27, 44, 74], "adding": [27, 79, 137, 162, 224], "deploy": [27, 29, 91, 120, 200, 207], "mechan": [27, 39, 69, 74, 79, 90, 104, 107, 112, 169, 170, 175, 207, 218, 227], "nijkamp": [27, 51], "weng": 27, "shen": [27, 67], "qian": [27, 130], "park": [27, 63], "reform": [27, 236], "nlu": [27, 75, 76, 89, 143, 146], "nlg": [27, 63, 74, 122, 143, 146], "hendryck": [27, 50, 52, 66, 74], "huang": [27, 52, 207], "zhong": 27, "sun": [27, 61], "gunasekar": 27, "gpt4": [27, 60, 76, 78], "2023b": [27, 33, 96], "tom": 27, "premack": 27, "woodruff": 27, "1978": 27, "08155": 28, "accomplish": [28, 29, 45, 79], "customiz": 28, "generic": [28, 42, 61], "empir": [28, 34, 86, 89, 91, 96, 133, 175], "mathemat": [28, 44, 75, 170, 189], "entertain": [28, 218], "etc": [28, 204, 214], "even": [28, 33, 35, 69, 75, 111, 113, 130, 168, 178, 206, 213, 224, 225, 226, 228, 233], "potenti": [28, 29, 33, 34, 35, 78, 79, 86, 127, 200, 207, 214, 218], "10848": 29, "wechat": 29, "undergon": 29, "spectrum": [29, 206], "often": [29, 32, 35, 36, 41, 89, 112, 113, 203, 205, 211, 229], "henc": [29, 113], "adjust": [29, 31, 79, 218, 225, 226, 227, 228], "greater": [29, 32, 122, 130, 211], "sum": [29, 170, 218, 219, 233], "furthermor": [29, 32, 34, 211], "delv": [29, 199, 211], "strategi": [29, 35, 36, 86, 87, 96, 105, 132, 139, 158, 200, 201, 203, 206, 211, 213, 225, 226, 232], "openbmb": [29, 32, 43, 164, 184], "agentvers": [29, 32], "pivot": [29, 31], "expert": [29, 33, 40, 45, 61, 71, 86, 87, 127, 133, 155, 162, 184, 187, 240, 241], "recruit": 29, "ongo": 29, "joint": [29, 61, 67, 137, 152, 175, 192], "devis": 29, "unsatisfactori": 29, "bookshelf": 29, "minecraft": 29, "random": [29, 45, 74, 112, 133, 175, 218, 223, 225, 226, 236], "concurr": 29, "selector": 29, "visibl": [29, 60], "conversationag": 29, "toolag": 29, "06117": 30, "concept": [30, 32, 61, 197, 199, 211, 218], "18679": 31, "yizhang": 31, "bang": 31, "bangbang": 31, "binhao": 31, "danyang": 31, "jiaqi": 31, "jiayi": 31, "lingyao": 31, "min": [31, 81, 112, 119, 125, 158, 225, 228, 229], "taicheng": 31, "guo": [31, 52, 155], "tuo": 31, "wei": [31, 33, 130, 241], "tao": 31, "wenyi": 31, "xiangru": 31, "tang": [31, 214], "xiangtao": 31, "xinb": 31, "yay": 31, "fei": 31, "zongz": 31, "xu": [31, 77, 130, 137, 241], "compromis": [31, 168], "depend": [31, 34, 62, 97, 105, 165, 195, 214, 218, 223, 224], "emphas": [31, 75], "graph": [31, 39, 101, 107, 117, 209, 211, 214, 221, 226, 235, 240], "profici": [31, 36, 44, 58], "enrich": [31, 211], "requisit": 31, "identif": [31, 147, 240], "superior": [31, 33, 75, 160, 168, 199], "feed": [31, 105, 106, 162, 223, 227, 229], "07061": 32, "rapid": 32, "pave": [32, 42], "struggl": [32, 36, 41, 79], "third": [32, 79, 107, 162, 203, 226, 229], "relianc": [32, 48, 200], "ecosystem": [32, 130, 211], "setup": [32, 34, 79, 206], "protocol": [32, 101, 226], "instant": [32, 75, 77], "messag": [32, 47, 130, 159, 233], "embodi": 32, "showcas": [32, 79, 211, 225], "link": [32, 53, 107, 211, 214], "seamless": [32, 86, 212, 213, 224, 225], "conceptu": [32, 40, 58, 155, 175, 197], "block": [32, 33, 79, 87, 88, 96, 106, 113, 117, 122, 125, 143, 159, 170, 177, 201, 225, 227, 229], "registri": 32, "session": [32, 53, 63, 120], "managemnt": 32, "contact": 32, "info": [32, 47, 70], "n1": [32, 97], "n2": [32, 97], "simplifi": [32, 33, 61, 120, 146], "clariti": [32, 44, 61, 127, 165, 226], "austin": [32, 52], "1975": 32, "searl": 32, "1969": 32, "finin": 32, "1994": 32, "labrou": 32, "finit": [32, 144], "speaker": [32, 61, 63, 86, 138, 141, 146, 170], "alloc": [32, 101, 132], "walkthrough": 32, "08435": 33, "ada": [33, 43, 218, 238], "substanti": [33, 36, 41, 75, 89, 175], "effort": [33, 34, 96, 169, 200, 208, 224], "wherein": 33, "formul": [33, 225, 230], "aim": [33, 56, 75, 130, 164, 189, 200, 206, 207, 230], "invent": [33, 218], "unexplor": 33, "ever": [33, 79, 130], "ture": [33, 48], "theoret": [33, 98, 111, 113, 194], "flow": [33, 34, 61, 107, 136, 145, 147, 151, 158, 170, 226, 228, 241], "thereof": 33, "grow": [33, 106], "archiv": 33, "great": [33, 91, 122, 200, 216, 218, 224, 226], "surpris": 33, "safe": [33, 37, 80, 101, 187], "shengranhu": 33, "twitter": [33, 61, 83], "candid": [33, 50, 82, 127, 132, 133, 208, 228], "brief": [33, 127], "everi": [33, 81, 104, 130, 201, 204, 223], "deepli": 33, "literatur": 33, "maxim": [33, 130, 226, 231], "academ": [33, 61, 75, 161, 165], "arc": [33, 52, 84, 130, 143, 181, 182, 211], "bootstrap": [33, 86], "against": [33, 35, 50, 168, 202, 228], "sc": [33, 136], "ensembl": [33, 35, 159], "parallel": [33, 79, 87, 96, 97, 111, 114, 118, 127, 132, 155, 182, 207, 214, 228, 229], "madaan": [33, 130], "shinn": 33, "debat": 33, "perspect": [33, 35, 87, 200, 214, 222, 224, 225], "go": [33, 51, 130, 133, 226, 227, 228], "2024c": 33, "10762": 34, "deepwisdom": [34, 35, 36], "af": 34, "typic": [34, 75, 97, 101, 165], "construct": [34, 61, 160, 165, 208, 218], "generaliz": 34, "sought": 34, "fall": [34, 127, 130, 213], "reformul": 34, "aflow": 34, "mont": [34, 35, 132, 133], "carlo": [34, 35, 132, 133], "modif": [34, 39, 144, 175, 211, 227, 228], "six": [34, 45, 158], "efficaci": [34, 91], "yield": [34, 112, 113, 151, 226], "smaller": [34, 41, 105, 120, 143, 187, 191, 200, 213, 232], "dollar": [34, 137], "mcts": [34, 35, 132, 133], "mix": [34, 62, 70, 84, 96, 98, 119, 124, 201, 211, 217], "probabl": [34, 127, 191], "expans": [34, 133, 211], "backpropag": [34, 90, 133], "17238": 35, "california": [35, 63, 69, 82, 130], "berkeley": [35, 52, 74, 85, 97, 102, 132, 168, 223, 230], "san": [35, 85, 102, 146, 168, 223], "diego": [35, 85, 102, 146, 168, 223], "automl": 35, "sela": 35, "encompass": [35, 96, 211], "newer": 35, "overcom": [35, 96], "configur": [35, 79, 102, 104, 111, 164, 169], "win": [35, 45], "underscor": [35, 36, 184], "offer": [35, 75, 127, 146, 211, 213, 214, 218], "tackl": [35, 42, 96], "auto": [35, 133, 159, 162, 220], "weka": 35, "sklearn": 35, "autogluon": 35, "h2o": 35, "pool": [35, 101, 104, 227, 239], "methodnam": 35, "_code": 35, "21012": 36, "universit": [36, 69], "de": [36, 69, 84, 88, 170, 195], "montr": 36, "mila": [36, 69], "lost": [36, 64, 199], "phenomenon": 36, "overlook": 36, "shed": [36, 91], "light": [36, 61, 91, 130, 135], "simultan": [36, 86, 105, 127, 192, 200, 226, 228], "especi": [36, 41, 75, 90, 204, 228], "lose": 36, "incomplet": [36, 127, 214], "inaccur": [36, 204, 218], "captur": [36, 52, 61, 223, 227, 231], "increment": [36, 63, 112, 217], "though": [36, 130, 193, 213], "notabl": [36, 43, 75, 169, 200, 211], "resili": 36, "evolutionari": 37, "01990": 37, "foundationag": 37, "awesom": [37, 57], "12508": 38, "skywork": 38, "nanyang": 38, "technolog": [38, 39, 45, 46, 58, 60, 75, 118, 130, 182, 189, 211, 218, 224, 242], "sub": [38, 61, 96, 97, 101, 119, 170, 211, 212, 225, 226], "simpleqa": [38, 72], "hle": [38, 80], "22101": 39, "pdf": [39, 43, 45, 46, 47, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 67, 68, 69, 70, 75, 76, 77, 78, 79, 81, 82, 83, 84, 85, 107, 123, 134, 135, 148, 151, 152, 155, 156, 158, 160, 166, 173, 174, 176, 182, 189, 206, 214, 217, 226, 234, 236, 237, 238, 239, 240, 241, 242], "1memtensor": [39, 242], "co": [39, 45, 52, 54, 56, 60, 61, 62, 74, 75, 78, 122, 127, 163, 167, 170, 183, 185, 242], "ltd": [39, 242], "2shanghai": [39, 45, 60, 242], "jiao": [39, 62, 242], "tong": [39, 62, 242], "3renmin": [39, 43], "4research": 39, "institut": [39, 47, 82, 165, 240, 242], "telecom": [39, 242], "memtensor": [39, 242], "openmem": [39, 242], "explicit": [39, 71, 221, 225, 235], "schedul": [39, 111, 117, 130, 184, 214, 226, 240, 242], "govern": [39, 182, 242], "definit": [39, 133], "parametr": [39, 64, 207, 212, 213, 228], "emb": [39, 219], "hoc": 39, "kv": [39, 101, 122, 133, 187, 188, 218, 240, 241], "cach": [39, 122, 133, 188, 218, 242], "hidden": [39, 86, 105, 119, 167, 242], "constitut": [39, 75, 127, 187], "preserv": [39, 119, 122, 165, 214], "contextu": [39, 145, 175, 242], "concaten": [39, 89, 137, 161, 164, 172, 224], "hipporag": [39, 242], "pgrag": [39, 242], "systemat": 39, "easyedit": [39, 242], "mem0": [39, 242], "letta": [39, 242], "pluggabl": 39, "plaintext": [39, 242], "mem": [39, 164, 229, 240, 242], "memory3": [39, 242], "metadata": [39, 209, 211, 221, 242], "header": 39, "payload": [39, 242], "smallest": [39, 70], "attribut": [39, 50, 58, 63, 165, 190, 197, 214, 242], "ttl": [39, 242], "lifecycl": 39, "pars": [39, 169], "memread": [39, 242], "memschedul": [39, 242], "memlifecycl": [39, 242], "memoper": [39, 242], "memvault": 39, "memgovern": 39, "memstor": 39, "inject": [39, 62, 91, 133, 224], "memorycub": [39, 242], "traceabl": 39, "memload": 39, "memdump": 39, "mip": [39, 242], "memblock": [39, 242], "00445": 40, "mrkl": 40, "moduar": 40, "modular": [40, 88, 214], "neuro": 40, "symbol": [40, 166, 201], "discret": [40, 89, 90, 136, 138, 146], "ai21": 40, "lab": [40, 57, 59, 122, 124, 143, 145, 147, 167, 211, 218, 225, 226], "lm": [40, 41, 46, 50, 54, 76, 85, 87, 98, 112, 116, 125, 130, 134, 139, 143, 145, 146, 160, 169, 175, 205, 211, 213, 236, 242], "miracl": [40, 208], "jurass": 40, "huge": [40, 194], "lms": [40, 41, 50, 54, 64, 130, 205], "usher": [40, 208], "gateway": 40, "avoid": [40, 61, 218], "neural": [40, 48, 49, 86, 87, 120, 143, 191, 194, 222, 225, 227, 229], "pronounc": 40, "mkrl": 40, "04761": 41, "universitat": 41, "pompeu": 41, "fabra": 41, "07": [41, 43, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 69, 70, 75, 76, 77, 81, 82, 83, 84, 85, 102, 130, 134, 135, 136, 139, 151, 152, 155, 166, 182, 214, 217, 229, 236, 240, 242], "textual": [41, 176], "paradox": 41, "factual": [41, 44, 127, 190, 202, 203, 206, 214], "lookup": [41, 101], "much": [41, 113, 116, 124, 184, 214, 228], "simpler": [41, 230], "decid": 41, "argument": [41, 211], "done": [41, 79, 116, 226], "noth": [41, 130, 191], "calendar": 41, "varieti": [41, 120, 199, 204, 225], "sacrif": 41, "img": [41, 159, 160, 201, 227], "upic": [41, 201], "se9t17": 41, "png": [41, 201], "17580": 42, "jarvi": 42, "cannot": [42, 165, 212, 218, 223], "except": [42, 55, 116, 201], "advoc": [42, 207], "philosophi": 42, "strong": [42, 75, 86, 87, 90, 106, 133, 144, 178, 205, 206, 225, 226, 228, 229], "abund": [42, 176], "wide": [42, 60, 75, 89, 120, 130, 170, 175, 176, 181, 189, 191, 206, 228], "sophist": [42, 169, 213, 218], "impress": [42, 79, 211], "16789": 43, "776": 43, "1tsinghua": 43, "2modelbest": 43, "4yal": 43, "5wechat": 43, "tencent": [43, 59, 167], "6zhihu": 43, "16": [43, 47, 49, 50, 52, 53, 56, 58, 68, 70, 76, 79, 85, 97, 98, 102, 104, 113, 116, 117, 118, 119, 120, 123, 124, 130, 134, 137, 138, 140, 143, 149, 164, 165, 166, 168, 174, 175, 192, 195, 225, 226, 229, 233, 236, 239, 241], "464": [43, 52], "dfs": [43, 56], "unsur": [43, 203], "whole": [43, 133, 191, 223], "davinci": 43, "003": [43, 75, 122, 167], "gorilla": [43, 45], "turbo": [43, 45, 46, 50, 52, 58, 63, 65, 77, 145, 170, 187, 188, 214], "16k": [43, 50, 62, 63, 64, 112, 214], "853": 43, "190": 43, "404": 43, "451": 43, "nsub": 43, "inst": 43, "rel": [43, 225], "i1": 43, "i2": 43, "i3": 43, "200k": [43, 62, 64, 65], "87k": 43, "25k": 43, "convent": [43, 120, 160, 199], "126": 43, "486": 43, "bert": [43, 45, 48, 60, 67, 75, 77, 98, 106, 108, 112, 120, 122, 135, 147, 152, 155, 166, 173, 177, 195, 211, 218, 219, 237, 239, 240, 242], "bm25": [43, 50, 54, 211, 238, 239, 242], "002": [43, 218, 236, 238], "ndcg": [43, 211], "78": [43, 49, 53, 54, 58, 68, 85, 119, 130, 131, 149, 165, 182, 192, 214, 225, 229, 238], "4096": [43, 76, 134, 141, 143, 149, 155, 166, 171, 172, 182, 187, 189, 226, 236, 240], "8192": [43, 49, 97, 105, 155, 169, 170, 181], "cat": [43, 81, 84, 165], "vicuna": [43, 45, 58, 59, 60, 62, 123, 124, 159, 161, 162, 164, 205, 240], "alpaca": [43, 76, 85, 96, 102, 123, 145, 181, 205], "huggingfac": [43, 45, 50, 52, 54, 56, 60, 61, 62, 63, 64, 74, 75, 78, 112, 122, 124, 137, 163, 167, 170, 183, 185, 240], "torchhub": 43, "tensorhub": 43, "ast": [43, 48, 50, 52, 54, 149], "zs": [43, 136, 158], "tot": [43, 45, 219], "1024": [43, 98, 105, 112, 138, 143, 155, 164, 166, 173, 201, 224, 226, 229, 236, 238, 239], "warmup": [43, 48, 130, 140, 141, 143, 165, 176, 184, 201, 225], "300": [43, 50, 55, 56, 63, 67, 68, 77, 79, 167, 170, 181, 231], "entreapi": 43, "faker": 43, "longitut": 43, "boolean": 43, "give_answ": 43, "give_up_and_restart": 43, "02xx": 44, "xxxxx_bleu": 44, "0401": 44, "xxxxx_roug": 44, "packag": [44, 144], "1803": 44, "01937_rouge2": 44, "measur": [44, 75, 98, 124, 143, 147, 168, 203, 204, 214, 226, 228], "1804": [44, 190], "08771_sacrebleu": 44, "report": [44, 86, 122, 145, 178, 205, 214, 218, 220, 226], "2306": [44, 87], "05685_judg": 44, "mt": [44, 47, 77, 81, 116, 122, 139, 170, 187, 237, 240], "chatbot": [44, 77, 130, 155, 160, 187], "arena": [44, 77, 112, 155, 187, 189], "14033_t": 44, "12045_": 44, "07982_": 44, "dual": [44, 65, 166, 187, 200, 224], "1809": 44, "09600_hotpotqa": 44, "explain": [44, 50, 71, 137, 214, 218], "2109": 44, "07958_truthfulqa": 44, "mimic": [44, 174], "falsehood": 44, "2311": [44, 221, 235], "12022_gpqa": 44, "graduat": [44, 75], "proof": [44, 236], "04368_simpleqa": 44, "2107": 44, "03374_humanev": 44, "07732_mbpp": 44, "synthesi": [44, 75, 86, 138, 187, 222, 229], "06770_swe": 44, "resolv": [44, 45, 47, 54, 62, 101, 206], "16694_humanev": 44, "cross": [44, 49, 58, 79, 86, 106, 111, 123, 130, 136, 171, 174, 194, 195, 197, 201, 224, 225, 227, 229], "lingual": [44, 86, 136, 195], "07974_livecodebench": 44, "holist": [44, 200], "contamin": [44, 187], "10499_cibench": 44, "plugin": 44, "03859_swe": 44, "06992_swe": 44, "01257_codeforc": 44, "codeforc": [44, 49, 52, 149, 189], "05136_lv": 44, "balanc": [44, 79, 86, 97, 101, 155, 200, 213, 226, 231], "length": [44, 65, 82, 105, 112, 113, 133, 137, 143, 169, 189, 214, 221, 226, 235], "256k": [44, 64, 130], "17753_locomo": 44, "veri": [44, 62, 78, 82, 105, 106, 122, 127, 130, 162, 191, 218], "2404": [44, 86, 209, 221], "06654_ruler": 44, "11963_needlebench": 44, "2103": [44, 87], "03874_math": 44, "2110": [44, 87], "14168_gsm8k": 44, "2405": [44, 86, 190, 209, 221, 235], "12209_mathbench": 44, "theori": [44, 233], "13394_mme": 44, "06281_mmbench": 44, "player": 44, "16125_seed": 44, "12793_sharegpt4v": 44, "18095_sharegpt": 44, "align": [44, 64, 82, 96, 124, 127, 130, 133, 136, 160, 165, 169, 170, 171, 174, 187, 201, 221, 227, 231, 235, 241], "2009": [44, 50], "03300_mmlu": 44, "massiv": [44, 57, 181], "multitask": [44, 86, 145], "2305": [44, 87, 190, 221, 235], "08322_c": 44, "suit": [44, 52, 96], "09212_cmmlu": 44, "15020_superclu": 44, "12983_gaia": 44, "07972_osworld": 44, "14249_hle": 44, "exam": [44, 75], "14033": 45, "compass": [45, 53, 58, 65], "lovesnowbest": 45, "1scienc": 45, "3tsinghua": 45, "4jilin": 45, "660": 45, "426": [45, 49], "553": 45, "487": 45, "753": 45, "305": [45, 83], "respond": [45, 50, 214, 218], "databas": [45, 46, 47, 209, 211, 221, 228], "golden": 45, "planner": 45, "executor": 45, "inclus": [45, 79], "claude2": 45, "llama2": [45, 60, 62, 64, 76, 122, 164, 181, 182, 184, 238, 239, 240], "70b": [45, 52, 53, 62, 63, 64, 65, 68, 76, 124, 125, 164, 181, 184, 187, 188, 219, 238, 240], "1106": [45, 53, 237], "preview": [45, 53, 56, 72, 101, 237], "sharegpt": [45, 85, 96, 102, 145, 161, 240], "wizardlm": [45, 240], "codellama": [45, 52], "agentlm": 45, "chatglm3": [45, 62, 68], "baichuan2": [45, 76, 181, 182, 237], "13b": [45, 46, 50, 53, 58, 60, 68, 75, 76, 77, 85, 98, 102, 119, 122, 123, 143, 159, 161, 162, 165, 181, 182, 184, 237, 239, 240], "toolbench": [45, 46, 53], "bank": [45, 136, 214, 240], "rewoo": 45, "swiftsag": 45, "533": 45, "hopcroft": 45, "karp": 45, "lis": 45, "2pr": 45, "irrelev": [45, 65, 70, 127, 206, 212, 214, 218], "unabl": 45, "bingmap": 45, "rapidapi": 45, "12045": 46, "sierra": [46, 47], "tau": [46, 143, 226, 228], "retail": [46, 218], "airlin": [46, 218], "collat": [46, 96], "convey": [46, 60], "fli": [46, 124, 130], "ensur": [46, 53, 75, 79, 120, 160, 211, 216, 218], "guidelin": 46, "laid": 46, "reject": [46, 127, 133, 187, 202, 211], "economi": [46, 81], "cancel": [46, 79, 101, 130], "rebook": 46, "rule": [46, 62, 133, 169, 214, 218, 237, 240], "bfcl": [46, 189], "toolemu": 46, "dstc": 46, "dialog": [46, 79, 160, 211], "pomdp": [46, 79], "db": [46, 47], "r_action": 46, "r_output": 46, "operatornam": [46, 226], "wedg": 46, "mathrm": [46, 81, 123, 143, 226], "mathbb": [46, 112, 113, 119, 143, 201, 218, 225, 226, 227, 228, 229, 230, 231, 239], "binom": 46, "quad": [46, 127, 143, 218, 225, 226, 228, 229, 239], "e_task": 46, "115": [46, 151], "schema": [46, 101], "fc": [46, 195], "llama3": [46, 52, 53, 64, 68, 164, 188, 218], "38": [46, 49, 54, 69, 70, 79, 155, 174, 195, 214, 240], "scaffold": 46, "07982": 47, "tau2": 47, "adher": [47, 127], "easier": [47, 202, 211], "flowbench": 47, "apigen": 47, "intellag": 47, "toolsandbox": 47, "decentr": [47, 101], "partial": [47, 50, 70, 127, 194, 204, 214, 218], "markov": 47, "crm": 47, "mock": 47, "reliabl": [47, 75, 79, 199, 205, 218], "toggl": 47, "half": [47, 79, 81], "roam": 47, "therefor": [47, 68, 88, 133], "statist": [47, 50, 62, 75, 76, 158, 167], "prd": 47, "2285": 47, "114": [47, 54, 81], "assert": [47, 49, 52], "o4": [47, 155], "litellm": 47, "04": [47, 118, 149, 224, 226, 227, 229], "20250219": 47, "086": [47, 228], "059": [47, 158], "default": [47, 127, 189], "oracl": [47, 53], "service_issu": 47, "mobile_data_issu": 47, "mms_issu": 47, "apn": 47, "vpn": 47, "scope": [47, 79, 127], "ord": 47, "phl": 47, "w4284542": 47, "sku": 47, "03374": 48, "5265": 48, "codex": [48, 49, 50, 51, 52, 181], "164": [48, 51, 149], "12b": [48, 65, 67, 241], "gvisor": 48, "ebpf": 48, "120": [48, 60, 119, 130, 145, 149, 161, 166], "5400": 48, "159": 48, "gb": [48, 97, 102, 123, 164, 229, 231], "adam": [48, 67, 91, 98, 106, 116, 125, 134, 135, 175, 176, 182, 223, 225], "nucleus": [48, 52, 133, 140], "neo": [48, 70], "85m": 48, "300m": [48, 160, 172], "tabnin": 48, "12m": [48, 160], "filter": [48, 53, 54, 61, 63, 132, 201, 209, 211, 212, 221, 224, 226, 228, 237], "sys": [48, 85, 101], "setprofil": 48, "travi": [48, 214], "tox": 48, "pypi": [48, 50], "1640": 48, "misalign": 48, "econom": [48, 75, 86], "labor": 48, "market": [48, 130, 214], "secur": [48, 212, 218], "implic": [48, 214], "environment": [48, 133, 214], "legal": [48, 75, 214, 217], "risk": [48, 207, 218], "network": [48, 87, 106, 120, 159, 184, 191, 193, 194, 195, 199, 214, 218, 223, 224, 225, 226, 227, 228, 230, 231, 239], "differenti": [48, 89, 206, 223], "pcfg": 48, "code2seq": 48, "deepcod": 48, "latent": [48, 133, 143, 231], "predictor": [48, 136, 145], "codebert": [48, 49], "pymt5": 48, "spoc": [48, 49], "transcod": 48, "contracod": 48, "flashfil": 48, "hearthston": 48, "codesearchnet": [48, 211], "codexglu": [48, 49], "facebook": [48, 116, 119, 130, 137, 143, 230], "buggi": 48, "07732": 49, "244m": 49, "137b": 49, "239": 49, "dsls": 49, "cubert": 49, "9749": 49, "23914": 49, "749": 49, "101": [49, 62, 79, 119, 130], "374": 49, "amini": 49, "dsl": 49, "391": [49, 79], "423": 49, "209": [49, 63], "192": [49, 195], "822": 49, "883": 49, "188": 49, "1370": 49, "sentencepiec": [49, 141, 143, 182], "2810": 49, "bpe": [49, 137, 140, 141, 144, 170, 176, 181, 182, 187, 240], "32000": [49, 240], "woodal": 49, "383": 49, "gram": [49, 62, 69, 83, 187, 188], "68b": 49, "off": [49, 97, 111, 112, 133, 138, 189, 226, 228], "zaremba": 49, "rnn": [49, 120, 134, 158, 160, 195, 201], "lstm": [49, 107, 134, 158, 160, 175], "balog": 49, "devlin": [49, 106], "dreamcod": 49, "bayou": 49, "java": [49, 51, 101, 130], "induct": [49, 213, 229, 240], "port": 49, "repair": 49, "code2vec": 49, "sygus": 49, "topcod": 49, "nap": 49, "progr": 49, "codenet": 49, "bender": [49, 130], "451mwh": 49, "tco2e": 49, "lowercase_with_underscor": 49, "06770": 50, "princeton": [50, 54], "785": 50, "swebench": [50, 54], "pr": [50, 54, 55], "2294": 50, "bench_verifi": 50, "bench_lit": 50, "bench_multilingu": [50, 54], "repositori": [50, 54, 137, 211], "pull": [50, 54, 55, 101], "instanc": [50, 54, 58, 79, 91, 97, 176, 211], "merg": [50, 96, 187, 188, 211, 214], "codebas": 50, "snapshot": 50, "19000": 50, "100000": 50, "maximum": [50, 98, 105, 113, 119, 200, 214, 231], "micro": [50, 105, 218], "195": [50, 146], "gold": [50, 55, 69, 84], "30000": [50, 85], "10000": [50, 137, 233], "438k": 50, "spars": [50, 64, 87, 96, 226, 228, 236, 238], "robertson": 50, "0613": [50, 58, 237], "delet": 50, "collaps": 50, "srivastava": 50, "owner": [50, 101, 214], "base_commit": 50, "problem_stat": 50, "test_patch": 50, "fail_to_pass": 50, "env_install_commit": 50, "hints_text": 50, "repo": [50, 218], "diff": 50, "created_at": 50, "kept": 50, "readm": 50, "conda": [50, 101], "log_pr": 50, "log_post": 50, "importerror": 50, "attributeerror": 50, "pass_to_pass": 50, "added": [50, 120, 228], "remov": [50, 54, 101, 214, 226], "225": [50, 113], "licens": [50, 188], "rank": [50, 56, 59, 69, 87, 96, 112, 118, 127, 130, 214, 229, 238], "alpha": [50, 82, 122, 125, 155, 223, 224, 225, 226, 229, 239], "dropout": [50, 67, 106, 112, 130, 134, 176, 182, 195, 239], "05": [50, 52, 55, 68, 85, 134, 143, 195, 201, 214, 215, 225, 229, 239], "6e": [50, 130, 182], "deepspe": [50, 96, 98, 117, 161, 168, 240], "ulyss": 50, "halstead": 50, "mccabe": 50, "radon": 50, "psf": 50, "greedi": [50, 65, 133, 140, 161], "md": [50, 98], "_1": [50, 141, 218, 219, 226, 229], "py": [50, 55, 137], "def": [50, 52, 101, 119], "euclidean": [50, 231], "return": [50, 79, 97, 101, 107, 112, 119, 130, 206, 212, 214, 218, 226], "bresenham": 50, "x0": [50, 140, 233], "y0": 50, "dx": [50, 237], "dy": 50, "sx": 50, "els": [50, 79], "sy": [50, 83], "err": 50, "true": [50, 59, 67, 70, 101, 115, 119, 203], "append": [50, 102, 229, 233], "e2": [50, 82, 86], "provd": 50, "16694": 51, "floatai": 51, "copenhagen": 51, "080": 51, "monolingu": [51, 139], "incod": [51, 52], "starcod": [51, 52, 181], "nl": 51, "codet5": [51, 52, 181], "codegen2": 51, "mbpp": [51, 52, 53, 56, 170, 181], "dsp": 51, "mtpb": 51, "ds": [51, 52, 53, 56, 113], "athiwaratkun": 51, "pl": [51, 84], "odex": 51, "fri": 51, "erni": [51, 77], "116": [51, 53], "bloom": [51, 75, 76, 119, 121, 122, 143], "bertscor": [51, 63, 242], "javascript": [51, 54], "974": 51, "stack": 51, "overflow": 51, "220m": [51, 160], "770m": 51, "1b": [51, 56, 116, 119, 135, 144, 165, 174, 182], "16b": [51, 127, 155], "scala": 51, "afro": 51, "asiat": 51, "indo": 51, "european": 51, "iranian": 51, "turkic": 51, "disai": 51, "101079164": 51, "kotlin": 51, "perl": [51, 84], "php": 51, "rubi": 51, "swift": [51, 214], "typescript": [51, 54], "afrikaan": 51, "tagalog": 51, "estonian": 51, "07974": 52, "uc": [52, 74, 85, 97, 102, 132, 146, 230], "mit": [52, 68, 122, 124, 162, 230], "cornel": [52, 54], "leetcod": [52, 56, 181], "atcod": [52, 56], "codestr": 52, "deepseek": [52, 53, 56, 65, 68, 127, 163, 164, 166, 183, 185, 189, 241], "sql": 52, "2023c": 52, "singhal": 52, "alphacodium": 52, "facet": [52, 214], "abc": [52, 56], "agc": 52, "medium": [52, 134, 137, 241], "divis": 52, "511": 52, "gu": [52, 155], "479": 52, "442": 52, "181": [52, 83], "starcoder2": [52, 56], "codeqwen": 52, "phind": 52, "34b": [52, 64, 182], "magicod": 52, "kulal": 52, "kwon": 52, "top_p": [52, 56], "stdin": 52, "ins": 52, "33b": [52, 123], "98": [52, 55, 134, 143, 149, 161, 189, 217, 226, 236], "lcb": 52, "134": [52, 79], "mixtral": [52, 56, 64, 79, 122, 187, 238], "codegen": [52, 53, 75, 76], "santacod": 52, "alphacod": [52, 55, 149], "codegeex": 52, "wizardcod": 52, "l2ceval": 52, "numpyev": 52, "pandasev": 52, "codecontest": [52, 56], "codescop": 52, "algo": 52, "olausson": 52, "nye": 52, "cruxev": 52, "sch": [52, 226], "fer": 52, "riddel": 52, "400": [52, 67, 79, 82, 98, 124, 144, 168, 218, 237, 240], "349": 52, "2222": 52, "jan": 52, "sep": [52, 175], "coder": [52, 56, 86, 189], "dscoder": 52, "codegemma": 52, "8x22b": [52, 64], "8x7b": [52, 238], "opencodeinterpret": 52, "command": [52, 64], "performoper": 52, "hi": 52, "10499": 53, "1shanghai": [53, 58], "2shanghaitech": 53, "opencompass": [53, 65, 76, 155, 164, 181], "download": [53, 137], "rc1": 53, "cibench_dataset": 53, "zip": [53, 62], "ipython": 53, "cover": [53, 75, 127, 130, 176, 212, 213, 214], "gsm8k": [53, 67, 68, 76, 78, 146, 149, 170, 182, 187, 188, 211, 240], "mathbench": 53, "qwenag": 53, "jupyt": 53, "notebook": 53, "pytorch": [53, 87, 97, 98, 102, 106, 107, 112, 115, 121, 122, 165, 166, 167, 168, 229], "tensorflow": [53, 97, 104, 106], "ms": [53, 61, 69, 139, 167, 193, 194, 196, 199, 211, 225, 228], "panda": [53, 220], "matplotlib": [53, 155, 165], "seaborn": 53, "fig": [53, 79, 164, 225, 226], "manner": [53, 96, 130, 138, 151, 218, 225], "markdown": [53, 85, 155, 164, 214], "easiest": 53, "hardest": 53, "concis": [53, 61, 206, 214], "statement": [53, 160, 204, 206], "orient": [53, 82, 161, 171, 172, 201, 211], "exe": 53, "num": [53, 60, 81], "vis": 53, "20b": [53, 58, 65, 68, 75, 76, 117, 119, 182], "internlm2": [53, 58, 68], "internlm": [53, 58, 65, 68, 76, 182, 237], "ifev": [53, 170, 188, 189], "bbh": 53, "pearson": [53, 77, 82, 237], "67b": 53, "scipi": 53, "scikit": 53, "131": [53, 155, 187, 188], "lightgbm": 53, "nltk": 53, "opencv": 53, "210": 53, "147": [53, 57], "template_cn": 53, "1900": 53, "788": 53, "492": 53, "50mb": 53, "03859": 54, "tubingen": 54, "center": [54, 79, 80, 81, 132, 224, 225, 226, 228], "1478": 54, "643": [54, 170, 187, 188], "619": 54, "devop": 54, "617": 54, "f2p": 54, "p2p": 54, "css": 54, "js": 54, "517": 54, "written": [54, 71], "102": [54, 145], "ts": [54, 214], "92": [54, 69, 78, 149, 159, 229, 238], "parenthesi": [54, 226], "jsx": 54, "tsx": 54, "145": [54, 141], "228k": 54, "1324": 54, "openlay": 54, "pixelmatch": 54, "lighthous": 54, "wp": [54, 82], "calypso": 54, "174": 54, "scss": 54, "tag": [54, 79, 82], "webgl": 54, "prs": 54, "automatt": 54, "gif": 54, "ide": [54, 79], "codesandbox": 54, "jsfiddl": 54, "codepen": 54, "stackblitz": 54, "editor": 54, "p5js": 54, "sitter": 54, "reproduct": 54, "npm": 54, "eslint": 54, "xvfb": 54, "64k": [54, 62, 64, 112, 214], "100k": [54, 60, 175], "prismj": 54, "prism": 54, "ux": 54, "62": [54, 155, 174, 182, 214, 229], "bpmn": 54, "p5": 54, "yes": [54, 57, 59, 69, 130, 155, 164, 174], "prettier": 54, "557": [54, 62], "465": 54, "100100100100": 54, "fleiss": [54, 123], "kappa": 54, "rust": 54, "06992": 55, "lassond": 55, "school": [55, 67, 75, 130], "weak": [55, 86, 87], "leakag": 55, "autocoderov": 55, "294": 55, "honeycomb": 55, "251": 55, "suspici": 55, "_ax": 55, "cbook": 55, "django": 55, "548": 55, "655": 55, "evalplus": 55, "alpharepair": 55, "fuzzgpt": 55, "titanfuzz": 55, "dei": 55, "01257": 56, "codeelo": 56, "qwenlm": [56, 142, 160, 169, 170, 181, 187, 188, 189], "xcodeev": 56, "taco": [56, 155], "livecodebench": [56, 170, 187, 189], "usaco": 56, "bigcodebench": 56, "qwq": [56, 189], "32b": [56, 65, 188, 189], "omni": [56, 86, 155, 169], "1578": 56, "1261": 56, "dp": [56, 107, 113, 182], "codewar": 56, "katti": 56, "div": 56, "387": 56, "30b": [56, 118, 122, 187, 189], "parenthes": [56, 145, 147, 158], "percentil": 56, "underlin": [56, 57, 127, 147, 162, 189], "800": [56, 57, 62, 98, 141, 155, 170, 223], "1300": [56, 182], "3500": 56, "im": 56, "tr": [56, 140, 143], "varianc": [56, 98, 122, 133], "violin": 56, "plot": [56, 165, 226], "mike": 56, "mirzayanov": 56, "opencod": 56, "yi": [56, 58, 62, 64, 68, 130, 133, 164], "14b": [56, 65, 68, 98, 181, 187, 188, 189, 237, 241], "top_k": 56, "repetition_penalti": 56, "096": [56, 184, 189], "768": [56, 139, 155, 166, 169, 170, 173, 188, 189, 218, 224, 226], "iid": 56, "var": [56, 64, 75], "r_i": [56, 82, 219], "r_": [56, 82, 127], "348": 56, "4009": 56, "contest": 56, "2034": 56, "abb": 56, "aac": 56, "13394": 57, "1871": 57, "1tencent": [57, 59], "youtu": [57, 167, 228], "2xiamen": 57, "bradyfu": 57, "coars": [57, 58, 97, 151, 228], "commonsens": [57, 176, 211], "whose": [57, 122, 137, 184, 224], "worth": 57, "coco": [57, 58, 60, 61, 124, 155, 159, 160, 161, 162, 166, 173, 174, 192, 194, 196, 197, 199, 200, 225, 226], "170": [57, 143, 155, 214], "optic": [57, 226, 228], "140": [57, 139, 145, 158, 181], "poster": [57, 61], "celebr": 57, "scene": [57, 190, 222, 226, 229], "landmark": [57, 218, 225, 228], "artwork": [57, 69, 191], "otter": [57, 174], "lynx": 57, "wemm": 57, "lion": 57, "sphinx": 57, "infmllm": 57, "git2": 57, "185": 57, "xcompos": [57, 58], "06281": 58, "1259": 58, "vlmevalkit": 58, "2nanyang": 58, "3the": 58, "kong": [58, 61, 62, 166], "4nation": 58, "singapor": 58, "5zhejiang": [58, 242], "3217": 58, "125": [58, 119, 139, 166, 214, 217], "ct": [58, 140, 241], "3d": [58, 166, 169, 221, 224, 227], "dev": [58, 74, 75, 135, 146, 170, 241], "clevr": 58, "scienceqa": [58, 161, 172], "vqav2": [58, 149, 160, 166, 171, 173], "owlev": 58, "lvlms": [58, 160, 169, 170], "ehub": [58, 59], "nocap": [58, 173], "flickr30k": [58, 173], "gqa": [58, 76, 160, 161, 166, 171, 172, 173, 187, 188, 189, 240, 241], "ok": [58, 173, 174], "vizwiz": [58, 60, 172, 174], "youcook2": 58, "mme": [58, 59, 60, 166, 170, 172, 241], "openflamingo": [58, 59, 124, 159], "blip": [58, 59, 60, 63, 159, 162, 164, 171, 172, 173, 174, 211], "former": [58, 159], "instructblip": [58, 59, 60, 161, 172], "max": [58, 81, 102, 112, 119, 122, 125, 145, 147, 227], "217": 58, "minigpt4": 58, "visualglm": 58, "0125": 58, "vanillaev": 58, "idef": 58, "cogvlm": [58, 164], "mplug": [58, 174], "owl": [58, 174], "minicpm": [58, 170, 240], "xcomposer2": 58, "en": [58, 62, 74, 82, 84, 98, 130, 140, 141, 144, 155, 160, 170, 238], "2d": [58, 112, 155, 165, 169, 201, 220, 223, 224, 225, 226, 228, 229, 241], "3000": [58, 59, 82, 85, 139, 195, 226], "3200": [58, 67, 237, 240], "impli": [58, 101], "origin": [58, 62, 122, 124, 130, 160, 206, 211, 214, 217, 226, 230, 233], "seedbench": 58, "80b": 58, "mpt": [58, 113, 143, 174, 181], "chatglm": [58, 65, 76, 77, 219, 237], "cp": 58, "fp": [58, 73, 120, 122], "ar": [58, 140, 152, 164, 167, 201, 224, 225, 226, 241], "lr": [58, 130, 201], "17b": [58, 98], "16125": 59, "673": 59, "ailab": [59, 136], "cvc": 59, "2arc": 59, "pcg": 59, "242": 59, "2194": 59, "mmbench": [59, 60, 155, 161, 162, 166, 169, 170, 241], "2974": 59, "cc3m": [59, 160, 173], "ssv2": 59, "epic": 59, "blip2": 59, "tag2text": 59, "sam": [59, 60, 228], "lamm": 59, "imagellm": 59, "videollm": 59, "gvt": 59, "fals": [59, 67, 68, 70, 119, 189, 191], "flan": [59, 85, 123, 130, 161, 162, 173], "vpgtran": [59, 164], "videochat": 59, "valley": 59, "1600": [59, 226], "12793": [60, 186], "772": 60, "1univers": 60, "sharegpt4omni": 60, "50k": [60, 140], "lcs": [60, 187, 188, 240], "laion": [60, 159, 160, 164, 165, 173, 174], "cc": [60, 63, 79, 99, 112, 116, 158, 159, 169], "3m": [60, 134, 160], "sbu": [60, 160, 173], "20k": [60, 75, 85, 218], "textcap": [60, 61], "wikiart": 60, "1k": [60, 68, 98, 104, 112, 166], "share": [60, 79, 90, 96, 97, 113, 164, 184, 187, 218, 225, 227], "2m": [60, 112, 144, 214], "118k": 60, "570k": 60, "558k": 60, "942": 60, "1943": 60, "instructgpt": [60, 70, 87, 123, 205, 242], "laclip": 60, "veclip": 60, "23k": [60, 172], "array": [60, 82, 106, 143, 218], "delin": [60, 211], "seed": [60, 144, 151, 154, 155, 158, 161, 166, 170], "usag": [60, 79, 96, 111, 112, 164, 218, 242], "abbrevi": 60, "336": [60, 161, 162, 225], "576": [60, 169], "mlp": [60, 134, 143, 155, 161, 165, 166, 168, 169, 170, 195, 201, 219, 223, 225, 226, 239, 240, 241], "2e": [60, 85, 161, 175, 219], "4700": 60, "665k": 60, "128": [60, 61, 85, 102, 105, 112, 113, 115, 121, 124, 130, 135, 142, 143, 155, 161, 165, 166, 168, 170, 175, 184, 189, 195, 201, 223, 224, 225, 226, 236, 240], "5200": 60, "vet": [60, 166, 241], "qbench": 60, "1000k": [60, 65], "adj": 60, "adv": 60, "prep": 60, "18095": 61, "shenzhen": 61, "freedomintellig": 61, "a800": [61, 141, 182, 240], "evalgen": 61, "dpg": 61, "imgedit": 61, "allava": 61, "45k": [61, 241], "46k": 61, "genev": [61, 166, 241], "ultraedit": 61, "motion": [61, 226, 227, 228], "91k": 61, "vitron": 61, "dimens": [61, 105, 112, 113, 169, 172, 184, 206, 218, 224, 226], "subcategori": 61, "exp": [61, 81, 84, 166, 218, 223, 225, 226, 228], "lambda": [61, 228, 229], "regener": 61, "profession": [61, 75], "appropri": [61, 175, 199, 214], "theme": 61, "_theme": 61, "fit": [61, 102, 111, 218, 226], "join": 61, "_document": 61, "_categori": 61, "chosen": [61, 225], "conceiv": 61, "font": [61, 127], "characterist": [61, 146, 218, 222], "_font": 61, "prioriti": 61, "ornat": 61, "unnecessarili": 61, "unless": [61, 122], "genuin": 61, "histor": [61, 204, 218], "recreat": 61, "minim": [61, 79, 89, 97, 120, 130, 175, 176, 218, 223, 227, 229, 231], "parchment": 61, "old": [61, 193], "compel": 61, "english": [61, 130, 145, 158, 160, 164, 178, 208, 214], "aesthet": 61, "organ": [61, 170, 214, 218], "slide": [61, 170, 227], "palett": 61, "corpor": 61, "gray": [61, 101, 122], "contrast": [61, 79, 155, 173, 176], "readabl": 61, "accent": 61, "textur": [61, 229], "smooth": [61, 122, 218, 225, 228], "untextur": 61, "subtl": 61, "linen": 61, "distract": [61, 168], "placehold": 61, "logo": 61, "tech": [61, 214, 218], "care": [61, 79, 106, 113, 218, 233], "meta_prompt_system": 61, "beauti": [61, 211], "essenc": 61, "mood": [61, 206], "priorit": 61, "appeal": 61, "rigid": [61, 225, 229], "doesn": [61, 127, 218], "awkward": [61, 233], "verbos": [61, 85, 174], "explan": [61, 71, 127, 130, 165, 206, 208, 214, 218], "preambl": 61, "bullet": [61, 130], "misti": 61, "forest": 61, "creatur": [61, 218], "mystic": 61, "deer": 61, "dappl": 61, "ancient": [61, 130, 218], "sunlight": 61, "mysteri": 61, "tall": 61, "quiet": 61, "portrait": 61, "her": 61, "seren": 61, "gaze": 61, "backdrop": 61, "swirl": 61, "cosmic": 61, "stardust": [61, 65], "illumin": [61, 226], "intim": 61, "05136": 62, "infinig": 62, "lveval": 62, "tsinghua": [62, 65], "128k": [62, 64, 65, 155, 171, 172, 187, 214], "729": 62, "645": 62, "confus": [62, 158], "insert": [62, 106, 145, 165], "cfi": 62, "kpr": 62, "lic": 62, "mixup": 62, "en2zh": 62, "lic_mixup": 62, "hotpotwikiqa": 62, "wikipedia": [62, 69, 70, 72, 116, 117, 143, 175, 211], "2wikimultihopqa": [62, 211, 238], "hotpotwikiqa_mixup": 62, "loogl": 62, "mr": 62, "loogle_mir_mixup": 62, "loogle_cr_mixup": 62, "duread": 62, "dureader_mixup": 62, "sd": [62, 170], "160": [62, 143, 155, 167, 196, 225], "loogle_sd_mixup": 62, "cmrc": [62, 182], "cmrc_mixup": 62, "multifieldqa": 62, "zh": [62, 65, 74, 141, 144, 151, 160, 170, 171, 172], "longbench": [62, 64, 65, 188], "multifieldqa_en_mixup": 62, "multifieldqa_zh_mixup": 62, "factrecal": 62, "synthet": [62, 223, 230, 232], "evid": [62, 203, 206, 207, 211, 214, 216, 218], "lengthi": 62, "factrecall_en": 62, "factrecall_zh": 62, "21k": 62, "stand": [62, 130, 175, 223], "ak": 62, "2k": [62, 65, 85, 112, 155, 165, 188], "moonshot": 62, "zeroscrol": [62, 64], "13k": [62, 130], "bamboo": 62, "niah": [62, 65], "ruler": [62, 65, 188], "yarn": [62, 64, 65, 187, 188, 189], "compress": [62, 87, 211, 218, 230], "pg19": [62, 236], "blacklist": 62, "1048k": 62, "124": 62, "139": 62, "197": 62, "133": 62, "924": 62, "955": 62, "hf": [62, 167, 239], "8k": [62, 64, 67, 76, 113, 188, 214, 218, 226, 229], "a6": 62, "a7": 62, "bluelm": 62, "a12": 62, "a13": 62, "nallavan": 62, "vazhvan": 62, "17753": 63, "north": 63, "carolina": 63, "chapel": 63, "hill": 63, "southern": [63, 82], "snap": 63, "9209": 63, "msc": 63, "adversari": [63, 194, 203], "factscor": [63, 205], "mmrelev": 63, "dragon": 63, "mmdialog": 63, "4b": [63, 65, 160, 174, 184, 188, 189, 240], "9000": [63, 192], "127": [63, 119, 122, 123, 166], "705": 63, "104": [63, 119], "547": 63, "285": 63, "871": 63, "512": [63, 65, 106, 112, 122, 125, 130, 143, 155, 182, 195, 211, 218, 225, 226, 236, 240], "nc": [63, 158], "deed": 63, "a6000": [63, 121], "fp32": [63, 98, 113, 115, 117, 118, 123, 124, 130, 181], "57": [63, 74, 78, 79, 105, 119, 120, 123, 130, 149, 155, 182, 193, 229, 236], "miss": [63, 112, 127, 130, 201, 207], "misunderstand": [63, 127], "cue": [63, 225], "salienc": 63, "06654": 64, "274": 64, "09": [64, 65, 227], "rulerrul": 64, "rwkv": [64, 77], "mamba": 64, "ring": [64, 97], "shift": [64, 74, 96, 124, 133, 233], "dilat": 64, "sink": 64, "alibi": 64, "xpos": 64, "rope": [64, 96, 143, 155, 169, 170, 181, 182, 187, 188, 189, 240, 241], "infinitebench": 64, "ltm": 64, "x3": [64, 233], "zeta": 64, "moe": [64, 96, 103, 110, 127, 133, 152, 155, 189, 221, 240, 241], "1m": [64, 65, 160, 175, 187, 226], "bfloat16": [64, 96, 115, 120, 123, 167, 173, 181, 188, 218, 229, 236, 240], "wavg": 64, "dec": [64, 173], "104b": 64, "lwm": 64, "gradientai": 64, "uuid": 64, "longalpaca": 64, "512k": 64, "v5": 64, "slimpj": 64, "lv": [64, 187, 188], "nocha": 64, "flenqa": 64, "verif": [64, 132, 211], "ag": 64, "glm": [64, 76, 86, 119, 122, 155, 171, 172], "phi3": [64, 188], "prefix": [64, 88, 90, 138, 167, 217, 240], "dbrx": 64, "v0": [64, 159], "glm4": [64, 65, 68], "jamba": 64, "longlora": 64, "11963": 65, "needbench": 65, "paulgrahamessay": 65, "chinesedomainmodelingev": 65, "compassbench": 65, "readthedoc": 65, "advanced_guid": 65, "compassbench_intro": 65, "compassbench_v2_0": 65, "filler": 65, "rightmost": 65, "elimin": [65, 218], "lorem": 65, "ipsum": 65, "r1": [65, 127, 189, 241], "o3": [65, 80, 122, 189], "passkey": 65, "haystack": [65, 187], "longform": [65, 236], "bigbird": 65, "rt": [65, 200], "emerald": 65, "island": 65, "shard": [65, 87, 97, 116], "atc": 65, "enl": 65, "chunk": [65, 145, 167, 170, 187, 211, 214, 216, 217, 220, 238, 240, 242], "gemma": [65, 127, 143, 164, 187, 189, 240], "27b": [65, 127], "10b": 65, "internlm3": 65, "dca": [65, 187, 188, 189], "9b": [65, 105, 160, 164, 174, 188], "qwen1": [65, 68, 187], "zephyr": 65, "lmdeploy": 65, "paul": 65, "graham": 65, "jasmin": 65, "jame": 65, "janet": 65, "carolyn": 65, "wyatt": 65, "emili": 65, "joseph": 65, "taylor": [65, 214], "eileen": 65, "dan": 65, "newton": 65, "mother": 65, "carol": 65, "barron": 65, "kathi": 65, "marshal": 65, "matern": 65, "grandfath": 65, "georg": [65, 130], "est": 65, "nanci": 65, "03874": 66, "openaipubl": [66, 71, 72, 74], "blob": [66, 71, 72, 74, 107], "math_test": 66, "csv": [66, 71, 72, 74, 220], "math_500_test": 66, "14168": 67, "4789": 67, "grade": [67, 85, 130, 131, 159, 214, 237], "upwork": [67, 71, 130], "surg": 67, "surgehq": 67, "8500": 67, "dolphin18k": 67, "aqua": [67, 68], "rat": 67, "mathqa": [67, 68], "ape210k": 67, "asdiv": [67, 68], "khan": 67, "academi": [67, 171], "mathematica": 67, "amp": [67, 115, 165], "175b": [67, 91, 119, 120, 121, 122, 130], "residu": [67, 134, 143, 194, 223], "reversible_50000": 67, "argmax": [67, 219], "mse": [67, 217, 231, 241], "example_solutions_1": 67, "example_solutions_8": 67, "12209": 68, "primari": [68, 101, 120, 204], "colleg": [68, 75, 170, 228], "subject": [68, 70, 75, 80, 151, 214, 218], "topic": [68, 88, 127, 130, 143, 214, 238], "algebra": 68, "equat": [68, 143, 218], "quadrat": [68, 112, 113, 218, 226], "amc": 68, "sat": [68, 137, 194], "mmlu": [68, 71, 74, 75, 76, 77, 78, 80, 85, 123, 146, 149, 162, 170, 181, 182, 187, 188, 189, 211, 237, 240], "scibench": 68, "3709": 68, "1500": [68, 136, 144, 147, 165, 182], "circularev": 68, "ce": [68, 201, 241], "perplex": [68, 106, 112, 118, 119, 124, 134, 143, 182, 204, 236], "ppl": [68, 117, 124, 125], "2048": [68, 85, 97, 102, 105, 119, 122, 143, 155, 181, 188, 195, 236, 240], "110b": [68, 187], "rl": [68, 127, 130, 133, 147, 155, 188], "circular": 68, "infus": 68, "law": [68, 75, 132, 138, 155, 184, 206], "mammoth": [68, 241], "alg514": 68, "singleeq": 68, "draw": [68, 88, 96, 207, 226], "addsub": 68, "singleop": 68, "multiarith": 68, "math23k": [68, 170], "numglu": 68, "lila": 68, "grammar": 68, "gsm": 68, "ceval": [68, 75, 170, 182], "hg": 68, "math401": [68, 170], "opendatalab": 68, "sin": [68, 130, 223, 224], "circ": [68, 226, 228], "cos": [68, 223, 224, 228, 239], "ii": [68, 69, 105, 127, 160, 166, 226], "iii": [68, 69, 160, 166, 226], "uv": 68, "cap": [68, 160], "aaannn": 68, "nnnaaa": 68, "log_2": [68, 130], "2x": 68, "let": [68, 112, 218], "09600": 69, "3188": 69, "carnegi": [69, 79, 85, 104, 107, 108], "mellon": [69, 79, 85, 104, 107, 108], "montreal": 69, "senior": 69, "fellow": 69, "089": 69, "814": 69, "661": 69, "triviaqa": [69, 71, 143, 182, 211], "searchqa": 69, "qangaroo": 69, "complexwebquest": 69, "kb": [69, 101], "andrew": 69, "wood": 69, "nba": 69, "iron": 69, "maiden": 69, "ac": [69, 72], "dc": 69, "turk": [69, 74], "parlai": 69, "779": 69, "fullwiki": 69, "405": 69, "bigram": [69, 81, 84], "tf": [69, 97], "idf": 69, "central": [69, 101, 174, 214, 218], "cqw": 69, "wh": [69, 225, 226], "did": [69, 79, 105, 130, 137], "person": [69, 130, 139, 211, 214, 218], "king": 69, "edward": 69, "rihanna": 69, "cartoonito": 69, "apalache": 69, "fort": 69, "richardson": 69, "10th": 69, "13th": 69, "centuri": 69, "die": [69, 206], "schweigsam": 69, "frau": 69, "mvp": 69, "clark": 69, "gardner": 69, "bi": [69, 107, 206], "entiti": [69, 218, 220, 238], "upper": [69, 98, 105], "marco": [69, 211], "wikiextractor": 69, "corenlp": 69, "turker": 69, "wikiproject": 69, "591": 69, "uni": 69, "r_q": 69, "cand": 69, "coran": 69, "288": [69, 118, 195, 225], "304": 69, "286": [69, 83], "07958": 70, "2101": [70, 87], "oxford": 70, "sylinrl": 70, "817": 70, "dialogpt": [70, 143], "invers": [70, 133], "uninform": 70, "exagger": 70, "say": [70, 71, 79, 130, 214], "liter": 70, "mimick": 70, "superstit": 70, "437": 70, "380": 70, "webtext": 70, "unifiedqa": [70, 74], "gopher": 70, "harm": [70, 130, 149], "rlhf": [70, 75, 76, 85, 96, 123, 127, 133, 149, 152, 162, 188, 237, 241, 242], "evan": 70, "9k": [70, 123], "rouge1": 70, "bleurt": 70, "unfilt": 70, "misconcept": 70, "fiction": [70, 130, 218], "practic": [70, 138, 159, 165, 184, 194, 206, 212], "null": [70, 130, 238], "pegasus": 70, "fortun": 70, "cooki": [70, 79], "contradict": 70, "qualifi": 70, "1955": [70, 130], "sam4621": 70, "alex1083": 70, "alex9137": 70, "12022": 71, "idavidrein": 71, "1new": 71, "2coher": 71, "3anthrop": 71, "pbc": 71, "726": 71, "gpqa_diamond": 71, "diamond": [71, 189], "198": [71, 165, 193], "writer": [71, 79], "who": [71, 130, 214, 218, 238], "agre": 71, "oversight": 71, "canari": 71, "546": 71, "191": [71, 158], "reclor": 71, "commonsenseqa": [71, 76, 181, 211], "expertqa": 71, "04368": 72, "simple_qa_test_set": 72, "326": [72, 81], "858": 72, "709": 72, "550": [72, 165], "fandom": 72, "uk": 72, "imdb": 72, "gpt4o": 72, "confid": [72, 212, 226, 227, 228], "confidence_scor": 72, "2c": 72, "2i": 72, "f_": [72, 82, 127, 227, 228], "tp": [73, 182], "tn": 73, "fn": 73, "9999999": 73, "tpr": 73, "fpr": 73, "03300": 74, "columbia": 74, "uchicago": 74, "uiuc": 74, "peopl": [74, 130, 182, 191, 205, 214, 218], "eec": 74, "edu": [74, 234], "4737": [74, 219], "15908": 74, "stem": [74, 75, 76, 82, 85, 182, 189], "mmlu_": 74, "giuliolovisotto": 74, "openai_multilingual_mmlu": 74, "mmmlu": 74, "197k": 74, "14k": 74, "cmmlu": [74, 181, 182, 237, 240], "glue": [74, 75, 76, 77, 78, 116, 123, 175, 182], "superglu": [74, 76, 89, 130, 182, 226], "hellaswag": [74, 85, 122, 125, 130, 181, 182, 211], "iqa": 74, "cosmosqa": 74, "gre": 74, "usml": 74, "1540": 74, "14079": 74, "sever": [74, 75, 97, 105, 113, 165, 178, 205, 206, 207, 213, 214, 218, 226], "percent": 74, "chanc": [74, 112, 216], "val": [74, 170], "roberta": [74, 91, 116, 237], "08322": 75, "hkust": 75, "215": 75, "abcd": [75, 82], "disciplinari": 75, "elementari": 75, "educ": [75, 218], "mere": [75, 204], "memor": [75, 236, 240], "conclus": 75, "big": [75, 77, 97, 211], "helm": [75, 76, 85, 123], "clue": [75, 76, 77], "13948": 75, "948": 75, "weipu": 75, "cevalbenchmark": 75, "ao": 75, "204": 75, "agiev": [75, 76, 77, 181], "mmcu": [75, 76], "yuzhuo": 75, "2020aaa0106502": 75, "broader": [75, 96], "038": 75, "015": 75, "458": 75, "420": [75, 143, 158], "vari": [75, 159, 169, 211, 214], "certif": 75, "qualif": 75, "tax": [75, 130, 181, 187], "civil": 75, "servant": 75, "exemplar": [75, 133], "176b": [75, 119, 121, 122], "65b": [75, 76, 118, 123], "6gb": [75, 98, 102], "fp16": [75, 98, 113, 117, 118, 119, 120, 121, 122, 124, 130, 137, 168, 173], "100b": [75, 76, 98], "moon": 75, "certain": [75, 79, 194, 206, 214], "lag": 75, "weakest": 75, "biolog": 75, "geographi": 75, "polit": [75, 130], "underperform": 75, "tend": 75, "vocat": 75, "fire": [75, 225], "difficult": [75, 106, 225], "board": 75, "room": [75, 130, 206, 218, 227, 228], "visit": [75, 171, 172], "leaderboard": [75, 77, 240], "chatglm2": [75, 76, 77, 240], "cluster": [75, 87, 104, 214, 224], "80gb": [75, 102, 112, 113, 121, 218], "gpus": [75, 106, 107, 111, 113, 116, 118, 168], "was": [75, 78, 79, 130, 175, 214, 216, 233], "cpus": 75, "timefram": 75, "reproduc": [75, 79, 87, 145, 165, 206], "transpar": [75, 207, 211], "09212": 76, "289": [76, 79], "superclu": 76, "aclu": 76, "m3ke": 76, "528": 76, "105": 76, "baichuan": [76, 172, 182], "xvers": [76, 182], "batgpt": 76, "158": 76, "148": 76, "411": 76, "194": 76, "falcon": [76, 122, 143, 181, 240], "tii": 76, "1000b": 76, "refinedweb": [76, 182], "40b": [76, 187, 240], "bigscienc": 76, "bloomz": [76, 77], "bactrian": 76, "mbzuai": [76, 85, 146], "rlhaf": 76, "15b": [76, 168], "moss": [76, 77, 145, 167], "extractchoic": 76, "race": [76, 106, 130, 176, 182], "piqa": [76, 122, 125, 181, 182], "15020": 77, "1clue": 77, "2westlak": 77, "nli": [77, 133, 211], "elo": [77, 123, 165, 181, 189], "900": [77, 79, 181], "minimax": 77, "sst": [77, 130, 211], "langya": 77, "9900": 77, "130b": [77, 86, 119, 122], "ziya": 77, "360": [77, 79], "sparkdesk": 77, "spearman": [77, 82], "515": 77, "1915": 77, "555": 77, "1536": 77, "9397": 77, "12983": 78, "1fair": 78, "2huggingfac": 78, "3autogpt": 78, "4genai": 78, "175": [78, 136, 178], "466": 78, "166": 78, "agentbench": 78, "unix": 78, "openagi": 78, "semantickernel": 78, "proper": [78, 206], "brows": [78, 79, 202], "07972": 79, "xlang": 79, "cmu": 79, "salesforc": 79, "waterloo": 79, "103": [79, 105, 211], "viewer": 79, "evaluation_exampl": 79, "ubuntu": 79, "369": 79, "intervent": [79, 218], "product": [79, 115, 119, 130, 135, 218, 226], "therebi": [79, 96, 169, 207, 211, 231, 232], "kind": [79, 130, 218], "arbitrari": [79, 197, 225], "script": [79, 137], "reveal": [79, 89, 214], "defici": [79, 91], "primarili": [79, 178, 211, 233], "digit": 79, "o_t": 79, "vm": 79, "thunderbird": 79, "yellow": [79, 107], "host": 79, "headless": 79, "cloud": [79, 101, 115, 118, 127, 149, 225, 227, 229], "andobtain": 79, "evaluationof": 79, "wait": [79, 97, 111, 171, 172], "540": [79, 165, 226], "alt": [79, 155, 165], "miniwob": 79, "keyboard": 79, "completelist": 79, "vlc": 79, "gimp": 79, "reddit": [79, 130, 202, 204], "stackoverflow": 79, "coursera": 79, "udemi": 79, "tiktok": 79, "calc": 79, "268": 79, "nl2bash": 79, "302": 79, "intuit": [79, 111], "exec": 79, "env": [79, 97], "eas": [79, 90], "init": [79, 101], "func": 79, "111": [79, 120], "1080": 79, "6000": [79, 174], "ffmpeg": 79, "infoui": 79, "profil": [79, 97, 104, 107, 130], "captcha": 79, "vms": 79, "painless": [79, 222], "virtual": [79, 88, 226], "pyatspi": 79, "computer_13": 79, "good": [79, 193, 233], "donot": 79, "locatecenteronscreen": 79, "sinc": [79, 105, 112, 175, 189, 191, 205, 212, 228], "variabl": [79, 224], "yourself": 79, "insid": [79, 147, 223], "easili": [79, 224], "password": 79, "feel": [79, 130], "sudo": 79, "never": [79, 225], "librari": [79, 87, 101, 106], "moveto": 79, "tag_3": 79, "tag_2": 79, "dragto": 79, "tag_1": 79, "row": [79, 106, 113, 119, 165, 214, 225, 226, 229], "tone": [79, 206], "bright": 79, "photo": 79, "width": [79, 115, 124, 233], "height": [79, 195], "image_icon_x": 79, "image_icon_i": 79, "1793": 79, "920": [79, 155], "doubleclick": 79, "menu": 79, "colors_menu_x": 79, "colors_menu_i": 79, "344": [79, 120], "dropdown": 79, "approxim": [79, 112, 113, 118, 121, 145, 230, 236], "pixel": [79, 224, 225, 226, 228, 229], "apart": 79, "brightness_contrast_option_x": 79, "brightness_contrast_option_i": 79, "shadow": 79, "cancel_button_x": 79, "cancel_button_i": 79, "375": 79, "625": 79, "exposur": 79, "588": 79, "estim": [79, 104, 107, 164, 205, 227, 229], "403": 79, "wrong": [79, 201, 212, 216], "duplic": [79, 195, 229], "meet": [79, 86, 97, 127, 170, 211, 214, 218], "ten": [79, 137, 230], "year": [79, 113, 130, 200], "2013": [79, 195, 214, 226], "fill": [79, 168, 170, 218, 226], "vacant": 79, "cell": [79, 105], "c2": [79, 123, 214], "empti": 79, "319": 79, "222": 79, "scottsdal": 79, "c3": [79, 211, 214], "icml": 79, "atlanta": 79, "c4": [79, 119, 125, 174], "lake": 79, "taho": 79, "copi": [79, 88, 97, 101, 102], "c16": 79, "541": 79, "beach": [79, 130], "bing": [79, 202, 204], "thingi": 79, "stuff": 79, "1280": 79, "cursor": 79, "drop": [79, 89, 130], "tag_31": 79, "customis": 79, "appear": [79, 158, 204, 223], "usual": [79, 225], "ll": [79, 112, 226], "reach": [79, 113, 226], "tag_47": 79, "tag_25": 79, "tab": 79, "typewrit": 79, "searchengin": 79, "might": [79, 89, 130, 206], "onc": [79, 97, 101, 190, 211, 225, 229, 233], "tag_42": 79, "exit": [79, 101, 240], "14249": 80, "centerforaisafeti": 80, "2scale": 80, "lastexam": 80, "2500": 80, "hundr": [80, 229], "rms": [80, 127], "subset": [80, 96, 137, 144, 147, 203, 206, 208, 226], "aclantholog": [81, 82, 100], "p02": 81, "1040": 81, "dl": [81, 107, 115], "acm": [81, 107, 115], "3115": 81, "1073083": 81, "1073135": 81, "ibm": 81, "watson": 81, "34680": 81, "bp": [81, 84], "cdot": [81, 82, 123, 125, 143, 144, 145, 201, 223, 225, 226, 227, 228, 230], "w_": [81, 125, 218], "understudi": [81, 82, 84], "p_n": [81, 225], "p_1": [81, 225], "count_": 81, "_ref": 81, "_count": 81, "unigram": [81, 82, 83, 84, 143], "p_2": [81, 225], "leq": [81, 127, 143, 144], "logbleu": 81, "synonymi": 81, "paraphras": 81, "goe": [81, 130, 212], "thirti": 81, "mat": [81, 130], "ref1": 81, "approx": [81, 143, 155], "7143": 81, "adequaci": 81, "fluenci": [81, 206], "east": [81, 130], "asian": 81, "asia": 81, "fold": [81, 97], "3468": 81, "2571": 81, "s2": [81, 82, 168, 189], "s1": [81, 82, 133, 189], "s3": [81, 82, 101], "h1": 81, "h2": 81, "aclweb": 82, "antholog": 82, "w04": 82, "1013": [82, 119], "pdf2": 82, "upload": 82, "2016": [82, 96], "was2004": 82, "20772": 82, "duc": 82, "nist": 82, "hovi": 82, "gist": 82, "polic": 82, "kill": [82, 101], "gunman": 82, "len": [82, 119, 233], "guman": 82, "cup": 82, "beta": [82, 116, 125, 130, 155, 224, 226, 240], "rightarrow": [82, 218, 230], "infti": [82, 228], "w_1": [82, 226], "w_2": [82, 226], "w_3": 82, "w_4": 82, "w_5": 82, "c_1": 82, "w_6": 82, "w_7": 82, "w_8": 82, "c_2": 82, "w_9": 82, "lcs_": 82, "s_1": 82, "s_2": 82, "mead": 82, "s_i": [82, 127, 201, 229], "s_j": [82, 122], "wlcs": 82, "k_1": [82, 225], "k_2": [82, 225], "dot": [82, 97, 112, 201, 226, 229], "sqrt": [82, 218, 227], "2001": 82, "2003": [82, 222], "kendal": [82, 137], "s4": 82, "su4": 82, "s9": 82, "su9": 82, "correl": [82, 206, 218, 229], "judgment": [82, 133, 205], "2002": 82, "295": 82, "149": [82, 225], "624": [82, 240], "a1": [82, 211], "a2": [82, 187, 211], "a3": 82, "e1": 82, "01937": 83, "syssum1": 83, "syssum2": 83, "refsum": 83, "727": [83, 241], "571": 83, "wordnet": 83, "pos": [83, 98], "refuniq": 83, "suniq": 83, "topicnn": 83, "jj": 83, "topicuniqnn": 83, "08771": 84, "berlin": 84, "germani": 84, "3243": 84, "bilingu": [84, 86], "trigram": 84, "breviti": 84, "penalti": [84, 133, 170], "p1": [84, 229], "p2": [84, 229], "p3": 84, "p4": 84, "wmt": [84, 130], "suppli": [84, 214], "variat": [84, 134, 222], "uncas": 84, "unk": 84, "737": 84, "004": 84, "none": [84, 119, 195], "evalb": 84, "penn": 84, "treebank": 84, "mose": 84, "multev": 84, "mteval": 84, "v13a": 84, "detok": 84, "2008": 84, "iwslt": 84, "chrf": 84, "pip": [84, 101, 205, 229], "wmt14": 84, "tok": [84, 143], "13a": 84, "apach": [84, 97], "05685": 85, "4701": 85, "pairwis": [85, 127, 130, 226, 237], "swap": [85, 175], "naturalinstruct": [85, 123], "coqa": [85, 130], "openassist": [85, 123], "2114": 85, "ip": [85, 101, 207, 241], "truthfulqa": [85, 130, 203, 240], "dynabench": 85, "honesti": 85, "harmless": [85, 133], "fastchat": [85, 96], "llm_judg": 85, "lmsys": 85, "blog": [85, 98, 105, 115, 133, 137, 142, 165, 177, 218], "pii": [85, 130], "125k": 85, "70k": 85, "skypilot": 85, "spot": [85, 97, 226], "flashattent": [85, 143, 165, 168], "22k": 85, "1810": 86, "04805_bert": 86, "bidirect": [86, 158], "18xx_gpt1": 86, "19xx_gpt2": 86, "unsupervis": 86, "2012": [86, 105], "00413_cpm": 86, "13971_llama": 86, "09288_llama": 86, "2309": [86, 87], "16609_qwen": 86, "19341_skywork": 86, "14196_deepseek": 86, "rise": [86, 208], "06395_minicpm": 86, "unveil": 86, "04434_deepseek": 86, "mixtur": [86, 87, 133, 155, 184, 205, 218, 240, 241], "12793_chatglm": 86, "famili": [86, 137, 140], "10671_qwen2": 86, "2412": [86, 87, 222], "15115_qwen2": 86, "09388_qwen3": 86, "2112": [86, 190], "15093_ctr": 86, "08485_llava": 86, "12966_qwen": 86, "03744_llava2": 86, "07533_vila": 86, "05525_deepseek": 86, "01800_minicpm": 86, "2409": 86, "17146_molmo": 86, "pixmo": [86, 155], "13848_janus": 86, "decoupl": [86, 127], "00774_freez": 86, "latenc": [86, 91, 122, 124, 133, 146, 164, 200, 228], "frozen": [86, 88, 89, 90], "04468_nvila": 86, "13923_qwen2": 86, "2503": [86, 149, 222], "20215_qwen2": 86, "13642_stream": 86, "2005": [86, 158, 209, 221], "08100_conform": 86, "convolut": [86, 105, 112, 143, 194, 196, 199, 201], "2106": [86, 87], "07447_hubert": 86, "02418_yourtt": 86, "tts": [86, 144, 145, 167, 170, 171, 172], "voic": [86, 137, 138, 140, 142, 151, 170, 171, 172], "everyon": [86, 98], "04356_whisper": 86, "2301": 86, "02111_vall": 86, "codec": [86, 143, 144, 167, 170], "03926_vall": 86, "e_x": 86, "foreign": 86, "05370_vall": 86, "pariti": 86, "05407_cosyvoic": 86, "10759_qwen2": 86, "audio": [86, 113, 137, 138, 140, 141, 145, 147, 167, 187, 211], "00037_moshi": 86, "10117_cosyvoice2": 86, "06282_minmo": 86, "02707_voila": 86, "17589_cosyvoice3": 86, "12597_blip": 86, "01390_openflamingo": 86, "15664_auxiliari": 86, "loss": [86, 106, 108, 116, 125, 137, 141, 155, 159, 165, 194, 199, 214, 218, 224, 228, 229, 240], "load": [86, 96, 97, 101, 112, 113, 119, 155, 164, 233], "07490_modem": 86, "08774_gpt": 86, "11805_gemini": 86, "05530_gemini1": 86, "unlock": [86, 113, 224], "02430_seed": 86, "04675_seed": 86, "asr": [86, 134, 135, 136, 137, 139, 141, 142, 144, 145, 149, 151, 167, 170, 171, 172, 211], "20020_gemini2": 86, "xxxxx_seed": 86, "superb": [86, 140], "07062_seed1": 86, "1712": 87, "05889_ray": 87, "1910": 87, "02054_deepspeed_zero": 87, "trillion": [87, 111, 169, 181, 184], "xx_ray": 87, "06180_vllm": 87, "pagedattent": 87, "00190_prefix": 87, "10385_p": 87, "too": [87, 130, 168], "2104": 87, "08691_prompt": 87, "09685_lora": 87, "01335_self": 87, "convert": [87, 152, 165, 176, 227], "09353_dora": 87, "12354_lora": 87, "03507_galor": 87, "gradient": [87, 96, 104, 105, 107, 123, 130, 190, 229], "13372_llamafactori": 87, "1701": 87, "06538_moe": 87, "outrag": 87, "gate": [87, 134], "1806": 87, "03377_pipedream": 87, "fast": [87, 113, 136, 155, 191, 193, 209, 221], "dnn": [87, 138, 231], "1811": [87, 195, 222], "06965_gpipe": 87, "giant": 87, "1909": 87, "08053_megatron": 87, "billion": [87, 90, 105, 145, 170, 178, 203], "19xx_pipedream": 87, "2006": 87, "09503_pipedream": 87, "2bw": 87, "15704_pytorch": 87, "acceler": [87, 105, 119, 120, 164, 226], "16668_gshard": 87, "04473_effici": 87, "megatron": [87, 98, 106, 112, 182, 240], "14135_flashattent": 87, "awar": [87, 97, 125, 140, 145, 155, 160, 176, 181, 229, 242], "08691_flashattent": 87, "faster": [87, 96, 112, 147, 168, 190, 193, 200], "partit": [87, 105, 164, 214], "02861_bitsandbyt": 87, "bit": [87, 115, 117, 118, 120, 121, 124, 125, 164, 233, 240], "2206": 87, "01861_zeroqu": 87, "09557_lut": 87, "gemm": [87, 106, 113, 117, 120, 122, 124], "matrix": [87, 106, 112, 113, 117, 218, 225, 226], "lut": [87, 124], "2208": 87, "07339_llm": 87, "int8": [87, 96, 118, 120, 121, 123, 124, 125], "05433_fp8": 87, "fp8": [87, 119, 123], "17323_gptq": 87, "2211": 87, "10438_smoothquant": 87, "14314_qlora": 87, "00978_awq": 87, "05516_autoround": 87, "sign": [87, 120, 225], "descent": [87, 96], "06674_llama": 87, "guard": 87, "safeguard": 87, "1703": 87, "03864_evolut": 87, "02495_deepseek": 87, "grm": 87, "13958_toolrl": 87, "2203": [87, 190, 222], "02155_train": 87, "20050_let": 87, "03314_scale": 87, "14135_scale": 87, "roadmap": 87, "00190": 88, "bart": 88, "facto": 88, "pretrain": [88, 89, 116, 130, 145, 162, 221, 225, 235], "modifi": [88, 130, 218], "lightweight": [88, 125, 199, 209, 212, 221], "attend": [88, 218, 219], "extrapol": [88, 236], "freez": [88, 91, 96, 167, 218], "consequ": [88, 111], "vertic": [88, 104, 158], "10385": 89, "lama": 89, "unstabl": 89, "trainabl": [89, 91, 96, 190], "stabil": [89, 174], "sizeabl": 89, "margin": [89, 90, 191], "britain": 89, "zone": 89, "contrari": [89, 96], "08691": [90, 113], "unlik": [90, 91, 101, 125, 138, 175, 208, 218, 229], "reus": 90, "burden": 90, "simplif": [90, 211], "deberta": 91, "retrain": [91, 184, 218], "feasibl": 91, "prohibit": 91, "matric": [91, 96, 112, 119], "par": [91, 184], "despit": [91, 130, 161, 192, 207, 228], "fewer": [91, 112, 130, 200], "throughput": [91, 107, 111, 113, 164, 182, 228], "investig": 91, "reparametr": 91, "01335": 92, "12354": 94, "jiaweizzhao": 95, "galor": [95, 96], "03507": 95, "13372": 96, "llamaboard": 96, "vital": 96, "trivial": [96, 205], "cut": 96, "touvron": 96, "litgpt": 96, "2023d": 96, "coloss": 96, "lmflow": 96, "diao": 96, "gpt4all": 96, "anand": 96, "houlsbi": 96, "lower": [96, 112, 122, 137], "dimension": [96, 214, 218, 237], "badam": 96, "bcd": 96, "luo": 96, "hu": [96, 215], "qlora": 96, "dettmer": 96, "dora": 96, "hayou": 96, "pissa": 96, "meng": 96, "princip": [96, 225], "converg": [96, 106, 226], "micikevicius": 96, "dao": [96, 113], "diminish": [96, 107], "2022a": [96, 137], "frantar": 96, "egiazarian": 96, "decreas": [96, 138, 195], "nevertheless": [96, 201], "restrict": 96, "unsloth": 96, "triton": [96, 236], "tillet": 96, "flop": [96, 102, 106, 112, 113, 124, 170, 182, 195, 200, 236, 241], "han": [96, 122, 124], "backward": [96, 104, 105, 106, 107, 108, 125], "propag": [96, 105, 226], "float": [96, 119, 120, 130, 214], "expedit": 96, "wolf": 96, "automodelforvision2seq": 96, "automodelforcausallm": 96, "autotoken": 96, "monkey": 96, "bitsandbyt": [96, 115, 119], "attach": [96, 211], "peft": [96, 123, 168], "mangrulkar": 96, "rslora": 96, "kalajdzievski": 96, "ascend": 96, "npu": [96, 164, 167], "cuda": [96, 102, 112, 117, 119, 122, 123, 228, 240], "float32": [96, 124, 165, 240], "taori": 96, "shuffl": [96, 113, 214], "krell": 96, "trl": 96, "dpo": [96, 127, 133, 144, 151, 164, 169, 170, 187, 188], "kto": 96, "ethayarajh": 96, "orpo": 96, "2n": 96, "ppo": [96, 97, 130, 133, 151, 155, 181], "ouyang": [96, 127, 202], "set_adapt": 96, "disable_adapt": 96, "rasley": 96, "05889": 97, "1619": 97, "impos": 97, "demand": [97, 208, 211], "ray": [97, 223, 226], "fault": [97, 155], "toler": [97, 155], "mapreduc": 97, "spark": [97, 101, 147], "naiad": 97, "storm": 97, "graphx": 97, "pregel": 97, "mxnet": [97, 104], "tpu": [97, 98, 105, 115, 119, 149], "alphago": [97, 133], "dask": [97, 101], "ciel": 97, "clipper": 97, "pseudocod": 97, "stateless": 97, "server": [97, 101, 102, 107, 111], "tradeoff": 97, "failur": [97, 226], "orlean": 97, "akka": [97, 101], "remot": [97, 101, 218], "a1i": 97, "a2i": 97, "mutabl": 97, "worker": [97, 104, 107, 108, 113], "m1": [97, 164], "m2": 97, "m3": [97, 240], "lineag": [97, 101, 181], "satisfi": 97, "driver": [97, 101], "pub": [97, 101], "forward": [97, 104, 105, 106, 107, 108, 125, 227, 229], "thick": 97, "arrow": [97, 107, 112, 130, 158, 226], "solid": [97, 107], "regist": [97, 112, 227, 229, 233], "entri": 97, "allreduc": [97, 105], "placement": [97, 106], "180": [97, 164, 224, 226], "iop": 97, "15gb": [97, 223], "18k": 97, "5mb": [97, 223], "30ms": 97, "flush": [97, 107, 108], "openmpi": 97, "100mb": 97, "200ms": 97, "1gb": [97, 101, 116], "1200ms": 97, "sgd": [97, 104, 105, 230], "horovod": 97, "6200": 97, "4400": 97, "6900": 97, "290": 97, "mpi": [97, 101], "bsp": [97, 104], "bulk": [97, 104], "synchron": [97, 104, 105, 137], "barrier": 97, "redi": [97, 101], "scatter": [97, 98], "gather": [97, 98, 106], "rollout": [97, 133, 155, 189], "32768": [97, 169, 187, 189], "5ms": 97, "dryad": 97, "dag": [97, 220], "erlang": [97, 101], "sdn": 97, "gfs": 97, "omega": [97, 112, 226], "cilk": 97, "steal": 97, "a3c": 97, "dqn": 97, "gc": [97, 101], "determinist": [97, 133], "replay": [97, 133], "stochast": [97, 133, 136], "aws": [97, 101, 104], "timelin": [97, 104, 107, 108], "02054": 98, "extrem": [98, 116, 130, 191, 206, 226], "petaflop": [98, 106, 111], "11b": [98, 240], "mp": [98, 128], "pp": [98, 104, 107, 182], "offload": 98, "momentum": [98, 116], "byte": [98, 124, 187, 233, 240], "24gb": [98, 123, 168, 227], "3gb": 98, "60gb": 98, "redund": [98, 200, 214], "4gb": [98, 116], "120gb": 98, "bucket": 98, "9gb": 98, "128b": 98, "cb": [98, 119], "33gb": 98, "2gb": [98, 116, 229], "apex": 98, "p_o": 98, "n_d": 98, "170b": 98, "torch": [98, 101, 119, 229], "nn": [98, 225, 226, 229], "v100": [98, 104, 116, 138, 139, 140, 141, 194, 195, 196, 223], "dgx": 98, "gbps": [98, 104], "hpc": [98, 101], "proceed": [99, 112, 133], "hash": [99, 112, 236], "bdbca288fee7f92f2bfa9f7012727740": 99, "1tbw9a4j62rui5omijbmxli": 101, "la5w4q_tjyjgjl_jn2fi": 101, "serverless": 101, "modin": 101, "grpc": 101, "kubernet": 101, "slurm": 101, "multiprocess": 101, "celeri": 101, "flink": 101, "mar": 101, "nccl": [101, 107], "raysgd": 101, "gcs": 101, "objectref": 101, "__main__": 101, "raylet": 101, "plasma": 101, "x_ref": 101, "heap": 101, "100kb": 101, "corework": 101, "referenc": 101, "spec": 101, "inlin": 101, "takeaway": 101, "detach": 101, "async": 101, "asyncio": 101, "thread": [101, 104, 113], "homogen": 101, "tombston": 101, "subtre": 101, "no_restart": 101, "ipc": 101, "caller": 101, "directori": 101, "fallback": 101, "versus": [101, 226], "evict": 101, "inelig": 101, "pressur": [101, 120], "pin": 101, "objectstorefullerror": 101, "outofdiskerror": 101, "flowchart": 101, "restor": 101, "storag": [101, 232], "ref": [101, 137, 160, 170, 240], "dealloc": 101, "known": [101, 196, 225], "temp_borrow": 101, "obj_ref": 101, "temporarili": 101, "foo": 101, "perman": 101, "parent": [101, 130, 211], "y_ref": 101, "child": [101, 211], "wrap": 101, "reconstruct": [101, 125, 138, 143, 222], "small_obj_ref": 101, "large_or_pending_obj_ref": 101, "leas": 101, "spillback": 101, "affin": 101, "gang": 101, "special_gpu": 101, "grant": 101, "reschedul": 101, "hybrid": [101, 107, 238], "pack": [101, 124, 164, 166], "rpc": 101, "bundl": [101, 225, 226, 227, 228], "ping": 101, "remove_placement_group": 101, "pg": [101, 236], "killactor": 101, "rayactorerror": 101, "max_restart": 101, "client": [101, 218], "max_task_retri": 101, "dashboard": 101, "poll": 101, "runtimeenv": 101, "auxiliari": [101, 137], "singleton": 101, "live": [101, 130], "pink": [101, 226], "launch": [101, 146], "monitor": [101, 218], "gcp": 101, "k8s": 101, "downscal": 101, "upscal": 101, "speed": [101, 112, 113, 168, 190, 196, 226], "supervisor": 101, "succeed": 101, "runtimeenvag": 101, "pex": 101, "pod": 101, "rayclust": 101, "crd": 101, "stdout": 101, "stderr": 101, "prometheus": 101, "opencensus": 101, "06180": 102, "2085": 102, "2585": 102, "wast": 102, "reserv": [102, 214], "prevent": [102, 112, 177, 218], "slot": [102, 218], "cellular": 102, "opt": [102, 119, 121, 122, 123, 124, 164, 173, 174, 229], "800kb": 102, "h100": [102, 115, 143, 165, 168, 229], "contigu": 102, "pagedstorag": 102, "768mb": 102, "fastapi": 102, "reshap": [102, 195], "fastertransform": [102, 118, 122, 124], "coalesc": 102, "warp": [102, 117], "cudamemcpyasync": 102, "fork": 102, "orca": 102, "pcie": [102, 107, 155], "06538": 103, "jagiellonian": 103, "03377": 104, "pipeline_parallel": [104, 107, 108], "1f1b": [104, 107, 108], "stash": 104, "sync": 104, "stall": [104, 107], "exchang": [104, 225], "minibatch": [104, 107, 130, 230], "asp": [104, 107, 136], "tempor": [104, 107, 169, 201, 238], "overlap": [104, 107, 143, 165, 225, 227, 229, 240], "startup": [104, 107], "steadi": [104, 107, 214], "noam": [104, 107], "stale": 104, "caff": 104, "cntk": 104, "zeromq": 104, "advertis": 104, "config": [104, 164], "partinion": 104, "replic": [104, 106, 107, 116], "130": [104, 141, 144, 145, 155, 182, 226], "msvd": 104, "1970": 104, "titan": [104, 193], "vgg16": 104, "incept": 104, "v3": [104, 127, 142, 143, 144, 145, 151, 152, 170, 172, 189, 226], "s2vt": 104, "rmsprop": 104, "geep": 104, "06965": 105, "amoebanet": 105, "siboehm": 105, "articl": [105, 130, 137, 211, 214, 216], "re": [105, 130, 169], "mater": 105, "remateri": 105, "480": 105, "350": 105, "fk": 105, "th": [105, 127], "bk": 105, "divid": [105, 133, 164, 197, 233], "materi": [105, 112, 223], "bubbl": [105, 107], "224": [105, 160, 162, 164, 225, 227], "82m": 105, "owe": [105, 200], "26gb": [105, 123], "46gb": 105, "318m": 105, "25x": 105, "perfect": [105, 127], "imbalanc": 105, "vocabulari": [105, 170, 184, 226], "298": 105, "08b": [105, 160], "05b": 105, "nmt": 105, "spmd": 105, "simd": [105, 113, 124], "halo": 105, "pipedream": [105, 108], "batchnorm": [105, 112, 134, 224], "08053": 106, "tensor": [106, 111, 113, 114, 115, 116, 117, 118, 119, 122, 229], "1d": [106, 134, 144, 155, 158, 169, 170, 224], "teraflop": 106, "wikitext103": 106, "lambada": [106, 122, 125, 181], "quit": [106, 193], "orthogon": 106, "complimentari": 106, "sustain": [106, 107, 130], "peak": [106, 111, 177], "gpipe": [106, 107, 108], "mesh": [106, 223], "radford": [106, 170, 175, 176], "gelu": [106, 117, 143, 176, 181, 182, 226], "relu": [106, 112, 119, 122], "conjug": 106, "ident": [106, 141, 218, 228], "x_": [106, 117, 122, 166, 225, 226], "x_1": [106, 112], "x_2": 106, "x1a1": 106, "x2a2": 106, "y_1": 106, "y_2": 106, "257": [106, 173], "entropi": [106, 123, 130, 201, 224], "deepakn94": 107, "asset": [107, 218], "sosp19": 107, "1145": [107, 115], "3341301": 107, "3359646": 107, "microbatch": [107, 108], "owt": 107, "flexflow": 107, "frequent": [107, 204], "idl": 107, "asic": 107, "fpga": 107, "10gbps": 107, "100gbps": 107, "15gbps": 107, "nvlink": [107, 182], "30gbps": 107, "runtim": [107, 112, 113, 115, 122, 124, 203], "topolog": 107, "bandwidth": [107, 112, 113, 120], "b1": 107, "b2": 107, "equal": [107, 203], "num_opt_active_minibatch": 107, "lceil": [107, 112], "replica": [107, 227], "rceil": [107, 112, 125], "b_i": 107, "w1": [107, 124], "w2": [107, 124], "wn": 107, "bfs": [107, 132, 219, 239], "distributeddataparallel": 107, "gloo": 107, "09503": 108, "axi": 108, "period": [108, 218], "15704": 109, "16668": 110, "04473": 111, "3072": [111, 139], "502": 111, "led": 111, "imposs": 111, "unrealist": 111, "unfortun": 111, "fundament": [111, 214], "thousand": [111, 137, 230], "spend": [111, 113, 130], "compos": [111, 218], "footprint": [111, 112], "quantit": [111, 169, 211], "trade": [111, 112, 226], "14135": [112, 133], "paper_fil": 112, "67d57c32e20fd0a7a302cb81d36e40d5": 112, "sram": [112, 113, 123], "slow": 112, "hungri": 112, "wall": 112, "speedup": [112, 113, 168, 242], "analyz": [112, 127], "seq": 112, "mlperf": 112, "lift": 112, "classif": [112, 116, 130, 137, 142, 170, 176, 192, 201, 211, 237], "outer": [112, 119], "bottleneck": [112, 113, 124, 199, 228], "softmax": [112, 113, 115, 118, 119, 122, 135, 143, 144, 145, 147, 152, 176, 201, 218, 226, 240], "linform": [112, 236], "0tb": [112, 113], "192kb": [112, 113], "19tb": [112, 113, 118], "elementwis": 112, "reduct": [112, 130, 164], "qk": [112, 113, 189, 241], "pv": [112, 113], "gg": 112, "subquadrat": 112, "max_i": 112, "x_i": [112, 141, 166, 225, 227], "bmatrix": [112, 225, 228], "ldot": [112, 218, 219, 225, 226], "x_b": 112, "ell": [112, 230], "sum_i": [112, 225], "b_c": 112, "4d": 112, "b_r": 112, "mathbf": [112, 119, 123, 125, 140, 141, 201, 218, 219, 224, 227, 229, 230], "t_r": [112, 219], "t_c": 112, "k_j": 112, "v_j": 112, "q_i": [112, 201], "ij": [112, 228], "theorem": 112, "additionalmemori": 112, "theta": [112, 127, 166, 218, 224, 228, 239], "nd": 112, "proposit": [112, 211, 226], "sparsiti": 112, "_m": [112, 201, 218, 228], "lra": 112, "halid": 112, "ffn": [112, 134, 139, 169, 181, 182, 187, 188, 218, 236], "layernorm": [112, 117, 119, 122, 134, 143, 168, 182, 195, 201], "resolut": [113, 155, 161, 164, 228], "exploit": 113, "asymmetr": 113, "multipli": [113, 117], "ineffici": [113, 233], "occup": [113, 223, 225], "tweak": 113, "matmul": [113, 118, 122], "tflop": [113, 124, 164, 240], "fa2": 113, "fa": 113, "65k": 113, "mosaicml": 113, "hbm": 113, "sm": 113, "fraction": [113, 120], "doing": 113, "bf16": [113, 123, 145, 168, 182], "kernel": [113, 122, 123, 124, 143, 228], "simt": 113, "multiprocessor": 113, "dv": 113, "dq": [113, 123], "dk": 113, "64m": 113, "256mb": 113, "tile": [113, 168], "nabla": [113, 229], "tensorrt": 115, "onnx": 115, "ggml": 115, "calibr": [115, 120, 122, 133, 218, 225, 226, 237], "qat": [115, 124, 125], "gtx": 115, "use_fp16": 115, "mantissa": [115, 120], "expon": 115, "754": [115, 120, 214], "intel": [115, 120, 122, 124, 125, 164], "e4m3": [115, 120], "e5m2": [115, 120], "wikibook": [115, 143], "amper": 115, "datacent": 115, "norman": 115, "jouppi": 115, "isca": 115, "3079856": 115, "3080246": 115, "secret": 115, "tpus": 115, "hopper": [115, 122], "gptq": [115, 118, 122, 124, 125], "john": [115, 130, 203], "gustafson": 115, "beat": [115, 190], "1907": 115, "01007": 115, "w4": [115, 117, 118, 124], "channel": [115, 122, 124, 168, 224], "w4g": [115, 125], "w4g128": [115, 125], "w3g128": [115, 125], "w2g128": [115, 125], "signround": [115, 125], "g128": [115, 124], "02861": 116, "washington": [116, 119, 123, 165, 168], "11gb": 116, "41gb": 116, "m_t": 116, "r_t": 116, "8bit": [116, 119, 124, 143], "outlier": [116, 118, 122, 123, 226, 228], "stabl": [116, 161, 184, 218, 229, 240], "median": 116, "moco": 116, "cls": [116, 173, 175], "adafactor": 116, "almost": [116, 225], "slower": [116, 124], "instabl": 116, "gpt3": [116, 125], "epsilon": [116, 182, 229], "stori": [116, 130, 176], "openwebtext": 116, "209m": 116, "440": 116, "dall": [116, 166], "adagrad": 116, "sm3": 116, "hbfp": 116, "01861": 117, "519": 117, "neox": 117, "j6b": 117, "neox20b": 117, "int2": 117, "hessian": [117, 125, 228], "w16a8": 117, "w8a8": [117, 122, 124, 168], "wikitext": [117, 122, 211], "8a16": 117, "wmma": 117, "cutlass": 117, "350m": [117, 167], "wxay": 117, "mhsa": [117, 134, 195, 201], "ffc": 117, "bertlarg": 117, "pile": [117, 120, 125, 236, 240], "classifi": [117, 127, 130, 141, 144, 175, 191, 213, 224, 241], "clamp": 117, "dequant": [117, 118, 119, 123, 124, 125], "int32": [117, 119], "09557": 118, "nuqmm": [118, 119, 121, 122], "pohang": 118, "naver": [118, 225, 226], "aic": 118, "optq": 118, "scheme": [118, 122, 236], "w8": 118, "a8": 118, "a16": 118, "prune": 118, "smoothquant": [118, 123, 125], "w4a16": [118, 124, 168], "awq": [118, 125, 168], "cubla": 118, "4bit": [118, 123, 124, 143, 233], "3bit": [118, 143], "2bit": [118, 125, 143], "6ms": 118, "tb": 118, "atomicadd": 118, "1kb": 118, "07339": 119, "ens": 119, "saclay": 119, "timdettm": 119, "f16": 119, "absolut": [119, 175, 176, 225, 228], "_x": 119, "i32": 119, "constant": [119, 225], "otim": 119, "_w": 119, "accumul": [119, 223], "ndx": 119, "zp": [119, 125], "0normal": 119, "int16": 119, "125m": [119, 123], "96x": 119, "1750": [119, 120, 121, 178], "h_i": [119, 219], "65535": 119, "1234": 119, "zeroqu": [119, 121, 122], "lm_head": 119, "has_fp16_weight": 119, "replace_8bit_linear": 119, "module_to_not_convert": 119, "named_children": 119, "children": 119, "isinst": 119, "init_empty_weight": 119, "_modul": 119, "in_featur": 119, "out_featur": 119, "fp16_model": 119, "state_dict": 119, "pt": [119, 241], "int8_model": 119, "delay": 119, "load_state_dict": 119, "0031": 119, "0438": 119, "0494": 119, "0046": 119, "0410": 119, "0436": 119, "0394": 119, "0787": 119, "0986": 119, "0595": 119, "0162": 119, "0859": 119, "1227": 119, "1209": 119, "1158": 119, "0186": 119, "0530": 119, "0804": 119, "0725": 119, "0638": 119, "0487": 119, "0524": 119, "1076": 119, "0200": 119, "0406": 119, "0663": 119, "0123": 119, "0551": 119, "0121": 119, "0041": 119, "0865": 119, "0013": 119, "0427": 119, "0764": 119, "1189": 119, "dtype": 119, "109": [119, 136, 182], "121": 119, "requires_grad": 119, "scb": 119, "05433": 120, "arm": [120, 124, 133], "cnn": [120, 122, 130, 134, 135, 145, 158, 160, 166, 191, 194, 195, 196, 224], "inf": 120, "binad": 120, "240": 120, "11110": 120, "eeeee": 120, "1111": 120, "eeee": 120, "mmm": 120, "00000": [120, 233], "0000": [120, 233], "875": 120, "wmt16": 120, "gnmt": 120, "mobilenet": 120, "deviat": [120, 127, 211, 226], "sort": 120, "integ": [120, 127, 214, 218], "hyperparamet": 120, "datatyp": 120, "prior": [120, 191, 192, 222, 225], "17323": 121, "ist": 121, "daslab": 121, "ternari": 121, "ptq": [121, 124, 125, 143], "adaround": 121, "bitsplit": 121, "adaqu": 121, "brecq": 121, "obq": 121, "choleski": 121, "rtn": [121, 124, 125], "10438": 122, "530b": 122, "350gb": [122, 124], "x_int8": 122, "x_fp16": 122, "delta": [122, 228], "0118": 122, "ci": 122, "flat": 122, "uniform": [122, 226], "migrat": 122, "pretti": [122, 193], "bondarenko": 122, "winogrand": [122, 130, 182], "x_j": 122, "w_j": 122, "bmms": 122, "bmm": 122, "suppress": [122, 200], "iml": 122, "3tb": 122, "w4a4": 122, "14314": 123, "artidoro": 123, "bitandbyt": 123, "recomput": 123, "quantil": 123, "48gb": 123, "650": 123, "guanaco": 123, "780gb": 123, "bard": [123, 149], "5gb": [123, 164], "oasst1": 123, "spike": 123, "nf": 123, "nfk": 123, "6961928009986877": 123, "5250730514526367": 123, "39491748809814453": 123, "28444138169288635": 123, "18477343022823334": 123, "09105003625154495": 123, "07958029955625534": 123, "16093020141124725": 123, "24611230194568634": 123, "33791524171829224": 123, "44070982933044434": 123, "5626170039176941": 123, "7229568362236023": 123, "blocksiz": 123, "373": 123, "doubledequ": 123, "c1": [123, 140, 214], "c_": [123, 140, 201, 226, 240], "normalfloat4": 123, "float4": 123, "super": 123, "rougel": 123, "21gb": 123, "abbi": 123, "switchback": 123, "ia3": 123, "fisher": [123, 143, 145, 226], "metaicl": 123, "rlaif": 123, "hh": 123, "lamda": 123, "sparrow": 123, "bigbench": 123, "raft": 123, "chip2": 123, "crow": [123, 130], "00978": 124, "boost": [124, 182], "15w": 124, "jetson": [124, 162, 240], "orin": [124, 162, 240], "nano": 124, "flexgen": 124, "cpp": [124, 164], "exllama": 124, "int3": 124, "mlc": 124, "tvm": 124, "mb": 124, "protect": 124, "rtx": [124, 168, 201], "4090": [124, 164, 168, 201], "amount": [124, 199], "10ms": [124, 134, 142, 170], "310ms": 124, "165": 124, "1tb": 124, "traffic": 124, "4tflop": 124, "16bit": 124, "neon": 124, "reorder": 124, "unpack": 124, "bitwis": 124, "dram": 124, "fma": 124, "qkv": [124, 181, 187, 188, 189, 218], "avx": 124, "w0": 124, "w31": 124, "w16": 124, "w17": 124, "w15": 124, "05516": 125, "autoround": 125, "signsgd": 125, "quant": 125, "aqlm": 125, "zeroquantv2": 125, "rptq": 125, "spiq": 125, "lrq": 125, "teq": 125, "omniqu": 125, "hqq": 125, "squeezellm": 125, "easyqu": 125, "nupe": 125, "flexround": 125, "oscil": 125, "aquant": 125, "widetild": [125, 218, 225], "lfloor": 125, "y_f": 125, "y_q": 125, "min_": [125, 225, 228, 230], "_f": 125, "wikitext2": 125, "ptb": 125, "10k": [125, 134, 140, 214, 218], "03864": 126, "02495": 127, "pointwis": 127, "semi": [127, 211], "y_i": [127, 239], "p_j": 127, "p_i": [127, 130, 229, 236], "finer": 127, "rft": 127, "hint": 127, "grpo": [127, 188, 189], "kl": [127, 130, 133, 147, 155, 189], "sum_j": 127, "320": [127, 135, 138, 139, 155, 167], "k_": [127, 228], "italic": 127, "metarm": 127, "ppe": [127, 188], "rmb": [127, 188], "realmistak": 127, "roc": [127, 174], "auc": [127, 174, 217, 225, 226, 228, 229], "tie": [127, 237], "argmax_i": 127, "btrm": 127, "gemma2": [127, 188], "pairrm": 127, "236b": 127, "671b": 127, "nemotron": [127, 188], "guidanc": [127, 141, 144, 241], "inflex": 127, "stiennon": [127, 130], "bradley": [127, 133, 165], "terri": [127, 133, 165], "gao": [127, 133, 206], "prm": [127, 131, 132, 133], "criteria": [127, 208, 214], "littl": [127, 193], "strict": [127, 206], "compli": 127, "omiss": 127, "useless": 127, "ampl": 127, "slight": [127, 206, 224, 229], "thorough": [127, 200, 214], "lot": [127, 178], "stray": 127, "separ": [127, 134, 143, 175, 191, 218, 227, 233, 240], "comma": 127, "respones": 127, "fluent": [127, 204], "minor": [127, 224], "disjoint": 127, "illog": 127, "punctuat": [127, 144], "serious": [127, 130], "credibl": [127, 211], "judgement": [127, 206, 214], "weixin": 128, "qq": 128, "r__g2": 128, "1yo8ydbtltm8psiq": 128, "06674": 129, "02155": 130, "12774": 130, "bigger": [130, 193], "untruth": 130, "simpli": [130, 175, 226], "avenu": [130, 211], "100x": 130, "moreov": [130, 160, 196, 200, 224], "regress": [130, 133, 138, 159, 162, 191, 226], "proxim": [130, 133], "atari": 130, "christiano": 130, "ziegler": 130, "nahian": 130, "gabriel": 130, "kenton": 130, "askel": [130, 184], "mishra": 130, "bahdanau": 130, "bommasani": 130, "dhamala": 130, "carlini": 130, "solaiman": 130, "gehman": 130, "nadeem": 130, "welbl": 130, "dennison": 130, "ngo": 130, "sheng": 130, "vig": 130, "dathathri": 130, "schick": 130, "33k": 130, "31k": 130, "scaleai": 130, "decay": [130, 184, 225, 229, 240], "ptx": 130, "held": 130, "t0": [130, 233], "playground": 130, "regain": 130, "enthusiasm": 130, "career": 130, "know": [130, 214, 218, 224], "greec": 130, "compactor": 130, "sarcast": 130, "tweet": 130, "tweet_content1": 130, "sentiment1": 130, "tweet_content2": 130, "sentiment2": 130, "professor": 130, "cours": 130, "lectur": 130, "calculus": 130, "smith": 130, "hall": 130, "paz": 130, "ad": [130, 137], "bear": 130, "seal": 130, "email": 130, "repli": 130, "job": 130, "rap": 130, "lyric": 130, "mention": [130, 164, 214], "broadway": 130, "br": 130, "commerci": [130, 204, 205, 206], "spanish": 130, "lt": 130, "west": 130, "road1": 130, "unto": 130, "hit": [130, 206, 238, 239], "road2": 130, "road3": 130, "desin": 130, "barn": 130, "heart": 130, "clever": 130, "hello": [130, 146, 241], "subscript": 130, "marv": 130, "reluct": 130, "pound": 130, "kilogram": 130, "again": 130, "busi": [130, 218, 238], "hypertext": 130, "markup": 130, "airplan": 130, "enlighten": [130, 218], "buddha": 130, "wisdom": 130, "peac": 130, "equanim": 130, "moral": 130, "circl": [130, 214, 224], "ellips": [130, 226], "tell": [130, 206, 218], "hydrogen": 130, "helium": 130, "life": [130, 218], "expect": [130, 214], "presid": 130, "statu": 130, "liberti": 130, "indigin": 130, "zealand": 130, "student": 130, "tl": 130, "dr": 130, "transcript": [130, 146, 165, 214], "complaint": 130, "johnathan": 130, "silver": 130, "indi": 130, "guy": 130, "south": 130, "america": 130, "shaman": 130, "documentari": 130, "juggl": 130, "babi": 130, "boy": 130, "alfr": 130, "theo": 130, "interior": 130, "fake": 130, "plant": 130, "rare": 130, "gem": [130, 225, 226], "neutral": 130, "compani": [130, 214, 218], "fedex": 130, "media": [130, 214, 218], "casey": 130, "startl": 130, "hadn": 130, "begun": 130, "war": 130, "essay": [130, 178], "von": 130, "neumann": 130, "earli": [130, 211, 240], "covert": 130, "resum": 130, "she": [130, 206], "american": 130, "didn": 130, "bad": 130, "watch": 130, "netflix": 130, "hasn": 130, "week": 130, "hey": 130, "man": [130, 175], "yesterday": 130, "going": 130, "thursday": 130, "come": [130, 206, 218, 230], "ummmm": 130, "heavi": 130, "stone": 130, "stay": [130, 218], "yoga": 130, "batman": 130, "comic": 130, "torsalplex": 130, "devz9": 130, "luca": 130, "director": 130, "famous": [130, 218], "leonardo": 130, "vinci": 130, "grader": 130, "passag": [130, 206], "him": 130, "said": [130, 194], "quot": [130, 190, 208], "duti": 130, "unembed": 130, "65e": 130, "03e": 130, "boolq": [130, 181, 182], "multin": [130, 175, 176], "openbookqa": [130, 170], "quac": 130, "9e": 130, "5e": [130, 135, 139, 173, 175, 195], "04e": 130, "45e": 130, "02": [130, 151, 233, 238], "ema": [130, 141, 143], "992": 130, "squadv2": 130, "9600": 130, "4e": 130, "896k": 130, "unbias": [130, 206], "offens": 130, "winogend": [130, 149], "realtoxicityprompt": 130, "rte": 130, "wsc": 130, "fr": [130, 170], "daili": 130, "mail": 130, "tldr": 130, "20050": 131, "prm800k": 131, "orm": [131, 132, 133], "03314": 132, "budget": [132, 189], "lookahead": [132, 143], "vers": 132, "wherea": [132, 142, 218, 226], "accross": 132, "zhuanlan": 132, "zhihu": 132, "773907223": 132, "inferec": 132, "overoptim": 133, "mlr": 133, "v202": 133, "gao23h": 133, "2204": 133, "05862": 133, "einviron": 133, "trigger": [133, 212], "penultim": 133, "quan": 133, "nguyen": 133, "bandit": 133, "bon": 133, "uncertainti": [133, 229], "dg": 133, "ood": [133, 155, 218], "granular": [133, 211], "finest": 133, "coarsest": 133, "bond": 133, "vbon": 133, "treebon": 133, "mctsr": 133, "coverag": [133, 188, 226], "snell": 133, "lightman": 133, "plateau": 133, "stroebl": 133, "overthink": 133, "zeng": 133, "d_search": 133, "d_expert": 133, "d_": [133, 144, 145, 195, 226, 227], "_search": 133, "narrow": 133, "leik": 133, "08100": 134, "4060": 134, "depthwis": [134, 143], "wer": [134, 135, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 149, 151, 152, 170, 172], "contextnet": 134, "glu": [134, 143], "swish": 134, "10m": [134, 225], "30m": 134, "118m": 134, "139m": 134, "subsampl": [134, 226], "norm": [134, 138, 181, 189, 225, 226, 241], "conv": 134, "970": 134, "filterbank": 134, "25ms": [134, 142, 170], "specaug": 134, "7m": [134, 160], "118": 134, "8m": [134, 160], "nois": [134, 211], "1e": [134, 141, 144, 155, 161, 166, 173, 225, 239], "warm": [134, 139, 195], "lingvo": 134, "07447": 135, "3789": 135, "hubert": [135, 137, 138, 143, 146, 147], "mfcc": 135, "wav2vec": [135, 137, 138], "librispeech": [135, 137, 139, 141, 142, 143, 144, 146, 151, 152, 170, 171, 172], "960": [135, 138, 151], "libri": [135, 137], "wavlm": [135, 138, 140, 143, 147, 151], "frame": [135, 143, 155, 191, 225, 226, 227, 229], "y3": 135, "y4": 135, "pseudo": 135, "deepclust": 135, "960h": [135, 137], "60k": [135, 138, 166], "spanbert": [135, 211], "pq": [135, 226], "95m": 135, "317m": 135, "964m": 135, "16khz": [135, 136, 137, 140, 142, 143, 149, 170], "20ms": [135, 143], "ctc": [135, 139, 167, 171, 172, 190, 195], "discretebert": 135, "vq": [135, 138, 141, 143, 144, 147, 166], "gumbel": [135, 144, 147], "librivox": 135, "minibatchkmean": 135, "250k": [135, 173], "400k": 135, "wav2lett": 135, "fairseq": 135, "ax": 135, "puriti": 135, "pnmi": 135, "ipl": 135, "it2": 135, "it1": 135, "02418": 136, "sopra": 136, "coqui": 136, "pat": 136, "bat": 136, "phonet": [136, 143], "alphabet": 136, "ipa": [136, 139], "stft": [136, 143], "mfccs": 136, "cft": 136, "dft": 136, "fft": 136, "deepvoice3": 136, "tacotron": [136, 139], "attentron": 136, "zsm": 136, "glowtt": 136, "edresson": 136, "e2e": [136, 146, 152], "hifi": [136, 139], "gan": [136, 139], "posterior": 136, "global": [136, 161, 195, 201, 209, 220, 221, 228, 229], "mas": 136, "monoton": 136, "voxceleb2": 136, "eer": 136, "967": 136, "244": [136, 158], "1151": 136, "ljspeech": 136, "mos": [136, 139, 144], "autovc": 136, "noisevc": 136, "04356": 137, "whisper": [137, 141, 142, 143, 144, 145, 146, 147, 149, 151, 152, 170, 171, 172], "5280": 137, "spoken": 137, "mel": [137, 138, 139, 141, 142, 143, 144, 145, 152, 170], "transcrib": 137, "mls": [137, 152], "voxpopuli": [137, 149, 170], "covost2": [137, 142, 145, 149, 170], "seq2seq": 137, "corpus": [137, 160, 169, 176, 178, 206, 218], "ted": 137, "lium": 137, "arti": 137, "callhom": [137, 152], "switchboard": [137, 152], "corpora": [137, 176, 206, 212], "ldc2002s09": 137, "ldc2002t43": 137, "wsj": 137, "ldc93s6b": 137, "ldc94s13b": 137, "s5": 137, "preprocess": 137, "coraal": 137, "231": 137, "interview": 137, "fairspeech": 137, "chime": 137, "s5_track1": 137, "binaur": 137, "_p": 137, "wav": [137, 170], "ami": [137, 152], "ihm": [137, 152], "sdm1": 137, "s5b": 137, "hernandez": 137, "etal": 137, "talk": 137, "slice": [137, 164], "meanwhil": [137, 199, 200], "stephen": 137, "colbert": 137, "timestamp": [137, 143], "inspect": [137, 200], "rev16": 137, "podcast": [137, 214], "rev": 137, "portion": 137, "sponsor": 137, "kincaid46": 137, "jason": 137, "kincaid": 137, "airtabl": 137, "earn": 137, "delrio": 137, "202206": 137, "farrington": 137, "pratap": 137, "fleur": [137, 142, 145, 149, 152, 170], "conneau": 137, "utter": 137, "ids": [137, 169, 214], "get_asr_data": 137, "ardila": 137, "covost": 137, "wav2vec2": 137, "lv60": 137, "ft": 137, "hsu": 137, "2021b": 137, "ebook": 137, "100h": 137, "baevski": 137, "ls960": 137, "2021a": 137, "xlarg": 137, "s2t": [137, 145], "2020a": 137, "unispeech": 137, "stt_en_conformer_ctc_larg": 137, "kuchaiev": 137, "stt_en_conformer_transducer_xlarg": 137, "speechbrain": 137, "crdnn": 137, "rnnlm": 137, "ravanelli": 137, "transformerlm": 137, "hmm": [137, 138], "uh": 137, "02111": 138, "unilm": [138, 139], "806": 138, "shelf": [138, 228], "phonem": [138, 139], "spectrogram": [138, 139], "waveform": [138, 139], "acoust": [138, 139, 140, 151], "7000": [138, 140], "librilight": [138, 139, 140], "vocod": [138, 141, 143, 144, 145, 151], "gslm": [138, 143, 146], "audiolm": [138, 139, 143, 146], "soundstream": [138, 140, 143, 147], "revisit": 138, "rvq": [138, 146], "65536": [138, 182], "24khz": [138, 140, 143, 144], "75hz": 138, "750": [138, 164], "nar": [138, 140, 151, 167], "seven": 138, "kaldi": [138, 139], "spk": [138, 144], "tdnn": [138, 140], "cmos": [138, 139, 140, 151], "smos": [138, 139, 140], "yourtt": [138, 139], "03926": 139, "aka": 139, "vallex": 139, "decompress": 139, "thank": [139, 162], "g2p": [139, 144], "wavenet": 139, "diffwav": 139, "sound": [139, 142, 170, 206], "audiogen": 139, "translatotron": 139, "encodec": [139, 140, 143], "speechut": 139, "asv": 139, "nisqa": 139, "wenetspeech": [139, 152, 170, 171, 172], "7300": 139, "st": [139, 145, 195], "gigast": 139, "emim": 139, "tran": 139, "_enc1": 139, "_enc2": 139, "_dec": 139, "side": [139, 201, 206, 223, 225], "05370": 140, "repetit": [140, 143, 170], "libriheavi": 140, "spear": [140, 214], "mega": 140, "ella": 140, "rall": [140, 211], "uniaudio": 140, "soundstorm": 140, "naturalspeech": [140, 143], "voicebox": 140, "polyvoic": 140, "speechx": 140, "viola": 140, "audiopalm": [140, 143], "voco": 140, "funcodec": 140, "c0": [140, 214], "eos": [140, 146, 171], "bos": [140, 240], "geq": [140, 143, 240], "nll": 140, "6kbit": 140, "conform": [140, 141, 152], "transduc": 140, "dnsmos": [140, 147], "48khz": 140, "108": [140, 225, 240], "05407": 141, "funaudiollm": [141, 144, 145, 147], "fun": 141, "schemat": [141, 219], "enlarg": 141, "tild": [141, 144, 201, 218, 228, 230, 231], "timestep": [141, 143, 144], "probabilist": [141, 144], "densiti": [141, 144, 223, 226], "hifigan": 141, "h_l": 141, "textencod": 141, "teacher": [141, 143, 145], "forc": [141, 143, 145, 214, 228, 241], "ot": 141, "cfm": [141, 144, 147], "dpm": [141, 191], "nu_t": 141, "p_0": 141, "mu_l": 141, "paralinguist": 141, "libritt": 141, "585": 141, "2456": 141, "171": 141, "yue": [141, 170], "jp": 141, "ko": [141, 144], "espnet": 141, "codebook": [141, 143, 144, 166, 167], "4000": [141, 145], "sensevoic": [141, 144, 145, 147], "tini": [141, 195, 201, 240], "32g": 141, "10759": 142, "lalm": [142, 170], "stride": [142, 143, 195], "40ms": [142, 170], "s2tt": [142, 145, 170], "ser": [142, 145, 147, 151, 170], "vsc": [142, 170], "emot": [142, 145, 147, 170, 206], "vocal": [142, 146, 170], "00037": 143, "kyutai": 143, "157": 143, "alexa": [143, 146], "mimi": 143, "copet": 143, "voxtlm": [143, 146], "spirit": [143, 146], "spectron": [143, 146], "speechgpt": [143, 146, 171, 172], "pslm": [143, 145], "dgslm": 143, "bespok": 143, "duplex": 143, "rmsnorm": [143, 169, 181, 182, 187, 188, 189, 241], "silu": 143, "stackexchang": 143, "commoncrawl": 143, "fnv": 143, "1a": [143, 144], "vae": [143, 241], "speechtoken": 143, "autoencod": 143, "seanet": 143, "transpos": 143, "na": [143, 214], "model_dim": 143, "layerscal": [143, 229], "80ms": 143, "weight_decay": 143, "8e": 143, "4m": [143, 155], "5hz": 143, "1kbps": 143, "discrimin": [143, 176], "tagliasacchi": 143, "50hz": [143, 144], "flatten": 143, "sake": 143, "temp": 143, "v_s": 143, "v_": [143, 239], "z_s": 143, "v_0": 143, "l_": [143, 144, 170, 240], "n_k": 143, "n_1": 143, "mid": [143, 218, 219, 226, 229, 239], "epad": 143, "2q": 143, "lll": 143, "prime": [143, 226], "wikisourc": 143, "wikinew": 143, "pes2o": 143, "herm": 143, "diariz": 143, "olmo": [143, 165], "abx": 143, "beg": 143, "visqol": 143, "mushra": 143, "rvqgan": 143, "semanticodec": 143, "litellama": 143, "640ms": 143, "240ms": 143, "160ms": 143, "textless": 143, "swuggi": 143, "oxid": 143, "accid": [143, 218], "sblimp": 143, "storycloz": 143, "twist": [143, 171, 172], "stopic": 143, "ipu": 143, "paus": 143, "vall": [143, 167], "fastconform": 143, "noisi": 143, "gibberish": 143, "alert": [143, 218], "382": 143, "audios": 143, "radioact": 143, "10117": 144, "cosyvoice2": [144, 145], "fsq": [144, 147], "1c": 144, "encoder1": 144, "25hz": [144, 172], "text1": 144, "speech1": 144, "speech2": 144, "prompt_text": 144, "prompt_speech": 144, "first_n_text": 144, "ode": 144, "unet": 144, "cfg": [144, 166], "uncondit": 144, "nfe": 144, "fm": 144, "voc": [144, 192], "laughter": 144, "endofprompt": 144, "msft": 144, "unknown": [144, 225], "884": 144, "918": 144, "paraform": [144, 145, 151, 152], "eres2net": [144, 147], "ja": 144, "commonvoic": [144, 147, 170], "sne": [144, 151], "sid": 144, "cer": [144, 145, 147, 167], "nmos": [144, 170], "chattt": 144, "openvoic": 144, "l_asr": 144, "l_dpo": 144, "06282": 145, "tongyi": [145, 147], "600ms": 145, "800ms": 145, "tier": 145, "vita": [145, 167, 171, 172], "synclm": 145, "intrinsicvoic": 145, "omni2": 145, "paralingpt": 145, "projector": [145, 162, 219], "cosyvoic": [145, 171, 172], "token2wav": 145, "wave": 145, "syn": [145, 201], "lid": [145, 147], "aed": [145, 147], "alimeet": 145, "mandarin": [145, 152], "boldfac": [145, 147], "seaco": 145, "unweight": 145, "ua": 145, "wa": 145, "macro": 145, "salmonn": 145, "swab": 145, "s2s": 145, "trivia": [145, 167], "chitchat": 145, "250ms": 145, "150ms": 145, "70ms": 145, "130ms": 145, "l20": 145, "aec": 145, "vad": [145, 152, 167], "faith": 145, "02707": 146, "maitrix": 146, "2010s": 146, "nuanc": [146, 211], "proactiv": 146, "whipser": 146, "moshi": [146, 167, 171, 172], "hertz": 146, "tiao": 146, "aiao": 146, "usdm": 146, "wespeak": 146, "nq": [146, 211], "1580": 146, "17589": 147, "cosyvoice3": 147, "diffro": 147, "minmo": [147, 170], "mossformer2": 147, "300ms": 147, "50ms": 147, "dit": [147, 151, 170], "outsid": 147, "f5": 147, "sovit": [147, 164], "emo": 147, "fluer": 147, "w2v": 147, "repmono": 147, "mixphn": 147, "repal": 147, "catphn": 147, "corret": 147, "procunci": 147, "expresso": 147, "08774": 148, "20020": 149, "studio": 149, "vertex": 149, "25b": 149, "tpuv4": 149, "tpuv5": 149, "superpod": 149, "jax": 149, "xla": 149, "goodput": 149, "sdc": 149, "natural2cod": 149, "tamazight": 149, "kanur": 149, "mgsm": 149, "xlsum": 149, "wikilingua": 149, "mathvista": [149, 155, 165, 170, 241], "mmmu": [149, 155, 165, 166, 170, 241], "xm": 149, "3600": 149, "nextqa": 149, "activitynet": 149, "usm": [149, 152], "rm": [149, 155, 181, 188, 219], "gmail": 149, "bbq": [149, 165], "cbrn": 149, "1400": [149, 236], "05530": 150, "02430": 151, "bytedancespeech": 151, "seedtts_tech_report": 151, "timbr": [151, 170], "jiang": 151, "le": [151, 234], "dev_clean": 151, "test_clean": 151, "dev_oth": 151, "test_oth": 151, "voxceleb1": 151, "tts_sft": 151, "tts_icl": 151, "028": 151, "rtf": 151, "132": 151, "vc": 151, "diffvc": 151, "hierspeech": 151, "hack": 151, "tts_dit": 151, "04675": 152, "acllm": 152, "2010": [152, 214], "luis": 152, "mwer": 152, "wwer": 152, "75m": 152, "770": 152, "7a": 152, "7c": 152, "aishel": [152, 171, 172], "fst": 152, "hardcas": 152, "tedlium": 152, "1240": 152, "11805": 153, "07062": 155, "genom": [155, 160, 161, 173], "cua": 155, "5320": 155, "mim": 155, "eva02": 155, "siglip": [155, 164, 165, 166, 168, 171, 172], "superclass": 155, "mico": 155, "fps": [155, 169, 192, 194, 196, 201, 227, 228], "640": 155, "384": [155, 166, 172, 195, 225, 226], "synthdog": [155, 160], "echart": 155, "objects365": 155, "openimag": 155, "refcoco": [155, 160, 161, 165, 166, 170, 197], "molmo": 155, "countgd": 155, "depthanyth": [155, 229], "1800": 155, "280": [155, 203], "450": 155, "k12": 155, "3t": [155, 182], "71m": 155, "240b": 155, "072": [155, 187, 188], "hat": [155, 217, 223, 226, 229, 239], "1817": 155, "7011": 155, "0785": 155, "0745": 155, "0968": 155, "7139": 155, "infovqa": [155, 169], "1488": 155, "5319": 155, "longcot": 155, "sympi": 155, "16384": [155, 182], "workload": 155, "megascal": 155, "bytecheckpoint": 155, "rlvf": 155, "verl": 155, "objectnet": 155, "532m": 155, "internvl": [155, 164], "eva": [155, 166], "18b": 155, "blind": 155, "visulog": 155, "realworldqa": [155, 164, 165, 170], "mmstar": [155, 169, 170], "blink": 155, "lvis": [155, 197], "mg": 155, "countbench": [155, 169], "nyu": [155, 224], "motionbench": 155, "tvbench": 155, "tempcompass": 155, "ovbench": 155, "ovobench": 155, "streambench": 155, "streamingbench": 155, "mmvu": 155, "charad": [155, 169], "sta": [155, 169], "webvoyag": 155, "hex": [155, 233], "frvr": 155, "870": 155, "611": 155, "maverick": 155, "rebus": 155, "mermaid": [155, 165], "klotski": 155, "contributor": 155, "dong": 155, "fame": 155, "136": 155, "alli": 155, "bingyi": 155, "kang": 155, "borui": 155, "wan": 155, "pot": 155, "london": [155, 228], "beij": [155, 217, 218, 240], "chewi": 155, "325": 155, "25025": 155, "stepfun": 155, "0513": 155, "tool_cal": 155, "tool_respons": 155, "15664": 156, "07490v1": 157, "15093": 158, "fudanvi": 158, "ctr": 158, "quadrangl": 158, "circumscrib": 158, "horizont": [158, 201], "distanc": [158, 214, 226, 228], "iiit5k": [158, 195, 201], "ic03": 158, "ic13": [158, 195, 201], "gb18030": 158, "755": 158, "unicod": 158, "514": 158, "526": 158, "636": 158, "455": 158, "rctw": 158, "263": 158, "rect": 158, "107": 158, "657": 158, "lsvt": 158, "243": 158, "063": 158, "951": 158, "ctw": 158, "364": 158, "mtwi": 158, "589": 158, "471": 158, "render": [158, 200, 225], "wiki": [158, 172], "scut": 158, "hccdoc": 158, "254": 158, "389": 158, "603": [158, 176], "651": 158, "bg": 158, "occlus": 158, "obliqu": 158, "curv": [158, 201, 211], "scribbl": 158, "blur": 158, "crnn": 158, "aster": 158, "stn": 158, "moran": 158, "asrn": 158, "sar": 158, "abinet": 158, "transocr": 158, "ned": 158, "decim": [158, 233], "08485": [159, 198], "wisconsin": [159, 161], "madison": [159, 161], "redmond": [159, 161], "haotian": [159, 161, 198], "instructpix2pix": 159, "595k": 159, "158k": 159, "nat": 159, "soc": 159, "lan": 159, "g1": [159, 233], "g7": [159, 195, 233], "12966": 160, "iv": [160, 226], "endow": 160, "meticul": [160, 211], "receptor": 160, "vls": 160, "tupl": 160, "openclip": 160, "bigg": 160, "280m": 160, "600m": 160, "datacomp": 160, "coyo": [160, 162], "700m": 160, "200m": [160, 164], "cc12m": [160, 173], "6m": [160, 225], "108m": 160, "105m": 160, "hous": [160, 187, 189], "vgqa": 160, "dvqa": 160, "ai2d": [160, 165, 170], "grounding2": 160, "5m": [160, 225, 226, 228], "grit": 160, "refcocog": [160, 170], "rpn": 160, "accommod": [160, 211], "pictur": 160, "chatml": [160, 169, 170, 181], "im_start": [160, 170, 181], "im_end": [160, 170, 181], "03744": 161, "connector": [161, 165], "qformer": 161, "okvqa": [161, 162], "ocrvqa": 161, "interpol": 161, "downsampl": 161, "pope": [161, 166], "tricki": 161, "448x448": 161, "224x224": 161, "672x448": 161, "07533": 162, "nvlab": [162, 168], "vila": [162, 168], "mmc4": 162, "flickr": [162, 174], "25m": [162, 226], "zoom": 162, "05525": 163, "01800": 164, "chinchilla": [164, 184], "kosmo": [164, 174], "shikra": 164, "phi": [164, 218, 240], "mobilellm": 164, "mobilevlm": 164, "400m": [164, 171, 241], "resampl": [164, 174], "1344": 164, "bolster": 164, "cauldron": 164, "conquer": 164, "omnilmm": 164, "ideal": 164, "xiaomi": 164, "snapdragon": 164, "influenc": 164, "comp": [164, 227], "16gb": [164, 187, 214], "gen3": 164, "xeon": 164, "platinum": 164, "8580": 164, "adreno": 164, "17gb": 164, "2s": [164, 228, 229], "5s": 164, "0s": 164, "7s": [164, 229], "3s": 164, "vivo": 164, "mac": 164, "rw": 164, "obj": 164, "halbench": 164, "res": [164, 165], "men": 164, "17146": 165, "allenai": 165, "allen": 165, "712k": 165, "162k": 165, "73k": 165, "230": 165, "metaclip": 165, "196": 165, "askmodelanyth": 165, "223k": 165, "capqa": 165, "countbenchqa": 165, "subdivid": 165, "vqa2": 165, "internvl2": [165, 169, 241], "infoqa": 165, "sharegpt4v": 165, "ama": 165, "border": 165, "arrang": [165, 211], "144": [165, 188], "fsdp": [165, 174], "sdpa": 165, "long_capt": 165, "long_caption_83": 165, "xxx": [165, 218], "3h": 165, "264": 165, "850": [165, 225], "6h": 165, "2h": 165, "9h": 165, "570": [165, 170], "5h": 165, "7k": 165, "4h": 165, "2730": 165, "dinov2": [165, 229], "grefcoco": 165, "vega": 165, "graphviz": 165, "character": 165, "gres": 165, "13848": 166, "152": 166, "1deepseek": 166, "2the": 166, "3peke": 166, "chameleon": 166, "emu": 166, "univit": 166, "internvideo": 166, "mscoco": 166, "fid": 166, "sdxl": 166, "und": 166, "flame": 166, "snowflak": 166, "internvit": 166, "movqgan": 166, "eeg": 166, "patch16": 166, "hai": 166, "7777": 166, "sharegpt4444v": 166, "111k": 166, "120k": [166, 218], "mmb": [166, 172], "mjhq": 166, "llamagen": 166, "sdv2": 166, "meme": 166, "rgb": [166, 201, 211, 222, 223, 226, 238], "00774": 167, "aslp": 167, "ticodec": 167, "120m": 167, "04468": 168, "1nvidia": 168, "2mit": 168, "3uc": [168, 223], "4uc": 168, "5univers": 168, "6tsinghua": 168, "hanlab": 168, "nvila": 168, "onevis": 168, "ov": [168, 172, 241], "disclos": 168, "geforc": 168, "64gb": 168, "deltaloss": 168, "b200": 168, "liger": 168, "lita": 168, "medic": 168, "xai": 168, "13923": 169, "upgrad": 169, "curat": [169, 237], "ultra": 169, "swiglu": [169, 181, 182, 187, 188, 189, 241], "comprehend": 169, "pace": 169, "14x14": 169, "merger": 169, "rotari": [169, 170, 236, 240], "volum": [169, 206], "instag": 169, "mmvet": [169, 170], "ocrbench": 169, "spatial": [169, 191, 199, 223], "odinw": [169, 170, 197], "lvbench": 169, "20215": 170, "tmrope": 170, "adpot": 170, "xie": 170, "151": [170, 187, 188, 189], "chu": 170, "675": 170, "prefil": 170, "lipman": 170, "bigvgan": 170, "vision_start": 170, "mp4": 170, "vision_end": 170, "rafailov": [170, 184], "e_": [170, 227], "yw": 170, "yl": 170, "log_": 170, "y_w": 170, "y_l": 170, "redux": [170, 189], "livebench0803": 170, "gpqa": [170, 187, 189], "mmau": 170, "voicebench": 170, "mathvis": 170, "muirbench": 170, "ocrbench_v2": 170, "fu": 170, "mvbench": 170, "egoschema": 170, "mangalam": 170, "omnibench": 170, "meld": 170, "vocalsound": 170, "music": [170, 218, 238], "giantstep": 170, "tempo": 170, "musiccap": 170, "alpacaev": [170, 237], "commonev": 170, "mmsu": 170, "advbench": 170, "testmini": 170, "crpe": 170, "realworld": 170, "texta": 170, "textb": 170, "pointground": 170, "anastassiou": 170, "13642": 171, "ictnlp": 171, "blank": [171, 172, 195, 218], "attn": 171, "h800": [171, 172], "speechqa": 171, "ultrachat": [171, 172, 240], "574": [171, 172], "slam": [172, 222, 224, 226], "minicpm2": 172, "anygpt": 172, "emova": 172, "openomni": 172, "so400m": 172, "patch14": 172, "1752": 172, "1687": 172, "vllms": 172, "spokenqa": 172, "fang": 172, "empathi": 172, "12597": 173, "vlp": 173, "flamingo80b": 173, "lit": 173, "188m": 173, "itc": 173, "itg": 173, "itm": 173, "flant5": 173, "129m": 173, "capfilt": 173, "80k": [173, 225, 226], "spice": 173, "01390": 174, "mlfoundat": 174, "open_flamingo": 174, "ai2": 174, "m3w": 174, "obelisc": 174, "lauren": 174, "endofchunk": 174, "webdataset": 174, "ddp": 174, "hatefulmem": 174, "redpajama": [174, 236], "paperswithcod": 174, "04805": 175, "unlabel": [175, 176], "eleven": 175, "push": 175, "heavili": [175, 212], "scratch": [175, 196, 199], "nsp": 175, "bookscorpus": [175, 176], "800m": 175, "500m": 175, "straightforward": [175, 225], "elmo": 175, "dog": 175, "hairi": 175, "actual": [175, 213, 226], "went": 175, "bought": 175, "gallon": 175, "milk": 175, "isnext": 175, "penguin": 175, "bird": [175, 218], "notnext": 175, "wordpiec": 175, "cdn": 176, "language_understanding_pap": 176, "alec": 176, "tim": 176, "saliman": 176, "ilya": 176, "sutskev": 176, "cloze": [176, 178], "entail": 176, "scarc": 176, "adequ": [176, 213], "gain": [176, 199], "ftfi": 176, "spaci": 176, "186": 176, "1265": 176, "707": 176, "663": 176, "184": [176, 224], "gpt2": 177, "jalammar": 177, "00413": 178, "tsinghuaai": 178, "cpm": 178, "baai": 178, "plm": [178, 219, 239], "570gb": 178, "100gb": 178, "plms": 178, "proven": 178, "benefici": [178, 232], "drew": 178, "warn": 178, "13971": 179, "09288": 180, "16609": 181, "pmp": 181, "cl100k": 181, "4x": 181, "3x": 181, "hyper": [181, 226], "ntk": 181, "logn": 181, "humanevalpack": 181, "octogeex": 181, "codegeex2": 181, "minerva": 181, "62b": 181, "dolli": 181, "gaokao": 181, "naturalquest": [181, 203], "siqa": 181, "ocn": 181, "clib": 181, "factool": 181, "19341": 182, "kunlun": 182, "ccnet": 182, "25519": 182, "utf": [182, 236], "hgx": 182, "80g": 182, "roce": 182, "1873": 182, "2t": 182, "aquila2": 182, "5t": [182, 241], "11008": 182, "dp256": 182, "pp2": 182, "mfu": 182, "dp512": 182, "662k": 182, "950k": 182, "36kr": 182, "douban": 182, "gcore": 182, "financ": [182, 218], "sina": 182, "jiemian": 182, "14196": 183, "06395": 184, "burgeon": 184, "concern": [184, 204, 207, 212], "immens": 184, "slms": 184, "wind": 184, "tunnel": 184, "wsd": 184, "lrs": 184, "conduc": 184, "depth": [184, 199, 224, 228, 229, 240], "intrigu": 184, "occur": 184, "axe": 184, "cement": 184, "slm": [184, 211, 212], "thin": 184, "ultrafeedback": [184, 240], "cui": 184, "mtbench": 184, "04434": 185, "10671": 187, "57b": 187, "a14b": 187, "ontolog": 187, "repurpos": [187, 191], "needl": 187, "needlebench": 187, "prone": [187, 206], "jail": 187, "15115": 188, "405b": 188, "bbpe": [188, 189], "536": 188, "262": 188, "262k": 188, "minicpm3": 188, "claude3": 188, "mgsm8k": 188, "blend": [188, 223, 225], "athen": 188, "minfer": 188, "09388": 189, "235b": 189, "119": 189, "asi": 189, "a22b": 189, "22b": 189, "30t": 189, "generaldomain": 189, "a3b": 189, "669": 189, "abf": 189, "llama4": 189, "3995": 189, "flag": 189, "template1": 189, "disabl": 189, "nothink": 189, "livebench": 189, "alignbench": 189, "writingbench": 189, "zebralog": 189, "autolog": 189, "gemini2": 189, "thinkfollow": 189, "1506": 190, "02640_you": 190, "1612": [190, 236], "08242_yolo9000": 190, "stronger": 190, "02767_yolov3": 190, "10934_yolov4": 190, "00159_svtr": 190, "2207": 190, "02696_yolov7": 190, "freebi": 190, "detector": [190, 191, 197], "marri": 190, "08485_visual": 190, "13616_yolov9": 190, "programm": 190, "14458_yolov10": 190, "15858_svtrv2": 190, "09332_webgpt": 190, "browser": 190, "11147_gophercit": 190, "09848_generative_search": 190, "14251_factscor": 190, "14627_alc": 190, "02185_citat": 190, "16883_hagrid": 190, "02640": 191, "yolo": [191, 192, 193, 200], "155": 191, "picasso": 191, "astound": 191, "08242": 192, "yolo9000": 192, "yolov2": 192, "pascal": 192, "2007": 192, "rcnn": 192, "ssd": [192, 193], "156": 192, "drawn": [192, 203, 226], "02767": 193, "bunch": 193, "swell": 193, "worri": 193, "320x320": 193, "yolov3": 193, "retinanet": 193, "8x": 193, "pjreddi": 193, "darknet": [193, 194], "10934": 194, "alexeyab": 194, "wrc": 194, "csp": 194, "cmbn": 194, "mish": 194, "dropblock": 194, "ciou": 194, "ap": [194, 196, 197, 200, 225], "ap50": 194, "tesla": [194, 195], "justif": 194, "exclus": 194, "mosaic": 194, "regular": [194, 228], "realtim": 194, "00159": 195, "paddlepaddl": 195, "paddleocr": 195, "str": [195, 201], "svtr": [195, 201], "mha": 195, "recogn": [195, 201], "enjoy": [195, 200], "bilstm": 195, "pren2d": 195, "visionlan": 195, "borisyuk": 195, "atienza": 195, "d_3": 195, "dosovitskiy": 195, "3a": 195, "bn": 195, "d_i": [195, 226, 229], "6625": [195, 238], "d0": 195, "l6": 195, "g6": [195, 233], "15m": 195, "29g": 195, "l8": 195, "45m": 195, "63g": 195, "g10": 195, "66m": 195, "55g": 195, "l10": 195, "g11": 195, "81m": 195, "07g": 195, "lx": 195, "gx": 195, "mjsynth": 195, "mj": 195, "synthtext": 195, "icdar": 195, "1095": 195, "857": 195, "svt": [195, 201], "647": 195, "ic15": [195, 201], "glass": 195, "svtp": [195, 201], "639": 195, "cute80": [195, 201], "cute": 195, "batch_siz": 195, "prog": 195, "gl": 195, "lg": 195, "02696": 196, "wongkinyiu": [196, 199], "yolov7": 196, "e6": 196, "swin": 196, "509": 196, "convnext": 196, "yolov5": 196, "5scale": 196, "r50": 196, "yolor": 196, "yolox": 196, "yolov4": 196, "deform": [196, 227], "05499": 197, "modescop": 197, "tight": 197, "13616": 199, "yolov9": [199, 200], "academia": 199, "sinica": 199, "pgi": 199, "gelan": 199, "closest": 199, "acquisit": [199, 237], "ignor": 199, "undergo": 199, "transmit": 199, "revers": [199, 211, 233], "cope": 199, "confirm": 199, "14458": 200, "thu": 200, "mig": 200, "yolov10": 200, "ultralyt": 200, "nms": 200, "r18": 200, "predomin": 200, "hamper": 200, "advers": 200, "besid": [200, 206, 212], "boundari": 200, "15858": 201, "topdu": 201, "openocr": 201, "connectionist": 201, "msr": 201, "frm": [201, 226], "sgm": 201, "edtr": 201, "svtrv2": 201, "puzzl": 201, "irregular": 201, "lister": 201, "union14m": 201, "u14m": 201, "rectif": 201, "d_2": [201, 225], "w_i": 201, "ln": 201, "1tphfz": 201, "l_i": 201, "c_i": [201, 223, 225, 226], "l_s": 201, "e_i": 201, "sigma": [201, 223, 225, 226, 228], "f_i": [201, 225], "lambda_1": 201, "lambda_2": 201, "ctcloss": 201, "2l": 201, "mo": 201, "cless": 201, "salient": 201, "mw": 201, "ost": 201, "ostw": 201, "osth": 201, "ltb": 201, "3376": 201, "bctr": 201, "hw": [201, 225, 226], "rebu": 201, "onecyclelr": 201, "6624": 201, "qualit": [201, 227], "fixed32": 201, "tps": 201, "maerec": 201, "relationship": [201, 211, 220], "09332": 202, "reiichiro": 202, "nakano": 202, "jacob": [202, 203], "hilton": 202, "suchir": 202, "balaji": 202, "christina": 202, "christoph": 202, "hess": 202, "shantanu": 202, "jain": 202, "eli5": [202, 203, 206, 211], "vote": 202, "lfqa": 202, "krishna": 202, "11147": 203, "menick": 203, "maja": 203, "trebacz": 203, "vladimir": 203, "mikulik": 203, "aslanid": 203, "trust": 203, "claim": [203, 206, 214, 238, 240], "convinc": 203, "nonsens": 203, "rlhp": 203, "whilst": 203, "apprais": 203, "gophercit": 203, "abstain": 203, "whi": [203, 206, 214], "trustworthi": [203, 204], "rerank": [203, 211, 238], "09848": 204, "nelson": 204, "tianyi": 204, "perci": 204, "neevaai": 204, "youchat": 204, "prerequisit": 204, "audit": [204, 242], "unsupport": [204, 205], "facad": [204, 225], "hope": [204, 226], "tailor": [204, 211, 214], "14251": 205, "binari": [205, 224], "inadequ": 205, "biographi": [205, 211], "perplexityai": 205, "26k": 205, "tianyu": 206, "howard": 206, "yen": 206, "jiatong": 206, "danqi": 206, "14627": 206, "alc": 206, "analys": 206, "premis": 206, "hypothesi": 206, "shia": 206, "sunni": 206, "islam": 206, "muslim": 206, "ideolog": 206, "heritag": 206, "leadership": 206, "death": 206, "prophet": 206, "632": 206, "branch": [206, 224], "son": 206, "ali": 206, "nowaday": 206, "polar": 206, "disord": [206, 214], "bipolar": 206, "swing": 206, "depress": 206, "genet": 206, "symptom": 206, "hear": 206, "frequenc": [206, 218], "soundwav": 206, "volumn": 206, "amplitud": [206, 231], "instrument": [206, 218], "discern": 206, "front": 206, "behind": [206, 214], "ear": 206, "louder": 206, "someon": 206, "journalist": 206, "minimum": [206, 228], "suffici": [206, 228], "corefer": 206, "standalon": [206, 226], "02185": 207, "jie": 207, "kevin": [207, 214], "chuan": 207, "alongsid": 207, "intellectu": 207, "angl": [207, 214, 224, 228], "acknowledg": 207, "confront": 207, "pitfal": 207, "16883": 208, "hagrid": 208, "had": 208, "imbu": 208, "atop": 208, "catalyst": 208, "11401_retriev": [209, 221], "10997_retriev": [209, 221], "15884_crag": [209, 221], "14403_adapt": [209, 221], "16130_graphrag": [209, 221], "graphrag": [209, 217, 221], "16506_grag": [209, 221, 235], "13213_multi": [209, 221], "05779_lightrag": [209, 221], "10450_kblam": [209, 221], "03137_lightprof": [209, 221], "11401": 210, "6707": 210, "0324": 210, "10997": 211, "1581": 211, "encount": 211, "outdat": 211, "untrac": 211, "synergist": 211, "intrins": [211, 228, 229], "vast": 211, "scrutin": 211, "tripartit": 211, "profound": 211, "concentr": 211, "deeper": 211, "ptm": 211, "inherit": 211, "introduct": 211, "drawback": [211, 214], "unstructur": 211, "small2big": 211, "preced": 211, "hyde": [211, 217], "kg": [211, 239], "cove": 211, "rrr": 211, "router": 211, "aurelio": 211, "angi": 211, "voyag": [211, 238], "bge": [211, 238, 240], "mrr": [211, 238], "rarank": 211, "llmlingua": 211, "richer": 211, "flare": 211, "introspect": 211, "subdivis": 211, "ie": 211, "qustion": 211, "tqa": 211, "webq": 211, "popqa": 211, "musiqu": 211, "narrativeqa": 211, "nqa": 211, "asqa": 211, "qmsum": 211, "qm": 211, "qasper": 211, "covid": 211, "cmb": 211, "mmcu_med": 211, "graphqa": [211, 239], "wizard": 211, "wow": 211, "kbp": 211, "dulemon": 211, "camrest": 211, "toy": 211, "sport": [211, 238], "wikiev": 211, "rex": 211, "zsre": 211, "csqa": 211, "strategyqa": 211, "pubhealth": 211, "wikiasp": 211, "xsum": 211, "violen": 211, "trec": 211, "nomiracl": 211, "jrc": 211, "acqui": 211, "counterfactu": 211, "crud": [211, 242], "raga": [211, 238], "trulens8": 211, "crag": [211, 212], "retro": [211, 240], "cm3": 211, "gss": 211, "ueop": 211, "knn": [211, 224, 236, 240, 242], "vid2seq": 211, "rbps": 211, "cok": 211, "15884": 212, "inevit": 212, "behav": 212, "recompos": 212, "14403": 213, "simplest": 213, "operation": 213, "incom": 213, "llmsretriev": 213, "16130": 214, "688": 214, "qfs": 214, "sensemak": 214, "llamaindex": [214, 238], "nebulagraph": 214, "neo4j": 214, "multihop": [214, 216], "covari": [214, 220], "leiden": 214, "traag": 214, "empower": [214, 217], "cto": 214, "scott": 214, "1669": 214, "3197": 214, "root": [214, 226], "fewest": 214, "greatest": 214, "281": 214, "tpm": 214, "rpm": 214, "graspolog": 214, "claimifi": 214, "075": 214, "agglom": 214, "564": 214, "691": 214, "520": 214, "001": [214, 236], "selfcheckgpt": 214, "drill": 214, "2400": 214, "openord": 214, "martin": 214, "2011": 214, "jacomi": 214, "2014": [214, 234], "kuratov": 214, "ve": 214, "kelc": 214, "britney": 214, "justin": 214, "timberlak": 214, "entity_nam": 214, "entity_typ": 214, "entity_descript": 214, "tuple_delimit": 214, "tuple_": 214, "delimit": 214, "source_ent": 214, "target_ent": 214, "relationship_descript": 214, "relationship_strength": 214, "strength": 214, "target_": 214, "record_delimit": 214, "completion_delimit": 214, "jerom": 214, "powel": 214, "investor": 214, "feder": 214, "committe": 214, "hold": 214, "growth": 214, "money": 214, "input_text": 214, "analyst": 214, "belong": 214, "maker": 214, "complianc": 214, "reput": 214, "pose": [214, 229], "explanatori": 214, "report_titl": 214, "executive_summari": 214, "impact_severity_r": 214, "rating_explan": 214, "insight_1_summari": 214, "insight_1_explan": 214, "insight_2_summari": 214, "insight_2_explan": 214, "alleg": 214, "wrongdo": 214, "verdant": 214, "oasi": 214, "plaza": 214, "uniti": 214, "march": [214, 228], "harmoni": 214, "tribun": 214, "bailey": 214, "asadi": 214, "revolv": 214, "moder": [214, 226], "unrest": 214, "conflict": 214, "reaction": 214, "provok": 214, "threat": 214, "amplifi": 214, "commentari": 214, "shall": 214, "ceo": [214, 238], "response_typ": 214, "report_data": 214, "answer_help": 214, "score_valu": 214, "context_data": 214, "winner": 214, "immateri": 214, "chose": 214, "answer1": 214, "answer2": 214, "nuclear": 214, "leav": 214, "viewpoint": [214, 223, 225, 226, 229], "climat": 214, "greenhous": 214, "emiss": 214, "deforest": 214, "disast": 214, "biodivers": 214, "franc": [214, 219], "river": 214, "sein": 214, "misl": 214, "fallaci": 214, "shapiro": 214, "wilk": 214, "wilcoxon": 214, "holm": 214, "bonferroni": 214, "16506": [215, 239], "yuntong": 215, "zhihan": 215, "bo": 215, "pan": 215, "ling": 215, "grag": [215, 239], "np": [215, 239], "13213": 216, "secondari": 216, "05779": 217, "telecommunications1": 217, "kong2": 217, "hkud": 217, "dedupl": [217, 240], "ultradomain": 217, "agricultur": 217, "cs": [217, 234], "naiverag": 217, "rq": 217, "mapk": 217, "rmse": [217, 227, 228], "399": 217, "610": 217, "gnns": 217, "graphgpt": 217, "llaga": 217, "gnn": [217, 239], "galm": 217, "brannon": 217, "10450": 218, "kblam": 218, "tripl": 218, "mlms": 218, "mlm": 218, "table1": 218, "table2": 218, "boldsymbol": [218, 226, 228], "langl": 218, "rangl": 218, "disk": 218, "later": 218, "regardless": 218, "panel": 218, "thematrix": 218, "founded_year": 218, "1976": 218, "k_m": 218, "v_m": 218, "overset": 218, "km": 218, "_k": [218, 226, 239], "_v": 218, "_q": [218, 229], "refus": 218, "15000": [218, 236], "predic": 218, "raw": [218, 225], "freebas": 218, "mu": 218, "ratner": 218, "cai": 218, "merth": 218, "kbs": 218, "idea_typ": 218, "greek": 218, "rock": 218, "band": [218, 223], "anim": [218, 225], "phenomena": 218, "classic": 218, "genr": 218, "roman": 218, "hindu": 218, "cthulhu": 218, "mytho": 218, "mytholog": 218, "planet": 218, "literari": 218, "botan": 218, "mission": 218, "philosoph": 218, "chemic": 218, "marin": 218, "object_typ": 218, "car": 218, "healthcar": 218, "textbook": 218, "consult": 218, "firm": 218, "biotech": 218, "bookstor": 218, "commerc": 218, "site": 218, "profit": 218, "hyphen": 218, "descipt": 218, "polish": 218, "openend": 218, "arriv": 218, "sens": 218, "alexandria": 218, "greattool": 218, "sensibl": 218, "name1": 218, "name2": 218, "unanser": 218, "sorri": 218, "compact": 218, "elabor": 218, "_g": 218, "useth": 218, "clarifi": 218, "cur": 218, "reefpuls": 218, "jellyfish": 218, "hazard": 218, "safer": 218, "anywher": 218, "injuri": 218, "homeown": 218, "aquarium": 218, "delic": 218, "ph": [218, 219], "ammonia": 218, "nitrit": 218, "nitrat": 218, "inhabit": 218, "healthi": 218, "fluctuat": 218, "sitraka": 218, "itsm": 218, "flagship": 218, "incid": 218, "desk": 218, "analyt": 218, "03137": 219, "lightprof": 219, "kgs": 219, "kgqa": 219, "catastroph": [219, 226, 230], "forget": 219, "kape": 219, "structgpt": 219, "tog": 219, "knowledgenavig": 219, "tail": 219, "iscapitalof": 219, "b_1": 219, "b_2": 219, "b_k": 219, "r_1": 219, "r_2": 219, "r_j": 219, "locatedin": 219, "r_l": 219, "e_1": 219, "r_m": 219, "e_m": 219, "workedat": 219, "h_q": 219, "v_q": 219, "g_r": 219, "r_n": 219, "structemb": 219, "_2": [219, 226], "t_h": 219, "t_t": 219, "f_c": 219, "concat": 219, "knowledgeencod": 219, "arg": [219, 225, 228, 230], "p_h": 219, "p_s": 219, "p_p": 219, "ps": 219, "q1": 219, "q2": 219, "q3": 219, "webqsp": [219, 239], "sparql": 219, "cwq": 219, "689": 219, "datashap": 220, "datafram": 220, "textunit": 220, "umap": 220, "16300_random": [221, 235], "infinit": [221, 235], "18743_alignbench": [221, 235], "15391_multihop": [221, 235], "01178_memory3": [221, 235], "14683_emerg": [221, 235], "memo": [221, 235], "10959v3_dataset": 222, "20653_dataset": 222, "minmax": 222, "08934_nerf": 222, "radianc": 222, "08586": 222, "vanish": 222, "geometr": [222, 228, 229], "14132_dust3r": 222, "09756_mast3r": 222, "mast3r": [222, 227, 229], "09401_slam3r": 222, "monocular": [222, 228], "12392_mast3r": 222, "11651_vggt": 222, "geometri": [222, 223, 225, 226, 227], "crc": 222, "08934": 223, "1uc": 223, "2googl": 223, "5d": [223, 225], "drum": 223, "surround": 223, "hemispher": [223, 224], "nerf": [223, 225, 228], "camera": [223, 224, 227, 229], "sdf": 223, "shapenet": [223, 225], "volumetr": [223, 225], "emit": 223, "ship": 223, "inset": 223, "surfac": [223, 229], "specular": 223, "int_": 223, "dt": 223, "quadratur": 223, "stratifi": 223, "sigma_i": [223, 229], "delta_i": 223, "llff": [223, 227], "1008": 223, "756": 223, "nv": 223, "srn": 223, "rig": 223, "lego": 223, "gear": 223, "tread": 223, "microphon": 223, "shini": 223, "grill": 223, "lambertian": 223, "artifact": 223, "mast": 223, "blurri": 223, "distort": [223, 225, 228, 229], "yanconglin": 224, "vanishingpoint_houghtransform_gaussianspher": 224, "delft": 224, "netherland": 224, "straight": 224, "offset": [224, 233], "scannet": [224, 225, 227], "scenec": 224, "urban": 224, "contour": 224, "ransac": [224, 225, 226], "linkag": 224, "conic": 224, "fibonacci": 224, "lattic": 224, "edgeconv": 224, "ht": 224, "azimuth": 224, "elev": 224, "ab": 224, "psi": [224, 228, 231], "overrightarrow": 224, "vec": 224, "ob": 224, "xz": 224, "tan": 224, "n_x": 224, "n_z": 224, "n_i": 224, "n_": [224, 225, 240], "leakyrelu": 224, "14132": 225, "aalto": 225, "europ": [225, 226], "pnp": 225, "f_x": 225, "c_x": 225, "skew": 225, "coeffici": 225, "k_3": 225, "3x4": 225, "3x3": 225, "tedious": 225, "cumbersom": 225, "mandatori": 225, "triangul": [225, 226], "opposit": 225, "stanc": 225, "radic": 225, "unconstrain": 225, "nor": 225, "cast": 225, "binocular": 225, "photograph": 225, "quantiti": 225, "depthmap": 225, "dtu": [225, 226], "tank": [225, 227], "templ": [225, 227], "eth": 225, "shade": 225, "keypoint": [225, 229], "ba": [225, 226, 228], "featuremetr": 225, "ill": 225, "pavllo": 225, "mde": 225, "p_m": 225, "siames": [225, 226], "1_i": 225, "2_": 225, "g_0": 225, "g_i": 225, "decoderblock": 225, "g_b": 225, "ambigu": 225, "ell_": [225, 226], "regr": [225, 226], "v_i": 225, "conf": [225, 226], "neighbor": [225, 226], "_j": 225, "f_1": 225, "weiszfeld": 225, "f_2": 225, "epipolar": [225, 226], "procrust": 225, "chi": 225, "p_e": 225, "sigma_": 225, "prod_": [225, 239], "eq": 225, "k_n": 225, "waymo": 225, "co3d": [225, 226, 227], "512px": 225, "dpt": [225, 226, 229], "7scene": 225, "cambridg": 225, "cm": 225, "rotat": [225, 229, 233], "matcher": [225, 226], "hloc": 225, "co3dv2": [225, 226], "37k": [225, 226], "colmap": [225, 229], "realestate10k": [225, 226], "rra": [225, 226], "rta": [225, 226], "maa": [225, 226], "posediffus": 225, "kitti": 225, "ddad": 225, "nyuv2": 225, "bonn": 225, "tum": 225, "absrel": 225, "slowtv": 225, "rescal": 225, "eth3d": [225, 227], "inlier": 225, "habitat": 225, "7mm": 225, "8mm": 225, "focal": [225, 226], "megadepth": [225, 226, 229], "pointcloud": [225, 227], "appar": 225, "kingscolleg": 225, "oldhospit": 225, "stmaryschurch": 225, "shopfacad": 225, "greatcourt": 225, "chess": 225, "pumpkin": 225, "stair": 225, "motorcycl": 225, "toaster": 225, "drastic": 225, "cherri": 225, "co3d_v2": 225, "octre": 225, "indoor": 225, "6cm": 225, "times3": 225, "times4": 225, "d_1": 225, "1_": 225, "arkitscen": 225, "09756": 226, "descriptor": 226, "johann": 226, "nberger": 226, "stereo": [226, 227, 228], "mvs": [226, 227, 228], "tolia": 226, "bow": 226, "rootsift": 226, "delf": 226, "vlad": 226, "oxford5k": 226, "paris6k": 226, "holiday": 226, "instr": 226, "fischler": 226, "boll": 226, "1981": 226, "consensus": 226, "cartographi": 226, "p3p": 226, "dlt": 226, "epnp": 226, "upnp": 226, "rpnp": 226, "degrad": [226, 228], "attain": 226, "vcre": 226, "loftr": [226, 229], "infonc": 226, "aachen": 226, "inloc": 226, "toft": 226, "superpoint": [226, 229], "densegap": 226, "u_": 226, "nu_": 226, "pointmap": [226, 227, 229], "intertwin": 226, "prime1": 226, "nu": 226, "desc": 226, "prime2": 226, "d_j": 226, "mutual": 226, "_a": 226, "l_2": 226, "_n": [226, 239], "longmapsto": 226, "equiv": 226, "u_n": 226, "v_n": 226, "bigcup_t": 226, "cycl": 226, "ldots6": 226, "kwh": 226, "_reciproc": 226, "_nn": 226, "reloc": [226, 227, 228], "0001": [226, 233], "faiss": [226, 236, 240], "460": 226, "reproject": 226, "sfm": [226, 227], "relpos": 226, "posereg": 226, "posediff": 226, "raydiff": 226, "pixsfm": [226, 229], "maa30": 226, "wors": 226, "raydiffus": 226, "4328": 226, "824": 226, "9972": 226, "329": 226, "iphone7": 226, "chamfer": [226, 228], "alon": 226, "regim": 226, "top1": [226, 233], "foster": 226, "otherwis": 226, "until": 226, "basin": 226, "d_u": 226, "bipartit": 226, "lemma": 226, "arboresc": 226, "u1": 226, "u2": 226, "u3": 226, "corollari": 226, "09401": 227, "pku": 227, "vcl": 227, "3dv": 227, "i2p": 227, "l2w": 227, "nicer": [227, 228], "dust3r": [227, 228, 229], "droid": [227, 228], "tandem": 227, "spann3r": [227, 228], "eleg": 227, "i_i": [227, 228, 229], "minimalist": 227, "travers": 227, "reg": 227, "sce": 227, "i_l": 227, "i_key": 227, "e_img": 227, "d_key": 227, "d_sup": 227, "f_key": 227, "f_sup": 227, "g_key": 227, "g_sup": 227, "sup": 227, "reservoir": 227, "patchif": 227, "4090d": 227, "ate": 227, "blendedmv": 227, "umeyama": 227, "icp": [227, 228], "2022zd0160800": 227, "musket": 227, "zihan": 227, "songyou": 227, "peng": 227, "ase": 227, "heatmap": 227, "lighter": 227, "y_j": 227, "perd": 227, "experienc": 227, "cumul": 227, "drift": [227, 228], "unorgan": 227, "12392": 228, "imperi": 228, "edexheim": 228, "wozt71nbftq": 228, "inerti": 228, "spatiallm": 228, "cube": 228, "pointmvsnet": 228, "ssrnet": 228, "delaunay": 228, "acceleromet": 228, "gyroscop": 228, "magnetomet": 228, "gps": 228, "vi": 228, "lidar": 228, "orb": 228, "dso": 228, "ldso": 228, "cartograph": 228, "loam": 228, "vin": 228, "mono": 228, "okvi": 228, "lvi": 228, "fishey": 228, "equiangular": 228, "centr": 228, "altogeth": 228, "burgher": 228, "gaussian": 228, "splat": [228, 229], "keyfram": 228, "levenberg": 228, "marquardt": 228, "normalis": 228, "minimis": 228, "angular": 228, "_0": [228, 237], "j_i": 228, "mathfrak": 228, "leftarrow": 228, "oplus": 228, "triangleq": 228, "brute": 228, "psi_1": 228, "psi_2": 228, "2ms": 228, "kd": 228, "k_k": 228, "e_p": 228, "2_p": 228, "huber": [228, 229], "e_r": 228, "2_r": 228, "reweight": 228, "jacobian": 228, "ep": 228, "er": 228, "asmk": 228, "wc": 228, "7n": 228, "uncalibr": 228, "dpv": 228, "047": 228, "066": 228, "undistort": 228, "041m": 228, "vicon": 228, "3cm": 228, "frontend": 228, "permit": 228, "incoher": 228, "fr1": 228, "mh01": 228, "333": 228, "022m": 228, "deepfactor": 228, "deepv2d": 228, "164m": 228, "11651": 229, "facebookresearch": 229, "vggt": 229, "metaai": 229, "trove": 229, "extrins": 229, "vggsfm": 229, "moge": 229, "lrm": 229, "keynet": 229, "lightglu": 229, "patchmatch": 229, "particl": 229, "vid": 229, "tapir": 229, "cotrack": 229, "locotrack": 229, "oil": 229, "quaternion": 229, "i_q": 229, "pmap": 229, "odot": 229, "aleator": 229, "129": 229, "160k": 229, "0002": 229, "518": 229, "frustum": 229, "unord": 229, "tracker": 229, "63gb": 229, "fast3r": 229, "theseus": 229, "gamma": 229, "pi": 229, "pinhol": 229, "land": 229, "pn": 229, "multiheadattent": 229, "qknorm": 229, "168": 229, "imc": 229, "sift": 229, "10s": 229, "20s": 229, "sp": 229, "sg": 229, "dfsfm": 229, "9s": 229, "6s": 229, "vggsfmv2": 229, "8s": 229, "phototrop": 229, "phototour": 229, "british": 229, "deit": 229, "cait": 229, "ace": 229, "flowmap": 229, "10959v3": 230, "mnist": 230, "lenet": 230, "cifar10": 230, "svhn": 230, "poison": 230, "misclassifi": 230, "hinton": 230, "gd": 230, "theta_": 230, "theta_t": 230, "eta": 230, "nabla_": 230, "_t": 230, "theta_1": 230, "theta_0": 230, "xavier": 230, "alexnet": 230, "attack": 230, "20653": 231, "ncfd": 231, "discrep": 231, "cf": 231, "ncfm": 231, "imagesquawk": 231, "2080": 231, "ti": 231, "dm": 231, "mmd": 231, "hilbert": 231, "redefin": 231, "parameter": 231, "euler": 231, "formula": 231, "phi_": 231, "bm": 231, "condens": 232, "0617": 233, "00000110": 233, "00010111": 233, "1001": 233, "0000010101101": 233, "00ad": 233, "173": 233, "quotient": 233, "____": 233, "___": 233, "0000011000010111": 233, "1559": 233, "dividend": 233, "divisor": 233, "0011": 233, "0110": 233, "1100": 233, "0111": 233, "1110": 233, "1011": 233, "0101": 233, "0010": 233, "remaind": 233, "06172": 233, "10111": 233, "polynomi": 233, "mod": 233, "xore": 233, "10011011": 233, "11001010": 233, "01010001": 233, "1101": 233, "1111111": 233, "1100001010": 233, "_______________": 233, "10011": 233, "11010110110000": 233, "00001": 233, "00010": 233, "00101": 233, "01011": 233, "10110": 233, "01010": 233, "10100": 233, "01110": 233, "0111010110": 233, "crc8": 233, "100110001": 233, "checksum": 233, "1101011011": 233, "nobodi": 233, "11010110111110": 233, "checksum2": 233, "x8": 233, "x5": 233, "x4": 233, "0x131": 233, "ccitt": 233, "x16": 233, "x12": 233, "x25": 233, "crc16": 233, "x15": 233, "crc12": 233, "x11": 233, "crc32": 233, "x32": 233, "x26": 233, "x23": 233, "x22": 233, "x10": 233, "x7": 233, "ethernet": 233, "100000100110000010001110110110111": 233, "0x04c11db7": 233, "notat": 233, "0b11101101101110001000001100100000": 233, "0xedb88320": 233, "crc32_q": 233, "0b11010101100000101000001010000001": 233, "0xd5828281": 233, "04c11db7": 233, "104c11db7": 233, "crc1": 233, "pop": 233, "xor": 233, "t7": 233, "t6": 233, "t4": 233, "t3": 233, "t2": 233, "t1": 233, "g5": 233, "g4": 233, "g3": 233, "g2": 233, "g0": 233, "remind": 233, "step1": 233, "1010110110000": 233, "step2": 233, "010110110000": 233, "step3": 233, "10110110000": 233, "step4": 233, "0110110000": 233, "step5": 233, "1010": 233, "110110000": 233, "step6": 233, "10110000": 233, "step7": 233, "0110000": 233, "step8": 233, "110000": 233, "step9": 233, "step10": 233, "0100": 233, "nil": 233, "nibbl": 233, "longword": 233, "32bit": 233, "4byte": 233, "1bit": 233, "1byte": 233, "1st": 233, "2nd": 233, "top8": 233, "0100010": 233, "0011000": 233, "255": 233, "exhaus": 233, "top_byt": 233, "next_augmessage_byt": 233, "precomputed_t": 233, "goto": 233, "iff": 233, "0xff": 233, "zlib": 233, "crc_v3": 233, "1405": 234, "4053": 234, "from2": 234, "quocl": 234, "paragraph_vector": 234, "mikolov": 234, "doc2vec": 234, "gensim": 234, "lib": 234, "16300": 236, "237": 236, "_block": 236, "_local": 236, "stingi": 236, "50000": 236, "matteo": 236, "pagliardini": 236, "olivia": 236, "simin": 236, "fan": 236, "snsf": 236, "200020_200342": 236, "tex": 236, "latin1": 236, "1919": 236, "gutenberg": 236, "cmt": 236, "p_jump": 236, "jump": 236, "groupedsoftmax": 236, "llama7b": 236, "070": 236, "18743": 237, "critiquellm": 237, "thudm": 237, "683": 237, "gdp": 237, "1896": 237, "int_0": 237, "15391": 238, "dpr": [238, 242], "reciproc": 238, "mediastack": 238, "lightetern": 238, "xlmr": 238, "el": 238, "uniev": 238, "609": 238, "046": 238, "172": 238, "556": 238, "7467": 238, "scifact": 238, "hover": 238, "multirc": 238, "worldwid": 238, "polygon": 238, "fox": 238, "health": 238, "cnbc": 238, "yardbark": 238, "bloomberg": 238, "reuter": 238, "ego": 239, "autoprompt": 239, "subgraph": 239, "t_e": 239, "subseteq": 239, "y_": 239, "bigcup_": 239, "sentencebert": 239, "z_g": 239, "v_g": 239, "e_g": 239, "z_q": 239, "alpha_n": 239, "phi_1": 239, "z_n": 239, "ominus": 239, "alpha_": 239, "phi_2": 239, "z_e": 239, "explagraph": 239, "minilm": 239, "labs": 239, "e5": 239, "7236": 239, "4148": 239, "7275": 239, "5835": 239, "nsf": 239, "nih": 239, "2414115": 239, "2403312": 239, "2007716": 239, "2007976": 239, "1942594": 239, "1907805": 239, "r01ag089806": 239, "r01ca297856": 239, "l12": 239, "sentencetransform": 239, "mcontriev": 239, "prize": 239, "steiner": 239, "a10g": 239, "gat": 239, "3722": 239, "4287": 239, "01178": 240, "1center": 240, "2moqi": 240, "3center": 240, "peke": 240, "realm": 240, "longllama": 240, "longmem": 240, "qmoe": 240, "arctic": 240, "deja": 240, "vu": 240, "superposit": 240, "mover": 240, "neuron": 240, "homomorph": 240, "circuit": 240, "tin": 240, "tout": 240, "costwrit": 240, "costread": 240, "17pb": 240, "7340tb": 240, "9tb": 240, "02tb": 240, "d_h": 240, "h_": 240, "11a": 240, "redpajamav2": 240, "slimpajama": 240, "200tb": 240, "wanjuan": 240, "wenshu": 240, "mnbvc": 240, "500tb": 240, "minhash": 240, "xinyu": 240, "20gb": 240, "299": 240, "wikihow": 240, "4t": [240, 241], "1t": [240, 241], "120b": 240, "slimorca": 240, "capybara": 240, "deita": 240, "metamathqa": 240, "binar": 240, "distilabel": 240, "synth": 240, "xxl": 240, "haluev": 240, "halluqa": 240, "jec": 240, "agx": 240, "733": 240, "1131": 240, "228": 240, "nsfc": 240, "92270001": 240, "vocab": 240, "60416": 240, "308": 240, "000144": 240, "000144n": 240, "624n": 240, "494": 240, "13400": 240, "opq20x80": 240, "residual2x14": 240, "pq8x10": 240, "uint8": 240, "14683": 241, "florenc": 241, "bagel": 241, "mot": 241, "sd3": 241, "flux": 241, "intelligentbench": 241, "siglip2": 241, "t2i": 241, "2100m": 241, "65m": 241, "koala36m": 241, "mvimgnet2": 241, "4500": 241, "378": 241, "6t": 241, "36k": 241, "40k": 241, "mmvp": 241, "gedit": 241, "18t": 241, "68t": 241, "64t": 241, "61t": 241, "0t": 241, "janus": 241, "metaqueri": 241, "step1x": 241, "ic": 241, "januspro": 241, "ziqian": 241, "haoli": 241, "shengyang": 241, "2507": 242, "03724": 242, "3institut": 242, "4tongji": 242, "6univers": 242, "7peke": 242, "8renmin": 242, "9beihang": 242, "10research": 242, "slayer": 242, "prag": 242, "dyprag": 242, "rome": 242, "memit": 242, "steer": 242, "iti": 242, "ifs": 242, "zep": 242, "pagerank": 242, "l0": 242, "dumper": 242, "recoveri": 242, "consolid": 242, "fingerprint": 242, "memorycal": 242, "memoryadapt": 242, "langmem": 242, "meteor": 242, "0630": 242, "p50": 242, "p95": 242, "ttft": 242}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"googl": [2, 71], "scholar": 2, "semant": [2, 83, 141, 143, 144, 166, 201, 219], "web": [2, 32, 158], "of": [2, 7, 8, 10, 11, 12, 13, 16, 17, 19, 32, 33, 36, 45, 50, 52, 55, 56, 58, 63, 64, 65, 68, 70, 75, 76, 78, 79, 81, 82, 83, 84, 85, 90, 91, 94, 96, 98, 100, 101, 102, 103, 105, 112, 118, 120, 122, 123, 125, 127, 133, 135, 143, 147, 149, 150, 151, 152, 155, 156, 157, 158, 160, 165, 166, 167, 170, 171, 172, 174, 175, 183, 184, 185, 186, 194, 195, 196, 201, 205, 211, 218, 227, 230, 234, 236, 237, 239, 242], "scienc": [2, 31], "sci": 2, "hub": 2, "librari": [2, 99, 105], "genesi": 2, "libgen": 2, "unpaywal": 2, "acl": 2, "antholog": 2, "arxiv": 2, "cnki": 2, "ai": [3, 4, 5, 23, 42, 47, 54, 71, 78, 97, 129, 133, 146, 153, 242], "agent": [3, 9, 10, 12, 13, 14, 16, 17, 18, 19, 22, 24, 25, 26, 28, 29, 31, 32, 33, 34, 35, 37, 38, 44, 46, 47, 54, 63, 68, 79, 133, 159, 181], "aio": [3, 13], "tool": [3, 13, 41, 45, 46, 128, 186, 211], "agi": 3, "1905": 4, "10985_ai": 4, "ga": 4, "generat": [4, 7, 11, 24, 34, 35, 39, 43, 48, 50, 51, 52, 53, 56, 59, 61, 63, 75, 76, 88, 102, 118, 121, 123, 127, 138, 141, 143, 144, 145, 147, 149, 151, 155, 159, 166, 170, 171, 176, 178, 204, 205, 206, 208, 210, 211, 212, 214, 215, 217, 218, 238, 239], "algorithm": [4, 102, 105, 112, 113, 121, 233], "an": [4, 19, 27, 31, 39, 54, 58, 99, 101, 112, 158, 174], "altern": [4, 126], "paradigm": [4, 217], "for": [4, 8, 10, 11, 12, 16, 18, 19, 25, 26, 27, 31, 32, 35, 36, 38, 39, 43, 46, 48, 49, 50, 51, 52, 55, 57, 61, 63, 69, 70, 75, 76, 78, 79, 81, 82, 83, 84, 88, 90, 97, 102, 107, 116, 117, 118, 119, 120, 121, 122, 124, 125, 127, 129, 130, 133, 134, 136, 137, 141, 143, 144, 145, 146, 147, 155, 156, 158, 160, 162, 165, 166, 167, 169, 174, 175, 181, 196, 197, 208, 210, 211, 216, 218, 219, 223, 224, 227, 230, 236, 238, 242], "produc": 4, "general": [4, 8, 38, 51, 54, 75, 78, 107, 133, 160, 189, 218, 241], "artifici": 4, "intellig": [4, 12, 32, 183], "2408": [5, 33, 34, 132, 156, 164], "06292_the": 5, "scientist": 5, "toward": [5, 98, 136, 147, 163], "fulli": [5, 151], "autom": [5, 17, 18, 19, 33, 34, 35], "open": [5, 27, 68, 77, 79, 133, 161, 165, 174, 179, 180, 182, 188, 197, 218], "end": [5, 68, 79, 146, 164, 200, 218, 242], "scientif": 5, "discoveri": [5, 32], "2108": [6, 49], "03353_": 6, "screen2word": 6, "automat": [6, 11, 81, 82, 110, 130, 181, 188], "mobil": [6, 7, 14, 16], "ui": [6, 7, 11, 12, 17, 52], "summar": [6, 63, 83, 214], "with": [6, 8, 14, 15, 16, 17, 21, 22, 42, 49, 50, 51, 53, 59, 60, 61, 62, 66, 68, 81, 83, 85, 98, 102, 110, 112, 113, 117, 123, 124, 127, 130, 137, 139, 141, 143, 144, 147, 151, 152, 154, 155, 161, 162, 166, 167, 169, 171, 172, 173, 184, 195, 197, 201, 202, 203, 206, 208, 216, 218, 223, 225, 226, 228, 230, 231, 233, 238, 240], "multimod": [6, 7, 9, 15, 54, 57, 59, 61, 63, 79, 145, 149, 150, 159, 161, 165, 166, 170, 171, 172, 241], "learn": [6, 8, 12, 17, 22, 35, 49, 97, 99, 104, 106, 107, 120, 126, 127, 128, 133, 135, 137, 138, 141, 143, 144, 147, 151, 154, 155, 162, 175, 188, 199, 224], "abstract": [6, 7, 8, 10, 11, 12, 13, 15, 16, 17, 18, 19, 30, 38, 39, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 97, 98, 104, 106, 107, 108, 111, 112, 113, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 130, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 149, 151, 152, 155, 158, 159, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 176, 182, 187, 188, 189, 191, 192, 194, 195, 196, 199, 200, 201, 214, 217, 218, 219, 223, 224, 225, 226, 227, 228, 229, 230, 231, 236, 237, 238, 239, 240, 241, 242], "introduct": [6, 7, 8, 10, 11, 12, 13, 16, 17, 18, 19, 31, 35, 38, 39, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 97, 98, 102, 104, 105, 106, 107, 112, 113, 117, 119, 120, 121, 122, 123, 124, 125, 127, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 146, 147, 149, 151, 152, 155, 158, 159, 161, 162, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 181, 182, 187, 188, 189, 195, 201, 214, 217, 218, 219, 223, 224, 225, 226, 227, 228, 229, 230, 231, 236, 237, 238, 239, 240, 241, 242], "relat": [6, 7, 8, 10, 12, 16, 18, 19, 35, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 80, 97, 98, 101, 104, 107, 112, 116, 117, 119, 121, 122, 123, 124, 125, 127, 130, 135, 137, 138, 139, 140, 143, 145, 146, 159, 161, 162, 164, 165, 166, 168, 171, 172, 173, 174, 175, 176, 181, 201, 214, 217, 218, 219, 223, 224, 225, 226, 227, 228, 229, 231, 236, 237, 238, 239], "work": [6, 7, 8, 10, 12, 16, 18, 19, 35, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 80, 96, 97, 98, 104, 107, 112, 113, 116, 117, 119, 121, 122, 123, 124, 125, 127, 130, 135, 136, 137, 138, 139, 140, 143, 145, 146, 159, 161, 162, 164, 165, 166, 167, 168, 171, 172, 173, 174, 175, 176, 181, 201, 217, 218, 219, 223, 224, 225, 226, 227, 228, 229, 231, 236, 237, 238, 239], "dataset": [6, 7, 11, 43, 45, 49, 51, 52, 53, 54, 60, 63, 65, 66, 67, 69, 70, 71, 80, 130, 136, 137, 139, 141, 143, 147, 158, 165, 168, 195, 201, 208, 224, 227, 232, 236, 237, 238], "creation": [6, 35, 101], "model": [6, 8, 10, 11, 15, 16, 17, 19, 27, 30, 39, 41, 43, 45, 48, 49, 50, 52, 54, 56, 57, 58, 60, 61, 64, 65, 67, 68, 70, 72, 75, 76, 77, 78, 85, 91, 92, 94, 96, 97, 98, 101, 102, 104, 106, 107, 110, 111, 112, 118, 122, 127, 130, 132, 133, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 149, 151, 152, 154, 157, 160, 161, 162, 164, 165, 167, 168, 169, 171, 172, 173, 174, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 195, 201, 203, 206, 207, 211, 218, 219, 224, 225, 228, 236, 237, 240, 241, 242], "design": [6, 12, 19, 33, 39, 51, 57, 75, 78, 101, 105, 118, 133, 167, 240, 242], "2209": [7, 120], "08199_screenqa": 7, "larg": [7, 8, 10, 15, 27, 30, 39, 43, 45, 48, 49, 52, 57, 60, 68, 72, 77, 78, 91, 94, 102, 103, 111, 117, 118, 119, 122, 137, 141, 144, 145, 161, 171, 172, 173, 174, 178, 183, 186, 206, 207, 211, 219, 224, 237, 242], "scale": [7, 8, 68, 90, 110, 111, 117, 118, 119, 120, 122, 127, 132, 133, 137, 147, 152, 162, 168, 178, 188, 201, 211, 218, 226], "question": [7, 11, 49, 63, 64, 68, 69, 70, 71, 78, 143, 160, 202, 218], "answer": [7, 11, 63, 64, 69, 70, 143, 160, 202, 203, 214, 217], "pair": [7, 225], "over": [7, 49], "app": [7, 48, 79], "screenshot": 7, "problem": [7, 49, 56, 66, 67, 83, 84, 138, 140, 161, 226, 229, 239], "set": [7, 48, 50, 51, 58, 69, 77, 127, 140, 141, 144, 147, 182, 196, 197, 217, 218, 226, 227, 240], "task": [7, 8, 10, 11, 16, 18, 32, 38, 42, 50, 53, 57, 63, 64, 65, 79, 83, 97, 101, 145, 146, 147, 155, 160, 165, 175, 176, 210, 211, 238], "and": [7, 8, 9, 10, 11, 13, 16, 17, 19, 24, 29, 32, 35, 37, 42, 48, 49, 51, 52, 53, 54, 58, 61, 64, 65, 68, 69, 70, 72, 75, 78, 79, 83, 85, 96, 97, 98, 101, 102, 104, 105, 106, 107, 110, 112, 113, 117, 118, 119, 121, 122, 123, 124, 127, 130, 133, 136, 137, 138, 143, 144, 145, 146, 147, 149, 151, 152, 155, 158, 160, 165, 166, 167, 171, 172, 173, 175, 179, 180, 185, 188, 194, 195, 201, 207, 211, 214, 217, 218, 224, 225, 226, 227, 228, 229, 230, 234, 236, 237, 240, 242], "metric": [7, 8, 11, 12, 45, 50, 53, 57, 81, 137, 140, 143, 214], "evalu": [7, 8, 10, 12, 13, 17, 19, 27, 45, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 62, 63, 65, 68, 70, 75, 76, 77, 78, 80, 81, 82, 83, 85, 97, 98, 102, 104, 123, 130, 137, 138, 139, 140, 143, 144, 146, 147, 149, 152, 155, 160, 161, 162, 165, 166, 170, 174, 181, 182, 187, 188, 189, 204, 205, 211, 214, 217, 218, 224, 225, 228, 237, 240, 241, 242], "screenqa": [7, 11], "data": [7, 8, 10, 11, 15, 31, 52, 57, 58, 60, 69, 70, 71, 72, 75, 79, 85, 96, 98, 104, 106, 109, 123, 130, 133, 143, 144, 145, 147, 149, 159, 160, 161, 165, 166, 169, 171, 172, 174, 175, 182, 189, 225, 230, 238, 240, 241], "annot": [7, 10, 11, 43, 53, 67], "analysi": [7, 10, 19, 48, 50, 53, 55, 56, 57, 58, 60, 64, 65, 68, 69, 71, 77, 79, 98, 112, 116, 123, 127, 137, 138, 139, 143, 144, 145, 158, 176, 195, 214, 230], "experi": [7, 8, 10, 11, 12, 16, 17, 18, 35, 38, 43, 45, 46, 47, 51, 52, 53, 54, 56, 57, 60, 61, 64, 65, 67, 68, 69, 70, 74, 75, 76, 77, 97, 109, 112, 122, 124, 125, 127, 134, 136, 137, 138, 139, 140, 142, 145, 146, 151, 158, 159, 162, 164, 166, 167, 168, 169, 171, 172, 173, 176, 182, 195, 201, 218, 219, 224, 225, 227, 229, 236, 239], "baselin": [7, 12, 63, 71, 79, 81, 143, 144, 158, 161, 171, 172, 182], "conclus": [7, 8, 10, 11, 12, 16, 17, 18, 19, 39, 43, 45, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 74, 76, 77, 79, 81, 82, 85, 96, 97, 102, 117, 118, 120, 122, 124, 125, 127, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 149, 152, 155, 158, 159, 161, 162, 164, 166, 167, 168, 169, 170, 171, 172, 173, 174, 176, 181, 182, 187, 188, 189, 195, 201, 214, 217, 218, 219, 223, 224, 225, 226, 227, 228, 229, 231, 236, 237, 238, 239, 240, 241, 242], "limit": [7, 8, 10, 12, 16, 48, 49, 52, 53, 54, 56, 62, 63, 64, 68, 71, 78, 112, 118, 119, 121, 123, 127, 136, 137, 138, 145, 147, 151, 172, 173, 174, 182, 218, 224, 228, 229, 238, 239], "ethic": [7, 10, 50, 53, 56, 61, 68, 70], "consider": [7, 10, 12, 53, 61, 68, 123], "detail": [7, 8, 10, 43, 45, 50, 53, 58, 62, 63, 67, 68, 69, 75, 79, 81, 85, 112, 117, 118, 130, 135, 155, 158, 160, 161, 165, 166, 174, 175, 181, 182, 195, 201, 225, 226, 227, 229, 236, 237], "vh": 7, "out": [7, 68, 101], "sync": [7, 107], "rule": [7, 17, 53, 127], "qualiti": [7, 47, 70, 127, 139, 143, 151, 172, 237], "control": [7, 8, 12, 19, 32, 47, 70, 97, 101, 145], "post": [7, 117, 121, 122, 143, 147, 149, 155, 169, 170, 187, 188, 189], "process": [7, 50, 61, 69, 77, 100, 133, 151, 211], "short": [7, 11, 39, 72, 137], "prompt": [7, 11, 33, 43, 47, 53, 58, 60, 61, 64, 65, 68, 70, 75, 76, 79, 85, 88, 90, 127, 130, 138, 145, 155, 161, 174, 206, 214, 218, 219, 220, 237, 238, 239], "exampl": [7, 11, 16, 52, 53, 60, 65, 67, 70, 76, 79, 84, 123, 155, 161, 165, 214, 229, 236, 238], "2212": [8, 137], "06817_rt": 8, "robot": [8, 153], "transform": [8, 100, 102, 106, 117, 119, 121, 122, 134, 136, 143, 158, 175, 176, 224, 226, 229, 236, 241], "real": [8, 43, 50, 64, 79, 143, 146, 163, 191, 196, 200, 201, 227, 228], "world": [8, 43, 50, 133, 153, 163, 201, 224], "at": [8, 119], "preliminari": [8, 34, 122, 127, 158, 161, 182, 219, 228], "system": [8, 13, 17, 19, 33, 39, 54, 56, 79, 81, 97, 101, 102, 117, 143, 146, 214, 238, 242], "overview": [8, 17, 32, 50, 63, 98, 101, 143, 167, 170, 211, 225], "rt": 8, "token": [8, 76, 80, 141, 143, 144, 146, 147, 150, 164, 166, 171, 181, 182, 187, 188, 218, 236, 240], "infer": [8, 118, 120, 127, 138, 139, 140, 143, 151, 171, 172, 240], "speed": [8, 98, 194, 240], "experiment": [8, 19, 50, 52, 58, 63, 68, 85, 104, 118, 121, 130, 135, 136, 139, 141, 144, 147, 217, 226, 227], "setup": [8, 13, 19, 50, 52, 53, 54, 58, 63, 75, 80, 104, 122, 136, 138, 139, 140, 166, 176, 228], "can": [8, 41, 50, 65, 132], "to": [8, 11, 16, 17, 41, 43, 54, 61, 62, 67, 68, 76, 92, 98, 102, 126, 127, 130, 132, 133, 137, 138, 139, 140, 141, 145, 146, 167, 186, 189, 199, 200, 203, 206, 207, 214, 224, 225, 226, 233, 236, 242], "perform": [8, 10, 12, 49, 52, 65, 70, 75, 76, 79, 99, 105, 112, 116, 137, 170, 226], "number": [8, 236], "instruct": [8, 43, 45, 57, 61, 65, 118, 123, 130, 133, 141, 143, 144, 145, 147, 151, 159, 161, 165, 169, 187, 188, 198, 218], "new": [8, 11, 146, 196, 211], "object": [8, 71, 97, 101, 140, 147, 191, 194, 196, 197, 200, 201, 225, 230], "environ": [8, 9, 21, 29, 47, 54, 79, 101, 133], "we": 8, "push": [8, 123], "the": [8, 10, 12, 13, 19, 21, 36, 45, 49, 58, 64, 65, 66, 68, 70, 75, 76, 81, 83, 84, 90, 98, 100, 103, 105, 121, 123, 125, 130, 132, 133, 143, 147, 153, 155, 165, 166, 175, 177, 183, 184, 195, 196, 201, 217, 218, 226, 233], "result": [8, 11, 16, 18, 49, 50, 51, 52, 53, 54, 58, 59, 62, 63, 64, 68, 70, 75, 78, 79, 80, 85, 117, 118, 120, 127, 130, 135, 136, 143, 144, 147, 161, 165, 166, 171, 172, 174, 182, 214, 218, 223, 225, 226, 227, 228, 237, 240, 241], "further": [8, 54, 69], "by": [8, 45, 79, 95, 117, 131, 135, 143, 155, 158, 176, 225], "incorpor": 8, "heterogen": [8, 32], "sourc": [8, 27, 49, 60, 133, 174, 211], "such": 8, "as": [8, 9, 10, 19, 54, 78, 85, 126, 138, 223, 240], "simul": [8, 47], "or": [8, 83], "from": [8, 17, 70, 127, 130, 133, 165, 175, 186, 214, 225, 227, 229, 242], "differ": [8, 53, 55, 70, 75, 79, 127, 155, 230], "how": [8, 70, 132], "do": [8, 54, 65], "various": [8, 102], "method": [8, 35, 49, 67, 79, 81, 102, 118, 130, 133, 135, 151, 152, 173, 174, 195, 201, 214, 225, 226, 227, 228, 229, 237], "long": [8, 17, 62, 63, 64, 137, 152, 188, 189, 205, 211, 242], "horizon": 8, "scenario": [8, 52, 102, 224], "chang": [8, 55], "vari": 8, "amount": [8, 158], "quantiti": 8, "divers": [8, 69, 107, 152, 214], "futur": [8, 16, 19, 65, 79, 96, 112, 113, 127, 133, 136, 137, 138, 167, 211, 218, 228, 236], "card": [8, 56], "collect": [8, 17, 52, 54, 57, 69, 71, 72, 75, 85, 130, 240], "select": [8, 214, 226], "ablat": [8, 18, 19, 60, 62, 67, 102, 122, 134, 137, 140, 143, 144, 147, 161, 165, 166, 195, 201, 218, 225, 228], "2312": [9, 45, 129, 149, 162, 211, 225], "13771_appag": 9, "smartphon": 9, "user": [9, 46, 47, 130], "action": [9, 12, 17, 18, 19, 79], "space": [9, 16, 17, 18, 35, 79], "explor": [9, 29, 85, 143], "phase": [9, 239], "deploy": [9, 124, 149, 164, 168], "2401": [10, 92, 183, 212, 238], "10935_seeclick": 10, "har": 10, "gui": [10, 12, 16, 17, 19, 155], "ground": [10, 17, 155, 165, 172, 197, 226, 229], "advanc": [10, 149, 154, 211], "visual": [10, 53, 54, 67, 155, 158, 159, 160, 161, 162, 164, 166, 168, 172, 195, 201, 225, 226, 227, 229], "autonom": [10, 32, 146], "navig": [10, 11, 14], "vision": [10, 11, 160, 163, 165, 169, 171, 172, 174, 190, 225, 242], "languag": [10, 11, 22, 27, 30, 39, 41, 43, 45, 46, 48, 49, 50, 51, 52, 53, 57, 64, 72, 74, 76, 77, 78, 91, 92, 96, 100, 101, 102, 106, 111, 118, 122, 130, 137, 138, 139, 140, 141, 143, 144, 145, 146, 160, 162, 163, 165, 168, 171, 172, 173, 174, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 203, 206, 207, 211, 218, 219, 236, 237, 240, 242], "approach": [10, 98, 127, 137, 161, 168, 169, 174, 175, 211, 214, 230], "lvlms": 10, "construct": [10, 43, 45, 46, 50, 51, 52, 53, 58, 70, 171, 172, 228], "train": [10, 11, 17, 43, 48, 50, 67, 69, 85, 95, 98, 104, 105, 106, 107, 108, 109, 111, 117, 120, 121, 122, 123, 133, 138, 139, 140, 142, 143, 144, 145, 147, 149, 152, 155, 159, 160, 162, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 176, 178, 181, 182, 184, 187, 188, 189, 197, 225, 226, 227, 229, 240, 241], "screenspot": 10, "benchmark": [10, 11, 12, 16, 38, 45, 46, 49, 50, 51, 52, 55, 56, 57, 59, 60, 62, 63, 64, 68, 69, 70, 71, 75, 76, 77, 78, 79, 85, 116, 127, 144, 146, 147, 149, 158, 161, 171, 172, 182, 188, 211, 237, 238], "on": [10, 18, 19, 48, 50, 54, 56, 58, 75, 76, 78, 81, 98, 109, 111, 118, 122, 124, 127, 130, 141, 143, 144, 146, 147, 162, 164, 174, 182, 219, 224, 227, 237, 242], "miniwob": 10, "aitw": 10, "android": 10, "in": [10, 11, 12, 16, 17, 19, 30, 35, 37, 39, 42, 47, 50, 64, 65, 72, 76, 79, 84, 97, 102, 104, 106, 118, 119, 120, 133, 138, 141, 147, 149, 151, 155, 161, 166, 188, 201, 204, 205, 211, 226, 241, 242], "wild": [10, 147], "mind2web": 10, "seeclick": 10, "unifi": [10, 17, 19, 96, 144, 166, 191, 241], "pre": [10, 121, 133, 138, 142, 143, 146, 155, 160, 162, 164, 165, 169, 173, 175, 176, 178, 182, 184, 187, 188, 189, 197], "configur": [10, 11, 64, 171, 172], "human": [10, 49, 53, 54, 56, 63, 70, 79, 80, 81, 85, 129, 130, 133, 137, 139, 140, 158, 181, 202, 208, 237], "sampl": [10, 102, 155, 169, 218, 219, 223], "showcas": 10, "case": [10, 12, 18, 79, 85, 101, 155, 158, 172, 217, 230, 238], "studi": [10, 12, 18, 85, 102, 122, 134, 140, 144, 158, 166, 172, 195, 201, 217, 218, 226, 228], "error": [10, 16, 53, 64, 65, 68, 80, 233], "downstream": [10, 211, 225], "formul": [10, 18, 50, 138, 140], "2402": [11, 12, 31, 51, 62, 63, 93, 94, 199], "04615_screenai": 11, "infograph": 11, "understand": [11, 45, 65, 74, 76, 89, 127, 145, 149, 150, 152, 155, 160, 163, 166, 172, 175, 176], "methodolog": [11, 68, 98, 117, 118, 125, 130, 142, 160, 182, 219, 236, 239], "architectur": [11, 13, 17, 24, 32, 97, 101, 140, 142, 143, 145, 149, 155, 159, 160, 164, 165, 168, 169, 171, 172, 174, 182, 188, 189, 195, 217, 220, 229, 242], "stage": [11, 17, 104, 143, 171, 172, 182, 184, 189, 240, 242], "screen": 11, "llms": [11, 19, 51, 53, 55, 56, 59, 65, 68, 78, 102, 122, 123, 124, 125, 127, 162, 165, 239, 242], "addit": [11, 50, 64, 67, 70, 77, 85, 127, 130, 137, 166, 174, 175, 226, 227, 229, 236], "mixtur": [11, 103, 156, 157, 185], "pretrain": [11, 106, 181, 240, 241], "fine": [11, 45, 48, 50, 58, 61, 85, 92, 96, 117, 133, 144, 147, 151, 155, 160, 165, 168, 175, 176, 180, 187, 188, 205, 211, 226, 240], "tune": [11, 17, 48, 50, 61, 85, 88, 89, 90, 92, 96, 127, 133, 144, 147, 151, 155, 159, 160, 161, 165, 168, 175, 176, 180, 187, 188, 198, 211, 218, 220, 239, 240], "definit": [11, 79, 229, 240], "schema": [11, 164], "llm": [11, 12, 13, 28, 31, 35, 39, 43, 47, 50, 52, 57, 58, 59, 60, 63, 64, 67, 70, 77, 79, 85, 86, 87, 95, 102, 118, 119, 122, 124, 129, 132, 134, 135, 152, 162, 166, 167, 181, 182, 208, 211, 214, 216, 218, 219, 230, 236, 240, 241, 242], "content": [11, 61, 143], "contain": 11, "singl": [11, 62, 65, 68, 195, 229], "element": [11, 214], "multipl": [11, 118, 119, 230], "complex": [11, 16, 18, 112, 155], "repositori": 11, "07939_ufo": 12, "focus": [12, 214], "window": [12, 214, 227], "os": [12, 98, 242], "interact": [12, 17, 46, 145, 146, 171, 172], "base": [12, 17, 18, 50, 52, 58, 68, 98, 102, 118, 127, 129, 140, 141, 143, 151, 152, 158, 172, 175, 187, 188, 217, 218, 219, 224, 226, 240, 242], "ufo": 12, "nutshel": 12, "hostag": [12, 19], "appag": [12, 19], "special": [12, 19, 56, 181], "mode": [12, 53, 144, 189], "custom": [12, 146], "filter": [12, 43, 69, 143, 169, 174, 216, 240], "plan": [12, 24, 45], "reflect": [12, 17, 18, 24, 63, 214], "safeguard": [12, 129], "lesson": 12, "2403": [13, 52, 95, 96, 150, 163, 213], "16971_aio": 13, "oper": [13, 14, 16, 19, 39, 73, 79, 242], "kernel": [13, 102, 112, 117, 118, 226], "relationship": [13, 214], "connect": 13, "between": [13, 49, 75, 113], "modul": [13, 16, 18, 53, 201, 211, 227], "core": [13, 17], "schedul": [13, 97, 101, 102, 104, 107], "context": [13, 36, 62, 64, 65, 138, 141, 150, 151, 152, 188, 211, 214, 236], "manag": [13, 16, 101, 102, 104], "memori": [13, 17, 24, 39, 63, 95, 97, 98, 101, 102, 104, 108, 112, 122, 123, 229, 236, 240, 242], "storag": [13, 240], "access": [13, 236], "sdk": 13, "rq1": [13, 217], "appendix": [13, 16, 43, 45, 47, 49, 50, 51, 52, 53, 54, 56, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 72, 75, 76, 77, 78, 85, 101, 112, 117, 118, 122, 130, 139, 152, 158, 165, 166, 171, 172, 174, 175, 182, 214, 217, 218, 225, 226, 227, 229, 236, 237, 238, 239, 240], "discuss": [13, 19, 45, 50, 56, 68, 70, 74, 75, 78, 80, 85, 97, 113, 119, 122, 123, 130, 136, 143, 149, 158, 174, 182, 189, 211, 214, 225, 229], "2futur": 13, "direct": [13, 112, 113, 127, 133, 225, 240], "2406": [14, 46, 140, 151, 186, 216, 226], "01014_mobil": 14, "v2": [14, 101, 185], "devic": [14, 124], "assist": [14, 16, 78, 159, 202], "effect": [14, 19, 36, 55, 64, 76, 104, 107, 132, 172], "via": [14, 28, 30, 116, 125, 132, 137, 138, 147], "multi": [14, 16, 18, 19, 26, 28, 29, 36, 38, 49, 58, 60, 62, 63, 64, 65, 69, 75, 85, 106, 136, 139, 143, 144, 146, 147, 160, 201, 211, 216, 225, 227, 229, 238], "collabor": [14, 18, 26, 29, 32, 49, 208], "2411": [15, 72, 167, 201], "02059_tablegpt2": 15, "tabular": 15, "integr": [15, 19], "2501": [16, 17, 56, 80, 145], "11733_mobil": 16, "self": [16, 52, 127, 135, 147, 214, 218], "evolv": 16, "hierach": 16, "framework": [16, 17, 18, 26, 38, 48, 78, 87, 96, 97, 139, 152, 166, 174, 176, 219, 226], "evolut": [16, 17, 97], "foundat": [16, 37, 75, 143, 146, 179, 180, 182], "full": [16, 69, 146], "trajectori": 16, "comparison": [16, 19, 51, 52, 60, 75, 76, 112, 127, 133, 137, 144, 155, 166, 175, 195, 201, 214, 227], "previous": 16, "sota": 16, "recoveri": [16, 225], "escal": 16, "remain": 16, "all": [16, 32, 52, 58, 98, 128, 186], "eval": [16, 18, 45, 62, 75, 130, 147], "atom": [16, 205], "list": 16, "shortcut": 16, "tip": 16, "12326_ui": 17, "tar": 17, "pioneer": 17, "nativ": [17, 169], "path": [17, 43, 68, 219], "modular": [17, 144, 211], "activ": [17, 18, 98, 124], "lifelong": 17, "prospect": [17, 211], "capabl": [17, 45, 77, 78, 118, 147, 149, 161, 168, 188], "percept": [17, 18, 57], "reason": [17, 30, 45, 65, 68, 133, 154, 155, 169, 181, 189, 219], "enhanc": [17, 35, 55, 145, 169], "trace": [17, 64, 65], "improv": [17, 54, 60, 83, 118, 161, 176, 216, 226], "abil": [17, 53, 58, 76, 152], "infus": 17, "enrich": 17, "tutori": 17, "stimul": 17, "thought": [17, 75, 76], "augment": [17, 39, 134, 210, 211, 212, 215, 217, 218, 236, 238, 239, 240], "prior": [17, 155, 224, 228], "term": [17, 63, 242], "onlin": [17, 188], "bootstrap": [17, 165, 173], "dpo": [17, 142, 184, 240], "2502": [18, 169, 231], "14282_pc": 18, "hierarch": [18, 38, 68, 143, 158, 223], "pc": 18, "dynam": [18, 97, 116, 169], "decis": 18, "make": [18, 224], "2504": [19, 37, 127, 128, 154, 219], "14603_ufo2": 19, "desktop": 19, "agento": 19, "rpa": 19, "cua": 19, "ufo2": 19, "background": [19, 102, 104, 106, 107, 112, 113, 116, 117, 118, 119, 121, 123, 133, 138, 139, 162, 214, 218], "substrat": 19, "level": [19, 50, 56, 61, 62, 71, 75, 82, 102, 130, 164, 217], "orchestr": 19, "execut": [19, 32, 35, 48, 49, 50, 52, 101, 102, 112], "applic": [19, 28, 68, 97, 101, 102, 118, 139, 151, 174, 225, 242], "runtim": [19, 101, 104, 228, 229], "hybrid": [19, 155, 211], "detect": [19, 191, 194, 197, 200, 214, 224, 233], "api": [19, 23, 43, 45, 46, 101, 130], "continu": [19, 88, 240], "knowledg": [19, 117, 155, 210, 218, 219, 240], "specul": [19, 133], "pictur": 19, "interfac": [19, 105, 242], "pip": 19, "implement": [19, 43, 45, 63, 98, 102, 104, 112, 113, 118, 161, 165, 166, 195, 201, 227, 229, 233], "engin": [19, 49, 50, 204, 219], "success": [19, 79], "rate": [19, 43, 55, 56, 143, 169], "effici": [19, 90, 94, 95, 96, 102, 104, 105, 108, 112, 117, 118, 122, 123, 161, 168, 179, 185], "comput": [19, 67, 75, 79, 96, 97, 110, 132, 236, 240, 242], "use": [19, 41, 75, 81, 83, 105, 106, 111, 141, 199, 216, 238], "2210": [20, 101, 121], "03629_react": 20, "2303": [21, 22, 23, 42, 139, 148], "08268_chat": 21, "11366_reflexion": 22, "verbal": 22, "reinforc": [22, 126, 127, 133, 144, 147, 154, 155, 188], "16434_taskmatrix": 23, "2304": [24, 159, 198, 204], "03442_gener": 24, "retriev": [24, 36, 45, 50, 64, 65, 211, 212, 215, 217, 219, 227, 236, 238, 239, 240, 242], "react": [24, 43], "2307": [25, 43, 58, 59, 77, 113, 180, 207, 208], "07924_chatdev": 25, "communic": [25, 98], "softwar": [25, 49, 50, 54, 79], "develop": [25, 50, 54, 149], "2308": [26, 27, 28, 29, 160, 174], "00352_metagpt": 26, "meta": [26, 61, 127, 216], "program": [26, 48, 49, 97, 183], "04026_agentsim": 27, "sandbox": [27, 48], "08155_autogen": 28, "enabl": [28, 206], "next": [28, 76, 155], "gen": 28, "convers": [28, 32, 47, 63, 129, 136], "10848_agentvers": 29, "facilit": [29, 43], "emerg": [29, 76, 97, 119, 241], "behavior": [29, 133], "2310": [30, 50, 161, 182], "06117_step": 30, "back": 30, "take": 30, "step": [30, 45, 49, 98, 131, 155, 230], "evok": 30, "18679_metagpt_di": 31, "interpret": [31, 53], "2407": [32, 53, 65, 141, 142, 152, 187, 240], "07061_ioa": 32, "internet": 32, "weav": 32, "ioa": 32, "key": [32, 46, 75, 207], "mechan": 32, "registr": [32, 227], "nest": 32, "team": [32, 149], "format": [32, 120, 155, 160, 161], "flow": [32, 141, 144], "assign": 32, "put": [32, 97], "it": 32, "togeth": [32, 97], "08435_ada": [33, 34], "workflow": 34, "introduc": [34, 36], "2410": [35, 36, 54, 55, 143, 157, 166, 217, 218], "17238_sela": 35, "tree": [35, 116, 133], "search": [35, 102, 133, 155, 204], "machin": [35, 49, 81, 97, 104, 105], "insight": [35, 98], "propos": [35, 132], "pipelin": [35, 61, 63, 98, 104, 105, 107, 108, 146, 147, 169], "code": [35, 48, 49, 51, 52, 53, 55, 56, 68, 139, 155, 181, 183], "21012_fact": 36, "examin": 36, "iter": [36, 155, 211, 228], "rewrit": 36, "fact": 36, "01990_advanc": 37, "challeng": [37, 65, 102, 106, 117, 133, 224], "2506": [38, 47, 61, 171, 172], "12508_agentorchestra": 38, "purpos": 38, "solv": [38, 42, 66, 67], "agentorchestra": 38, "2505": [39, 146, 147, 155, 189, 241], "22101_memo": 39, "mag": 39, "version": 39, "memo": [39, 242], "philosophi": [39, 101, 242], "memcub": [39, 242], "2205": [40, 112, 195], "00445_mrkl": 40, "2302": [41, 179], "04761_toolform": 41, "teach": [41, 203], "themselv": 41, "17580_hugginggpt": 42, "chatgpt": [42, 75], "its": 42, "friend": [42, 117], "hug": 42, "face": 42, "16789_toolllm": 43, "master": 43, "16000": 43, "toolllm": 43, "toolbench": 43, "toolllama": 43, "toolev": 43, "dfsdt": 43, "main": [43, 53, 58, 241], "apibench": 43, "ood": 43, "rapidapi": 43, "respons": [43, 68, 149, 161, 207], "compress": [43, 124, 143, 164, 168, 240], "pass": [43, 46, 47, 56, 112, 113], "win": 43, "solut": [43, 55, 67, 226], "qa": [44, 62, 64, 71], "14033_t": 45, "util": 45, "decomposit": 45, "grain": [45, 58, 117, 205], "protocol": 45, "summari": [45, 75, 82, 84, 121, 214], "q1": 45, "q2": 45, "q3": 45, "review": [45, 122], "document": [45, 61, 155, 158, 234], "12045_": 46, "bench": [46, 47, 50, 54, 55, 59, 85], "ool": 46, "gent": 46, "ser": 46, "polici": [46, 47, 97, 133, 149], "domain": [46, 47, 54, 157, 224], "characterist": [46, 73, 113, 158, 231], "gpt": [46, 61, 70, 75, 77, 89, 117, 130, 159, 164, 175, 177, 182, 218, 228, 238], "4o": [46, 61], "disscuss": 46, "07982_": 47, "dual": [47, 217], "tau": 47, "dec": 47, "pomdp": 47, "persona": [47, 63], "broader": [47, 48, 54, 63, 119], "impact": [47, 48, 50, 61, 63, 65, 70, 76, 102, 119, 143, 149], "telecom": 47, "verifi": [47, 55, 67, 131, 132, 203, 204], "origin": [47, 49], "retail": 47, "airlin": 47, "2107": 48, "03374_humanev": 48, "function": [48, 55, 231], "correct": [48, 212], "humanev": [48, 51], "hand": 48, "written": [48, 130], "supervis": [48, 135, 137, 141, 144, 147, 160, 165, 175, 176, 187, 188, 240], "docstr": 48, "hazard": 48, "induct": 48, "synthesi": [48, 49, 139, 144, 145, 223], "07732_mbpp": 49, "python": [49, 53], "most": 49, "basic": [49, 233], "mbpp": 49, "mathqa": 49, "bleu": [49, 81, 82, 84], "compar": [49, 56, 102, 137], "edit": [49, 63], "constraint": 49, "more": [49, 53, 55, 58, 132, 168, 181, 182, 201, 227, 241], "common": [49, 64, 82, 116], "sibl": 49, "risk": 49, "10": [49, 68, 98, 102, 155, 228], "06770_swe": 50, "resolv": 50, "github": 50, "issu": [50, 55], "swe": [50, 54, 55], "featur": [50, 105, 119, 130, 158, 175, 201, 226, 229], "lite": [50, 55], "llama": [50, 75, 145, 182, 218], "codellama": 50, "statement": [50, 56, 226], "reproduc": [50, 133], "high": [50, 99, 130, 149, 151], "valid": [50, 54, 75, 113, 121, 174, 224], "procedur": [50, 175], "test": [50, 52, 54, 67, 68, 69, 74, 132, 182], "character": 50, "oracl": 50, "societ": [50, 61], "depth": [50, 143, 155, 225], "16694_humanev": 51, "xl": 51, "multilingu": [51, 105, 137, 141, 147, 155], "cross": [51, 53, 139], "lingual": [51, 139], "natur": [51, 100, 139], "principl": [51, 75, 127], "pls": 51, "nls": 51, "exist": [51, 54, 56, 84, 102, 226], "acknowledg": [51, 75, 151, 155, 236, 239, 240, 241], "comprehens": [51, 55, 57, 59, 77, 160, 214], "07974_livecodebench": 52, "holist": 52, "contamin": 52, "free": [52, 76, 156, 226, 237], "livecodebench": 52, "curat": [52, 149, 211], "platform": [52, 124], "specif": [52, 176], "repair": 52, "output": [52, 65, 129, 160, 167, 218], "predict": [52, 76, 135, 195, 226, 229], "avoid": 52, "licens": [52, 158], "qualit": [52, 79, 123, 138, 155, 161, 162, 166, 225, 226, 228, 229, 241], "10499_cibench": 53, "your": [53, 58, 64, 139, 164], "plugin": 53, "cibench": 53, "topic": [53, 83], "candid": [53, 81], "refin": [53, 132], "debug": 53, "difficulti": [53, 71, 76, 79, 122], "categori": [53, 61, 77, 85], "demo": 53, "subject": [53, 76, 140], "03859_swe": 54, "split": [54, 75, 143], "statist": [54, 68, 79, 82, 143, 214], "inconsist": 54, "resourc": [54, 75, 101], "agentless": 54, "aider": 54, "autocoderov": 54, "moatless": 54, "analys": [54, 105, 171, 172, 227], "imag": [54, 61, 63, 105, 149, 155, 160, 165, 170, 173, 174, 226], "categor": 54, "is": [54, 58, 128, 162], "represent": [54, 118, 135, 158, 223, 234], "text": [54, 61, 81, 137, 138, 140, 141, 143, 144, 145, 146, 147, 149, 158, 160, 170, 171, 172, 195, 201, 205, 206, 217, 239], "necess": 54, "scope": [54, 101], "06992_swe": 55, "robust": [55, 137, 211, 224], "critic": 55, "leak": 55, "incorrect": 55, "fix": 55, "file": 55, "incomplet": 55, "updat": [55, 83, 155, 162], "resolut": [55, 101, 165, 169], "build": [55, 78, 97, 207], "awar": [55, 112, 124, 144, 158, 225, 226], "01257_codeforc": 56, "competit": 56, "codeforc": 56, "elo": 56, "contribut": [56, 75, 155, 226], "decod": [56, 102, 145, 201], "hyperparamet": [56, 67, 165], "our": [56, 78, 226], "calcul": [56, 67], "demonstr": [56, 68], "judg": [56, 85], "2306": [57, 76, 85, 124], "13394_mme": 57, "mme": 57, "suit": [57, 75], "cognit": 57, "06281_mmbench": 58, "modal": [58, 60, 63, 149, 171, 211], "around": 58, "player": 58, "mmbench": 58, "strategi": [58, 69, 72, 76, 97, 126, 133, 137, 156, 184], "involv": [58, 79], "choic": [58, 68, 76, 224], "extract": [58, 64, 201, 214, 216, 219], "circularev": 58, "about": [58, 117, 133], "leaf": 58, "16125_seed": 59, "seed": [59, 147, 152], "2311": [60, 71, 78, 237], "12793_sharegpt4v": 60, "better": [60, 65, 113, 192], "caption": [60, 160], "sharegpt4v": 60, "pt": 60, "7b": [60, 182], "sft": [60, 130, 142, 144, 152, 155, 162, 164, 181, 240], "quantit": [60, 80, 162], "dialogu": [60, 63, 143, 145, 167], "18095_sharegpt": 61, "align": [61, 143, 145, 146, 172, 181, 225, 237, 240], "sharegpt": 61, "janus": [61, 166], "mllms": [61, 164], "exponenti": 61, "decay": 61, "distribut": [61, 76, 97, 102, 109, 130, 132, 158, 182, 234], "first": 61, "05136_lv": 62, "balanc": [62, 156], "length": [62, 64, 68, 81, 158, 165, 218, 236], "up": [62, 97, 122, 147, 162, 240], "256k": 62, "lv": 62, "techniqu": [62, 96, 102], "hop": [62, 64, 69, 216, 238], "17753_locomo": 63, "veri": 63, "locomo": [63, 242], "tempor": [63, 143, 155, 168], "event": 63, "graph": [63, 97, 215, 217, 219, 225, 228, 239], "respond": 63, "share": [63, 101, 102, 158], "reaction": 63, "verif": [63, 67, 72], "dialog": 63, "minigpt": 63, "2404": [64, 79, 184, 214], "06654_ruler": 64, "what": [64, 199, 226], "size": [64, 76, 98, 102, 130, 147, 158], "ruler": 64, "needl": [64, 65], "haystack": 64, "niah": 64, "variabl": 64, "track": [64, 228, 229], "vt": 64, "word": [64, 67, 158], "cwe": 64, "frequent": 64, "fwe": 64, "aggreg": [64, 226], "correl": [64, 76], "templat": [64, 85, 127, 218], "mk": 64, "mv": 64, "mq": 64, "passkey": 64, "vanilla": 64, "11963_needlebench": 65, "inform": [65, 70, 199, 208, 240], "dens": [65, 187, 225, 226, 227, 228], "needlebench": 65, "spars": [65, 103, 112, 240], "language_": 65, "which": 65, "under": [65, 70], "bilingu": [65, 68, 81, 182], "scenario_": 65, "ancestr": 65, "think": [65, 154, 189], "follow": [65, 130, 159, 161], "partial": 65, "repetit": 65, "hallucin": [65, 155, 161], "2103": [66, 89], "03874_math": 66, "measur": [66, 70, 72, 74, 76, 82, 83], "mathemat": [66, 68, 181], "math": [66, 67, 68, 123, 181], "2110": [67, 116], "14168_gsm8k": 67, "finetun": [67, 123, 143, 240], "time": [67, 127, 132, 143, 146, 165, 169, 191, 196, 200, 227, 228], "regular": [67, 76], "2405": [68, 185, 200, 215, 239], "12209_mathbench": 68, "theori": [68, 123, 240], "profici": 68, "mathbench": 68, "overal": [68, 195], "accuraci": [68, 73, 80, 118, 194], "extra": 68, "english": [68, 75, 137], "chines": [68, 75, 76, 77, 158, 178, 237], "type": 68, "misunderstand": 68, "concept": [68, 101], "flaw": 68, "misalign": 68, "exceed": 68, "max": 68, "constrain": 68, "option": [68, 75], "non": [68, 98, 116, 138, 140, 224], "adher": 68, "small": [68, 184], "chat": [68, 145, 180], "1809": 69, "09600_hotpotqa": 69, "explain": 69, "medium": 69, "wiki": 69, "invert": 69, "index": [69, 211, 217, 220, 239], "dev": 69, "2109": 70, "07958_truthfulqa": 70, "mimic": 70, "falsehood": 70, "truthfulqa": 70, "vs": [70, 78, 81, 82, 112, 116, 123, 133, 134, 182, 211, 224, 228], "175b": [70, 118], "temperatur": 70, "paraphras": 70, "refer": [70, 81, 101, 160, 237], "truth": 70, "check": 70, "disagr": 70, "12022_gpqa": 71, "graduat": 71, "proof": [71, 112], "gpqa": 71, "04368_simpleqa": 72, "form": [72, 137, 152, 205], "factual": [72, 123, 149, 205], "calibr": [72, 80, 158, 228], "100": [72, 96], "guess": 72, "score": [72, 73, 84, 85, 218], "precis": [73, 81, 82, 115, 205], "recal": [73, 81, 82, 123], "f1": [73, 165], "confus": 73, "matrix": [73, 118, 119], "roc": 73, "receiv": 73, "curv": 73, "2009": 74, "03300_mmlu": 74, "massiv": [74, 76, 105], "multitask": [74, 76, 137, 177], "2305": [75, 123, 131, 205, 206, 236], "08322_c": 75, "disciplin": 75, "eval_": 75, "hard": 75, "doe": 75, "few": [75, 85], "shot": [75, 85, 136, 137, 138, 139, 140, 141, 147, 151], "help": [75, 124, 162], "chain": [75, 76], "orient": [75, 160], "author": [75, 151], "stat": 75, "explan": 75, "being": [75, 76], "claud": 75, "bloomz": 75, "mt": [75, 85], "glm": [75, 145, 186], "130b": [75, 186], "chatglm": 75, "6b": 75, "alpaca": 75, "moss": 75, "breakdown": [75, 76, 118, 228], "observ": [75, 79, 101], "bias": [75, 85, 120, 130, 151], "09212_cmmlu": 76, "cmmlu": 76, "concurr": 76, "shown": 76, "estim": [76, 225, 226, 228, 240], "perplex": 76, "express": [76, 160], "match": [76, 141, 144, 225, 226, 228], "algorithmsl": 76, "other": [76, 102, 162, 238], "cot": [76, 189], "15020_superclu": 77, "superclu": 77, "carena": 77, "close": 77, "12983_gaia": 78, "gaia": 78, "composit": [78, 161, 182], "extend": [78, 98, 174, 218, 225], "descript": [78, 84, 236], "07972_osworld": 79, "osworld": 79, "infrastructur": [79, 149, 155, 182, 242], "vlm": [79, 162, 165], "feasibl": 79, "varianc": 79, "across": [79, 104, 150], "failur": [79, 101, 155, 158], "14249_hle": 80, "last": 80, "exam": 80, "count": [80, 101, 155, 165], "02xx": 81, "xxxxx_bleu": 81, "translat": [81, 105, 137, 139, 145], "modi": 81, "ed": 81, "gram": [81, 82, 84], "modifi": 81, "block": [81, 97, 102, 112, 116, 123, 134, 195, 236], "rank": [81, 91, 93, 94, 95, 123, 239], "onli": [81, 115, 122, 137, 143, 191], "combin": [81, 133, 149, 195], "themodi": 81, "sentenc": [81, 82, 234], "troubl": 81, "breviti": 81, "penalti": 81, "monolingu": [81, 147], "group": [81, 101, 140, 236], "pairwis": [81, 82, 225], "judgment": 81, "0401": 82, "xxxxx_roug": 82, "packag": 82, "roug": [82, 83], "co": [82, 227], "occurr": 82, "jackknif": 82, "longest": 82, "subsequ": 82, "lcs": 82, "normal": [82, 120, 137, 145, 147, 229], "weight": [82, 93, 107, 115, 122, 124, 125, 165], "skip": 82, "bigram": 82, "su": 82, "1803": 83, "01937_rouge2": 83, "current": 83, "captur": 83, "synonym": 83, "nn": [83, 119], "topicuniq": 83, "subset": 83, "coverag": 83, "1804": [84, 193], "08771_sacrebleu": 84, "call": 84, "clariti": 84, "report": [84, 142, 148, 155, 170, 181, 187], "way": 84, "forward": [84, 112, 113, 134], "parsev": 84, "script": 84, "sacrebleu": 84, "05685_judg": 85, "chatbot": [85, 123, 159, 165], "arena": [85, 165], "turn": [85, 147], "agreement": [85, 237], "prefer": [85, 151, 240], "standard": [85, 112, 113, 123, 137], "posit": [85, 115, 223, 236], "wise": [85, 116, 123], "vicuna": 85, "zero": [85, 98, 136, 137, 138, 139, 140, 141, 147, 151], "nlp": [86, 130, 210], "moe": [86, 184, 187, 188], "2101": 88, "00190_prefix": 88, "optim": [88, 96, 97, 98, 102, 105, 116, 117, 123, 125, 132, 141, 143, 147, 194, 201, 211, 223, 225, 230, 240], "10385_p": 89, "too": 89, "2104": [90, 111], "08691_prompt": 90, "power": 90, "paramet": [90, 98, 106, 123, 132, 143, 225, 240], "2106": [91, 135], "09685_lora": 91, "low": [91, 93, 94, 95, 123, 151, 167], "adapt": [91, 93, 94, 123, 136, 164, 211], "01335_self": 92, "play": [92, 146], "convert": 92, "weak": [92, 137, 189], "strong": [92, 185, 189], "09353_dora": 93, "decompos": 93, "12354_lora": 94, "03507_galor": 95, "gradient": [95, 98, 125, 133, 199, 230], "project": [95, 133, 228], "13372_llamafactori": 96, "llamafactori": 96, "loader": 96, "worker": [96, 101], "trainer": 96, "1712": 97, "05889_ray": 97, "motiv": [97, 152], "requir": [97, 123], "layer": [97, 103, 104, 117, 218, 240, 242], "global": [97, 101, 214, 225, 227], "store": [97, 101], "gcs": 97, "bottom": 97, "everyth": 97, "microbenchmark": [97, 102], "rl": [97, 151, 152, 189], "proxim": 97, "dataflow": [97, 220], "actor": [97, 101], "1910": 98, "02054_deepspeed_zero": 98, "trillion": 98, "parallel": [98, 102, 104, 105, 106, 107, 108, 109, 113], "reduc": 98, "where": 98, "did": 98, "go": 98, "state": [98, 100, 116, 123, 155, 165, 166, 195, 196, 201], "residu": 98, "consumpt": 98, "dp": 98, "deep": [98, 99, 106, 120, 175, 224], "dive": 98, "into": [98, 147, 153, 218], "p_": 98, "partit": [98, 104, 107, 113], "p_g": 98, "p_p": 98, "implic": 98, "p_a": 98, "checkpoint": 98, "c_b": 98, "constant": 98, "buffer": 98, "m_d": 98, "defragment": 98, "volum": [98, 223], "11": [98, 155, 228], "conclud": 98, "remark": [98, 240], "pytorch": 99, "imper": 99, "style": [99, 145], "art": [100, 123, 155, 165, 166, 195, 196, 201], "xx_ray": 101, "goal": 101, "ray": [101, 228], "compon": 101, "node": 101, "head": [101, 106, 226, 229, 240], "ownership": 101, "lifetim": 101, "fate": 101, "handl": 101, "spill": 101, "depend": 101, "borrow": 101, "fulfil": 101, "placement": 101, "death": 101, "servic": [101, 102], "metadata": [101, 216], "fault": 101, "toler": 101, "cluster": [101, 111, 135], "autoscal": 101, "job": 101, "submiss": 101, "multiten": 101, "kuberay": 101, "diagram": [101, 155], "2309": [102, 125, 181], "06180_vllm": 102, "serv": 102, "pagedattent": 102, "autoregress": [102, 138, 140, 143, 174], "batch": [102, 107], "kv": [102, 236, 242], "cach": [102, 236], "vllm": 102, "beam": 102, "prefix": 102, "preemption": 102, "support": [102, 203], "recomput": [102, 112], "swap": 102, "1701": 103, "06538_moe": 103, "outrag": 103, "neural": [103, 105, 106, 138, 139, 140, 223, 231], "network": [103, 105], "gate": 103, "expert": [103, 156, 157, 185], "1806": 104, "03377_pipedream": 104, "fast": [104, 112, 217, 226], "dnn": [104, 107, 108], "pipedream": [104, 107], "gpu": [104, 111, 112, 118], "1811": [105, 230], "06965_gpipe": 105, "giant": [105, 110], "gpipe": 105, "classif": 105, "trade": [105, 118], "off": [105, 118], "1909": 106, "08053_megatron": 106, "lm": [106, 111, 144, 182], "billion": 106, "attent": [106, 112, 113, 158, 218, 236, 241], "mlp": 106, "19xx_pipedream": 107, "intra": 107, "inter": [107, 227], "hardwar": [107, 112, 113, 117], "stash": 107, "vertic": 107, "stale": 107, "2006": [108, 109, 110], "09503_pipedream": 108, "2bw": 108, "15704_pytorch": 109, "acceler": [109, 118, 124, 242], "16668_gshard": 110, "condit": [110, 138, 141, 155, 165], "shard": 110, "04473_effici": 111, "megatron": 111, "14135_flashattent": 112, "exact": 112, "io": 112, "hierarchi": 112, "fusion": [112, 172, 189, 219, 228], "hbm": 112, "flashattent": [112, 113], "extens": [112, 151, 236], "tile": 112, "backward": [112, 113], "rabe": 112, "staat": 112, "08691_flashattent": 113, "faster": [113, 192], "warp": 113, "empir": [113, 120, 158, 161], "tf32": 115, "tensorfloat": 115, "32": [115, 116], "bf16": 115, "brain": 115, "float": 115, "16": [115, 155], "fp16": 115, "ieee": 115, "half": 115, "fp8": [115, 120, 168], "int8": [115, 117, 119, 122], "int4": 115, "quantiz": [115, 116, 117, 118, 121, 122, 123, 124, 125, 138, 143], "02861_bitsandbyt": 116, "bit": [116, 119, 123], "linear": [116, 119, 230], "2206": [117, 118], "01861_zeroqu": 117, "afford": 117, "qat": 117, "ptq": 117, "zeroqu": 117, "bert": [117, 175], "scheme": 117, "distil": [117, 189, 230, 231, 232], "cost": [117, 240], "lkd": 117, "09557_lut": 118, "gemm": 118, "lut": 118, "lms": 118, "bcq": 118, "latenc": [118, 144, 145, 151, 167], "opt": 118, "2208": 119, "07339_llm": 119, "absmax": 119, "zeropoint": 119, "magnitud": 119, "outlier": 119, "bnb": 119, "linear8bitlt": 119, "05433_fp8": 120, "aspect": [120, 158, 211], "usag": 120, "binari": [120, 233], "interchang": 120, "expon": 120, "subnorm": 120, "per": 120, "tensor": 120, "factor": [120, 151], "17323_gptq": 121, "accur": [121, 122], "gptq": 121, "2211": 122, "10438_smoothquant": 122, "smoothquant": 122, "dequant": 122, "speedup": 122, "save": 122, "14314_qlora": 123, "qlora": 123, "normalfloat": 123, "nf4": 123, "doubl": 123, "page": 123, "suggest": 123, "refus": 123, "secret": 123, "keep": 123, "mind": 123, "00978_awq": 124, "awq": 124, "salient": 124, "tinychat": 124, "map": [124, 171, 172, 224, 226], "onto": 124, "edg": 124, "whi": [124, 226], "05516_autoround": 125, "round": 125, "sign": 125, "descent": [125, 230], "1703": 126, "03864_evolut": 126, "scalabl": [126, 141, 144, 184], "02495_deepseek": 127, "grm": 127, "generalist": 127, "reward": [127, 128, 133, 147, 188], "rm": [127, 130], "boost": 127, "critiqu": 127, "spct": 127, "unpin": 127, "vote": 127, "guid": [127, 233], "grms": 127, "13958_toolrl": 128, "need": 128, "06674_llama": 129, "guard": 129, "input": [129, 160, 167, 176], "2203": [130, 203, 224], "02155_train": 130, "feedback": [130, 202], "instructgpt": 130, "public": 130, "label": 130, "illustr": [130, 175, 177], "rlhf": [130, 155, 181, 187], "toxic": [130, 143], "structur": [130, 225, 229], "each": 130, "20050_let": 131, "03314_scale": 132, "be": 132, "than": 132, "2412": [133, 144, 168, 188, 227, 228], "14135_scale": 133, "roadmap": 133, "o1": 133, "perspect": [133, 226, 231], "fromgpt": 133, "initi": [133, 230], "like": 133, "behaviour": 133, "outcom": 133, "shape": [133, 240], "ensembl": [133, 135], "role": [133, 146], "guidanc": [133, 201], "intern": 133, "extern": [133, 240], "sequenti": 133, "revis": 133, "law": [133, 152, 188, 211], "clone": 133, "2005": [134, 210], "08100_conform": 134, "convolut": [134, 224], "speech": [134, 135, 137, 138, 139, 140, 141, 143, 144, 145, 147, 151, 152, 167, 170, 171, 172], "recognit": [134, 137, 145, 152, 155, 158, 195, 201], "conform": 134, "encod": [134, 136, 152, 164, 165, 166, 169, 173, 201, 223], "transduc": 134, "librispeech": [134, 138, 140], "macaron": 134, "feed": 134, "07447_hubert": 135, "mask": [135, 236], "hidden": 135, "unit": 135, "ii": [135, 155, 211, 224], "iii": [135, 211], "iv": [135, 211], "mean": 135, "vi": [135, 211], "2112": [136, 158, 202], "02418_yourtt": 136, "speaker": [136, 139, 144, 147, 151], "tts": [136, 138, 139, 140, 141, 143, 146, 147, 151], "voic": [136, 139, 143, 145, 146], "everyon": 136, "phonem": 136, "mel": 136, "spectrum": 136, "fourier": 136, "yourtt": 136, "audio": [136, 139, 142, 143, 146, 149, 152, 170], "vctk": [136, 138, 140], "libritt": 136, "mls": 136, "scl": 136, "04356_whisper": 137, "identif": [137, 143], "nois": 137, "transcript": 137, "transfer": [137, 147, 175], "reliabl": 137, "2301": [138, 173], "02111_vall": 138, "codec": [138, 139, 140], "are": [138, 140, 177], "synthes": [138, 140, 141], "vall": [138, 139, 140], "spoken": [138, 143, 145], "encodec": 138, "regard": 138, "ar": 138, "03926_vall": 139, "e_x": 139, "speak": 139, "foreign": 139, "own": 139, "s2st": 139, "similar": 139, "id": 139, "emot": 139, "mainten": 139, "switch": 139, "05370_vall": 140, "e2": 140, "pariti": 140, "2023": 140, "05407_cosyvoic": 141, "cosyvoic": [141, 144, 147], "transport": 141, "rich": 141, "10759_qwen2": 142, "technic": [142, 148, 155, 170, 181, 187], "00037_moshi": 143, "moshi": [143, 145], "helium": 143, "bottleneck": 143, "causal": [143, 241], "stream": [143, 144, 145, 151, 171, 172], "adversari": 143, "acoust": 143, "rvq": 143, "rq": 143, "delay": 143, "inner": [143, 227], "monologu": 143, "deriv": 143, "asr": [143, 146, 147, 152], "joint": [143, 162], "sequenc": 143, "hyper": 143, "loss": [143, 156, 225, 226], "mmlu": 143, "mosnet": 143, "safeti": [143, 149, 151], "regurgit": 143, "consist": 143, "watermark": 143, "signal": 143, "10117_cosyvoice2": 144, "instroduct": 144, "chunk": 144, "japanes": 144, "korean": 144, "06282_minmo": 145, "seamless": 145, "minmo": 145, "omni": [145, 167, 170, 171, 172], "freez": 145, "formula": 145, "controltoken": 145, "duplex": [145, 146, 167], "smooth": 145, "punctuat": 145, "invers": 145, "02707_voila": 146, "voila": 146, "interleav": [146, 162], "one": 146, "million": [146, 150], "built": 146, "17589_cosyvoice3": 147, "differenti": [147, 229], "pronunci": 147, "inpaint": 147, "polyglot": 147, "cv3": 147, "mos": 147, "08774_gpt": 148, "11805_gemini": 149, "famili": [149, 151, 184, 186], "academ": 149, "trend": [149, 174], "gemini": [149, 153], "nano": 149, "video": [149, 155, 170, 227], "assess": [149, 214], "mitig": 149, "assur": 149, "danger": 149, "red": 149, "ultra": 149, "05530_gemini1": 150, "unlock": 150, "02430_seed": 151, "versatil": [151, 160], "diffus": 151, "alphabet": [151, 158], "order": 151, "04675_seed": 152, "recip": [152, 155, 169], "ssl": 152, "cn": 152, "ml": [152, 190], "2503": [153, 170, 229], "20020_gemini2": 153, "bring": 153, "physic": 153, "xxxxx_seed": 154, "v1": 154, "superb": 154, "07062_seed1": 155, "vl": [155, 160, 163, 169], "seed1": 155, "seedvit": 155, "ocr": 155, "3d": [155, 222, 223, 225, 226, 228, 229], "stem": 155, "rlvr": 155, "reject": [155, 169], "reasoning_": 155, "pattern": [155, 211], "puzzl": 155, "find": 155, "geometri": [155, 224, 228, 229], "scene": [155, 158, 195, 201, 223, 225, 227, 228], "spatial": [155, 164, 168], "sort": 155, "12": 155, "13": [155, 165], "pars": 155, "14": 155, "15": 155, "novel": 155, "creativ": 155, "write": 155, "17": 155, "imagin": 155, "18": 155, "19": 155, "cases_": 155, "combinatori": 155, "20": 155, "dream": 155, "1k": 155, "15664_auxiliari": 156, "load": 156, "07490_modem": 157, "15093_ctr": 158, "charact": 158, "handwrit": 158, "preprocess": 158, "ratio": 158, "frequenc": 158, "recogniz": 158, "ctc": [158, 201], "rectif": 158, "2d": 158, "prab": 158, "pluggabl": 158, "radic": 158, "branch": 158, "extractor": 158, "08485_llava": 159, "scienceqa": 159, "12966_qwen": 160, "local": [160, 214, 225, 226, 227], "read": [160, 165], "beyond": 160, "03744_llava2": 161, "lmms": 161, "llava": 161, "hd": 161, "07533_vila": 162, "essenti": 162, "corpus": [162, 182], "recov": [162, 225], "degrad": 162, "vlms": 162, "05525_deepseek": 163, "01800_minicpm": 164, "4v": 164, "mllm": 164, "phone": 164, "side": 164, "minicpm": [164, 184], "rlaif": 164, "2409": 165, "17146_molmo": 165, "pixmo": 165, "molmo": 165, "cap": 165, "androidcontrol": 165, "clock": 165, "point": [165, 224, 225, 226, 229], "dropout": 165, "doc": 165, "contrast": 165, "synthet": [165, 174, 218], "13848_janus": 166, "decoupl": 166, "simpl": [166, 217, 230], "flexibl": 166, "mention": 166, "00774_freez": 167, "smart": 167, "frozen": [167, 173, 174], "04468_nvila": 168, "frontier": 168, "then": 168, "prune": [168, 239], "13923_qwen2": 169, "qwen2": [169, 187, 188], "frame": 169, "mrope": 169, "absolut": 169, "20215_qwen2": 170, "archtectur": 170, "perceiv": 170, "thinker": 170, "talker": 170, "13642_stream": [171, 172], "simultan": [171, 172], "instructomni": [171, 172], "spokenvisit": [171, 172], "12597_blip": 173, "former": 173, "vqa": 173, "01390_openflamingo": 174, "openflamingo_": 174, "embed": [174, 195, 211, 219], "vqav2": 174, "openflamingo": 174, "note": 174, "mmc4": 174, "credit": 174, "1810": 175, "04805_bert": 175, "bidirect": 175, "unsupervis": [175, 176, 177], "openai": 175, "18xx_gpt1": 176, "19xx_gpt2": 177, "learner": 177, "2012": 178, "00413_cpm": 178, "13971_llama": 179, "09288_llama": 180, "16609_qwen": 181, "qwen": 181, "19341_skywork": 182, "skywork": 182, "skypil": 182, "14196_deepseek": 183, "coder": 183, "when": 183, "meet": 183, "rise": 183, "06395_minicpm": 184, "unveil": 184, "potenti": 184, "two": [184, 240], "128k": 184, "04434_deepseek": 185, "econom": 185, "12793_chatglm": 186, "10671_qwen2": 187, "15115_qwen2": 188, "offlin": 188, "hous": 188, "09388_qwen3": 189, "qwen3": 189, "cold": 189, "start": 189, "1506": 191, "02640_you": 191, "look": 191, "onc": 191, "1612": 192, "08242_yolo9000": 192, "stronger": 192, "02767_yolov3": 193, "2004": 194, "10934_yolov4": 194, "00159_svtr": 195, "progress": 195, "overlap": 195, "patch": 195, "mix": [195, 219], "merg": 195, "variant": 195, "2207": 196, "02696_yolov7": 196, "trainabl": 196, "bag": 196, "freebi": 196, "detector": 196, "dino": 197, "marri": 197, "08485_visual": 198, "13616_yolov9": 199, "you": 199, "want": 199, "programm": 199, "14458_yolov10": 200, "15858_svtrv2": 201, "beat": 201, "resiz": 201, "rearrang": 201, "09332_webgpt": 202, "browser": 202, "11147_gophercit": 203, "quot": 203, "09848_generative_search": 204, "14251_factscor": 205, "14627_alc": 206, "citat": 206, "nli": 206, "02185_citat": 207, "account": 207, "16883_hagrid": 208, "seek": 208, "attribut": 208, "rag": [209, 211, 213, 214, 216, 217, 238, 240], "11401_retriev": 210, "intens": 210, "10997_retriev": 211, "survey": 211, "naiv": 211, "c1": 211, "c2": 211, "queri": [211, 214, 216, 220, 238], "recurs": 211, "target": 211, "vii": 211, "product": 211, "readi": 211, "15884_crag": 212, "14403_adapt": 213, "16130_graphrag": 214, "graphrag": [214, 220], "entiti": [214, 219], "communiti": 214, "instanc": 214, "16506_grag": [215, 239], "13213_multi": 216, "databas": 216, "05779_lightrag": 217, "lightrag": 217, "rq2": 217, "rq3": 217, "rq4": 217, "10450_kblam": 218, "kb": 218, "rectangular": 218, "inject": 218, "through": 218, "enron": 218, "03137_lightprof": 219, "lightweight": 219, "kg": 219, "anchor": 219, "link": 219, "stage1": 219, "stage2": 219, "stage3": 219, "2003": 223, "08934_nerf": 223, "repres": 223, "radianc": 223, "field": 223, "view": [223, 225, 229, 239], "render": 223, "08586": 224, "vanish": 224, "geometr": [224, 225], "variat": 224, "shift": 224, "manhattan": 224, "versus": 224, "vp": 224, "hough": 224, "gaussian": 224, "sphere": 224, "spheric": 224, "exp": 224, "14132_dust3r": 225, "made": 225, "easi": 225, "intrins": 225, "extrins": 225, "dust3r": [225, 226], "motion": [225, 229], "sfm": [225, 228, 229], "stereo": [225, 229], "mvs": [225, 229], "rgb": [225, 227, 228], "pointmap": [225, 228], "camera": [225, 226, 228], "inspir": 225, "croco": 225, "regress": 225, "confid": 225, "pose": [225, 226, 228], "monocular": [225, 227], "reconstruct": [225, 226, 227, 228, 229], "implicit": [225, 240], "slam": [225, 227, 228], "tab": [225, 228], "09756_mast3r": 226, "mast3r": [226, 228], "sift": 226, "invari": 226, "colmap": 226, "asmk": 226, "pnp": 226, "befor": 226, "claim": 226, "keypoint": 226, "semi": 226, "reciproc": 226, "coars": 226, "multiview": 226, "theoret": 226, "09401_slam3r": 227, "slam3r": 227, "keyfram": 227, "increment": 227, "dtu": 227, "12392_mast3r": 228, "imu": 228, "central": 228, "mathbf": 228, "kf": 228, "gauss": 228, "newton": 228, "irl": 228, "loop": 228, "closur": 228, "backend": 228, "optimis": 228, "relocalis": 228, "known": 228, "tum": 228, "eth3d": 228, "euroc": 228, "canon": 228, "pinhol": 228, "initialis": 228, "ate": 228, "11651_vggt": 229, "ani": 229, "notat": 229, "backbon": 229, "patchifi": 229, "bundl": 229, "adjust": 229, "ba": 229, "formal": [229, 239], "10959v3_dataset": 230, "random": 230, "epoch": 230, "20653_dataset": 231, "minmax": 231, "painless": 233, "crc": 233, "idea": 233, "behind": 233, "polynom": 233, "arithmet": 233, "no": 233, "carri": 233, "choos": 233, "poli": 233, "straightforward": 233, "tabl": 233, "driven": 233, "slight": 233, "mangl": 233, "16300_random": 236, "infinit": 236, "landmark": 236, "softmax": 236, "uniqu": 236, "miss": 236, "flash": 236, "offload": 236, "cpu": 236, "18743_alignbench": 237, "alignbench": 237, "judgement": 237, "15391_multihop": 238, "multihop": 238, "soft": 239, "textual": 239, "01178_memory3": 240, "explicit": [240, 242], "memory3": 240, "circuitri": 240, "sparsif": 240, "dimens": 240, "warmup": 240, "vector": 240, "supplementari": 240, "14683_emerg": 241, "properti": 241, "cube": 242, "memgovern": 242, "memvault": 242, "memload": 242, "memdump": 242, "memstor": 242, "innov": 242}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.todo": 2, "nbsphinx": 4, "sphinx": 57}, "alltitles": {"\u901a\u7528": [[0, "id2"], [1, "id2"], [73, "id1"], [114, "id2"], [115, "id1"], [232, "id2"]], "\u5982\u4f55\u770b\u4e00\u4e2a\u8bba\u6587\u662f\u4e0d\u662f\u91cd\u8981": [[1, "id3"]], "\u5b66\u672f\u7f51\u7ad9": [[2, "id1"]], "\u6574\u4f53\u5206\u6790": [[2, "id2"]], "1. \u5b66\u672f\u641c\u7d22\u5e73\u53f0\uff08\u6838\u5fc3\u529f\u80fd\uff1a\u68c0\u7d22\u4e0e\u53d1\u73b0\u6587\u732e\uff09": [[2, "id3"]], "Google Scholar": [[2, "google-scholar"]], "Semantic Scholar": [[2, "semantic-scholar"]], "Web of Science": [[2, "web-of-science"]], "\u767e\u5ea6\u5b66\u672f": [[2, "id4"]], "2. \u8d44\u6e90\u5171\u4eab\u5e73\u53f0\uff08\u6838\u5fc3\u529f\u80fd\uff1a\u514d\u8d39\u83b7\u53d6\u4ed8\u8d39\u6587\u732e\uff09": [[2, "id5"]], "Sci-Hub": [[2, "sci-hub"]], "Library Genesis (LibGen)": [[2, "library-genesis-libgen"]], "Unpaywall": [[2, "unpaywall"]], "\u8bba\u6587\u6570\u636e\u5e93\uff08\u6838\u5fc3\u529f\u80fd\uff1a\u5b58\u50a8\u4e0e\u63d0\u4f9b\u6587\u732e\u539f\u6587\uff09": [[2, "id6"]], "ACL Anthology": [[2, "acl-anthology"]], "\u6838\u5fc3\u7279\u70b9": [[2, "id7"]], "\u91cd\u8981\u6027\u4e0e\u4f5c\u7528": [[2, "id8"]], "\u8865\u5145\u8bf4\u660e": [[2, "id9"], [50, "id15"]], "ArXiv": [[2, "arxiv"]], "\u77e5\u7f51 CNKI": [[2, "cnki"]], "\u4e07\u65b9\u6570\u636e\u5e93": [[2, "id10"]], "AI Agent": [[3, "ai-agent"]], "\u901a\u7528 Agent": [[3, "agent"]], "\u89c6\u89c9 Agent&AIOS": [[3, "agent-aios"]], "\u8bb0\u5fc6": [[3, "id2"]], "Tools": [[3, "tools"]], "AGI": [[3, "agi"]], "1905.10985_AI-GA: AI-generating algorithms, an alternate paradigm for producing general artificial intelligence": [[4, "ai-ga-ai-generating-algorithms-an-alternate-paradigm-for-producing-general-artificial-intelligence"]], "2408.06292_The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery": [[5, "the-ai-scientist-towards-fully-automated-open-ended-scientific-discovery"]], "2108.03353_ Screen2Words: Automatic Mobile UI Summarization with Multimodal Learning": [[6, "screen2words-automatic-mobile-ui-summarization-with-multimodal-learning"]], "Abstract": [[6, "abstract"], [7, "abstract"], [10, "abstract"], [11, "abstract"], [12, "abstract"], [13, "abstract"], [15, "abstract"], [16, "abstract"], [17, "abstract"], [18, "abstract"], [19, "abstract"], [38, "abstract"], [39, "abstract"], [43, "abstract"], [45, "abstract"], [46, "abstract"], [47, "abstract"], [48, "abstract"], [49, "abstract"], [50, "abstract"], [51, "abstract"], [52, "abstract"], [53, "abstract"], [54, "abstract"], [55, "abstract"], [56, "abstract"], [57, "abstract"], [58, "abstract"], [59, "abstract"], [60, "abstract"], [61, "abstract"], [62, "abstract"], [63, "abstract"], [64, "abstract"], [65, "abstract"], [67, "abstract"], [68, "abstract"], [69, "abstract"], [70, "abstract"], [71, "abstract"], [72, "abstract"], [74, "abstract"], [75, "abstract"], [76, "abstract"], [77, "abstract"], [78, "abstract"], [79, "abstract"], [80, "abstract"], [81, "abstract"], [82, "abstract"], [83, "abstract"], [84, "abstract"], [85, "abstract"], [97, "abstract"], [98, "abstract"], [104, "abstract"], [106, "abstract"], [108, "abstract"], [111, "abstract"], [112, "abstract"], [113, "abstract"], [116, "abstract"], [117, "abstract"], [118, "abstract"], [119, "abstract"], [120, "abstract"], [121, "abstract"], [122, "abstract"], [123, "abstract"], [124, "abstract"], [125, "abstract"], [127, "abstract"], [130, "abstract"], [134, "abstract"], [135, "abstract"], [136, "abstract"], [137, "abstract"], [138, "abstract"], [139, "abstract"], [140, "abstract"], [141, "abstract"], [142, "abstract"], [143, "abstract"], [144, "abstract"], [145, "abstract"], [146, "abstract"], [147, "abstract"], [149, "abstract"], [151, "abstract"], [152, "abstract"], [155, "abstract"], [158, "abstract"], [159, "abstract"], [161, "abstract"], [162, "abstract"], [163, "abstract"], [164, "abstract"], [165, "abstract"], [166, "abstract"], [167, "abstract"], [168, "abstract"], [169, "abstract"], [170, "abstract"], [171, "abstract"], [172, "abstract"], [173, "abstract"], [174, "abstract"], [176, "abstract"], [182, "abstract"], [187, "abstract"], [188, "abstract"], [189, "abstract"], [191, "abstract"], [192, "abstract"], [194, "abstract"], [195, "abstract"], [196, "abstract"], [199, "abstract"], [200, "abstract"], [201, "abstract"], [214, "abstract"], [217, "abstract"], [218, "abstract"], [219, "abstract"], [223, "abstract"], [224, "abstract"], [225, "abstract"], [226, "abstract"], [227, "abstract"], [228, "abstract"], [229, "abstract"], [231, "abstract"], [236, "abstract"], [237, "abstract"], [238, "abstract"], [239, "abstract"], [240, "abstract"], [241, "abstract"], [242, "abstract"]], "1. Introduction": [[6, "introduction"], [7, "introduction"], [8, "introduction"], [10, "introduction"], [11, "introduction"], [13, "introduction"], [16, "introduction"], [17, "introduction"], [18, "introduction"], [62, "introduction"], [79, "introduction"], [81, "introduction"], [97, "introduction"], [102, "introduction"], [104, "introduction"], [105, "introduction"], [106, "introduction"], [107, "introduction"], [112, "introduction"], [113, "introduction"], [117, "introduction"], [119, "introduction"], [120, "introduction"], [121, "introduction"], [122, "introduction"], [123, "introduction"], [124, "introduction"], [125, "introduction"], [127, "introduction"], [130, "introduction"], [132, "introduction"], [133, "introduction"], [136, "introduction"], [137, "introduction"], [138, "introduction"], [139, "introduction"], [140, "introduction"], [142, "introduction"], [146, "introduction"], [149, "introduction"], [158, "introduction"], [159, "introduction"], [161, "introduction"], [162, "introduction"], [164, "introduction"], [165, "introduction"], [167, "introduction"], [168, "introduction"], [169, "introduction"], [170, "introduction"], [171, "introduction"], [176, "introduction"], [181, "introduction"], [187, "introduction"], [188, "introduction"], [189, "introduction"], [195, "introduction"], [201, "introduction"], [218, "introduction"], [223, "introduction"], [224, "introduction"], [225, "introduction"], [226, "introduction"], [227, "introduction"], [228, "introduction"], [229, "introduction"], [231, "introduction"]], "2. Related Work": [[6, "related-work"], [7, "related-work"], [8, "related-work"], [62, "related-work"], [98, "related-work"], [121, "related-work"], [124, "related-work"], [125, "related-work"], [138, "related-work"], [139, "related-work"], [140, "related-work"], [146, "related-work"], [159, "related-work"], [161, "related-work"], [164, "related-work"], [171, "related-work"], [176, "related-work"], [201, "related-work"], [223, "related-work"], [224, "related-work"], [225, "related-work"], [227, "related-work"], [228, "related-work"], [229, "related-work"], [231, "related-work"]], "2.1 \u5355\u6a21\u6001\u4e0e\u591a\u6a21\u6001\u5185\u5bb9\u6458\u8981": [[6, "id1"]], "2.2 \u7528\u6df1\u5ea6\u5b66\u4e60\u7406\u89e3\u624b\u673a\u5c4f\u5e55": [[6, "id2"]], "2.3 \u624b\u673aUI\u548c\u4ea4\u4e92\u6570\u636e\u96c6": [[6, "ui"]], "3. Dataset Creation": [[6, "dataset-creation"]], "4. Model Design": [[6, "model-design"]], "\u5176\u5b83": [[6, "id3"]], "2209.08199_ScreenQA: Large-Scale Question-Answer Pairs over Mobile App Screenshots": [[7, "screenqa-large-scale-question-answer-pairs-over-mobile-app-screenshots"]], "2.1 Multimodality": [[7, "multimodality"]], "2.2 Question Answering": [[7, "question-answering"]], "\u603b\u7ed3": [[7, "id2"], [7, "id3"], [7, "id4"], [8, "id5"], [8, "id6"], [10, "id2"], [10, "id4"], [11, "id2"], [17, "id3"], [17, "id4"], [17, "id5"], [17, "id6"], [17, "id9"], [17, "id10"], [17, "id12"], [19, "id21"], [19, "id22"], [39, "id1"], [39, "id5"], [43, "id1"], [43, "id7"], [43, "id10"], [43, "id22"], [43, "id29"], [45, "id1"], [45, "id2"], [45, "id6"], [45, "id10"], [45, "id12"], [46, "id1"], [47, "id1"], [47, "id4"], [47, "id7"], [47, "id11"], [47, "id21"], [47, "id22"], [47, "id27"], [47, "id28"], [48, "id1"], [49, "id8"], [49, "id17"], [49, "id24"], [49, "id36"], [50, "id1"], [50, "id9"], [50, "id13"], [52, "id1"], [52, "id6"], [52, "id10"], [52, "id11"], [52, "id15"], [53, "id1"], [53, "id5"], [54, "id1"], [54, "id4"], [54, "id5"], [54, "id14"], [54, "id19"], [54, "id20"], [54, "id29"], [55, "id1"], [56, "id1"], [56, "id5"], [56, "id11"], [57, "id1"], [57, "id5"], [57, "id9"], [58, "id1"], [58, "id7"], [58, "id10"], [58, "id15"], [58, "id16"], [58, "id17"], [59, "id1"], [59, "id6"], [59, "id11"], [60, "id1"], [60, "id7"], [60, "id13"], [60, "id18"], [61, "id1"], [61, "id6"], [61, "id14"], [61, "id15"], [61, "id16"], [62, "id1"], [62, "id5"], [62, "id13"], [62, "id17"], [62, "id24"], [62, "id25"], [63, "id1"], [63, "id3"], [63, "id4"], [63, "id13"], [64, "id1"], [64, "id6"], [64, "id11"], [65, "id1"], [65, "id6"], [65, "id9"], [65, "id14"], [65, "id20"], [65, "id25"], [65, "id26"], [65, "id27"], [67, "id1"], [67, "id4"], [67, "id5"], [68, "id3"], [68, "id6"], [68, "id9"], [68, "id18"], [68, "id31"], [69, "id1"], [69, "id11"], [69, "id20"], [69, "id24"], [70, "id1"], [70, "id4"], [70, "id7"], [70, "id11"], [70, "id18"], [71, "id1"], [72, "id9"], [74, "id1"], [74, "id9"], [75, "id1"], [75, "id5"], [75, "id6"], [75, "id7"], [76, "id1"], [76, "id8"], [76, "id11"], [77, "id1"], [77, "id7"], [77, "id8"], [77, "id12"], [77, "id14"], [78, "id1"], [79, "id2"], [79, "id3"], [81, "id1"], [82, "id1"], [84, "id3"], [84, "id8"], [84, "id9"], [85, "id1"], [85, "id3"], [85, "id12"], [97, "id2"], [97, "id3"], [98, "id2"], [98, "id3"], [98, "id7"], [98, "id8"], [98, "id9"], [101, "id5"], [102, "id2"], [102, "id3"], [102, "id4"], [102, "id5"], [102, "id6"], [102, "id7"], [104, "id2"], [104, "id6"], [106, "id3"], [106, "id6"], [107, "id3"], [107, "id4"], [112, "id4"], [117, "id14"], [118, "id1"], [119, "id12"], [120, "id2"], [127, "id4"], [127, "id5"], [127, "id6"], [130, "id2"], [130, "id3"], [130, "id4"], [131, "id5"], [133, "id4"], [133, "id6"], [133, "id7"], [133, "id9"], [134, "id11"], [135, "id1"], [135, "id15"], [135, "id16"], [136, "id5"], [136, "id11"], [138, "id10"], [141, "id1"], [151, "id10"], [152, "id4"], [152, "id14"], [155, "id15"], [155, "id20"], [155, "id29"], [155, "id35"], [155, "id42"], [155, "id49"], [155, "id57"], [155, "id60"], [155, "id65"], [166, "id1"], [166, "id6"], [166, "id12"], [166, "id14"], [166, "id22"], [166, "id23"], [171, "id6"], [172, "id4"], [172, "id15"], [172, "id17"], [172, "id21"], [173, "id6"], [173, "id10"], [173, "id14"], [174, "id4"], [174, "id11"], [174, "id12"], [174, "id15"], [182, "id1"], [182, "id8"], [182, "id11"], [182, "id21"], [214, "id1"], [214, "id6"], [214, "id14"], [214, "id20"], [214, "id27"], [217, "id1"], [217, "id3"], [217, "id8"], [225, "id18"], [227, "id25"], [230, "id5"], [236, "id7"], [236, "id13"], [236, "id22"], [236, "id24"], [237, "id8"], [237, "id10"], [238, "id5"], [238, "id9"], [238, "id11"], [238, "id12"], [239, "id4"], [239, "id5"], [239, "id12"], [240, "id7"], [240, "id9"], [240, "id16"], [240, "id28"], [240, "id36"], [240, "id38"], [240, "id41"], [240, "id42"], [240, "id44"], [240, "id49"], [241, "id6"], [241, "id17"], [241, "id22"], [241, "id28"], [241, "id34"], [242, "id16"], [242, "id19"], [242, "id24"], [242, "id26"], [242, "id27"], [242, "id30"]], "3. Problem Setting: Tasks and Metrics": [[7, "problem-setting-tasks-and-metrics"]], "\u8bc4\u4f30\u6307\u6807(Evaluation Metrics)": [[7, "evaluation-metrics"]], "ScreenQA \u4efb\u52a1\u7c7b\u578b": [[7, "screenqa"]], "4. Data Annotation": [[7, "data-annotation"]], "5. Dataset Analysis": [[7, "dataset-analysis"]], "6. Experiments and Baselines": [[7, "experiments-and-baselines"]], "7. Conclusion": [[7, "conclusion"], [122, "conclusion"], [164, "conclusion"], [181, "conclusion"], [223, "conclusion"], [231, "conclusion"]], "8. Limitations": [[7, "limitations"]], "9. Ethical Considerations": [[7, "ethical-considerations"]], "A. Data Annotation Details": [[7, "a-data-annotation-details"]], "A.1 VH Out-of-Sync Rules": [[7, "a-1-vh-out-of-sync-rules"]], "A.2 Question Annotation UI": [[7, "a-2-question-annotation-ui"]], "A.3 Answer Annotation UI": [[7, "a-3-answer-annotation-ui"]], "A.4 Annotation quality control": [[7, "a-4-annotation-quality-control"]], "A.5 Annotation post-processing": [[7, "a-5-annotation-post-processing"]], "A.6 Short Answer Generation Prompts": [[7, "a-6-short-answer-generation-prompts"]], "B. Data Examples": [[7, "b-data-examples"]], "2212.06817_RT-1: ROBOTICS TRANSFORMER FOR REAL-WORLD CONTROL AT SCALE": [[8, "rt-1-robotics-transformer-for-real-world-control-at-scale"]], "ABSTRACT": [[8, "abstract"], [107, "abstract"], [230, "abstract"]], "3. Preliminaries": [[8, "preliminaries"]], "4. System Overview": [[8, "system-overview"]], "5. RT-1: ROBOTICS TRANSFORMER": [[8, "rt-1-robotics-transformer"]], "\u6574\u4f53\u67b6\u6784": [[8, "id2"]], "Tokenization": [[8, "tokenization"]], "\u6a21\u578b\u7ed3\u6784\u4e0e\u53c2\u6570\u89c4\u6a21": [[8, "id3"]], "\u63a8\u7406\u901f\u5ea6\u4f18\u5316-Inference Speed": [[8, "inference-speed"]], "\u6570\u636e\u4e0e\u4efb\u52a1\u80fd\u529b": [[8, "id4"]], "6. EXPERIMENTS": [[8, "experiments"], [218, "experiments"]], "6.1 EXPERIMENTAL SETUP": [[8, "experimental-setup"]], "6.2 can rt-1 learn to perform a large number of instructions, and to generalize to new tasks, objects and environments?": [[8, "can-rt-1-learn-to-perform-a-large-number-of-instructions-and-to-generalize-to-new-tasks-objects-and-environments"]], "6.3 can we push the resulting model further by incorporating heterogeneous data sources such as simulation or data from different robots?": [[8, "can-we-push-the-resulting-model-further-by-incorporating-heterogeneous-data-sources-such-as-simulation-or-data-from-different-robots"]], "6.4 how do various methods generalize long-horizon robotic scenarios?": [[8, "how-do-various-methods-generalize-long-horizon-robotic-scenarios"]], "6.5 how do generalization metrics change with varying amounts of data quantity and data diversity?": [[8, "how-do-generalization-metrics-change-with-varying-amounts-of-data-quantity-and-data-diversity"]], "7. CONCLUSIONS, LIMITATIONS AND FUTURE WORK": [[8, "conclusions-limitations-and-future-work"]], "B. MODEL CARD": [[8, "b-model-card"]], "C. MODEL AND DATA": [[8, "c-model-and-data"]], "C.1 MODEL INFERENCE": [[8, "c-1-model-inference"]], "C.2 DATA COLLECTION AT SCALE.": [[8, "c-2-data-collection-at-scale"]], "C.3 MODEL SELECTION AT SCALE": [[8, "c-3-model-selection-at-scale"]], "D. EXPERIMENTS": [[8, "d-experiments"]], "D.1 EVALUATION DETAILS": [[8, "d-1-evaluation-details"]], "D.2 HETEROGENEOUS DATA": [[8, "d-2-heterogeneous-data"]], "D.3 LONG-HORIZON EVALUATION DETAILS": [[8, "d-3-long-horizon-evaluation-details"]], "D.4 MODEL ABLATIONS": [[8, "d-4-model-ablations"]], "2312.13771_AppAgent: Multimodal Agents as Smartphone Users": [[9, "appagent-multimodal-agents-as-smartphone-users"]], "3.1 Environment and Action Space": [[9, "environment-and-action-space"]], "3.2 Exploration Phase": [[9, "exploration-phase"]], "3.3 Deployment Phase": [[9, "deployment-phase"]], "2401.10935_SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents": [[10, "seeclick-harnessing-gui-grounding-for-advanced-visual-gui-agents"]], "2. Related work": [[10, "related-work"], [130, "related-work"], [218, "related-work"]], "Autonomous GUI Navigation": [[10, "autonomous-gui-navigation"]], "Large Vision-Language Models": [[10, "large-vision-language-models"]], "3. Approach": [[10, "approach"], [161, "approach"]], "3.1 GUI grounding for LVLMs": [[10, "gui-grounding-for-lvlms"]], "3.2 Data Construction": [[10, "data-construction"]], "3.3 Training Details": [[10, "training-details"]], "4. ScreenSpot: A Grounding Benchmark": [[10, "screenspot-a-grounding-benchmark"]], "5. Experiments": [[10, "experiments"], [122, "experiments"], [124, "experiments"], [138, "experiments"], [139, "experiments"], [159, "experiments"]], "5.1 GUI Grounding on ScreenSpot": [[10, "gui-grounding-on-screenspot"]], "5.2 Visual GUI Agent Tasks": [[10, "visual-gui-agent-tasks"]], "5.2.1 MiniWob": [[10, "miniwob"]], "5.2.2 AITW(Android In The Wild)": [[10, "aitw-android-in-the-wild"]], "5.2.3 Mind2Web": [[10, "mind2web"]], "5.2.4 Grounding and Agent Performance": [[10, "grounding-and-agent-performance"]], "5.2.5 SeeClick as Unified GUI Agent": [[10, "seeclick-as-unified-gui-agent"]], "6. Conclusion": [[10, "conclusion"], [17, "conclusion"], [118, "conclusion"], [124, "conclusion"], [139, "conclusion"], [141, "conclusion"], [159, "conclusion"], [161, "conclusion"], [162, "conclusion"], [168, "conclusion"], [170, "conclusion"], [171, "conclusion"], [187, "conclusion"], [188, "conclusion"]], "Limitations": [[10, "limitations"], [127, "limitations"], [172, "limitations"], [238, "limitations"]], "Ethical considerations": [[10, "ethical-considerations"]], "A. Details of SeeClick Pre-training": [[10, "a-details-of-seeclick-pre-training"]], "A.1 Pre-training Tasks": [[10, "a-1-pre-training-tasks"]], "A.2 Training Configurations": [[10, "a-2-training-configurations"]], "B ScreenSpot Annotation & Evaluation": [[10, "b-screenspot-annotation-evaluation"]], "B.1 Human Annotation": [[10, "b-1-human-annotation"]], "B.2 Sample Showcase": [[10, "b-2-sample-showcase"]], "B.3 Evaluation Detail": [[10, "b-3-evaluation-detail"]], "B.4 SeeClick Case Study & Error Analysis": [[10, "b-4-seeclick-case-study-error-analysis"]], "\u5c0f\u7ed3": [[10, "id3"], [54, "id13"], [60, "id10"], [82, "id17"], [143, "id36"], [172, "id20"], [219, "id5"], [240, "id21"]], "C. Downstream Agent Tasks": [[10, "c-downstream-agent-tasks"]], "C.1 Formulation of SeeClick as Visual GUI Agent": [[10, "c-1-formulation-of-seeclick-as-visual-gui-agent"]], "C.2 MiniWob": [[10, "c-2-miniwob"]], "C.3 AITW": [[10, "c-3-aitw"]], "C.4 Mind2web": [[10, "c-4-mind2web"]], "2402.04615_ScreenAI: A Vision-Language Model for UI and Infographics Understanding": [[11, "screenai-a-vision-language-model-for-ui-and-infographics-understanding"]], "2. Methodology": [[11, "methodology"], [142, "methodology"]], "2.1 Architecture": [[11, "architecture"]], "2.2 Model Configurations": [[11, "model-configurations"]], "2.3 Stages of Training": [[11, "stages-of-training"]], "3. Automatic data generation": [[11, "automatic-data-generation"]], "3.1 Screen Annotation": [[11, "screen-annotation"]], "3.2 LLMs to Generate Additional Tasks": [[11, "llms-to-generate-additional-tasks"]], "4. Data Mixtures": [[11, "data-mixtures"]], "4.1 Pretraining Mixture": [[11, "pretraining-mixture"]], "4.2 Fine-Tuning Tasks and Benchmarks": [[11, "fine-tuning-tasks-and-benchmarks"]], "\u5173\u952e\u70b9\u603b\u7ed3": [[11, "id3"]], "\u9002\u7528\u573a\u666f": [[11, "id4"]], "5. Experiments and Results": [[11, "experiments-and-results"]], "6. Conclusions": [[11, "conclusions"], [117, "conclusions"], [158, "conclusions"], [229, "conclusions"]], "A Definitions of Metrics": [[11, "a-definitions-of-metrics"]], "B. Screen Schema Examples": [[11, "b-screen-schema-examples"]], "C. Prompts For LLM Generated Content": [[11, "c-prompts-for-llm-generated-content"]], "D. Screen Navigation Generated Examples": [[11, "d-screen-navigation-generated-examples"]], "F. ScreenQA Short Answers Generation": [[11, "f-screenqa-short-answers-generation"]], "F.1 For answers contained in a single UI element": [[11, "f-1-for-answers-contained-in-a-single-ui-element"]], "F.2 For answers contained in multiple UI elements": [[11, "f-2-for-answers-contained-in-multiple-ui-elements"]], "G. Complex Question Answering Datasets": [[11, "g-complex-question-answering-datasets"]], "H. New Benchmarks Repositories": [[11, "h-new-benchmarks-repositories"]], "2402.07939_UFO: A UI-Focused Agent for Windows OS Interaction": [[12, "ufo-a-ui-focused-agent-for-windows-os-interaction"]], "1.Introduction": [[12, "introduction"], [19, "introduction"], [38, "introduction"], [46, "introduction"], [48, "introduction"], [71, "introduction"], [72, "introduction"], [74, "introduction"], [78, "introduction"], [80, "introduction"], [82, "introduction"], [143, "introduction"], [147, "introduction"]], "2.Related Work": [[12, "related-work"], [46, "related-work"], [74, "related-work"], [80, "related-work"], [143, "related-work"], [145, "related-work"]], "2.1 LLM Agents": [[12, "llm-agents"]], "2.2 LLM-based GUI Intelligence": [[12, "llm-based-gui-intelligence"]], "3.The Design of UFO": [[12, "the-design-of-ufo"]], "3.1 UFO in a Nutshell": [[12, "ufo-in-a-nutshell"]], "3.2 HostAgent": [[12, "hostagent"]], "3.3 AppAgent": [[12, "appagent"]], "3.4 Control Interaction": [[12, "control-interaction"]], "3.5 Special Design Consideration": [[12, "special-design-consideration"]], "3.5.1 Interactive Mode": [[12, "interactive-mode"]], "3.5.2 Action Customization": [[12, "action-customization"]], "3.5.3 Control Filtering": [[12, "control-filtering"]], "3.5.4 Plan Reflection": [[12, "plan-reflection"]], "3.5.5 Safeguard": [[12, "safeguard"]], "4.Experiment": [[12, "experiment"]], "4.1 Benchmark & Baselines & Metrics": [[12, "benchmark-baselines-metrics"]], "4.2 Performance Evaluation": [[12, "performance-evaluation"]], "4.3 Case Study": [[12, "case-study"]], "\u2705 \u603b\u7ed3\uff1a": [[12, "id1"]], "5.Limitations & Lessons Learned": [[12, "limitations-lessons-learned"]], "6.Conclusion": [[12, "conclusion"], [74, "conclusion"], [81, "conclusion"], [147, "conclusion"]], "2403.16971_AIOS: LLM Agent Operating System": [[13, "aios-llm-agent-operating-system"]], "2. The Architecture of AIOS": [[13, "the-architecture-of-aios"]], "3. AIOS Kernel": [[13, "aios-kernel"]], "3.1 Relationship and Connection between Modules": [[13, "relationship-and-connection-between-modules"]], "3.2 LLM Core(s)": [[13, "llm-core-s"]], "3.3 Scheduler": [[13, "scheduler"]], "3.4 Context Manager": [[13, "context-manager"]], "3.5 Memory Manager": [[13, "memory-manager"]], "3.6 Storage Manager": [[13, "storage-manager"]], "3.7 Tool Manager": [[13, "tool-manager"]], "3.8 Access Manager": [[13, "access-manager"]], "3.9 AIOS-Agent SDK": [[13, "aios-agent-sdk"]], "4 Evaluation": [[13, "evaluation"], [62, "evaluation"], [182, "evaluation"], [217, "evaluation"]], "\ud83d\udd27 4.1 \u5b9e\u9a8c\u8bbe\u7f6e\uff08Setup\uff09": [[13, "setup"]], "\u2705 4.2 \u4efb\u52a1\u6027\u80fd\u8bc4\u4f30\uff08RQ1\uff09": [[13, "rq1"]], "Appendix E Discussion": [[13, "appendix-e-discussion"]], "E.2Future Directions": [[13, "e-2future-directions"]], "2406.01014_Mobile-Agent-v2: Mobile Device Operation Assistant with Effective Navigation via Multi-Agent Collaboration": [[14, "mobile-agent-v2-mobile-device-operation-assistant-with-effective-navigation-via-multi-agent-collaboration"]], "2411.02059_TableGPT2: A Large Multimodal Model with Tabular Data Integration": [[15, "tablegpt2-a-large-multimodal-model-with-tabular-data-integration"]], "2501.11733_Mobile-Agent-E: Self-Evolving Mobile Assistant for Complex Tasks": [[16, "mobile-agent-e-self-evolving-mobile-assistant-for-complex-tasks"]], "2. Mobile-Agent-E": [[16, "mobile-agent-e"]], "2.1. Hierachical Multi-Agent Framework": [[16, "hierachical-multi-agent-framework"]], "2.2. Self-Evolution Module": [[16, "self-evolution-module"]], "3. Experiments": [[16, "experiments"], [18, "experiments"], [136, "experiments"], [137, "experiments"], [142, "experiments"], [168, "experiments"], [169, "experiments"], [195, "experiments"]], "4. Results": [[16, "results"], [130, "results"], [228, "results"]], "5. Related Work": [[16, "related-work"], [116, "related-work"], [119, "related-work"], [137, "related-work"], [162, "related-work"], [168, "related-work"]], "5.1. GUI Agents": [[16, "gui-agents"]], "5.2. Self-Evolution in Foundation Models": [[16, "self-evolution-in-foundation-models"]], "6. Conclusion and Future Work": [[16, "conclusion-and-future-work"]], "Appendix A Full Trajectory Comparison Example with Previous SOTA": [[16, "appendix-a-full-trajectory-comparison-example-with-previous-sota"]], "Appendix B Error Recovery with Escalation to Manager": [[16, "appendix-b-error-recovery-with-escalation-to-manager"]], "Appendix C Remaining Limitations": [[16, "appendix-c-remaining-limitations"]], "Appendix D All Tasks in Mobile-Eval-E Benchmark": [[16, "appendix-d-all-tasks-in-mobile-eval-e-benchmark"]], "Appendix E Atomic Operation Space": [[16, "appendix-e-atomic-operation-space"]], "Appendix F Full list of Self-Evolved Shortcuts": [[16, "appendix-f-full-list-of-self-evolved-shortcuts"]], "Appendix G Full list of Self-Evolved Tips": [[16, "appendix-g-full-list-of-self-evolved-tips"]], "2501.12326_UI-TARS: Pioneering Automated GUI Interaction with Native Agents": [[17, "ui-tars-pioneering-automated-gui-interaction-with-native-agents"]], "\u80cc\u666f: GUI \u4ee3\u7406(GUI Agents)\u7684\u91cd\u8981\u6027": [[17, "gui-gui-agents"]], "\u4f20\u7edf GUI \u4ee3\u7406\u65b9\u6cd5\u7684\u5c40\u9650\u6027": [[17, "gui"]], "\u539f\u751f GUI \u4ee3\u7406(Native GUI Agent)": [[17, "gui-native-gui-agent"]], "\u5f53\u524d\u7aef\u5230\u7aef GUI \u4ee3\u7406\u9762\u4e34\u7684\u6311\u6218": [[17, "id2"]], "UI-TARS: \u65b0\u4e00\u4ee3\u539f\u751f GUI \u4ee3\u7406": [[17, "ui-tars-gui"]], "2. Evolution Path of GUI Agents": [[17, "evolution-path-of-gui-agents"]], "2.1 Rule-based Agents": [[17, "rule-based-agents"]], "Stage 1: Rule-based Agents": [[17, "stage-1-rule-based-agents"]], "2.2 From Modular Agent Framework to Native Agent Model": [[17, "from-modular-agent-framework-to-native-agent-model"]], "Stage 2: Agent Framework": [[17, "stage-2-agent-framework"]], "Stage 3: Native Agent Model": [[17, "stage-3-native-agent-model"]], "2.3 Active and Lifelong Agent (Prospect)": [[17, "active-and-lifelong-agent-prospect"]], "Stage 4: Action and Lifelong Agent": [[17, "stage-4-action-and-lifelong-agent"]], "3. Core Capabilities of Native Agent Model": [[17, "core-capabilities-of-native-agent-model"]], "3.1 Core Capabilities": [[17, "core-capabilities"]], "1 \u611f\u77e5(Perception)": [[17, "perception"]], "2 \u884c\u52a8(Action)": [[17, "action"]], "3 \u63a8\u7406(Reasoning): \u7cfb\u7edf 1 & 2 \u601d\u7ef4": [[17, "reasoning-1-2"]], "4 \u8bb0\u5fc6(Memory)": [[17, "memory"]], "3.2 Capability Evaluation": [[17, "capability-evaluation"]], "4. UI-TARS": [[17, "ui-tars"]], "4.1 Architecture Overview": [[17, "architecture-overview"]], "4.2 Enhancing GUI Perception": [[17, "enhancing-gui-perception"]], "4.3 Unified Action Modeling and Grounding": [[17, "unified-action-modeling-and-grounding"]], "1. \u7edf\u4e00\u7684\u64cd\u4f5c\u7a7a\u95f4(Unified Action Space)": [[17, "unified-action-space"]], "2. \u64cd\u4f5c\u8f68\u8ff9\u6536\u96c6(Action Trace Collection)": [[17, "action-trace-collection"]], "3. \u63d0\u5347\u64cd\u4f5c\u5b9a\u4f4d\u80fd\u529b(Improving Grounding Ability)": [[17, "improving-grounding-ability"]], "\u5e94\u7528\u573a\u666f": [[17, "id7"]], "4.4 Infusing System-2 Reasoning": [[17, "infusing-system-2-reasoning"]], "Reasoning Enrichment with GUI Tutorials": [[17, "reasoning-enrichment-with-gui-tutorials"]], "Reasoning Stimulation with Thought Augmentation": [[17, "reasoning-stimulation-with-thought-augmentation"]], "\u5173\u952e\u7406\u89e3": [[17, "id8"]], "4.5 Learning from Prior Experience in Long-term Memory": [[17, "learning-from-prior-experience-in-long-term-memory"]], "Online Trace Bootstrapping": [[17, "online-trace-bootstrapping"]], "Reflection Tuning": [[17, "reflection-tuning"]], "Agent DPO": [[17, "agent-dpo"]], "4.6 Training": [[17, "training"]], "\u8bad\u7ec3\u7684\u4e09\u5927\u9636\u6bb5": [[17, "id11"]], "5. Experiment": [[17, "experiment"]], "2502.14282_PC-Agent: A Hierarchical Multi-Agent Collaboration Framework for Complex Task Automation on PC": [[18, "pc-agent-a-hierarchical-multi-agent-collaboration-framework-for-complex-task-automation-on-pc"]], "2. PC-Agent": [[18, "pc-agent"]], "2.1 Task Formulation": [[18, "task-formulation"]], "2.2 Active Perception Module": [[18, "active-perception-module"]], "2.3 Hierarchical Multi-agent Collaboration": [[18, "hierarchical-multi-agent-collaboration"]], "2.4 Reflection-based Dynamic Decision-making": [[18, "reflection-based-dynamic-decision-making"]], "3.1 PC-Eval": [[18, "pc-eval"]], "3.2 Result": [[18, "result"]], "3.3 Ablation Study": [[18, "ablation-study"], [195, "ablation-study"]], "3.4 Case Study": [[18, "case-study"]], "4. Related Work": [[18, "related-work"]], "5. Conclusion": [[18, "conclusion"], [125, "conclusion"], [140, "conclusion"], [142, "conclusion"], [144, "conclusion"], [146, "conclusion"], [189, "conclusion"], [201, "conclusion"], [225, "conclusion"], [226, "conclusion"], [227, "conclusion"]], "A.3 Action Space": [[18, "a-3-action-space"], [79, "a-3-action-space"]], "2504.14603_UFO2: The Desktop AgentOS": [[19, "ufo2-the-desktop-agentos"]], "\u4f20\u7edfRPA\u7684\u5c40\u9650\uff1a": [[19, "rpa"]], "CUA\u7684\u5174\u8d77\u4e0e\u95ee\u9898\uff1a": [[19, "cua"]], "UFO2 \u7684\u521b\u65b0\uff1a": [[19, "ufo2"]], "\u603b\u7ed3\uff1a": [[19, "id1"], [19, "id17"], [49, "id34"], [50, "id6"], [51, "id4"], [53, "id6"], [53, "id7"], [57, "id3"], [58, "id19"], [58, "id25"], [61, "id3"], [61, "id17"], [62, "id12"], [64, "id18"], [64, "id22"], [68, "id17"], [69, "id15"], [75, "id8"], [75, "id10"], [76, "id14"], [76, "id16"], [82, "id4"], [85, "id9"], [85, "id11"], [134, "id2"], [134, "id7"], [135, "id8"], [151, "id11"], [151, "id13"], [152, "id2"], [155, "id59"], [165, "id6"], [173, "id2"], [174, "id3"], [227, "id5"], [227, "id10"], [227, "id11"], [229, "id4"], [229, "id6"], [237, "id2"], [238, "id7"], [240, "id4"], [240, "id51"], [241, "id2"]], "2.Background": [[19, "background"]], "\u4f20\u7edf\u684c\u9762\u81ea\u52a8\u5316\u7684\u95ee\u9898": [[19, "id2"]], "\u65b0\u8d8b\u52bf\uff1a\u7528\u5927\u6a21\u578b\u9a71\u52a8\u7684\u201c\u7535\u8111\u4ee3\u7406\u4eba\uff08CUA\uff09\u201d": [[19, "id3"]], "\u5f53\u524d CUA \u7684\u4e09\u5927\u95ee\u9898": [[19, "id4"]], "\u6839\u672c\u95ee\u9898\uff1a\u64cd\u4f5c\u7cfb\u7edf\u7f3a\u4e4f\u201c\u81ea\u52a8\u5316\u201d\u8fd9\u4e2a\u57fa\u7840\u80fd\u529b": [[19, "id5"]], "\u89e3\u51b3\u65b9\u6848\uff1aUFO2 / AgentOS": [[19, "ufo2-agentos"]], "3.System Design of UFO2": [[19, "system-design-of-ufo2"]], "3.1. UFO2 as a System Substrate for Automation": [[19, "ufo2-as-a-system-substrate-for-automation"]], "3.2. HostAgent: System-Level Orchestration and Execution Control": [[19, "hostagent-system-level-orchestration-and-execution-control"]], "\u5b83\u4e3b\u8981\u505a\u4ec0\u4e48\uff1f": [[19, "id6"]], "\u600e\u4e48\u63a7\u5236\u6267\u884c\u6d41\u7a0b\uff1f": [[19, "id7"]], "\u600e\u4e48\u7ba1\u7406\u8bb0\u5fc6\uff1f": [[19, "id8"]], "\u5b83\u7684\u4f5c\u7528\u603b\u7ed3\uff1a": [[19, "id9"]], "3.3. AppAgent: Application-Specialized Execution Runtime": [[19, "appagent-application-specialized-execution-runtime"]], "\u4ec0\u4e48\u662f AppAgent\uff1f": [[19, "appagent"]], "AppAgent \u7684\u6838\u5fc3\u7279\u70b9\uff1a": [[19, "id10"]], "\u5b83\u662f\u600e\u4e48\u5de5\u4f5c\u7684\uff1f": [[19, "id11"]], "\u611f\u77e5\u5c42\uff1a": [[19, "id12"]], "\u8f93\u51fa\u5c42\uff1a": [[19, "id13"]], "\u6267\u884c\u63a7\u5236\uff08\u72b6\u6001\u673a\uff09\uff1a": [[19, "id14"]], "\u8bb0\u5fc6\u4e0e\u5171\u4eab\u72b6\u6001\uff1a": [[19, "id15"]], "\u53ef\u6269\u5c55\u6027\uff1a": [[19, "id16"]], "3.4. Hybrid Control Detection": [[19, "hybrid-control-detection"]], "3.5. Unified GUI\u2013API Action Orchestrator": [[19, "unified-guiapi-action-orchestrator"]], "3.6. Continuous Knowledge Integration Substrate": [[19, "continuous-knowledge-integration-substrate"]], "3.7. Speculative Multi-Action Execution": [[19, "speculative-multi-action-execution"]], "4.Picture-in-Picture Interface": [[19, "picture-in-picture-interface"]], "\u2705 \u4e3a\u4ec0\u4e48\u8981\u7528 PiP\uff1f": [[19, "pip"]], "\u2705 PiP \u662f\u4ec0\u4e48\uff1f": [[19, "id18"]], "\u2705 \u6280\u672f\u600e\u4e48\u5b9e\u73b0\uff1f": [[19, "id19"]], "\u2705 \u6709\u4ec0\u4e48\u597d\u5904\uff1f": [[19, "id20"]], "5.Implementation and Specialized Engineering Design": [[19, "implementation-and-specialized-engineering-design"]], "6.Evaluation": [[19, "evaluation"]], "6.1 Experimental Setup": [[19, "experimental-setup"]], "6.2 Success Rate Comparison": [[19, "success-rate-comparison"]], "6.3 Evaluation on Hybrid Control Detection": [[19, "evaluation-on-hybrid-control-detection"]], "6.4 Effectiveness of GUI + API Integration": [[19, "effectiveness-of-gui-api-integration"]], "6.5 Continuous Knowledge Integration Evaluation": [[19, "continuous-knowledge-integration-evaluation"]], "6.6 Effectiveness of Speculative Multi-Action Execution": [[19, "effectiveness-of-speculative-multi-action-execution"]], "6.7 Operator as an AppAgent": [[19, "operator-as-an-appagent"]], "6.8 Efficiency Analysis": [[19, "efficiency-analysis"]], "6.9 Model Ablation": [[19, "model-ablation"]], "7.Discussion & Future Work": [[19, "discussion-future-work"]], "\u23f1\ufe0f \u5ef6\u8fdf\u4e0e\u54cd\u5e94\u901f\u5ea6": [[19, "id23"]], "\ud83e\udde0 \u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\u7684\u5dee\u8ddd": [[19, "id24"]], "\ud83d\udcbb \u8de8\u64cd\u4f5c\u7cfb\u7edf\u7684\u901a\u7528\u6027": [[19, "id25"]], "\u2705 \u603b\u7ed3\u4e00\u53e5\u8bdd\uff1a": [[19, "id26"], [122, "id12"], [144, "id8"], [169, "id6"]], "8.Related Work": [[19, "related-work"], [48, "related-work"]], "8.1. Computer-Using Agents (CUAs)": [[19, "computer-using-agents-cuas"]], "8.2. LLMs for Operating Systems": [[19, "llms-for-operating-systems"]], "\ud83d\udccc UFO2 \u7684\u4f4d\u7f6e\uff1a": [[19, "id27"]], "9.Conclusion": [[19, "conclusion"]], "2210.03629_ReAct": [[20, "react"]], "2303.08268_Chat-with-the-Environment": [[21, "chat-with-the-environment"]], "\u6b63\u6587": [[21, "id2"]], "2303.11366_Reflexion: Language Agents with Verbal Reinforcement Learning": [[22, "reflexion-language-agents-with-verbal-reinforcement-learning"]], "2303.16434_TaskMatrix.AI": [[23, "taskmatrix-ai"]], "\u5927\u8111": [[23, "id2"]], "\u63a5\u53e3\u5e73\u53f0": [[23, "id3"]], "API \u9009\u62e9\u5668": [[23, "api"]], "2304.03442_Generative-Agents": [[24, "generative-agents"]], "Generative Agent Architecture": [[24, "generative-agent-architecture"]], "Memory and Retrieval": [[24, "memory-and-retrieval"]], "Reflection": [[24, "reflection"]], "Planning and Reacting": [[24, "planning-and-reacting"]], "2307.07924_ChatDev: Communicative Agents for Software Development": [[25, "chatdev-communicative-agents-for-software-development"]], "2308.00352_MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework": [[26, "metagpt-meta-programming-for-a-multi-agent-collaborative-framework"]], "2308.04026_AgentSims: An Open-Source Sandbox for Large Language Model Evaluation": [[27, "agentsims-an-open-source-sandbox-for-large-language-model-evaluation"]], "2308.08155_AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation": [[28, "autogen-enabling-next-gen-llm-applications-via-multi-agent-conversation"]], "2308.10848_AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors": [[29, "agentverse-facilitating-multi-agent-collaboration-and-exploring-emergent-behaviors"]], "\u7406\u5ff5": [[29, "id2"]], "Environment": [[29, "environment"]], "\u667a\u80fd\u4f53": [[29, "id3"]], "2310.06117_Step-Back: Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models": [[30, "step-back-take-a-step-back-evoking-reasoning-via-abstraction-in-large-language-models"]], "2402.18679_MetaGPT_DI: Data Interpreter: An LLM Agent For Data Science": [[31, "metagpt-di-data-interpreter-an-llm-agent-for-data-science"]], "INTRODUCTION": [[31, "introduction"]], "2407.07061_IoA: Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence": [[32, "ioa-internet-of-agents-weaving-a-web-of-heterogeneous-agents-for-collaborative-intelligence"]], "2.1 OVERVIEW OF IOA": [[32, "overview-of-ioa"]], "2.2 ARCHITECTURE OF IOA": [[32, "architecture-of-ioa"]], "2.3 KEY MECHANISMS": [[32, "key-mechanisms"]], "2.3.1 Agent Registration and Discovery": [[32, "agent-registration-and-discovery"]], "2.3.2 Autonomous Nested Team Formation": [[32, "autonomous-nested-team-formation"]], "2.3.3 Autonomous Conversation Flow Control": [[32, "autonomous-conversation-flow-control"]], "2.3.4 Task Assignment and Execution": [[32, "task-assignment-and-execution"]], "2.5 Putting It All Together": [[32, "putting-it-all-together"]], "2408.08435_ADAS: Automated Design of Agentic Systems": [[33, "adas-automated-design-of-agentic-systems"]], "Prompt": [[33, "prompt"]], "2408.08435_ADAS: Automating Agentic Workflow Generation": [[34, "adas-automating-agentic-workflow-generation"]], "Introduce": [[34, "introduce"], [36, "introduce"]], "PRELIMINARY": [[34, "preliminary"]], "2410.17238_SELA: Tree-Search Enhanced LLM Agents for Automated Machine Learning": [[35, "sela-tree-search-enhanced-llm-agents-for-automated-machine-learning"]], "1 Introduction": [[35, "introduction"], [39, "introduction"], [43, "introduction"], [45, "introduction"], [47, "introduction"], [49, "introduction"], [50, "introduction"], [52, "introduction"], [53, "introduction"], [54, "introduction"], [55, "introduction"], [56, "introduction"], [57, "introduction"], [58, "introduction"], [59, "introduction"], [60, "introduction"], [61, "introduction"], [63, "introduction"], [64, "introduction"], [65, "introduction"], [67, "introduction"], [68, "introduction"], [69, "introduction"], [70, "introduction"], [75, "introduction"], [76, "introduction"], [77, "introduction"], [84, "introduction"], [85, "introduction"], [134, "introduction"], [151, "introduction"], [152, "introduction"], [155, "introduction"], [166, "introduction"], [172, "introduction"], [173, "introduction"], [174, "introduction"], [175, "introduction"], [182, "introduction"], [214, "introduction"], [217, "introduction"], [236, "introduction"], [237, "introduction"], [238, "introduction"], [239, "introduction"], [241, "introduction"], [242, "introduction"]], "2 Related Works": [[35, "related-works"], [53, "related-works"]], "3 Method": [[35, "method"], [173, "method"]], "3.1 Insight Proposal and Search Space Creation": [[35, "insight-proposal-and-search-space-creation"]], "3.2 Pipeline Execution and Code Generation": [[35, "pipeline-execution-and-code-generation"]], "3.3 Tree Search in Machine Learning Experiments": [[35, "tree-search-in-machine-learning-experiments"]], "2410.21012_FACT: Examining the Effectiveness of Iterative Context Rewriting for Multi-fact Retrieval": [[36, "fact-examining-the-effectiveness-of-iterative-context-rewriting-for-multi-fact-retrieval"]], "2504.01990_Advances and Challenges in Foundation Agents": [[37, "advances-and-challenges-in-foundation-agents"]], "2506.12508_AgentOrchestra: A Hierarchical Multi-Agent Framework for General-Purpose Task Solving": [[38, "agentorchestra-a-hierarchical-multi-agent-framework-for-general-purpose-task-solving"]], "3.AgentOrchestra": [[38, "agentorchestra"]], "4.Experiments": [[38, "experiments"], [74, "experiments"], [145, "experiments"]], "\u5b9e\u9a8c\u76ee\u7684": [[38, "id1"]], "\u8bc4\u6d4b\u57fa\u51c6\uff08Benchmark\uff09": [[38, "benchmark"]], "\u8bc4\u4f30\u65b9\u5f0f": [[38, "id2"], [236, "id20"]], "\u5b9e\u9a8c\u7ed3\u679c\uff08\u7b80\u8981\uff09": [[38, "id3"]], "\u603b\u7ed3\u4eae\u70b9": [[38, "id4"], [218, "id2"]], "2505.22101_MemOS: An Operating System for Memory-Augmented Generation (MAG) in LLM (Short Version)": [[39, "memos-an-operating-system-for-memory-augmented-generation-mag-in-llm-short-version"]], "2 Memory in Large Language Models": [[39, "memory-in-large-language-models"], [242, "memory-in-large-language-models"]], "3 MemOS Design Philosophy": [[39, "memos-design-philosophy"], [242, "memos-design-philosophy"]], "4 MemOS": [[39, "memos"]], "4.1 MemOS \u4e2d\u7684\u8bb0\u5fc6\u7c7b\u578b": [[39, "id2"]], "4.2 \u8bb0\u5fc6\u7acb\u65b9\u4f53\uff08MemCube\uff09\uff1a\u6838\u5fc3\u8d44\u6e90": [[39, "memcube"]], "4.3 MemOS \u67b6\u6784": [[39, "id3"]], "4.4 \u7cfb\u7edf\u6267\u884c\u6d41\u7a0b": [[39, "id4"]], "5 Conclusion": [[39, "conclusion"], [43, "conclusion"], [47, "conclusion"], [53, "conclusion"], [57, "conclusion"], [59, "conclusion"], [76, "conclusion"], [152, "conclusion"], [166, "conclusion"]], "2205.00445_MRKL": [[40, "mrkl"]], "2302.04761_Toolformer: Language Models Can Teach Themselves to Use Tools": [[41, "toolformer-language-models-can-teach-themselves-to-use-tools"]], "2303.17580_HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face": [[42, "hugginggpt-solving-ai-tasks-with-chatgpt-and-its-friends-in-hugging-face"]], "2307.16789_ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs": [[43, "toolllm-facilitating-large-language-models-to-master-16000-real-world-apis"]], "LLM\u603b\u7ed3": [[43, "llm"], [52, "llm"], [134, "llm"], [166, "llm"], [230, "llm"]], "1. \u80cc\u666f\u4e0e\u52a8\u673a": [[43, "id2"], [56, "id2"], [59, "id2"], [77, "id2"], [182, "id2"], [242, "id1"]], "2. ToolLLM \u6846\u67b6": [[43, "toolllm"]], "(1) \u6570\u636e\u6784\u5efa\uff1aToolBench": [[43, "toolbench"]], "(2) \u6a21\u578b\u8bad\u7ec3\uff1aToolLLaMA": [[43, "toolllama"]], "(3) \u8bc4\u4f30\uff1aToolEval": [[43, "tooleval"]], "3. \u5b9e\u9a8c\u4e0e\u7ed3\u679c": [[43, "id3"]], "4. \u603b\u7ed3": [[43, "id4"], [49, "id7"], [152, "id13"]], "2 Dataset Construction": [[43, "dataset-construction"]], "2.1 API\u6536\u96c6": [[43, "api"]], "2.2 \u6307\u4ee4\u751f\u6210": [[43, "id5"]], "2.3 \u89e3\u51b3\u65b9\u6848\u8def\u5f84\u6807\u6ce8": [[43, "id6"]], "3 Experiments": [[43, "experiments"], [45, "experiments"], [57, "experiments"], [70, "experiments"], [134, "experiments"], [151, "experiments"]], "\u4e00\u3001\u8bc4\u4f30\u6307\u6807\u4e0e\u521d\u6b65\u5b9e\u9a8c": [[43, "id8"]], "\u4e8c\u3001API \u68c0\u7d22\u5668\u7684\u6027\u80fd\u8bc4\u4f30": [[43, "id9"]], "\u4e09\u3001DFSDT \u4e0e ReACT \u7684\u5bf9\u6bd4\u5b9e\u9a8c": [[43, "dfsdt-react"]], "3.2 Main Experiments": [[43, "main-experiments"]], "3.2 \u4e3b\u8981\u5b9e\u9a8c\u603b\u7ed3": [[43, "id11"]], "\u6a21\u578b\u8bad\u7ec3": [[43, "id12"]], "\u5b9e\u9a8c\u8bbe\u7f6e": [[43, "id13"], [43, "id17"], [61, "id12"], [77, "id9"], [151, "id2"], [151, "id8"]], "\u57fa\u7ebf\u6a21\u578b": [[43, "id14"]], "\u5b9e\u9a8c\u7ed3\u679c": [[43, "id15"], [43, "id18"], [77, "id11"], [135, "id14"], [151, "id4"], [236, "id5"], [238, "id4"], [240, "id6"]], "\u7ed3\u8bba": [[43, "id16"], [43, "id19"], [71, "id9"], [79, "id4"], [85, "id15"], [98, "id10"], [135, "id5"], [172, "id8"], [230, "id4"]], "3.3 APIBench \u4e0a\u7684\u5206\u5e03\u5916\uff08OOD\uff09\u6cdb\u5316\u5b9e\u9a8c": [[43, "apibench-ood"]], "4 Related Work": [[43, "related-work"], [75, "related-work"]], "Appendix": [[43, "appendix"], [47, "appendix"], [50, "appendix"], [62, "appendix"], [101, "appendix"], [166, "appendix"], [226, "appendix"], [227, "appendix"]], "Appendix A Implementation Details": [[43, "appendix-a-implementation-details"]], "A.1 API\u7b5b\u9009\uff08Filtering RapidAPI\uff09": [[43, "a-1-api-filtering-rapidapi"]], "A.2 API\u54cd\u5e94\u538b\u7f29\uff08API Response Compression\uff09": [[43, "a-2-api-api-response-compression"]], "A.3 ToolLLaMA\u6a21\u578b\u8bad\u7ec3\uff08Training ToolLLaMA\uff09": [[43, "a-3-toolllama-training-toolllama"]], "A.4 DFSDT\u7b97\u6cd5\uff08DFSDT\uff09": [[43, "a-4-dfsdt-dfsdt"]], "A.5 ToolEval\u8bc4\u4f30\u65b9\u6cd5\uff08ToolEval\uff09": [[43, "a-5-tooleval-tooleval"]], "1. \u901a\u8fc7\u7387\uff08Pass Rate\uff09": [[43, "pass-rate"]], "2. \u80dc\u7387\uff08Win Rate\uff09": [[43, "win-rate"]], "3. \u4e0e\u4eba\u5de5\u8bc4\u4f30\u5bf9\u6bd4": [[43, "id20"]], "4. \u8bc4\u4f30\u6311\u6218": [[43, "id21"]], "A.6 APIBench\u5b9e\u9a8c\u7ec6\u8282": [[43, "a-6-apibench"]], "A.7 Prompts for Instruction Generation": [[43, "a-7-prompts-for-instruction-generation"]], "1. \u6307\u4ee4\u751f\u6210\u63d0\u793a\uff08Instruction Generation Prompts\uff09": [[43, "instruction-generation-prompts"]], "1.1 \u5355\u5de5\u5177\u6307\u4ee4\u751f\u6210\u4efb\u52a1\u63cf\u8ff0": [[43, "id23"]], "1.2 \u591a\u5de5\u5177\u6307\u4ee4\u751f\u6210\u4efb\u52a1\u63cf\u8ff0": [[43, "id24"]], "1.3 \u63d0\u4f9b\u7684API\u793a\u4f8b": [[43, "id25"]], "2. \u89e3\u51b3\u65b9\u6848\u8def\u5f84\u6ce8\u89e3\u63d0\u793a\uff08Solution Path Annotation Prompts\uff09": [[43, "solution-path-annotation-prompts"]], "2.1 \u7cfb\u7edf\u63d0\u793a": [[43, "id26"]], "2.2 \u591a\u6837\u5316\u7528\u6237\u63d0\u793a": [[43, "id27"]], "2.3 \u4efb\u52a1\u63cf\u8ff0\u6a21\u677f": [[43, "id28"]], "\u8bc4\u6d4b\u57fa\u51c6": [[44, "id2"], [44, "id3"]], "\u6570\u636e\u96c6-Agent": [[44, "agent"]], "\u6570\u636e\u96c6-QA": [[44, "qa"]], "\u6570\u636e\u96c6-\u7f16\u7a0b": [[44, "id4"]], "\u6570\u636e\u96c6-\u957f\u6587\u672c": [[44, "id5"]], "\u6570\u636e\u96c6-\u6570\u5b66": [[44, "id6"]], "\u6570\u636e\u96c6-\u56fe\u7247": [[44, "id7"]], "\u6570\u636e\u96c6": [[44, "id8"], [135, "id9"], [217, "id4"]], "2312.14033_T-Eval: Evaluating the Tool Utilization Capability of Large Language Models Step by Step": [[45, "t-eval-evaluating-the-tool-utilization-capability-of-large-language-models-step-by-step"]], "2 T-Eval": [[45, "t-eval"]], "1. \u8bc4\u4f30\u7ef4\u5ea6\u7684\u5206\u89e3\uff082.1 Evaluation Decomposition\uff09": [[45, "evaluation-decomposition"]], "2. \u7ec6\u7c92\u5ea6\u8bc4\u4f30\u534f\u8bae\uff082.2 Fine-Grained Evaluation Protocol\uff09": [[45, "fine-grained-evaluation-protocol"]], "3. \u6570\u636e\u96c6\u6784\u5efa\uff082.3 Dataset Construction\uff09": [[45, "dataset-construction"]], "4. \u6570\u636e\u96c6\u6982\u89c8\uff082.4 Dataset Summary\uff09": [[45, "dataset-summary"]], "1. \u5b9e\u9a8c\u8bbe\u7f6e": [[45, "id3"], [76, "id3"]], "2. \u4e3b\u8981\u5b9e\u9a8c\u7ed3\u679c": [[45, "id4"]], "3. \u7814\u7a76\u95ee\u9898\u4e0e\u5206\u6790": [[45, "id5"]], "Q1: \u54ea\u4e2a\u6a21\u578b\u66f4\u9002\u5408\u5de5\u5177\u4f7f\u7528\uff1f": [[45, "q1"]], "Q2: \u5f53\u524d\u6a21\u578b\u4e0e\u7406\u60f3\u5de5\u5177\u4ee3\u7406\u7684\u5dee\u8ddd\uff1f": [[45, "q2"]], "Q3: \u4ec0\u4e48\u6837\u7684\u8bad\u7ec3\u6570\u636e\u6709\u52a9\u4e8e\u5de5\u5177\u4f7f\u7528\uff1f": [[45, "q3"]], "4 Discussion": [[45, "discussion"], [68, "discussion"]], "4.1 \u683c\u5f0f\u9075\u5faa\u4e0e\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u7684\u5173\u7cfb": [[45, "id7"]], "4.2 \u5305\u5bb9\u6027\u8bc4\u4f30\u534f\u8bae\u7684\u5fc5\u8981\u6027": [[45, "id8"]], "4.3 \u4e0e\u5176\u4ed6\u57fa\u51c6\u7684\u6bd4\u8f83": [[45, "id9"]], "5 Related Work": [[45, "related-work"], [54, "related-work"], [68, "related-work"], [217, "related-work"], [238, "related-work"]], "6 Conclusion": [[45, "conclusion"], [54, "conclusion"], [58, "conclusion"], [60, "conclusion"], [67, "conclusion"], [68, "conclusion"], [77, "conclusion"], [172, "conclusion"], [173, "conclusion"], [174, "conclusion"], [176, "conclusion"], [217, "conclusion"], [236, "conclusion"], [238, "conclusion"], [239, "conclusion"]], "Appendix A T-Eval\u00a0Benchmark Details": [[45, "appendix-a-t-eval-benchmark-details"]], "Appendix B Implementation Details": [[45, "appendix-b-implementation-details"], [229, "appendix-b-implementation-details"]], "Appendix C Detailed Evaluation Metrics": [[45, "appendix-c-detailed-evaluation-metrics"]], "\u603b\u4f53\u7ed3\u6784": [[45, "id11"]], "C.1 Instruct\uff08\u751f\u6210\u6307\u4ee4\uff09": [[45, "c-1-instruct"]], "C.2 Plan\uff08\u89c4\u5212\uff09": [[45, "c-2-plan"]], "C.3 Reason\uff08\u63a8\u7406\uff09": [[45, "c-3-reason"]], "C.4 Retrieve\uff08\u68c0\u7d22\uff09": [[45, "c-4-retrieve"]], "C.5 Understand\uff08\u7406\u89e3\u53c2\u6570\uff09": [[45, "c-5-understand"]], "C.6 Review\uff08\u8bc4\u4f30\u54cd\u5e94\uff09": [[45, "c-6-review"]], "Appendix D API Documentation": [[45, "appendix-d-api-documentation"]], "2406.12045_\u03c4-bench: A Benchmark for Tool-Agent-User": [[46, "bench-a-benchmark-for-tool-agent-user"]], "\ud83c\udf1f \u8bed\u8a00\u4ee3\u7406\uff08Language Agents\uff09\u7684\u6f5c\u529b\u4e0e\u6311\u6218": [[46, "language-agents"]], "\ud83e\uddea \u65b0\u63d0\u51fa\u7684 \u03c4-bench \u8bc4\u6d4b\u6846\u67b6": [[46, "bench"]], "\ud83d\udcca \u5b9e\u9a8c\u53d1\u73b0": [[46, "id2"]], "\ud83c\udfaf \u76ee\u6807\u4e0e\u8d21\u732e": [[46, "id3"]], "\u03c4-bench \u505a\u4e86\u4ec0\u4e48\uff1a": [[46, "id4"]], "\u4e0e\u5df2\u6709\u5de5\u4f5c\u7684\u533a\u522b\uff1a": [[46, "id5"]], "\u03c4-bench \u7684\u7279\u70b9\uff1a": [[46, "id6"]], "3.\u03c4-bench: A benchmark for T ool-A gent-U ser Interaction": [[46, "bench-a-benchmark-for-t-ool-a-gent-u-ser-interaction"]], "\ud83d\udd01 \u4efb\u52a1\u5efa\u6a21": [[46, "id7"]], "\ud83d\udd27 \u6570\u636e\u5e93\u548cAPI\u5de5\u5177": [[46, "api"]], "\ud83d\udcdc \u9886\u57df\u89c4\u5219\uff08Policy\uff09": [[46, "policy"]], "\ud83d\udc64 \u6a21\u62df\u7528\u6237": [[46, "id8"]], "\ud83e\udde9 \u4efb\u52a1\u5b9e\u4f8b": [[46, "id9"]], "\ud83c\udfc6 \u5956\u52b1\u8ba1\u7b97": [[46, "id10"]], "\ud83d\udcc8 \u8bc4\u4ef7\u6307\u6807\uff08pass^k\uff09": [[46, "pass-k"]], "\ud83d\udcca \u793a\u4f8b\uff1a\u4e24\u4e2a\u4efb\u52a1\u9886\u57df": [[46, "id11"]], "4. Benchmark Construction": [[46, "benchmark-construction"]], "\u57fa\u51c6\u6784\u5efa\u6d41\u7a0b\uff08\u4e09\u4e2a\u9636\u6bb5\uff09": [[46, "id12"]], "4.1 Domains": [[46, "domains"]], "4.2 Key Characteristics": [[46, "key-characteristics"]], "5.Experiments": [[46, "experiments"]], "\ud83d\udccc \u5b9e\u9a8c\u5185\u5bb9\u6982\u8ff0": [[46, "id13"]], "\ud83e\udde0 \u65b9\u6cd5\u5bf9\u6bd4": [[46, "id14"]], "\ud83d\udcca \u4e3b\u8981\u7ed3\u679c": [[46, "id15"]], "\ud83e\udde9 \u5931\u8d25\u539f\u56e0\u5206\u6790\uff08gpt-4o\uff09": [[46, "gpt-4o"]], "\ud83e\uddea \u89c4\u5219\u4f5c\u7528\u7684\u5bf9\u6bd4\u5b9e\u9a8c": [[46, "id16"]], "\ud83d\udd0d \u7ed3\u8bba": [[46, "id17"]], "6.Disscussion": [[46, "disscussion"]], "\u03c4-bench \u7684\u4f5c\u7528\uff1a": [[46, "id18"]], "\u5b58\u5728\u7684\u6539\u8fdb\u7a7a\u95f4\uff1a": [[46, "id19"]], "\u667a\u80fd\u4f53\u9762\u4e34\u7684\u6311\u6218\uff1a": [[46, "id20"]], "2506.07982_\ud835\udf0f\u00b2-Bench: Evaluating Conversational Agents in a Dual-Control Environment": [[47, "bench-evaluating-conversational-agents-in-a-dual-control-environment"]], "LLM \u603b\u7ed3": [[47, "llm"], [50, "llm"], [57, "llm"], [59, "llm"], [60, "llm"], [64, "llm"], [67, "llm"], [70, "llm"], [77, "llm"], [85, "llm"], [135, "llm"], [182, "llm"], [214, "llm"], [236, "llm"], [241, "llm"]], "1. \u73b0\u6709\u57fa\u51c6\u7684\u5c40\u9650\u6027": [[47, "id2"]], "2. \u03c4\u00b2-bench\u7684\u6838\u5fc3\u521b\u65b0\uff1a\u53cc\u63a7\u73af\u5883": [[47, "bench"]], "3. \u03c4\u00b2-bench\u7684\u56db\u5927\u8d21\u732e": [[47, "id3"]], "2 Related Work": [[47, "related-work"], [56, "related-work"], [58, "related-work"], [59, "related-work"], [60, "related-work"], [63, "related-work"], [64, "related-work"], [65, "related-work"], [76, "related-work"], [77, "related-work"], [166, "related-work"], [172, "related-work"], [173, "related-work"], [175, "related-work"], [236, "related-work"], [239, "related-work"]], "\u4e00\u3001\u5bf9\u8bdd\u5f0fAI\u4ee3\u7406\u7684\u57fa\u51c6\u6d4b\u8bd5": [[47, "ai"]], "\u4e8c\u3001\u5bf9\u8bdd\u4ee3\u7406\u7684\u7528\u6237\u6a21\u62df": [[47, "id5"]], "\u4e09\u3001\u591a\u4ee3\u7406\u57fa\u51c6": [[47, "id6"]], "3 \\tau^{2}-bench: Evaluating Agents in a Dual-Control Environment": [[47, "tau-2-bench-evaluating-agents-in-a-dual-control-environment"]], "\u7ae0\u8282\u603b\u7ed3\uff1a": [[47, "id8"]], "3.1 Dec-POMDP \u6a21\u578b\u63cf\u8ff0": [[47, "dec-pomdp"]], "3.2 \u57df\u4e0e\u4efb\u52a1\u521b\u5efa": [[47, "id9"]], "3.3 \u4efb\u52a1\u8bc4\u4f30": [[47, "id10"]], "4 Experiments": [[47, "experiments"], [53, "experiments"], [61, "experiments"], [65, "experiments"], [76, "experiments"], [77, "experiments"], [166, "experiments"], [172, "experiments"], [176, "experiments"], [201, "experiments"], [236, "experiments"]], "4 \u5b9e\u9a8c": [[47, "id12"]], "4.1 \u4ee3\u7406\u8bbe\u7f6e": [[47, "id13"]], "4.2 \u5b9e\u9a8c\u7ed3\u679c": [[47, "id14"]], "Pass^k \u6307\u6807": [[47, "pass-k"]], "\u6d88\u878d\u5206\u6790": [[47, "id15"]], "\u653f\u7b56\u6587\u6863\u5bf9\u6027\u80fd\u7684\u5f71\u54cd": [[47, "id16"]], "\u52a8\u4f5c\u6570\u91cf\u548c\u5b50\u4efb\u52a1\u7684\u590d\u6742\u6027\u5f71\u54cd": [[47, "id17"]], "\u95ee\u9898\u7c7b\u578b\u7684\u5f71\u54cd": [[47, "id18"]], "\u7528\u6237\u89d2\u8272\uff08Persona\uff09\u7684\u5f71\u54cd": [[47, "persona"]], "4.3 \u53cc\u63a7\u673a\u5236\u5bf9\u57fa\u51c6\u53ef\u9760\u6027\u7684\u5f71": [[47, "id19"]], "\u7528\u6237\u6a21\u62df\u5668\u8d28\u91cf\u8bc4\u4f30": [[47, "id20"]], "Broader Impact": [[47, "broader-impact"]], "Appendix A Telecom Domain": [[47, "appendix-a-telecom-domain"]], "\u7528\u6237\u753b\u50cf\uff08User Persona\uff09": [[47, "user-persona"]], "Appendix B Verifying Original \\tau^{2}-bench": [[47, "appendix-b-verifying-original-tau-2-bench"]], "B.1 \u9a8c\u8bc1\u5b9e\u73b0": [[47, "b-1"]], "B.2 \u9a8c\u8bc1\u4efb\u52a1": [[47, "b-2"]], "Appendix C Prompts": [[47, "appendix-c-prompts"], [60, "appendix-c-prompts"]], "\u603b\u7ed3\u5185\u5bb9\uff1a": [[47, "id23"]], "C.1 Agent\u7cfb\u7edf\u63d0\u793a": [[47, "c-1-agent"]], "C.2 \u7528\u6237\u7cfb\u7edf\u63d0\u793a": [[47, "c-2"]], "\u9644\uff1a\u793a\u4f8b\u4efb\u52a1\u6307\u4ee4": [[47, "id24"]], "\u603b\u7ed3\u8bc4\u4ef7\uff1a": [[47, "id25"]], "Appendix D Domain Policies": [[47, "appendix-d-domain-policies"]], "\u8bba\u6587\u7ae0\u8282\u5185\u5bb9\u603b\u7ed3": [[47, "id26"]], "D.1 \u96f6\u552e\u653f\u7b56\uff08Retail Policy\uff09": [[47, "d-1-retail-policy"]], "D.2 \u822a\u7a7a\u653f\u7b56\uff08Airline Policy\uff09": [[47, "d-2-airline-policy"]], "D.3 \u7535\u4fe1\u653f\u7b56\uff08Telecom Policy\uff09": [[47, "d-3-telecom-policy"]], "Appendix E User Simulator Quality": [[47, "appendix-e-user-simulator-quality"]], "E.1 \u96f6\u552e\u9886\u57df\u5e38\u89c1\u9519\u8bef\u7c7b\u578b\u4e0e\u5931\u8d25\u6a21\u5f0f": [[47, "e-1"]], "E.2 \u822a\u7a7a\u9886\u57df\u5e38\u89c1\u9519\u8bef\u7c7b\u578b\u4e0e\u5931\u8d25\u6a21\u5f0f": [[47, "e-2"]], "E.3 \u7535\u4fe1\u9886\u57df\u5e38\u89c1\u9519\u8bef\u7c7b\u578b\u4e0e\u5931\u8d25\u6a21\u5f0f": [[47, "e-3"]], "E.4 \u4ee3\u8868\u6027\u6848\u4f8b": [[47, "e-4"]], "2107.03374_HumanEval: Evaluating Large Language Models Trained on Code": [[48, "humaneval-evaluating-large-language-models-trained-on-code"]], "2.Evaluation Framework": [[48, "evaluation-framework"]], "2.1 Functional Correctness": [[48, "functional-correctness"]], "2.2 HumanEval: Hand-Written Evaluation Set": [[48, "humaneval-hand-written-evaluation-set"]], "2.3 Sandbox for Executing Generated Programs": [[48, "sandbox-for-executing-generated-programs"]], "3.Code Fine-Tuning": [[48, "code-fine-tuning"]], "\ud83d\udcca \u6570\u636e\u4e0e\u8bad\u7ec3\u65b9\u6cd5\uff1a": [[48, "id2"]], "\u2705 \u8bc4\u4f30\u65b9\u5f0f\u4e0e\u7ed3\u679c\uff1a": [[48, "id3"]], "\ud83d\udd0d \u4e0e\u5176\u4ed6\u6a21\u578b\u5bf9\u6bd4\uff1a": [[48, "id4"]], "\ud83e\uddea \u5728 APPS \u7f16\u7a0b\u6d4b\u8bd5\u96c6\u4e0a\u7684\u8868\u73b0\uff1a": [[48, "apps"]], "4.Supervised Fine-Tuning": [[48, "supervised-fine-tuning"]], "\ud83d\udccc \u80cc\u666f\u95ee\u9898": [[48, "id5"]], "\u2705 \u89e3\u51b3\u65b9\u6cd5\uff1a\u6784\u9020\u9ad8\u8d28\u91cf\u51fd\u6570\u8bad\u7ec3\u96c6\uff0c\u8fdb\u884c\u76d1\u7763\u5fae\u8c03": [[48, "id6"]], "1\ufe0f\u20e3 \u7f16\u7a0b\u7ade\u8d5b\u9898\uff084.1\uff09": [[48, "id7"]], "2\ufe0f\u20e3 \u6301\u7eed\u96c6\u6210\u6d4b\u8bd5\u4e2d\u7684\u51fd\u6570\uff084.2\uff09": [[48, "id8"]], "\ud83d\udd0d \u8d28\u91cf\u63a7\u5236\uff084.3\uff09": [[48, "id9"]], "\ud83e\uddea \u5fae\u8c03\u65b9\u6cd5\uff084.4\uff09": [[48, "id10"]], "\ud83d\udcc8 \u5b9e\u9a8c\u7ed3\u679c\uff084.5\uff09": [[48, "id11"]], "5.Docstring Generation": [[48, "docstring-generation"]], "6.Limitations": [[48, "limitations"], [71, "limitations"], [78, "limitations"], [145, "limitations"]], "7.Broader Impacts and Hazard Analysis": [[48, "broader-impacts-and-hazard-analysis"]], "\ud83d\udd0d \u603b\u4f53\u89c2\u70b9\uff1a": [[48, "id12"]], "\u26a0\ufe0f \u6838\u5fc3\u98ce\u9669\u7b80\u8981\u8bf4\u660e\uff1a": [[48, "id13"]], "\u4e00\u3001\u7a0b\u5e8f\u5f52\u7eb3\uff08Program Induction\uff09\uff1a": [[48, "program-induction"]], "\u4e8c\u3001\u7a0b\u5e8f\u751f\u6210\uff08Program Synthesis\uff09\uff1a": [[48, "program-synthesis"]], "\u4e09\u3001\u5927\u6a21\u578b\u9a71\u52a8\u7684\u8fdb\u5c55\uff1a": [[48, "id14"]], "\u56db\u3001\u6570\u636e\u96c6\u4e0e\u8bc4\u6d4b\uff1a": [[48, "id15"]], "\u4e94\u3001\u4ee3\u7801\u5f00\u53d1\u7684\u66f4\u5e7f\u6cdb\u4efb\u52a1\uff1a": [[48, "id16"]], "9.Conclusions": [[48, "conclusions"]], "2108.07732_MBPP: Program Synthesis with Large Language Models": [[49, "mbpp-program-synthesis-with-large-language-models"]], "1. \u80cc\u666f\u4e0e\u7814\u7a76\u52a8\u673a": [[49, "id1"]], "2. \u4e3b\u8981\u8d21\u732e": [[49, "id2"]], "2.1 \u65b0\u5efa\u4e24\u4e2a\u7528\u4e8e\u6d4b\u8bd5 Python \u7a0b\u5e8f\u5408\u6210\u7684\u6570\u636e\u96c6": [[49, "python"]], "2.2 \u5927\u8bed\u8a00\u6a21\u578b\u5728\u7a0b\u5e8f\u5408\u6210\u4efb\u52a1\u4e2d\u7684\u8868\u73b0": [[49, "id3"]], "2.3 \u6a21\u578b\u4e0e\u4eba\u7c7b\u534f\u4f5c\uff08Human-Model Collaboration\uff09": [[49, "human-model-collaboration"]], "2.4 \u6a21\u578b\u6267\u884c\u4ee3\u7801\u7684\u80fd\u529b\u5206\u6790": [[49, "id4"]], "2.5 \u6a21\u578b\u6027\u80fd\u7684\u654f\u611f\u6027\u5206\u6790\u4e0e\u9c81\u68d2\u6027\u8bc4\u4f30": [[49, "id5"]], "3. \u4e0e\u5176\u4ed6\u5de5\u4f5c\u7684\u5bf9\u6bd4": [[49, "id6"]], "2 Datasets": [[49, "datasets"]], "1. Mostly Basic Programming Problems (MBPP)": [[49, "mostly-basic-programming-problems-mbpp"]], "2. MathQA-Python": [[49, "mathqa-python"]], "3 Model and Methods": [[49, "model-and-methods"]], "4 MBPP Synthesis Results": [[49, "mbpp-synthesis-results"]], "1. \u6a21\u578b\u89c4\u6a21\u4e0e\u5408\u6210\u6027\u80fd\u7684\u5173\u7cfb": [[49, "id9"]], "2. \u6a21\u578b\u9519\u8bef\u7c7b\u578b\u5206\u6790": [[49, "id10"]], "3. \u63d0\u793a\u793a\u4f8b\u6570\u91cf\u5bf9\u6027\u80fd\u7684\u5f71\u54cd": [[49, "id11"]], "4. \u63d0\u793a\u793a\u4f8b\u5185\u5bb9\u5bf9\u6027\u80fd\u7684\u5f71\u54cd": [[49, "id12"]], "5. \u89e3\u51b3\u65b9\u6848\u7684\u6cdb\u5316\u80fd\u529b": [[49, "id13"]], "6. \u6a21\u578b\u8fc7\u5ea6\u62df\u5408\u6d4b\u8bd5\u65ad\u8a00": [[49, "id14"]], "7. \u91c7\u6837\u7b56\u7565\u5bf9\u6027\u80fd\u7684\u5f71\u54cd": [[49, "id15"]], "8. BLEU\u5206\u6570\u4e0e\u5408\u6210\u6027\u80fd\u7684\u76f8\u5173\u6027": [[49, "bleu"]], "9. \u9884\u8bad\u7ec3\u4e0e\u6d4b\u8bd5\u6570\u636e\u91cd\u53e0\u95ee\u9898": [[49, "id16"]], "4.9 Comparing Performance Between the Original and Edited Questions": [[49, "comparing-performance-between-the-original-and-edited-questions"]], "\u4e00\u3001\u6570\u636e\u96c6\u4e0e\u5b9e\u9a8c\u8bbe\u8ba1": [[49, "id18"]], "\u4e8c\u3001\u6a21\u578b\u6027\u80fd\u5bf9\u6bd4": [[49, "id19"]], "\u4e09\u3001\u7f16\u8f91\u5185\u5bb9\u5206\u6790": [[49, "id20"]], "\u56db\u3001\u6027\u80fd\u5dee\u5f02\u7684\u5173\u952e\u56e0\u7d20": [[49, "id21"]], "\u4e94\u3001\u9519\u8bef\u6a21\u5f0f\u5206\u6790\uff08\u89c1\u88684\uff09": [[49, "id22"]], "1. \u591a\u7ea6\u675f\u6216\u591a\u6b65\u9aa4\u7684\u95ee\u9898\uff08Multi-constraint / Multi-step Problems\uff09": [[49, "multi-constraint-multi-step-problems"]], "2. \u5b58\u5728\u5e38\u89c1\u53d8\u79cd\u7684\u95ee\u9898\uff08Problems with More-Common Siblings\uff09": [[49, "problems-with-more-common-siblings"]], "3. \u5176\u4ed6\u9519\u8bef\u7c7b\u578b": [[49, "id23"]], "5 Human-Model Collaboration Results": [[49, "human-model-collaboration-results"]], "6 Program Execution Results": [[49, "program-execution-results"]], "\u6838\u5fc3\u5185\u5bb9\u603b\u7ed3\u5982\u4e0b\uff1a": [[49, "id25"], [51, "id3"], [57, "id2"], [58, "id18"], [64, "id9"]], "1. \u7814\u7a76\u80cc\u666f\u4e0e\u95ee\u9898": [[49, "id26"]], "2. \u5b9e\u9a8c\u76ee\u6807": [[49, "id27"]], "3. \u5b9e\u9a8c\u8bbe\u8ba1\u4e0e\u8bbe\u7f6e": [[49, "id28"]], "4. \u5b9e\u9a8c\u4e00\uff1a\u96f6\u6837\u672c\u6267\u884c\u6027\u80fd\u5206\u6790": [[49, "id29"]], "5. \u5b9e\u9a8c\u4e8c\uff1a\u6267\u884c\u4efb\u52a1\u4e0a\u7684\u5fae\u8c03": [[49, "id30"]], "6. \u5b9e\u9a8c\u4e09\uff1a\u6267\u884c\u5fae\u8c03\u5bf9\u7a0b\u5e8f\u5408\u6210\u7684\u5f71\u54cd": [[49, "id31"]], "7. \u7ed3\u8bba\u4e0e\u5c55\u671b": [[49, "id32"]], "7 MathQA Results": [[49, "mathqa-results"]], "\u4e3b\u8981\u53d1\u73b0\u5305\u62ec\uff1a": [[49, "id33"]], "8 Related Work": [[49, "related-work"]], "\u4e00\u3001\u795e\u7ecf\u8bed\u8a00\u6a21\u578b\u7684\u542f\u53d1": [[49, "id35"]], "\u4e8c\u3001\u7a0b\u5e8f\u5408\u6210\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff08Machine Learning for Program Synthesis\uff09": [[49, "machine-learning-for-program-synthesis"]], "\u4e09\u3001\u9762\u5411\u8f6f\u4ef6\u5de5\u7a0b\u7684\u673a\u5668\u5b66\u4e60\uff08Machine Learning for Software Engineering\uff09": [[49, "machine-learning-for-software-engineering"]], "\u56db\u3001\u9762\u5411\u6e90\u4ee3\u7801\u7684\u673a\u5668\u5b66\u4e60\u57fa\u51c6\uff08Benchmarks for Machine Learning over Source Code\uff09": [[49, "benchmarks-for-machine-learning-over-source-code"]], "9 Risks and Limitations": [[49, "risks-and-limitations"]], "10 Conclusion": [[49, "conclusion"]], "Appendix A Appendix": [[49, "appendix-a-appendix"], [152, "appendix-a-appendix"], [237, "appendix-a-appendix"], [239, "appendix-a-appendix"]], "Appendix A \u9644\u5f55\u603b\u7ed3": [[49, "appendix-a"]], "A.1 \u7ed9\u4f17\u5305\u5de5\u4f5c\u8005\u548c\u4e13\u5bb6\u8bc4\u5ba1\u7684\u6307\u5bfc": [[49, "a-1"]], "A.2 \u4eba\u673a\u534f\u4f5c\u5b9e\u9a8c\u7684\u6307\u5bfc": [[49, "a-2"]], "A.3 \u6267\u884c\u5b9e\u9a8c\u4e2d\u7684\u63d0\u793a\u6a21\u677f": [[49, "a-3"]], "A.4 \u4eba\u673a\u4ea4\u4e92\u793a\u4f8b": [[49, "a-4"]], "\u603b\u4f53\u603b\u7ed3\uff1a": [[49, "id37"], [63, "id15"], [68, "id29"], [69, "id28"], [155, "id61"], [182, "id13"]], "2310.06770_SWE-bench: Can Language Models Resolve Real-World GitHub Issues?": [[50, "swe-bench-can-language-models-resolve-real-world-github-issues"]], "\u80cc\u666f\u4e0e\u52a8\u673a\uff1a": [[50, "id2"]], "SWE-bench \u7684\u8bbe\u8ba1\uff1a": [[50, "swe-bench"]], "SWE-bench \u7684\u4f18\u52bf\uff1a": [[50, "id3"]], "\u5b9e\u9a8c\u7ed3\u679c\uff1a": [[50, "id4"], [58, "id11"], [155, "id26"]], "\u8865\u5145\u8d21\u732e\uff1a": [[50, "id5"]], "2 SWE-bench": [[50, "id7"]], "\u4e00\u3001SWE-bench \u6982\u8ff0": [[50, "id8"]], "\u4e8c\u3001\u57fa\u51c6\u6784\u5efa\u8fc7\u7a0b\uff08Benchmark Construction\uff09": [[50, "benchmark-construction"]], "\u4e09\u3001\u4efb\u52a1\u5b9a\u4e49\uff08Task Formulation\uff09": [[50, "task-formulation"]], "\u56db\u3001SWE-bench \u7684\u7279\u70b9\uff08Features of SWE-bench\uff09": [[50, "swe-bench-features-of-swe-bench"]], "\u4e94\u3001SWE-bench Lite\uff08\u7b80\u5316\u7248\u672c\uff09": [[50, "swe-bench-lite"]], "3 SWE-Llama: Fine-tuning CodeLlama for SWE-bench": [[50, "swe-llama-fine-tuning-codellama-for-swe-bench"]], "4 Experimental Setup": [[50, "experimental-setup"]], "4.1 \u57fa\u4e8e\u68c0\u7d22\u7684\u65b9\u6cd5": [[50, "id10"]], "4.2 \u8f93\u5165\u683c\u5f0f": [[50, "id11"]], "4.3 \u8bc4\u4f30\u7684\u6a21\u578b": [[50, "id12"]], "5 Results": [[50, "results"], [52, "results"], [214, "results"]], "6 Related Work": [[50, "related-work"], [52, "related-work"], [55, "related-work"], [69, "related-work"], [70, "related-work"], [97, "related-work"], [237, "related-work"]], "7 Discussion": [[50, "discussion"]], "8 Ethics Statement": [[50, "ethics-statement"]], "9 Reproducibility Statement": [[50, "reproducibility-statement"]], "Appendix A Benchmark Details": [[50, "appendix-a-benchmark-details"]], "A.1 High Level Overview": [[50, "a-1-high-level-overview"]], "A.2 Construction Process": [[50, "a-2-construction-process"]], "A.3 Execution-Based Validation": [[50, "a-3-execution-based-validation"]], "A.4 \u8bc4\u4f30\u6d41\u7a0b\uff08Evaluation Procedure\uff09": [[50, "a-4-evaluation-procedure"]], "A.5 Evaluation Test Set Characterization": [[50, "a-5-evaluation-test-set-characterization"]], "A.6 Development Set Characterization": [[50, "a-6-development-set-characterization"]], "A.7 SWE-BENCH LITE CHARACTERIZATION": [[50, "a-7-swe-bench-lite-characterization"]], "Appendix B Additional Details on Training SWE-Llama": [[50, "appendix-b-additional-details-on-training-swe-llama"]], "Appendix C Additional Results": [[50, "appendix-c-additional-results"]], "C.1 Results with \u201cOracle\u201d Retrieval": [[50, "c-1-results-with-oracle-retrieval"]], "\u603b\u4f53\u7ed3\u8bba": [[50, "id14"], [63, "id9"], [182, "id17"], [239, "id11"]], "C.7 Software Engineering Metrics": [[50, "c-7-software-engineering-metrics"]], "Appendix D Additional Experimental Details": [[50, "appendix-d-additional-experimental-details"]], "D.1 \u68c0\u7d22\u7ec6\u8282": [[50, "d-1"]], "D.2 \u63a8\u7406\u8bbe\u7f6e": [[50, "d-2"]], "D.3 \u63d0\u793a\u6a21\u677f\u793a\u4f8b": [[50, "d-3"]], "Appendix E Societal Impact": [[50, "appendix-e-societal-impact"]], "Appendix F In-depth Analysis of SWE-Llama Generations": [[50, "appendix-f-in-depth-analysis-of-swe-llama-generations"]], "2402.16694_HumanEval-XL: A Multilingual Code Generation Benchmark for Cross-lingual Natural Language Generalization": [[51, "humaneval-xl-a-multilingual-code-generation-benchmark-for-cross-lingual-natural-language-generalization"]], "A Multilingual Code Generation Benchmark for Cross-lingual Natural Language Generalization": [[51, "a-multilingual-code-generation-benchmark-for-cross-lingual-natural-language-generalization"]], "1.\u00a0\u00a0\u00a0Introduction": [[51, "introduction"]], "2.\u00a0\u00a0\u00a0Related work": [[51, "related-work"]], "1. \u4ee3\u7801\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\uff08Code Generation Benchmarks\uff09": [[51, "code-generation-benchmarks"]], "2. \u591a\u8bed\u8a00\u4ee3\u7801\u5927\u6a21\u578b\uff08Multilingual Code LLMs\uff09": [[51, "multilingual-code-llms"]], "3.\u00a0\u00a0\u00a0HumanEval-XL": [[51, "humaneval-xl"]], "\u672c\u7ae0\u8282\u603b\u7ed3\uff1aHumanEval-XL \u7684\u8bbe\u8ba1\u4e0e\u6784\u5efa": [[51, "id1"]], "\u4e00\u3001\u8bbe\u8ba1\u539f\u5219\uff08Design Principles\uff09": [[51, "design-principles"]], "\u4e8c\u3001\u6570\u636e\u96c6\u6784\u5efa\uff08Dataset Construction\uff09": [[51, "dataset-construction"]], "\u4e09\u3001\u8bed\u8a00\u4e0e\u7f16\u7a0b\u8bed\u8a00\u8986\u76d6\uff08PLs and NLs\uff09": [[51, "pls-and-nls"]], "\u56db\u3001\u6570\u636e\u96c6\u5bf9\u6bd4\uff08Comparison with Existing Datasets\uff09": [[51, "comparison-with-existing-datasets"]], "\u4e94\u3001\u603b\u7ed3": [[51, "id2"], [52, "id5"], [58, "id22"]], "4.\u00a0\u00a0\u00a0Experiments": [[51, "experiments"]], "5.\u00a0\u00a0\u00a0Conclusion": [[51, "conclusion"]], "Acknowledgments": [[51, "acknowledgments"], [239, "acknowledgments"]], "Appendix A Experiment Settings": [[51, "appendix-a-experiment-settings"]], "Appendix B Comprehensive Experiment Results": [[51, "appendix-b-comprehensive-experiment-results"]], "2403.07974_LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code": [[52, "livecodebench-holistic-and-contamination-free-evaluation-of-large-language-models-for-code"]], "\u4e00\u3001\u80cc\u666f\u4e0e\u95ee\u9898": [[52, "id2"]], "\u4e8c\u3001LiveCodeBench\u7684\u63d0\u51fa": [[52, "livecodebench"]], "\u4e09\u3001\u5b9e\u8bc1\u7ed3\u679c\u4e0e\u53d1\u73b0": [[52, "id3"]], "\u56db\u3001\u76f8\u5173\u5de5\u4f5c\u5bf9\u6bd4": [[52, "id4"]], "2 Holistic Evaluation": [[52, "holistic-evaluation"]], "3 Benchmark Curation": [[52, "benchmark-curation"]], "3.1 \u6570\u636e\u6536\u96c6\uff08Data Collection\uff09": [[52, "data-collection"]], "3.2 \u5e73\u53f0\u7279\u5b9a\u7684\u5904\u7406\uff08Platform Specific Curation\uff09": [[52, "platform-specific-curation"]], "3.3 \u9488\u5bf9\u4e0d\u540c\u573a\u666f\u7684\u57fa\u51c6\u6784\u5efa\uff08Scenario-specific benchmark construction\uff09": [[52, "scenario-specific-benchmark-construction"]], "4 Experiment Setup": [[52, "experiment-setup"]], "\u5b9e\u9a8c\u6a21\u578b\u8bbe\u7f6e": [[52, "id7"]], "\u8bc4\u4f30\u6307\u6807": [[52, "id8"], [65, "id11"], [65, "id13"], [151, "id3"]], "\u4e0d\u540c\u573a\u666f\u7684\u5b9e\u9a8c\u8bbe\u7f6e": [[52, "id9"]], "\u4ee3\u7801\u751f\u6210\uff08Code Generation\uff09": [[52, "code-generation"]], "\u81ea\u4fee\u590d\uff08Self Repair\uff09": [[52, "self-repair"]], "\u4ee3\u7801\u6267\u884c\uff08Code Execution\uff09": [[52, "code-execution"]], "\u6d4b\u8bd5\u8f93\u51fa\u9884\u6d4b\uff08Test Output Prediction\uff09": [[52, "test-output-prediction"]], "5.1 \u907f\u514d\u6c61\u67d3\u95ee\u9898\uff08Avoiding Contamination\uff09": [[52, "avoiding-contamination"]], "5.2 \u6027\u80fd\u4e0e\u6a21\u578b\u6bd4\u8f83\uff08Performance and Model Comparisons\uff09": [[52, "performance-and-model-comparisons"]], "6.1 \u4ee3\u7801\u751f\u6210": [[52, "id12"]], "6.2 \u7efc\u5408\u6027\u4efb\u52a1": [[52, "id13"]], "6.3 \u6570\u636e\u6c61\u67d3\u95ee\u9898": [[52, "id14"]], "7 Limitations": [[52, "limitations"], [68, "limitations"], [239, "limitations"]], "8 Conclusion": [[52, "conclusion"], [241, "conclusion"], [242, "conclusion"]], "Appendix A Dataset": [[52, "appendix-a-dataset"], [54, "appendix-a-dataset"]], "A.1 License\uff08\u6388\u6743\uff09": [[52, "a-1-license"]], "A.2 Generator Based Test Generation\uff08\u57fa\u4e8e\u751f\u6210\u5668\u7684\u6d4b\u8bd5\u751f\u6210\uff09": [[52, "a-2-generator-based-test-generation"]], "A.3 Code Execution\uff08\u4ee3\u7801\u6267\u884c\uff09": [[52, "a-3-code-execution"]], "Appendix B UI": [[52, "appendix-b-ui"]], "Appendix C Experimental Setup": [[52, "appendix-c-experimental-setup"], [63, "appendix-c-experimental-setup"]], "C.1 \u6a21\u578b": [[52, "c-1"]], "C.2 \u4ee3\u7801\u751f\u6210": [[52, "c-2"]], "C.3 \u81ea\u4fee\u590d\uff08Self Repair\uff09": [[52, "c-3-self-repair"]], "C.4 \u4ee3\u7801\u6267\u884c": [[52, "c-4"]], "C.5 \u6d4b\u8bd5\u8f93\u51fa\u9884\u6d4b": [[52, "c-5"]], "Appendix D Results": [[52, "appendix-d-results"], [63, "appendix-d-results"]], "D.1 \u6c61\u67d3\uff08Contamination\uff09": [[52, "d-1-contamination"]], "D.2 \u6240\u6709\u7ed3\u679c\uff08All Results\uff09": [[52, "d-2-all-results"]], "Appendix E Qualitative Examples": [[52, "appendix-e-qualitative-examples"]], "E.1 \u4ee3\u7801\u6267\u884c\u9519\u8bef\u793a\u4f8b\u603b\u7ed3": [[52, "e-1"]], "2407.10499_CIBench: Evaluating Your LLMs with a Code Interpreter Plugin": [[53, "cibench-evaluating-your-llms-with-a-code-interpreter-plugin"]], "3 CIBench": [[53, "cibench"]], "1. \u8bc4\u4f30\u6570\u636e\u96c6\u6784\u5efa": [[53, "id2"]], "\ud83d\udce6 \u6a21\u5757\u9009\u62e9\uff08Python Modules\uff09": [[53, "python-modules"]], "\ud83e\udde9 \u4e3b\u9898\u751f\u6210\uff08Topic Candidates\uff09": [[53, "topic-candidates"]], "\ud83e\uddea \u4efb\u52a1\u751f\u6210\u4e0e\u4f18\u5316\uff08Tasks Generation & Refinement\uff09": [[53, "tasks-generation-refinement"]], "\ud83d\udc68\u200d\ud83d\udcbb \u4eba\u5de5\u7cbe\u4fee\uff08Human Refinement\uff09": [[53, "human-refinement"]], "2. \u8bc4\u4f30\u6a21\u5f0f\u4e0e\u6307\u6807": [[53, "id3"]], "\ud83d\udcca \u8bc4\u4f30\u6a21\u5f0f\uff08Evaluation Modes\uff09": [[53, "evaluation-modes"], [53, "id4"]], "1. \u5b9e\u9a8c\u8bbe\u7f6e\uff08Experiments Setup\uff09": [[53, "experiments-setup"]], "2. \u4e3b\u8981\u7ed3\u679c\uff08Main Results\uff09": [[53, "main-results"]], "3. \u9519\u8bef\u6a21\u5f0f\u5206\u6790\uff08Error Mode Analysis\uff09": [[53, "error-mode-analysis"]], "4. \u66f4\u591a\u5206\u6790\uff08More Analysis\uff09": [[53, "more-analysis"]], "4.1 \u8c03\u8bd5\u80fd\u529b\u5206\u6790\uff08Debug Ability Analysis\uff09": [[53, "debug-ability-analysis"]], "4.2 \u53ef\u89c6\u5316\u6307\u6807\u5206\u6790\uff08Visualization Metric Analysis\uff09": [[53, "visualization-metric-analysis"]], "4.3 \u8de8\u8bed\u8a00\u5206\u6790\uff08Cross Language Analysis\uff09": [[53, "cross-language-analysis"]], "4.4 \u96be\u5ea6\u5206\u6790\uff08Difficulty Analysis\uff09": [[53, "difficulty-analysis"]], "4.5 \u4e0d\u540c\u6a21\u5757\u7c7b\u522b\u5206\u6790\uff08Different Category Modules Analysis\uff09": [[53, "different-category-modules-analysis"]], "4.6 \u5c40\u9650\u6027\uff08Limitations\uff09": [[53, "limitations"]], "Appendix A Dataset Details": [[53, "appendix-a-dataset-details"], [67, "appendix-a-dataset-details"]], "A.1 \u6a21\u5757\u7248\u672c\u8bbe\u7f6e": [[53, "a-1"]], "A.2 \u6570\u636e\u96c6\u7edf\u8ba1": [[53, "a-2"]], "Appendix B Construction Prompts and Rules": [[53, "appendix-b-construction-prompts-and-rules"]], "Appendix C Experiment Example Demo": [[53, "appendix-c-experiment-example-demo"]], "Appendix D Subjective Visualization Evaluation": [[53, "appendix-d-subjective-visualization-evaluation"]], "Appendix E Dataset Error Analysis": [[53, "appendix-e-dataset-error-analysis"]], "Appendix F Human Annotator": [[53, "appendix-f-human-annotator"]], "Appendix G Ethical Consideration": [[53, "appendix-g-ethical-consideration"]], "\u9644\u5f55 G\uff1a\u4f26\u7406\u8003\u8651": [[53, "g"]], "\u56fe\u4f8b\u8bf4\u660e": [[53, "id8"]], "\u8d28\u91cf\u63a7\u5236\u89c4\u5219": [[53, "id9"]], "\u4e3b\u89c2\u53ef\u89c6\u5316\u8bc4\u5206\u63d0\u793a": [[53, "id10"]], "\u9519\u8bef\u7c7b\u578b\u793a\u4f8b": [[53, "id11"]], "2410.03859_SWE-bench-Multimodal: Do AI Systems Generalize to Visual Software Domains?": [[54, "swe-bench-multimodal-do-ai-systems-generalize-to-visual-software-domains"]], "2 SWE-bench Multimodal": [[54, "swe-bench-multimodal"]], "2.1 \u57fa\u7840\u56de\u987e\u4e0e\u9650\u5236": [[54, "id2"]], "2.2 \u6570\u636e\u6536\u96c6\u65b9\u6cd5": [[54, "id3"]], "2.3 SWE-bench M \u7684\u6838\u5fc3\u7279\u5f81": [[54, "swe-bench-m"]], "3 Evaluating on SWE-bench M": [[54, "evaluating-on-swe-bench-m"]], "3.1 Do Existing Systems Generalize?\uff08\u73b0\u6709\u7cfb\u7edf\u662f\u5426\u5177\u5907\u6cdb\u5316\u80fd\u529b\uff1f\uff09": [[54, "do-existing-systems-generalize"]], "3.2 Experiment Setup\uff08\u5b9e\u9a8c\u8bbe\u7f6e\uff09": [[54, "experiment-setup"]], "4 Results": [[54, "results"], [70, "results"], [174, "results"]], "\u4e00\u3001\u57fa\u7ebf\u7cfb\u7edf\u6027\u80fd\u5bf9\u6bd4": [[54, "id6"]], "\u4e8c\u3001\u4efb\u52a1\u89e3\u51b3\u65f6\u95f4\u4e0e\u7cfb\u7edf\u6027\u80fd": [[54, "id7"]], "\u4e09\u3001\u56fe\u50cf\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd": [[54, "id8"]], "\u56db\u3001\u7cfb\u7edf\u8bbe\u8ba1\u5bf9\u8bed\u8a00\u652f\u6301\u7684\u5c40\u9650\u6027": [[54, "id9"]], "\u4e94\u3001\u591a\u6a21\u6001\u5de5\u5177\u7684\u4f7f\u7528\u4e0e\u6311\u6218": [[54, "id10"]], "\u516d\u3001\u7814\u7a76\u7ed3\u8bba\u4e0e\u672a\u6765\u65b9\u5411": [[54, "id11"]], "\u603b\u4f53\u89c2\u70b9": [[54, "id12"]], "A.1 \u5f00\u53d1\u96c6\uff08Development Split\uff09": [[54, "a-1-development-split"]], "A.2 \u6570\u636e\u96c6\u9644\u52a0\u7279\u5f81": [[54, "a-2"]], "A.3 \u9644\u52a0\u5206\u6790": [[54, "a-3"]], "Appendix B Collection": [[54, "appendix-b-collection"]], "1. \u6570\u636e\u7edf\u8ba1\uff08B.1 Statistics\uff09": [[54, "b-1-statistics"]], "2. \u4e0d\u4e00\u81f4\u6027\u6d4b\u8bd5\uff08B.2 Inconsistency Testing\uff09": [[54, "b-2-inconsistency-testing"]], "3. \u8d44\u6e90\u6536\u96c6\uff08B.3 Resource Collection\uff09": [[54, "b-3-resource-collection"]], "Appendix C Experiments": [[54, "appendix-c-experiments"]], "1. \u5b9e\u9a8c\u4e0e\u6d88\u878d\u7814\u7a76\u7684\u989d\u5916\u7ec6\u8282": [[54, "id15"]], "2. \u57fa\u7ebf\u6a21\u578b\u7684\u8c03\u6574\u65b9\u6cd5": [[54, "id16"]], "a. Agentless": [[54, "a-agentless"]], "b. Aider": [[54, "b-aider"]], "c. AutoCodeRover": [[54, "c-autocoderover"]], "d. Moatless": [[54, "d-moatless"]], "e. SWE-agent": [[54, "e-swe-agent"]], "3. \u57fa\u7ebf\u914d\u7f6e\u7684\u5b9e\u9a8c\u53c2\u6570\u641c\u7d22": [[54, "id17"]], "4. \u5b9e\u9a8c\u7ed3\u679c": [[54, "id18"]], "C.3 Further Analyses": [[54, "c-3-further-analyses"]], "Appendix D Human Validation": [[54, "appendix-d-human-validation"]], "D.1 \u56fe\u50cf\u5206\u7c7b\uff08Image Categorization\uff09": [[54, "d-1-image-categorization"]], "D.2 \u56fe\u50cf\u662f\u5426\u80fd\u8868\u793a\u4e3a\u6587\u672c\uff08Is an image representable as text?\uff09": [[54, "d-2-is-an-image-representable-as-text"]], "D.3 Image Necessity.": [[54, "d-3-image-necessity"]], "D.3 \u56fe\u50cf\u5fc5\u8981\u6027\u603b\u7ed3": [[54, "d-3"]], "\u6807\u6ce8\u6d41\u7a0b\uff1a": [[54, "id21"]], "\u7ed3\u679c\uff1a": [[54, "id22"], [54, "id25"]], "\u5f71\u54cd\u56e0\u7d20\uff1a": [[54, "id23"]], "D.4 \u4efb\u52a1\u96be\u5ea6\u603b\u7ed3": [[54, "d-4"]], "\u6807\u6ce8\u65b9\u6cd5\uff1a": [[54, "id24"]], "\u5f71\u54cd\u96be\u5ea6\u7684\u5173\u952e\u56e0\u7d20\uff1a": [[54, "id26"]], "\u7ed3\u8bba\uff1a": [[54, "id27"], [55, "id5"], [56, "id13"], [64, "id20"], [64, "id24"], [70, "id14"], [82, "id22"], [116, "id11"]], "\u603b\u7ed3\u6027\u89c2\u70b9": [[54, "id28"]], "Appendix E Limitations": [[54, "appendix-e-limitations"]], "\u4e00\u3001\u66f4\u5e7f\u7684\u8986\u76d6\u8303\u56f4\uff08Broader Scope\uff09": [[54, "broader-scope"]], "\u4e8c\u3001\u6539\u8fdb\u6a21\u578b\u4e0e\u73af\u5883\uff08Improved Models and Environments\uff09": [[54, "improved-models-and-environments"]], "2410.06992_SWE-Bench+: Enhanced Coding Benchmark for LLMs": [[55, "swe-bench-enhanced-coding-benchmark-for-llms"]], "2 Robustness Analysis of SWE-Bench": [[55, "robustness-analysis-of-swe-bench"]], "\u4e00\u3001\u7814\u7a76\u76ee\u6807\u4e0e\u65b9\u6cd5": [[55, "id2"]], "\u4e8c\u3001\u6a21\u578b\u751f\u6210\u8865\u4e01\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff08Critical Issues\uff09": [[55, "critical-issues"]], "1. \u89e3\u51b3\u65b9\u6848\u6cc4\u9732\uff08Solution Leak\uff09": [[55, "solution-leak"]], "2. \u9519\u8bef\u4fee\u590d\uff08Incorrect Fixes\uff09": [[55, "incorrect-fixes"]], "3. \u4fee\u6539\u65e0\u5173\u6587\u4ef6\uff08Different Files/Functions Changed\uff09": [[55, "different-files-functions-changed"]], "4. \u4e0d\u5b8c\u6574\u4fee\u590d\uff08Incomplete Fixes\uff09": [[55, "incomplete-fixes"]], "5. \u4e0e\u6807\u51c6\u8865\u4e01\u4e0d\u540c\uff08Different Fixes\uff09": [[55, "different-fixes"]], "6. \u66f4\u5168\u9762\u7684\u4fee\u590d\uff08More Comprehensive Fixes\uff09": [[55, "more-comprehensive-fixes"]], "\u4e09\u3001\u4fee\u6b63\u540e\u7684\u89e3\u51b3\u7387\uff08Updated Resolution Rate\uff09": [[55, "updated-resolution-rate"]], "\u56db\u3001SWE-Bench Lite \u548c SWE-Bench Verified \u7684\u5206\u6790": [[55, "swe-bench-lite-swe-bench-verified"]], "1. SWE-Bench Lite": [[55, "swe-bench-lite"]], "2. SWE-Bench Verified": [[55, "swe-bench-verified"]], "\u4e94\u3001\u7ed3\u8bba\u4e0e\u542f\u793a": [[55, "id3"]], "3 Building SWE-Bench+": [[55, "building-swe-bench"]], "4 Robustness of SWE-Bench+": [[55, "robustness-of-swe-bench"]], "5 Effectiveness-aware Evaluation": [[55, "effectiveness-aware-evaluation"]], "\u4e3b\u8981\u5185\u5bb9\u603b\u7ed3\uff1a": [[55, "id4"], [57, "id4"], [61, "id2"], [134, "id3"], [174, "id2"], [237, "id1"]], "7 Conclusion": [[55, "conclusion"], [56, "conclusion"], [63, "conclusion"], [64, "conclusion"], [70, "conclusion"], [85, "conclusion"], [182, "conclusion"], [214, "conclusion"], [237, "conclusion"]], "2501.01257_CodeForces: Benchmarking Competition-level Code Generation of LLMs on CodeForces": [[56, "codeforces-benchmarking-competition-level-code-generation-of-llms-on-codeforces"]], "2. CodeForces \u57fa\u51c6\u7684\u7279\u70b9": [[56, "codeforces"]], "3. \u8bc4\u6d4b\u7ed3\u679c\u4e0e\u53d1\u73b0": [[56, "id3"]], "4. \u4e3b\u8981\u8d21\u732e": [[56, "id4"]], "3 CodeForces Benchmark": [[56, "codeforces-benchmark"]], "4 Evaluation on Existing LLMs": [[56, "evaluation-on-existing-llms"]], "4.1 \u5b9e\u9a8c\u8bbe\u7f6e": [[56, "id6"]], "4.2 Elo \u8bc4\u7ea7": [[56, "elo"]], "4.3 \u4e3b\u8981\u7ed3\u679c": [[56, "id7"]], "\u6a21\u578b\u8868\u73b0\u5bf9\u6bd4": [[56, "id8"]], "\u6bd4\u8d5b\u96be\u5ea6\u4e0e\u6a21\u578b\u8868\u73b0": [[56, "id9"]], "\u9898\u76ee\u96be\u5ea6\u4e0e\u901a\u8fc7\u7387": [[56, "id10"]], "Pass@n \u6307\u6807": [[56, "pass-n"]], "5 Analysis Experiments": [[56, "analysis-experiments"]], "6 Discussion": [[56, "discussion"], [85, "discussion"], [214, "discussion"]], "6.1 \u8d21\u732e\uff08Contributions\uff09": [[56, "contributions"]], "6.2 \u5c40\u9650\u6027\uff08Limitations\uff09": [[56, "limitations"]], "8 Ethical Statement": [[56, "ethical-statement"]], "Appendix A Model Cards": [[56, "appendix-a-model-cards"]], "Appendix B Decoding Hyperparameters": [[56, "appendix-b-decoding-hyperparameters"]], "Appendix C Analysis of Our Elo Rating Calculation System": [[56, "appendix-c-analysis-of-our-elo-rating-calculation-system"]], "Appendix D Human-comparable Elo Rating": [[56, "appendix-d-human-comparable-elo-rating"]], "Appendix E Problem Demonstration": [[56, "appendix-e-problem-demonstration"]], "Appendix F Special Judge": [[56, "appendix-f-special-judge"]], "\u8981\u70b9\u603b\u7ed3\uff1a": [[56, "id12"]], "2306.13394_MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models": [[57, "mme-a-comprehensive-evaluation-benchmark-for-multimodal-large-language-models"]], "2 MME Evaluation Suite": [[57, "mme-evaluation-suite"]], "2.1 \u6307\u4ee4\u8bbe\u8ba1\uff08Instruction Design\uff09": [[57, "instruction-design"]], "2.2 \u8bc4\u4f30\u6307\u6807\uff08Evaluation Metric\uff09": [[57, "evaluation-metric"]], "2.3 \u6570\u636e\u6536\u96c6\uff08Data Collection\uff09": [[57, "data-collection"]], "2.3.1 \u611f\u77e5\u4efb\u52a1\uff08Perception Tasks\uff09": [[57, "perception-tasks"]], "2.3.2 \u8ba4\u77e5\u4efb\u52a1\uff08Cognition Tasks\uff09": [[57, "cognition-tasks"]], "\u5b9e\u9a8c\u90e8\u5206\u603b\u7ed3": [[57, "id6"]], "3.1 \u611f\u77e5\u80fd\u529b\u8bc4\u4f30": [[57, "id7"]], "3.1.2 \u8ba4\u77e5\u80fd\u529b\u8bc4\u4f30": [[57, "id8"]], "4 Analysis": [[57, "analysis"], [214, "analysis"]], "2307.06281_MMBench: Is Your Multi-modal Model an All-around Player?": [[58, "mmbench-is-your-multi-modal-model-an-all-around-player"]], "\u4e00\u3001\u80cc\u666f\u4e0e\u52a8\u673a": [[58, "id2"]], "\u4e8c\u3001MMBench \u7684\u63d0\u51fa": [[58, "mmbench"]], "1. \u6570\u636e\u96c6\u8bbe\u8ba1": [[58, "id3"]], "2. \u8bc4\u4f30\u7b56\u7565": [[58, "id4"]], "3. \u8bc4\u4f30\u4e0e\u5206\u6790": [[58, "id5"]], "\u4e09\u3001\u4e3b\u8981\u8d21\u732e": [[58, "id6"]], "2.1 \u591a\u6a21\u6001\u6570\u636e\u96c6": [[58, "id8"]], "2.2 \u591a\u6a21\u6001\u6a21\u578b": [[58, "id9"]], "3 The construction of MMBench": [[58, "the-construction-of-mmbench"]], "4 Evaluation Strategy": [[58, "evaluation-strategy"]], "\u4e00\u3001LLM\u53c2\u4e0e\u7684\u9009\u62e9\u63d0\u53d6\uff08LLM-involved Choice Extraction\uff09": [[58, "llm-llm-involved-choice-extraction"]], "\u4e8c\u3001CircularEval\u8bc4\u4f30\u7b56\u7565": [[58, "circulareval"]], "\u6838\u5fc3\u601d\u60f3\uff1a": [[58, "id12"]], "\u4f18\u52bf\uff1a": [[58, "id13"]], "\u5b9e\u9a8c\u6548\u679c\uff1a": [[58, "id14"]], "5 Evaluation Results": [[58, "evaluation-results"]], "5.1 \u5b9e\u9a8c\u8bbe\u7f6e\uff08Experimental Setup\uff09": [[58, "experimental-setup"]], "5.2 \u4e3b\u8981\u7ed3\u679c\uff08Main Results\uff09": [[58, "main-results"]], "5.3 \u7ec6\u7c92\u5ea6\u5206\u6790\uff08Fine-grained Analysis\uff09": [[58, "fine-grained-analysis"]], "Appendix A More Details about the Data": [[58, "appendix-a-more-details-about-the-data"]], "A.1 \u5404\u53f6\u80fd\u529b\uff08Leaf Abilities\uff09\u7684\u5b9a\u4e49\u4e0e\u793a\u4f8b": [[58, "a-1-leaf-abilities"]], "A.2 MMBench \u7684\u6570\u636e\u6765\u6e90": [[58, "a-2-mmbench"]], "Appendix B More Details on MMBench Construction": [[58, "appendix-b-more-details-on-mmbench-construction"]], "Appendix C More Details on LLM-based Choice Extraction": [[58, "appendix-c-more-details-on-llm-based-choice-extraction"]], "\u4e00\u3001\u542f\u53d1\u5f0f\u5339\u914d\u7684\u5931\u8d25\u6848\u4f8b": [[58, "id20"]], "\u4e8c\u3001\u57fa\u4e8eLLM\u7684\u9009\u62e9\u63d0\u53d6\u63d0\u793a\uff08Prompt\uff09": [[58, "llm-prompt"]], "\u4e09\u3001\u4e0d\u540c\u9009\u62e9\u63d0\u53d6\u5668\u7684\u6027\u80fd\u8bc4\u4f30": [[58, "id21"]], "\u56db\u3001LLM\u8bed\u4e49\u5339\u914d\u7684\u6709\u6548\u6027\u9a8c\u8bc1": [[58, "llm"]], "Appendix D Evaluation Settings and Results": [[58, "appendix-d-evaluation-settings-and-results"]], "D.3 More Results": [[58, "d-3-more-results"]], "\u603b\u4f53\u8868\u73b0\u603b\u7ed3\uff1a": [[58, "id23"]], "\u91cd\u8981\u53d1\u73b0\uff1a": [[58, "id24"]], "2307.16125_SEED-Bench: Benchmarking Multimodal LLMs with Generative Comprehension": [[59, "seed-bench-benchmarking-multimodal-llms-with-generative-comprehension"]], "2. \u76f8\u5173\u7814\u7a76\u4e0e\u73b0\u6709\u57fa\u51c6\u6bd4\u8f83": [[59, "id3"]], "3. SEED-Bench \u7684\u63d0\u51fa": [[59, "seed-bench"]], "4. \u6570\u636e\u751f\u6210\u4e0e\u8fc7\u6ee4\u6d41\u7a0b": [[59, "id4"]], "5. \u8bc4\u4f30\u4e0e\u5b9e\u9a8c": [[59, "id5"]], "3 SEED-Bench": [[59, "id7"]], "4 Evaluation Results": [[59, "evaluation-results"]], "4.1 \u6a21\u578b\u8bc4\u4f30\u8303\u56f4": [[59, "id8"]], "4.2 \u8bc4\u4f30\u7ed3\u679c": [[59, "id9"]], "4.3 \u5206\u6790\u4e0e\u53d1\u73b0": [[59, "id10"]], "2311.12793_ShareGPT4V: Improving Large Multi-Modal Models with Better Captions": [[60, "sharegpt4v-improving-large-multi-modal-models-with-better-captions"]], "1.1 \u591a\u6a21\u6001\u5927\u6a21\u578b\u7684\u53d1\u5c55\u80cc\u666f": [[60, "id2"]], "1.2 \u95ee\u9898\u63d0\u51fa\u4e0e\u5b9e\u9a8c\u9a8c\u8bc1": [[60, "id3"]], "1.3 \u6570\u636e\u96c6\u6784\u5efa\u65b9\u6cd5": [[60, "id4"]], "1.4 \u6a21\u578b\u4e0e\u5b9e\u9a8c\u7ed3\u679c": [[60, "id5"]], "1.5 \u4e3b\u8981\u8d21\u732e": [[60, "id6"]], "3 ShareGPT4V Dataset": [[60, "sharegpt4v-dataset"]], "1. \u6570\u636e\u96c6\u6982\u8ff0": [[60, "id8"]], "2. \u6570\u636e\u6536\u96c6\uff08ShareGPT4V\uff09": [[60, "sharegpt4v"]], "3. \u6570\u636e\u6269\u5c55\uff08ShareGPT4V-PT\uff09": [[60, "sharegpt4v-pt"]], "4. \u603b\u4f53\u5b9e\u9a8c\u6548\u679c": [[60, "id9"]], "4 ShareGPT4V-7B Model": [[60, "sharegpt4v-7b-model"]], "4.1 \u6a21\u578b\u67b6\u6784": [[60, "id11"]], "4.2 \u9884\u8bad\u7ec3": [[60, "id12"]], "4.3 \u76d1\u7763\u5fae\u8c03\uff08SFT\uff09": [[60, "sft"]], "5 Experiments": [[60, "experiments"], [69, "experiments"], [239, "experiments"]], "1. \u5b9e\u9a8c\u57fa\u51c6\uff08Benchmarks\uff09": [[60, "benchmarks"]], "2. \u5b9a\u91cf\u6bd4\u8f83\uff08Quantitative Comparison\uff09": [[60, "quantitative-comparison"]], "3. \u591a\u6a21\u6001\u5bf9\u8bdd\u80fd\u529b\uff08Multi-modal Dialogue\uff09": [[60, "multi-modal-dialogue"]], "4. \u6d88\u878d\u5b9e\u9a8c\uff08Ablations\uff09": [[60, "ablations"]], "\uff081\uff09ShareGPT4V\u6570\u636e\u96c6\u7684\u6709\u6548\u6027": [[60, "id14"]], "\uff082\uff09\u9884\u8bad\u7ec3\u63cf\u8ff0\u8d28\u91cf\u7684\u5f71\u54cd": [[60, "id15"]], "\uff083\uff09\u9884\u8bad\u7ec3\u6570\u636e\u91cf\u7684\u5f71\u54cd": [[60, "id16"]], "\uff084\uff09\u89c6\u89c9\u7f16\u7801\u5668\u4e2d\u53ef\u5b66\u4e60\u5757\u6570\u7684\u5f71\u54cd": [[60, "id17"]], "Appendix A Data Sources": [[60, "appendix-a-data-sources"]], "Appendix B Caption Analysis": [[60, "appendix-b-caption-analysis"]], "Appendix D Examples": [[60, "appendix-d-examples"]], "2506.18095_ShareGPT-4o-Image: Aligning Multimodal Models with GPT-4o-Level Image Generation": [[61, "sharegpt-4o-image-aligning-multimodal-models-with-gpt-4o-level-image-generation"]], "2 ShareGPT-4o-Image": [[61, "sharegpt-4o-image"]], "2.1 \u6587\u672c\u5230\u56fe\u50cf\u6570\u636e": [[61, "id4"]], "2.2 \u6307\u4ee4\u5f15\u5bfc\u7684\u56fe\u50cf\u7f16\u8f91\u6570\u636e": [[61, "id5"]], "3 Janus-4o: Fine-Tuning with ShareGPT-4o-Image": [[61, "janus-4o-fine-tuning-with-sharegpt-4o-image"]], "\u603b\u7ed3\uff1aJanus-4o \u6a21\u578b\u7684\u5fae\u8c03\u4e0e\u6587\u672c-\u56fe\u50cf\u751f\u6210\u80fd\u529b\u7684\u589e\u5f3a": [[61, "janus-4o"]], "1. Janus-4o \u6982\u8ff0": [[61, "id7"]], "2. \u6587\u672c\u5230\u56fe\u50cf\u7684\u5fae\u8c03": [[61, "id8"]], "3. \u6587\u672c-\u56fe\u50cf\u5230\u56fe\u50cf\u7684\u5fae\u8c03": [[61, "id9"]], "4. \u8054\u5408\u5fae\u8c03": [[61, "id10"]], "5. \u603b\u4f53\u8bc4\u4ef7": [[61, "id11"]], "\u5b9e\u9a8c\u7ed3\u679c\u4e0e\u5206\u6790": [[61, "id13"]], "5 conclusion": [[61, "conclusion"]], "Appendix A Related Work": [[61, "appendix-a-related-work"], [112, "appendix-a-related-work"]], "A.1 \u6307\u4ee4\u5f15\u5bfc\u7684\u751f\u6210\u6a21\u578b": [[61, "a-1"]], "A.2 \u56fe\u50cf\u751f\u6210\u6570\u636e\u96c6": [[61, "a-2"]], "A.3 \u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09": [[61, "a-3-mllms"]], "Appendix B Image Generation Categories": [[61, "appendix-b-image-generation-categories"]], "\u4e00\u3001\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\uff08Text-to-Image\uff09\u5206\u7c7b": [[61, "text-to-image"]], "\u4e8c\u3001\u6587\u672c\u52a0\u56fe\u50cf\u5230\u56fe\u50cf\u751f\u6210\uff08Text-and-Image-to-Image\uff09\u5206\u7c7b": [[61, "text-and-image-to-image"]], "\u4e09\u3001\u5bf9\u8c61\u7c7b\u522b\u6570\u91cf k \u7684\u5206\u5e03\uff08Exponential Decay Distribution\uff09": [[61, "k-exponential-decay-distribution"]], "Appendix C Prompts for Generation": [[61, "appendix-c-prompts-for-generation"]], "C.1 Image-First Prompt": [[61, "c-1-image-first-prompt"]], "C.2 Content Generation Process": [[61, "c-2-content-generation-process"]], "C.3 Meta Prompts for Image Text Instruction": [[61, "c-3-meta-prompts-for-image-text-instruction"]], "Appendix D Document Pipeline": [[61, "appendix-d-document-pipeline"]], "Appendix E Ethical Considerations and Societal Impact": [[61, "appendix-e-ethical-considerations-and-societal-impact"]], "2402.05136_LV-Eval: A Balanced Long-Context Benchmark with 5 Length Levels Up to 256K": [[62, "lv-eval-a-balanced-long-context-benchmark-with-5-length-levels-up-to-256k"]], "\u80cc\u666f": [[62, "id2"], [162, "id1"], [230, "id2"]], "\u95ee\u9898": [[62, "id3"]], "\u89e3\u51b3\u65b9\u6848\uff1aLV-Eval \u57fa\u51c6": [[62, "lv-eval"]], "\u5b9e\u9a8c\u53d1\u73b0": [[62, "id4"]], "\u4e00\u3001\u957f\u4e0a\u4e0b\u6587\u8bc4\u6d4b\u57fa\u51c6\uff08Long-Context Benchmarks\uff09": [[62, "long-context-benchmarks"]], "\u4e8c\u3001\u957f\u4e0a\u4e0b\u6587\u6280\u672f\uff08Long-Context Techniques\uff09": [[62, "long-context-techniques"]], "3 LV-Eval Benchmark": [[62, "lv-eval-benchmark"]], "LV-Eval \u57fa\u51c6\u603b\u7ed3": [[62, "id6"]], "LV-Eval \u662f\u4ec0\u4e48\uff1f": [[62, "id7"]], "\u6838\u5fc3\u6784\u6210\uff1a": [[62, "id8"]], "\u6784\u5efa\u8fc7\u7a0b\u5305\u542b 3 \u4e2a\u4e3b\u8981\u6b65\u9aa4\uff1a": [[62, "id9"]], "\u8bc4\u6d4b\u6307\u6807\u4f18\u5316\uff1a": [[62, "id10"]], "\u4eba\u5de5\u6807\u6ce8\u5de5\u4f5c\uff1a": [[62, "id11"]], "5 Limitations": [[62, "limitations"]], "\u4e00\u3001\u9644\u5f55A\uff1aQA\u5bf9\u7684\u8be6\u7ec6\u6784\u5efa\u65b9\u6cd5": [[62, "a-qa"]], "1. \u591a\u8df3\u95ee\u7b54\uff08Multi-hop QA\uff09\u6570\u636e\u96c6": [[62, "multi-hop-qa"]], "2. \u5355\u8df3\u95ee\u7b54\uff08Single-hop QA\uff09\u6570\u636e\u96c6": [[62, "single-hop-qa"]], "\u4e8c\u3001\u9644\u5f55B\uff1a\u6807\u6ce8\u7ec6\u8282": [[62, "b"]], "1. \u6807\u6ce8\u4eba\u5458": [[62, "id14"]], "2. \u6807\u6ce8\u65f6\u95f4": [[62, "id15"]], "3. \u6807\u6ce8\u6307\u5bfc\u65b9\u9488": [[62, "id16"]], "Appendix C Detailed Evaluation Results": [[62, "appendix-c-detailed-evaluation-results"]], "1. \u591a\u8df3\u95ee\u7b54\u4efb\u52a1\u7684\u6311\u6218\u6027\u5206\u6790": [[62, "id18"]], "2. \u5355\u8df3\u95ee\u7b54\u4efb\u52a1\u7684\u8bc4\u4f30\u7ed3\u679c": [[62, "id19"]], "3. \u4e0a\u4e0b\u6587\u957f\u5ea6\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd": [[62, "id20"]], "4. \u90e8\u5206\u6a21\u578b\u8868\u73b0\u5206\u6790": [[62, "id21"]], "5. \u8bc4\u4f30\u6570\u636e\u4e0e\u6a21\u578b\u5bf9\u6bd4": [[62, "id22"]], "6. \u7ed3\u8bba\u4e0e\u542f\u793a": [[62, "id23"]], "Appendix D Detailed Ablation Results": [[62, "appendix-d-detailed-ablation-results"]], "Appendix D \u8be6\u7ec6\u6d88\u878d\u5b9e\u9a8c\u7ed3\u679c\u603b\u7ed3": [[62, "appendix-d"]], "Appendix E LV-Eval \u6570\u636e\u793a\u4f8b": [[62, "appendix-e-lv-eval"]], "Appendix F \u6a21\u578b\u5931\u8d25\u6848\u4f8b": [[62, "appendix-f"]], "2402.17753_LoCoMo: Evaluating Very Long-Term Conversational Memory of LLM Agents": [[63, "locomo-evaluating-very-long-term-conversational-memory-of-llm-agents"]], "3 Generative Pipeline for LoCoMo": [[63, "generative-pipeline-for-locomo"]], "3. LoCoMo \u7684\u751f\u6210\u7ba1\u9053\u6982\u8ff0": [[63, "locomo"]], "3.1 \u89d2\u8272\u8bbe\u5b9a\uff08Persona\uff09": [[63, "persona"]], "3.2 \u65f6\u95f4\u4e8b\u4ef6\u56fe\uff08Temporal Event Graph\uff09": [[63, "temporal-event-graph"]], "3.3 \u865a\u62df\u4ee3\u7406\u67b6\u6784": [[63, "id2"]], "1. \u53cd\u601d\u4e0e\u56de\u5e94\uff08Reflect & Respond\uff09": [[63, "reflect-respond"]], "2. \u56fe\u50cf\u5206\u4eab\u4e0e\u56fe\u50cf\u53cd\u5e94\uff08Image Sharing & Image Reaction\uff09": [[63, "image-sharing-image-reaction"]], "3.4 \u4eba\u7c7b\u9a8c\u8bc1\u4e0e\u7f16\u8f91\uff08Human Verification & Editing\uff09": [[63, "human-verification-editing"]], "4 LoCoMo Evaluation Benchmark": [[63, "locomo-evaluation-benchmark"]], "1. \u95ee\u7b54\u4efb\u52a1\uff08Question Answering Task\uff09": [[63, "question-answering-task"]], "2. \u4e8b\u4ef6\u603b\u7ed3\u4efb\u52a1\uff08Event Summarization Task\uff09": [[63, "event-summarization-task"]], "3. \u591a\u6a21\u6001\u5bf9\u8bdd\u751f\u6210\u4efb\u52a1\uff08Multi-Modal Dialogue Generation Task\uff09": [[63, "multi-modal-dialogue-generation-task"]], "5 Experimental Setup": [[63, "experimental-setup"]], "1. \u5b9e\u9a8c\u8bbe\u7f6e\u6982\u8ff0": [[63, "id5"]], "2. \u95ee\u7b54\u4efb\u52a1\uff08Question Answering\uff09": [[63, "question-answering"]], "3. \u4e8b\u4ef6\u6458\u8981\u751f\u6210\u4efb\u52a1\uff08Event Summarization\uff09": [[63, "event-summarization"]], "4. \u591a\u6a21\u6001\u5bf9\u8bdd\u751f\u6210\u4efb\u52a1\uff08Multi-modal Dialogue Generation\uff09": [[63, "multi-modal-dialogue-generation"]], "5. \u603b\u7ed3": [[63, "id6"], [132, "id6"]], "6 Experimental Results": [[63, "experimental-results"]], "6.1 \u95ee\u7b54\u4efb\u52a1\uff08Question Answering Task\uff09": [[63, "id7"]], "6.2 \u4e8b\u4ef6\u56fe\u603b\u7ed3\u4efb\u52a1\uff08Event Summarization Task\uff09": [[63, "id8"]], "6.3 \u591a\u6a21\u6001\u5bf9\u8bdd\u751f\u6210\u4efb\u52a1\uff08Multi-Modal Dialog Generation Task\uff09": [[63, "multi-modal-dialog-generation-task"]], "8 Limitations": [[63, "limitations"], [64, "limitations"]], "9 Broader Impacts": [[63, "broader-impacts"]], "Appendix Overview": [[63, "appendix-overview"]], "Appendix A Generative Pipeline for LoCoMo": [[63, "appendix-a-generative-pipeline-for-locomo"]], "Appendix B Dataset": [[63, "appendix-b-dataset"]], "\u9644\u5f55B\uff1a\u6570\u636e\u96c6": [[63, "b"]], "B.1 \u6570\u636e\u96c6\u7edf\u8ba1": [[63, "b-1"]], "B.2 \u6570\u636e\u96c6\u6388\u6743": [[63, "b-2"]], "B.3 \u6807\u6ce8\u4eba\u5458\u4fe1\u606f": [[63, "b-3"]], "1. \u57fa\u7ebf\u65b9\u6cd5\uff08Baselines\uff09": [[63, "baselines"]], "1.1 \u95ee\u7b54\u4efb\u52a1": [[63, "id10"]], "1.2 \u4e8b\u4ef6\u6458\u8981\u4efb\u52a1": [[63, "id11"]], "1.3 \u591a\u6a21\u6001\u5bf9\u8bdd\u751f\u6210": [[63, "id12"]], "2. \u5b9e\u73b0\u7ec6\u8282\uff08Implementation Details\uff09": [[63, "implementation-details"]], "\u603b\u7ed3\u5185\u5bb9\u5982\u4e0b\uff1a": [[63, "id14"], [70, "id13"], [173, "id3"]], "1. \u88686\uff1aMiniGPT-5\u591a\u6a21\u6001\u5bf9\u8bdd\u751f\u6210\u6027\u80fd\u6bd4\u8f83": [[63, "minigpt-5"]], "2. D.1 \u4e8b\u4ef6\u603b\u7ed3\u4efb\u52a1\uff08Event Summarization Task\uff09": [[63, "d-1-event-summarization-task"]], "3. D.2 \u591a\u6a21\u6001\u5bf9\u8bdd\u751f\u6210\u4efb\u52a1\uff08Multimodal Dialog Generation Task\uff09": [[63, "d-2-multimodal-dialog-generation-task"]], "2404.06654_RULER: What\u2019s the Real Context Size of Your Long-Context Language Models?": [[64, "ruler-what-s-the-real-context-size-of-your-long-context-language-models"]], "\u4e3b\u8981\u89c2\u70b9\u4e0e\u7814\u7a76\u76ee\u7684": [[64, "id2"]], "\u65b9\u6cd5\u4e0e\u5b9e\u9a8c\u8bbe\u8ba1": [[64, "id3"]], "\u6838\u5fc3\u53d1\u73b0": [[64, "id4"]], "\u7ed3\u8bba\u4e0e\u610f\u4e49": [[64, "id5"]], "1. \u957f\u4e0a\u4e0b\u6587\u8bed\u8a00\u6a21\u578b\u7684\u7814\u7a76\u8fdb\u5c55": [[64, "id7"]], "2. \u957f\u4e0a\u4e0b\u6587\u6a21\u578b\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e0e\u4efb\u52a1": [[64, "id8"]], "3 The Ruler\u00a0Benchmark": [[64, "the-ruler-benchmark"]], "1. \u4efb\u52a1\u8bbe\u8ba1\u4e0e\u751f\u6210": [[64, "id10"]], "2. \u68c0\u7d22\u4efb\u52a1\uff08Needle-in-a-Haystack, NIAH\uff09": [[64, "needle-in-a-haystack-niah"]], "3. \u591a\u8df3\u8ffd\u8e2a\u4efb\u52a1\uff08Variable Tracking, VT\uff09": [[64, "variable-tracking-vt"]], "4. \u805a\u5408\u4efb\u52a1\uff08Common Words Extraction, CWE\uff1bFrequent Words Extraction, FWE\uff09": [[64, "common-words-extraction-cwe-frequent-words-extraction-fwe"]], "5. \u95ee\u7b54\u4efb\u52a1\uff08QA\uff09": [[64, "qa"]], "4 Experiments & Results": [[64, "experiments-results"]], "1. \u6a21\u578b\u4e0e\u63a8\u7406\u8bbe\u7f6e": [[64, "id12"]], "2. \u4efb\u52a1\u914d\u7f6e": [[64, "id13"]], "3. \u6709\u6548\u4e0a\u4e0b\u6587\u957f\u5ea6\uff08Effective Context Length\uff09": [[64, "effective-context-length"]], "4. \u6a21\u578b\u6392\u540d\u6807\u51c6": [[64, "id14"]], "5. \u4e3b\u8981\u5b9e\u9a8c\u7ed3\u679c": [[64, "id15"]], "6. \u603b\u4f53\u7ed3\u8bba": [[64, "id16"]], "5 Task Error Analysis": [[64, "task-error-analysis"]], "\u4e3b\u8981\u53d1\u73b0\u603b\u7ed3\u5982\u4e0b\uff1a": [[64, "id17"]], "6 Model Analysis": [[64, "model-analysis"]], "\u603b\u7ed3\u5982\u4e0b\uff1a": [[64, "id19"], [242, "id5"]], "Appendix A Models": [[64, "appendix-a-models"]], "Appendix B Task Configurations": [[64, "appendix-b-task-configurations"]], "\u68c0\u7d22\u4efb\u52a1 (Retrieval)": [[64, "retrieval"]], "\u591a\u8df3\u8ffd\u8e2a (Multi-hop Tracing)": [[64, "multi-hop-tracing"]], "\u805a\u5408\u4efb\u52a1 (Aggregation)": [[64, "aggregation"]], "\u95ee\u7b54\u4efb\u52a1 (QA)": [[64, "id21"]], "Appendix C Task Correlation Analysis": [[64, "appendix-c-task-correlation-analysis"]], "Appendix D Prompt Templates": [[64, "appendix-d-prompt-templates"]], "1. \u6a21\u578b\u6a21\u677f\uff08Model Templates\uff09": [[64, "model-templates"]], "2. \u4efb\u52a1\u6a21\u677f\uff08Task Templates\uff09": [[64, "task-templates"]], "(1) S-NIAH & MK-NIAH": [[64, "s-niah-mk-niah"]], "(2) MV-NIAH & MQ-NIAH": [[64, "mv-niah-mq-niah"]], "(3) VT\uff08Variable Tracking\uff09": [[64, "vt-variable-tracking"]], "(4) CWE\uff08Common Word Extraction\uff09": [[64, "cwe-common-word-extraction"]], "(5) FWE\uff08Frequent Word Extraction\uff09": [[64, "fwe-frequent-word-extraction"]], "(6) QA\uff08Question Answering\uff09": [[64, "qa-question-answering"]], "Appendix E Passkey Retrieval and Vanilla NIAH Results": [[64, "appendix-e-passkey-retrieval-and-vanilla-niah-results"]], "Appendix F Additional Results": [[64, "appendix-f-additional-results"]], "\u5173\u952e\u603b\u7ed3\uff1a": [[64, "id23"]], "2407.11963_NeedleBench: Can LLMs Do Retrieval and Reasoning in Information-Dense Context": [[65, "needlebench-can-llms-do-retrieval-and-reasoning-in-information-dense-context"]], "1. \u957f\u6587\u672c\u5904\u7406\u80fd\u529b\u7684\u91cd\u8981\u6027": [[65, "id2"]], "2. \u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u6027": [[65, "id3"]], "3. NeedleBench \u7684\u63d0\u51fa\u4e0e\u7279\u70b9": [[65, "needlebench"]], "4. \u7814\u7a76\u53d1\u73b0": [[65, "id4"]], "5. \u8bba\u6587\u7684\u4e3b\u8981\u8d21\u732e": [[65, "id5"]], "1. \u957f\u4e0a\u4e0b\u6587\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55": [[65, "id7"]], "2. \u957f\u4e0a\u4e0b\u6587\u8bc4\u4f30\u57fa\u51c6\u7684\u5206\u7c7b": [[65, "id8"]], "3 Tasks and Datasets": [[65, "tasks-and-datasets"]], "3.1 NeedleBench \u4fe1\u606f\u7a00\u758f\u4efb\u52a1\uff08Information-Sparse Tasks\uff09": [[65, "needlebench-information-sparse-tasks"]], "\u6570\u636e\u96c6\u6784\u5efa": [[65, "id10"]], "3.2 NeedleBench \u4fe1\u606f\u5bc6\u96c6\u4efb\u52a1\uff08Information-Dense Tasks\uff09": [[65, "needlebench-information-dense-tasks"]], "\u4efb\u52a1\u7279\u70b9": [[65, "id12"]], "1. \u5b9e\u9a8c\u8bbe\u8ba1\u4e0e\u8bc4\u4f30\u8303\u56f4": [[65, "id15"]], "2. \u4fe1\u606f\u7a00\u758f\u4efb\u52a1\u7684\u4e3b\u8981\u7ed3\u679c": [[65, "id16"]], "3. \u591a\u70b9\u63a8\u7406\u4efb\u52a1\u7684\u96be\u70b9\u5206\u6790\uff084.1.2\uff09": [[65, "id17"]], "4. \u6a21\u578b\u89c4\u6a21\u5bf9\u63a8\u7406\u6027\u80fd\u7684\u5f71\u54cd\uff084.1.3\uff09": [[65, "id18"]], "5. \u63a8\u7406\u4efb\u52a1\u590d\u6742\u5ea6\u7684\u5f71\u54cd\uff084.1.4\uff09": [[65, "id19"]], "4.1.5 Impact of Language_ Which Model Performs Better under the Bilingual Scenario_": [[65, "impact-of-language-which-model-performs-better-under-the-bilingual-scenario"]], "4.1.5 \u8bed\u8a00\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff1a\u54ea\u79cd\u6a21\u578b\u5728\u53cc\u8bed\u573a\u666f\u4e2d\u8868\u73b0\u66f4\u597d\uff1f": [[65, "id21"]], "4.2 NeedleBench \u4fe1\u606f\u5bc6\u96c6\u4efb\u52a1": [[65, "id22"]], "4.2.1 \u9ad8\u7ea7\u63a8\u7406\u6a21\u578b\u662f\u5426\u80fd\u6cdb\u5316\u5230\u957f\u94fe\u63a8\u7406\uff1f": [[65, "id23"]], "4.2.2 \u4fe1\u606f\u5bc6\u96c6\u578b\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u4e2d\u7684\u201c\u6d45\u601d\u8003\u201d\u74f6\u9888": [[65, "id24"]], "5 Conclusion and Future Work": [[65, "conclusion-and-future-work"]], "Appendix A Evaluated Models": [[65, "appendix-a-evaluated-models"]], "Appendix B NeedleBench\u00a0Prompt Examples": [[65, "appendix-b-needlebench-prompt-examples"]], "B.1 Single-Needle Retrieval\uff08\u5355\u76ee\u6807\u68c0\u7d22\uff09": [[65, "b-1-single-needle-retrieval"]], "B.2 Multi-Needle Retrieval\uff08\u591a\u76ee\u6807\u68c0\u7d22\uff09": [[65, "b-2-multi-needle-retrieval"]], "B.3 Multi-Needle Reasoning\uff08\u591a\u76ee\u6807\u63a8\u7406\uff09": [[65, "b-3-multi-needle-reasoning"]], "B.4 Ancestral Trace Challenge\uff08\u7956\u5148\u8ffd\u6eaf\u6311\u6218\uff09": [[65, "b-4-ancestral-trace-challenge"]], "Appendix C Error Analysis Examples": [[65, "appendix-c-error-analysis-examples"]], "C.1 Under-thinking Error\uff08\u601d\u8003\u4e0d\u8db3\u9519\u8bef\uff09": [[65, "c-1-under-thinking-error"]], "C.2 Instruction Following Error\uff08\u6307\u4ee4\u9075\u5faa\u9519\u8bef\uff09": [[65, "c-2-instruction-following-error"]], "C.3 Partial Understanding Error\uff08\u90e8\u5206\u7406\u89e3\u9519\u8bef\uff09": [[65, "c-3-partial-understanding-error"]], "C.4 Repetitive Output Error\uff08\u91cd\u590d\u8f93\u51fa\u9519\u8bef\uff09": [[65, "c-4-repetitive-output-error"]], "C.5 Hallucination Error\uff08\u5e7b\u89c9\u9519\u8bef\uff09": [[65, "c-5-hallucination-error"]], "2103.03874_MATH: Measuring Mathematical Problem Solving With the MATH Dataset": [[66, "math-measuring-mathematical-problem-solving-with-the-math-dataset"]], "2110.14168_GSM8K: Training Verifiers to Solve Math Word Problems": [[67, "gsm8k-training-verifiers-to-solve-math-word-problems"]], "2 Dataset": [[67, "dataset"], [237, "dataset"]], "3 Related Work": [[67, "related-work"]], "4 Methods": [[67, "methods"]], "\u65b9\u6cd5\u6982\u8ff0": [[67, "id2"], [159, "id2"]], "2. \u6a21\u578b\u4e0e\u8bad\u7ec3\u8bbe\u7f6e": [[67, "id3"]], "4.1 Finetuning": [[67, "finetuning"]], "4.2 Verification": [[67, "verification"]], "4.3 Verification Ablations": [[67, "verification-ablations"]], "5 Additional Experiments": [[67, "additional-experiments"]], "5.1 \u6d4b\u8bd5\u65f6\u8ba1\u7b97\uff08Test Time Compute\uff09": [[67, "test-time-compute"]], "5.2 \u6b63\u5219\u5316\uff08Regularization\uff09": [[67, "regularization"]], "Appendix B Hyperparameters": [[67, "appendix-b-hyperparameters"]], "Appendix C Calculator Annotations": [[67, "appendix-c-calculator-annotations"]], "Appendix D Example Model Solutions": [[67, "appendix-d-example-model-solutions"]], "Appendix E Verifier Details": [[67, "appendix-e-verifier-details"]], "Appendix F Verifier Visualization": [[67, "appendix-f-verifier-visualization"]], "2405.12209_MathBench: Evaluating the Theory and Application Proficiency of LLMs with a Hierarchical Mathematics Benchmark": [[68, "mathbench-evaluating-the-theory-and-application-proficiency-of-llms-with-a-hierarchical-mathematics-benchmark"]], "\u80cc\u666f\u4e0e\u610f\u4e49": [[68, "id1"]], "MathBench \u7684\u63d0\u51fa\u4e0e\u7279\u70b9": [[68, "mathbench"]], "MathBench \u7684\u76ee\u6807\u4e0e\u8d21\u732e": [[68, "id2"]], "2 Methodology": [[68, "methodology"], [182, "methodology"]], "\u4e00\u3001\u5206\u5c42\u77e5\u8bc6\u4f53\u7cfb\uff082.1\uff09": [[68, "id4"]], "\u4e8c\u3001\u6570\u636e\u6536\u96c6\u4e0e\u7edf\u8ba1\uff082.2\uff09": [[68, "id5"]], "3 Experiments and Analysis": [[68, "experiments-and-analysis"]], "\u5b9e\u9a8c\u914d\u7f6e": [[68, "id7"]], "\u4e3b\u8981\u7ed3\u679c": [[68, "id8"]], "MathBench-A\uff08\u5e94\u7528\u80fd\u529b\uff09": [[68, "mathbench-a"]], "MathBench-T\uff08\u7406\u8bba\u80fd\u529b\uff09": [[68, "mathbench-t"]], "3.3 Evaluation of Base Models": [[68, "evaluation-of-base-models"]], "\u603b\u7ed3\uff1a3.3 \u4e0e 3.4 \u8282\u4e3b\u8981\u5185\u5bb9": [[68, "id10"]], "3.3 Evaluation of Base Models \u4e3b\u8981\u5185\u5bb9\u603b\u7ed3\uff1a": [[68, "id11"]], "3.4 Detailed Analysis \u4e3b\u8981\u5185\u5bb9\u603b\u7ed3\uff1a": [[68, "detailed-analysis"]], "\u5173\u952e\u7ed3\u8bba\uff1a": [[68, "id12"]], "\u540e\u7eed\u7814\u7a76\u65b9\u5411\u5efa\u8bae\uff1a": [[68, "id13"]], "4.1 \u4ee3\u7801\u4ee3\u7406\uff08Code Agent\uff09\u5728 MathBench \u4e0a\u7684\u8868\u73b0": [[68, "code-agent-mathbench"]], "4.2 \u6a21\u578b\u89c4\u6a21\u5bf9\u6570\u5b66\u80fd\u529b\u7684\u5f71\u54cd": [[68, "id14"]], "4.3 \u9519\u8bef\u5206\u6790": [[68, "id15"]], "4.4 \u63a8\u7406\u8def\u5f84\u5206\u6790": [[68, "id16"]], "8 Ethical Considerations": [[68, "ethical-considerations"]], "Appendix A MathBench Statistics": [[68, "appendix-a-mathbench-statistics"]], "\u603b\u7ed3\uff1a\u9644\u5f55A MathBench\u7edf\u8ba1\u4fe1\u606f": [[68, "a-mathbench"]], "A.1 \u6570\u636e\u96c6\u7edf\u8ba1": [[68, "a-1"]], "A.2 \u6570\u636e\u6536\u96c6\u7ec6\u8282": [[68, "a-2"]], "A.3 \u8d28\u91cf\u7b5b\u9009": [[68, "a-3"]], "Appendix B Detailed Experimental Results": [[68, "appendix-b-detailed-experimental-results"]], "\u603b\u7ed3\uff1aAppendix B \u8be6\u7ec6\u5b9e\u9a8c\u7ed3\u679c": [[68, "appendix-b"]], "B.1 Overall Results\uff08\u6574\u4f53\u7ed3\u679c\uff09": [[68, "b-1-overall-results"]], "B.2 Results with Accuracy\uff08\u51c6\u786e\u6027\u8bc4\u4f30\uff09": [[68, "b-2-results-with-accuracy"]], "B.3 Bilingual\uff08\u53cc\u8bed\u8868\u73b0\uff09": [[68, "b-3-bilingual"]], "Appendix C Extra Analysis": [[68, "appendix-c-extra-analysis"]], "1. \u4e09\u89d2\u51fd\u6570\u95ee\u9898\u5206\u6790": [[68, "id19"]], "2. \u7406\u60f3\u7684\u6027\u8d28\u95ee\u9898\u5206\u6790": [[68, "id20"]], "3. \u629b\u7269\u7ebf\u4e0e\u5706\u7684\u4ea4\u70b9\u95ee\u9898\u5206\u6790": [[68, "id21"]], "4. \u9636\u4e58\u672b\u5c3e\u96f6\u7684\u6570\u91cf\u95ee\u9898\u5206\u6790": [[68, "id22"]], "5. \u6982\u7387\u4e0e\u7edf\u8ba1\u95ee\u9898\u5206\u6790": [[68, "id23"]], "6. \u9009\u9879\u9650\u5236\u95ee\u9898\u5206\u6790": [[68, "id24"]], "7. \u975e\u9075\u4ece\u63d0\u793a\u7684\u95ee\u9898\u5206\u6790": [[68, "id25"]], "8. \u5c0f\u6a21\u578b\u7684\u63a8\u7406\u8def\u5f84\u5206\u6790": [[68, "id26"]], "9. \u5927\u6a21\u578b\u7684\u63a8\u7406\u8def\u5f84\u5206\u6790": [[68, "id27"]], "10. \u6570\u5b66\u6a21\u578b\u7684\u63a8\u7406\u8def\u5f84\u5206\u6790": [[68, "id28"]], "C.1 Prompts Demonstration": [[68, "c-1-prompts-demonstration"]], "C.1 \u63d0\u793a\u793a\u4f8b\uff08Prompts Demonstration\uff09": [[68, "id30"]], "C.1.1 \u82f1\u6587\u5f00\u653e\u5f0f\u6d4b\u8bd5\uff08English Open-ended test\uff09": [[68, "c-1-1-english-open-ended-test"]], "C.1.2 \u4e2d\u6587\u5f00\u653e\u5f0f\u6d4b\u8bd5\uff08Chinese Open-ended test\uff09": [[68, "c-1-2-chinese-open-ended-test"]], "C.1.3 \u82f1\u6587\u5355\u9009\u9898\u5e26\u63a8\u7406\uff08English single choice with reasoning\uff09": [[68, "c-1-3-english-single-choice-with-reasoning"]], "C.1.4 \u4e2d\u6587\u5355\u9009\u9898\u5e26\u63a8\u7406\uff08Chinese single choice with reasoning\uff09": [[68, "c-1-4-chinese-single-choice-with-reasoning"]], "C.2 \u9519\u8bef\u7c7b\u578b\u793a\u4f8b\uff08Error Types Demonstration\uff09": [[68, "c-2-error-types-demonstration"]], "C.2.1 \u6982\u5ff5\u8bef\u89e3\uff08Misunderstandings of concepts\uff09": [[68, "c-2-1-misunderstandings-of-concepts"]], "C.2.2 \u63a8\u7406\u9519\u8bef\uff08Flawed reasoning\uff09": [[68, "c-2-2-flawed-reasoning"]], "C.2.3 \u4e0e\u95ee\u9898\u4e0d\u4e00\u81f4\uff08Misaligned with the question\uff09": [[68, "c-2-3-misaligned-with-the-question"]], "C.2.4 \u8d85\u51fa\u6700\u5927\u8f93\u51fa\u957f\u5ea6\uff08Exceed max out length\uff09": [[68, "c-2-4-exceed-max-out-length"]], "C.2.5 \u56de\u7b54\u53d7\u9650\u4e8e\u9009\u9879\uff08Responses constrained to Options\uff09": [[68, "c-2-5-responses-constrained-to-options"]], "C.2.6 \u672a\u9075\u5faa\u63d0\u793a\uff08Non-adherence to the prompt\uff09": [[68, "c-2-6-non-adherence-to-the-prompt"]], "C.3 \u63a8\u7406\u8def\u5f84\u793a\u4f8b\uff08Reasoning Paths Demonstration\uff09": [[68, "c-3-reasoning-paths-demonstration"]], "C.3.1 \u5c0f\u578b\u804a\u5929\u6a21\u578b\uff08Small-scale chat model\uff09": [[68, "c-3-1-small-scale-chat-model"]], "C.3.2 \u5927\u578b\u804a\u5929\u6a21\u578b\uff08Large-scale chat model\uff09": [[68, "c-3-2-large-scale-chat-model"]], "C.3.3 \u6570\u5b66\u6a21\u578b\uff08Math model\uff09": [[68, "c-3-3-math-model"]], "1809.09600_HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering": [[69, "hotpotqa-a-dataset-for-diverse-explainable-multi-hop-question-answering"]], "2 Data Collection": [[69, "data-collection"]], "1. \u7814\u7a76\u76ee\u6807": [[69, "id2"]], "2. \u6570\u636e\u6536\u96c6\u7684\u6311\u6218": [[69, "id3"]], "3. \u6570\u636e\u6536\u96c6\u7684\u4e3b\u8981\u6b65\u9aa4": [[69, "id4"]], "\uff081\uff09\u6784\u5efa\u7ef4\u57fa\u767e\u79d1\u8d85\u94fe\u63a5\u56fe": [[69, "id5"]], "\uff082\uff09\u751f\u6210\u5019\u9009\u6bb5\u843d\u5bf9": [[69, "id6"]], "\uff083\uff09\u6bd4\u8f83\u7c7b\u95ee\u9898": [[69, "id7"]], "4. \u652f\u6491\u4e8b\u5b9e\u7684\u6536\u96c6": [[69, "id8"]], "5. \u6570\u636e\u6536\u96c6\u6d41\u7a0b\uff08\u7b97\u6cd5 1\uff09": [[69, "id9"]], "6. \u521b\u65b0\u70b9": [[69, "id10"]], "3 Processing and Benchmark Settings": [[69, "processing-and-benchmark-settings"]], "1. \u6570\u636e\u6536\u96c6\u4e0e\u5206\u7ec4": [[69, "id12"]], "2. \u8bad\u7ec3\u4e0e\u6d4b\u8bd5\u96c6\u5212\u5206": [[69, "id13"]], "3. \u4e24\u79cd\u57fa\u51c6\u6d4b\u8bd5\u8bbe\u7f6e": [[69, "id14"]], "4. train-medium \u7684\u5206\u6790": [[69, "train-medium"]], "4 Dataset Analysis": [[69, "dataset-analysis"]], "\u4e00\u3001\u95ee\u9898\u7c7b\u578b\u5206\u6790": [[69, "id16"]], "\u4e8c\u3001\u7b54\u6848\u7c7b\u578b\u5206\u6790": [[69, "id17"]], "\u4e09\u3001\u591a\u8df3\u63a8\u7406\u7c7b\u578b\u5206\u6790": [[69, "id18"]], "\u56db\u3001\u5176\u4ed6\u53d1\u73b0": [[69, "id19"]], "5.1 \u6a21\u578b\u67b6\u6784\u4e0e\u8bad\u7ec3": [[69, "id21"]], "5.2 \u5b9e\u9a8c\u7ed3\u679c": [[69, "id22"]], "5.3 \u4eba\u7c7b\u8868\u73b0\u8bc4\u4f30": [[69, "id23"]], "7 Conclusions": [[69, "conclusions"], [82, "conclusions"]], "Appendix A Data Collection Details": [[69, "appendix-a-data-collection-details"]], "\u9644\u5f55A \u6570\u636e\u6536\u96c6\u7ec6\u8282": [[69, "a"]], "A.1 \u6570\u636e\u9884\u5904\u7406": [[69, "a-1"]], "A.2 \u6570\u636e\u6536\u96c6\u8fdb\u4e00\u6b65\u7ec6\u8282": [[69, "a-2"]], "\u7ef4\u57fa\u767e\u79d1\u9875\u9762\u7684\u7b5b\u9009": [[69, "id25"]], "\u6fc0\u52b1\u673a\u5236": [[69, "id26"]], "A.3 \u4f17\u5305\u5de5\u4f5c\u8005\u754c\u9762": [[69, "a-3"]], "Appendix B Further Data Analysis": [[69, "appendix-b-further-data-analysis"]], "Appendix C Full Wiki Setting Details": [[69, "appendix-c-full-wiki-setting-details"]], "\u5185\u5bb9\u603b\u7ed3\uff1a": [[69, "id27"]], "C.1 \u5012\u6392\u7d22\u5f15\u7b5b\u9009\u7b56\u7565\uff08Inverted Index Filtering Strategy\uff09": [[69, "c-1-inverted-index-filtering-strategy"]], "C.2 \u8bad\u7ec3\u96c6\uff08train-medium\uff09\u4e0e\u56f0\u96be\u6837\u672c\uff08dev/test\uff09\u7684\u6bd4\u8f83": [[69, "c-2-train-medium-dev-test"]], "2109.07958_TruthfulQA: Measuring How Models Mimic Human Falsehoods": [[70, "truthfulqa-measuring-how-models-mimic-human-falsehoods"]], "2 The TruthfulQA Benchmark": [[70, "the-truthfulqa-benchmark"]], "2.1 \u5b9a\u4e49\u771f\u5b9e\u6027\u76ee\u6807": [[70, "id2"]], "2.2 \u6784\u5efaTruthfulQA": [[70, "truthfulqa"]], "2.3 TruthfulQA\u7684\u9a8c\u8bc1": [[70, "id3"]], "3.1 \u6a21\u578b\u4e0e\u63d0\u793a\u8bcd": [[70, "id5"]], "3.2 \u4efb\u52a1\u4e0e\u8bc4\u4f30\u65b9\u6cd5": [[70, "id6"]], "4.1 \u6a21\u578b\u4e0e\u4eba\u7c7b\u5728\u4e8b\u5b9e\u6027\u4e0a\u7684\u5bf9\u6bd4": [[70, "id8"]], "4.2 \u6a21\u578b\u89c4\u6a21\u8d8a\u5927\uff0c\u771f\u5b9e\u6027\u53cd\u800c\u8d8a\u5dee": [[70, "id9"]], "4.3 \u7ed3\u679c\u7684\u89e3\u91ca\uff1a\u865a\u5047\u56de\u7b54\u7684\u6210\u56e0\u5206\u6790": [[70, "id10"]], "4.4 \u81ea\u52a8\u5316\u8bc4\u4f30 vs \u4eba\u5de5\u8bc4\u4f30": [[70, "vs"]], "5 Discussion": [[70, "discussion"], [75, "discussion"], [174, "discussion"], [182, "discussion"]], "8 Ethics and Impact": [[70, "ethics-and-impact"]], "Appendix A Additional examples from TruthfulQA": [[70, "appendix-a-additional-examples-from-truthfulqa"]], "Appendix B Additional results": [[70, "appendix-b-additional-results"]], "\u603b\u7ed3\uff1a\u9644\u5f55B \u5185\u5bb9\u6982\u8ff0": [[70, "b"]], "B.1 \u81ea\u52a8\u8bc4\u4f30\u6307\u6807\u4e0e\u4eba\u7c7b\u8bc4\u4f30\u7684\u5bf9\u6bd4": [[70, "b-1"]], "B.2 \u5404\u6a21\u578b\u5728TruthfulQA\u4e0a\u7684\u771f\u7406\u6027\u4e0e\u4fe1\u606f\u91cf\u8868\u73b0": [[70, "b-2-truthfulqa"]], "B.3 \u65b0\u8bed\u8a00\u6a21\u578b\u5728TruthfulQA\u4e0a\u7684\u8868\u73b0": [[70, "b-3-truthfulqa"]], "B.4 \u5bf9\u6297\u8fc7\u6ee4\u4e0e\u672a\u8fc7\u6ee4\u95ee\u9898\u7684\u6bd4\u8f83": [[70, "b-4"]], "B.5 \u6309\u95ee\u9898\u7c7b\u522b\u5212\u5206\u7684\u6a21\u578b\u8868\u73b0": [[70, "b-5"]], "\u603b\u4f53\u8bc4\u4ef7\uff1a": [[70, "id12"], [75, "id9"]], "B.6 Performance of GPT-3-175B under different prompts": [[70, "b-6-performance-of-gpt-3-175b-under-different-prompts"]], "B.6 \u4e0d\u540c\u63d0\u793a\u4e0b\u7684GPT-3-175B\u8868\u73b0": [[70, "b-6-gpt-3-175b"]], "B.7 \u4e0d\u540c\u6a21\u578b\u5728\u771f\u5b9e\u6027\u4e0a\u7684\u5206\u5e03": [[70, "b-7"]], "B.8 \u66f4\u9ad8\u7684\u91c7\u6837\u6e29\u5ea6\uff08Temperature\uff09": [[70, "b-8-temperature"]], "B.9 \u95ee\u9898\u6539\u5199\uff08Paraphrased Questions\uff09": [[70, "b-9-paraphrased-questions"]], "Appendix C Dataset construction": [[70, "appendix-c-dataset-construction"]], "\u7ae0\u8282\u5185\u5bb9\u603b\u7ed3\uff1a": [[70, "id15"]], "1. \u53c2\u8003\u7b54\u6848\u7684\u6784\u5efa\uff08C.1 Reference answers\uff09": [[70, "c-1-reference-answers"]], "2. \u63a7\u5236\u95ee\u9898\uff08C.2 Control questions\uff09": [[70, "c-2-control-questions"]], "Appendix D Human evaluations": [[70, "appendix-d-human-evaluations"]], "\u8bc4\u4f30\u65b9\u6cd5\u7684\u4e3b\u8981\u7279\u70b9\uff1a": [[70, "id16"]], "\u8bc4\u4f30\u6807\u7b7e\u4e0e\u793a\u4f8b\uff08\u90e8\u5206\uff09": [[70, "id17"]], "\u771f\u5b9e\u6027\u8bc4\u4f30\u6807\u7b7e\uff08Truthfulness\uff09\uff1a": [[70, "truthfulness"]], "\u4fe1\u606f\u91cf\u8bc4\u4f30\u6807\u7b7e\uff08Informativeness\uff09\uff1a": [[70, "informativeness"]], "Appendix E Prompts": [[70, "appendix-e-prompts"]], "Appendix F Checking for data quality and disagreement": [[70, "appendix-f-checking-for-data-quality-and-disagreement"]], "2311.12022_GPQA: A Graduate-Level Google-Proof Q&A Benchmark": [[71, "gpqa-a-graduate-level-google-proof-q-a-benchmark"]], "2.Data Collection": [[71, "data-collection"]], "3.Dataset Analysis": [[71, "dataset-analysis"]], "\u4e00\u3001\u95ee\u9898\u5ba2\u89c2\u6027\uff08Question Objectivity\uff09": [[71, "question-objectivity"]], "\u4e8c\u3001\u95ee\u9898\u96be\u5ea6\uff08Question Difficulty\uff09": [[71, "question-difficulty"]], "\u603b\u7ed3\u4e00\u53e5\u8bdd\uff1a": [[71, "id2"]], "4.Baseline": [[71, "baseline"]], "\ud83c\udf1f\u80cc\u666f": [[71, "id3"]], "\ud83e\uddea\u5b9e\u9a8c\u8bbe\u7f6e": [[71, "id4"]], "\ud83d\udcca\u7ed3\u679c\u603b\u7ed3": [[71, "id5"]], "\ud83d\udd01\u989d\u5916\u8bf4\u660e": [[71, "id6"]], "5.Related Work": [[71, "related-work"]], "1. AI \u5b89\u5168\u4e2d\u7684\u6570\u636e\u91c7\u96c6\u4e0e\u6d4b\u8bd5": [[71, "ai"]], "2. \u9ad8\u8d28\u91cf\u6570\u636e\u91c7\u96c6\u65b9\u5f0f": [[71, "id7"]], "3. \u4e3a\u53ef\u6269\u5c55\u76d1\u7763\u6784\u5efa\u7684\u6570\u636e\u6807\u51c6\uff08GPQA\u6ee1\u8db3\u5176\u4e2d7\u9879\uff09": [[71, "gpqa7"]], "4. QA\u8bc4\u6d4b\u57fa\u51c6\u7684\u6784\u5efa\u65b9\u6cd5": [[71, "qa"]], "5. \u4e0e\u5176\u4ed6\u4e13\u5bb6\u95ee\u7b54\u96c6\u7684\u5bf9\u6bd4": [[71, "id8"]], "7.Conclusion": [[71, "conclusion"], [143, "conclusion"]], "2411.04368_SimpleQA: Measuring short-form factuality in large language models": [[72, "simpleqa-measuring-short-form-factuality-in-large-language-models"]], "2.Data Collection and Verification": [[72, "data-collection-and-verification"]], "2.1 \u95ee\u9898\u4e0e\u7b54\u6848\u6807\u51c6": [[72, "id1"]], "2.2 \u6570\u636e\u8d28\u91cf": [[72, "id2"]], "2.3 \u6570\u636e\u591a\u6837\u6027": [[72, "id3"]], "2.4 \u8bc4\u5206\u4e0e\u6307\u6807": [[72, "id4"]], "4.Measuring calibration": [[72, "measuring-calibration"]], "\u4ec0\u4e48\u662f\u6821\u51c6\uff1f": [[72, "id5"]], "\u600e\u4e48\u8861\u91cf\u6821\u51c6\uff1f": [[72, "id6"]], "\u65b9\u6cd5\u4e00\uff1a\u8ba9\u6a21\u578b\u8bf4\u51fa\u5b83\u7684\u4fe1\u5fc3\u503c": [[72, "id7"]], "\u65b9\u6cd5\u4e8c\uff1a\u540c\u4e00\u4e2a\u95ee\u9898\u95ee 100 \u6b21\uff0c\u770b\u7b54\u6848\u51fa\u73b0\u7684\u9891\u7387": [[72, "id8"]], "Appendix B Guessing strategy and F-score": [[72, "appendix-b-guessing-strategy-and-f-score"]], "\u63a8\u7406\u8fc7\u7a0b": [[72, "id10"]], "\u60c5\u51b5 A\uff1a\u9009\u62e9\u4f5c\u7b54": [[72, "a"]], "\u60c5\u51b5 B\uff1a\u653e\u5f03\u4f5c\u7b54": [[72, "b"]], "\u8bc4\u6d4b\u6807\u51c6": [[73, "id2"]], "\u51c6\u786e\u7387(Accuracy)": [[73, "accuracy"]], "\u7cbe\u786e\u7387(Precision, \u7cbe\u51c6\u7387)": [[73, "precision"]], "\u53ec\u56de\u7387(Recall)": [[73, "recall"]], "F1 Score": [[73, "f1-score"]], "\u53ef\u89c6\u5316\u7cbe\u5ea6\u548c\u53ec\u56de\u7387": [[73, "id3"]], "\u6df7\u6dc6\u77e9\u9635\uff08confusion matrix\uff09": [[73, "confusion-matrix"]], "\u53d7\u8bd5\u8005\u7279\u5f81\u66f2\u7ebf\uff08ROC \u66f2\u7ebf\uff0cReceiver Operating Characteristic curve\uff09": [[73, "roc-receiver-operating-characteristic-curve"]], "2009.03300_MMLU: Measuring Massive Multitask Language Understanding": [[74, "mmlu-measuring-massive-multitask-language-understanding"]], "1.1. \u9884\u8bad\u7ec3": [[74, "id2"]], "2.2. \u8bc4\u4f30\u57fa\u51c6": [[74, "id3"]], "3.A Multitask Test": [[74, "a-multitask-test"]], "\ud83c\udf10 \u6d4b\u8bd5\u6982\u8ff0": [[74, "id4"]], "\ud83d\udd0d \u6570\u636e\u96c6\u7ed3\u6784": [[74, "id5"]], "\ud83e\udde0 \u4eba\u7c7b\u8868\u73b0": [[74, "id6"]], "\ud83c\udfaf \u8bc4\u4f30\u76ee\u6807": [[74, "id7"]], "\ud83e\udde9 \u5404\u5b66\u79d1\u793a\u4f8b": [[74, "id8"]], "5.Discussion": [[74, "discussion"], [78, "discussion"], [80, "discussion"]], "1. \u591a\u6a21\u6001\u7406\u89e3": [[74, "id10"]], "2. \u4e92\u8054\u7f51\u4f5c\u4e3a\u8bad\u7ec3\u96c6": [[74, "id11"]], "3. \u7c7b\u4f3c\u4eba\u7c7b\u7684\u5b66\u4e60\u65b9\u5f0f": [[74, "id12"]], "4. \u6a21\u578b\u7684\u5c40\u9650\u6027": [[74, "id13"]], "5. \u6269\u5927\u89c4\u6a21\u672a\u5fc5\u662f\u7b54\u6848": [[74, "id14"]], "2305.08322_C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models": [[75, "c-eval-a-multi-level-multi-discipline-chinese-evaluation-suite-for-foundation-models"]], "C-Eval_ A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models": [[75, "id2"]], "\u80cc\u666f\u4e0e\u52a8\u673a": [[75, "id3"], [85, "id13"], [238, "id1"]], "C-Eval \u7684\u4ecb\u7ecd\u4e0e\u7279\u70b9": [[75, "c-eval"]], "\u5b9e\u9a8c\u4e0e\u7ed3\u679c": [[75, "id4"], [135, "id4"], [166, "id5"], [227, "id15"]], "2 The C-Eval\u00a0Evaluation Suite": [[75, "the-c-eval-evaluation-suite"]], "2.1 Design Principle\uff08\u8bbe\u8ba1\u539f\u5219\uff09": [[75, "design-principle"]], "2.2 Data Collection\uff08\u6570\u636e\u6536\u96c6\uff09": [[75, "data-collection"]], "2.3 C-Eval Hard\uff08C-Eval Hard\uff09": [[75, "c-eval-hard-c-eval-hard"]], "2.4 Evaluation\uff08\u8bc4\u4f30\uff09": [[75, "evaluation"]], "3 Experiment": [[75, "experiment"]], "3.1 Setup\uff08\u5b9e\u9a8c\u8bbe\u7f6e\uff09": [[75, "setup"]], "3.2 Models\uff08\u8bc4\u4f30\u6a21\u578b\uff09": [[75, "models"]], "3.3 Results\uff08\u5b9e\u9a8c\u7ed3\u679c\uff09": [[75, "results"]], "General comparison\uff08\u603b\u4f53\u6bd4\u8f83\uff09": [[75, "general-comparison"]], "Does few-shot prompting help?\uff08\u4e94\u6837\u672c\u63d0\u793a\u662f\u5426\u6709\u6548\uff09": [[75, "does-few-shot-prompting-help"]], "Does chain-of-thought prompting help?\uff08\u601d\u7ef4\u94fe\u63d0\u793a\u662f\u5426\u6709\u6548\uff09": [[75, "does-chain-of-thought-prompting-help"]], "Difference between English- and Chinese-oriented models\uff08\u4e2d\u82f1\u6587\u6a21\u578b\u6bd4\u8f83\uff09": [[75, "difference-between-english-and-chinese-oriented-models"]], "Results on C-Eval Hard\uff08C-Eval Hard \u96be\u5ea6\u6d4b\u8bd5\uff09": [[75, "results-on-c-eval-hard-c-eval-hard"]], "Results on the validation split\uff08\u9a8c\u8bc1\u96c6\u7ed3\u679c\uff09": [[75, "results-on-the-validation-split"]], "\u82f1\u8bed\u57fa\u51c6\uff08English Benchmarks\uff09": [[75, "english-benchmarks"]], "\u4e2d\u6587\u57fa\u51c6\uff08Chinese Benchmarks\uff09": [[75, "chinese-benchmarks"]], "Acknowledgement": [[75, "acknowledgement"], [240, "acknowledgement"]], "Appendix A Author Contributions": [[75, "appendix-a-author-contributions"]], "Appendix B Detailed Stats of C-Eval": [[75, "appendix-b-detailed-stats-of-c-eval"]], "Appendix C Explanation Data Generation": [[75, "appendix-c-explanation-data-generation"]], "Appendix D Evaluation Prompts": [[75, "appendix-d-evaluation-prompts"]], "Appendix E Details of the models being evaluated": [[75, "appendix-e-details-of-the-models-being-evaluated"]], "1. ChatGPT \u548c GPT-4": [[75, "chatgpt-gpt-4"]], "2. Claude": [[75, "claude"]], "3. BLOOMZ-mt": [[75, "bloomz-mt"]], "4. LLaMA": [[75, "llama"]], "5. GLM-130B \u548c ChatGLM-6B": [[75, "glm-130b-chatglm-6b"]], "6. Chinese-LLaMA": [[75, "chinese-llama"]], "7. Chinese-Alpaca": [[75, "chinese-alpaca"]], "8. MOSS": [[75, "moss"]], "Appendix F Breakdown of Model Performance": [[75, "appendix-f-breakdown-of-model-performance"]], "Appendix F Summary: Breakdown of Model Performance": [[75, "appendix-f-summary-breakdown-of-model-performance"]], "Key Observations:": [[75, "key-observations"]], "Appendix G Option Bias": [[75, "appendix-g-option-bias"]], "\u603b\u7ed3\uff1aAppendix G Option Bias": [[75, "id11"]], "Appendix H Compute and Resources Used for Evaluation": [[75, "appendix-h-compute-and-resources-used-for-evaluation"]], "2306.09212_CMMLU: Measuring massive multitask language understanding in Chinese": [[76, "cmmlu-measuring-massive-multitask-language-understanding-in-chinese"]], "3 CMMLU": [[76, "cmmlu"]], "4. \u5b9e\u9a8c\u603b\u7ed3": [[76, "id2"]], "2. \u4e3b\u8981\u7ed3\u679c": [[76, "id4"]], "3. \u6309\u79d1\u76ee\u5206\u7c7b\u7684\u8868\u73b0": [[76, "id5"]], "4. \u5206\u6790\u56e0\u7d20": [[76, "id6"]], "5. \u7ed3\u8bba\u4e0e\u542f\u793a": [[76, "id7"]], "Impact of model size on performance": [[76, "impact-of-model-size-on-performance"]], "1. \u6a21\u578b\u89c4\u6a21\u5bf9\u6027\u80fd\u7684\u5f71\u54cd": [[76, "id9"]], "2. \u5426\u5b9a\u8868\u8fbe\u548c\u5b50\u9009\u9879\u95ee\u9898\u5bf9\u6a21\u578b\u7684\u6311\u6218": [[76, "id10"]], "Appendix A Comparison to concurrent benchmarks": [[76, "appendix-a-comparison-to-concurrent-benchmarks"]], "Appendix B CMMLU Subjects": [[76, "appendix-b-cmmlu-subjects"]], "Appendix C CMMLU Examples": [[76, "appendix-c-cmmlu-examples"]], "Appendix D CMMLU Difficulty Distribution": [[76, "appendix-d-cmmlu-difficulty-distribution"]], "Appendix E Emergent Ability shown in CMMLU subjects": [[76, "appendix-e-emergent-ability-shown-in-cmmlu-subjects"]], "Appendix F Models being Evaluated": [[76, "appendix-f-models-being-evaluated"]], "Appendix G Strategies for Estimating Model Choices": [[76, "appendix-g-strategies-for-estimating-model-choices"]], "1. \u4e0b\u4e00\u8bcd\u9884\u6d4b\uff08Next Token Prediction\uff09": [[76, "next-token-prediction"]], "2. \u56f0\u60d1\u5ea6\u6bd4\u8f83\uff08Perplexity Comparison\uff09": [[76, "perplexity-comparison"]], "3. \u81ea\u7531\u751f\u6210\uff08Free Generation\uff09": [[76, "free-generation"]], "\u603b\u7ed3\u4e0e\u6bd4\u8f83": [[76, "id12"]], "Appendix H Regular expressions matching algorithmsl": [[76, "appendix-h-regular-expressions-matching-algorithmsl"]], "\u4e3b\u8981\u5185\u5bb9\u603b\u7ed3\u5982\u4e0b\uff1a": [[76, "id13"], [85, "id4"], [85, "id10"], [238, "id6"], [240, "id50"]], "Appendix I Correlation to other Benchmarks": [[76, "appendix-i-correlation-to-other-benchmarks"]], "Appendix J Breakdown of Model Performance": [[76, "appendix-j-breakdown-of-model-performance"]], "J.3 The effect of chain-of-thought prompt": [[76, "j-3-the-effect-of-chain-of-thought-prompt"]], "J.3 Chain-of-thought \u63d0\u793a\uff08CoT\uff09\u7684\u5f71\u54cd": [[76, "j-3-chain-of-thought-cot"]], "\u4e3b\u8981\u89c2\u5bdf\u5185\u5bb9\uff1a": [[76, "id15"]], "2307.15020_SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark": [[77, "superclue-a-comprehensive-chinese-large-language-model-benchmark"]], "2. SuperCLUE \u7684\u8bbe\u8ba1\u76ee\u6807": [[77, "superclue"]], "3. \u4efb\u52a1\u4e0e\u5b50\u4efb\u52a1": [[77, "id3"]], "4. \u8bc4\u4f30\u65b9\u6cd5": [[77, "id4"]], "5. \u5b9e\u9a8c\u4e0e\u7ed3\u679c": [[77, "id5"]], "6. \u672a\u6765\u65b9\u5411": [[77, "id6"]], "3 SuperCLUE Benchmark": [[77, "superclue-benchmark"]], "1. CArena": [[77, "carena"]], "2. OPEN Set": [[77, "open-set"]], "3. CLOSE Set": [[77, "close-set"]], "\u6a21\u578b\u9009\u62e9": [[77, "id10"]], "5 Additional Analysis": [[77, "additional-analysis"]], "\u4e00\u3001GPT-4\u4e0e\u4eba\u7c7b\u8bc4\u4f30\u7684\u9ad8\u4e00\u81f4\u6027": [[77, "gpt-4"]], "\u4e8c\u3001CLOSE\u96c6\u4e0eOPEN\u96c6\u8bc4\u4f30\u7ed3\u679c\u7684\u4e0d\u4e00\u81f4\u6027": [[77, "closeopen"]], "\u4e09\u3001CLOSE\u96c6\u4e0eOPEN\u96c6\u7684\u4e92\u8865\u6027": [[77, "id13"]], "Appendix A Evaluation Process": [[77, "appendix-a-evaluation-process"]], "Appendix B Capability Categories": [[77, "appendix-b-capability-categories"]], "\u80fd\u529b\u7c7b\u522b\u8be6\u7ec6\u5b9a\u4e49": [[77, "id15"]], "\u6807\u6ce8\u8fc7\u7a0b": [[77, "id16"]], "2311.12983_GAIA: a benchmark for General AI Assistants": [[78, "gaia-a-benchmark-for-general-ai-assistants"]], "\u2705 \u80cc\u666f\u4e0e\u95ee\u9898\uff1a": [[78, "id2"]], "\u2705 GAIA \u7684\u63d0\u51fa\uff1a": [[78, "gaia"]], "\u2705 GAIA \u7684\u610f\u4e49\uff1a": [[78, "id3"]], "2.Related work": [[78, "related-work"]], "Evaluating Large Language Models.": [[78, "evaluating-large-language-models"]], "Evaluating General Assistants.": [[78, "evaluating-general-assistants"]], "3.GAIA": [[78, "id4"]], "3.1 GAIA \u7b80\u4ecb": [[78, "id5"]], "3.2 Evaluation": [[78, "evaluation"]], "3.3 Composition of GAIA": [[78, "composition-of-gaia"]], "3.4 Building and extending GAIA": [[78, "building-and-extending-gaia"]], "4.LLMs results on GAIA": [[78, "llms-results-on-gaia"]], "1. \u95ed\u6e90\u6a21\u578b\u7684\u590d\u73b0\u6027\u95ee\u9898": [[78, "id6"]], "2. \u9759\u6001 vs \u52a8\u6001\u8bc4\u4f30\u57fa\u51c6": [[78, "vs"]], "3. \u671d\u5411\u7edf\u4e00\u7684\u751f\u6210\u6a21\u578b\u8bc4\u4f30\u65b9\u5f0f": [[78, "id7"]], "4. \u90e8\u5206\u81ea\u52a8\u5316 vs \u5b8c\u5168\u81ea\u52a8\u5316": [[78, "id8"]], "Appendix A Extended related work": [[78, "appendix-a-extended-related-work"], [218, "appendix-a-extended-related-work"]], "Large Language Models as General Assistants.": [[78, "large-language-models-as-general-assistants"]], "Appendix C Extended description of GAIA": [[78, "appendix-c-extended-description-of-gaia"]], "Description of capabilities.": [[78, "description-of-capabilities"]], "Appendix D Extended description of our question design framework": [[78, "appendix-d-extended-description-of-our-question-design-framework"]], "2404.07972_OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments": [[79, "osworld-benchmarking-multimodal-agents-for-open-ended-tasks-in-real-computer-environments"]], "2. OSWORLD Environment": [[79, "osworld-environment"]], "2.1 Task Definition": [[79, "task-definition"]], "2.2 Real Computer Environment Infrastructure": [[79, "real-computer-environment-infrastructure"]], "2.3 Observation Space": [[79, "observation-space"]], "2.4 Action Space": [[79, "action-space"]], "3. OSWORLD Benchmark": [[79, "osworld-benchmark"]], "3.1 Operating System and Software Environments": [[79, "operating-system-and-software-environments"]], "3.2 Tasks": [[79, "tasks"]], "3.3 Data Statistics": [[79, "data-statistics"]], "3.4 Human Performance": [[79, "human-performance"]], "4. Benchmarking LLM and VLM Agent Baselines": [[79, "benchmarking-llm-and-vlm-agent-baselines"]], "4.1 LLM and VLM Agent Baselines": [[79, "llm-and-vlm-agent-baselines"]], "4.2 Results": [[79, "results"]], "5. Analysis": [[79, "analysis"]], "5.1 Performance by Task Difficulty, Feasibility and App Involved": [[79, "performance-by-task-difficulty-feasibility-and-app-involved"]], "5.2 Performance by Multimodal Observation Variances": [[79, "performance-by-multimodal-observation-variances"]], "5.3 Performance across Different Operating Systems": [[79, "performance-across-different-operating-systems"]], "5.4 Qualitative Analysis": [[79, "qualitative-analysis"], [138, "qualitative-analysis"]], "6. Related Work": [[79, "related-work"], [122, "related-work"], [127, "related-work"], [181, "related-work"]], "7. Conclusion and Future Work": [[79, "conclusion-and-future-work"], [127, "conclusion-and-future-work"]], "A. Details of OSWORLD Environment": [[79, "a-details-of-osworld-environment"]], "A.1 Environment Infrastructure": [[79, "a-1-environment-infrastructure"]], "A.2 Observation Space": [[79, "a-2-observation-space"]], "C. Details of Baseline Methods": [[79, "c-details-of-baseline-methods"]], "C.2 Prompt Details": [[79, "c-2-prompt-details"]], "D. Examples of Qualitative Analysis": [[79, "d-examples-of-qualitative-analysis"]], "D.1 Success and Failure Cases": [[79, "d-1-success-and-failure-cases"]], "2501.14249_HLE: Humanity\u2019s Last Exam": [[80, "hle-humanitys-last-exam"]], "3.Dataset": [[80, "dataset"]], "\u6570\u636e\u96c6\u7b80\u4ecb": [[80, "id1"]], "\u9898\u76ee\u6765\u6e90": [[80, "id2"]], "\u9898\u76ee\u7c7b\u578b": [[80, "id3"]], "\u63d0\u4ea4\u8981\u6c42": [[80, "id4"]], "\u5956\u52b1\u673a\u5236": [[80, "id5"]], "\u8bc4\u5ba1\u6d41\u7a0b": [[80, "id6"]], "4.Evaluation": [[80, "evaluation"]], "\ud83d\udccc \u7814\u7a76\u76ee\u7684": [[80, "id7"]], "\ud83e\uddea 4.1 \u8bc4\u4f30\u65b9\u6cd5\uff08Setup\uff09": [[80, "setup"]], "\ud83d\udcca 4.2 \u91cf\u5316\u7ed3\u679c\uff08Quantitative Results\uff09": [[80, "quantitative-results"]], "\u2705 \u51c6\u786e\u7387\uff08Accuracy\uff09": [[80, "accuracy"]], "\u2696\ufe0f \u6821\u51c6\u8bef\u5dee\uff08Calibration Error\uff09": [[80, "calibration-error"]], "\ud83d\udd22 Token \u6570\u91cf\uff08Token Counts\uff09": [[80, "token-token-counts"]], "02xx.xxxxx_BLEU: a Method for Automatic Evaluation of Machine Translation": [[81, "xx-xxxxx-bleu-a-method-for-automatic-evaluation-of-machine-translation"]], "\u6838\u5fc3\u601d\u60f3": [[81, "id2"], [82, "id7"], [240, "id5"]], "\u6982\u5ff5\u548c\u5b9a\u4e49\uff1a": [[81, "id3"]], "\u516c\u5f0f": [[81, "id4"], [82, "id15"]], "\u8bba\u6587\u8d21\u732e\u70b9": [[81, "id5"]], "\u8bba\u6587\u5c40\u9650\u6027": [[81, "id6"]], "\u8ba1\u7b97\u6b65\u9aa4": [[81, "id7"]], "\u591a\u4e2aReference\u5904\u7406": [[81, "reference"]], "\u793a\u4f8b\u8bb2\u89e3": [[81, "id8"], [120, "id3"]], "\ud83d\udcdd \u8f93\u5165": [[81, "id9"]], "\ud83c\udfaf Candidate 1": [[81, "candidate-1"]], "\ud83c\udfaf Candidate 2": [[81, "candidate-2"]], "\u4e3a\u4ec0\u4e48\u63d0\u51fa BLEU \u65b9\u6cd5\uff1f": [[81, "bleu"]], "\u6838\u5fc3\u89c2\u70b9\u662f\u4ec0\u4e48\uff1f": [[81, "id10"]], "2.The Baseline BLEU Metric": [[81, "the-baseline-bleu-metric"]], "2.1 Modi\ufb01ed n-gram precision": [[81, "modified-n-gram-precision"]], "2.1.1 Modified n-gram precision on blocks of text": [[81, "modified-n-gram-precision-on-blocks-of-text"]], "2.1.2 Ranking systems using only modi\ufb01ed": [[81, "ranking-systems-using-only-modified"]], "2.1.3 Combining themodi\ufb01ed n-gram": [[81, "combining-themodified-n-gram"]], "2.2 Sentence length(\u53e5\u5b50\u957f\u5ea6\u5bf9\u7ffb\u8bd1\u8bc4\u4f30\u7684\u5f71\u54cd)": [[81, "sentence-length"]], "2.2.1 The trouble with recall": [[81, "the-trouble-with-recall"]], "2.2.2 Sentence brevity penalty": [[81, "sentence-brevity-penalty"]], "2.3 BLEU details": [[81, "bleu-details"]], "3.The BLEU Evaluation": [[81, "the-bleu-evaluation"]], "BLEU\u8bc4\u4f30\u7b80\u8981\u8bf4\u660e\uff1a": [[81, "id11"]], "\u5173\u4e8e\u53c2\u8003\u7ffb\u8bd1\u6570\u91cf\uff1a": [[81, "id12"]], "4.The Human Evaluation": [[81, "the-human-evaluation"]], "4.1 Monolingual group pairwise judgments": [[81, "monolingual-group-pairwise-judgments"]], "4.2 Bilingual group pairwise judgments": [[81, "bilingual-group-pairwise-judgments"]], "5.BLEU vs The Human Evaluation": [[81, "bleu-vs-the-human-evaluation"]], "0401.xxxxx_ROUGE: A Package for Automatic Evaluation of Summaries": [[82, "xxxxx-rouge-a-package-for-automatic-evaluation-of-summaries"]], "2.ROUGE-N: N-gram Co-Occurrence Statistics": [[82, "rouge-n-n-gram-co-occurrence-statistics"]], "\u516c\u5f0f\u542b\u4e49\uff1a": [[82, "id2"]], "ROUGE vs BLEU": [[82, "rouge-vs-bleu"]], "\u591a\u4e2a\u53c2\u8003\u6458\u8981\u65f6\u600e\u4e48\u5904\u7406": [[82, "id3"]], "Jackknifing \u6280\u672f\uff1a": [[82, "jackknifing"]], "3.ROUGE-L: Longest Common Subsequence": [[82, "rouge-l-longest-common-subsequence"]], "3.1 Sentence-Level LCS": [[82, "sentence-level-lcs"]], "\ud83d\udd39 ROUGE-L \u7684\u4f18\u70b9": [[82, "rouge-l"]], "3.2 Summary-Level LCS": [[82, "summary-level-lcs"]], "1. Recall (\u53ec\u56de\u7387)\uff1a\u516c\u5f0f (5)": [[82, "recall-5"]], "2. Precision (\u51c6\u786e\u7387)\uff1a\u516c\u5f0f (6)": [[82, "precision-6"]], "3. F-measure (F\u5206\u6570)\uff1a\u516c\u5f0f (7)": [[82, "f-measure-f-7"]], "\ud83e\uddea \u4e3e\u4f8b\u89e3\u91ca": [[82, "id5"]], "\u2705 \u603b\u7ed3\u8981\u70b9": [[82, "id6"]], "3.3 ROUGE-L vs. Normalized Pairwise LCS": [[82, "rouge-l-vs-normalized-pairwise-lcs"]], "4 ROUGE-W: Weighted Longest Common Subsequence": [[82, "rouge-w-weighted-longest-common-subsequence"]], "ROUGE-L \u7684\u95ee\u9898": [[82, "id8"]], "\u89e3\u51b3\u65b9\u6cd5": [[82, "id9"]], "\u5177\u4f53\u64cd\u4f5c": [[82, "id10"]], "\u6743\u91cd\u51fd\u6570\u7684\u8bbe\u8ba1\u8981\u6c42\uff1a": [[82, "id11"]], "\u6743\u91cd\u51fd\u6570\u793a\u4f8b": [[82, "id12"]], "\u8bf4\u660e": [[82, "id13"], [119, "id13"]], "\u5f97\u5206\u8ba1\u7b97": [[82, "id14"]], "\u51fd\u6570\u7684\u9006\u51fd\u6570\u6765\u8ba1\u7b97\u53ec\u56de\u7387\u3001\u7cbe\u786e\u7387": [[82, "id16"]], "5.ROUGE-S: Skip-Bigram Co-Occurrence Statistics": [[82, "rouge-s-skip-bigram-co-occurrence-statistics"]], "ROUGE-SU\uff1aROUGE-S \u7684\u6269\u5c55\u7248": [[82, "rouge-su-rouge-s"]], "\u603b\u7ed3\u5bf9\u6bd4\uff1a": [[82, "id18"]], "6 Evaluations of ROUGE": [[82, "evaluations-of-rouge"]], "\u76ee\u7684": [[82, "id19"]], "\u8bc4\u4f30\u65b9\u6cd5": [[82, "id20"], [162, "id4"], [188, "id8"], [217, "id7"]], "\u4e3b\u8981\u53d1\u73b0\uff1a": [[82, "id21"], [136, "id10"], [143, "id24"]], "1803.01937_ROUGE2.0: Updated and Improved Measures for Evaluation of Summarization Tasks": [[83, "rouge2-0-updated-and-improved-measures-for-evaluation-of-summarization-tasks"]], "1. Problems with the current ROUGE measures": [[83, "problems-with-the-current-rouge-measures"]], "2. ROUGE 2.0": [[83, "rouge-2-0"]], "2.1 Semantics Capture using Synonyms: Rouge-{NN|Topic|TopicUniq}+Synonyms": [[83, "semantics-capture-using-synonyms-rouge-nn-topic-topicuniq-synonyms"]], "2.2 Topic or Subset Coverage: ROUGE Topic": [[83, "topic-or-subset-coverage-rouge-topic"]], "1804.08771_SacreBLEU: A Call for Clarity in Reporting BLEU Scores": [[84, "sacrebleu-a-call-for-clarity-in-reporting-bleu-scores"]], "BLEU": [[84, "bleu"]], "\u5b9a\u4e49": [[84, "id1"], [201, "id1"]], "\u6838\u5fc3\u8ba1\u7b97\u6b65\u9aa4": [[84, "id2"]], "n-gram": [[84, "n-gram"]], "2 Problem Description": [[84, "problem-description"]], "1. BLEU\u5b9a\u4e49\u4e0d\u660e\u786e": [[84, "id4"]], "2. \u53c2\u8003\u53e5\u9884\u5904\u7406\u65b9\u5f0f\u4e0d\u540c\u5bfc\u81f4\u4e0d\u53ef\u6bd4": [[84, "id5"]], "3. \u8bba\u6587\u4e2d\u7f3a\u4e4f\u660e\u786e\u7684\u914d\u7f6e\u8bf4\u660e": [[84, "id6"]], "4. \u6570\u636e\u96c6\u7248\u672c\u4e0d\u660e\u786e": [[84, "id7"]], "3 A way forward": [[84, "a-way-forward"]], "3.1 The example of PARSEVAL": [[84, "the-example-of-parseval"]], "3.2 Existing scripts": [[84, "existing-scripts"]], "3.3 SacreBLEU": [[84, "sacrebleu"]], "4 Summary": [[84, "summary"]], "2306.05685_Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena": [[85, "judging-llm-as-a-judge-with-mt-bench-and-chatbot-arena"]], "2 MT-Bench and Chatbot Arena": [[85, "mt-bench-and-chatbot-arena"]], "2.1 \u52a8\u673a": [[85, "id2"]], "2.2 MT-Bench": [[85, "mt-bench"]], "2.3 Chatbot Arena": [[85, "chatbot-arena"]], "3 LLM as a Judge": [[85, "llm-as-a-judge"]], "1. LLM\u4f5c\u4e3a\u88c1\u5224\u7684\u4e09\u79cd\u5f62\u5f0f": [[85, "id5"]], "2. LLM\u4f5c\u4e3a\u88c1\u5224\u7684\u4f18\u52bf": [[85, "id6"]], "3. LLM\u4f5c\u4e3a\u88c1\u5224\u7684\u5c40\u9650\u6027": [[85, "id7"]], "4. \u6539\u8fdb\u65b9\u6cd5": [[85, "id8"]], "5. \u591a\u8f6e\u5bf9\u8bdd\u8bc4\u4f30\uff08Multi-turn Judge\uff09": [[85, "multi-turn-judge"]], "4 Agreement Evaluation": [[85, "agreement-evaluation"]], "5 Human Preference Benchmark and Standardized Benchmark": [[85, "human-preference-benchmark-and-standardized-benchmark"]], "Appendix A Prompt templates": [[85, "appendix-a-prompt-templates"]], "Appendix B Case Study": [[85, "appendix-b-case-study"]], "Appendix C Data Collection": [[85, "appendix-c-data-collection"]], "C.1 MT-bench \u4eba\u5de5\u8bc4\u4f30": [[85, "c-1-mt-bench"]], "C.2 Chatbot Arena": [[85, "c-2-chatbot-arena"]], "C.3 \u6570\u636e\u53d1\u5e03": [[85, "c-3"]], "Appendix D Additional Experimental Results": [[85, "appendix-d-additional-experimental-results"]], "\u9644\u5f55D \u8865\u5145\u5206\u6790\u4e0e\u5b9e\u9a8c\u7ed3\u679c\u603b\u7ed3": [[85, "d"]], "D.1 \u4f4d\u7f6e\u504f\u89c1\uff08Position Bias\uff09": [[85, "d-1-position-bias"]], "D.2 \u5c11\u6837\u672c\u8bc4\u5224\u8005\uff08Few-shot Judge\uff09": [[85, "d-2-few-shot-judge"]], "D.3 \u4e00\u81f4\u6027\u8bc4\u4f30\uff08Agreement Evaluation\uff09": [[85, "d-3-agreement-evaluation"]], "D.4 \u6309\u7c7b\u522b\u8bc4\u5206\uff08Category-wise Scores\uff09": [[85, "d-4-category-wise-scores"]], "Appendix E Training Details of Vicuna Models": [[85, "appendix-e-training-details-of-vicuna-models"]], "Appendix F Exploring Vicuna as a judge": [[85, "appendix-f-exploring-vicuna-as-a-judge"]], "F.1 \u96f6\u6837\uff08Zero-Shot\uff09Vicuna": [[85, "f-1-zero-shot-vicuna"]], "F.2 \u7cbe\u8c03\uff08Fine-Tuned\uff09Vicuna": [[85, "f-2-fine-tuned-vicuna"]], "\u7ed3\u679c\u5206\u6790": [[85, "id14"]], "LLM \u6a21\u578b": [[86, "llm"]], "NLP \u6a21\u578b": [[86, "nlp"]], "\u591a\u6a21\u6001\u6a21\u578b": [[86, "id2"]], "LLM \u97f3\u9891": [[86, "id3"]], "LLM \u89c6\u9891": [[86, "id4"]], "LLM MoE": [[86, "llm-moe"]], "\u5546\u4e1a\u6a21\u578b": [[86, "id5"]], "LLM \u5468\u8fb9\u6280\u672f": [[87, "llm"]], "Framework": [[87, "framework"]], "\u5927\u6a21\u578b\u8c03\u4f18": [[87, "id2"]], "\u5206\u5e03\u5f0f\u6a21\u578b": [[87, "id3"]], "LLM \u91cf\u5316": [[87, "id4"]], "LLM \u5b89\u5168": [[87, "id5"]], "LLM\u5f3a\u5316\u5b66\u4e60": [[87, "id6"]], "\u5176\u4ed6": [[87, "id7"], [119, "id17"], [132, "id7"], [222, "id2"], [222, "id4"]], "2101.00190_Prefix-Tuning: Optimizing Continuous Prompts for Generation": [[88, "prefix-tuning-optimizing-continuous-prompts-for-generation"]], "2103.10385_p-tuning: GPT Understands, Too": [[89, "p-tuning-gpt-understands-too"]], "2104.08691_Prompt Tuning: The Power of Scale for Parameter-Efficient Prompt Tuning": [[90, "prompt-tuning-the-power-of-scale-for-parameter-efficient-prompt-tuning"]], "2106.09685_LoRA: Low-Rank Adaptation of Large Language Models": [[91, "lora-low-rank-adaptation-of-large-language-models"]], "2401.01335_Self-Play: Fine-Tuning Converts Weak Language Models to Strong Language Models": [[92, "self-play-fine-tuning-converts-weak-language-models-to-strong-language-models"]], "2402.09353_DoRA: Weight-Decomposed Low-Rank Adaptation": [[93, "dora-weight-decomposed-low-rank-adaptation"]], "2402.12354_LoRA+: Efficient Low Rank Adaptation of Large Models": [[94, "lora-efficient-low-rank-adaptation-of-large-models"]], "2403.03507_GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection": [[95, "galore-memory-efficient-llm-training-by-gradient-low-rank-projection"]], "2403.13372_LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models": [[96, "llamafactory-unified-efficient-fine-tuning-of-100-language-models"]], "\u7ade\u4e89\u6846\u67b6": [[96, "id2"]], "3. Efficient Fine-Tuning Techniques": [[96, "efficient-fine-tuning-techniques"]], "3.1 Efficient Optimization": [[96, "efficient-optimization"]], "3.2 Efficient Computation": [[96, "efficient-computation"]], "4 LlamaFactory Framework": [[96, "llamafactory-framework"]], "4.1 Model Loader": [[96, "model-loader"]], "4.2 Data Worker": [[96, "data-worker"]], "4.3 Trainer": [[96, "trainer"]], "6 Conclusion and Future Work": [[96, "conclusion-and-future-work"]], "1712.05889_Ray: A Distributed Framework for Emerging AI Applications": [[97, "ray-a-distributed-framework-for-emerging-ai-applications"]], "2. Motivation and Requirements": [[97, "motivation-and-requirements"]], "3. Programming and Computation Model": [[97, "programming-and-computation-model"]], "3.1 Programming Model": [[97, "programming-model"]], "3.2 Computation Model": [[97, "computation-model"]], "4. Architecture": [[97, "architecture"]], "4.1 Application Layer": [[97, "application-layer"]], "4.2 System Layer": [[97, "system-layer"]], "4.2.1 Global Control Store (GCS)": [[97, "global-control-store-gcs"]], "4.2.2 Bottom-Up Distributed Scheduler": [[97, "bottom-up-distributed-scheduler"]], "4.2.3 In-Memory Distributed Object Store": [[97, "in-memory-distributed-object-store"]], "4.3 Putting Everything Together": [[97, "putting-everything-together"]], "5. Evaluation": [[97, "evaluation"], [104, "evaluation"], [143, "evaluation"], [149, "evaluation"], [165, "evaluation"], [170, "evaluation"], [187, "evaluation"], [188, "evaluation"]], "5.1 Microbenchmarks": [[97, "microbenchmarks"]], "5.2 Building blocks": [[97, "building-blocks"]], "5.3 RL \u5e94\u7528": [[97, "rl"]], "5.3.1 Evolution Strategies": [[97, "evolution-strategies"]], "5.3.2 Proximal Policy Optimization": [[97, "proximal-policy-optimization"]], "Dynamic task graphs": [[97, "dynamic-task-graphs"]], "Dataflow systems": [[97, "dataflow-systems"]], "Machine learning frameworks": [[97, "machine-learning-frameworks"]], "Actor systems": [[97, "actor-systems"]], "Global control store and scheduling": [[97, "global-control-store-and-scheduling"]], "7 Discussion and Experiences": [[97, "discussion-and-experiences"]], "8. Conclusion": [[97, "conclusion"]], "1910.02054_DeepSpeed_ZeRO: Memory Optimizations Toward Training Trillion Parameter Models": [[98, "deepspeed-zero-memory-optimizations-toward-training-trillion-parameter-models"]], "1. Extended Introduction": [[98, "extended-introduction"]], "2.1 Data, Model and Pipeline Parallelism": [[98, "data-model-and-pipeline-parallelism"]], "2.2 Non-parallelism based approach to reduce memory": [[98, "non-parallelism-based-approach-to-reduce-memory"]], "2.3 Training Optimizers": [[98, "training-optimizers"]], "3 Where Did All the Memory Go?": [[98, "where-did-all-the-memory-go"]], "3.1 Model States: Optimizer States, Gradients and Parameters": [[98, "model-states-optimizer-states-gradients-and-parameters"]], "3.2 Residual Memory Consumption": [[98, "residual-memory-consumption"]], "4 ZeRO: Insights and Overview": [[98, "zero-insights-and-overview"]], "4.1 Insights and Overview: ZeRO-DP": [[98, "insights-and-overview-zero-dp"]], "4.2 Insights and Overview: ZeRO-R": [[98, "insights-and-overview-zero-r"]], "4.2.1 \u51cf\u5c11\u6fc0\u6d3b\u5185\u5b58\u6d88\u8017": [[98, "id4"]], "4.2.2 \u7ba1\u7406\u4e34\u65f6\u7f13\u51b2\u533a": [[98, "id5"]], "4.2.3 \u7ba1\u7406\u5185\u5b58\u788e\u7247": [[98, "id6"]], "5 Deep Dive into ZeRO-DP": [[98, "deep-dive-into-zero-dp"]], "5.1 P_{os} : Optimizer State Partitioning": [[98, "p-os-optimizer-state-partitioning"]], "5.2 P_g : Gradient Partitioning": [[98, "p-g-gradient-partitioning"]], "5.3 P_p : Parameter Partitioning": [[98, "p-p-parameter-partitioning"]], "5.4 Implication on Model Size": [[98, "implication-on-model-size"]], "6 Deep Dive into ZeRO-R": [[98, "deep-dive-into-zero-r"]], "6.1 P_a : Partitioned Activation Checkpointing": [[98, "p-a-partitioned-activation-checkpointing"]], "6.2 C_B : Constant Size Buffers": [[98, "c-b-constant-size-buffers"]], "6.3 M_D : Memory Defragmentation": [[98, "m-d-memory-defragmentation"]], "7 Communication Analysis of ZeRO-DP": [[98, "communication-analysis-of-zero-dp"]], "7.1 Data Parallel Communication Volume": [[98, "data-parallel-communication-volume"]], "7.2 ZeRO-DP Communication Volume": [[98, "zero-dp-communication-volume"]], "7.2.1 Communication Volume with P_{os+g}": [[98, "communication-volume-with-p-os-g"]], "7.2.2 Communication Volume with P_{os+g+p}": [[98, "communication-volume-with-p-os-g-p"]], "8. Communication Analysis of ZeRO-R": [[98, "communication-analysis-of-zero-r"]], "9. Step Towards 1 Trillion Parameters": [[98, "step-towards-1-trillion-parameters"]], "10. Implementation and Evaluation": [[98, "implementation-and-evaluation"]], "10.1 Implementation and Methodology": [[98, "implementation-and-methodology"]], "10.2 Speed and Model Size": [[98, "speed-and-model-size"]], "11. Concluding Remarks": [[98, "concluding-remarks"]], "PyTorch: An Imperative Style, High-Performance Deep Learning Library": [[99, "pytorch-an-imperative-style-high-performance-deep-learning-library"]], "Transformers: State-of-the-Art Natural Language Processing": [[100, "transformers-state-of-the-art-natural-language-processing"]], "2210.XX_Ray v2 Architecture": [[101, "xx-ray-v2-architecture"]], "Overview": [[101, "overview"], [101, "id6"]], "API philosophy": [[101, "api-philosophy"]], "System scope": [[101, "system-scope"]], "System design goals": [[101, "system-design-goals"]], "Related systems": [[101, "related-systems"]], "Ray 2.0 \u7684\u91cd\u5927\u6539\u8fdb": [[101, "ray-2-0"]], "Architecture Overview": [[101, "architecture-overview"]], "Application concepts": [[101, "application-concepts"]], "Design": [[101, "design"]], "Components": [[101, "components"]], "worker Node": [[101, "worker-node"]], "Head Node": [[101, "head-node"]], "Ownership": [[101, "ownership"]], "Memory model": [[101, "memory-model"]], "Language Runtime": [[101, "language-runtime"]], "Lifetime of a Task": [[101, "lifetime-of-a-task"]], "Lifetime of an Object": [[101, "lifetime-of-an-object"]], "Lifetime of an Actor": [[101, "lifetime-of-an-actor"]], "Failure Model": [[101, "failure-model"]], "System Model": [[101, "system-model"]], "Application Model": [[101, "application-model"]], "\u4f8b\u5b50": [[101, "id2"]], "\u907f\u514d Fate-sharing \u7684\u65b9\u6cd5": [[101, "fate-sharing"]], "\u7cfb\u7edf\u63d0\u4f9b\u7684\u6062\u590d\u624b\u6bb5": [[101, "id3"]], "Object Management": [[101, "object-management"]], "Object resolution": [[101, "object-resolution"]], "Memory management": [[101, "memory-management"]], "Handling out-of-memory cases": [[101, "handling-out-of-memory-cases"]], "Object spilling": [[101, "object-spilling"]], "Reference Counting": [[101, "reference-counting"]], "Object Failure": [[101, "object-failure"]], "Task Management": [[101, "task-management"]], "Dependency resolution": [[101, "dependency-resolution"]], "\u7b80\u5355\u4f8b\u5b50": [[101, "id4"]], "Borrowed Object": [[101, "borrowed-object"]], "Resource fulfillment": [[101, "resource-fulfillment"]], "Resource Management and Scheduling": [[101, "resource-management-and-scheduling"]], "Ray \u7684\u8c03\u5ea6\u673a\u5236": [[101, "ray"]], "Placement Groups": [[101, "placement-groups"]], "Actor management": [[101, "actor-management"]], "Actor creation": [[101, "actor-creation"]], "Actor task execution": [[101, "actor-task-execution"]], "Actor death": [[101, "actor-death"]], "Actor \u5d29\u6e83 & \u5bb9\u9519": [[101, "actor"]], "Global Control Service": [[101, "global-control-service"]], "Node management": [[101, "node-management"]], "Resource management": [[101, "resource-management"]], "Actor \u7ba1\u7406": [[101, "id7"]], "Placement Group \u7ba1\u7406": [[101, "placement-group"]], "Metadata store": [[101, "metadata-store"]], "Fault tolerance": [[101, "fault-tolerance"]], "Cluster Management": [[101, "cluster-management"]], "Autoscaler": [[101, "autoscaler"]], "Job Submission": [[101, "job-submission"]], "Runtime Environments and Multitenancy": [[101, "runtime-environments-and-multitenancy"]], "KubeRay": [[101, "kuberay"]], "Ray Observability": [[101, "ray-observability"]], "Architecture diagram": [[101, "architecture-diagram"]], "2309.06180_vLLM: Efficient Memory Management for Large Language Model Serving with PagedAttention": [[102, "vllm-efficient-memory-management-for-large-language-model-serving-with-pagedattention"]], "2. Background": [[102, "background"], [113, "background"], [118, "background"], [119, "background"], [123, "background"], [133, "background"], [162, "background"]], "2.1.Transformer-Based Large Language Models": [[102, "transformer-based-large-language-models"]], "2.2.LLM Service & Autoregressive Generation": [[102, "llm-service-autoregressive-generation"]], "2.3.Batching Techniques for LLMs": [[102, "batching-techniques-for-llms"]], "3. Memory Challenges in LLM Serving": [[102, "memory-challenges-in-llm-serving"]], "3.1.Memory Management in Existing Systems": [[102, "memory-management-in-existing-systems"]], "4. Method": [[102, "method"]], "4.1.PagedAttention": [[102, "pagedattention"]], "4.2.KV Cache Manager": [[102, "kv-cache-manager"]], "4.3.Decoding with PagedAttention and vLLM": [[102, "decoding-with-pagedattention-and-vllm"]], "4.4.Application to Other Decoding Scenarios": [[102, "application-to-other-decoding-scenarios"]], "Parallel sampling": [[102, "parallel-sampling"]], "Beam search": [[102, "beam-search"]], "Shared prefix": [[102, "shared-prefix"]], "4.5.Scheduling and Preemption": [[102, "scheduling-and-preemption"]], "4.6.Distributed Execution": [[102, "distributed-execution"]], "5. Implementation": [[102, "implementation"]], "5.1.Kernel-level Optimization": [[102, "kernel-level-optimization"]], "5.2.Supporting Various Decoding Algorithms": [[102, "supporting-various-decoding-algorithms"]], "6. Evaluation": [[102, "evaluation"]], "7. Ablation Studies": [[102, "ablation-studies"]], "7.1.Kernel Microbenchmark": [[102, "kernel-microbenchmark"]], "7.2.Impact of Block Size": [[102, "impact-of-block-size"]], "7.3.Comparing Recomputation and Swapping": [[102, "comparing-recomputation-and-swapping"]], "10. Conclusion": [[102, "conclusion"]], "1701.06538_MoE: Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer": [[103, "moe-outrageously-large-neural-networks-the-sparsely-gated-mixture-of-experts-layer"]], "1806.03377_PipeDream: Fast and Efficient Pipeline Parallel DNN Training": [[104, "pipedream-fast-and-efficient-pipeline-parallel-dnn-training"]], "2. Background & Related Work": [[104, "background-related-work"]], "2.1 DNN Training": [[104, "dnn-training"]], "Data Parallelism": [[104, "data-parallelism"]], "Model Parallelism": [[104, "model-parallelism"]], "3. Parallel Training in PipeDream": [[104, "parallel-training-in-pipedream"]], "3.1 Pipeline Parallelism": [[104, "pipeline-parallelism"]], "3.2 Partitioning Layers Across Machines": [[104, "partitioning-layers-across-machines"]], "3.3 Work Scheduling": [[104, "work-scheduling"]], "3.4 Effective Learning": [[104, "effective-learning"]], "3.5 GPU Memory Management": [[104, "gpu-memory-management"]], "4. Implementation": [[104, "implementation"]], "\u7cfb\u7edf\u8f93\u5165\u548c\u521d\u59cb\u5316": [[104, "id3"]], "Stage Runtime \u67b6\u6784": [[104, "stage-runtime"]], "\u673a\u5668\u901a\u4fe1": [[104, "id4"]], "\u68c0\u67e5\u70b9\u4e0e\u5bb9\u9519": [[104, "id5"]], "\u6838\u5fc3\u7ed3\u8bba": [[104, "id7"]], "5.1 Experimental Setup": [[104, "experimental-setup"]], "1811.06965_GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism": [[105, "gpipe-efficient-training-of-giant-neural-networks-using-pipeline-parallelism"]], "\u6536\u96c6": [[105, "id2"], [106, "id2"], [107, "id2"]], "2. The GPipe Library": [[105, "the-gpipe-library"]], "2.1 \u63a5\u53e3\u8bbe\u8ba1(Interface)": [[105, "interface"]], "2.2 Algorithm": [[105, "algorithm"]], "2.3 Performance Optimization": [[105, "performance-optimization"]], "3. Performance Analyses": [[105, "performance-analyses"]], "4. Image Classification": [[105, "image-classification"]], "5. Massive Massively Multilingual Machine Translation": [[105, "massive-massively-multilingual-machine-translation"]], "6. Design Features and Trade-Offs": [[105, "design-features-and-trade-offs"]], "1909.08053_Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism": [[106, "megatron-lm-training-multi-billion-parameter-language-models-using-model-parallelism"]], "2. Background and Challenges": [[106, "background-and-challenges"]], "2.1 Neural Language Model Pretraining": [[106, "neural-language-model-pretraining"]], "2.2 Transformer Language Models and Multi-Head Attention": [[106, "transformer-language-models-and-multi-head-attention"]], "2.3 Data and Model Parallelism in Deep Learning": [[106, "data-and-model-parallelism-in-deep-learning"]], "3. Model Parallel Transformers": [[106, "model-parallel-transformers"]], "\u591a\u5c42\u611f\u77e5\u673a(MLP)\u6a21\u5757\u5e76\u884c\u5316": [[106, "mlp"]], "\u81ea\u6ce8\u610f\u529b\u6a21\u5757\u5e76\u884c\u5316": [[106, "id4"]], "\u8f93\u51fa\u5d4c\u5165\u7684\u5e76\u884c\u5316": [[106, "id5"]], "19xx_PipeDream: Generalized Pipeline Parallelism for DNN Training": [[107, "xx-pipedream-generalized-pipeline-parallelism-for-dnn-training"]], "2. BACKGROUND AND RELATED WORK": [[107, "background-and-related-work"]], "2.1 Intra-batch Parallelism": [[107, "intra-batch-parallelism"]], "2.2 Inter-batch Parallelism": [[107, "inter-batch-parallelism"]], "2.3 DNN Model and Hardware Diversity": [[107, "dnn-model-and-hardware-diversity"]], "3. \u6d41\u6c34\u7ebf\u5e76\u884c(PIPELINE PARALLELISM)": [[107, "pipeline-parallelism"]], "3.1 \u6311\u6218 1: \u5de5\u4f5c\u5206\u533a(Work Partitioning)": [[107, "work-partitioning"]], "3.2 \u6311\u6218 2: \u5de5\u4f5c\u8c03\u5ea6(Work Scheduling)": [[107, "work-scheduling"]], "\u89e3\u51b3\u65b9\u6848: PipeDream\u7684\u8c03\u5ea6\u7b56\u7565": [[107, "pipedream"]], "3.3 \u6311\u6218 3: \u6709\u6548\u5b66\u4e60(Effective Learning)": [[107, "effective-learning"]], "\u89e3\u51b3\u65b9\u6848: \u6743\u91cd\u7f13\u5b58(Weight Stashing)": [[107, "weight-stashing"]], "\u5782\u76f4\u540c\u6b65(Vertical Sync)": [[107, "vertical-sync"]], "\u8fc7\u65f6\u6027(Staleness)": [[107, "staleness"]], "4. \u5b9e\u73b0": [[107, "id5"]], "6. \u7ed3\u8bba": [[107, "id6"]], "2006.09503_PipeDream-2BW: Memory-Efficient Pipeline-Parallel DNN Training": [[108, "pipedream-2bw-memory-efficient-pipeline-parallel-dnn-training"]], "2006.15704_PyTorch Distributed: Experiences on Accelerating Data Parallel Training": [[109, "pytorch-distributed-experiences-on-accelerating-data-parallel-training"]], "2006.16668_GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding": [[110, "gshard-scaling-giant-models-with-conditional-computation-and-automatic-sharding"]], "2104.04473_Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM": [[111, "efficient-large-scale-language-model-training-on-gpu-clusters-using-megatron-lm"]], "2205.14135_FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness": [[112, "flashattention-fast-and-memory-efficient-exact-attention-with-io-awareness"]], "2 Background": [[112, "background"], [214, "background"]], "2.1 Hardware Performance": [[112, "hardware-performance"]], "GPU \u5185\u5b58\u5c42\u6b21\u7ed3\u6784(Memory Hierarchy)": [[112, "gpu-memory-hierarchy"]], "GPU \u6267\u884c\u6a21\u578b(Execution Model)": [[112, "gpu-execution-model"]], "\u5185\u5b58\u4f18\u5316\u65b9\u6cd5: Kernel Fusion": [[112, "kernel-fusion"]], "2.2 Standard Attention Implementation": [[112, "standard-attention-implementation"], [113, "standard-attention-implementation"]], "\u81ea\u6ce8\u610f\u529b\u8ba1\u7b97\u6d41\u7a0b": [[112, "id2"]], "\u8ba1\u7b97\u590d\u6742\u5ea6": [[112, "id3"]], "HBM \u8bbf\u95ee\u7684\u5f71\u54cd": [[112, "hbm"]], "\u6807\u51c6\u6ce8\u610f\u529b vs. FlashAttention": [[112, "vs-flashattention"]], "\u6807\u51c6\u6ce8\u610f\u529b\u7684\u4e3b\u8981\u95ee\u9898": [[112, "id5"]], "FlashAttention \u5982\u4f55\u4f18\u5316": [[112, "flashattention"]], "3. FLASHATTENTION: Algorithm, Analysis, and Extensions": [[112, "flashattention-algorithm-analysis-and-extensions"]], "3.1 An Efficient Attention Algorithm With Tiling and Recomputation": [[112, "an-efficient-attention-algorithm-with-tiling-and-recomputation"]], "Tiling\uff08\u5206\u5757\u8ba1\u7b97\uff09": [[112, "tiling"]], "Recomputation\uff08\u91cd\u8ba1\u7b97\uff09": [[112, "recomputation"]], "Implementation details: Kernel Fusion\uff08\u5185\u6838\u878d\u5408\uff09": [[112, "implementation-details-kernel-fusion"]], "\u4f2a\u4ee3\u7801\u89e3\u6790": [[112, "id6"]], "3.2 Analysis: IO Complexity of FlashAttention": [[112, "analysis-io-complexity-of-flashattention"]], "3.3 Extension: Block-Sparse FlashAttention": [[112, "extension-block-sparse-flashattention"]], "4. Experiments": [[112, "experiments"], [125, "experiments"], [140, "experiments"], [146, "experiments"], [162, "experiments"], [171, "experiments"], [224, "experiments"], [227, "experiments"], [229, "experiments"]], "5. Limitations and Future Directions": [[112, "limitations-and-future-directions"]], "Appendix B Algorithm Details": [[112, "appendix-b-algorithm-details"]], "B.1 Memory-efficient forward pass": [[112, "b-1-memory-efficient-forward-pass"]], "B.2 Memory-efficient backward pass": [[112, "b-2-memory-efficient-backward-pass"]], "B.3 FlashAttention: Forward Pass": [[112, "b-3-flashattention-forward-pass"]], "B.4 FlashAttention: Backward Pass": [[112, "b-4-flashattention-backward-pass"]], "B.5 Comparison with Rabe and Staats": [[112, "b-5-comparison-with-rabe-and-staats"]], "Appendix C Proofs": [[112, "appendix-c-proofs"]], "Appendix D Extension Details": [[112, "appendix-d-extension-details"]], "2307.08691_FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning": [[113, "flashattention-2-faster-attention-with-better-parallelism-and-work-partitioning"]], "2.1 Hardware characteristics": [[113, "hardware-characteristics"]], "2.3 FlashAttention": [[113, "flashattention"]], "2.3.1 Forward pass": [[113, "forward-pass"]], "2.3.2 Backward pass": [[113, "backward-pass"]], "3. FlashAttention-2: Algorithm, Parallelism, and Work Partitioning": [[113, "flashattention-2-algorithm-parallelism-and-work-partitioning"]], "3.1 Algorithm": [[113, "algorithm"]], "3.1.1 Forward pass": [[113, "id2"]], "3.1.2 Backward pass": [[113, "id3"]], "3.2 Parallelism": [[113, "parallelism"]], "3.3 Work Partitioning Between Warps": [[113, "work-partitioning-between-warps"]], "4. Empirical Validation": [[113, "empirical-validation"]], "5. Discussion and Future Directions": [[113, "discussion-and-future-directions"]], "\u6df7\u5408\u7cbe\u5ea6": [[115, "id2"]], "\u6d6e\u70b9\u6570\u683c\u5f0f": [[115, "id3"]], "TF32\uff08TensorFloat-32\uff09": [[115, "tf32-tensorfloat-32"]], "BF16\uff08Brain Float 16\uff09": [[115, "bf16-brain-float-16"]], "FP16\uff08IEEE Half Precision\uff09": [[115, "fp16-ieee-half-precision"]], "FP8\uff088\u4f4d\u6d6e\u70b9\uff09": [[115, "fp8-8"]], "INT8 / INT4\uff08\u5b9a\u70b9\u6574\u6570\uff09": [[115, "int8-int4"]], "Posit": [[115, "posit"]], "weight-only quantization": [[115, "weight-only-quantization"]], "\u901a\u7528\u683c\u5f0f\uff1aW{N}G{M}": [[115, "w-n-g-m"]], "\u5404\u914d\u7f6e\u5177\u4f53\u89e3\u91ca": [[115, "id4"]], "\u9009\u7528\u5efa\u8bae": [[115, "id5"]], "2110.02861_bitsandbytes: 8-bit Optimizers via Block-wise Quantization": [[116, "bitsandbytes-8-bit-optimizers-via-block-wise-quantization"]], "1. Background": [[116, "background"]], "\u4e00\u3001Stateful Optimizers\uff08\u6709\u72b6\u6001\u4f18\u5316\u5668\uff09": [[116, "stateful-optimizers"]], "\u4e8c\u3001Non-linear Quantization\uff08\u975e\u7ebf\u6027\u91cf\u5316\uff09": [[116, "non-linear-quantization"]], "\u4e09\u3001Dynamic Tree Quantization\uff08\u52a8\u6001\u6811\u91cf\u5316\uff09": [[116, "dynamic-tree-quantization"]], "2. 8-bit Optimizers": [[116, "bit-optimizers"]], "\ud83c\udf1f 8-bit\u4f18\u5316\u5668\u7684\u6838\u5fc3\u7ec4\u6210\uff1a": [[116, "bit"]], "\ud83d\udd27 \u4f7f\u7528\u65b9\u5f0f\uff1a": [[116, "id1"]], "\ud83d\ude80 \u4f18\u52bf\uff1a": [[116, "id2"]], "3. 8-bit vs 32-bit Optimizer Performance for common Benchmarks": [[116, "bit-vs-32-bit-optimizer-performance-for-common-benchmarks"]], "\ud83d\udccc \u5b9e\u9a8c\u76ee\u7684": [[116, "id3"]], "\u2699\ufe0f \u5b9e\u9a8c\u8bbe\u7f6e": [[116, "id4"]], "\u2705 \u7ed3\u8bba": [[116, "id5"]], "4. Analysis": [[116, "analysis"]], "\u7814\u7a76\u76ee\u7684\uff1a": [[116, "id6"]], "\u5206\u6790\u65b9\u6cd5\uff1a": [[116, "id7"]], "\u5b9e\u9a8c\u8bbe\u7f6e\uff1a": [[116, "id8"], [136, "id9"]], "\u6d88\u878d\u5b9e\u9a8c\u4e3b\u8981\u53d1\u73b0\uff1a": [[116, "id9"]], "\u8d85\u53c2\u654f\u611f\u6027\u5206\u6790\u7ed3\u679c\uff1a": [[116, "id10"]], "\u4e00\u3001\u4f18\u5316\u5668\u72b6\u6001\u7684\u538b\u7f29\u4e0e\u5206\u5e03": [[116, "id12"]], "\u4e8c\u3001\u901a\u7528\u7684\u5185\u5b58\u4f18\u5316\u6280\u672f": [[116, "id13"]], "\u4e09\u3001\u91cf\u5316\u65b9\u6cd5\u4e0e\u6570\u636e\u7c7b\u578b": [[116, "id14"]], "2206.01861_ZeroQuant: Efficient and Affordable Post-Training Quantization for Large-Scale Transformers": [[117, "zeroquant-efficient-and-affordable-post-training-quantization-for-large-scale-transformers"]], "2. Relative Work": [[117, "relative-work"]], "\ud83c\udf1f \u603b\u4f53\u4ecb\u7ecd\uff1a": [[117, "id1"]], "\ud83e\udde0 \u4e3b\u6d41\u65b9\u6cd5 1\uff1a\u8bad\u7ec3\u611f\u77e5\u91cf\u5316\uff08QAT\uff09": [[117, "qat"]], "\ud83e\udde0 \u4e3b\u6d41\u65b9\u6cd5 2\uff1a\u8bad\u7ec3\u540e\u91cf\u5316\uff08PTQ\uff09": [[117, "ptq"]], "\u2757 \u5f53\u524d\u6311\u6218\uff1a": [[117, "id2"]], "\u2705 ZeroQuant \u7684\u8d21\u732e\uff1a": [[117, "zeroquant"]], "3. Background and Challenges": [[117, "background-and-challenges"]], "\ud83d\udccc \u80cc\u666f\u77e5\u8bc6": [[117, "id3"]], "\ud83d\udccc \u5b58\u5728\u7684\u95ee\u9898": [[117, "id4"]], "1. GPT \u548c BERT \u4e0a\u4f4e\u6bd4\u7279\u91cf\u5316\u96be\u5ea6\u5927": [[117, "gpt-bert"]], "2. INT8 \u7cbe\u5ea6\u5c31\u5df2\u660e\u663e\u964d\u4f4e\u6027\u80fd": [[117, "int8"]], "\ud83d\udccc \u539f\u56e0\u5206\u6790": [[117, "id5"]], "\ud83d\udd38 \u6fc0\u6d3b\u8303\u56f4\u53d8\u5316\u5927": [[117, "id6"]], "\ud83d\udd38 \u6ce8\u610f\u529b\u6743\u91cd\u884c\u4e4b\u95f4\u5dee\u5f02\u5927": [[117, "id7"]], "\ud83d\udccc \u5c0f\u7ed3": [[117, "id8"], [228, "id9"]], "4. Methodology": [[117, "methodology"]], "4.1 Fine-grained Hardware-friendly Quantization Scheme": [[117, "fine-grained-hardware-friendly-quantization-scheme"]], "4.2 Layer-by-layer Knowledge Distillation with Affordable Cost": [[117, "layer-by-layer-knowledge-distillation-with-affordable-cost"]], "4.3 Quantization-Optimized Transformer Kernels": [[117, "quantization-optimized-transformer-kernels"]], "5. Results": [[117, "results"]], "\ud83d\udd0d BERT \u5b9e\u9a8c\u4e3b\u8981\u7ed3\u8bba": [[117, "bert"]], "\ud83d\udd0d GPT-3 \u6a21\u578b\u5b9e\u9a8c": [[117, "gpt-3"]], "\u26a1 \u63a8\u7406\u901f\u5ea6\u63d0\u5347": [[117, "id9"]], "\ud83d\ude80 \u5927\u6a21\u578b\u6269\u5c55\u6027\u9a8c\u8bc1": [[117, "id10"]], "\ud83e\uddea \u6d88\u878d\u5b9e\u9a8c\u7ed3\u679c": [[117, "id11"]], "\ud83d\udd10 \u65e0\u539f\u59cb\u8bad\u7ec3\u6570\u636e\u4e5f\u80fd\u7528 LKD": [[117, "lkd"]], "Appendix A Background": [[117, "appendix-a-background"]], "\u4e00\u3001Transformer\u7ed3\u6784\uff08A.1\uff09": [[117, "transformer-a-1"]], "\u4e8c\u3001\u91cf\u5316\u57fa\u7840\uff08A.2\uff09": [[117, "a-2"]], "Appendix D Details about System Optimization": [[117, "appendix-d-details-about-system-optimization"]], "\u6574\u4f53\u4f18\u5316\u76ee\u6807\uff1a": [[117, "id12"]], "\u4e3b\u8981\u4f18\u5316\u65b9\u6cd5\uff1a": [[117, "id13"]], "2206.09557_LUT-GEMM: Quantized Matrix Multiplication based on LUTs for Efficient Inference in Large-Scale Generative Language Models": [[118, "lut-gemm-quantized-matrix-multiplication-based-on-luts-for-efficient-inference-in-large-scale-generative-language-models"]], "1. Instructions": [[118, "instructions"], [141, "instructions"]], "LUT-GEMM \u7684\u6838\u5fc3\u4f18\u52bf\uff1a": [[118, "lut-gemm"]], "2.1 GPU-Accelerated Generative LMs": [[118, "gpu-accelerated-generative-lms"]], "2.2 Quantization Methods and Limitations": [[118, "quantization-methods-and-limitations"]], "2.3 \u4e8c\u8fdb\u5236\u7f16\u7801\u91cf\u5316\uff08BCQ\uff09": [[118, "bcq"]], "3. Design Methodology of LUT-GEMM": [[118, "design-methodology-of-lut-gemm"]], "3.1 LUT based Quantized Matrix Multiplication": [[118, "lut-based-quantized-matrix-multiplication"]], "3.2 LUT Based implementation on GPU": [[118, "lut-based-implementation-on-gpu"]], "3.3 Representational Capability of LUT-GEMM": [[118, "representational-capability-of-lut-gemm"]], "3.4 Latency-Accuracy Trade-Off for Improved Applicability": [[118, "latency-accuracy-trade-off-for-improved-applicability"]], "4. Experimental results": [[118, "experimental-results"], [226, "experimental-results"]], "\ud83c\udf1f \u6838\u5fc3\u89c2\u70b9\u603b\u7ed3": [[118, "id2"]], "4.1 Kernel\uff08\u5185\u6838\uff09\u5bf9\u6bd4\u7ed3\u679c": [[118, "kernel"]], "4.2 \u7aef\u5230\u7aef\u63a8\u7406\u5ef6\u8fdf": [[118, "id3"]], "\ud83d\udccc \u603b\u7ed3\u4e00\u53e5\u8bdd": [[118, "id4"]], "5. Accelerating Quantized OPT-175B": [[118, "accelerating-quantized-opt-175b"]], "Appendix A LLM Inference Latency Breakdown": [[118, "appendix-a-llm-inference-latency-breakdown"]], "Appendix B Detailed Implementation": [[118, "appendix-b-detailed-implementation"]], "2208.07339_LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale": [[119, "llm-int8-8-bit-matrix-multiplication-for-transformers-at-scale"]], "\u76f8\u5173\u53c2\u8003": [[119, "id1"]], "\ud83c\udf1f\u80cc\u666f\u95ee\u9898\uff1a": [[119, "id2"]], "\ud83e\udde0\u8fd9\u7bc7\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\uff1a": [[119, "id3"]], "\ud83d\udd0d\u79bb\u7fa4\u7279\u5f81\u7684\u5f71\u54cd\uff1a": [[119, "id4"]], "\ud83d\udcca\u5b9e\u9a8c\u8bc1\u660e\uff1a": [[119, "id5"]], "\ud83d\udccc \u7814\u7a76\u76ee\u7684\uff1a": [[119, "id6"]], "\ud83d\udd39 1. absmax(\u5bf9\u79f0\u91cf\u5316)": [[119, "absmax"]], "\ud83d\udd39 2. zeropoint(\u975e\u5bf9\u79f0\u91cf\u5316)": [[119, "zeropoint"]], "\u793a\u4f8b": [[119, "id7"], [119, "id16"], [119, "id18"]], "\ud83e\uddee \u77e9\u9635\u4e58\u6cd5\u4e2d\u7684\u4f7f\u7528\u65b9\u5f0f": [[119, "id8"]], "\ud83e\udde0 \u6838\u5fc3\u7ed3\u8bba\u9884\u793a\uff1a": [[119, "id9"]], "3. Int8 Matrix Multiplication at Scale": [[119, "int8-matrix-multiplication-at-scale"]], "\ud83c\udf1f\u6838\u5fc3\u95ee\u9898": [[119, "id10"]], "\u2705\u89e3\u51b3\u65b9\u6848\uff1aLLM.int8() \u65b9\u6cd5": [[119, "llm-int8"]], "\ud83d\udcca\u5b9e\u9a8c": [[119, "id11"]], "4. Emergent Large Magnitude Features in Transformers at Scale": [[119, "emergent-large-magnitude-features-in-transformers-at-scale"]], "\u5b9a\u4e49-\u4ec0\u4e48\u662f\u201cOutlier Feature\u201d\uff1f": [[119, "outlier-feature"]], "\u8fd9\u4e9b Outlier Feature \u662f\u600e\u4e48\u51fa\u73b0\u7684\uff1f": [[119, "id14"]], "\u4e3a\u4ec0\u4e48 Outlier \u4f1a\u5e26\u6765\u95ee\u9898\uff1f": [[119, "outlier"]], "\u5e94\u5bf9\u65b9\u6cd5\uff1a": [[119, "id15"]], "6. Discussion and Limitations": [[119, "discussion-and-limitations"]], "7. Broader Impacts": [[119, "broader-impacts"]], "\u5c06\u6240\u6709 nn.Linear \u6a21\u5757\u66ff\u6362\u4e3a bnb.nn.Linear8bitLt \u800c\u65e0\u9700\u5360\u7528\u5185\u5b58:": [[119, "nn-linear-bnb-nn-linear8bitlt"]], "2209.05433_FP8: FP8 Formats For Deep Learning": [[120, "fp8-fp8-formats-for-deep-learning"]], "2. Aspects of FP8 Usage in Deep Learning": [[120, "aspects-of-fp8-usage-in-deep-learning"]], "3. FP8 Binary Interchange Format": [[120, "fp8-binary-interchange-format"]], "\u4e24\u79cd FP8 \u7f16\u7801\u683c\u5f0f": [[120, "fp8"]], "\u683c\u5f0f\u7ec6\u8282": [[120, "id1"]], "4. \u6307\u6570\u504f\u7f6e\uff08Exponent Bias\uff09": [[120, "exponent-bias"]], "Normal": [[120, "normal"]], "Subnormal": [[120, "subnormal"]], "4. Empirical Results": [[120, "empirical-results"]], "4.1 Training": [[120, "training"]], "4.2 Inference": [[120, "inference"]], "4.3 Per-tensor Scaling Factors": [[120, "per-tensor-scaling-factors"]], "\u2705 \u603b\u7ed3": [[120, "id4"], [181, "id9"], [225, "id16"]], "5. Conclusions": [[120, "conclusions"]], "2210.17323_GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers": [[121, "gptq-accurate-post-training-quantization-for-generative-pre-trained-transformers"]], "3. Background": [[121, "background"], [218, "background"]], "4. The GPTQ Algorithm": [[121, "the-gptq-algorithm"]], "5. Experimental Validation": [[121, "experimental-validation"]], "6. Summary and Limitations": [[121, "summary-and-limitations"]], "2211.10438_SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models": [[122, "smoothquant-accurate-and-efficient-post-training-quantization-for-large-language-models"]], "SmoothQuant \u7684\u6838\u5fc3\u601d\u8def\uff1a": [[122, "smoothquant"]], "\u4f18\u70b9\uff1a": [[122, "id1"]], "2. Preliminaries": [[122, "preliminaries"], [127, "preliminaries"], [158, "preliminaries"]], "1. \u91cf\u5316\uff08Quantization\uff09\u662f\u4ec0\u4e48\uff1f": [[122, "quantization"]], "2. \u57fa\u672c\u516c\u5f0f\uff1a": [[122, "id2"]], "\u793a\u4f8b\uff1a": [[122, "id3"]], "\ud83d\udd04 \u91cf\u5316\u8fc7\u7a0b\uff1a": [[122, "id4"]], "\ud83d\udce6 \u53cd\u91cf\u5316\uff08Dequantization\uff09\u4e5f\u53ef\u4ee5\u505a\uff1a": [[122, "dequantization"]], "3. \u0394\uff08\u91cf\u5316\u6b65\u957f\uff09\u600e\u4e48\u5f97\u51fa\uff1f": [[122, "id5"]], "4. \u91cf\u5316\u7684\u7c92\u5ea6\u6709\u4e0d\u540c\u79cd\u7c7b\uff1a": [[122, "id6"]], "5. \u4e3a\u4ec0\u4e48 INT8 \u6709\u7528\uff1f": [[122, "int8"]], "3. Review of Quantization Difficulty": [[122, "review-of-quantization-difficulty"]], "\u5404\u79cd\u91cf\u5316\u65b9\u6cd5\u7684\u5bf9\u6bd4\uff08\u4ee5INT8\u4e3a\u4f8b\uff09\uff1a": [[122, "id7"]], "\u96be\u70b9\u603b\u7ed3\uff1a": [[122, "id8"]], "4. SmoothQuant": [[122, "id9"]], "\ud83d\udccc \u6838\u5fc3\u601d\u60f3\uff1a": [[122, "id10"]], "\ud83e\udde0 \u539f\u7406\u7b80\u5316\uff1a": [[122, "id11"]], "\u2699\ufe0f \u5728 Transformer \u4e2d\u7684\u5e94\u7528\uff1a": [[122, "transformer"]], "\u4e00\u3001\u5b9e\u9a8c\u8bbe\u7f6e\uff085.1 Setups\uff09": [[122, "setups"]], "\u4e8c\u3001\u51c6\u786e\u7387\u8bc4\u4f30\uff085.2 Accurate Quantization\uff09": [[122, "accurate-quantization"]], "\u4e09\u3001\u52a0\u901f\u4e0e\u5185\u5b58\u8282\u7701\uff085.3 Speedup and Memory Saving\uff09": [[122, "speedup-and-memory-saving"]], "\u56db\u3001\u89c4\u6a21\u5316\u90e8\u7f72\uff085.4 Scaling Up\uff09": [[122, "scaling-up"]], "\u4e94\u3001\u6d88\u878d\u5b9e\u9a8c\uff085.5 Ablation Study\uff09": [[122, "ablation-study"]], "1. \u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09": [[122, "llms"]], "2. \u6a21\u578b\u91cf\u5316\uff08Model Quantization\uff09": [[122, "model-quantization"]], "3. LLM\u91cf\u5316\u7684\u6311\u6218\u4e0e\u73b0\u72b6": [[122, "llm"]], "Appendix A. Discussion on Weight-Only Quantization": [[122, "appendix-a-discussion-on-weight-only-quantization"]], "\u80cc\u666f\uff1a": [[122, "id13"]], "\u6838\u5fc3\u8ba8\u8bba\u8981\u70b9\uff1a": [[122, "id14"]], "2305.14314_QLoRA: Efficient Finetuning of Quantized LLMs": [[123, "qlora-efficient-finetuning-of-quantized-llms"]], "\u5173\u952e\u8bcd": [[123, "id1"], [225, "id1"]], "Block-wise k-bit Quantization(\u5206\u5757\u4f4e\u6bd4\u7279\u91cf\u5316)": [[123, "block-wise-k-bit-quantization"]], "Low-rank Adapters": [[123, "low-rank-adapters"]], "Memory Requirement of Parameter-Efficient Finetuning": [[123, "memory-requirement-of-parameter-efficient-finetuning"]], "3. QLoRA Finetuning": [[123, "qlora-finetuning"]], "\u6838\u5fc3\u6280\u672f\u70b9: 4-bit NormalFloat (NF4) \u91cf\u5316": [[123, "bit-normalfloat-nf4"]], "\u6838\u5fc3\u6280\u672f\u70b9: Double Quantization\uff08\u53cc\u91cd\u91cf\u5316\uff09": [[123, "double-quantization"]], "\u6838\u5fc3\u6280\u672f\u70b9: Paged Optimizers\uff08\u5206\u9875\u4f18\u5316\u5668\uff09": [[123, "paged-optimizers"]], "QLoRA": [[123, "qlora"]], "4. QLoRA vs. Standard Finetuning": [[123, "qlora-vs-standard-finetuning"]], "\u2705 \u6838\u5fc3\u7ed3\u8bba": [[123, "id2"]], "\ud83d\udcca \u4e3b\u8981\u5b9e\u9a8c\u7ed3\u8bba": [[123, "id3"]], "\ud83e\udde0 \u603b\u4f53\u610f\u4e49": [[123, "id4"]], "5. Pushing the Chatbot State-of-the-art with QLoRA": [[123, "pushing-the-chatbot-state-of-the-art-with-qlora"]], "\ud83c\udf1f \u4e3b\u8981\u7ed3\u8bba\uff1a": [[123, "id5"]], "\ud83e\uddea \u5b9e\u9a8c\u8bbe\u7f6e\uff1a": [[123, "id6"], [136, "id13"]], "\ud83d\udcca \u8bc4\u4f30\u65b9\u5f0f\uff1a": [[123, "id7"], [143, "id31"]], "\ud83d\udd1d \u7ed3\u679c\u4eae\u70b9\uff1a": [[123, "id8"]], "\ud83d\udca1 \u989d\u5916\u89c2\u5bdf\uff1a": [[123, "id9"]], "6. Qualitative Analysis": [[123, "qualitative-analysis"]], "6.1 Qualitative Analysis of Example Generations": [[123, "qualitative-analysis-of-example-generations"]], "1. \u4e8b\u5b9e\u56de\u5fc6\uff08Factual Recall\uff09": [[123, "factual-recall"]], "2. \u6697\u793a\u6027\uff08Suggestibility\uff09": [[123, "suggestibility"]], "3. \u62d2\u7edd\u6027\uff08Refusal\uff09": [[123, "refusal"]], "4. \u4fdd\u5bc6\u6027\uff08Secret Keeping\uff09": [[123, "secret-keeping"]], "5. \u6570\u5b66\u80fd\u529b\uff08Math\uff09": [[123, "math"]], "6. \u5fc3\u7406\u63a8\u7406\u80fd\u529b\uff08Theory of Mind\uff09": [[123, "theory-of-mind"]], "6.2 Considerations": [[123, "considerations"]], "1. \u8bc4\u4f30\u95ee\u9898\uff08Evaluation\uff09": [[123, "evaluation"]], "2. \u6570\u636e\u4e0e\u8bad\u7ec3\uff08Data & Training\uff09": [[123, "data-training"]], "7. Related Work": [[123, "related-work"]], "\u91cf\u5316\uff08Quantization\uff09": [[123, "quantization"]], "\u5fae\u8c03\u4e0e\u9002\u914d\u5668\uff08Finetuning with Adapters\uff09": [[123, "finetuning-with-adapters"]], "\u6307\u4ee4\u5fae\u8c03\uff08Instruction Finetuning\uff09": [[123, "instruction-finetuning"]], "\u804a\u5929\u673a\u5668\u4eba\uff08Chatbots\uff09": [[123, "chatbots"]], "8. Limitations and Discussion": [[123, "limitations-and-discussion"]], "2306.00978_AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration": [[124, "awq-activation-aware-weight-quantization-for-llm-compression-and-acceleration"]], "3. AWQ: Activation-aware Weight Quantization": [[124, "awq-activation-aware-weight-quantization"]], "1. \u5173\u952e\u601d\u60f3\uff1a\u4fdd\u62a4\u91cd\u8981\u6743\u91cd\uff08salient weights\uff09": [[124, "salient-weights"]], "2. \u95ee\u9898\uff1a\u6df7\u5408\u7cbe\u5ea6\u96be\u90e8\u7f72 \u2192 \u66ff\u4ee3\u65b9\u6cd5\uff1a\u7f29\u653e": [[124, "id1"]], "\u7ed3\u8bba\u603b\u7ed3\uff1a": [[124, "id2"]], "4. TinyChat: Mapping AWQ onto Edge Platforms": [[124, "tinychat-mapping-awq-onto-edge-platforms"]], "4.1 Why AWQ Helps Accelerate On-Device LLMs": [[124, "why-awq-helps-accelerate-on-device-llms"]], "4.2 Deploy AWQ with TinyChat": [[124, "deploy-awq-with-tinychat"]], "2309.05516_AutoRound: Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs": [[125, "autoround-optimize-weight-rounding-via-signed-gradient-descent-for-the-quantization-of-llms"]], "3. Methodology": [[125, "methodology"]], "1703.03864_Evolution Strategies: as a Scalable Alternative to Reinforcement Learning": [[126, "evolution-strategies-as-a-scalable-alternative-to-reinforcement-learning"]], "2504.02495_DeepSeek-GRM: Inference-Time Scaling for Generalist Reward Modeling": [[127, "deepseek-grm-inference-time-scaling-for-generalist-reward-modeling"]], "2.1 Comparisons of Different RM approaches": [[127, "comparisons-of-different-rm-approaches"]], "2.2 Boosting Reward Quality with Principles": [[127, "boosting-reward-quality-with-principles"]], "3. Self-Principled Critique Tuning (SPCT)": [[127, "self-principled-critique-tuning-spct"]], "3.1 Unpinning Principles from Understanding to Generation": [[127, "unpinning-principles-from-understanding-to-generation"]], "3.2 Rule-Based Reinforcement Learning": [[127, "rule-based-reinforcement-learning"]], "\u5c0f\u7ed3: SPCT \u6709\u5565\u4eae\u70b9": [[127, "spct"]], "4. Inference-Time Scaling with SPCT": [[127, "inference-time-scaling-with-spct"]], "\u6838\u5fc3\u80cc\u666f": [[127, "id2"]], "4.1 Voting with Generated Rewards": [[127, "voting-with-generated-rewards"]], "4.2 Meta Reward Modeling Guided Voting": [[127, "meta-reward-modeling-guided-voting"]], "\u603b\u7ed3\u7406\u89e3": [[127, "id3"]], "5. Results on Reward Modeling Benchmarks": [[127, "results-on-reward-modeling-benchmarks"]], "5.1 Experiment Settings": [[127, "experiment-settings"]], "5.2 Results and Analysis": [[127, "results-and-analysis"]], "Generative Reward Models, GRMs": [[127, "generative-reward-models-grms"]], "Inference-Time Scaling for LLMs": [[127, "inference-time-scaling-for-llms"]], "A. Additional Related Work": [[127, "a-additional-related-work"]], "B. Limitations and Future Directions": [[127, "b-limitations-and-future-directions"]], "Future Directions": [[127, "future-directions"]], "G. Prompt Templates": [[127, "g-prompt-templates"]], "2504.13958_ToolRL: Reward is All Tool Learning Needs": [[128, "toolrl-reward-is-all-tool-learning-needs"]], "2312.06674_Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations": [[129, "llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations"]], "2203.02155_Training language models to follow instructions with human feedback(InstructGPT)": [[130, "training-language-models-to-follow-instructions-with-human-feedback-instructgpt"]], "3. Methods and experimental details": [[130, "methods-and-experimental-details"]], "3.1 High-level methodology": [[130, "high-level-methodology"]], "3.2 Dataset": [[130, "dataset"]], "3.4 Human data collection": [[130, "human-data-collection"]], "3.5 Models": [[130, "models"]], "4.1 Results on the API distribution": [[130, "results-on-the-api-distribution"]], "4.2 Results on public NLP datasets": [[130, "results-on-public-nlp-datasets"]], "5. Discussion": [[130, "discussion"]], "Appendix A Additional prompt data details": [[130, "appendix-a-additional-prompt-data-details"]], "A.1 Labeler-written prompts": [[130, "a-1-labeler-written-prompts"]], "A.2 API user prompts": [[130, "a-2-api-user-prompts"]], "A.2.1 Illustrative user prompts from InstructGPT distribution": [[130, "a-2-1-illustrative-user-prompts-from-instructgpt-distribution"]], "A.2.2 Illustrative user prompts from GPT-3 distribution": [[130, "a-2-2-illustrative-user-prompts-from-gpt-3-distribution"]], "A.3 Dataset sizes": [[130, "a-3-dataset-sizes"]], "Appendix B Additional human data collection details": [[130, "appendix-b-additional-human-data-collection-details"]], "Appendix C Additional model details": [[130, "appendix-c-additional-model-details"]], "\u76d1\u7763\u5fae\u8c03SFT": [[130, "sft"]], "\u5956\u52b1\u6a21\u578b(RM)\u8bad\u7ec3": [[130, "rm"]], "RLHF(\u57fa\u4e8e\u4eba\u7c7b\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60)": [[130, "rlhf"]], "Appendix D Automatic evaluation details": [[130, "appendix-d-automatic-evaluation-details"]], "D.1 Toxicity and bias evaluation details": [[130, "d-1-toxicity-and-bias-evaluation-details"]], "D.2 Prompt structure and evaluation features for each eval dataset": [[130, "d-2-prompt-structure-and-evaluation-features-for-each-eval-dataset"]], "2305.20050_Let\u2019s Verify Step by Step": [[131, "lets-verify-step-by-step"]], "1. \u7814\u7a76\u80cc\u666f": [[131, "id2"]], "2. \u76d1\u7763\u65b9\u6cd5\u5bf9\u6bd4": [[131, "id3"]], "3. \u6838\u5fc3\u53d1\u73b0": [[131, "id4"]], "2408.03314_Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters": [[132, "scaling-llm-test-time-compute-optimally-can-be-more-effective-than-scaling-model-parameters"]], "1. \u7814\u7a76\u80cc\u666f\u4e0e\u6838\u5fc3\u95ee\u9898": [[132, "id2"]], "2. \u4e3b\u8981\u7814\u7a76\u65b9\u6cd5": [[132, "id3"]], "3. \u5173\u952e\u53d1\u73b0": [[132, "id4"]], "4. \u7814\u7a76\u7684\u610f\u4e49": [[132, "id5"]], "3. How to Scale Test-Time Computation Optimally": [[132, "how-to-scale-test-time-computation-optimally"]], "5. Scaling Test-Time Compute via Verifiers": [[132, "scaling-test-time-compute-via-verifiers"]], "6. Refining the Proposal Distribution": [[132, "refining-the-proposal-distribution"]], "2412.14135_Scaling of Search and Learning: A Roadmap to Reproduce o1 from Reinforcement Learning Perspective": [[133, "scaling-of-search-and-learning-a-roadmap-to-reproduce-o1-from-reinforcement-learning-perspective"]], "FromGPT": [[133, "fromgpt"]], "AI\u7684\u8303\u5f0f\u8f6c\u53d8": [[133, "ai"]], "Policy Initialization": [[133, "policy-initialization"]], "Reward Design": [[133, "reward-design"]], "Search": [[133, "search"]], "Learning": [[133, "learning"]], "\u4ee3\u7406(Agent)": [[133, "agent"]], "\u73af\u5883(Environment)": [[133, "environment"]], "3. Policy Initialization": [[133, "id2"]], "3.1 Pre-Training": [[133, "pre-training"]], "3.2 Instruction Fine-Tuning": [[133, "instruction-fine-tuning"]], "3.3 Human-like Reasoning Behaviours": [[133, "human-like-reasoning-behaviours"]], "3.4 Speculation About the Policy Initialization of o1": [[133, "speculation-about-the-policy-initialization-of-o1"]], "3.5 Challenges of Policy Initialization for Reproducing o1": [[133, "challenges-of-policy-initialization-for-reproducing-o1"]], "4. Reward Design": [[133, "id3"]], "4.1 Outcome Reward vs Process Reward": [[133, "outcome-reward-vs-process-reward"]], "4.2 Reward Design Methods": [[133, "reward-design-methods"]], "4.2.1 Reward from Environment": [[133, "reward-from-environment"]], "4.2.2 Reward Modeling from Data": [[133, "reward-modeling-from-data"]], "4.2.3 Reward Shaping": [[133, "reward-shaping"]], "4.3 Speculation About the Reward Design of o1": [[133, "speculation-about-the-reward-design-of-o1"]], "4.4 Challenges of Reward Design for Reproducing o1": [[133, "challenges-of-reward-design-for-reproducing-o1"]], "4.5 Generalization(\u6cdb\u5316\u80fd\u529b)": [[133, "generalization"]], "\u5956\u52b1\u7ec4\u5408(Reward Ensemble)": [[133, "reward-ensemble"]], "\u4e16\u754c\u6a21\u578b(World Model)": [[133, "world-model"]], "5. Search": [[133, "id5"]], "5.1 The role of Search in o1": [[133, "the-role-of-search-in-o1"]], "5.2 Search Guidance": [[133, "search-guidance"]], "5.2.1 Internal Guidance": [[133, "internal-guidance"]], "5.2.2 External Guidance": [[133, "external-guidance"]], "5.2.3 Comparison of Internal and External Guidance": [[133, "comparison-of-internal-and-external-guidance"]], "5.2.4 Combination of Internal and External Guidance": [[133, "combination-of-internal-and-external-guidance"]], "5.3 Search Strategies": [[133, "search-strategies"]], "5.3.1 Tree Search": [[133, "tree-search"]], "5.3.2 Sequential Revisions": [[133, "sequential-revisions"]], "5.3.3 Comparison of Tree Search and Sequential Revisions": [[133, "comparison-of-tree-search-and-sequential-revisions"]], "5.3.4 Combination of Tree Search and Sequential Revisions": [[133, "combination-of-tree-search-and-sequential-revisions"]], "5.4 Speculation About the Search of o1": [[133, "speculation-about-the-search-of-o1"]], "5.5 Scaling Law of Search": [[133, "scaling-law-of-search"]], "5.6 Challenges of Search for Reproducing o1": [[133, "challenges-of-search-for-reproducing-o1"]], "6. Learning": [[133, "id8"]], "6.1 Learning Methods": [[133, "learning-methods"]], "6.1.1 Policy Gradient": [[133, "policy-gradient"]], "6.1.2 Behavior Cloning": [[133, "behavior-cloning"]], "6.1.3 Speculation about the learning of o1": [[133, "speculation-about-the-learning-of-o1"]], "6.2 Scaling Law of Reinforcement Learning": [[133, "scaling-law-of-reinforcement-learning"]], "6.3 Challenges of Learning for Reproducing o1": [[133, "challenges-of-learning-for-reproducing-o1"]], "7 Open-source o1 Project": [[133, "open-source-o1-project"]], "8. Future Directions": [[133, "future-directions"]], "2005.08100_Conformer: Convolution-augmented Transformer for Speech Recognition": [[134, "conformer-convolution-augmented-transformer-for-speech-recognition"]], "\u4e3b\u8981\u8d21\u732e\u5305\u62ec\uff1a": [[134, "id1"]], "2 Conformer Encoder": [[134, "conformer-encoder"]], "1. Conformer Encoder \u7684\u6574\u4f53\u7ed3\u6784": [[134, "id4"]], "2. Conformer Block \u7684\u5173\u952e\u7ec4\u6210\u6a21\u5757": [[134, "conformer-block"]], "3. Conformer Block \u7684\u7ed3\u6784\u8bbe\u8ba1": [[134, "id5"]], "4. \u6a21\u5757\u7ec4\u5408\u4e0e\u5b9e\u9a8c\u9a8c\u8bc1": [[134, "id6"]], "3.1 \u6570\u636e\u96c6": [[134, "id8"]], "3.2 Conformer Transducer \u6a21\u578b": [[134, "conformer-transducer"]], "3.3 LibriSpeech \u5b9e\u9a8c\u7ed3\u679c": [[134, "librispeech"]], "3.4 \u6d88\u878d\u5b9e\u9a8c\uff08Ablation Studies\uff09": [[134, "ablation-studies"]], "3.4.1 Conformer Block vs. Transformer Block": [[134, "conformer-block-vs-transformer-block"]], "3.4.2 \u5377\u79ef\u4e0eTransformer\u6a21\u5757\u7684\u7ec4\u5408\u65b9\u5f0f": [[134, "transformer"]], "3.4.3 Macaron Feed-Forward \u6a21\u5757": [[134, "macaron-feed-forward"]], "3.4.4 \u6ce8\u610f\u529b\u5934\u7684\u6570\u91cf": [[134, "id9"]], "3.4.5 \u5377\u79ef\u6838\u5927\u5c0f": [[134, "id10"]], "4 Conclusion": [[134, "conclusion"]], "2106.07447_HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units": [[135, "hubert-self-supervised-speech-representation-learning-by-masked-prediction-of-hidden-units"]], "\u6982\u8ff0": [[135, "id2"], [239, "id2"]], "\u65b9\u6cd5\u7ec6\u8282": [[135, "id3"]], "I Introduction": [[135, "i-introduction"]], "\u5185\u5bb9\u603b\u7ed3\u5982\u4e0b\uff1a": [[135, "id6"]], "\u603b\u4f53\u89c2\u70b9\uff1a": [[135, "id7"]], "II Method": [[135, "ii-method"]], "II-A\uff1a\u5b66\u4e60\u9690\u72b6\u6001\uff08Hidden Units\uff09": [[135, "ii-a-hidden-units"]], "II-B\uff1a\u63a9\u7801\u9884\u6d4b\u8fdb\u884c\u8868\u793a\u5b66\u4e60": [[135, "ii-b"]], "II-C\uff1a\u4f7f\u7528\u805a\u7c7b\u96c6\u6210\uff08Cluster Ensembles\uff09": [[135, "ii-c-cluster-ensembles"]], "II-D\uff1a\u8fed\u4ee3\u4f18\u5316\u805a\u7c7b\u5206\u914d": [[135, "ii-d"]], "II-E\uff1a\u6a21\u578b\u5b9e\u73b0\u7ec6\u8282": [[135, "ii-e"]], "III Related Work": [[135, "iii-related-work"]], "IV Experimental Details": [[135, "iv-experimental-details"]], "\u65e0\u76d1\u7763\u5355\u5143\u53d1\u73b0": [[135, "id10"]], "\u9884\u8bad\u7ec3": [[135, "id11"]], "\u76d1\u7763\u5fae\u8c03\u4e0e\u89e3\u7801": [[135, "id12"]], "\u76ee\u6807\u8d28\u91cf\u8bc4\u4f30": [[135, "id13"]], "V Results": [[135, "v-results"]], "V-A \u4e3b\u8981\u7ed3\u679c\uff1a\u4f4e\u8d44\u6e90\u4e0e\u9ad8\u8d44\u6e90\u8bbe\u7f6e": [[135, "v-a"]], "V-B \u5206\u6790\uff1aK-Means\u805a\u7c7b\u7a33\u5b9a\u6027": [[135, "v-b-k-means"]], "V-C \u5206\u6790\uff1a\u4e0d\u540c\u5c42\u548c\u8fed\u4ee3\u7684\u805a\u7c7b\u8d28\u91cf": [[135, "v-c"]], "V-D \u6d88\u878d\u5b9e\u9a8c\uff1a\u9884\u6d4b\u63a9\u7801\u5e27\u7684\u91cd\u8981\u6027": [[135, "v-d"]], "V-E \u6d88\u878d\u5b9e\u9a8c\uff1a\u805a\u7c7b\u96c6\u6210\u7684\u5f71\u54cd": [[135, "v-e"]], "V-F \u6d88\u878d\u5b9e\u9a8c\uff1a\u8d85\u53c2\u6570\u5f71\u54cd": [[135, "v-f"]], "VI Conclusion": [[135, "vi-conclusion"]], "2112.02418_YourTTS: Towards Zero-Shot Multi-Speaker TTS and Zero-Shot Voice Conversion for everyone": [[136, "yourtts-towards-zero-shot-multi-speaker-tts-and-zero-shot-voice-conversion-for-everyone"]], "\u5173\u952e\u6982\u5ff5": [[136, "id1"]], "Phonemes\uff08\u97f3\u7d20\uff09": [[136, "phonemes"]], "Mel Spectrum(mel \u9891\u8c31)": [[136, "mel-spectrum-mel"]], "Fourier Transform(\u5085\u91cc\u53f6\u53d8\u6362)": [[136, "fourier-transform"]], "\u4e00\u3001\u80cc\u666f\u548c\u95ee\u9898": [[136, "id2"]], "\u4e8c\u3001\u5df2\u6709\u65b9\u6cd5\u53d1\u5c55": [[136, "id3"]], "\u4e09\u3001\u591a\u8bed\u8a00 TTS \u7684\u8d8b\u52bf": [[136, "tts"]], "\u56db\u3001\u672c\u6587 YourTTS \u7684\u8d21\u732e": [[136, "yourtts"]], "\u4e94\u3001\u5b9e\u9a8c\u8d44\u6e90": [[136, "id4"]], "2. YourTTS Model": [[136, "yourtts-model"]], "\u2705 \u4e3b\u8981\u521b\u65b0\u70b9\uff1a": [[136, "id6"]], "\ud83d\ude80 \u63a8\u7406\u8fc7\u7a0b\u6982\u62ec\uff1a": [[136, "id7"]], "3.1 Speaker Encoder": [[136, "speaker-encoder"]], "3.2 Audio datasets": [[136, "audio-datasets"]], "3.3 Experimental setup": [[136, "experimental-setup"]], "4. Results and Discussion": [[136, "results-and-discussion"]], "\u8bc4\u4f30\u65b9\u6cd5\uff1a": [[136, "id8"]], "1. VCTK \u6570\u636e\u96c6\uff1a": [[136, "vctk"]], "2. LibriTTS \u6570\u636e\u96c6\uff1a": [[136, "libritts"]], "3. \u8461\u8404\u7259\u8bed MLS \u6570\u636e\u96c6\uff1a": [[136, "mls"]], "4. SCL \u7684\u5f71\u54cd\uff1a": [[136, "scl"]], "5. Zero-Shot Voice Conversion": [[136, "zero-shot-voice-conversion"]], "\ud83e\udde0 \u6a21\u578b\u8bbe\u8ba1\u4eae\u70b9\uff1a": [[136, "id12"]], "\ud83d\udcca \u5b9e\u9a8c\u7ed3\u679c\uff1a": [[136, "id14"]], "\u2705 \u82f1\u8bed \u2192 \u82f1\u8bed\uff1a": [[136, "id15"]], "\u2705 \u8461\u8bed \u2192 \u8461\u8bed\uff1a": [[136, "id16"]], "\ud83d\udd04 \u82f1\u8bed \u2194 \u8461\u8bed\uff08\u8de8\u8bed\u8a00\uff09\uff1a": [[136, "id17"]], "\ud83d\udccc \u7ed3\u8bba\uff1a": [[136, "id18"]], "6. Speaker Adaptation": [[136, "speaker-adaptation"]], "7. Conclusions, limitations and future work": [[136, "conclusions-limitations-and-future-work"]], "2212.04356_whisper: Robust Speech Recognition via Large-Scale Weak Supervision": [[137, "whisper-robust-speech-recognition-via-large-scale-weak-supervision"]], "2. Approach": [[137, "approach"], [168, "approach"], [169, "approach"]], "3.1 Zero-shot Evaluation": [[137, "zero-shot-evaluation"]], "3.2 Evaluation Metrics": [[137, "evaluation-metrics"]], "3.3 English Speech Recognition": [[137, "english-speech-recognition"]], "3.4 Multilingual Speech Recognition": [[137, "multilingual-speech-recognition"]], "3.5 Translation": [[137, "translation"]], "3.6 Language Identification": [[137, "language-identification"]], "3.7 Robustness to Additive Noise": [[137, "robustness-to-additive-noise"]], "3.8 Long-form Transcription": [[137, "long-form-transcription"]], "3.9 Comparison with Human Performance": [[137, "comparison-with-human-performance"]], "4. Analysis and Ablations": [[137, "analysis-and-ablations"]], "4.1 Model Scaling": [[137, "model-scaling"]], "4.2 Dataset Scaling": [[137, "dataset-scaling"]], "4.3 Multitask and Multilingual Transfer": [[137, "multitask-and-multilingual-transfer"]], "4.4 Text Normalization": [[137, "text-normalization"]], "4.5 Strategies for Reliable Long-form Transcription": [[137, "strategies-for-reliable-long-form-transcription"]], "Scaling Speech Recognition": [[137, "scaling-speech-recognition"]], "Multitask Learning": [[137, "multitask-learning"]], "Robustness": [[137, "robustness"]], "6. Limitations and Future Work": [[137, "limitations-and-future-work"]], "7. Conclusions": [[137, "conclusions"]], "A. Evaluation Datasets": [[137, "a-evaluation-datasets"]], "A.1 Short-form English-only datasets": [[137, "a-1-short-form-english-only-datasets"]], "A.2 Long-form English-only datasets": [[137, "a-2-long-form-english-only-datasets"]], "A.3 Multilingual datasets": [[137, "a-3-multilingual-datasets"]], "B Compared Models": [[137, "b-compared-models"]], "C. Text Standardization": [[137, "c-text-standardization"]], "2301.02111_Vall-E: Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers": [[138, "vall-e-neural-codec-language-models-are-zero-shot-text-to-speech-synthesizers"]], "\ud83d\udde3 \u80cc\u666f": [[138, "id1"]], "\ud83c\udf1f \u521b\u65b0\u70b9\uff1aVALL-E": [[138, "vall-e"]], "\ud83d\udd27 \u505a\u6cd5": [[138, "id2"]], "\u2705 \u6548\u679c": [[138, "id3"], [143, "id2"]], "\ud83d\udccc \u4e3b\u8981\u8d21\u732e\u603b\u7ed3": [[138, "id4"]], "\u4e00\u3001Zero-Shot TTS\uff08\u96f6\u6837\u672c\u8bed\u97f3\u5408\u6210\uff09": [[138, "zero-shot-tts"]], "\u4e8c\u3001Spoken Generative Pre-trained Models\uff08\u8bed\u97f3\u751f\u6210\u9884\u8bad\u7ec3\u6a21\u578b\uff09": [[138, "spoken-generative-pre-trained-models"]], "3. Background: Speech Quantization": [[138, "background-speech-quantization"]], "\ud83e\udde0 \u80cc\u666f\u95ee\u9898": [[138, "id5"]], "\ud83d\udd27 \u89e3\u51b3\u65b9\u6848\uff1a\u8bed\u97f3\u91cf\u5316": [[138, "id6"]], "\ud83e\uddf0 \u672c\u6587\u505a\u6cd5": [[138, "id7"]], "\ud83d\udce6 \u5177\u4f53\u4f7f\u7528\u7684\u6a21\u578b\uff1aEnCodec": [[138, "encodec"]], "\ud83d\udcc8 \u603b\u7ed3": [[138, "id8"]], "4. VALL-E": [[138, "id9"]], "4.1 Problem Formulation: Regarding TTS as Conditional Codec Language Modeling": [[138, "problem-formulation-regarding-tts-as-conditional-codec-language-modeling"]], "4.2 Training: Conditional Codec Language Modeling": [[138, "training-conditional-codec-language-modeling"]], "4.2.1 Autoregressive(AR) Codec Language Modeling": [[138, "autoregressive-ar-codec-language-modeling"]], "4.2.2 Non-Autoregressive Codec Language Modeling": [[138, "non-autoregressive-codec-language-modeling"]], "4.3 Inference: In-Context Learning via Prompting": [[138, "inference-in-context-learning-via-prompting"]], "5.1 Experiment Setup": [[138, "experiment-setup"]], "5.2 LibriSpeech Evaluation": [[138, "librispeech-evaluation"]], "5.3 VCTK Evaluation": [[138, "vctk-evaluation"]], "6. Conclusion, Limitations, and Future Work": [[138, "conclusion-limitations-and-future-work"]], "2303.03926_VALL-E_X: Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural Codec Language Modeling": [[139, "vall-e-x-speak-foreign-languages-with-your-own-voice-cross-lingual-neural-codec-language-modeling"]], "\ud83c\udf0d \u95ee\u9898\u80cc\u666f": [[139, "id1"]], "\ud83e\udde0 \u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3": [[139, "id2"]], "\ud83d\ude80 VALL-E X \u7684\u521b\u65b0\u70b9": [[139, "vall-e-x"]], "\ud83d\udd27 \u6280\u672f\u65b9\u6cd5": [[139, "id3"]], "\ud83d\udcca \u5b9e\u9a8c\u6548\u679c": [[139, "id4"]], "\ud83c\udfa7 \u5e94\u7528\u573a\u666f": [[139, "id5"]], "Speech/Audio Synthesis(\u8bed\u97f3/\u97f3\u9891\u5408\u6210)": [[139, "speech-audio-synthesis"]], "Cross-Lingual TTS": [[139, "cross-lingual-tts"]], "Speech to Speech Translation (S2ST)": [[139, "speech-to-speech-translation-s2st"]], "3 Cross-Lingual Codec Language Model": [[139, "cross-lingual-codec-language-model"]], "3.1 Background": [[139, "background"]], "3.2 Model Framework": [[139, "model-framework"]], "3.3 Multi-lingual Training": [[139, "multi-lingual-training"]], "3.4 Cross-Lingual Inference": [[139, "cross-lingual-inference"]], "4. VALL-E X Application": [[139, "vall-e-x-application"]], "1. \u96f6\u6837\u672c\u8de8\u8bed\u8a00\u8bed\u97f3\u5408\u6210\uff08Zero-Shot Cross-Lingual TTS\uff09": [[139, "zero-shot-cross-lingual-tts"]], "2. \u96f6\u6837\u672c\u8bed\u97f3\u7ffb\u8bd1\uff08Zero-Shot Speech-to-Speech Translation\uff09": [[139, "zero-shot-speech-to-speech-translation"]], "3. \u6548\u679c\u8bc4\u4f30": [[139, "id6"]], "5.1 Dataset": [[139, "dataset"]], "5.2 Experimental Setup": [[139, "experimental-setup"]], "5.3 Zero-Shot Cross-Lingual TTS Evaluation": [[139, "zero-shot-cross-lingual-tts-evaluation"]], "5.4 Zero-Shot S2ST Evaluation": [[139, "zero-shot-s2st-evaluation"]], "\ud83d\udde3\ufe0f \u8bf4\u8bdd\u4eba\u76f8\u4f3c\u5ea6\uff08Speaker Similarity\uff09": [[139, "speaker-similarity"]], "\ud83c\udf10 \u7ffb\u8bd1\u8d28\u91cf\uff08Translation Quality\uff09": [[139, "translation-quality"]], "\ud83d\udd09 \u8bed\u97f3\u81ea\u7136\u5ea6\uff08Speech Naturalness\uff09": [[139, "speech-naturalness"]], "\ud83d\udc42 \u4eba\u5de5\u8bc4\u4f30\uff08Human Evaluation\uff09": [[139, "human-evaluation"]], "5.5 Analysis": [[139, "analysis"]], "\ud83c\udff7\ufe0f \u8bed\u8a00\u6807\u7b7e\uff08Language ID\uff09\u7684\u5f71\u54cd": [[139, "language-id"]], "\ud83d\udde3\ufe0f \u63a7\u5236\u5916\u8bed\u53e3\u97f3": [[139, "id7"]], "\ud83d\ude22 \u4fdd\u7559\u60c5\u611f\uff08Voice Emotion Maintenance\uff09": [[139, "voice-emotion-maintenance"]], "\ud83d\udd01 \u4e2d\u82f1\u6df7\u5408\u8bed\u97f3\u5408\u6210\uff08Code-Switch Speech Synthesis\uff09": [[139, "code-switch-speech-synthesis"]], "A. Appendix": [[139, "a-appendix"]], "A.1.1 \u6a21\u578b\u9884\u8bad\u7ec3": [[139, "a-1-1"]], "A.1.2 \u6a21\u578b\u67b6\u6784": [[139, "a-1-2"]], "A.1.3 \u8bad\u7ec3\u7ec6\u8282": [[139, "a-1-3"]], "2406.05370_VALL-E2: Neural Codec Language Models are Human Parity Zero-Shot Text to Speech Synthesizers": [[140, "vall-e2-neural-codec-language-models-are-human-parity-zero-shot-text-to-speech-synthesizers"]], "\u80cc\u666f\u4ecb\u7ecd": [[140, "id1"]], "VALL-E\uff082023\uff09": [[140, "vall-e-2023"]], "\u540e\u7eed\u7814\u7a76": [[140, "id2"]], "VALL-E 2 \u7684\u521b\u65b0": [[140, "vall-e-2"]], "\u6027\u80fd\u8868\u73b0": [[140, "id3"]], "\u5e94\u7528\u4e0e\u98ce\u9669": [[140, "id4"]], "2.1 Zero-Shot TTS": [[140, "zero-shot-tts"]], "2.2 Codec-based Speech Models": [[140, "codec-based-speech-models"]], "3. VALL-E 2": [[140, "id5"]], "3.1 Problem Formulation: Grouped Codec Language Modeling": [[140, "problem-formulation-grouped-codec-language-modeling"]], "3.2 VALL-E 2 Architecture": [[140, "vall-e-2-architecture"]], "3.3 VALL-E 2 Training": [[140, "vall-e-2-training"]], "3.3.1 Autoregressive Model Training": [[140, "autoregressive-model-training"]], "3.3.2 Non-Autoregressive Model Training": [[140, "non-autoregressive-model-training"]], "3.4 VALL-E 2 Inference": [[140, "vall-e-2-inference"]], "3.4.1 Autoregressive Model Inference": [[140, "autoregressive-model-inference"]], "3.4.2 Non-Autoregressive Model Inference": [[140, "non-autoregressive-model-inference"]], "4.1 Setups": [[140, "setups"]], "4.1.1 Model Training": [[140, "model-training"]], "4.1.2 Evaluation Metrics": [[140, "evaluation-metrics"]], "4.1.3 Evaluation Settings": [[140, "evaluation-settings"]], "4.2 LibriSpeech Evaluation": [[140, "librispeech-evaluation"]], "4.2.1 Objective Evaluation": [[140, "objective-evaluation"]], "4.2.2 Subjective Evaluation": [[140, "subjective-evaluation"]], "4.2.3 Ablation Study": [[140, "ablation-study"]], "4.3 VCTK Evaluation": [[140, "vctk-evaluation"]], "4.3.1 Objective Evaluation": [[140, "id6"]], "4.3.2 Subjective Evaluation": [[140, "id7"]], "4.3.3 Ablation Study": [[140, "id8"]], "2407.05407_CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens": [[141, "cosyvoice-a-scalable-multilingual-zero-shot-text-to-speech-synthesizer-based-on-supervised-semantic-tokens"]], "2. CosyVoice: A Scalable TTS model using Supervised Semantic Tokens": [[141, "cosyvoice-a-scalable-tts-model-using-supervised-semantic-tokens"]], "2.1 Supervised Semantic Tokens for Speech": [[141, "supervised-semantic-tokens-for-speech"]], "2.2 Large Language Model for TTS": [[141, "large-language-model-for-tts"]], "2.3 Optimal-transport Conditional Flow Matching": [[141, "optimal-transport-conditional-flow-matching"]], "2.3.1 Zero-shot In-context Learning": [[141, "zero-shot-in-context-learning"]], "2.4 Rich Generation with Instruction": [[141, "rich-generation-with-instruction"]], "3. Dataset": [[141, "dataset"]], "4. Experimental Settings": [[141, "experimental-settings"]], "4.1 Supervised Semantic Speech Tokenizer": [[141, "supervised-semantic-speech-tokenizer"]], "4.2 CosyVoice Model Settings": [[141, "cosyvoice-model-settings"]], "2407.10759_Qwen2-Audio Technical Report": [[142, "qwen2-audio-technical-report"]], "Model Architecture": [[142, "model-architecture"]], "Pre-training": [[142, "pre-training"]], "3. \u6307\u4ee4\u5fae\u8c03\uff08SFT\uff09": [[142, "sft"]], "4. DPO \u4f18\u5316": [[142, "dpo"]], "1. \u8bc4\u4f30\u65b9\u6cd5\uff1a": [[142, "id1"]], "2. \u4e3b\u8981\u7ed3\u679c\uff1a": [[142, "id2"]], "2410.00037_Moshi: a speech-text foundation model for real-time dialogue": [[143, "moshi-a-speech-text-foundation-model-for-real-time-dialogue"]], "\u2705 \u80cc\u666f\u95ee\u9898": [[143, "id1"]], "\u2705 Moshi\u7684\u521b\u65b0\u70b9": [[143, "moshi"]], "\u4e00\u3001\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\uff08Audio Language Modeling\uff09": [[143, "audio-language-modeling"]], "\u4e8c\u3001\u8bed\u97f3-\u6587\u672c\u8054\u5408\u6a21\u578b\uff08Speech-text Models\uff09": [[143, "speech-text-models"]], "\u4e09\u3001\u8bed\u97f3\u5bf9\u8bdd\u6a21\u578b\uff08Spoken Dialogue Models\uff09": [[143, "spoken-dialogue-models"]], "\ud83d\udccc\u8bed\u97f3\u5bf9\u8bdd\u7684\u6311\u6218\uff1a": [[143, "id3"]], "\ud83d\udccc\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\uff1a": [[143, "id4"]], "\u2705Moshi\u7684\u4f18\u52bf\uff1a": [[143, "id5"]], "3.Model": [[143, "model"]], "3.1 Overview": [[143, "overview"], [225, "overview"]], "\ud83d\udd27 \u67b6\u6784\u4e3b\u8981\u5305\u62ec 5 \u4e2a\u6838\u5fc3\u6a21\u5757\uff1a": [[143, "id6"]], "3.2 The Helium Text Language Model": [[143, "the-helium-text-language-model"]], "3.2.1 Architecture": [[143, "architecture"]], "3.2.2 Pre-training data filtering": [[143, "pre-training-data-filtering"]], "3.3 Audio Tokenization": [[143, "audio-tokenization"]], "3.3.1 Architecture": [[143, "id7"]], "Transformer-based bottleneck.": [[143, "transformer-based-bottleneck"]], "Causality and streaming.": [[143, "causality-and-streaming"]], "Optimization.": [[143, "optimization"]], "Quantization rate.": [[143, "quantization-rate"]], "Adversarial-only training.": [[143, "adversarial-only-training"]], "3.3.2 Learning semantic-acoustic tokens with a split RVQ": [[143, "learning-semantic-acoustic-tokens-with-a-split-rvq"]], "3.4 Generative Audio Modeling": [[143, "generative-audio-modeling"]], "3.4.1 Hierarchical autoregressive modeling with RQ-Transformer": [[143, "hierarchical-autoregressive-modeling-with-rq-transformer"]], "\ud83d\udd27 \u95ee\u9898\u80cc\u666f\uff1a": [[143, "id8"]], "\ud83e\udde0 \u76ee\u6807\uff1a": [[143, "id9"]], "\ud83c\udf32 \u89e3\u51b3\u65b9\u6848\uff1aRQ-Transformer\uff08\u5206\u5c42\u81ea\u56de\u5f52\u5efa\u6a21\uff09": [[143, "rq-transformer"]], "\ud83e\uddf1 \u5b9a\u4e49\uff1a": [[143, "id10"]], "\ud83e\udde0 Temporal Transformer \u7684\u5de5\u4f5c\u65b9\u5f0f": [[143, "temporal-transformer"]], "\ud83e\uddf1 Depth Transformer \u7684\u5de5\u4f5c\u65b9\u5f0f": [[143, "depth-transformer"]], "\u6574\u5408": [[143, "id11"]], "\u2699\ufe0f \u6a21\u578b\u6548\u7387\u8bbe\u8ba1": [[143, "id12"]], "3.4.2 Audio modeling": [[143, "audio-modeling"]], "\ud83c\udfaf \u76ee\u6807\uff1a": [[143, "id13"]], "\ud83e\udde0 \u505a\u6cd5\uff1a": [[143, "id14"]], "\ud83d\udd01 Acoustic Delay\uff08\u58f0\u5b66\u5ef6\u8fdf\uff09\uff1a": [[143, "acoustic-delay"]], "\ud83d\ude80 \u521b\u65b0\u70b9\uff1a": [[143, "id15"]], "3.4.3 Multi-stream modeling": [[143, "multi-stream-modeling"]], "3.4.4 Inner Monologue(\u5185\u5fc3\u72ec\u767d)": [[143, "inner-monologue"]], "Aligning text and audio tokens.": [[143, "aligning-text-and-audio-tokens"]], "Deriving streaming ASR and TTS.": [[143, "deriving-streaming-asr-and-tts"]], "Joint sequence modeling for Moshi.": [[143, "joint-sequence-modeling-for-moshi"]], "Inference of Moshi.": [[143, "inference-of-moshi"]], "\ud83c\udfaf \u603b\u7ed3\u4e00\u53e5\u8bdd\uff1a": [[143, "id16"]], "4. Datasets and Training": [[143, "datasets-and-training"]], "4.1 Text Data": [[143, "text-data"]], "4.2 Audio Data": [[143, "audio-data"]], "4.3 Speech-Text Instruct Data": [[143, "speech-text-instruct-data"]], "4.4 Training Stages and Hyper-parameters": [[143, "training-stages-and-hyper-parameters"]], "Helium pre-training.": [[143, "helium-pre-training"]], "Moshi pre-training.": [[143, "moshi-pre-training"]], "Moshi post-training.": [[143, "moshi-post-training"]], "Moshi finetuning.": [[143, "moshi-finetuning"]], "TTS Training.": [[143, "tts-training"]], "Training loss.": [[143, "training-loss"]], "5.1 Text Language Modeling": [[143, "text-language-modeling"]], "5.2 Audio Tokenization": [[143, "id17"]], "\u4e00\u3001\u8bc4\u4f30\u65b9\u5f0f": [[143, "id18"]], "\u4e8c\u3001\u5bf9\u6bd4\u65b9\u6cd5\u548c\u6a21\u578b": [[143, "id19"]], "\u4e09\u3001\u4e3b\u8981\u7ed3\u679c": [[143, "id20"]], "\u56db\u3001\u8ba8\u8bba\u603b\u7ed3": [[143, "id21"]], "5.3 Ablations on Generative Modeling": [[143, "ablations-on-generative-modeling"]], "\u5b9e\u9a8c\u76ee\u7684\uff1a": [[143, "id22"]], "\u5ea6\u91cf\u65b9\u5f0f\uff1a": [[143, "id23"]], "5.4 Audio Language Modeling": [[143, "id25"]], "\ud83d\udcca 1. \u8bc4\u4f30\u6307\u6807\uff08Metrics\uff09": [[143, "metrics"]], "\u2696\ufe0f 2. \u5bf9\u6bd4\u6a21\u578b\uff08Baselines\uff09": [[143, "baselines"]], "\ud83c\udfc6 3. \u7ed3\u679c\uff08Results\uff09": [[143, "results"]], "\ud83d\udcac 4. \u8ba8\u8bba\uff08Discussion\uff09": [[143, "discussion"]], "5.5 Spoken Question Answering": [[143, "spoken-question-answering"]], "\ud83c\udf1f \u8bc4\u4f30\u65b9\u6cd5\uff1a": [[143, "id26"]], "\ud83c\udd9a \u5bf9\u6bd4\u6a21\u578b\uff1a": [[143, "id27"]], "\ud83d\udcc8 \u7ed3\u679c\u603b\u7ed3\uff1a": [[143, "id28"]], "\ud83e\udde0 \u8ba8\u8bba\uff1a": [[143, "id29"]], "5.6 Quality and Statistics of Generated Dialogues": [[143, "quality-and-statistics-of-generated-dialogues"]], "5.7 Streaming ASR and TTS": [[143, "streaming-asr-and-tts"]], "\ud83d\udccc \u65b9\u6cd5\u6982\u8ff0\uff1a": [[143, "id30"]], "\u2705 \u5b9e\u9a8c\u7ed3\u679c\uff1a": [[143, "id32"]], "\ud83d\udca1 \u8bf4\u660e\uff1a": [[143, "id33"]], "5.8 Compressing Moshi and Impact on Speech Quality": [[143, "compressing-moshi-and-impact-on-speech-quality"]], "\ud83c\udf1f \u80cc\u666f": [[143, "id34"]], "\ud83e\udde0 \u8bed\u8a00\u80fd\u529b\u65b9\u9762\uff08MMLU \u6d4b\u8bd5\uff09\uff1a": [[143, "mmlu"]], "\ud83d\udd0a \u97f3\u9891\u8d28\u91cf\u65b9\u9762\uff08MOSNet\u6307\u6807 + \u71b5\u8c31\u5206\u6790\uff09\uff1a": [[143, "mosnet"]], "\u2705 \u603b\u7ed3\u5efa\u8bae\uff1a": [[143, "id35"]], "6.Safety": [[143, "safety"]], "6.1 Toxicity Analysis": [[143, "toxicity-analysis"]], "6.2 Regurgitation Analysis": [[143, "regurgitation-analysis"]], "6.3 System Voice Consistency": [[143, "system-voice-consistency"]], "6.4 Identification of the Content Generated by Moshi: Watermarking": [[143, "identification-of-the-content-generated-by-moshi-watermarking"]], "Evaluation of signal-based watermarking.": [[143, "evaluation-of-signal-based-watermarking"]], "Exploration on generative-based watermarking for audio.": [[143, "exploration-on-generative-based-watermarking-for-audio"]], "Discussion on generative audio watermarking.": [[143, "discussion-on-generative-audio-watermarking"]], "2412.10117_CosyVoice2: Scalable Streaming Speech Synthesis with Large Language Models": [[144, "cosyvoice2-scalable-streaming-speech-synthesis-with-large-language-models"]], "1. Instroduction": [[144, "instroduction"]], "\ud83d\udccc \u80cc\u666f\u6982\u8ff0": [[144, "id1"]], "\ud83d\udd27 \u4e3b\u6d41\u65b9\u6cd5": [[144, "id2"]], "\ud83d\udeab \u5f53\u524d\u95ee\u9898": [[144, "id3"]], "\u2705 CosyVoice 2 \u7684\u521b\u65b0\u70b9": [[144, "cosyvoice-2"]], "\u2b50 \u6548\u679c": [[144, "id4"]], "2. CosyVoice 2": [[144, "id5"]], "2.1 Text Tokenizer": [[144, "text-tokenizer"]], "2.2 Supervised Semantic Speech Tokenizer": [[144, "supervised-semantic-speech-tokenizer"]], "2.3 Unified Text-Speech Language Model": [[144, "unified-text-speech-language-model"]], "2.4 Chunk-aware Flow Matching": [[144, "chunk-aware-flow-matching"]], "\ud83d\udd27 \u6838\u5fc3\u6d41\u7a0b\uff1a": [[144, "id6"]], "\ud83d\udce6 \u6d41\u5f0f\u751f\u6210\u652f\u6301\uff08\u91cd\u70b9\uff09\uff1a": [[144, "id7"]], "2.5 Latency Analysis for Streaming Mode": [[144, "latency-analysis-for-streaming-mode"]], "2.6 Instructed Generation": [[144, "instructed-generation"]], "2.7 Multi-Speaker Fine-tuning": [[144, "multi-speaker-fine-tuning"]], "2.8 Reinforcement Learning for SFT": [[144, "reinforcement-learning-for-sft"]], "3. Experimental Settings": [[144, "experimental-settings"]], "3.1 Training Data for Speech Tokenizer": [[144, "training-data-for-speech-tokenizer"]], "3.2 Training Data for CosyVoice 2": [[144, "training-data-for-cosyvoice-2"]], "3.3 Evaluation Settings": [[144, "evaluation-settings"]], "3.4 \u65e5\u8bed\u4e0e\u97e9\u8bed\u6d4b\u8bd5\u57fa\u51c6": [[144, "id9"]], "4. Experimental Results": [[144, "experimental-results"]], "4.1 Evaluations on Speech Tokenizer": [[144, "evaluations-on-speech-tokenizer"]], "4.2 Comparison Results with Baselines": [[144, "comparison-results-with-baselines"]], "4.3 Modular Ablation Study": [[144, "modular-ablation-study"]], "4.4 Results on Japanese and Korean Benchmarks": [[144, "results-on-japanese-and-korean-benchmarks"]], "4.5 Results on Instructed Generation": [[144, "results-on-instructed-generation"]], "4.6 Results on Speaker Fine-tuned Models": [[144, "results-on-speaker-fine-tuned-models"]], "4.7 LM Fine-tuning with Reinforcement Learning": [[144, "lm-fine-tuning-with-reinforcement-learning"]], "2501.06282_MinMo: A Multimodal Large Language Model for Seamless Voice Interaction": [[145, "minmo-a-multimodal-large-language-model-for-seamless-voice-interaction"]], "1.Instruction": [[145, "instruction"]], "\ud83d\udccc MinMo \u662f\u4ec0\u4e48\uff1f": [[145, "minmo"]], "\ud83d\udd0d MinMo \u6709\u4ec0\u4e48\u80fd\u529b\uff1f": [[145, "id1"]], "\u5f53\u524d\u8bed\u97f3\u4ea4\u4e92\u7684\u4e24\u7c7b\u5927\u6a21\u578b": [[145, "id2"]], "\u7b2c\u4e00\u7c7b\uff1a\u539f\u751f\u591a\u6a21\u6001\u6a21\u578b\uff08\u5982 Moshi\u3001GLM-4-Voice\uff09": [[145, "moshiglm-4-voice"]], "\u7b2c\u4e8c\u7c7b\uff1a\u5bf9\u9f50\u591a\u6a21\u6001\u6a21\u578b\uff08\u5982 LLaMA-Omni\u3001Freeze-Omni\uff09": [[145, "llama-omnifreeze-omni"]], "\u65b0\u6a21\u578b MinMo \u7684\u8bed\u97f3\u89e3\u7801\u5668\u8bbe\u8ba1\uff1a": [[145, "id3"]], "\ud83d\udd04 \u4e3a\u4ec0\u4e48 MinMo \u5f88\u7279\u522b\uff1f": [[145, "id4"]], "\u2705 \u89e3\u51b3\u4e86\u73b0\u6709\u6a21\u578b\u7684\u4e09\u5927\u75db\u70b9\uff1a": [[145, "id5"]], "\u2705 MinMo \u7684\u89e3\u51b3\u65b9\u6848\uff1a": [[145, "id6"]], "\ud83d\udcca \u4e0e\u5176\u4ed6\u6a21\u578b\u7684\u6bd4\u8f83": [[145, "id7"]], "\ud83d\udcce \u603b\u7ed3\u4e09\u70b9\u8d21\u732e\uff1a": [[145, "id8"]], "Multimodal Spoken Dialogue Models": [[145, "multimodal-spoken-dialogue-models"]], "Text Style-Controllable Speech Synthesis": [[145, "text-style-controllable-speech-synthesis"]], "3.MinMo": [[145, "id9"]], "3.1 Model Architecture": [[145, "model-architecture"]], "\ud83e\udde0 \u6a21\u578b\u7ed3\u6784\u7b80\u4ecb": [[145, "id10"]], "\ud83d\udd01 \u751f\u6210\u8fc7\u7a0b": [[145, "id11"]], "3.2 Streaming Voice Decoder": [[145, "streaming-voice-decoder"]], "\ud83d\udccc \u5ef6\u8fdf\u8ba1\u7b97\u516c\u5f0f\uff08Latency Formula\uff09": [[145, "latency-formula"]], "3.3 Tasks and Training Data": [[145, "tasks-and-training-data"]], "\ud83d\udde3\ufe0f \u4e00\u3001\u8bed\u97f3\u8f6c\u6587\u672c\uff08Speech-to-Text\uff09": [[145, "speech-to-text"]], "\ud83d\udd0a \u4e8c\u3001\u6587\u672c\u8f6c\u8bed\u97f3\uff08Text-to-Speech\uff09": [[145, "text-to-speech"]], "\ud83d\udd04 \u4e09\u3001\u8bed\u97f3\u5bf9\u8bdd\uff08Speech-to-Speech\uff09": [[145, "speech-to-speech"]], "\ud83c\udf9b\ufe0f \u56db\u3001\u8bed\u97f3\u63a7\u5236\u6307\u4ee4\uff08Speech-to-ControlToken\uff09": [[145, "speech-to-controltoken"]], "3.4 Model Training": [[145, "model-training"]], "\ud83e\udde9 \u9636\u6bb5\u4e00\uff1a\u8bed\u97f3\u5bf9\u6587\u672c\u5bf9\u9f50\uff08Speech-to-Text Alignment\uff09": [[145, "speech-to-text-alignment"]], "\ud83d\udd0a \u9636\u6bb5\u4e8c\uff1a\u6587\u672c\u5bf9\u8bed\u97f3\u5bf9\u9f50\uff08Text-to-Speech Alignment\uff09": [[145, "text-to-speech-alignment"]], "\ud83d\udd01 \u9636\u6bb5\u4e09\uff1a\u8bed\u97f3\u5bf9\u8bed\u97f3\u5bf9\u9f50\uff08Speech-to-Speech Alignment\uff09": [[145, "speech-to-speech-alignment"]], "\ud83d\udd01 \u9636\u6bb5\u56db\uff1a\u5168\u53cc\u5de5\u4ea4\u4e92\u5bf9\u9f50\uff08Duplex Interaction Alignment\uff09": [[145, "duplex-interaction-alignment"]], "\u2705 \u6700\u7ec8\u6548\u679c": [[145, "id12"]], "4.1 Speech Recognition and Translation": [[145, "speech-recognition-and-translation"]], "4.2 Speech Analysis and Understanding": [[145, "speech-analysis-and-understanding"]], "4.3 Speech-to-Text Enhancement": [[145, "speech-to-text-enhancement"]], "4.4 Voice Generation": [[145, "voice-generation"]], "4.5 Voice Chat": [[145, "voice-chat"]], "\u4e00\u3001\u8bed\u97f3\u95ee\u7b54\u548c\u8bed\u97f3\u5bf9\u8bdd\u8bad\u7ec3\u65b9\u5f0f": [[145, "id13"]], "\u4e8c\u3001\u8bed\u97f3\u95ee\u7b54\u80fd\u529b\u8bc4\u4f30": [[145, "id14"]], "\u4e09\u3001\u591a\u8f6e\u8bed\u97f3\u4ea4\u4e92\u80fd\u529b\u8bc4\u4f30": [[145, "id15"]], "\u56db\u3001\u5168\u53cc\u5de5\u8bed\u97f3\u5bf9\u8bdd\uff08\u53cc\u65b9\u53ef\u540c\u65f6\u8bf4\u8bdd\uff09": [[145, "id16"]], "\u4e94\u3001\u54cd\u5e94\u901f\u5ea6\u548c\u5ef6\u8fdf\u5206\u6790": [[145, "id17"]], "5.Conclusion": [[145, "conclusion"]], "A. Prompts for Voice Understanding Tasks": [[145, "a-prompts-for-voice-understanding-tasks"]], "A.1 Spoken Language Smoothing": [[145, "a-1-spoken-language-smoothing"]], "A.2 Punctuation and Inverse Text Normalization": [[145, "a-2-punctuation-and-inverse-text-normalization"]], "2505.02707_Voila: Voice-Language Foundation Models for Real-Time Autonomous Interaction and Voice Role-Play": [[146, "voila-voice-language-foundation-models-for-real-time-autonomous-interaction-and-voice-role-play"]], "\u6838\u5fc3\u95ee\u9898\uff1a\u73b0\u6709 AI \u7cfb\u7edf\u7684\u4ea4\u4e92\u65b9\u5f0f\u592a\u201c\u88ab\u52a8\u201d": [[146, "ai"]], "\u8bed\u97f3\u662f\u5b9e\u73b0\u81ea\u7136\u4ea4\u4e92\u7684\u5173\u952e\u65b9\u5f0f": [[146, "id1"]], "\u4ece\u4f20\u7edf\u8bed\u97f3\u52a9\u624b\u5230\u7aef\u5230\u7aef\u8bed\u97f3\u5927\u6a21\u578b": [[146, "id2"]], "\u89e3\u51b3\u65b9\u6848\uff1aVoila \u6a21\u578b\u5bb6\u65cf": [[146, "voila"]], "Voila \u7684\u6280\u672f\u4eae\u70b9": [[146, "id3"]], "1. \u4f20\u7edf\u6d41\u6c34\u7ebf\u7cfb\u7edf\uff08Pipeline Systems\uff09": [[146, "pipeline-systems"]], "2. \u7aef\u5230\u7aef\u6a21\u578b\uff08End-to-end Models\uff09": [[146, "end-to-end-models"]], "3. \u5168\u53cc\u5de5\u6a21\u578b\uff08Full-duplex Models\uff09": [[146, "full-duplex-models"]], "3. Voila: Voice-Language Foundation Models": [[146, "voila-voice-language-foundation-models"]], "3.1 Voice Tokenizer": [[146, "voice-tokenizer"]], "3.2 Text and Audio Alignment": [[146, "text-and-audio-alignment"]], "Multi-task alignment": [[146, "multi-task-alignment"]], "Text-audio interleaved alignment.": [[146, "text-audio-interleaved-alignment"]], "3.3 One Million Pre-built Voices and Customizing New Voices": [[146, "one-million-pre-built-voices-and-customizing-new-voices"]], "4.1 Voila Benchmark": [[146, "voila-benchmark"]], "4.2 Evaluation on Voila Benchmark": [[146, "evaluation-on-voila-benchmark"]], "4.3 Evaluation on ASR and TTS": [[146, "evaluation-on-asr-and-tts"]], "2505.17589_CosyVoice3: Towards In-the-wild Speech Generation via Scaling-up and Post-training": [[147, "cosyvoice3-towards-in-the-wild-speech-generation-via-scaling-up-and-post-training"]], "\u4e00\u3001\u80cc\u666f\u548c\u73b0\u72b6": [[147, "id1"]], "\u4e8c\u3001\u76ee\u524d\u4e3b\u6d41\u7684\u96f6\u6837\u672c TTS \u6280\u672f\u6709\u4e09\u7c7b\uff1a": [[147, "tts"]], "\u4e09\u3001CosyVoice 2 \u7b80\u4ecb": [[147, "cosyvoice-2"]], "\u56db\u3001\u65b0\u6a21\u578b CosyVoice 3 \u7684\u6539\u8fdb": [[147, "cosyvoice-3"]], "\u4e94\u3001\u7ed3\u679c": [[147, "id2"]], "2.CosyVoice 3": [[147, "id3"]], "2.1 Speech Tokenizer via Supervised Multi-task Training": [[147, "speech-tokenizer-via-supervised-multi-task-training"]], "2.2 Reinforcement Learning with Differentiable Reward Optimization": [[147, "reinforcement-learning-with-differentiable-reward-optimization"]], "2.3 Pronunciation Inpainting": [[147, "pronunciation-inpainting"]], "2.4 Self-training for Text Normalization": [[147, "self-training-for-text-normalization"]], "2.5 Instructed Speech Generation": [[147, "instructed-speech-generation"]], "2.6 Capability Transfer in Speaker Fine-tuning": [[147, "capability-transfer-in-speaker-fine-tuning"]], "2.6.1 Turning a Monolingual Speaker into a Polyglot": [[147, "turning-a-monolingual-speaker-into-a-polyglot"]], "2.6.2 Transferring the Capability of Instructed Generation": [[147, "transferring-the-capability-of-instructed-generation"]], "3.The Multilingual Data Pipeline": [[147, "the-multilingual-data-pipeline"]], "4.Experimental Settings": [[147, "experimental-settings"]], "4.1 Training Data for Speech Tokenizer": [[147, "training-data-for-speech-tokenizer"]], "4.2 Scaling up Dataset Size and Model Size for CosyVoice 3": [[147, "scaling-up-dataset-size-and-model-size-for-cosyvoice-3"]], "4.3 Evaluation Settings for Zero-shot Capability": [[147, "evaluation-settings-for-zero-shot-capability"]], "4.4 CV3-Eval: a Multilingual Benchmark": [[147, "cv3-eval-a-multilingual-benchmark"]], "5.Experimental Results": [[147, "experimental-results"]], "5.1 Objective TTS Results on SEED-TTS-Eval": [[147, "objective-tts-results-on-seed-tts-eval"]], "5.2 Objective Evaluation on Multilingual Benchmark CV3-Eval": [[147, "objective-evaluation-on-multilingual-benchmark-cv3-eval"]], "5.2.1 \u591a\u8bed\u8a00\u8bed\u97f3\u514b\u9686\u7ed3\u679c": [[147, "id4"]], "5.2.2 \u8de8\u8bed\u8a00\u8bed\u97f3\u514b\u9686\u7ed3\u679c": [[147, "id5"]], "5.2.3 \u60c5\u611f\u8bed\u97f3\u514b\u9686\u7ed3\u679c": [[147, "id6"]], "5.2.4 \u4e3b\u89c2\u8bc4\u4f30\u7ed3\u679c\uff08MOS\uff09": [[147, "mos"]], "5.3 Ablation of Speech Tokenizer": [[147, "ablation-of-speech-tokenizer"]], "\u4e00\u3001\u4e0a\u6e38\uff1a\u8bed\u97f3\u8bc6\u522b\u4efb\u52a1\uff08ASR\uff09": [[147, "asr"]], "\u4e8c\u3001\u4e0b\u6e38\uff1a\u8bed\u97f3\u5408\u6210\u4efb\u52a1\uff08TTS\uff09": [[147, "id7"]], "5.4 Ablation of Reinforcement Learning": [[147, "ablation-of-reinforcement-learning"]], "5.5 Pronunciation Inpainting": [[147, "id8"]], "5.6 Instructed Generation": [[147, "instructed-generation"]], "5.7 Results on Speaker Fine-tuned Models": [[147, "results-on-speaker-fine-tuned-models"]], "5.8 Results on Turning a Monolingual Speaker into a Polyglot": [[147, "results-on-turning-a-monolingual-speaker-into-a-polyglot"]], "7.Limitations": [[147, "limitations"]], "2303.08774_GPT-4 Technical Report": [[148, "gpt-4-technical-report"]], "2312.11805_Gemini: A Family of Highly Capable Multimodal Models": [[149, "gemini-a-family-of-highly-capable-multimodal-models"]], "2. Model Architecture": [[149, "model-architecture"]], "3. Training Infrastructure": [[149, "training-infrastructure"]], "5.1 Text": [[149, "text"]], "5.1.1. \u5b66\u672f\u57fa\u51c6\u6d4b\u8bd5\u8868\u73b0(Academic Benchmarks)": [[149, "academic-benchmarks"]], "5.1.2. \u80fd\u529b\u8d8b\u52bf\u5206\u6790(Trends in Capabilities)": [[149, "trends-in-capabilities"]], "5.1.3. Gemini Nano \u7cfb\u5217\uff08Nano 1 / Nano 2\uff09": [[149, "gemini-nano-nano-1-nano-2"]], "5.1.4 \u591a\u8bed\u8a00\u80fd\u529b": [[149, "id1"]], "5.1.5 \u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b": [[149, "id2"]], "5.1.6 \u4e8b\u5b9e\u6027\uff08Factuality\uff09": [[149, "factuality"]], "5.1.7 \u590d\u6742\u63a8\u7406\u7cfb\u7edf": [[149, "id3"]], "5.2 MultiModal": [[149, "multimodal"]], "5.2.1 \u56fe\u7247\u7406\u89e3\uff08Image Understanding\uff09": [[149, "image-understanding"]], "5.2.2 \u89c6\u9891\u7406\u89e3\uff08Video Understanding\uff09": [[149, "video-understanding"]], "5.2.3 \u56fe\u50cf\u751f\u6210\uff08Image Generation\uff09": [[149, "image-generation"]], "5.2.4 \u97f3\u9891\u7406\u89e3\uff08Audio Understanding\uff09": [[149, "audio-understanding"]], "5.2.5 \u591a\u6a21\u6001\u7ec4\u5408\uff08Modality Combination\uff09": [[149, "modality-combination"]], "6. Post-Training Models": [[149, "post-training-models"]], "\ud83d\udd27 \u540e\u8bad\u7ec3\u7684\u56db\u4e2a\u6b65\u9aa4": [[149, "id4"]], "\u2705 6.5 \u6a21\u578b\u80fd\u529b\u7b80\u8ff0": [[149, "id5"]], "\ud83d\udccc 6.5.1 \u6307\u4ee4\u8ddf\u968f\u80fd\u529b": [[149, "id6"]], "\ud83d\udee0 6.5.2 \u5de5\u5177\u4f7f\u7528\u80fd\u529b": [[149, "id7"]], "\ud83c\udf0d 6.5.3 \u591a\u8bed\u8a00\u80fd\u529b": [[149, "id8"]], "\ud83d\uddbc 6.5.4 \u591a\u6a21\u6001\u89c6\u89c9\u7406\u89e3": [[149, "id9"]], "\ud83d\udcbb 6.5.5 \u7f16\u7a0b\u80fd\u529b": [[149, "id10"]], "7. Responsible Deployment": [[149, "responsible-deployment"]], "7.1. Impact Assessment": [[149, "impact-assessment"]], "7.2. Safety Policies": [[149, "safety-policies"]], "7.3. Mitigations": [[149, "mitigations"]], "\u4e00\u3001\u6570\u636e\u5904\u7406\uff08Data Curation\uff09": [[149, "data-curation"]], "\u4e8c\u3001\u6a21\u578b\u5b89\u5168\u673a\u5236\uff08Model Mitigation\uff09": [[149, "model-mitigation"]], "\u4e09\u3001\u5b89\u5168\u673a\u5236\u6210\u6548\u4e3e\u4f8b": [[149, "id11"]], "7.4. Safety Evaluations": [[149, "safety-evaluations"]], "7.4.1. Development & Assurance Evaluations": [[149, "development-assurance-evaluations"]], "\u4e00\u3001\u5b89\u5168\u8bc4\u4f30\u7684\u6574\u4f53\u6d41\u7a0b": [[149, "id12"]], "\u4e8c\u3001\u5177\u4f53\u7684\u8bc4\u4f30\u5185\u5bb9": [[149, "id13"]], "\u4e09\u3001\u5371\u9669\u80fd\u529b\u8bc4\u4f30\uff08Dangerous Capabilities\uff09": [[149, "dangerous-capabilities"]], "7.4.2. Gemini Advanced": [[149, "gemini-advanced"]], "7.4.3. Red Teaming": [[149, "red-teaming"]], "\u6a21\u578b\u7ea7\u7ea2\u961f\u6d4b\u8bd5": [[149, "id14"]], "Gemini Advanced \u7279\u522b\u6d4b\u8bd5": [[149, "id15"]], "7.4.4 \u5916\u90e8\u7ec4\u7ec7\u8bc4\u4f30 Gemini Ultra \u6a21\u578b": [[149, "gemini-ultra"]], "7.4.5\u5916\u90e8\u8bc4\u4f30 Gemini Advanced": [[149, "id16"]], "8. Discussion and Conclusion": [[149, "discussion-and-conclusion"]], "2403.05530_Gemini1.5: Unlocking multimodal understanding across millions of tokens of context": [[150, "gemini1-5-unlocking-multimodal-understanding-across-millions-of-tokens-of-context"]], "2406.02430_Seed-TTS: A Family of High-Quality Versatile Speech Generation Models": [[151, "seed-tts-a-family-of-high-quality-versatile-speech-generation-models"]], "\u4e3b\u8981\u8d21\u732e\u603b\u7ed3\uff1a": [[151, "id1"]], "2 Method": [[151, "method"]], "3.1 Zero-shot in-context learning\uff08\u96f6\u6837\u672c\u4e0a\u4e0b\u6587\u5b66\u4e60\uff09": [[151, "zero-shot-in-context-learning"]], "\u4e0e\u4f20\u7edf\u8bed\u97f3\u5fae\u8c03\u6a21\u578b\u7684\u6bd4\u8f83": [[151, "id5"]], "\u8bed\u97f3\u7406\u89e3\u8bc4\u4f30": [[151, "id6"]], "\u8bed\u97f3\u76f8\u4f3c\u6027\u53ef\u89c6\u5316": [[151, "id7"]], "3.2 Speaker fine-tuning\uff08\u8bed\u97f3\u5fae\u8c03\uff09": [[151, "speaker-fine-tuning"]], "\u8bc4\u4f30\u7ed3\u679c": [[151, "id9"]], "\u6307\u4ee4\u5fae\u8c03\uff08Instruction fine-tuning\uff09": [[151, "instruction-fine-tuning"]], "3.3 Low-latency inference and streaming processing": [[151, "low-latency-inference-and-streaming-processing"]], "4 Model extensions": [[151, "model-extensions"]], "4.1 \u901a\u8fc7\u81ea\u84b8\u998f\u5b9e\u73b0\u8bed\u97f3\u56e0\u5b50\u5316\uff08Speech Factorization\uff09": [[151, "speech-factorization"]], "4.2 \u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u504f\u597d\u4f18\u5316\uff08Preference Biasing with RL\uff09": [[151, "preference-biasing-with-rl"]], "4.3 Fully diffusion-based speech generation": [[151, "fully-diffusion-based-speech-generation"]], "\u6838\u5fc3\u5185\u5bb9\u603b\u7ed3\uff1a": [[151, "id12"], [173, "id1"], [241, "id1"]], "5 Model applications, limitations, and safety": [[151, "model-applications-limitations-and-safety"]], "6 Authors (alphabetical order)": [[151, "authors-alphabetical-order"]], "7 Acknowledgement": [[151, "acknowledgement"]], "2407.04675_Seed-ASR: Understanding Diverse Speech and Contexts with LLM-based Speech Recognition": [[152, "seed-asr-understanding-diverse-speech-and-contexts-with-llm-based-speech-recognition"]], "2 Motivation": [[152, "motivation"]], "3 Methods": [[152, "methods"], [214, "methods"], [237, "methods"]], "1. \u6846\u67b6\u4e0e\u8bad\u7ec3\u6d41\u7a0b\uff08Framework and Training Recipe\uff09": [[152, "framework-and-training-recipe"]], "2. \u97f3\u9891\u7f16\u7801\u5668\u7684 SSL \u8bad\u7ec3\uff08SSL of Audio Encoder\uff09": [[152, "ssl-ssl-of-audio-encoder"]], "3. \u76d1\u7763\u5fae\u8c03\uff08SFT\uff09": [[152, "sft"]], "4. \u4e0a\u4e0b\u6587\u611f\u77e5\u5fae\u8c03\uff08Context SFT\uff09": [[152, "context-sft"]], "5. \u5f3a\u5316\u5b66\u4e60\uff08RL\uff09": [[152, "rl"]], "6. \u89c2\u5bdf\u4e0e\u5b9e\u9a8c\u5206\u6790": [[152, "id1"]], "3.6.1 Scaling Law": [[152, "scaling-law"]], "3.6.1 \u6a21\u578b\u6269\u5c55\u89c4\u5f8b\uff08Scaling Law\uff09": [[152, "id3"]], "3.6.2 \u957f\u6587\u672c\u5904\u7406\u80fd\u529b\uff08Long-form Ability\uff09": [[152, "long-form-ability"]], "4 Model and Evaluation": [[152, "model-and-evaluation"]], "1. \u6a21\u578b\u7ed3\u6784\u4e0e\u8bad\u7ec3\u6d41\u7a0b": [[152, "id5"]], "2. \u8bc4\u4f30\u65b9\u6cd5\u4e0e\u6570\u636e\u96c6": [[152, "id6"]], "3. Seed-ASR (CN) \u7684\u8bc4\u4f30\u7ed3\u679c": [[152, "seed-asr-cn"]], "\uff081\uff09\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0": [[152, "id7"]], "\uff082\uff09\u591a\u9886\u57df\u4e0e\u591a\u6e90\u89c6\u9891\u8bc4\u4f30": [[152, "id8"]], "\uff083\uff09\u591a\u65b9\u8a00\u4e0e\u591a\u53e3\u97f3\u8bc4\u4f30": [[152, "id9"]], "\uff084\uff09\u5bf9\u8bdd\u4e0a\u4e0b\u6587\u8bc4\u4f30": [[152, "id10"]], "\uff085\uff09\u4e3b\u89c2\u8bc4\u4ef7": [[152, "id11"]], "\uff086\uff09\u9636\u6bb5\u8bad\u7ec3\u7684\u6d88\u878d\u7814\u7a76": [[152, "id12"]], "4.2 Seed-ASR (ML)": [[152, "seed-asr-ml"]], "A.1 Seed-ASR (ML) \u7684\u8be6\u7ec6\u7ed3\u679c": [[152, "a-1-seed-asr-ml"]], "A.2 Seed-ASR (ML) \u8bc4\u4f30\u4f7f\u7528\u7684\u82f1\u6587\u548c\u591a\u8bed\u8a00\u516c\u5f00\u6d4b\u8bd5\u96c6": [[152, "a-2-seed-asr-ml"]], "A.3 \u8bad\u7ec3\u6570\u636e\u7edf\u8ba1": [[152, "a-3"]], "\u603b\u7ed3\u8981\u70b9": [[152, "id15"]], "2503.20020_Gemini2: Gemini Robotics: Bringing AI into the Physical World": [[153, "gemini2-gemini-robotics-bringing-ai-into-the-physical-world"]], "2504.xxxxx_Seed-Thinking-v1.5: Advancing Superb Reasoning Models with Reinforcement Learning": [[154, "xxxxx-seed-thinking-v1-5-advancing-superb-reasoning-models-with-reinforcement-learning"]], "2505.07062_Seed1.5-VL Technical Report": [[155, "seed1-5-vl-technical-report"]], "Seed1.5-VL Technical Report": [[155, "id1"]], "1. \u5f15\u8a00\u603b\u7ed3": [[155, "id2"]], "1.1 \u80cc\u666f\u4e0e\u91cd\u8981\u6027": [[155, "id3"]], "1.2 \u73b0\u6709\u6311\u6218": [[155, "id4"]], "1.3 Seed1.5-VL \u6a21\u578b\u4ecb\u7ecd": [[155, "seed1-5-vl"]], "1.4 \u8bad\u7ec3\u6548\u7387\u4e0e\u6280\u672f\u4f18\u5316": [[155, "id5"]], "1.5 \u6a21\u578b\u8bc4\u4f30\u4e0e\u5e94\u7528\u573a\u666f": [[155, "id6"]], "1.6 \u6a21\u578b\u6548\u7387\u4e0e\u5f00\u653e\u6027": [[155, "id7"]], "1.7 \u540e\u7eed\u7ae0\u8282\u7ed3\u6784": [[155, "id8"]], "\u603b\u7ed3\u4e00\u53e5\u8bdd": [[155, "id9"]], "2 Architecture": [[155, "architecture"]], "2.1 \u89c6\u89c9\u7f16\u7801\u5668\uff08SeedViT\uff09": [[155, "seedvit"]], "2.1.1 \u67b6\u6784\u8bbe\u8ba1": [[155, "id10"]], "2.1.2 \u9884\u8bad\u7ec3\u9636\u6bb5": [[155, "id11"]], "2.2 \u89c6\u9891\u7f16\u7801": [[155, "id12"]], "\u6838\u5fc3\u673a\u5236\uff1a": [[155, "id13"]], "\u957f\u89c6\u9891\u5904\u7406\u673a\u5236\uff1a": [[155, "id14"]], "3 Pre-training": [[155, "pre-training"], [182, "pre-training"]], "3.1 \u9884\u8bad\u7ec3\u6570\u636e": [[155, "id16"]], "3.1.1 \u901a\u7528\u56fe\u50cf-\u6587\u672c\u5bf9\u4e0e\u77e5\u8bc6\u6570\u636e": [[155, "id17"]], "3.1.2 \u5149\u5b66\u5b57\u7b26\u8bc6\u522b\uff08OCR\uff09": [[155, "ocr"]], "3.1.3 \u89c6\u89c9\u5b9a\u4f4d\u4e0e\u8ba1\u6570": [[155, "id18"]], "3.1.4 3D\u7a7a\u95f4\u7406\u89e3": [[155, "d"]], "3.1.5 \u89c6\u9891\u7406\u89e3": [[155, "id19"]], "3.1.6 STEM\u6559\u80b2": [[155, "stem"]], "3.1.7 \u56fe\u5f62\u7528\u6237\u754c\u9762\uff08GUI\uff09": [[155, "gui"]], "3.2 Training Recipe": [[155, "training-recipe"]], "3.2 \u8bad\u7ec3\u7b56\u7565\u603b\u7ed3": [[155, "id21"]], "\u5404\u9636\u6bb5\u8bad\u7ec3\u76ee\u6807\uff1a": [[155, "id22"]], "\u4f18\u5316\u5668\u548c\u5b66\u4e60\u7387\u8bbe\u7f6e\uff1a": [[155, "id23"]], "3.3 \u7f29\u653e\u89c4\u5f8b\u603b\u7ed3": [[155, "id24"]], "\u635f\u5931\u4e0e\u8bad\u7ec3\u6570\u636e\u91cf\u7684\u5e42\u5f8b\u5173\u7cfb\uff1a": [[155, "id25"]], "\u610f\u4e49\u4e0e\u5e94\u7528\uff1a": [[155, "id27"]], "4 Post-training": [[155, "post-training"]], "4. Post-training \u603b\u89c8": [[155, "id28"]], "4.1 \u76d1\u7763\u5fae\u8c03\uff08SFT\uff09": [[155, "sft"]], "4.2 \u4eba\u7c7b\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60\uff08RLHF\uff09": [[155, "rlhf"]], "4.3 \u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\uff08RLVR\uff09": [[155, "rlvr"]], "4.4 Hybrid Reinforcement Learning": [[155, "hybrid-reinforcement-learning"]], "\u603b\u7ed3\uff1a4.4 \u6df7\u5408\u5f3a\u5316\u5b66\u4e60\u4e0e 4.5 \u62d2\u7edd\u91c7\u6837\u5fae\u8c03\u7684\u8fed\u4ee3\u66f4\u65b0": [[155, "id30"]], "4.4 \u6df7\u5408\u5f3a\u5316\u5b66\u4e60\uff08Hybrid Reinforcement Learning\uff09": [[155, "id31"]], "4.5 \u901a\u8fc7\u62d2\u7edd\u91c7\u6837\u5fae\u8c03\u7684\u8fed\u4ee3\u66f4\u65b0\uff08Iterative Update by Rejection Sampling Fine-tuning\uff09": [[155, "iterative-update-by-rejection-sampling-fine-tuning"]], "\u603b\u4f53\u8bc4\u4ef7": [[155, "id32"]], "5 Training Infrastructure": [[155, "training-infrastructure"]], "5.1 \u5927\u89c4\u6a21\u9884\u8bad\u7ec3": [[155, "id33"]], "5.2 \u540e\u8bad\u7ec3\u6846\u67b6": [[155, "id34"]], "6 Evaluation": [[155, "evaluation"], [242, "evaluation"]], "6.1 \u516c\u5f00\u57fa\u51c6\u6d4b\u8bd5": [[155, "id36"]], "6.1.1 \u89c6\u89c9\u7f16\u7801\u5668\u7684\u96f6\u6837\u672c\u5206\u7c7b\u80fd\u529b": [[155, "id37"]], "6.1.2 \u89c6\u89c9\u4efb\u52a1\u8bc4\u4f30": [[155, "id38"]], "6.2 \u667a\u80fd\u4ee3\u7406\u4efb\u52a1\u8bc4\u4f30": [[155, "id39"]], "6.3 \u5185\u90e8\u57fa\u51c6\u6d4b\u8bd5\u4e0e\u884c\u4e1a\u9886\u5148\u6a21\u578b\u5bf9\u6bd4": [[155, "id40"]], "6.4 \u6a21\u578b\u9650\u5236": [[155, "id41"]], "6.1.3 Video Task Evaluation": [[155, "video-task-evaluation"]], "6.1.3 \u89c6\u9891\u4efb\u52a1\u8bc4\u4f30": [[155, "id43"]], "6.2 \u591a\u6a21\u6001\u4ee3\u7406": [[155, "id44"]], "GUI \u63a5\u5730\u4efb\u52a1": [[155, "id45"]], "GUI \u4ee3\u7406\u4efb\u52a1": [[155, "id46"]], "\u6e38\u620f\u4ee3\u7406\u4efb\u52a1": [[155, "id47"]], "6.3 \u5185\u90e8\u57fa\u51c6\u6d4b\u8bd5": [[155, "id48"]], "6.3.2 Comparison with State-of-the-arts": [[155, "comparison-with-state-of-the-arts"]], "1. \u4e0e\u6700\u5148\u8fdb\u6a21\u578b\u7684\u6bd4\u8f83": [[155, "id50"]], "2. \u6cdb\u5316\u80fd\u529b\u6d4b\u8bd5": [[155, "id51"]], "3. \u6a21\u578b\u7684\u5c40\u9650\u6027": [[155, "id52"]], "(1) \u89c6\u89c9\u611f\u77e5\u7684\u7cbe\u7ec6\u5ea6\u4e0d\u8db3": [[155, "id53"]], "(2) \u9ad8\u7ea7\u63a8\u7406\u80fd\u529b\u6709\u9650": [[155, "id54"]], "(3) \u6a21\u578b\u5e7b\u89c9\u95ee\u9898": [[155, "id55"]], "4. \u672a\u6765\u65b9\u5411": [[155, "id56"]], "7 Conclusion and Next Steps": [[155, "conclusion-and-next-steps"]], "8 Contributions and Acknowledgments": [[155, "contributions-and-acknowledgments"]], "9 Qualitative examples": [[155, "qualitative-examples"]], "9.7 Visual Reasoning_ Visual Pattern Recognition": [[155, "visual-reasoning-visual-pattern-recognition"]], "9.7 Visual Reasoning: Visual Pattern Recognition": [[155, "id58"]], "9.8 Visual Puzzles: Find the Differences": [[155, "visual-puzzles-find-the-differences"]], "9.9 Geometry": [[155, "geometry"]], "9.10 Counting in a complex scene": [[155, "counting-in-a-complex-scene"]], "9.11 Spatial Understanding: Depth Sorting": [[155, "spatial-understanding-depth-sorting"]], "9.12 Video Temporal Grounding": [[155, "video-temporal-grounding"]], "9.13 OCR Parsing and Document Understanding": [[155, "ocr-parsing-and-document-understanding"]], "9.14 Multilingual OCR Parsing": [[155, "multilingual-ocr-parsing"]], "9.15 Generate Code for a Diagram of Novel Format": [[155, "generate-code-for-a-diagram-of-novel-format"]], "9.16 Image-conditioned Creative Writing": [[155, "image-conditioned-creative-writing"]], "9.17 Failure Cases: 3D Spatial Imagination": [[155, "failure-cases-3d-spatial-imagination"]], "9.18 Failure Cases: Hallucination (Knowledge Prior)": [[155, "failure-cases-hallucination-knowledge-prior"]], "9.19 Failure Cases_ Combinatorial Search I": [[155, "failure-cases-combinatorial-search-i"]], "9.19 \u7ec4\u5408\u641c\u7d22\u5931\u8d25\u6848\u4f8b I": [[155, "i"]], "9.20 \u7ec4\u5408\u641c\u7d22\u5931\u8d25\u6848\u4f8b II": [[155, "ii"]], "10 Evaluation Details": [[155, "evaluation-details"]], "10.1 \u5185\u90e8\u57fa\u51c6\u7ed3\u6784": [[155, "id62"]], "10.2 \u5185\u90e8\u57fa\u51c6\u4e0a\u7684\u7efc\u5408\u6bd4\u8f83": [[155, "id63"]], "10.3 \u80fd\u529b\u4e0e\u57fa\u51c6\u4efb\u52a1": [[155, "id64"]], "10.4 \u8bc4\u4f30\u63d0\u793a\uff08Evaluation Prompts\uff09": [[155, "evaluation-prompts"]], "DREAM-1K": [[155, "dream-1k"]], "2408.15664_AUXILIARY-LOSS-FREE LOAD BALANCING STRATEGY FOR MIXTURE-OF-EXPERTS": [[156, "auxiliary-loss-free-load-balancing-strategy-for-mixture-of-experts"]], "2410.07490_MoDEM: Mixture of Domain Expert Models": [[157, "modem-mixture-of-domain-expert-models"]], "2112.15093_CTR: Benchmarking Chinese Text Recognition: Datasets, Baselines, and an Empirical Study": [[158, "ctr-benchmarking-chinese-text-recognition-datasets-baselines-and-an-empirical-study"]], "2.1 Hierarchical Representations for Chinese Characters": [[158, "hierarchical-representations-for-chinese-characters"]], "2.2 Characteristics of Chinese Texts": [[158, "characteristics-of-chinese-texts"]], "3. Datasets": [[158, "datasets"]], "3.1 Details of Datasets": [[158, "details-of-datasets"]], "\ud83c\udfd9 \u573a\u666f\u7c7b\u6570\u636e\u96c6\uff08Scene Dataset\uff09": [[158, "scene-dataset"]], "\ud83c\udf10 \u7f51\u9875\u7c7b\u6570\u636e\u96c6\uff08Web Dataset\uff09": [[158, "web-dataset"]], "\ud83d\udcc4 \u6587\u6863\u7c7b\u6570\u636e\u96c6\uff08Document Dataset\uff09": [[158, "document-dataset"]], "\u270d\ufe0f \u624b\u5199\u7c7b\u6570\u636e\u96c6\uff08Handwriting Dataset\uff09": [[158, "handwriting-dataset"]], "\ud83d\udd12 \u6570\u636e\u96c6\u8bb8\u53ef\u4fe1\u606f\uff08Licenses\uff09": [[158, "licenses"]], "3.2 Preprocessing": [[158, "preprocessing"]], "3.3 Analysis of Datasets": [[158, "analysis-of-datasets"]], "Alphabet size and amount of characters": [[158, "alphabet-size-and-amount-of-characters"]], "Distributions of text length and aspect ratio": [[158, "distributions-of-text-length-and-aspect-ratio"]], "Character and word frequency": [[158, "character-and-word-frequency"]], "Recognizability calibration by humans": [[158, "recognizability-calibration-by-humans"]], "4. Baselines": [[158, "baselines"]], "1. CTC-based \u65b9\u6cd5\uff1a": [[158, "ctc-based"]], "2. Rectification-based \u65b9\u6cd5\uff08\u56fe\u50cf\u77eb\u6b63\u7c7b\uff09\uff1a": [[158, "rectification-based"]], "3. 2D \u7279\u5f81\u89e3\u7801\u65b9\u6cd5\uff1a": [[158, "d"]], "4. \u8bed\u4e49\u5148\u9a8c\u5f15\u5bfc\u7684\u65b9\u6cd5\uff1a": [[158, "id1"]], "5. \u7eaf Attention\uff08\u81ea\u6ce8\u610f\u529b\uff09\u65b9\u6cd5\uff1a": [[158, "attention"]], "6. \u878d\u5408\u89c6\u89c9\u4e0e\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\uff1a": [[158, "id2"]], "7. Transformer \u67b6\u6784\uff1a": [[158, "transformer"]], "PRAB(Pluggable Radical-Aware Branch)": [[158, "prab-pluggable-radical-aware-branch"]], "5. An Empirical Study": [[158, "an-empirical-study"]], "5.1 Experiments": [[158, "experiments"]], "5.2 Discussions": [[158, "discussions"]], "Appendix A Details of PRAB": [[158, "appendix-a-details-of-prab"]], "A.1 Shared Feature Extractor": [[158, "a-1-shared-feature-extractor"]], "A.2 Recognition Branch(\u57fa\u4e8e\u6ce8\u610f\u529b)": [[158, "a-2-recognition-branch"]], "A.3 Pluggable Radical-Aware Branch\uff08\u8bad\u7ec3\u65f6\u4f7f\u7528\uff09": [[158, "a-3-pluggable-radical-aware-branch"]], "Appendix C Visualization of Failure Cases.": [[158, "appendix-c-visualization-of-failure-cases"]], "2304.08485_LLaVA: Visual Instruction Tuning": [[159, "llava-visual-instruction-tuning"]], "Multimodal Instruction-following Agents": [[159, "multimodal-instruction-following-agents"]], "\u6307\u4ee4\u5fae\u8c03\uff08Instruction Tuning\uff09\uff1a": [[159, "instruction-tuning"]], "3. GPT-assisted Visual Instruction Data Generation": [[159, "gpt-assisted-visual-instruction-data-generation"]], "\u80cc\u666f\u95ee\u9898": [[159, "id1"]], "\u4e09\u7c7b\u751f\u6210\u6570\u636e": [[159, "id3"]], "\u6210\u679c": [[159, "id4"]], "4. Visual Instruction Tuning": [[159, "visual-instruction-tuning"]], "4.1 Architecture": [[159, "architecture"]], "4.2 Training": [[159, "training"]], "\u603b\u4f53\u5b9e\u9a8c\u8bbe\u8ba1\uff1a": [[159, "id5"]], "5.1 \u591a\u6a21\u6001\u804a\u5929\u673a\u5668\u4eba\uff08Multimodal Chatbot\uff09": [[159, "multimodal-chatbot"]], "5.2 ScienceQA \u591a\u6a21\u6001\u95ee\u7b54": [[159, "scienceqa"]], "2308.12966_Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond": [[160, "qwen-vl-a-versatile-vision-language-model-for-understanding-localization-text-reading-and-beyond"]], "Methodology": [[160, "methodology"], [219, "methodology"]], "2.1 Model Architecture": [[160, "model-architecture"], [169, "model-architecture"]], "2.2 Inputs and Outputs": [[160, "inputs-and-outputs"]], "Training": [[160, "training"], [229, "id5"]], "3.1 Pre-training": [[160, "pre-training"]], "3.2 Multi-task Pre-training": [[160, "multi-task-pre-training"]], "3.3 Supervised Fine-tuning": [[160, "supervised-fine-tuning"]], "Evaluation": [[160, "evaluation"]], "4.1 Image Caption and General Visual Question Answering": [[160, "image-caption-and-general-visual-question-answering"]], "4.2 Text-oriented Visual Question Answering": [[160, "text-oriented-visual-question-answering"]], "4.3 Refer Expression Comprehension": [[160, "refer-expression-comprehension"]], "B. Data Format Details of Training": [[160, "b-data-format-details-of-training"]], "B.1 Data Format of Multi-Task Pre-training": [[160, "b-1-data-format-of-multi-task-pre-training"]], "B.2 Data Format of Supervised Fine-tuning": [[160, "b-2-data-format-of-supervised-fine-tuning"]], "2310.03744_LLaVA2: Improved Baselines with Visual Instruction Tuning": [[161, "llava2-improved-baselines-with-visual-instruction-tuning"]], "Instruction-following large multimodal models (LMMs).": [[161, "instruction-following-large-multimodal-models-lmms"]], "\u4e8c\u3001\u591a\u6a21\u6001\u6307\u4ee4\u8ddf\u968f\u6570\u636e": [[161, "id1"]], "3.1 Preliminaries": [[161, "preliminaries"], [228, "preliminaries"]], "3.2 \u54cd\u5e94\u683c\u5f0f\u63d0\u793a\uff08Response Format Prompting\uff09": [[161, "response-format-prompting"]], "3.3 \u6570\u636e\u4e0e\u6a21\u578b\u6269\u5c55": [[161, "id2"]], "3.4 \u652f\u6301\u66f4\u9ad8\u5206\u8fa8\u7387\uff08LLaVA-1.5-HD\uff09": [[161, "llava-1-5-hd"]], "4. Empirical Evaluation": [[161, "empirical-evaluation"]], "4.1 \u8bc4\u4f30\u57fa\u51c6\uff08Benchmarks\uff09": [[161, "benchmarks"]], "4.2 \u4e3b\u8981\u7ed3\u679c\uff08Results\uff09": [[161, "results"]], "4.3 \u80fd\u529b\u5c55\u793a\uff08Examples\uff09": [[161, "examples"]], "4.4 \u67b6\u6784\u5206\u6790\u4e0e\u6d88\u878d\u5b9e\u9a8c\uff08Ablation\uff09": [[161, "ablation"]], "4.5 \u7ed3\u8bba": [[161, "id3"]], "5. Open Problems in LMMs": [[161, "open-problems-in-lmms"]], "5.1 \u6570\u636e\u6548\u7387\uff08Data Efficiency\uff09": [[161, "data-efficiency"]], "5.2 \u5e7b\u89c9\u95ee\u9898\uff08Hallucination\uff09": [[161, "hallucination"]], "5.3 \u7ec4\u5408\u80fd\u529b\uff08Compositional Capabilities\uff09": [[161, "compositional-capabilities"]], "A. Implementation Details": [[161, "a-implementation-details"]], "\ud83d\udd27 A.1 \u5b9e\u73b0\u7ec6\u8282\uff08LLaVA-1.5-HD\uff09": [[161, "a-1-llava-1-5-hd"]], "\ud83d\udcf7 A.1.1 \u9884\u5904\u7406": [[161, "a-1-1"]], "\ud83c\udfcb\ufe0f\u200d\u2642\ufe0f A.1.2 \u8bad\u7ec3": [[161, "a-1-2"]], "\ud83d\udcda A.2 \u6570\u636e\u6784\u6210": [[161, "a-2"]], "\u2699\ufe0f A.3 \u8d85\u53c2\u6570\u8bbe\u7f6e": [[161, "a-3"]], "B. Qualitative Results": [[161, "b-qualitative-results"]], "B.1. Response Format Prompts": [[161, "b-1-response-format-prompts"]], "B.2. Compositional Capabilities": [[161, "b-2-compositional-capabilities"]], "2312.07533_VILA: On Pre-training for Visual Language Models": [[162, "vila-on-pre-training-for-visual-language-models"]], "\u6a21\u578b\u67b6\u6784": [[162, "id2"]], "\u8bad\u7ec3\u6d41\u7a0b\u5206\u4e09\u9636\u6bb5\uff1a": [[162, "id3"]], "3. On Pre-training for Visual Language Models": [[162, "on-pre-training-for-visual-language-models"]], "3.1 Updating LLM is Essential": [[162, "updating-llm-is-essential"]], "3.2. Interleaved Visual Language Corpus Helps Pre-training": [[162, "interleaved-visual-language-corpus-helps-pre-training"]], "3.3. Recover LLM Degradation with Joint SFT": [[162, "recover-llm-degradation-with-joint-sft"]], "4.1. Scaling up VLM pre-training": [[162, "scaling-up-vlm-pre-training"]], "4.2. Quantitative Evaluation": [[162, "quantitative-evaluation"]], "4.3. Qualitative Evaluation": [[162, "qualitative-evaluation"]], "4.4 Other Learnings.": [[162, "other-learnings"]], "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff1a": [[162, "llms"]], "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\uff1a": [[162, "vlms"]], "2403.05525_DeepSeek-VL: Towards Real-World Vision-Language Understanding": [[163, "deepseek-vl-towards-real-world-vision-language-understanding"]], "2408.01800_MiniCPM-V: A GPT-4V Level MLLM on Your Phone": [[164, "minicpm-v-a-gpt-4v-level-mllm-on-your-phone"]], "\u591a\u6a21\u6001\u5927\u6a21\u578b\uff08MLLMs\uff09": [[164, "mllms"]], "\u7aef\u4fa7\u591a\u6a21\u6001\u5927\u6a21\u578b\uff08End-side MLLMs\uff09": [[164, "end-side-mllms"]], "3. Model Architecture": [[164, "model-architecture"]], "MiniCPM-V \u6a21\u578b\u7ed3\u6784\u7b80\u4ecb": [[164, "minicpm-v"]], "\u81ea\u9002\u5e94\u89c6\u89c9\u7f16\u7801\uff08Adaptive Visual Encoding\uff09": [[164, "adaptive-visual-encoding"]], "Token \u538b\u7f29\uff08Token Compression\uff09": [[164, "token-token-compression"]], "\u7a7a\u95f4\u7ed3\u6784\u6807\u8bb0\uff08Spatial Schema\uff09": [[164, "spatial-schema"]], "4. Training": [[164, "training"], [165, "training"]], "\u6a21\u578b\u8bad\u7ec3\u603b\u4f53\u7ed3\u6784\uff1a": [[164, "id1"]], "\u4e00\u3001\u9884\u8bad\u7ec3\u9636\u6bb5\uff08Pre-training\uff09": [[164, "pre-training"]], "\u4e8c\u3001\u6709\u76d1\u7763\u5fae\u8c03\u9636\u6bb5\uff08SFT\uff09": [[164, "sft"]], "\u4e09\u3001RLAIF-V \u9636\u6bb5\uff08\u5f3a\u5316\u5bf9\u9f50\uff09": [[164, "rlaif-v"]], "5. End-side Deployment": [[164, "end-side-deployment"]], "\u4e00\u3001\u9762\u4e34\u7684\u6311\u6218": [[164, "id2"]], "\u4e8c\u3001\u57fa\u7840\u90e8\u7f72\u65b9\u6cd5": [[164, "id3"]], "\u4e09\u3001\u9ad8\u7ea7\u4f18\u5316\u7b56\u7565": [[164, "id4"]], "\u56db\u3001\u5b9e\u9a8c\u7ed3\u679c\u4e0e\u5c55\u671b": [[164, "id5"]], "6. Experiments": [[164, "experiments"]], "\u6a21\u578b\u7248\u672c": [[164, "id6"]], "\u6d88\u878d\u5b9e\u9a8c\u7ed3\u8bba": [[164, "id7"]], "\u6848\u4f8b\u5c55\u793a": [[164, "id8"]], "\u672c\u6587\u8d21\u732e\uff1a": [[164, "id9"]], "\u5c40\u9650\u6027\uff1a": [[164, "id10"]], "\u672a\u6765\u65b9\u5411\uff1a": [[164, "id11"]], "2409.17146_Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Vision-Language Models": [[165, "molmo-and-pixmo-open-weights-and-open-data-for-state-of-the-art-vision-language-models"]], "\ud83d\udccc \u80cc\u666f\u73b0\u72b6": [[165, "id1"]], "\u2705 Molmo \u9879\u76ee\u7684\u7a81\u7834": [[165, "molmo"]], "\ud83d\uddc2\ufe0f PixMo \u6570\u636e\u96c6\u4eae\u70b9": [[165, "pixmo"]], "\ud83e\udde0 \u6a21\u578b\u8bad\u7ec3\u65b9\u5f0f": [[165, "id2"], [181, "id10"]], "\ud83d\udcca \u7ed3\u679c\u8868\u73b0": [[165, "id3"]], "2. Architecture": [[165, "architecture"], [189, "architecture"]], "\u6a21\u578b\u67b6\u6784\u7b80\u8981\u8bf4\u660e": [[165, "id4"]], "\u5173\u952e\u8bbe\u8ba1\u70b9": [[165, "id5"]], "3. Data": [[165, "data"]], "\u2705 \u9884\u8bad\u7ec3\uff08Pre-training\uff09\uff1a": [[165, "pre-training"]], "\u2705 \u5fae\u8c03\uff08Fine-tuning\uff09\uff1a": [[165, "fine-tuning"]], "6. Ablations": [[165, "ablations"]], "\u5b9e\u9a8c\u6307\u6807": [[165, "id7"]], "\u6a21\u578b\u7ed3\u6784\u7684\u6d88\u878d\u5b9e\u9a8c\u7ed3\u8bba\uff1a": [[165, "id8"]], "\u6570\u636e\u7684\u6d88\u878d\u5b9e\u9a8c\u7ed3\u8bba\uff1a": [[165, "id9"]], "\u5173\u4e8e\u201c\u8ba1\u6570\u201d\u80fd\u529b\u7684\u5b9e\u9a8c\u7ed3\u8bba\uff1a": [[165, "id10"]], "\u4eba\u7c7b\u8bc4\u4f30\u7ed3\u8bba\uff1a": [[165, "id11"]], "Appendix A: Model Details": [[165, "appendix-a-model-details"]], "\u4e00\u3001\u56fe\u50cf\u7f16\u7801\uff08Image Encoding\uff09": [[165, "image-encoding"]], "\u4e8c\u3001\u8d85\u53c2\u6570\uff08Hyperparameters\uff09": [[165, "hyperparameters"]], "\u4e09\u3001\u5b9e\u73b0\u7ec6\u8282\uff08Implementation\uff09": [[165, "implementation"]], "Appendix B: Training Details": [[165, "appendix-b-training-details"]], "\u4e00\u3001\u9884\u8bad\u7ec3\uff08Pre-Training\uff09": [[165, "id12"]], "\u4e8c\u3001\u5fae\u8c03\uff08Fine-Tuning\uff09": [[165, "id13"]], "\u4e09\u3001\u8bad\u7ec3\u8d44\u6e90\u6d88\u8017\uff08Training Time\uff09": [[165, "training-time"]], "Appendix C: Evaluation Results": [[165, "appendix-c-evaluation-results"]], "1. \u56fe\u50cf\u5b57\u5e55\u8bc4\u4f30\u6307\u6807\uff08cap F1\uff09": [[165, "cap-f1"]], "2. \u4eba\u7c7b\u8bc4\u4f30": [[165, "id14"]], "3. AndroidControl \u4efb\u52a1": [[165, "androidcontrol"]], "Appendix D: Result Details": [[165, "appendix-d-result-details"]], "1. Chatbot Arena \u6392\u540d": [[165, "chatbot-arena"]], "2. \u8bfb\u949f\u8868\u4efb\u52a1\uff08Clock Reading\uff09": [[165, "clock-reading"]], "3. \u6307\u70b9\u4efb\u52a1\uff08Pointing Task\uff09": [[165, "pointing-task"]], "Appendix E Ablations Details": [[165, "appendix-e-ablations-details"]], "1. Vision encoder\uff08\u89c6\u89c9\u7f16\u7801\u5668\uff09": [[165, "vision-encoder"]], "2. Image resolution\uff08\u56fe\u50cf\u5206\u8fa8\u7387\uff09": [[165, "image-resolution"]], "3. Dropout\uff08\u4e22\u5f03\u7b56\u7565\uff09": [[165, "dropout"]], "4. Length conditioning\uff08\u957f\u5ea6\u63d0\u793a\uff09": [[165, "length-conditioning"]], "5. PixMo-Cap \u6570\u636e\u89c4\u6a21": [[165, "pixmo-cap"]], "6. Pre-training data\uff08\u9884\u8bad\u7ec3\u6570\u636e\uff09": [[165, "pre-training-data"]], "7. Supervised fine-tuning data\uff08\u6709\u76d1\u7763\u5fae\u8c03\u6570\u636e\uff09": [[165, "supervised-fine-tuning-data"]], "8. Counting\uff08\u8ba1\u6570\u4efb\u52a1\uff09": [[165, "counting"]], "9. \u5176\u4ed6\u6d88\u878d\u5b9e\u9a8c": [[165, "id15"]], "Appendix F Data Details": [[165, "appendix-f-data-details"]], "PixMo-Points": [[165, "pixmo-points"]], "PixMo-Cap": [[165, "id16"]], "PixMo-Docs": [[165, "pixmo-docs"]], "\u5f00\u653e\u6027\u6bd4\u8f83\uff08\u56fe13\uff09": [[165, "id17"]], "Appendix G Dataset Examples": [[165, "appendix-g-dataset-examples"]], "Appendix H Related Work": [[165, "appendix-h-related-work"]], "Vision-language contrastive models.": [[165, "vision-language-contrastive-models"]], "Multimodal LLMs.": [[165, "multimodal-llms"]], "Vision-language instruction tuning datasets.": [[165, "vision-language-instruction-tuning-datasets"]], "Synthetic vision-language datasets.": [[165, "synthetic-vision-language-datasets"]], "VLM grounding": [[165, "vlm-grounding"]], "Bootstrapping from LLMs": [[165, "bootstrapping-from-llms"]], "2410.13848_Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation": [[166, "janus-decoupling-visual-encoding-for-unified-multimodal-understanding-and-generation"]], "\u7814\u7a76\u80cc\u666f": [[166, "id2"]], "\u95ee\u9898\u4e0e\u6311\u6218": [[166, "id3"]], "\u672c\u6587\u8d21\u732e": [[166, "id4"]], "3 Janus: A Simple, Unified and Flexible Multimodal Framework": [[166, "janus-a-simple-unified-and-flexible-multimodal-framework"]], "3.1 \u67b6\u6784\u8bbe\u8ba1": [[166, "id7"], [240, "id23"]], "3.2 \u8bad\u7ec3\u6d41\u7a0b": [[166, "id8"]], "3.3 \u8bad\u7ec3\u76ee\u6807": [[166, "id9"]], "3.4 \u63a8\u7406\u8fc7\u7a0b": [[166, "id10"]], "3.5 \u6f5c\u5728\u6269\u5c55": [[166, "id11"]], "\u4e00\u3001\u5b9e\u9a8c\u8bbe\u7f6e\uff08Implementation Details\uff09": [[166, "implementation-details"]], "\u4e8c\u3001\u6570\u636e\u96c6\u8bbe\u7f6e\uff08Data Setup\uff09": [[166, "data-setup"]], "\u4e09\u3001\u8bc4\u4f30\u8bbe\u7f6e\uff08Evaluation Setup\uff09": [[166, "evaluation-setup"]], "\u56db\u3001\u5b9e\u9a8c\u7ed3\u679c": [[166, "id13"]], "4.4 Comparison with State-of-the-arts": [[166, "comparison-with-state-of-the-arts"]], "4.4 \u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u7684\u5bf9\u6bd4": [[166, "id15"]], "\u591a\u6a21\u6001\u7406\u89e3\u6027\u80fd": [[166, "id16"]], "\u89c6\u89c9\u751f\u6210\u6027\u80fd": [[166, "id17"]], "4.5 \u6d88\u878d\u7814\u7a76": [[166, "id18"]], "4.6 \u5b9a\u6027\u7ed3\u679c": [[166, "id19"]], "\u89c6\u89c9\u751f\u6210\u5bf9\u6bd4": [[166, "id20"]], "\u591a\u6a21\u6001\u7406\u89e3\u5bf9\u6bd4": [[166, "id21"]], "Appendix A Details of Semantic Tokenizer Mentioned in Ablation Study": [[166, "appendix-a-details-of-semantic-tokenizer-mentioned-in-ablation-study"]], "\u4e00\u3001\u8bed\u4e49 Tokenizer \u67b6\u6784\uff08A.1\uff09": [[166, "tokenizer-a-1"]], "\u4e8c\u3001\u8bad\u7ec3\u8fc7\u7a0b\uff08A.2\uff09": [[166, "a-2"]], "\u4e09\u3001\u4e0e LLM \u7684\u96c6\u6210\uff08A.3\uff09": [[166, "llm-a-3"]], "Appendix B Additional Qualitative Results": [[166, "appendix-b-additional-qualitative-results"]], "2411.00774_Freeze-Omni: A Smart and Low Latency Speech-to-speech Dialogue Model with Frozen LLM": [[167, "freeze-omni-a-smart-and-low-latency-speech-to-speech-dialogue-model-with-frozen-llm"]], "2. Model": [[167, "model"]], "2.1 Overview": [[167, "overview"], [170, "overview"]], "2.2 Modeling of speech input": [[167, "modeling-of-speech-input"]], "1. \u6d41\u5f0f\u8bed\u97f3\u7f16\u7801\u5668": [[167, "id1"]], "2. \u4e09\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565": [[167, "id2"], [167, "id4"]], "2.3 Modeling of speech output": [[167, "modeling-of-speech-output"]], "1. \u67b6\u6784\uff1a": [[167, "id3"]], "2.4 Design for duplex dialogue": [[167, "design-for-duplex-dialogue"]], "3. Experience": [[167, "experience"]], "1. \u6570\u636e\u96c6\u4e0e\u8bad\u7ec3\u8bbe\u7f6e": [[167, "id5"]], "2. \u8bed\u97f3\u8f93\u5165\u7406\u89e3\u80fd\u529b": [[167, "id6"]], "3. \u8bed\u97f3\u8f93\u51fa\u8d28\u91cf": [[167, "id7"]], "4. \u8bed\u97f3\u95ee\u7b54\u80fd\u529b": [[167, "id8"]], "5. \u7aef\u5230\u7aef\u5ef6\u8fdf\u5206\u6790": [[167, "id9"]], "4. Conclusion and Future Work": [[167, "conclusion-and-future-work"]], "2412.04468_NVILA: Efficient Frontier Visual Language Models": [[168, "nvila-efficient-frontier-visual-language-models"]], "2.1 Efficient Model Architecture": [[168, "efficient-model-architecture"]], "\u7a7a\u95f4\u7ef4\u5ea6\u4f18\u5316\uff082.1.1 Spatial \u201cScale-Then-Compress\u201d\uff09": [[168, "spatial-scale-then-compress"]], "\u65f6\u95f4\u7ef4\u5ea6\u4f18\u5316\uff082.1.2 Temporal \u201cScale-Then-Compress\u201d\uff09": [[168, "temporal-scale-then-compress"]], "2.2 Efficient Training": [[168, "efficient-training"]], "1. \u6570\u636e\u96c6\u526a\u679d\uff08Dataset Pruning\uff09": [[168, "dataset-pruning"]], "2. FP8 \u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\uff08FP8 Training\uff09": [[168, "fp8-fp8-training"]], "2.3 Efficient Fine-Tuning": [[168, "efficient-fine-tuning"]], "2.4 Efficient Deployment": [[168, "efficient-deployment"]], "4. More Capabilities": [[168, "more-capabilities"]], "2502.13923_Qwen2.5-VL": [[169, "qwen2-5-vl"]], "\ud83d\udca1 \u80cc\u666f\u4ecb\u7ecd": [[169, "id1"]], "\ud83c\udfaf Qwen2.5-VL \u7684\u76ee\u6807": [[169, "id2"]], "\ud83e\uddf1 \u6280\u672f\u521b\u65b0\u70b9": [[169, "id3"]], "\ud83c\udf1f Qwen2.5-VL \u7684\u5173\u952e\u80fd\u529b": [[169, "id4"]], "\ud83e\udde0 \u67b6\u6784\u4eae\u70b9": [[169, "id5"]], "\u2705 2.1.1 \u5feb\u901f\u9ad8\u6548\u7684\u89c6\u89c9\u7f16\u7801\u5668\uff08Vision Encoder\uff09": [[169, "vision-encoder"]], "\u2705 2.1.2 \u539f\u751f\u52a8\u6001\u5206\u8fa8\u7387\u4e0e\u5e27\u7387\uff08Native Dynamic Resolution & Frame Rate\uff09": [[169, "native-dynamic-resolution-frame-rate"]], "\u2705 2.1.3 \u591a\u6a21\u6001\u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801\u4e0e\u7edd\u5bf9\u65f6\u95f4\u5bf9\u9f50\uff08MRoPE with Absolute Time\uff09": [[169, "mrope-with-absolute-time"]], "2.2 Pre-Training": [[169, "pre-training"]], "2.2.1 Pre-Training Data": [[169, "pre-training-data"]], "2.2.2 Training Recipe": [[169, "training-recipe"]], "2.3 Post-training": [[169, "post-training"]], "2.3.1 Instruction Data": [[169, "instruction-data"]], "2.3.2 Data Filtering Pipeline": [[169, "data-filtering-pipeline"]], "2.3.3 Rejection Sampling for Enhanced Reasoning": [[169, "rejection-sampling-for-enhanced-reasoning"]], "2.3.4 Training Recipe": [[169, "id7"]], "4. Conclusion": [[169, "conclusion"], [195, "conclusion"]], "2503.20215_Qwen2.5-Omni Technical Report": [[170, "qwen2-5-omni-technical-report"]], "2. Archtecture": [[170, "archtecture"]], "2.2 \u611f\u77e5\uff08Perceivation\uff09": [[170, "perceivation"]], "2.3 \u751f\u6210\uff08Generation\uff09": [[170, "generation"]], "2.4 \u9762\u5411\u6d41\u5f0f\u7684\u8bbe\u8ba1": [[170, "id1"]], "3 \u9884\u8bad\u7ec3": [[170, "id2"]], "4 \u540e\u8bad\u7ec3\uff08Post-training\uff09": [[170, "post-training"]], "4.1 \u6570\u636e\u683c\u5f0f": [[170, "id3"]], "4.2 Thinker": [[170, "thinker"]], "4.3 Talker": [[170, "talker"]], "5.1 Evaluation of X\u2192Text": [[170, "evaluation-of-xtext"]], "5.1.1 Performance of Text\u2192Text": [[170, "performance-of-texttext"]], "5.1.2 Performance of Audio\u2192Text": [[170, "performance-of-audiotext"]], "5.1.3 Performance of Image \u2192 Text": [[170, "performance-of-image-text"]], "5.1.4 Performance of Video \u2192 Text": [[170, "performance-of-video-text"]], "5.1.5 Performance of Multimodality\u2192Text": [[170, "performance-of-multimodalitytext"]], "5.2 Evaluation of X\u2192Speech": [[170, "evaluation-of-xspeech"]], "2506.13642_Stream-Omni: Simultaneous Multimodal Interactions with Large Language-Vision-Speech Model": [[171, "stream-omni-simultaneous-multimodal-interactions-with-large-language-vision-speech-model"], [172, "stream-omni-simultaneous-multimodal-interactions-with-large-language-vision-speech-model"]], "\ud83d\udccc \u80cc\u666f\uff1a": [[171, "id1"]], "\u2757 \u73b0\u6709\u95ee\u9898\uff1a": [[171, "id2"]], "\u2705 Stream-Omni \u7684\u521b\u65b0\u70b9\uff1a": [[171, "stream-omni"]], "\ud83d\udcc8 \u6548\u679c\uff1a": [[171, "id3"]], "3. Stream-Omni": [[171, "id4"]], "3.1 Architecture": [[171, "architecture"]], "3.1.1 Vision Modality": [[171, "vision-modality"]], "3.1.2 Speech Modality": [[171, "speech-modality"]], "Speech Tokenizer": [[171, "speech-tokenizer"]], "Speech-Text Mapping": [[171, "speech-text-mapping"]], "Text Generation": [[171, "text-generation"]], "Streaming Speech Generation": [[171, "streaming-speech-generation"]], "\ud83d\ude80 Stream-Omni \u7684\u4f18\u52bf": [[171, "id5"]], "3.2 Training": [[171, "training"]], "3.2.1 Data Construction": [[171, "data-construction"], [172, "data-construction"]], "3.2.2 3-Stage Training": [[171, "stage-training"]], "3.3 Inference": [[171, "inference"]], "4.1 \u57fa\u51c6\u6d4b\u8bd5\uff08Benchmarks\uff09": [[171, "benchmarks"], [172, "benchmarks"]], "4.2 \u5bf9\u6bd4\u57fa\u7ebf\u6a21\u578b\uff08Baselines\uff09": [[171, "baselines"]], "4.3 \u6a21\u578b\u914d\u7f6e\uff08Configuration\uff09": [[171, "configuration"], [172, "configuration"]], "5. Results and Analyses": [[171, "results-and-analyses"]], "5.1 \u56fe\u50cf\u7406\u89e3\u80fd\u529b": [[171, "id7"]], "5.2 \u8bed\u97f3\u95ee\u7b54\u80fd\u529b": [[171, "id8"]], "5.3 \u89c6\u89c9\u5f15\u5bfc\u8bed\u97f3\u4ea4\u4e92": [[171, "id9"]], "5.4 \u8bed\u97f3-\u6587\u672c\u6620\u5c04\u8d28\u91cf": [[171, "id10"]], "5.5 \u8de8\u6a21\u6001\u878d\u5408\u7b56\u7565": [[171, "id11"]], "Appendix A Construction of InstructOmni": [[171, "appendix-a-construction-of-instructomni"], [172, "appendix-a-construction-of-instructomni"]], "Appendix B Construction of SpokenVisIT": [[171, "appendix-b-construction-of-spokenvisit"], [172, "appendix-b-construction-of-spokenvisit"]], "1. \u80cc\u666f\u4e0e\u6311\u6218": [[172, "id1"], [223, "id6"], [237, "id3"]], "2. \u63d0\u51fa\u7684\u89e3\u51b3\u65b9\u6848\uff1aStream-Omni": [[172, "stream-omni"]], "3. \u4f18\u52bf\u4e0e\u6210\u679c": [[172, "id2"]], "4. \u8bc4\u4f30": [[172, "id3"]], "1. \u73b0\u6709\u6a21\u578b\u5206\u7c7b\u4e0e\u7814\u7a76\u8fdb\u5c55": [[172, "id5"]], "2. \u672c\u6587\u5de5\u4f5c\u4e0e\u521b\u65b0\u70b9": [[172, "id6"]], "3. \u67b6\u6784\u6982\u8ff0\uff08\u56fe2\uff09": [[172, "id7"]], "3 Stream-Omni": [[172, "id9"]], "1. Stream-Omni \u6a21\u578b\u6982\u8ff0": [[172, "id10"]], "2. \u6a21\u578b\u67b6\u6784\uff08Architecture\uff09": [[172, "architecture"]], "2.1 \u89c6\u89c9\u6a21\u6001\u5904\u7406": [[172, "id11"]], "2.2 \u8bed\u97f3\u6a21\u6001\u5904\u7406": [[172, "id12"]], "2.3 \u6a21\u6001\u878d\u5408\u4e0e\u751f\u6210": [[172, "id13"]], "3. \u8bad\u7ec3\u7b56\u7565\uff08Training\uff09": [[172, "training"]], "4. \u6838\u5fc3\u8d21\u732e\u4e0e\u4f18\u52bf": [[172, "id14"]], "\u4e00\u3001\u6570\u636e\u6784\u5efa\uff08Data Construction\uff09": [[172, "id16"]], "\u4e8c\u3001\u4e09\u9636\u6bb5\u8bad\u7ec3\uff083-Stage Training\uff09": [[172, "stage-training"]], "\u4e09\u3001\u63a8\u7406\u8fc7\u7a0b\uff08Inference\uff09": [[172, "inference"]], "\u603b\u7ed3\uff1a\u7b2c4\u7ae0 \u5b9e\u9a8c\uff08Experiments\uff09": [[172, "id18"]], "4.2 \u57fa\u7ebf\u6a21\u578b\uff08Baselines\uff09": [[172, "baselines"]], "\u5173\u952e\u7ed3\u8bba\uff08\u901a\u8fc7\u5b9e\u9a8c\u6570\u636e\u603b\u7ed3\uff09": [[172, "id19"]], "5 Results and Analyses": [[172, "results-and-analyses"]], "1. Visual Understanding\uff08\u89c6\u89c9\u7406\u89e3\uff09": [[172, "visual-understanding"]], "2. Speech Interaction\uff08\u8bed\u97f3\u4ea4\u4e92\uff09": [[172, "speech-interaction"]], "3. Vision-grounded Speech Interaction\uff08\u89c6\u89c9\u5f15\u5bfc\u7684\u8bed\u97f3\u4ea4\u4e92\uff09": [[172, "vision-grounded-speech-interaction"]], "4. Quality of Speech-Text Mapping\uff08\u8bed\u97f3-\u6587\u672c\u6620\u5c04\u8d28\u91cf\uff09": [[172, "quality-of-speech-text-mapping"]], "5. Effect of Alignment-based Fusion\uff08\u5bf9\u9f50\u878d\u5408\u6548\u679c\uff09": [[172, "effect-of-alignment-based-fusion"]], "1. \u6784\u5efa\u80cc\u666f\u4e0e\u76ee\u6807": [[172, "id22"]], "2. \u6570\u636e\u96c6\u6784\u5efa\u8fc7\u7a0b": [[172, "id23"]], "3. \u8bc4\u4f30\u65b9\u6cd5": [[172, "id24"]], "4. \u603b\u4f53\u76ee\u6807": [[172, "id25"]], "Appendix C Case Study": [[172, "appendix-c-case-study"]], "\u603b\u7ed3\uff1aAppendix C Case Study": [[172, "id26"]], "\u5173\u952e\u8bcd\u603b\u7ed3\uff1a": [[172, "id27"]], "2301.12597_BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models": [[173, "blip-2-bootstrapping-language-image-pre-training-with-frozen-image-encoders-and-large-language-models"]], "Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models": [[173, "bootstrapping-language-image-pre-training-with-frozen-image-encoders-and-large-language-models"]], "2.1 \u7aef\u5230\u7aef\u89c6\u89c9-\u8bed\u8a00\u9884\u8bad\u7ec3": [[173, "id4"]], "2.2 \u6a21\u5757\u5316\u89c6\u89c9-\u8bed\u8a00\u9884\u8bad\u7ec3": [[173, "id5"]], "1. Q-Former \u67b6\u6784": [[173, "q-former"]], "2. \u7b2c\u4e00\u9636\u6bb5\uff1a\u89c6\u89c9-\u8bed\u8a00\u8868\u793a\u5b66\u4e60": [[173, "id7"]], "3. \u7b2c\u4e8c\u9636\u6bb5\uff1a\u89c6\u89c9\u5230\u8bed\u8a00\u7684\u751f\u6210\u5f0f\u9884\u8bad\u7ec3": [[173, "id8"]], "4. \u9884\u8bad\u7ec3\u8bbe\u7f6e": [[173, "id9"]], "4 Experiment": [[173, "experiment"]], "4.1 \u96f6\u6837\u672c\u56fe\u50cf\u5230\u6587\u672c\u751f\u6210": [[173, "id11"]], "4.2 \u56fe\u50cf\u63cf\u8ff0\u751f\u6210": [[173, "id12"]], "4.3 \u56fe\u50cf\u95ee\u7b54\uff08VQA\uff09": [[173, "vqa"]], "4.4 \u56fe\u50cf-\u6587\u672c\u68c0\u7d22": [[173, "id13"]], "5 Limitation": [[173, "limitation"]], "2308.01390_OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models": [[174, "openflamingo-an-open-source-framework-for-training-large-autoregressive-vision-language-models"]], "OpenFlamingo_ An Open-Source Framework for Training Large Autoregressive Vision-Language Models": [[174, "id1"]], "2 Related work": [[174, "related-work"]], "3 Approach": [[174, "approach"]], "3.1 \u6a21\u578b\u67b6\u6784\uff08Architecture\uff09": [[174, "architecture"]], "3.2 \u8bad\u7ec3\u6570\u636e\uff08Training data\uff09": [[174, "training-data"]], "3.3 \u8bad\u7ec3\u7ec6\u8282\uff08Training details\uff09": [[174, "training-details"]], "3.4 \u8bc4\u4f30\u65b9\u6cd5\uff08Evaluation method\uff09": [[174, "evaluation-method"]], "\u8bba\u6587\u7ae0\u8282\u603b\u7ed3\uff08\u7b2c\u56db\u90e8\u5206\uff1aResults\uff09": [[174, "id5"]], "1. \u6a21\u578b\u6027\u80fd\u6bd4\u8f83": [[174, "id6"]], "2. \u4e0a\u4e0b\u6587\u793a\u4f8b\u6570\u91cf\u5bf9\u6027\u80fd\u7684\u5f71\u54cd": [[174, "id7"]], "3. \u6a21\u578b\u89c4\u6a21\u8d8b\u52bf": [[174, "id8"]], "4. \u8bed\u8a00\u6307\u4ee4\u8c03\u4f18\u7684\u5f71\u54cd": [[174, "id9"]], "5. \u4e0e\u5fae\u8c03\u6a21\u578b\u7684\u5bf9\u6bd4": [[174, "id10"]], "5.1 \u51bb\u7ed3\u7684\u5d4c\u5165\u5411\u91cf\uff08Frozen embeddings\uff09": [[174, "frozen-embeddings"]], "5.2 VQAv2\u9a8c\u8bc1\u8d8b\u52bf\uff08VQAv2 validation trends\uff09": [[174, "vqav2-vqav2-validation-trends"]], "5.3 OpenFlamingo\u7684\u5e94\u7528\uff08Applications of OpenFlamingo\uff09": [[174, "openflamingo-applications-of-openflamingo"]], "5.4 \u9650\u5236\u4e0e\u98ce\u9669\uff08Limitations\uff09": [[174, "limitations"]], "Appendix A Extended results": [[174, "appendix-a-extended-results"]], "\u9644\u5f55A \u603b\u4f53\u5185\u5bb9\u6982\u89c8": [[174, "a"]], "\u9644\u5f55A\u8868\u683c\u4e0e\u56fe\u8868\u603b\u7ed3": [[174, "id13"]], "\u5173\u952e\u53d1\u73b0\u4e0e\u7ed3\u8bba": [[174, "id14"]], "Appendix B Additional notes on filtering MMC4": [[174, "appendix-b-additional-notes-on-filtering-mmc4"]], "Appendix C Synthetic data prompt": [[174, "appendix-c-synthetic-data-prompt"]], "Appendix D Image credits": [[174, "appendix-d-image-credits"]], "1810.04805_BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding": [[175, "bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding"]], "2.1 Unsupervised Feature-based Approaches": [[175, "unsupervised-feature-based-approaches"]], "2.2 Unsupervised Fine-tuning Approaches": [[175, "unsupervised-fine-tuning-approaches"]], "2.3 Transfer Learning from Supervised Data": [[175, "transfer-learning-from-supervised-data"]], "3 BERT": [[175, "bert"]], "3.1 Pre-training BERT": [[175, "pre-training-bert"]], "3.2 Fine-tuning BERT": [[175, "fine-tuning-bert"]], "Appendix A Additional Details for BERT": [[175, "appendix-a-additional-details-for-bert"]], "A.1 Illustration of the Pre-training Tasks": [[175, "a-1-illustration-of-the-pre-training-tasks"]], "A.2 Pre-training Procedure": [[175, "a-2-pre-training-procedure"]], "A.3 Fine-tuning Procedure": [[175, "a-3-fine-tuning-procedure"]], "A.4 Comparison of BERT and OpenAI GPT": [[175, "a-4-comparison-of-bert-and-openai-gpt"]], "18xx_GPT1: Improving Language Understanding by Generative Pre-Training": [[176, "xx-gpt1-improving-language-understanding-by-generative-pre-training"]], "3. Framework": [[176, "framework"]], "3.1 Unsupervised pre-training": [[176, "unsupervised-pre-training"]], "3.2 Supervised fine-tuning": [[176, "supervised-fine-tuning"]], "3.3 Task-specific input transformations": [[176, "task-specific-input-transformations"]], "4.1 Setup": [[176, "setup"]], "4.2 Supervised fine-tuning": [[176, "id2"]], "5 Analysis": [[176, "analysis"]], "\u5f15\u6587\u53e3\u7891": [[176, "id3"]], "\u8981\u70b9\u89e3\u8bfb": [[176, "id4"]], "19xx_GPT2: Language Models are Unsupervised Multitask Learners": [[177, "xx-gpt2-language-models-are-unsupervised-multitask-learners"]], "The Illustrated GPT-2": [[177, "the-illustrated-gpt-2"]], "\u53c2\u8003": [[177, "id2"], [233, "id3"]], "2012.00413_CPM: A Large-scale Generative Chinese Pre-trained Language Model": [[178, "cpm-a-large-scale-generative-chinese-pre-trained-language-model"]], "2302.13971_LLaMA: Open and Efficient Foundation Language Models": [[179, "llama-open-and-efficient-foundation-language-models"]], "2307.09288_Llama 2: Open Foundation and Fine-Tuned Chat Models": [[180, "llama-2-open-foundation-and-fine-tuned-chat-models"]], "2309.16609_Qwen Technical Report": [[181, "qwen-technical-report"]], "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5d1b\u8d77": [[181, "llm"]], "Qwen \u6a21\u578b\u7cfb\u5217\u4ecb\u7ecd": [[181, "qwen"]], "\u6a21\u578b\u5f00\u6e90\u60c5\u51b5": [[181, "id1"]], "2. Pretraining": [[181, "pretraining"]], "2.1 \u6570\u636e": [[181, "id2"]], "2.2 \u5206\u8bcd\uff08Tokenization\uff09": [[181, "tokenization"]], "2.3 \u6a21\u578b\u67b6\u6784": [[181, "id3"]], "2.4 \u8bad\u7ec3\u8fc7\u7a0b": [[181, "id4"]], "2.5 \u4e0a\u4e0b\u6587\u957f\u5ea6\u6269\u5c55": [[181, "id5"]], "2.6 \u5b9e\u9a8c\u7ed3\u679c": [[181, "id6"]], "3. Alignment": [[181, "alignment"]], "\ud83c\udf1f \u6574\u4f53\u6982\u8ff0": [[181, "id7"]], "\ud83e\udde0 3.1 \u76d1\u7763\u5fae\u8c03 SFT": [[181, "sft"]], "\ud83c\udfaf 3.2 \u4eba\u7c7b\u53cd\u9988\u5f3a\u5316\u5b66\u4e60 RLHF": [[181, "rlhf"]], "\ud83d\udcca 3.3 \u81ea\u52a8\u8bc4\u4f30\u4e0e\u4eba\u5de5\u8bc4\u4f30": [[181, "id8"]], "\ud83e\udd16 3.4 \u5de5\u5177\u8c03\u7528\u3001\u4ee3\u7801\u89e3\u91ca\u5668\u4e0e Agent \u80fd\u529b": [[181, "agent"]], "4. CODE-QWEN: SPECIALIZED MODEL FOR CODING": [[181, "code-qwen-specialized-model-for-coding"]], "\u2705 \u4ec0\u4e48\u662f CODE-QWEN\uff1f": [[181, "code-qwen"]], "\ud83d\udcca \u6a21\u578b\u8bc4\u4f30\u8868\u73b0": [[181, "id11"]], "\ud83d\udd0d \u603b\u7ed3\u91cd\u70b9": [[181, "id12"]], "5. MATH-QWEN: SPECIALIZED MODEL FOR MATHEMATICS REASONING": [[181, "math-qwen-specialized-model-for-mathematics-reasoning"]], "\u8bad\u7ec3\u65b9\u5f0f\uff1a": [[181, "id13"]], "\u6570\u5b66\u80fd\u529b\u8bc4\u4f30\uff1a": [[181, "id14"]], "6.1 \u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u53d1\u5c55": [[181, "id15"]], "6.2 \u5bf9\u9f50\uff08Alignment\uff09": [[181, "id16"]], "6.3 \u5de5\u5177\u8c03\u7528\u4e0e\u667a\u80fd\u4f53\uff08Agents\uff09": [[181, "agents"]], "6.4 \u7f16\u7a0b\u80fd\u529b": [[181, "id17"]], "6.5 \u6570\u5b66\u80fd\u529b": [[181, "id18"]], "A.1 MORE TRAINING DETAILS": [[181, "a-1-more-training-details"]], "A.2 EVALUATION": [[181, "a-2-evaluation"]], "A.2.1 AUTOMATIC EVALUATION": [[181, "a-2-1-automatic-evaluation"]], "A.2.2 HUMAN EVALUATION": [[181, "a-2-2-human-evaluation"]], "2310.19341_Skywork: A More Open Bilingual Foundation Model": [[182, "skywork-a-more-open-bilingual-foundation-model"]], "2. Skywork \u6a21\u578b\u6982\u8ff0": [[182, "skywork"]], "3. \u5f00\u653e\u6027\u8bbe\u8ba1": [[182, "id3"]], "4. \u4e2d\u82f1\u6587\u53cc\u8bed\u80fd\u529b": [[182, "id4"]], "5. \u6027\u80fd\u8bc4\u4f30": [[182, "id5"]], "6. \u6f5c\u5728\u5e94\u7528": [[182, "id6"]], "7. \u672a\u6765\u5de5\u4f5c": [[182, "id7"]], "2.1 \u4e24\u9636\u6bb5\u9884\u8bad\u7ec3": [[182, "id9"]], "2.2 \u8bad\u7ec3\u8fc7\u7a0b\u76d1\u63a7": [[182, "id10"]], "3 Pre-training\uff08\u9884\u8bad\u7ec3\uff09\u603b\u7ed3\uff1a": [[182, "id12"]], "3.1 SkyPile Corpus\uff08SkyPile\u8bed\u6599\u5e93\uff09": [[182, "skypile-corpus-skypile"]], "3.2 Training Data Composition\uff08\u8bad\u7ec3\u6570\u636e\u7ec4\u6210\uff09": [[182, "training-data-composition"]], "3.3 Tokenizer\uff08\u8bcd\u8868\uff09": [[182, "tokenizer"]], "3.4 Architecture\uff08\u67b6\u6784\uff09": [[182, "architecture"]], "3.5 Infrastructure\uff08\u57fa\u7840\u8bbe\u65bd\uff09": [[182, "infrastructure"]], "3.6 Training Details\uff08\u8bad\u7ec3\u7ec6\u8282\uff09": [[182, "training-details"]], "3.6.2 Stage-2 Pre-training": [[182, "stage-2-pre-training"]], "1. \u57fa\u7ebf\u6a21\u578b\u5bf9\u6bd4\uff08Baselines\uff09": [[182, "baselines"]], "2. \u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\uff08Benchmark Evaluation\uff09": [[182, "benchmark-evaluation"]], "3. \u8bed\u8a00\u5efa\u6a21\u8bc4\u4f30\uff08Language Modeling Results\uff09": [[182, "language-modeling-results"]], "(1) \u8bed\u8a00\u5efa\u6a21\u4f5c\u4e3a\u57fa\u51c6\u6d4b\u8bd5\u66ff\u4ee3\u65b9\u6848": [[182, "id14"]], "(2) \u591a\u6837\u5316\u6d4b\u8bd5\u96c6\u7684\u6784\u5efa": [[182, "id15"]], "(3) \u8bc4\u4f30\u7ed3\u679c": [[182, "id16"]], "5.1 \u9886\u57df\u5185\u6570\u636e\u9884\u8bad\u7ec3\u7684\u6548\u679c": [[182, "id18"]], "5.2 \u9886\u57df\u5185\u6570\u636e\u9884\u8bad\u7ec3\u662f\u5426\u5e38\u89c1\uff1f": [[182, "id19"]], "5.3 \u9884\u8bad\u7ec3\u4e0e\u6709\u76d1\u7763\u5fae\u8c03\u7684\u8fb9\u754c\u6a21\u7cca": [[182, "id20"]], "6 Limitation": [[182, "limitation"]], "Appendix A Details on GPT-7B vs. LLaMA-7B Experiment": [[182, "appendix-a-details-on-gpt-7b-vs-llama-7b-experiment"]], "Appendix B Preliminary Experiments on Distributed Training": [[182, "appendix-b-preliminary-experiments-on-distributed-training"]], "Appendix C More Benchmark Results": [[182, "appendix-c-more-benchmark-results"]], "Appendix D Details on LM Test Sets": [[182, "appendix-d-details-on-lm-test-sets"]], "2401.14196_DeepSeek-Coder: When the Large Language Model Meets Programming \u2013 The Rise of Code Intelligence": [[183, "deepseek-coder-when-the-large-language-model-meets-programming-the-rise-of-code-intelligence"]], "2404.06395_MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies": [[184, "minicpm-unveiling-the-potential-of-small-language-models-with-scalable-training-strategies"]], "5. Two Stage Pre-training Strategy": [[184, "two-stage-pre-training-strategy"]], "6. Model": [[184, "model"]], "7 MiniCPM Family": [[184, "minicpm-family"]], "7.1 MiniCPM-DPO": [[184, "minicpm-dpo"]], "7.2 MiniCPM-128K": [[184, "minicpm-128k"]], "7.3 MiniCPM-MoE": [[184, "minicpm-moe"]], "2405.04434_DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model": [[185, "deepseek-v2-a-strong-economical-and-efficient-mixture-of-experts-language-model"]], "2406.12793_ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools": [[186, "chatglm-a-family-of-large-language-models-from-glm-130b-to-glm-4-all-tools"]], "2407.10671_Qwen2 Technical Report": [[187, "qwen2-technical-report"]], "2. Tokenizer & Model": [[187, "tokenizer-model"]], "2.1 \u5206\u8bcd\u5668": [[187, "id1"]], "2.2 \u6a21\u578b\u7ed3\u6784": [[187, "id2"]], "2.2.1 Qwen2 Dense \u6a21\u578b": [[187, "qwen2-dense"]], "2.2.2 Qwen2 MoE \u6a21\u578b\uff08\u4e13\u5bb6\u6a21\u578b\uff09": [[187, "qwen2-moe"]], "2.2.3 \u6a21\u578b\u914d\u7f6e": [[187, "id3"]], "3. Pre-training": [[187, "pre-training"], [188, "pre-training"], [189, "pre-training"]], "\u9884\u8bad\u7ec3\u6570\u636e\u6539\u8fdb": [[187, "id4"]], "\u4e8c\u3001\u957f\u4e0a\u4e0b\u6587\u8bad\u7ec3": [[187, "id5"]], "4. Post-training": [[187, "post-training"], [188, "post-training"], [189, "post-training"]], "\u540e\u8bad\u7ec3\u7684\u76ee\u6807": [[187, "id6"]], "\ud83d\udcca \u6570\u636e\u6784\u5efa\uff084.1\uff09": [[187, "id7"]], "4.2 SUPERVISED FINE-TUNING": [[187, "supervised-fine-tuning"]], "4.3 \u4eba\u7c7b\u53cd\u9988\u5f3a\u5316\u5b66\u4e60\uff08RLHF\uff09": [[187, "rlhf"]], "\ud83c\udf1f \u603b\u4f53\u8bc4\u4f30\u65b9\u5f0f\uff1a": [[187, "id8"]], "5.1 BASE LANGUAGE MODELS": [[187, "base-language-models"]], "5.2 INSTRUCTION-TUNED MODEL": [[187, "instruction-tuned-model"]], "2412.15115_Qwen2.5": [[188, "qwen2-5"]], "\u80cc\u666f\u4e0e\u8d8b\u52bf": [[188, "id1"]], "Qwen2.5 \u7684\u53d1\u5e03\u4eae\u70b9": [[188, "id2"]], "2. Architecture and Tokenizer": [[188, "architecture-and-tokenizer"]], "\u7a20\u5bc6\u6a21\u578b\u7ed3\u6784\uff1a": [[188, "id3"]], "MoE \u6a21\u578b\u7ed3\u6784\uff1a": [[188, "moe"]], "\u5206\u8bcd\u5668\uff1a": [[188, "id4"]], "1. \u9884\u8bad\u7ec3\u6570\u636e": [[188, "id5"]], "2. \u8d85\u53c2\u6570\u4f18\u5316\uff08Scaling Laws\uff09": [[188, "scaling-laws"]], "3. \u957f\u4e0a\u4e0b\u6587\u9884\u8bad\u7ec3": [[188, "id6"]], "\u4e24\u5927\u6838\u5fc3\u6539\u8fdb\uff1a": [[188, "id7"]], "4.1 Supervised Fine-tuning": [[188, "supervised-fine-tuning"]], "4.2 Offline Reinforcement Learning": [[188, "offline-reinforcement-learning"]], "4.3 Online Reinforcement Learning": [[188, "online-reinforcement-learning"]], "4.4 Long Context Fine-tuning": [[188, "long-context-fine-tuning"]], "5.1 Base Models": [[188, "base-models"]], "5.2 Instruction-tuned Model": [[188, "instruction-tuned-model"]], "5.2.1 Open Benchmark Evaluation": [[188, "open-benchmark-evaluation"]], "5.2.2 In-house Automatic Evaluation": [[188, "in-house-automatic-evaluation"]], "5.2.3 \u5956\u52b1\u6a21\u578b\u8bc4\u4f30\uff08Reward Model\uff09": [[188, "reward-model"]], "5.2.4 \u957f\u4e0a\u4e0b\u6587\u80fd\u529b\uff08Long Context Capabilities\uff09": [[188, "long-context-capabilities"]], "2505.09388_Qwen3": [[189, "qwen3"]], "\ud83c\udf10 \u80cc\u666f\u4e0e\u52a8\u673a\uff1a": [[189, "id1"]], "\ud83e\udde0 Qwen3 \u7b80\u4ecb\uff1a": [[189, "id2"]], "\ud83d\udd27 \u6838\u5fc3\u521b\u65b0\uff1a": [[189, "id3"]], "\ud83c\udfd7\ufe0f \u8bad\u7ec3\u6d41\u7a0b\uff1a": [[189, "id4"]], "\ud83d\udcca \u6027\u80fd\u8868\u73b0\uff1a": [[189, "id5"]], "\ud83d\udcd8 \u63a5\u4e0b\u6765\u7684\u5185\u5bb9\uff1a": [[189, "id6"]], "3.1 Pre-training Data": [[189, "pre-training-data"]], "3.2 Pre-training Stage": [[189, "pre-training-stage"]], "3.3 Pre-training Evaluation": [[189, "pre-training-evaluation"]], "4.1 Long-CoT Cold Start\uff08\u57fa\u7840\u63a8\u7406\u9884\u8bad\u7ec3\uff09": [[189, "long-cot-cold-start"]], "4.2 Reasoning RL\uff08Reasoning RL\uff09": [[189, "reasoning-rl-reasoning-rl"]], "4.3 Thinking Mode Fusion": [[189, "thinking-mode-fusion"]], "4.4 General RL": [[189, "general-rl"]], "4.5 Strong-to-Weak Distillation": [[189, "strong-to-weak-distillation"]], "4.6 Post-training Evaluation": [[189, "post-training-evaluation"]], "\ud83e\uddea \u4e00\u3001\u8bc4\u4f30\u65b9\u5f0f": [[189, "id7"]], "\ud83d\udcca \u4e8c\u3001\u8bc4\u4f30\u7ed3\u679c\u603b\u7ed3": [[189, "id8"]], "4.7 Discussion": [[189, "discussion"]], "\u673a\u5668\u5b66\u4e60": [[190, "id2"]], "ML Vision": [[190, "ml-vision"]], "ML": [[190, "ml"]], "1506.02640_You Only Look Once: Unified, Real-Time Object Detection": [[191, "you-only-look-once-unified-real-time-object-detection"]], "1612.08242_YOLO9000: Better, Faster, Stronger": [[192, "yolo9000-better-faster-stronger"]], "1804.02767_YOLOv3": [[193, "yolov3"]], "2004.10934_YOLOv4: Optimal Speed and Accuracy of Object Detection": [[194, "yolov4-optimal-speed-and-accuracy-of-object-detection"]], "2205.00159_SVTR: Scene Text Recognition with a Single Visual Model": [[195, "svtr-scene-text-recognition-with-a-single-visual-model"]], "2. Method": [[195, "method"]], "2.1 Overall Architecture": [[195, "overall-architecture"]], "2.2 Progressive Overlapping Patch Embedding": [[195, "progressive-overlapping-patch-embedding"]], "2.3 Mixing Block": [[195, "mixing-block"]], "2.4 Merging": [[195, "merging"]], "2.5 Combining and Prediction": [[195, "combining-and-prediction"]], "2.6 Architecture Variants": [[195, "architecture-variants"]], "3.1 Datasets": [[195, "datasets"]], "3.2 Implementation Details": [[195, "implementation-details"]], "3.4 Comparison with State-of-the-Art": [[195, "comparison-with-state-of-the-art"]], "3.5 Visualization Analysis": [[195, "visualization-analysis"]], "2207.02696_YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors": [[196, "yolov7-trainable-bag-of-freebies-sets-new-state-of-the-art-for-real-time-object-detectors"]], "Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection": [[197, "grounding-dino-marrying-dino-with-grounded-pre-training-for-open-set-object-detection"]], "2304.08485_Visual Instruction Tuning": [[198, "visual-instruction-tuning"]], "2402.13616_YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information": [[199, "yolov9-learning-what-you-want-to-learn-using-programmable-gradient-information"]], "2405.14458_YOLOv10: Real-Time End-to-End Object Detection": [[200, "yolov10-real-time-end-to-end-object-detection"]], "2411.15858_SVTRv2: CTC Beats Encoder-Decoder Models in Scene Text Recognition": [[201, "svtrv2-ctc-beats-encoder-decoder-models-in-scene-text-recognition"]], "3. Methods": [[201, "methods"]], "3.1 Multi-Scale Resizing": [[201, "multi-scale-resizing"]], "3.2 Visual Feature Extraction": [[201, "visual-feature-extraction"]], "3.3 Feature Rearranging Module": [[201, "feature-rearranging-module"]], "3.4 Semantic Guidance Module": [[201, "semantic-guidance-module"]], "3.5 Optimization Objective": [[201, "optimization-objective"]], "4.1 Datasets and Implementation Details": [[201, "datasets-and-implementation-details"]], "4.2 Ablation Study": [[201, "ablation-study"]], "4.3 Comparison with State-of-the-arts": [[201, "comparison-with-state-of-the-arts"]], "8. More detail of real-world datasets": [[201, "more-detail-of-real-world-datasets"]], "2112.09332_WebGPT: Browser-assisted question-answering with human feedback": [[202, "webgpt-browser-assisted-question-answering-with-human-feedback"]], "2203.11147_GopherCite: Teaching language models to support answers with verified quotes": [[203, "gophercite-teaching-language-models-to-support-answers-with-verified-quotes"]], "2304.09848_Generative_Search: Evaluating Verifiability in Generative Search Engines": [[204, "generative-search-evaluating-verifiability-in-generative-search-engines"]], "2305.14251_FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation": [[205, "factscore-fine-grained-atomic-evaluation-of-factual-precision-in-long-form-text-generation"]], "2305.14627_ALCE: Enabling Large Language Models to Generate Text with Citations": [[206, "alce-enabling-large-language-models-to-generate-text-with-citations"]], "NLI \u5728\u5f15\u7528\u8d28\u91cf\u8bc4\u4f30\u4e2d\u7684\u5e94\u7528": [[206, "nli"]], "\u8bba\u6587\u4e2d\u7528\u7684prompt": [[206, "prompt"]], "2307.02185_Citation: A Key to Building Responsible and Accountable Large Language Models": [[207, "citation-a-key-to-building-responsible-and-accountable-large-language-models"]], "2307.16883_HAGRID: A Human-LLM Collaborative Dataset for Generative Information-Seeking with Attribution": [[208, "hagrid-a-human-llm-collaborative-dataset-for-generative-information-seeking-with-attribution"]], "RAG": [[209, "rag"]], "2005.11401_Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks": [[210, "retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks"]], "2312.10997_Retrieval-Augmented Generation for Large Language Models: A Survey": [[211, "retrieval-augmented-generation-for-large-language-models-a-survey"]], "II. Overview of RAG": [[211, "ii-overview-of-rag"]], "II-A Naive RAG": [[211, "ii-a-naive-rag"]], "II-B Advanced RAG": [[211, "ii-b-advanced-rag"]], "II-C Modular RAG": [[211, "ii-c-modular-rag"]], "II-C1 New Modules": [[211, "ii-c1-new-modules"]], "II-C2 New Patterns": [[211, "ii-c2-new-patterns"]], "II-D RAG vs Fine-tuning": [[211, "ii-d-rag-vs-fine-tuning"]], "III. Retrieval": [[211, "iii-retrieval"]], "III-A Retrieval Source": [[211, "iii-a-retrieval-source"]], "III-B Indexing Optimization": [[211, "iii-b-indexing-optimization"]], "III-C Query Optimization": [[211, "iii-c-query-optimization"]], "III-D Embedding": [[211, "iii-d-embedding"]], "III-E Adapter": [[211, "iii-e-adapter"]], "IV. Generation": [[211, "iv-generation"]], "IV-A Context Curation": [[211, "iv-a-context-curation"]], "IV-B LLM Fine-tuning": [[211, "iv-b-llm-fine-tuning"]], "V. Augmentation process in RAG": [[211, "v-augmentation-process-in-rag"]], "V-A Iterative Retrieval": [[211, "v-a-iterative-retrieval"]], "V-B Recursive Retrieval": [[211, "v-b-recursive-retrieval"]], "V-C Adaptive Retrieval": [[211, "v-c-adaptive-retrieval"]], "VI. Task and Evaluation": [[211, "vi-task-and-evaluation"]], "VI-A Downstream Task": [[211, "vi-a-downstream-task"]], "VI-B Evaluation Target": [[211, "vi-b-evaluation-target"]], "VI-C Evaluation Aspects": [[211, "vi-c-evaluation-aspects"]], "VI-D Evaluation Benchmarks and Tools": [[211, "vi-d-evaluation-benchmarks-and-tools"]], "VII. Discussion and Future Prospects": [[211, "vii-discussion-and-future-prospects"]], "VII-A RAG vs Long Context": [[211, "vii-a-rag-vs-long-context"]], "VII-B RAG Robustness": [[211, "vii-b-rag-robustness"]], "VII-C Hybrid Approaches": [[211, "vii-c-hybrid-approaches"]], "VII-D Scaling laws of RAG": [[211, "vii-d-scaling-laws-of-rag"]], "VII-E Production-Ready RAG": [[211, "vii-e-production-ready-rag"]], "VII-F Multi-modal RAG": [[211, "vii-f-multi-modal-rag"]], "2401.15884_CRAG: Corrective Retrieval Augmented Generation": [[212, "crag-corrective-retrieval-augmented-generation"]], "2403.14403_Adaptive-RAG": [[213, "adaptive-rag"]], "2404.16130_GraphRAG: From Local to Global: A GraphRAG Approach to Query-Focused Summarization": [[214, "graphrag-from-local-to-global-a-graphrag-approach-to-query-focused-summarization"]], "2.1 RAG\u65b9\u6cd5\u4e0e\u7cfb\u7edf": [[214, "rag"]], "2.2 \u77e5\u8bc6\u56fe\u8c31\u5728LLM\u4e0eRAG\u4e2d\u7684\u5e94\u7528": [[214, "llmrag"]], "2.3 \u81ea\u9002\u5e94\u57fa\u51c6\u6d4b\u8bd5": [[214, "id2"]], "2.4 RAG\u8bc4\u4f30\u6807\u51c6": [[214, "id3"]], "3.1 GraphRAG \u5de5\u4f5c\u6d41\u7a0b": [[214, "graphrag"]], "3.2 \u5168\u5c40\u7406\u89e3\u95ee\u9898\u751f\u6210": [[214, "id4"]], "3.3 \u5168\u5c40\u7406\u89e3\u8bc4\u4f30\u6807\u51c6": [[214, "id5"]], "4.1 \u5b9e\u9a8c1": [[214, "id7"]], "4.1.1 \u6570\u636e\u96c6": [[214, "id8"]], "4.1.2 \u5b9e\u9a8c\u6761\u4ef6": [[214, "id9"]], "4.1.3 \u5b9e\u9a8c\u914d\u7f6e": [[214, "id10"]], "4.2 \u5b9e\u9a8c2": [[214, "id11"]], "\u65b9\u6cd5\uff1a": [[214, "id12"]], "\u8bc4\u4f30\u6307\u6807\uff1a": [[214, "id13"]], "5.1 \u5b9e\u9a8c\u4e00\uff1a\u4e0d\u540c\u65b9\u6cd5\u5728\u6458\u8981\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u6bd4\u8f83": [[214, "id15"]], "\u56fe\u6784\u5efa\u4e0e\u6458\u8981\u5c42\u6b21": [[214, "id16"]], "\u6027\u80fd\u6bd4\u8f83": [[214, "id17"]], "5.2 \u5b9e\u9a8c\u4e8c\uff1a\u57fa\u4e8e\u58f0\u660e\u7684\u6307\u6807\u8bc4\u4f30": [[214, "id18"]], "\u58f0\u660e\u6570\u91cf\uff08Comprehensiveness\uff09": [[214, "comprehensiveness"]], "\u7c07\u6570\u91cf\uff08Diversity\uff09": [[214, "diversity"]], "\u5bf9\u6bd4\u4e00\u81f4\u6027\u5206\u6790": [[214, "id19"]], "6.1 \u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u6027": [[214, "id21"]], "6.2 \u672a\u6765\u5de5\u4f5c": [[214, "id22"]], "\u66f4\u5e7f\u6cdb\u7684\u5f71\u54cd": [[214, "id23"]], "Appendix A Entity and Relationship Extraction Approach": [[214, "appendix-a-entity-and-relationship-extraction-approach"]], "1. \u5b9e\u4f53\u4e0e\u5173\u7cfb\u62bd\u53d6\u65b9\u6cd5": [[214, "id24"]], "2. \u81ea\u6211\u53cd\u601d\uff08Self-Reflection\uff09\u6280\u672f": [[214, "self-reflection"]], "3. \u5206\u5757\u5927\u5c0f\u4e0e\u62bd\u53d6\u6548\u679c\u7684\u5173\u7cfb": [[214, "id25"]], "4. \u5b9e\u9a8c\u7ed3\u679c\uff08\u56fe3\uff09": [[214, "id26"]], "Appendix B Example Community Detection": [[214, "appendix-b-example-community-detection"]], "Appendix C Context Window Selection": [[214, "appendix-c-context-window-selection"]], "Appendix D Example Answer Comparison": [[214, "appendix-d-example-answer-comparison"]], "Appendix E System Prompts": [[214, "appendix-e-system-prompts"]], "E.1 \u5b9e\u4f53\u5b9e\u4f8b\u751f\u6210\uff08Element Instance Generation\uff09": [[214, "e-1-element-instance-generation"]], "\u82f1\u6587\u7248": [[214, "id28"], [214, "id30"], [214, "id32"], [214, "id34"]], "\u4e2d\u6587\u7248": [[214, "id29"], [214, "id31"], [214, "id33"], [214, "id35"]], "E.2 \u793e\u533a\u6458\u8981\u751f\u6210\uff08Community Summary Generation\uff09": [[214, "e-2-community-summary-generation"]], "E.3 \u793e\u533a\u95ee\u9898\u56de\u7b54\u751f\u6210\uff08Community Answer Generation\uff09": [[214, "e-3-community-answer-generation"]], "E.4 \u5168\u5c40\u95ee\u9898\u56de\u7b54\u751f\u6210\uff08Global Answer Generation\uff09": [[214, "e-4-global-answer-generation"]], "Appendix F Evaluation Prompts": [[214, "appendix-f-evaluation-prompts"]], "F.1 Relative Assessment Prompt": [[214, "f-1-relative-assessment-prompt"]], "F.2 Relative Assessment Metrics": [[214, "f-2-relative-assessment-metrics"]], "\u8bc4\u5206\u6807\u51c6-\u82f1\u6587": [[214, "id36"]], "\u8bc4\u5206\u6807\u51c6-\u4e2d\u6587": [[214, "id37"]], "Appendix G Statistical Analysis": [[214, "appendix-g-statistical-analysis"]], "\u7edf\u8ba1\u65b9\u6cd5\uff1a": [[214, "id38"]], "\u4e3b\u8981\u7ed3\u679c\u603b\u7ed3\uff1a": [[214, "id39"]], "\u603b\u4f53\u8d8b\u52bf\uff1a": [[214, "id40"]], "\u91cd\u8981\u7ed3\u8bba\uff1a": [[214, "id41"]], "2405.16506_GRAG: Graph Retrieval-Augmented Generation": [[215, "grag-graph-retrieval-augmented-generation"], [239, "grag-graph-retrieval-augmented-generation"]], "2406.13213_Multi-Meta-RAG: Improving RAG for Multi-Hop Queries using Database Filtering with LLM-Extracted Metadata": [[216, "multi-meta-rag-improving-rag-for-multi-hop-queries-using-database-filtering-with-llm-extracted-metadata"]], "2410.05779_LightRAG: Simple and Fast Retrieval-Augmented Generation": [[217, "lightrag-simple-and-fast-retrieval-augmented-generation"]], "2 Retrieval-Augmented Generation": [[217, "retrieval-augmented-generation"]], "3 The LightRAG\u00a0Architecture": [[217, "the-lightrag-architecture"]], "\u4e00\u3001LightRAG\u67b6\u6784\u6982\u8ff0": [[217, "lightrag"]], "\u4e8c\u3001\u57fa\u4e8e\u56fe\u7684\u6587\u672c\u7d22\u5f15\uff08Graph-based Text Indexing\uff09": [[217, "graph-based-text-indexing"]], "\u4e09\u3001\u53cc\u5c42\u68c0\u7d22\u8303\u5f0f\uff08Dual-level Retrieval Paradigm\uff09": [[217, "dual-level-retrieval-paradigm"]], "\u56db\u3001\u68c0\u7d22\u589e\u5f3a\u7684\u7b54\u6848\u751f\u6210\uff08Retrieval-Augmented Answer Generation\uff09": [[217, "retrieval-augmented-answer-generation"]], "\u4e94\u3001\u590d\u6742\u5ea6\u5206\u6790": [[217, "id2"]], "1. \u5b9e\u9a8c\u8bbe\u7f6e\uff084.1 Experimental Settings\uff09": [[217, "experimental-settings"]], "\u95ee\u9898\u751f\u6210": [[217, "id5"]], "\u5bf9\u6bd4\u57fa\u7ebf\u65b9\u6cd5": [[217, "id6"]], "2. LightRAG \u4e0e\u73b0\u6709 RAG \u65b9\u6cd5\u7684\u5bf9\u6bd4\uff084.2 RQ1\uff09": [[217, "lightrag-rag-4-2-rq1"]], "3. \u6d88\u878d\u5b9e\u9a8c\uff084.3 RQ2\uff09": [[217, "rq2"]], "4.4 Case Study (RQ3)": [[217, "case-study-rq3"]], "4.4 \u6848\u4f8b\u7814\u7a76\uff08RQ3\uff09\u603b\u7ed3\uff1a": [[217, "rq3"]], "4.5 \u6a21\u578b\u6210\u672c\u4e0e\u9002\u5e94\u6027\u5206\u6790\uff08RQ4\uff09\u603b\u7ed3\uff1a": [[217, "rq4"]], "\u603b\u4f53\u7ed3\u8bba\uff1a": [[217, "id9"]], "\u7b2c5\u7ae0 \u76f8\u5173\u5de5\u4f5c\uff08\u603b\u7ed3\uff09": [[217, "id10"]], "5.1 \u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09": [[217, "rag"]], "5.2 \u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u56fe\u7ed3\u6784\u7684\u7ed3\u5408": [[217, "id11"]], "7 Appendix": [[217, "appendix"]], "2410.10450_KBLaM: Knowledge Base augmented Language Model": [[218, "kblam-knowledge-base-augmented-language-model"]], "Self-attention layer": [[218, "self-attention-layer"]], "4. Augmenting LLM with the KB": [[218, "augmenting-llm-with-the-kb"]], "Knowledge tokens": [[218, "knowledge-tokens"]], "Rectangular Attention: Injecting knowledge token into prompt tokens": [[218, "rectangular-attention-injecting-knowledge-token-into-prompt-tokens"]], "KB length generalization through attention score scaling": [[218, "kb-length-generalization-through-attention-score-scaling"]], "5. KB instruction tuning": [[218, "kb-instruction-tuning"]], "6.1 EXPERIMENT SETTING": [[218, "experiment-setting"]], "6.2 EXPERIMENT RESULTS": [[218, "experiment-results"]], "7. CONCLUSION": [[218, "conclusion"]], "8. LIMITATIONS AND FUTURE WORK": [[218, "limitations-and-future-work"]], "Appendix B Ablation study": [[218, "appendix-b-ablation-study"]], "Appendix C Sample KB": [[218, "appendix-c-sample-kb"]], "SAMPLE Q&A": [[218, "sample-q-a"]], "PROMPT": [[218, "prompt"]], "PROMPT FOR SYNTHETIC KB GENERATION": [[218, "prompt-for-synthetic-kb-generation"]], "Prompt for open-ended Q&A generation": [[218, "prompt-for-open-ended-q-a-generation"]], "PROMPT FOR GPT EVALUATION OF OPEN-ENDED Q&A": [[218, "prompt-for-gpt-evaluation-of-open-ended-q-a"]], "PROMPT FOR LLAMA EVALUATION": [[218, "prompt-for-llama-evaluation"]], "QUESTION TEMPLATE": [[218, "question-template"]], "SAMPLE OUTPUT": [[218, "sample-output"]], "SYNTHETIC KB": [[218, "synthetic-kb"]], "ENRON": [[218, "enron"]], "2504.03137_LightPROF: A Lightweight Reasoning Framework for Large Language Model on Knowledge Graph": [[219, "lightprof-a-lightweight-reasoning-framework-for-large-language-model-on-knowledge-graph"]], "Introduction": [[219, "introduction"]], "Related Work": [[219, "related-work"]], "LLM Prompt Engineering": [[219, "llm-prompt-engineering"]], "KG-based LLM Reasoning": [[219, "kg-based-llm-reasoning"]], "Preliminaries": [[219, "preliminaries"]], "1. Knowledge Graph (KG)": [[219, "knowledge-graph-kg"]], "2. Anchor Entities": [[219, "anchor-entities"]], "3. Relation Link": [[219, "relation-link"]], "4. Reasoning Path": [[219, "reasoning-path"]], "Stage1: Reasoning Graph Retrieval": [[219, "stage1-reasoning-graph-retrieval"]], "1. \u8bed\u4e49\u63d0\u53d6(Semantic Extraction)": [[219, "semantic-extraction"]], "2. \u5173\u7cfb\u68c0\u7d22(Relation Retrieval)": [[219, "relation-retrieval"]], "3. \u63a8\u7406\u56fe\u91c7\u6837(Reasoning Graph Sampling)": [[219, "reasoning-graph-sampling"]], "Stage2: Knowledge Embedding": [[219, "stage2-knowledge-embedding"]], "1. \u5b9a\u4e49\u63a8\u7406\u56fe(Reasoning Graph)": [[219, "reasoning-graph"]], "2. \u83b7\u53d6\u4e09\u5143\u7ec4\u7684\u5d4c\u5165": [[219, "id2"]], "3. \u7ed3\u6784\u4fe1\u606f\u7f16\u7801": [[219, "id3"]], "4. \u6587\u672c\u4fe1\u606f\u878d\u5408(Fusion)": [[219, "fusion"]], "5. \u6700\u7ec8\u878d\u5408": [[219, "id4"]], "Stage3: Knowledge Prompts Mixed Reasoning": [[219, "stage3-knowledge-prompts-mixed-reasoning"]], "Experiments": [[219, "experiments"]], "Conclusion": [[219, "conclusion"]], "GraphRAG \u5b98\u65b9\u6587\u6863": [[220, "graphrag"]], "Indexing": [[220, "indexing"]], "> Indexing Architecture": [[220, "indexing-architecture"]], "> Indexing Dataflow": [[220, "indexing-dataflow"]], "> Prompt Tuning": [[220, "prompt-tuning"]], "Query": [[220, "query"]], "\u8bba\u6587": [[221, "id2"]], "\u6570\u636e\u96c6&\u6570\u636e\u84b8\u998f": [[222, "id3"]], "3D": [[222, "d"]], "2003.08934_NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis": [[223, "nerf-representing-scenes-as-neural-radiance-fields-for-view-synthesis"]], "\ud83c\udf1f\u6838\u5fc3\u601d\u60f3\uff1a": [[223, "id1"], [223, "id7"]], "\ud83d\udcf8\u600e\u4e48\u751f\u6210\u65b0\u89c6\u89d2\u56fe\u7247\uff08\u5373\u6e32\u67d3\u8fc7\u7a0b\uff09\uff1a": [[223, "id2"]], "\ud83c\udfaf\u600e\u4e48\u8bad\u7ec3\u8fd9\u4e2a\u6a21\u578b\uff1a": [[223, "id3"]], "\ud83e\udde0\u6280\u672f\u4eae\u70b9\uff1a": [[223, "id4"]], "\u2705\u4f18\u70b9\uff1a": [[223, "id5"]], "2. \u795e\u7ecf3D\u5f62\u72b6\u8868\u793a": [[223, "d"]], "3. \u65b0\u89c6\u89d2\u5408\u6210\uff08View Synthesis\uff09": [[223, "view-synthesis"]], "3. Neural Radiance Field Scene Representation": [[223, "neural-radiance-field-scene-representation"]], "4. Volume Rendering with Radiance Fields": [[223, "volume-rendering-with-radiance-fields"]], "\ud83d\udccc\u8be6\u7ec6\u89e3\u91ca\uff1a": [[223, "id8"]], "5. Optimizing a Neural Radiance Field": [[223, "optimizing-a-neural-radiance-field"]], "1. \u4e3a\u4ec0\u4e48\u8981\u4f18\u5316\uff1f": [[223, "id9"]], "2. \u6539\u8fdb\u4e00\uff1a\u4f4d\u7f6e\u7f16\u7801\uff08Positional Encoding\uff09": [[223, "positional-encoding"]], "3. \u6539\u8fdb\u4e8c\uff1a\u5206\u5c42\u4f53\u79ef\u91c7\u6837\uff08Hierarchical Sampling\uff09": [[223, "hierarchical-sampling"]], "4. \u8bad\u7ec3\u7ec6\u8282": [[223, "id10"]], "6. Result": [[223, "result"]], "2203.08586: Deep vanishing point detection: Geometric priors make dataset variations vanish": [[224, "deep-vanishing-point-detection-geometric-priors-make-dataset-variations-vanish"]], "\u6982\u5ff5": [[224, "id1"]], "\u2705 \u57fa\u4e8e\u51e0\u4f55\u7684\u6d88\u5931\u70b9\u68c0\u6d4b(Geometry-based vanishing point detection)": [[224, "geometry-based-vanishing-point-detection"]], "\u2705 \u57fa\u4e8e\u5b66\u4e60\u7684\u6d88\u5931\u70b9\u68c0\u6d4b(Learning-based vanishing point detection)": [[224, "learning-based-vanishing-point-detection"]], "\u2705 \u5bf9\u6297\u9886\u57df\u504f\u79fb(Robustness to domain shifts)": [[224, "robustness-to-domain-shifts"]], "\u2705 \u66fc\u54c8\u987f vs \u975e\u66fc\u54c8\u987f\u4e16\u754c(Manhattan versus non-Manhattan world)": [[224, "vs-manhattan-versus-non-manhattan-world"]], "\ud83d\udd1a \u603b\u7ed3": [[224, "id2"]], "3. Geometric priors for VP detection": [[224, "geometric-priors-for-vp-detection"]], "\ud83e\udde9 (i) \u970d\u592b\u53d8\u6362\uff08Hough Transform\uff09": [[224, "i-hough-transform"]], "\ud83e\udded (ii.1) \u9ad8\u65af\u7403\u9762\u6620\u5c04\uff08Gaussian Sphere Mapping\uff09": [[224, "ii-1-gaussian-sphere-mapping"]], "\ud83e\udde0 (ii.2) \u7403\u9762\u5377\u79ef\uff08Spherical Convolution\uff09": [[224, "ii-2-spherical-convolution"]], "4.1 Exp 1: Evaluating model choices": [[224, "exp-1-evaluating-model-choices"]], "4.2 Exp 2: Validation on large datasets": [[224, "exp-2-validation-on-large-datasets"]], "4.3 Exp 3: Challenging scenarios": [[224, "exp-3-challenging-scenarios"]], "5. Conclusion and limitations": [[224, "conclusion-and-limitations"]], "2312.14132_DUSt3R: Geometric 3D Vision Made Easy": [[225, "dust3r-geometric-3d-vision-made-easy"]], "\u76f8\u5173\u6982\u5ff5": [[225, "id2"]], "\ud83d\udcf7 \u4e00\u3001\u5185\u53c2\uff08Intrinsic Parameters\uff09": [[225, "intrinsic-parameters"]], "\ud83c\udf0d \u4e8c\u3001\u5916\u53c2\uff08Extrinsic Parameters\uff09": [[225, "extrinsic-parameters"]], "\ud83e\uddee \u4e09\u3001\u4e09\u7ef4\u70b9\u5230\u56fe\u50cf\u70b9\u7684\u6620\u5c04\u516c\u5f0f": [[225, "id3"]], "\ud83c\udfaf \u5e94\u7528\u573a\u666f": [[225, "id4"]], "\ud83d\udca1 \u7b2c\u4e00\u6bb5\uff1a\u80cc\u666f\u4ecb\u7ecd": [[225, "id5"]], "\ud83d\udd27 \u7b2c\u4e8c\u6bb5\uff1a\u4f20\u7edf\u65b9\u6cd5\u7684\u4e0d\u8db3": [[225, "id6"]], "\ud83d\ude80 \u7b2c\u4e09\u6bb5\uff1aDUSt3R \u7684\u6838\u5fc3\u521b\u65b0": [[225, "dust3r"]], "\ud83d\udcda \u7b2c\u56db\u6bb5\uff1a\u8bad\u7ec3\u4e0e\u5efa\u6a21\u601d\u8def": [[225, "id7"]], "\ud83e\udde9 \u7b2c\u4e94\u6bb5\uff1a\u591a\u89c6\u56fe\u878d\u5408\u65b9\u5f0f\u7684\u65b0\u8bbe\u8ba1": [[225, "id8"]], "\ud83d\udcdd \u603b\u7ed3\uff1a\u8bba\u6587\u8d21\u732e\uff08\u56db\u4e2a\u65b9\u9762\uff09": [[225, "id9"]], "1. Structure-from-Motion (SfM)": [[225, "structure-from-motion-sfm"]], "2. Multi-View Stereo (MVS)": [[225, "multi-view-stereo-mvs"]], "3. Direct RGB-to-3D": [[225, "direct-rgb-to-3d"]], "4. \u672c\u6587\u7684\u65b9\u6cd5\uff1aPointmaps \u548c\u53cc\u89c6\u89d2\u8f93\u5165": [[225, "pointmaps"]], "5. Pointmaps \u7684\u4f7f\u7528": [[225, "id10"]], "\ud83e\udde0 \u603b\u7ed3\uff1a": [[225, "id11"], [228, "id27"]], "3. Method": [[225, "method"], [226, "method"], [227, "method"], [228, "method"], [229, "method"]], "\u6982\u5ff5\u5b9a\u4e49": [[225, "id12"]], "\ud83d\udfe1 Pointmap\uff08\u70b9\u56fe\uff09": [[225, "pointmap"]], "\ud83d\udfe1 \u76f8\u673a\u4e0e\u573a\u666f\u5efa\u6a21\uff08Cameras and Scene\uff09": [[225, "cameras-and-scene"]], "\ud83d\udfe1 \u8de8\u76f8\u673a\u5750\u6807\u8f6c\u6362\uff08\u591a\u89c6\u89d2\u70b9\u56fe\u7684\u8f6c\u6362\uff09": [[225, "id13"]], "\u270d\ufe0f \u603b\u7ed3\uff1a": [[225, "id14"]], "\ud83e\udde0 \u76ee\u6807\u6982\u8ff0": [[225, "id15"]], "\ud83c\udfd7\ufe0f \u7f51\u7edc\u67b6\u6784\uff08Inspired by CroCo\uff09": [[225, "inspired-by-croco"]], "\ud83d\udca1 \u8bbe\u8ba1\u8ba8\u8bba\uff08Discussion\uff09": [[225, "discussion"]], "3.2 Training Objective": [[225, "training-objective"]], "\u4e00\u30013D\u56de\u5f52\u635f\u5931\uff083D Regression Loss\uff09": [[225, "d-3d-regression-loss"]], "\u4e8c\u3001\u7f6e\u4fe1\u5ea6\u611f\u77e5\u635f\u5931\uff08Confidence-aware Loss\uff09": [[225, "confidence-aware-loss"]], "\u603b\u7ed3\u7406\u89e3\uff1a": [[225, "id17"]], "3.3 Downstream Applications": [[225, "downstream-applications"]], "\u2705 Point Matching\uff08\u70b9\u5339\u914d\uff09": [[225, "point-matching"]], "\u2705 Recovering Intrinsics\uff08\u6062\u590d\u76f8\u673a\u5185\u53c2\uff09": [[225, "recovering-intrinsics"]], "\u2705 Relative Pose Estimation\uff08\u76f8\u5bf9\u59ff\u6001\u4f30\u8ba1\uff09": [[225, "relative-pose-estimation"]], "3.4 Global Alignment": [[225, "global-alignment"]], "\u2726 \u4e00\u3001\u6784\u5efa\u56fe\u7ed3\u6784: Pairwise Graph": [[225, "pairwise-graph"]], "\u2726 \u4e8c\u3001\u5168\u5c40\u4f18\u5316: Global optimization": [[225, "global-optimization"]], "\u2726 \u4e09\u3001\u76f8\u673a\u53c2\u6570\u6062\u590d\uff1aCamera Parameter Recovery": [[225, "camera-parameter-recovery"]], "\u2705 \u603b\u7ed3\u91cd\u70b9": [[225, "id19"]], "4. Experiments with DUSt3R": [[225, "experiments-with-dust3r"]], "\u524d\u8a00": [[225, "id20"], [226, "id1"]], "\ud83e\udde0 1. \u8bad\u7ec3\u6570\u636e\uff08Training data\uff09": [[225, "training-data"]], "\ud83c\udfd7\ufe0f 2. \u8bad\u7ec3\u7ec6\u8282\uff08Training details\uff09": [[225, "training-details"]], "\ud83d\udcca 3. \u8bc4\u4f30\uff08Evaluation\uff09": [[225, "evaluation"]], "\ud83c\udfa8 4. \u5b9a\u6027\u7ed3\u679c\uff08Qualitative results\uff09": [[225, "qualitative-results"]], "\u2705 \u603b\u7ed3\u4e00\u4e0b\u5173\u952e\u70b9\uff1a": [[225, "id21"]], "4.1 \u89c6\u89c9\u5b9a\u4f4d\uff08Visual Localization\uff09": [[225, "visual-localization"]], "4.2 \u591a\u89c6\u89d2\u76f8\u5bf9\u4f4d\u59ff\u4f30\u8ba1\uff08Multi-view Pose Estimation\uff09": [[225, "multi-view-pose-estimation"]], "4.3 \u5355\u76ee\u6df1\u5ea6\u4f30\u8ba1\uff08Monocular Depth Estimation\uff09": [[225, "monocular-depth-estimation"]], "4.4 \u591a\u89c6\u89d2\u6df1\u5ea6\u4f30\u8ba1\uff08Multi-view Depth\uff09": [[225, "multi-view-depth"]], "4.5 \u4e09\u7ef4\u91cd\u5efa\uff083D Reconstruction\uff09": [[225, "d-reconstruction"]], "4.6 \u6d88\u878d\u5b9e\u9a8c\uff08Ablations\uff09": [[225, "ablations"]], "\ud83e\udde9 \u603b\u7ed3\u4e00\u53e5\u8bdd\uff1a": [[225, "id22"]], "\ud83d\udd1a \u603b\u7ed3\u5185\u5bb9\u89e3\u6790": [[225, "id23"]], "\u2705 \u5173\u952e\u8bcd\u89e3\u91ca\uff1a": [[225, "id24"]], "\ud83d\udccc \u603b\u7ed3\u5173\u952e\u8bcd\u63d0\u70bc": [[225, "id25"]], "Appendix A \u9644\u5f55\u6982\u89c8": [[225, "appendix-a"]], "Appendix B.  Qualitative results": [[225, "appendix-b-qualitative-results"]], "Appendix C. Extended Related Work": [[225, "appendix-c-extended-related-work"]], "1. Implicit Camera Models\uff08\u9690\u5f0f\u76f8\u673a\u6a21\u578b\uff09": [[225, "implicit-camera-models"]], "2. Dense Visual SLAM\uff08\u5bc6\u96c6\u89c6\u89c9SLAM\uff09": [[225, "dense-visual-slam-slam"]], "3. Implicit 3D Reconstruction\uff08\u9690\u5f0f3D\u91cd\u5efa\uff09": [[225, "implicit-3d-reconstruction-3d"]], "4. RGB-pairs-to-3D": [[225, "rgb-pairs-to-3d"]], "Appendix D. \u591a\u89c6\u89d2\u59ff\u6001\u4f30\u8ba1\uff08Multi-view Pose Estimation\uff09": [[225, "appendix-d-multi-view-pose-estimation"]], "\ud83c\udf1f \u6838\u5fc3\u7ed3\u8bba\uff1a": [[225, "id26"], [225, "id27"]], "Appendix E. \u89c6\u89c9\u5b9a\u4f4d\uff08Visual Localization\uff09": [[225, "appendix-e-visual-localization"]], "\ud83e\uddea \u5b9e\u9a8c\u8bbe\u5b9a\uff1a": [[225, "id28"]], "\ud83d\udcca \u8868\u683c\u89e3\u8bfb\uff08Tab. 6\uff09\uff1a": [[225, "tab-6"]], "\ud83d\udccc \u603b\u7ed3\u4eae\u70b9\uff1a": [[225, "id29"]], "Appendix F. Training details": [[225, "appendix-f-training-details"]], "\u4e00\u3001\u8bad\u7ec3\u6570\u636e\u6765\u6e90\u548c\u5904\u7406": [[225, "id30"]], "\u4e8c\u3001\u6570\u636e\u589e\u5f3a\u7b56\u7565": [[225, "id31"]], "\u4e09\u3001\u8bad\u7ec3\u8d85\u53c2\u6570\uff08\u89c1\u8868 7\uff09": [[225, "id32"]], "2406.09756_MASt3R: Grounding Image Matching in 3D with MASt3R": [[226, "mast3r-grounding-image-matching-in-3d-with-mast3r"]], "SIFT (Scale-Invariant Feature Transform)": [[226, "sift-scale-invariant-feature-transform"]], "COLMAP": [[226, "colmap"]], "ASMK (Aggregated Selective Match Kernels)": [[226, "asmk-aggregated-selective-match-kernels"]], "PnP(Perspective-n-Point)": [[226, "pnp-perspective-n-point"]], "\u2460 \u7814\u7a76\u52a8\u673a\u4e0e\u80cc\u666f\uff08Why\uff09": [[226, "why"]], "\u2461 \u4f20\u7edf\u65b9\u6cd5\u56de\u987e\uff08What existed before\uff09": [[226, "what-existed-before"]], "\u2462 \u8fd1\u5e74\u6539\u8fdb\u65b9\u5411\uff08What improved\uff09": [[226, "what-improved"]], "\u2463 \u6838\u5fc3\u95ee\u9898\uff08Problem Statement\uff09": [[226, "problem-statement"]], "\u2464 \u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5 MASt3R\uff08Our Solution\uff09": [[226, "mast3r-our-solution"]], "\u2465 \u4e09\u5927\u8d21\u732e\u603b\u7ed3\uff08Claimed Contributions\uff09": [[226, "claimed-contributions"]], "\ud83e\udde0 \u601d\u7ef4\u5bfc\u56fe\u5f0f\u603b\u7ed3": [[226, "id2"]], "2. Related works": [[226, "related-works"]], "\u2460 \u5173\u952e\u70b9\u5339\u914d\uff08Keypoint-based Matching\uff09": [[226, "keypoint-based-matching"]], "\u2461 \u7a20\u5bc6\u5339\u914d\uff08Dense/Semi-dense Matching\uff09": [[226, "dense-semi-dense-matching"]], "\u2462 \u76f8\u673a\u4f4d\u59ff\u4f30\u8ba1\uff08Camera Pose Estimation\uff09": [[226, "camera-pose-estimation"]], "\u2463 \u54113D\u5339\u914d\u8fc7\u6e21\uff083D-Aware Matching\uff09": [[226, "d-3d-aware-matching"]], "\ud83e\udde0 \u603b\u7ed3\u601d\u7ef4\u5bfc\u56fe": [[226, "id3"]], "3.1 The DUSt3R framework": [[226, "the-dust3r-framework"]], "3.2. Matching prediction head and loss": [[226, "matching-prediction-head-and-loss"]], "3.3. Fast reciprocal matching": [[226, "fast-reciprocal-matching"]], "3.4. Coarse-to-fine matching": [[226, "coarse-to-fine-matching"]], "4.1. Training": [[226, "training"]], "4.2 Map-free localization": [[226, "map-free-localization"]], "4.3. Relative pose estimation": [[226, "relative-pose-estimation"]], "4.4. Visual localization(solute pose estimation)": [[226, "visual-localization-solute-pose-estimation"]], "4.5 Multiview 3D Reconstruction\uff08\u591a\u89c6\u56fe\u4e09\u7ef4\u91cd\u5efa\uff09": [[226, "multiview-3d-reconstruction"]], "Appendix A Additional Qualitative Results": [[226, "appendix-a-additional-qualitative-results"]], "B. Fast Reciprocal Matching": [[226, "b-fast-reciprocal-matching"]], "B.1. Theoretical study": [[226, "b-1-theoretical-study"]], "B.2. Performance improves with fast matching": [[226, "b-2-performance-improves-with-fast-matching"]], "C. Coarse-to-Fine": [[226, "c-coarse-to-fine"]], "D. Detailed experimental settings": [[226, "d-detailed-experimental-settings"]], "2412.09401_SLAM3R: Real-Time Dense Scene Reconstruction from Monocular RGB Videos": [[227, "slam3r-real-time-dense-scene-reconstruction-from-monocular-rgb-videos"]], "\u672f\u8bed": [[227, "id1"]], "1. SLAM3R\u7684\u76ee\u6807\u548c\u80cc\u666f\uff1a": [[227, "slam3r"]], "2. SLAM3R\u7684\u521b\u65b0\u4e0e\u65b9\u6cd5\uff1a": [[227, "id2"]], "3. SLAM3R\u7684\u4f18\u52bf\uff1a": [[227, "id3"]], "4. \u8d21\u732e\u603b\u7ed3\uff1a": [[227, "id4"]], "1. \u4f20\u7edf\u7684\u79bb\u7ebf\u65b9\u6cd5": [[227, "id6"]], "2. \u7a20\u5bc6SLAM\u65b9\u6cd5": [[227, "slam"]], "3. \u5355\u76ee\u7a20\u5bc6SLAM\u7cfb\u7edf": [[227, "id7"]], "4. \u7aef\u5230\u7aef\u7684\u7a20\u5bc6\u4e09\u7ef4\u91cd\u5efa": [[227, "id8"]], "5. SLAM3R\u7684\u521b\u65b0": [[227, "id9"]], "3.1 Inner-Window Local Reconstruction": [[227, "inner-window-local-reconstruction"]], "3.2 Inter-Window Global Registration": [[227, "inter-window-global-registration"]], "4.1 \u6bd4\u8f83\uff08Comparisons\uff09": [[227, "comparisons"]], "4.2 \u5206\u6790\uff08Analyses\uff09": [[227, "analyses"]], "5. \u7ed3\u8bba": [[227, "id12"]], "\u5c40\u9650\u6027\u548c\u672a\u6765\u5de5\u4f5c": [[227, "id13"]], "6. \u81f4\u8c22": [[227, "id14"]], "Appendix A Implementation details": [[227, "appendix-a-implementation-details"]], "\u68c0\u7d22\u6a21\u5757\uff08Retrieval Module\uff09": [[227, "retrieval-module"]], "\u591a\u5173\u952e\u5e27\u8054\u5408\u914d\u51c6\uff08Multi-keyframe Co-registration\uff09": [[227, "multi-keyframe-co-registration"]], "\u8bad\u7ec3\u7ec6\u8282\uff08Training Details\uff09": [[227, "training-details"]], "Appendix B Details for experimental settings": [[227, "appendix-b-details-for-experimental-settings"]], "1. \u91cd\u5efa\u8d28\u91cf\u8bc4\u4f30": [[227, "id16"]], "2. \u6548\u7387\u8bc4\u4f30": [[227, "id17"]], "3. \u76f8\u673a\u59ff\u6001\u7cbe\u5ea6\u8bc4\u4f30": [[227, "id18"]], "4. \u8f93\u5165\u6570\u636e\u7684\u4e0d\u540c\u8bbe\u7f6e": [[227, "id19"]], "5. \u5176\u4ed6\u5b9e\u9a8c\u7ec6\u8282": [[227, "id20"]], "Appendix C Additional comparisons and analyses": [[227, "appendix-c-additional-comparisons-and-analyses"]], "1. \u6570\u503c\u7ed3\u679c\u5bf9\u6bd4": [[227, "id21"]], "2. \u7a97\u53e3\u957f\u5ea6\u7684\u6536\u76ca\u9012\u51cf": [[227, "id22"]], "3. \u573a\u666f\u5e27\u6570\u5bf9\u914d\u51c6\u7684\u5f71\u54cd": [[227, "id23"]], "4. \u76f8\u673a\u4f4d\u59ff\u4f30\u8ba1": [[227, "id24"]], "D. More visual results": [[227, "d-more-visual-results"]], "Visualization of incremental reconstruction.": [[227, "visualization-of-incremental-reconstruction"]], "Reconstruction on DTU dataset.": [[227, "reconstruction-on-dtu-dataset"]], "2412.12392_MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors": [[228, "mast3r-slam-real-time-dense-slam-with-3d-reconstruction-priors"]], "GPT": [[228, "gpt"]], "\u5148\u9a8c\u77e5\u8bc6": [[228, "id1"]], "IMU": [[228, "imu"]], "SfM": [[228, "sfm"]], "SLAM": [[228, "slam"]], "central camera model": [[228, "central-camera-model"]], "3.2 Pointmap Matching": [[228, "pointmap-matching"]], "\ud83d\udd0d \u80cc\u666f\u4e0e\u95ee\u9898": [[228, "id2"]], "\ud83c\udf10 MASt3R \u7684\u7b56\u7565": [[228, "mast3r"]], "\ud83c\udf00 \u6838\u5fc3\u601d\u60f3\uff1a\u8fed\u4ee3\u6295\u5f71\u5339\u914d\uff08Iterative Projective Matching\uff09": [[228, "iterative-projective-matching"]], "\ud83d\udd27 \u89e3\u6cd5\u7ec6\u8282\uff1a\u4f18\u5316\u6c42\u89e3": [[228, "id3"]], "\ud83d\udd01 \u7cbe\u7ec6\u5339\u914d\uff1a\u4f7f\u7528\u7279\u5f81\u8fdb\u4e00\u6b65\u4f18\u5316": [[228, "id4"]], "\u2699\ufe0f \u5b9e\u73b0\u7ec6\u8282": [[228, "id5"]], "\ud83e\udde0 \u603b\u7ed3\u4e00\u4e0b\u6838\u5fc3\u8d21\u732e": [[228, "id6"]], "3.3 Tracking and Pointmap Fusion": [[228, "tracking-and-pointmap-fusion"]], "\ud83d\udccc \u80cc\u666f\u8bbe\u5b9a\uff1aTracking \u7684\u76ee\u6807": [[228, "tracking"]], "\ud83d\udd27 \u5982\u4f55\u4f30\u8ba1 \\mathbf{T}_{kf}\uff08\u5f53\u524d\u5e27\u5bf9\u5173\u952e\u5e27\u7684\u76f8\u5bf9\u4f4d\u59ff\uff09\uff1f": [[228, "mathbf-t-kf"]], "\ud83e\uddee \u65b9\u5f0f\u4e00\uff1a\u6700\u5c0f\u5316 3D \u70b9\u8bef\u5dee": [[228, "d"]], "\u2757\ufe0f\u95ee\u9898\uff1a3D \u70b9\u8bef\u5dee\u5bb9\u6613\u53d7\u5230\u6df1\u5ea6\u8bef\u5dee\u5f71\u54cd": [[228, "id7"]], "\u2705 \u6539\u8fdb\uff1a\u4f7f\u7528 Ray\uff08\u5c04\u7ebf\uff09\u8bef\u5dee\u6765\u4ee3\u66ff": [[228, "ray"]], "\u2696\ufe0f \u5904\u7406\u7eaf\u65cb\u8f6c\u9000\u5316\u7684\u95ee\u9898": [[228, "id8"]], "\ud83d\udd04 \u5982\u4f55\u4f18\u5316\uff1f\u4f7f\u7528 Gauss-Newton + IRLS \u8fed\u4ee3\u6c42\u89e3": [[228, "gauss-newton-irls"]], "\ud83d\udccc 3.4 \u56fe\u6784\u5efa\u4e0e\u56de\u73af\u68c0\u6d4b\uff08Graph Construction and Loop Closure\uff09": [[228, "graph-construction-and-loop-closure"]], "\ud83d\udd39\u4f55\u65f6\u6dfb\u52a0\u5173\u952e\u5e27\uff1a": [[228, "id10"]], "\ud83d\udd39\u56de\u73af\u68c0\u6d4b\u673a\u5236\uff1a": [[228, "id11"]], "\ud83d\udccc 3.5 \u540e\u7aef\u4f18\u5316\uff08Backend Optimisation\uff09": [[228, "backend-optimisation"]], "\ud83d\udd39\u8f93\u5165\uff1a": [[228, "id12"]], "\ud83d\udd39\u76ee\u6807\uff1a": [[228, "id13"]], "\ud83d\udd39\u516c\u5f0f\u89e3\u8bfb\uff08\u5f0f10\uff09\uff1a": [[228, "id14"]], "\ud83d\udccc 3.6 \u91cd\u5b9a\u4f4d\uff08Relocalisation\uff09": [[228, "relocalisation"]], "\ud83d\udccc 3.7 \u76f8\u673a\u6807\u5b9a\uff08Known Calibration\uff09": [[228, "known-calibration"]], "\u4f18\u5316\u505a\u6cd5\u6709\u4e24\u70b9\uff1a": [[228, "id15"]], "\u516c\u5f0f\uff08\u5f0f11\uff09\u89e3\u91ca\uff1a": [[228, "id16"]], "4.1 Camera Pose Estimation": [[228, "camera-pose-estimation"]], "\ud83e\udde0 \u603b\u4f53\u7406\u89e3": [[228, "id17"]], "\ud83d\udccd\u672f\u8bed\u89e3\u91ca": [[228, "id18"]], "\ud83d\udcca \u6570\u636e\u96c6\u9010\u4e2a\u89e3\u91ca": [[228, "id19"]], "\u2705 TUM RGB-D \u6570\u636e\u96c6\uff1a": [[228, "tum-rgb-d"]], "\u2705 7-Scenes \u6570\u636e\u96c6\uff08\u8868\u683c\u5206\u6790\uff09\uff1a": [[228, "scenes"]], "\u2705 ETH3D-SLAM \u6570\u636e\u96c6\uff1a": [[228, "eth3d-slam"]], "\u2705 EuRoC \u6570\u636e\u96c6\uff1a": [[228, "euroc"]], "\u2705 \u603b\u7ed3\u4eae\u70b9": [[228, "id20"]], "\ud83d\udd0d 4.2 Dense Geometry Evaluation\uff1a\u5bc6\u96c6\u51e0\u4f55\u8bc4\u4f30": [[228, "dense-geometry-evaluation"]], "\ud83c\udf0d \u8bc4\u4f30\u8bbe\u7f6e\uff1a": [[228, "id21"]], "\ud83d\udccf \u8bc4\u4f30\u6307\u6807\uff1a": [[228, "id22"]], "\u2705 7-Scenes \u8bc4\u4f30\u7ed3\u679c\uff1a": [[228, "id23"]], "\u2705 EuRoC \u8bc4\u4f30\u7ed3\u679c\uff1a": [[228, "id24"]], "\ud83d\uddbc\ufe0f 4.3 Qualitative Results\uff1a\u53ef\u89c6\u5316\u7ed3\u679c": [[228, "qualitative-results"]], "\ud83e\uddea 4.4 Ablation Studies\uff1a\u6d88\u878d\u5b9e\u9a8c": [[228, "ablation-studies"]], "\ud83d\udccc \u63a2\u7d22\u5f71\u54cd\u6027\u80fd\u7684\u5173\u952e\u8bbe\u8ba1\u9009\u62e9\uff1a": [[228, "id25"]], "\ud83e\uddee \u5149\u7ebf\u8bef\u5dee vs \u70b9\u8bef\u5dee\uff1a": [[228, "vs"]], "\ud83d\udd01 Canonical Pointmap \u7684\u66f4\u65b0\u7b56\u7565\uff1a": [[228, "canonical-pointmap"]], "\ud83e\udde9 \u5339\u914d\u7b56\u7565\uff1a": [[228, "id26"]], "5. Limitations and Future Work\uff08\u5c40\u9650\u4e0e\u672a\u6765\u5de5\u4f5c\uff09": [[228, "limitations-and-future-work"]], "\ud83e\uddf1 \u5c40\u96501\uff1a\u5168\u5c40\u51e0\u4f55\u4f18\u5316\u4e0d\u5b8c\u5584": [[228, "id28"]], "\ud83d\udcf7 \u5c40\u96502\uff1a\u4ec5\u5728\u9488\u5b54\u6a21\u578b\uff08pinhole camera\uff09\u56fe\u50cf\u4e0a\u8bad\u7ec3": [[228, "pinhole-camera"]], "\ud83d\udda5\ufe0f \u5c40\u96503\uff1a\u89e3\u7801\u5668\u6548\u7387\u4f4e\u3001\u6210\u4e3a\u7cfb\u7edf\u74f6\u9888": [[228, "id29"]], "\ud83e\uddfe 6. Conclusion\uff08\u603b\u7ed3\uff09": [[228, "conclusion"]], "\ud83c\udfaf \u7cfb\u7edf\u4eae\u70b9": [[228, "id30"]], "\u2699\ufe0f \u65b9\u6cd5\u5dee\u5f02": [[228, "id31"]], "\ud83e\udde0 \u603b\u7ed3\u4e00\u53e5\u8bdd\u7248\uff1a": [[228, "id32"]], "8. Initialisation\uff08\u521d\u59cb\u5316\uff09": [[228, "initialisation"]], "9. Runtime Breakdown\uff08\u8fd0\u884c\u65f6\u5206\u6790\uff09": [[228, "runtime-breakdown"]], "10. Evaluation Setup\uff08\u8bc4\u4f30\u8bbe\u7f6e\uff09": [[228, "evaluation-setup"]], "10.1 \u8f68\u8ff9\u8bc4\u4f30": [[228, "id33"]], "10.2 \u51e0\u4f55\u7cbe\u5ea6\u8bc4\u4f30": [[228, "id34"]], "ATE \u8f68\u8ff9\u8bef\u5dee\u8868\uff08Tab. 8\uff09": [[228, "ate-tab-8"]], "11. EuRoC \u7ed3\u679c\u603b\u7ed3": [[228, "id35"]], "2503.11651_VGGT: Visual Geometry Grounded Transformer": [[229, "vggt-visual-geometry-grounded-transformer"]], "\ud83d\udccc \u7ed3\u6784\u5149\u6062\u590d\uff08Structure from Motion, SfM\uff09": [[229, "structure-from-motion-sfm"]], "\ud83d\udccc \u591a\u89c6\u56fe\u7acb\u4f53\uff08Multi-view Stereo, MVS\uff09": [[229, "multi-view-stereo-mvs"]], "\ud83d\udccc \u70b9\u8ffd\u8e2a\uff08Tracking-Any-Point\uff09": [[229, "tracking-any-point"]], "\u2728 \u603b\u7ed3\u4e00\u4e0b": [[229, "id1"]], "3.1 Problem definition and notation": [[229, "problem-definition-and-notation"]], "3.2 Feature Backbone": [[229, "feature-backbone"]], "3.3 Prediction heads": [[229, "prediction-heads"]], "3.4 Training": [[229, "training"]], "\u2705 \u5c0f\u7ed3": [[229, "id2"]], "5. Discussions": [[229, "discussions"]], "\ud83d\udd34 \u5c40\u9650\u6027\uff08Limitations\uff09": [[229, "limitations"]], "\ud83d\udd35 \u8fd0\u884c\u65f6\u95f4\u4e0e\u5185\u5b58\uff08Runtime and Memory\uff09": [[229, "runtime-and-memory"]], "\ud83d\udfe0 Patchifying\uff08\u56fe\u50cf\u5206\u5757\uff09": [[229, "patchifying"]], "\ud83d\udfe1 \u53ef\u5fae Bundle Adjustment\uff08Differentiable BA\uff09": [[229, "bundle-adjustment-differentiable-ba"]], "\ud83d\udfe2 \u5355\u89c6\u56fe\u91cd\u5efa\uff08Single-view Reconstruction\uff09": [[229, "single-view-reconstruction"]], "\ud83d\udd35 \u9884\u6d4b\u5f52\u4e00\u5316\uff08Normalizing Prediction\uff09": [[229, "normalizing-prediction"]], "Appendix A Formal Definitions": [[229, "appendix-a-formal-definitions"]], "\u76f8\u673a\u4e0e3D\u70b9\u4e4b\u95f4\u7684\u51e0\u4f55\u53d8\u6362\u51fd\u6570": [[229, "d"]], "\u4ece\u4e00\u4e2a\u56fe\u50cf\u50cf\u7d20\u4f4d\u7f6e\u53cd\u63a8\u51fa\u5176\u5bf9\u5e94\u7684\u4e09\u7ef4\u70b9\u7684\u4f4d\u7f6e": [[229, "id3"]], "Architecture": [[229, "architecture"]], "Appendix C Additional Experiments": [[229, "appendix-c-additional-experiments"]], "\u2705 \u4f18\u52bf\u603b\u7ed3": [[229, "id7"]], "\ud83e\udde0 \u4e2d\u6587\u603b\u7ed3\u5f52\u7eb3\uff1a": [[229, "id8"]], "Appendix D Qualitative Examples": [[229, "appendix-d-qualitative-examples"]], "Appendix E Related Work": [[229, "appendix-e-related-work"]], "1811.10959v3_Dataset Distillation": [[230, "v3-dataset-distillation"]], "\u65b9\u6cd5": [[230, "id3"]], "1. INTRODUCTION": [[230, "introduction"]], "3. APPROACH": [[230, "approach"]], "3.1 OPTIMIZING DISTILLED DATA": [[230, "optimizing-distilled-data"]], "3.2 DISTILLATION FOR RANDOM INITIALIZATIONS": [[230, "distillation-for-random-initializations"]], "3.3 ANALYSIS OF A SIMPLE LINEAR CASE": [[230, "analysis-of-a-simple-linear-case"]], "3.4 MULTIPLE GRADIENT DESCENT STEPS AND MULTIPLE EPOCHS": [[230, "multiple-gradient-descent-steps-and-multiple-epochs"]], "3.5 DISTILLATION WITH DIFFERENT INITIALIZATIONS": [[230, "distillation-with-different-initializations"]], "3.6 DISTILLATION WITH DIFFERENT OBJECTIVES": [[230, "distillation-with-different-objectives"]], "2502.20653_Dataset Distillation with Neural Characteristic Function: A Minmax Perspective": [[231, "dataset-distillation-with-neural-characteristic-function-a-minmax-perspective"]], "Dataset distillation": [[232, "dataset-distillation"]], "A PAINLESS GUIDE TO CRC ERROR DETECTION ALGORITHMS": [[233, "a-painless-guide-to-crc-error-detection-algorithms"]], "The Basic Idea Behind CRC Algorithms": [[233, "the-basic-idea-behind-crc-algorithms"]], "Polynomical Arithmetic": [[233, "polynomical-arithmetic"]], "Binary Arithmetic with No Carries": [[233, "binary-arithmetic-with-no-carries"]], "\u4e00\u4e2a\u53ef\u7528\u7684\u5b9e\u4f8b": [[233, "id2"]], "Choosing A Poly": [[233, "choosing-a-poly"]], "A Straightforward CRC Implementation": [[233, "a-straightforward-crc-implementation"]], "A Table-Driven Implementation": [[233, "a-table-driven-implementation"]], "A Slightly Mangled Table-Driven Implementation": [[233, "a-slightly-mangled-table-driven-implementation"]], "Distributed Representations of Sentences and Documents": [[234, "distributed-representations-of-sentences-and-documents"]], "\u8bba\u6587\u6c60": [[235, "id2"]], "2305.16300_Random-Access Infinite Context Length for Transformers": [[236, "random-access-infinite-context-length-for-transformers"]], "\u7814\u7a76\u80cc\u666f\u4e0e\u52a8\u673a": [[236, "id1"]], "\u6838\u5fc3\u95ee\u9898": [[236, "id2"]], "\u4e3b\u8981\u8d21\u732e": [[236, "id3"]], "\u5173\u952e\u6280\u672f\u70b9": [[236, "id4"]], "\u610f\u4e49\u4e0e\u5e94\u7528\u524d\u666f": [[236, "id6"]], "3 Methodology": [[236, "methodology"]], "\u603b\u4f53\u601d\u8def": [[236, "id8"]], "\u65b9\u6cd5\u8be6\u89e3": [[236, "id9"]], "1. Landmark Token \u7684\u8bad\u7ec3": [[236, "landmark-token"]], "2. \u63a8\u7406\u8fc7\u7a0b": [[236, "id10"]], "\u4f4d\u7f6e\u7f16\u7801\u5904\u7406": [[236, "id11"]], "\u4e0e\u5176\u4ed6\u65b9\u6cd5\u7684\u5bf9\u6bd4": [[236, "id12"]], "3.3 Memory & Computation": [[236, "memory-computation"]], "4.1 \u8bed\u8a00\u5efa\u6a21\u5b9e\u9a8c": [[236, "id14"]], "\u6a21\u578b\u4e0e\u8bad\u7ec3": [[236, "id15"]], "\u7ed3\u679c": [[236, "id16"], [236, "id21"]], "\u5757\u68c0\u7d22\u7684\u7c92\u5ea6": [[236, "id17"]], "4.2 \u5fae\u8c03\u9884\u8bad\u7ec3\u6a21\u578b": [[236, "id18"]], "\u5b9e\u9a8c\u65b9\u6cd5": [[236, "id19"]], "5 Future Work": [[236, "future-work"]], "Acknowledgment": [[236, "acknowledgment"]], "Appendix A Grouped Softmax Example": [[236, "appendix-a-grouped-softmax-example"]], "Appendix B Dataset Description": [[236, "appendix-b-dataset-description"]], "Appendix C Number of Unique Retrieved Blocks": [[236, "appendix-c-number-of-unique-retrieved-blocks"]], "Appendix D Context Miss Token": [[236, "appendix-d-context-miss-token"]], "Appendix E Positional Augmentation": [[236, "appendix-e-positional-augmentation"]], "Appendix F Additional Extensions and Details": [[236, "appendix-f-additional-extensions-and-details"]], "1. \u63a9\u7801\u8bed\u8a00\u5efa\u6a21\uff08Masked Language Modeling\uff09": [[236, "masked-language-modeling"]], "2. \u4e0e Flash Attention \u7684\u7ed3\u5408": [[236, "flash-attention"]], "3. \u68c0\u7d22\u5757\u6570\u91cf\u4e0e\u5757\u5927\u5c0f\u7684\u6743\u8861": [[236, "id23"]], "Appendix G Offloading KV Cache to CPU": [[236, "appendix-g-offloading-kv-cache-to-cpu"]], "2311.18743_AlignBench: Benchmarking Chinese Alignment of Large Language Models": [[237, "alignbench-benchmarking-chinese-alignment-of-large-language-models"]], "2. AlignBench\u7684\u8bbe\u8ba1\u76ee\u6807": [[237, "alignbench"]], "3. AlignBench\u7684\u4e3b\u8981\u7279\u70b9": [[237, "id4"]], "4. AlignBench\u7684\u5e94\u7528\u4e0e\u6210\u679c": [[237, "id5"]], "5. \u603b\u4f53\u8d21\u732e": [[237, "id6"]], "6. \u8868\u683c\u5bf9\u6bd4": [[237, "id7"]], "4 Human Evaluation on AlignBench": [[237, "human-evaluation-on-alignbench"]], "\u4e00\u3001\u4e00\u81f4\u6027\u8bc4\u4f30\uff08Agreement Evaluation\uff09": [[237, "agreement-evaluation"]], "\u4e8c\u3001\u89e3\u91ca\u8d28\u91cf\u8bc4\u4f30\uff08Quality Evaluation\uff09": [[237, "quality-evaluation"]], "5 AlignBench: Benchmarking Results": [[237, "alignbench-benchmarking-results"]], "A.2 Prompts and Details of Methods": [[237, "a-2-prompts-and-details-of-methods"]], "A.2 \u63d0\u793a\u6a21\u677f\u4e0e\u65b9\u6cd5\u7ec6\u8282": [[237, "a-2"]], "\u4e3b\u8981\u5185\u5bb9\u5305\u62ec\uff1a": [[237, "id9"]], "A.3 \u5404\u7ef4\u5ea6\u8868\u73b0": [[237, "a-3"]], "A.4 \u6848\u4f8b\u5206\u6790": [[237, "a-4"]], "A.4.2 Reference-free Judgements": [[237, "a-4-2-reference-free-judgements"]], "\u4e00\u3001\u6838\u5fc3\u95ee\u9898\uff1a\u53c2\u8003\u6750\u6599\u7f3a\u5931\u5bfc\u81f4\u8bc4\u4f30\u56f0\u96be": [[237, "id11"]], "\u4e8c\u3001\u6570\u5b66\u79ef\u5206\u95ee\u9898\u5bf9\u6bd4\u5206\u6790": [[237, "id12"]], "\u4e09\u3001\u603b\u7ed3": [[237, "id13"], [242, "id17"]], "2401.15391_MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries": [[238, "multihop-rag-benchmarking-retrieval-augmented-generation-for-multi-hop-queries"]], "\u8d21\u732e": [[238, "id2"]], "\u65b9\u6cd5\u6982\u89c8": [[238, "id3"]], "2 RAG with multi-Hop queries": [[238, "rag-with-multi-hop-queries"]], "2.1 RAG\uff08\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff09\u6982\u8ff0": [[238, "rag"]], "2.2 \u591a\u8df3\u67e5\u8be2\uff08Multi-Hop Queries\uff09": [[238, "multi-hop-queries"]], "2.3 \u8bc4\u4f30\u6307\u6807": [[238, "id8"]], "3 A Benchmarking Dataset: MultiHop-RAG": [[238, "a-benchmarking-dataset-multihop-rag"]], "\u4e00\u3001MultiHop-RAG \u6570\u636e\u96c6\u6784\u5efa\u6d41\u7a0b": [[238, "multihop-rag"]], "\u4e8c\u3001MultiHop-RAG \u6570\u636e\u96c6\u7edf\u8ba1\u4fe1\u606f": [[238, "id10"]], "4 Benchmarking RAG system using MultiHop-RAG": [[238, "benchmarking-rag-system-using-multihop-rag"]], "\u4e00\u3001\u68c0\u7d22\u76f8\u5173\u4efb\u52a1\uff08Retrieval-related Task\uff09": [[238, "retrieval-related-task"]], "\u4e8c\u3001\u751f\u6210\u76f8\u5173\u4efb\u52a1\uff08Generation-related Task\uff09": [[238, "generation-related-task"]], "\u4e09\u3001\u5176\u4ed6\u6f5c\u5728\u6539\u8fdb\u65b9\u5411\uff08Other Use Cases\uff09": [[238, "other-use-cases"]], "Appendix A Appendix A: GPT-4 Prompts Used for Data Generation": [[238, "appendix-a-appendix-a-gpt-4-prompts-used-for-data-generation"]], "Appendix B Appendix B: Dataset Examples": [[238, "appendix-b-appendix-b-dataset-examples"]], "2.1 Prompt Tuning": [[239, "prompt-tuning"]], "2.2 LLMs\u5728\u56fe\u76f8\u5173\u4efb\u52a1\u4e2d\u7684\u5e94\u7528": [[239, "llms"]], "2.3 \u56fe\u4e0a\u7684\u68c0\u7d22\u65b9\u6cd5": [[239, "id1"]], "3 Problem Formalization": [[239, "problem-formalization"]], "4 Methodology": [[239, "methodology"]], "4.1 \u6587\u672c\u5b50\u56fe\u68c0\u7d22": [[239, "id3"]], "\u6587\u672c\u5b50\u56fe\u7d22\u5f15\uff08Indexing\uff09": [[239, "indexing"]], "\u6587\u672c\u5b50\u56fe\u6392\u5e8f\uff08Ranking\uff09": [[239, "ranking"]], "\u6587\u672c\u5b50\u56fe\u8f6f\u526a\u679d\uff08Soft Pruning\uff09": [[239, "soft-pruning"]], "4.2 Textual Graph Augmented Generation": [[239, "textual-graph-augmented-generation"]], "1. \u6587\u672c\u89c6\u56fe\uff08Text View of Textual Graphs\uff09": [[239, "text-view-of-textual-graphs"]], "2. \u56fe\u89c6\u56fe\uff08Graph View of Textual Graphs\uff09": [[239, "graph-view-of-textual-graphs"]], "3. \u751f\u6210\u9636\u6bb5\uff08Generation Phase\uff09": [[239, "generation-phase"]], "\u603b\u7ed3\uff1a\u7b2c\u4e94\u7ae0 \u5b9e\u9a8c\u90e8\u5206": [[239, "id6"]], "5.1 \u5b9e\u9a8c\u8bbe\u7f6e": [[239, "id7"]], "5.2 \u4e3b\u8981\u7ed3\u679c": [[239, "id8"]], "5.3 \u8ba8\u8bba": [[239, "id9"]], "5.4 \u6d88\u878d\u7814\u7a76": [[239, "id10"]], "\u9644\u5f55A \u603b\u7ed3": [[239, "a"]], "A.1 \u5c42\u6b21\u5316\u63cf\u8ff0": [[239, "a-1"]], "A.2 \u68c0\u7d22\u5668\u5bf9\u6bd4": [[239, "a-2"]], "A.3 \u5b9e\u73b0\u7ec6\u8282": [[239, "a-3"]], "A.4 \u5b9e\u9a8c\u5206\u6790": [[239, "a-4"]], "2407.01178_Memory3: Language Modeling with Explicit Memory": [[240, "memory3-language-modeling-with-explicit-memory"]], "Language Modeling with Explicit Memory": [[240, "language-modeling-with-explicit-memory"]], "\u7814\u7a76\u80cc\u666f\u4e0e\u52a8\u673a\uff1a": [[240, "id1"]], "\u4e3b\u8981\u5185\u5bb9\u4e0e\u65b9\u6cd5\uff1a": [[240, "id2"]], "\u5b9e\u9a8c\u4e0e\u7ed3\u679c\uff1a": [[240, "id3"]], "Memory3 \u6a21\u578b\u7279\u70b9": [[240, "memory3"]], "1\u2002_\u2002Introduction": [[240, "introduction"]], "1.1.1\u2002_\u2002Retrieval-augmented Training": [[240, "retrieval-augmented-training"]], "1.1.1 | \u57fa\u4e8e\u68c0\u7d22\u7684\u8bad\u7ec3\uff08Retrieval-augmented Training\uff09": [[240, "id8"]], "1.1.2 | \u7a00\u758f\u8ba1\u7b97\uff08Sparse Computation\uff09": [[240, "sparse-computation"]], "1.1.3 | \u53c2\u6570\u5373\u8bb0\u5fc6\uff08Parameter as Memory\uff09": [[240, "parameter-as-memory"]], "2\u2002_\u2002Memory Circuitry Theory": [[240, "memory-circuitry-theory"]], "\u6838\u5fc3\u6982\u5ff5\u603b\u7ed3\uff1a": [[240, "id10"]], "\u603b\u4f53\u8d21\u732e\uff1a": [[240, "id11"]], "Definition 2.": [[240, "definition-2"]], "1. \u5b9a\u4e49\u4e0e\u6838\u5fc3\u6982\u5ff5\uff1a\u8ba1\u7b97\u56fe\u3001\u540c\u6784\u4e0e\u77e5\u8bc6\uff08\u7535\u8def\uff09": [[240, "id12"]], "2. \u77e5\u8bc6\u7684\u5b9e\u4f8b": [[240, "id13"]], "3. \u77e5\u8bc6\u7684\u5916\u90e8\u5316\u4e0e\u8bb0\u5fc6": [[240, "id14"]], "4. \u7ed3\u8bba\u4e0e\u65ad\u8a00": [[240, "id15"]], "Remark 1.": [[240, "remark-1"]], "1. \u7535\u8def\u6784\u9020\u7684\u5173\u952e\u6027\u8d28": [[240, "id17"]], "2. \u8bb0\u5fc6\u589e\u5f3a LLM \u7684\u5f62\u5f0f\u5316\u5b9a\u4e49": [[240, "llm"]], "3. \u5199\u5165\u4ee3\u4ef7\u4e0e\u8bfb\u53d6\u4ee3\u4ef7\u7684\u6743\u8861\uff08\u8bb0\u5fc6\u5c42\u6b21\u7ed3\u6784\uff09": [[240, "id18"]], "4. \u77e5\u8bc6\u4f7f\u7528\u9891\u7387\u4e0e\u8bb0\u5fc6\u5206\u914d": [[240, "id19"]], "5. \u56fe\u793a\u4e0e\u7ed3\u8bba": [[240, "id20"]], "3\u2002_\u2002Design": [[240, "design"]], "3 | Design": [[240, "id22"]], "3.2 \u8bad\u7ec3\u76ee\u6807": [[240, "id24"]], "3.1 | \u63a8\u7406\u8fc7\u7a0b": [[240, "id25"]], "\u5907\u6ce8\u4e0e\u4f18\u5316": [[240, "id26"]], "3.2 | \u5199\u5165\u4e0e\u8bfb\u53d6\u8bb0\u5fc6": [[240, "id27"]], "3.3\u2002_\u2002Memory Sparsification and Storage": [[240, "memory-sparsification-and-storage"]], "\u4e00\u3001\u663e\u5f0f\u8bb0\u5fc6\u7684\u5b58\u50a8\u6311\u6218": [[240, "id29"]], "\u4e8c\u3001\u5404\u7ef4\u5ea6\u7684\u7a00\u758f\u5316\u7b56\u7565": [[240, "id30"]], "1. \u5c42\uff08Layers\uff09\u7684\u7a00\u758f\u5316": [[240, "layers"]], "2. \u5934\uff08Heads\uff09\u7684\u7a00\u758f\u5316": [[240, "heads"]], "3. Token \u7684\u7a00\u758f\u5316": [[240, "token"]], "4. \u5934\u7ef4\u5ea6\uff08Head Dimension\uff09\u7684\u538b\u7f29": [[240, "head-dimension"]], "\u4e09\u3001\u538b\u7f29\u6548\u679c": [[240, "id31"]], "\u56db\u3001\u90e8\u7f72\u65b9\u5f0f": [[240, "id32"]], "\u4e94\u3001\u8865\u5145\u8bf4\u660e\u4e0e\u5efa\u8bae": [[240, "id33"]], "\u5907\u6ce8 4\uff1a\u8bb0\u5fc6\u5934\u7684\u9009\u62e9\u65b9\u6cd5": [[240, "id34"]], "\u5907\u6ce8 5\uff1a\u81ea\u9002\u5e94\u7a00\u758f\u5316": [[240, "id35"]], "3.4\u2002_\u2002Model Shape": [[240, "model-shape"]], "3.4 | \u6a21\u578b\u7ed3\u6784\uff08Model Shape\uff09": [[240, "id37"]], "3.5 | \u8bad\u7ec3\u8bbe\u8ba1\uff08Training Designs\uff09": [[240, "training-designs"]], "3.6\u2002_\u2002Two-stage Pretrain": [[240, "two-stage-pretrain"]], "\u4e00\u3001\u9884\u8bad\u7ec3\u7684\u4e24\u4e2a\u9636\u6bb5": [[240, "id39"]], "\u4e8c\u3001\u5bf9 continual train \u7684\u4f18\u5316": [[240, "continual-train"]], "\u4e09\u3001\u9632\u6b62\u4fe1\u606f\u6cc4\u9732": [[240, "id40"]], "4\u2002_\u2002Pretraining Data": [[240, "pretraining-data"]], "4.1 \u6570\u636e\u6536\u96c6\uff08Data Collection\uff09": [[240, "data-collection"]], "4.2 \u6570\u636e\u8fc7\u6ee4\uff08Filtering\uff09": [[240, "filtering"]], "4.3 \u5206\u8bcd\u5668\uff08Tokenizer\uff09": [[240, "tokenizer"]], "4.4 \u77e5\u8bc6\u5e93\uff08Knowledge Base\uff09": [[240, "knowledge-base"]], "5\u2002_\u2002Pretrain": [[240, "pretrain"]], "1. \u9884\u8bad\u7ec3\u603b\u4f53\u8bbe\u8ba1": [[240, "id43"]], "2. \u8bad\u7ec3\u8bbe\u7f6e\uff08Set-up\uff09": [[240, "set-up"]], "3. \u9884\u70ed\u9636\u6bb5\uff08Warmup Stage\uff09": [[240, "warmup-stage"]], "4. \u6301\u7eed\u8bad\u7ec3\u9636\u6bb5\uff08Continual Train Stage\uff09": [[240, "continual-train-stage"]], "6\u2002_\u2002Fine-tuning and Alignment": [[240, "fine-tuning-and-alignment"]], "6.1 \u76d1\u7763\u5fae\u8c03\uff08Supervised Finetuning, SFT\uff09": [[240, "supervised-finetuning-sft"]], "6.2 \u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08Direct Preference Optimization, DPO\uff09": [[240, "direct-preference-optimization-dpo"]], "7\u2002_\u2002Evaluation": [[240, "evaluation"]], "7.1 \u901a\u7528\u80fd\u529b\u8bc4\u4f30": [[240, "id45"]], "7.2 \u5bf9\u8bdd\u80fd\u529b\u8bc4\u4f30": [[240, "id46"]], "7.3 \u5e7b\u89c9\u4e0e\u4e8b\u5b9e\u6027\u8bc4\u4f30": [[240, "id47"]], "7.4 \u4e13\u4e1a\u4efb\u52a1\u8bc4\u4f30": [[240, "id48"]], "7.5\u2002_\u2002Inference Speed": [[240, "inference-speed"]], "8\u2002_\u2002Conclusion": [[240, "conclusion"]], "Appendix A Cost Estimation": [[240, "appendix-a-cost-estimation"]], "\u6a21\u578b\u53c2\u6570\u8bbe\u5b9a": [[240, "id52"]], "\u9690\u5f0f\u8bb0\u5fc6\uff08Implicit Memory\uff09\u6210\u672c": [[240, "implicit-memory"]], "\u663e\u5f0f\u8bb0\u5fc6\uff08Explicit Memory\uff09\u6210\u672c": [[240, "explicit-memory"]], "\u5916\u90e8\u4fe1\u606f\uff08External Information\uff0c\u5982 RAG\uff09\u6210\u672c": [[240, "external-information-rag"]], "\u7efc\u5408\u6bd4\u8f83": [[240, "id53"]], "\u62d3\u5c55\u8ba8\u8bba": [[240, "id54"]], "Appendix B Vector Compression": [[240, "appendix-b-vector-compression"]], "Appendix C Supplementary Evaluation Results": [[240, "appendix-c-supplementary-evaluation-results"]], "2505.14683_Emerging Properties in Unified Multimodal Pretraining": [[241, "emerging-properties-in-unified-multimodal-pretraining"]], "2 Model": [[241, "model"]], "1. \u6a21\u578b\u67b6\u6784\u6982\u89c8": [[241, "id3"]], "2. \u751f\u6210\u7b56\u7565": [[241, "id4"]], "3. \u6a21\u578b\u7ec6\u8282": [[241, "id5"]], "4. \u5e7f\u4e49\u56e0\u679c\u6ce8\u610f\u529b\uff08Generalized Causal Attention\uff09": [[241, "generalized-causal-attention"]], "5. Transformer\u7ed3\u6784\u9009\u62e9\u4e0e\u5b9e\u9a8c": [[241, "transformer"]], "3 Data": [[241, "data"]], "\u6570\u636e\u7279\u70b9\u4e0e\u76ee\u6807": [[241, "id7"]], "\u6570\u636e\u6765\u6e90\u4e0e\u7edf\u8ba1": [[241, "id8"]], "\u6570\u636e\u6784\u5efa\u65b9\u6cd5": [[241, "id9"]], "3.1 \u7eaf\u6587\u672c\u6570\u636e": [[241, "id10"]], "3.2 \u56fe\u50cf-\u6587\u672c\u914d\u5bf9\u6570\u636e": [[241, "id11"]], "3.3 \u89c6\u89c9-\u6587\u672c\u4ea4\u9519\u6570\u636e": [[241, "id12"]], "3.3.1 \u6570\u636e\u8fc7\u6ee4": [[241, "id13"]], "3.3.2 \u6570\u636e\u6784\u9020": [[241, "id14"]], "3.3.3 \u63a8\u7406\u589e\u5f3a\u6570\u636e": [[241, "id15"]], "\u6570\u636e\u8bad\u7ec3\u7b56\u7565": [[241, "id16"]], "4 Training": [[241, "training"]], "1. \u591a\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565": [[241, "id18"]], "2. \u5173\u952e\u8d85\u53c2\u6570\u8c03\u6574": [[241, "id19"]], "4.1 \u6570\u636e\u91c7\u6837\u6bd4\u4f8b": [[241, "id20"]], "4.2 \u5b66\u4e60\u7387\u8bbe\u7f6e": [[241, "id21"]], "5 Evaluation": [[241, "evaluation"]], "6 Emerging Properties": [[241, "emerging-properties"]], "1. \u65b0\u5174\u5c5e\u6027\u7684\u5b9a\u4e49\u4e0e\u7814\u7a76\u80cc\u666f": [[241, "id23"]], "2. \u4efb\u52a1\u8868\u73b0\u4e0e\u8bad\u7ec3\u9636\u6bb5\u7684\u5173\u7cfb": [[241, "id24"]], "3. \u591a\u6a21\u6001\u7279\u5f81\u7684\u91cd\u8981\u6027": [[241, "id25"]], "4. \u5b9a\u6027\u5206\u6790\u4e0e\u751f\u6210\u8d28\u91cf\u63d0\u5347": [[241, "id26"]], "5. \u6838\u5fc3\u53d1\u73b0\u4e0e\u7ed3\u8bba": [[241, "id27"]], "7 Main Results": [[241, "main-results"]], "7.1 \u56fe\u50cf\u7406\u89e3": [[241, "id29"]], "7.2 \u56fe\u50cf\u751f\u6210": [[241, "id30"]], "7.3 \u56fe\u50cf\u7f16\u8f91": [[241, "id31"]], "7.4 \u5e26\u6709\u63a8\u7406\u7684\u751f\u6210/\u7f16\u8f91": [[241, "id32"]], "7.5 \u4e16\u754c\u5efa\u6a21": [[241, "id33"]], "7.6 More Qualitative Results": [[241, "more-qualitative-results"]], "9 Acknowledgement": [[241, "acknowledgement"]], "MemOS: A Memory OS for AI System": [[242, "memos-a-memory-os-for-ai-system"]], "LLM \u603b\u7ed3\uff1a": [[242, "llm"]], "2. \u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3": [[242, "id2"]], "3. \u56db\u5927\u5178\u578b\u6311\u6218": [[242, "id3"]], "4. MemOS\u7684\u63d0\u51fa\u4e0e\u6838\u5fc3\u7406\u5ff5": [[242, "memos"]], "5. \u603b\u7ed3\u4e0e\u610f\u4e49": [[242, "id4"]], "\u4e00\u3001\u8bb0\u5fc6\u7814\u7a76\u7684\u56db\u4e2a\u9636\u6bb5": [[242, "id6"]], "\u4e8c\u3001\u7b2c\u4e00\u9636\u6bb5\uff1a\u8bb0\u5fc6\u5b9a\u4e49\u4e0e\u63a2\u7d22": [[242, "id7"]], "1. \u8bb0\u5fc6\u5206\u7c7b\u4e0e\u6846\u67b6": [[242, "id8"]], "2. \u9690\u5f0f\u8bb0\u5fc6": [[242, "id9"]], "\u9690\u5f0f\u957f\u671f\u8bb0\u5fc6": [[242, "id10"]], "\u9690\u5f0f\u77ed\u671f\u8bb0\u5fc6": [[242, "id11"]], "3. \u663e\u5f0f\u8bb0\u5fc6": [[242, "id12"]], "\u663e\u5f0f\u77ed\u671f\u8bb0\u5fc6": [[242, "id13"]], "\u4e09\u3001MemOS \u7684\u521d\u6b65\u6784\u60f3": [[242, "id14"]], "\u56db\u3001\u603b\u7ed3": [[242, "id15"]], "Explicit Long-term Memory in LLMs": [[242, "explicit-long-term-memory-in-llms"]], "2.1 \u663e\u5f0f\u957f\u671f\u8bb0\u5fc6\u7684\u5efa\u7acb\uff08Stage 1\uff09": [[242, "stage-1"]], "2.2 \u4eba\u8111\u5f0f\u8bb0\u5fc6\u673a\u5236\u7684\u5f15\u5165\uff08Stage 2\uff09": [[242, "stage-2"]], "2.3 \u57fa\u4e8e\u5de5\u5177\u7684\u8bb0\u5fc6\u7ba1\u7406\uff08Stage 3\uff09": [[242, "stage-3"]], "2.4 \u7cfb\u7edf\u5316\u8bb0\u5fc6\u6cbb\u7406\uff08Stage 4\uff09": [[242, "stage-4"]], "\u4e00\u3001MemOS \u7684\u613f\u666f\uff083.1 Vision of MemOS\uff09": [[242, "memos-3-1-vision-of-memos"]], "\u4e8c\u3001\u4ece\u4f20\u7edf\u64cd\u4f5c\u7cfb\u7edf\u5230\u8bb0\u5fc6\u64cd\u4f5c\u7cfb\u7edf\uff083.2 From Computer OS to Memory OS\uff09": [[242, "from-computer-os-to-memory-os"]], "4 Memory Modeling in MemOS": [[242, "memory-modeling-in-memos"]], "4.1 \u5185\u5b58\u7c7b\u578b\u4e0e\u8bed\u4e49\u6f14\u5316\u8def\u5f84": [[242, "id18"]], "4.2 Memory Cube\uff08MemCube\uff09\uff1a\u5185\u5b58\u7684\u6838\u5fc3\u8d44\u6e90\u5355\u5143": [[242, "memory-cube-memcube"]], "5 Architecture of MemOS": [[242, "architecture-of-memos"]], "\u603b\u7ed3\uff1aMemOS \u67b6\u6784\u4e0e\u6267\u884c\u6d41\u7a0b": [[242, "id20"]], "\u4e00\u3001MemOS \u7684\u4e09\u5c42\u67b6\u6784": [[242, "id21"]], "1. \u63a5\u53e3\u5c42\uff08Interface Layer\uff09": [[242, "interface-layer"]], "2. \u64cd\u4f5c\u5c42\uff08Operation Layer\uff09": [[242, "operation-layer"]], "3. \u57fa\u7840\u8bbe\u65bd\u5c42\uff08Infrastructure Layer\uff09": [[242, "infrastructure-layer"]], "\u4e8c\u3001MemOS \u6267\u884c\u6d41\u7a0b\u4e0e\u4ea4\u4e92\u673a\u5236": [[242, "id22"]], "\u4e09\u3001MemOS \u7684\u8bbe\u8ba1\u4f18\u52bf": [[242, "id23"]], "5.5.1 MemGovernance": [[242, "memgovernance"]], "5.5.1 MemGovernance\uff08\u5185\u5b58\u6cbb\u7406\u6a21\u5757\uff09": [[242, "id25"]], "5.5.2 MemVault\uff08\u5185\u5b58\u5b58\u50a8\u4e0e\u8def\u7531\u57fa\u7840\u8bbe\u65bd\uff09": [[242, "memvault"]], "5.5.3 MemLoader \u4e0e MemDumper\uff08\u5185\u5b58\u52a0\u8f7d\u4e0e\u5bfc\u51fa\u6a21\u5757\uff09": [[242, "memloader-memdumper"]], "5.5.4 MemStore\uff08\u5185\u5b58\u5b58\u50a8\u4e0e\u5206\u53d1\u63a5\u53e3\uff09": [[242, "memstore"]], "1. \u6574\u4f53\u7cfb\u7edf\u8bc4\u4f30\uff08End-to-End Evaluation on LOCOMO\uff09": [[242, "end-to-end-evaluation-on-locomo"]], "2. \u5185\u5b58\u68c0\u7d22\u8bc4\u4f30\uff08Evaluation of Memory Retrieval\uff09": [[242, "evaluation-of-memory-retrieval"]], "3. KV\u7f13\u5b58\u52a0\u901f\u8bc4\u4f30\uff08Evaluation of KV-Based Memory Acceleration\uff09": [[242, "kv-evaluation-of-kv-based-memory-acceleration"]], "7 MemOS for Architecture Innovation and Applications": [[242, "memos-for-architecture-innovation-and-applications"]], "\u4e00\u3001MemOS\u63a8\u52a8\u7684\u67b6\u6784\u521b\u65b0": [[242, "id28"]], "\u4e8c\u3001MemOS\u7684\u5e94\u7528\u573a\u666f": [[242, "id29"]]}, "indexentries": {}})