# AI工程


## 🧠 一、通用后端工程能力

### 1. 系统设计与架构
- **常见架构**：微服务、RESTful API、消息队列（如Kafka、RabbitMQ）
- **扩展性与高可用性设计**：如服务降级、负载均衡
- **数据库设计**：SQL/NoSQL 的使用场景及性能优化

### 2. 编程能力
- 常见语言如 Python、Go、Java 的熟练程度
- 编写**高可维护性、模块化的代码**
- 数据结构与算法（主要考察实际应用能力，而非刷题）

### 3. DevOps / 工程化能力
- 容器化（Docker）、CI/CD 流程理解与实践
- 监控与日志系统（如 Prometheus, Grafana, ELK）
- 单元测试、Mock 测试等工程质量保障措施

---

## 🤖 二、AI场景相关后端能力

### 1. 模型服务化经验（关键）
- **模型部署方式**：
  - 例如使用 **FastAPI / Flask / TorchServe / Triton** 部署 PyTorch 模型
  - 模型热更新机制
- **推理性能优化**：
  - ONNX / TensorRT / quantization / batch 推理
  - 多模型加载 / 多GPU资源调度

### 2. 数据流与异步处理
- 大模型调用往往是 **高延迟任务**，要了解：
  - 异步任务框架（Celery / FastAPI 的 `async` / asyncio）
  - 推理任务排队与调度系统设计（如优先级、多租户支持）

### 3. 大模型服务生态理解（加分项）
- 各类 LLM 的调用模式（OpenAI API、vLLM、本地模型）
- Prompt 工程、Embedding 检索、向量数据库（如FAISS、Milvus）
- Chat History 管理 / 多轮对话缓存

---

## 🧪 三、面试官提问建议（可分阶段）

### 🔹 技术基础
- Python多线程与多进程的区别及应用？
- 如何设计一个支持并发高、可扩展的模型推理API服务？

### 🔹 实战经验
- 描述你部署过的AI模型服务，主要技术选型和难点？
- 如何处理模型调用延迟大、用户请求多的问题？

### 🔹 场景设计题
- “给你一个ChatGPT类服务，用户量暴涨，响应变慢，你会怎么排查并优化？”
- “如果你要部署一个10GB的大模型给多个微服务用，如何高效复用资源？”

---

## ✅ 四、面试官评估维度

| 维度             | 说明                                                                 |
|------------------|----------------------------------------------------------------------|
| 技术深度         | 是否理解模型服务背后的系统机制、性能瓶颈                             |
| 实践经验         | 是否有真实的AI后端部署和线上运维经验                                 |
| 架构能力         | 是否能设计出可维护、可扩展、可靠的后端架构                           |
| 沟通与协作       | 能否与算法工程师、前端、产品等高效沟通                               |
| 问题解决能力     | 面对线上突发情况，是否有应急排查和优化的能力                         |

---


## 🧩 一、整体通用评估维度（适用于AI工程化）

| 维度           | 示例说明 |
|----------------|----------|
| 系统理解       | 是否理解整个AI系统的模块职责、数据流动和部署方式 |
| 工程落地能力   | 是否能从需求出发，拆解并实现可交付的服务模块 |
| 工程质量控制   | 单测/集成测试/代码结构/CI/CD 是否有意识 |
| 算法协同经验   | 能否与算法、数据、前端团队良好配合 |
| 性能与扩展性   | 在大规模并发或大模型上下文中，能否考虑性能瓶颈与优化方向 |

---

## 📦 二、分组件的面试要点

### 1. **AI平台/模型管理平台**
> 涉及模型注册、版本管理、推理服务、资源调度等

**关注点：**
- 模型上线流程的标准化（如模型注册、A/B测试、灰度发布）
- 服务架构（是否支持多用户、多租户、分布式资源调度）
- 与Kubernetes、Kubeflow等平台的集成经验
- 模型推理服务的设计（如TorchServe、Triton、自研服务）

**示例问题：**
- 如何实现模型的动态加载和多版本切换？
- 模型注册中心设计需要考虑哪些字段？如何支持审计和回滚？
- 描述你使用Kubernetes管理AI任务的经验，有无资源隔离实践？

---

### 2. **数据标注系统**
> 包括数据采集、标注任务流转、质检、反馈闭环等

**关注点：**
- 标注任务调度系统设计（任务拆分/分发/进度追踪）
- 用户权限和审计设计（标注员 vs 审核员等角色）
- 数据存储设计（如图片/视频/音频文件 + 标注 JSON）
- 与训练平台、数据管理平台的联动

**示例问题：**
- 如何设计一个可扩展的图像标注任务系统？
- 多人协同标注时，如何避免任务冲突与数据丢失？
- 标注数据如何进行版本管理与合规追踪？

---


### 4. **Agent系统（如RAG Agent、数据分析助手）**
> 通常基于LLM构建，支持任务规划、多轮对话、工具调用等

**关注点：**
- Prompt工程、插件化工具调用框架（如LangChain、OpenAgents）
- 多轮上下文管理（token控制、session恢复、上下文记忆）
- 外部工具调用（搜索、代码执行、数据库查询等）封装与容错设计
- 推理耗时优化、缓存策略（如Embedding缓存、向量召回预取）

**示例问题：**
- 你如何设计一个RAG Agent支持多轮数据分析任务？
- 如何在调用多个外部工具时保持上下文一致性与错误处理能力？
- 实时多Agent协作时如何调度资源与防止死锁？

---

## ✅ 三、面试官行动建议

| 操作事项                  | 建议做法 |
|---------------------------|----------|
| 面试前准备模块画像        | 根据候选人经历匹配模块方向提问 |
| 实战问题优于算法题        | 多问“你怎么做过”，少问纯算法 |
| 要留一道设计题            | 比如“设计一个可复用的标注系统模块”，看候选人拆解思路 |
| 留10分钟自由交流          | 候选人自由提问，看沟通风格是否合拍 |
| 建立模块化评估表格        | 方便横向比较多个候选人 |

---

## 范例

AI后端开发工程师
岗位职责
1.  构建高并发、低延迟的大模型服务架构，优化GPU资源调度与推理性能
2.  设计RAG系统后端架构，实现高效检索（向量+传统）、缓存与异步处理机制
3.  开发Agent系统核心模块，包括工具调用、记忆存储、会话状态管理等
4.  搭建模型训练/推理平台，支持分布式训练、AB测试、监控告警等功能
5.  探索模型轻量化技术在边缘设备的落地应用
岗位要求
1.  本科及以上学历，计算机相关专业，3年以上后端开发经验，精通Go/Python/Java
2.  具备以下核心技术能力：
o 大模型服务化：熟悉vLLM/TGI等推理框架，掌握动态批处理、连续批处理等优化技术
o RAG系统架构：精通向量数据库（Milvus/Weaviate）、混合检索系统实现
o Agent系统支撑：掌握工具调用服务、长会话管理、状态持久化等实现
o 多模态服务：了解多模态数据处理与传输优化
3.  熟悉高并发架构，精通数据库（PostgreSQL/Redis）和消息队列（Kafka/RabbitMQ）
4.  出色的系统设计能力，能平衡性能、成本与扩展性需求








