

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="zh-CN" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="zh-CN" > <!--<![endif]-->
<head>


<!-- start added 2025-04-14   增加对markdown中公式的支持 -->
<script>
window.MathJax = {
    tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true
    },
    options: {
        ignoreHtmlClass: "tex2jax_ignore|mathjax_ignore",
        processHtmlClass: "tex2jax_process|mathjax_process|math|output_area"
    }
};
</script>
<script defer="defer" src="https://fastly.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<!-- end added 2025-04-14   增加对markdown中公式的支持 -->


<!-- start added 2025-08-06   增加对mermaid图的支持 -->
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', function() {
    mermaid.initialize({
        startOnLoad: true,
        theme: 'default',
        flowchart: { useMaxWidth: true }
    });
});
</script>
<!--  end added 2025-08-06   增加对mermaid图的支持 -->




  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>动手学深度学习(Dive into Deep Learning) &mdash; 新溪-gordon V2025.11 文档</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
    <link rel="index" title="索引" href="../../../genindex.html" />
    <link rel="search" title="搜索" href="../../../search.html" />
    <link rel="next" title="架构相关" href="../../architecture.html" />
    <link rel="prev" title="Build a Large Language Model (From Scratch)" href="Build_LLM_From_Scratch.html" /> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>
  <script src="../../../_static/js/jquery.min.js"></script>


<!-- 评论插件 gittalk start -->
<!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script> -->
<!-- 评论插件 gittalk end -->


</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../index.html" class="icon icon-home"> 新溪-gordon
          

          
          </a>

          
            
            
              <div class="version">
                V2025.11
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../../book.html">书籍</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../bookreview.html">书</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../bookreviews/2021.html">2021年看的书</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../bookreviews/2021s/cryptography-graph.html">图解密码技术</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bookreviews/2021s/deep-learning-with-python.html">Deep learning with Python</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bookreviews/2021s/how-networks-work.html">网络是怎么连接的</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bookreviews/2021s/building-microservices.html">微服务设计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bookreviews/2021s/microservice_design_principle_and_architecture.html">微服务设计原理与架构</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bookreviews/2021s/microservice-governance.html">微服务治理: 体系、架构及实践</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bookreviews/2021s/TCPIP-ILLustrated-Volume1.html">TCP/IP ILLustrated Volume 1: The Protocols</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bookreviews/2021s/SRE.html">SRE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bookreviews/2021s/the-site-reliability-workbook.html">The Site Reliability Workbook</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bookreviews/2021s/bitcoin-and-cryptocurrency-technologies.html">Bitcoin and Cryptocurrency Technologies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bookreviews/2021s/other.html">其他</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../bookreviews/detail.html">详情</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../bookreviews/detail.html#id3">编码实践</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bookreviews/detail.html#id4">设计模式</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bookreviews/detail.html#id5">工程实践</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bookreviews/detail.html#id6">领域驱动设计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bookreviews/detail.html#id7">产品与需求</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bookreviews/detail.html#id8">开发文化</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bookreviews/detail.html#id9">管理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bookreviews/detail.html#id10">科幻小说</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bookreviews/detail.html#id11">其他相关</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../booklist.html">要看的书</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../booklists/classic.html">经典书</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../booklists/classic.html#it-core">IT Core</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../booklists/classic.html#id3">编译原理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../booklists/classic.html#id4">组成原理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../booklists/classic.html#it">IT 设计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../booklists/classic.html#id5">管理</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../booklists/AI.html">AI 相关</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../booklists/AI.html#id2">推荐系统</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../booklists/IT.html">IT相关</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../booklists/IT.html#id2">区块链</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../booklists/IT.html#id3">统计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../booklists/IT.html#id4">网络</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../booklists/IT.html#id5">实时协同</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../booklists/methodology.html">方法论</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../booklists/fiction.html">小说</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../booklists/fiction.html#science-fiction">科幻小说science fiction</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../booklists/source.html">书籍来源</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../booklists/sources/geek.html">极客来源</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../booklist.html#id3">数学基础</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../booklist.html#id4">语言经典</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../booklist.html#c">C 语言</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../booklist.html#id5">计算机经典</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../booklist.html#id6">计算机语言设计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../booklist.html#id7">其他</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="../../ai.html">ai</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../Microsoft-AI-For-Beginners.html">Microsoft: AI-For-Beginners</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Microsoft-AI-For-Beginners.html#i-introduction-to-ai">I Introduction to AI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Microsoft-AI-For-Beginners.html#ii-symbolic-ai">II Symbolic AI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Microsoft-AI-For-Beginners.html#iii-introduction-to-neural-networks">III Introduction to Neural Networks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Microsoft-AI-For-Beginners.html#iv-computer-vision">IV Computer Vision</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Microsoft-AI-For-Beginners.html#v-nlp">V. NLP</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Microsoft-AI-For-Beginners.html#vi-other">VI. Other</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Microsoft-AI-For-Beginners.html#vii-ethics">VII. Ethics</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Microsoft-ML-for-Beginners.html">Microsoft: Machine Learning for Beginners</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Microsoft-ML-for-Beginners.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Microsoft-ML-for-Beginners.html#regression">2. Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Microsoft-ML-for-Beginners.html#web-app">3. Web-App</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Microsoft-ML-for-Beginners.html#classification">4. Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Microsoft-ML-for-Beginners.html#clustering">5. Clustering</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Microsoft-ML-for-Beginners.html#nlp">6. NLP</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Microsoft-ML-for-Beginners.html#timeseries">7. TimeSeries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Microsoft-ML-for-Beginners.html#reinforcement">8. Reinforcement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Microsoft-ML-for-Beginners.html#real-world">9. Real-World</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Microsoft-Generative-AI-For-Beginners.html">Microsoft: Generative AI For Beginners</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Microsoft-Generative-AI-For-Beginners.html#id2">第一章: 简介</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Microsoft-Generative-AI-For-Beginners.html#llms">第二章: 不同的 LLMs对比</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Microsoft-Generative-AI-For-Beginners.html#ai">第三章: AI安全</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Microsoft-Generative-AI-For-Beginners.html#id3">第四章: 提示工程基础</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Microsoft-Generative-AI-For-Beginners.html#id4">第五章: 提示工程进阶</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Microsoft-Generative-AI-For-Beginners.html#id5">第八章: 创建搜索应用</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Getting-Started-with-OpenCV.html">Getting Started with OpenCV</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Microsoft-Learn-Introduction-to-PyTorch.html">Microsoft Learn: Introduction to PyTorch</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Microsoft-Learn-Introduction-to-PyTorch.html#id2">简介</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../Microsoft-Learn-Introduction-to-NLP-with-PyTorch.html">Microsoft Learn: Introduction to NLP with PyTorch</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Microsoft-Learn-Introduction-to-NLP-with-PyTorch.html#id2">简介</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Microsoft-Learn-Introduction-to-NLP-with-PyTorch.html#representing-text-as-tensors">2. Representing text as Tensors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Microsoft-Learn-Introduction-to-NLP-with-PyTorch.html#bag-of-words-and-tf-idf-representations">3. Bag-of-Words and TF-IDF representations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Microsoft-Learn-Introduction-to-NLP-with-PyTorch.html#embeddings">4. Embeddings</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../HuggingFace-Learn.html">HuggingFace: Learn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Kaggle-Learn.html">Kaggle Learn</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../Kaggle-Learn.html#intermediate-machine-learning">Intermediate Machine Learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Kaggle-Learn.html#intro-to-deep-learning">Intro to Deep Learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../Kaggle-Learn.html#id4">参考</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../scikit-learn.html">scikit-learn 1.3.2</a></li>
<li class="toctree-l3"><a class="reference internal" href="Build_LLM_From_Scratch.html">Build a Large Language Model (From Scratch)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="Build_LLM_From_Scratch.html#understanding-llm">1. Understanding LLM</a></li>
<li class="toctree-l4"><a class="reference internal" href="Build_LLM_From_Scratch.html#working-with-text-data">2. Working with Text Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="Build_LLM_From_Scratch.html#coding-attention-mechanisms">3. Coding Attention Mechanisms</a></li>
<li class="toctree-l4"><a class="reference internal" href="Build_LLM_From_Scratch.html#implementing-a-gpt-model-from-scratch-to-generate-text">4 Implementing a GPT model from Scratch To Generate Text</a></li>
<li class="toctree-l4"><a class="reference internal" href="Build_LLM_From_Scratch.html#pretraining-on-unlabeled-data">5 Pretraining on Unlabeled Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="Build_LLM_From_Scratch.html#fine-tuning-for-classification">6 Fine-tuning for classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="Build_LLM_From_Scratch.html#fine-tuning-to-follow-instructions">7 Fine-tuning to follow instructions</a></li>
<li class="toctree-l4"><a class="reference internal" href="Build_LLM_From_Scratch.html#appendix-a-introduction-to-pytorch">Appendix A. Introduction to PyTorch</a></li>
<li class="toctree-l4"><a class="reference internal" href="Build_LLM_From_Scratch.html#appendix-b-references-and-further-reading">Appendix B. References and Further Reading</a></li>
<li class="toctree-l4"><a class="reference internal" href="Build_LLM_From_Scratch.html#appendix-c-exercise-solutions">Appendix C. Exercise Solutions</a></li>
<li class="toctree-l4"><a class="reference internal" href="Build_LLM_From_Scratch.html#appendix-d-adding-bells-and-whistles-to-the-training-loop">Appendix D. Adding Bells and Whistles to the Training Loop</a></li>
<li class="toctree-l4"><a class="reference internal" href="Build_LLM_From_Scratch.html#appendix-e-parameter-efficient-fine-tuning-with-lora">appendix E Parameter-efficient fine- tuning with LoRA</a></li>
<li class="toctree-l4"><a class="reference internal" href="Build_LLM_From_Scratch.html#id8">其他</a></li>
</ul>
</li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">动手学深度学习(Dive into Deep Learning)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id2">前言</a></li>
<li class="toctree-l4"><a class="reference internal" href="#part-1-basics-and-preliminaries">Part 1: Basics and Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="#part-2-modern-deep-learning-techniques">Part 2: Modern Deep Learning Techniques</a></li>
<li class="toctree-l4"><a class="reference internal" href="#part-3-scalability-efficiency-and-applications">Part 3: Scalability, Efficiency, and Applications</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../architecture.html">架构相关</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../architectures/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86%E4%B8%8E%E6%9E%B6%E6%9E%84.html">微服务设计原理与架构</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../architectures/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86%E4%B8%8E%E6%9E%B6%E6%9E%84.html#id3">微服务建模</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../architectures/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86%E4%B8%8E%E6%9E%B6%E6%9E%84.html#id17">服务拆分与集成</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../architectures/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86%E4%B8%8E%E6%9E%B6%E6%9E%84.html#id18">微服务架构关键要素</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../architectures/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86%E4%B8%8E%E6%9E%B6%E6%9E%84.html#id21">参考</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../architectures/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E7%B2%BE%E7%B2%B9.html">领域驱动设计精粹</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../architectures/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E7%B2%BE%E7%B2%B9.html#id4">第 2 章 运用限界上下文与通用语言进行战略设计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../architectures/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E7%B2%BE%E7%B2%B9.html#id6">第 3 章 运用子域进行战略设计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../architectures/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E7%B2%BE%E7%B2%B9.html#id7">第 4 章 运用上下文映射进行战略设计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../architectures/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E7%B2%BE%E7%B2%B9.html#id8">第 5 章 运用聚合进行战术设计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../architectures/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E7%B2%BE%E7%B2%B9.html#id9">第 6 章 运用领域事件进行战术设计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../architectures/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E7%B2%BE%E7%B2%B9.html#id10">第 7 章 加速和管理工具</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../architectures/%E5%AE%9E%E7%8E%B0%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1.html">实现领域驱动设计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../architectures/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1.html">领域驱动设计</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../optimize.html">优化相关</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../optimizes/%E6%80%A7%E8%83%BD%E4%B9%8B%E5%B7%85.html">性能之巅</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../optimizes/%E6%80%A7%E8%83%BD%E4%B9%8B%E5%B7%85.html#id3">书评</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../protocol.html">协议相关</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html">UNIX 网络编程卷1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id3">第1章 简介</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#tcp-udpsctp">第2章 传输层: TCP, UDP和SCTP</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id8">第3章 套接字编程简介</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id14">第4章 基本TCP套接字编程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id16">第5章 TCP客户/服务器程序示例</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#i-o-selectpoll">第6章 I/O复用: select和poll函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id24">第7章 套接字选项</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#udp">第8章 基本UDP套接字编程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id26">第9章 基本SCTP套接字编程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id27">第11章 名字与地址转换</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#ipv4ipv6">第12章 IPv4与IPv6的互操作性</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#inetd">第13章 守护进程和inetd超级服务器</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id31">第14章 高级I/O函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#unix">第15章 Unix域协议</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id35">第16章 非阻塞式I/O</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#ioctl">第17章 ioctl操作</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id36">第18章 路由套接字</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id37">第19章 密钥管理套接字</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id38">第20章 广播</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id41">第21章 多播</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id47">第22章 高级UDP套接字编程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id51">第23章 高级SCTP套接字编程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id52">第24章 带外数据</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id57">第25章 信号驱动式I/O</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id58">第26章 线程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#ip">第27章 IP选项</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id66">第28章 原始套接字</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id70">第29章 数据链路访问</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id74">第30章 客户/服务器程序设计范式</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#a-ipv4-ipv6-icmpv4icmpv6">附录A IPv4, IPv6, ICMPv4和ICMPv6</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id77">其他</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../protocols/TCP-IP%20%E8%AF%A6%E6%83%85%E5%8D%B71.html">TCP/IP 详情-卷1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/TCP-IP%20%E8%AF%A6%E6%83%85%E5%8D%B71.html#id3">第1章 概 述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/TCP-IP%20%E8%AF%A6%E6%83%85%E5%8D%B71.html#id4">第2章 链 路 层</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/TCP-IP%20%E8%AF%A6%E6%83%85%E5%8D%B71.html#ip">第3章 IP:网际协议</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/TCP-IP%20%E8%AF%A6%E6%83%85%E5%8D%B71.html#id15">其他</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../protocols/TCP-IP%20%E8%AF%A6%E6%83%85%E5%8D%B71-%E7%AC%AC2%E7%89%88.html">TCP:IP 详情卷1-第2版</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../protocols/TCP-IP%20%E8%AF%A6%E6%83%85%E5%8D%B71-%E7%AC%AC2%E7%89%88.html#id3">第1章 概 述</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../edge.html">边缘相关</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../edges/%E9%9B%BE%E8%AE%A1%E7%AE%97%E4%B8%8E%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%EF%BC%9A%E5%8E%9F%E7%90%86%E5%8F%8A%E8%8C%83%E5%BC%8F.html">雾计算与边缘计算: 原理及范式</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html">边缘计算入门 20 课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#id3">第 01 课: 边缘计算深度调研</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#id17">第 02 课: 云走向边缘, 云将无处不在</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#id27">第 03 课: 信通院-边缘计算发展现状与趋势展望</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#edgerec">第 04 课: EdgeRec: 边缘计算在推荐系统中的应用</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#id51">第 05 课: 阿里云边缘云原生应用实践应用实践</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#kubeedge-sedna-0-1">第 06 课: KubeEdge 子项目 Sedna 0.1 发布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#superedge">第 07 课: 用 SuperEdge 统管边缘设备和机器</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#k8s-10">第 08 课: 如何使用 k8s 管理 10 万边缘节点</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#ai">第 09 课: 边云协同-打通 AI 最后一公里</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#edgeadm-k8s">第 10 课: 用 edgeadm 一键安装边缘 K8s 集群</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#kubeedge-10086">第 11 课: 基于 KubeEdge 实现 10086 客服云边协同平台</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#volcano">第 12 课: Volcano 架构设计与原理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#id57">第 13 课: 一文读懂 SuperEdge 的云边隧道</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#id58">第 14 课: 打破内网壁垒-从云端一次添加上千边缘节点</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#id59">第 15 课: 一文读懂 SuperEdge 边缘容器架构与原理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#id60">第 16 课: 2020 十大边缘计算开源项目</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#addon-superedge-k8s">第 17 课: Addon SuperEdge 让原生 K8s 管理边缘应用</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#id63">第 18 课: SuperEdge 云边隧道新特性</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#id64">第 19 课: 《深入理解边缘计算》</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#fabedge">第 20 课: FabEdge 边缘网络方案</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#id65">第 21 课: 边缘计算云原生开源方案选型比较</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#id66">参考</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5.html">边缘计算方法与工程实践</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5.html#id3">第1章 边缘计算综述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5.html#id4">第2章 边缘计算基础资源架构技术</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5.html#id5">第3章 边缘计算软件架构</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5.html#id7">第4章 边缘计算安全管理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5.html#id23">第5章 边缘计算应用案例</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5.html#id39">第6章 边缘计算发展展望</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../iot.html">物联网相关</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../iots/%E5%9B%BE%E8%A7%A3%E7%89%A9%E8%81%94%E7%BD%91.html">图解物联网</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../iots/%E5%9B%BE%E8%A7%A3%E7%89%A9%E8%81%94%E7%BD%91.html#id3">第1章 物联网的基础知识</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../iots/%E5%9B%BE%E8%A7%A3%E7%89%A9%E8%81%94%E7%BD%91.html#id4">第 2 章 物联网的架构</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../iots/%E5%9B%BE%E8%A7%A3%E7%89%A9%E8%81%94%E7%BD%91.html#id5">第 3 章 物联网设备</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../iots/%E5%9B%BE%E8%A7%A3%E7%89%A9%E8%81%94%E7%BD%91.html#id9">第 4 章 先进的感测技术</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../iots/%E5%9B%BE%E8%A7%A3%E7%89%A9%E8%81%94%E7%BD%91.html#id12">第 5 章 物联网服务的系统开发</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../iots/%E5%9B%BE%E8%A7%A3%E7%89%A9%E8%81%94%E7%BD%91.html#id14">第 6 章 物联网与数据分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../iots/%E5%9B%BE%E8%A7%A3%E7%89%A9%E8%81%94%E7%BD%91.html#id15">第 7 章 物联网与可穿戴设备</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../iots/%E5%9B%BE%E8%A7%A3%E7%89%A9%E8%81%94%E7%BD%91.html#id16">第 8 章 物联网与机器人</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../iots/%E7%89%A9%E8%81%94%E7%BD%91%E8%AE%BE%E8%AE%A1.html">物联网设计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../iots/%E7%89%A9%E8%81%94%E7%BD%91%E8%AE%BE%E8%AE%A1.html#id3">第一部分 原型阶段</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../iots/%E8%87%AA%E5%B7%B1%E5%8A%A8%E6%89%8B%E8%AE%BE%E8%AE%A1%E7%89%A9%E8%81%94%E7%BD%91.html">自己动手设计物联网</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../lang.html">编程语言相关</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../langs/C%20%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1.html">C 程序设计</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../geek.html">极客时间</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../geeks/principle.html">[重要]编程基础</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/principles/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86.html">深入浅出计算机组成原理</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86.html#id4">指令和运算</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86.html#id15">处理器</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86.html#id35">书籍</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/principles/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98.html">网络编程实战</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98.html#id4">第一模块: 基础篇</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98.html#id28">第二模块: 提高篇</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98.html#id48">第三模块: 性能篇</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98.html#id62">第四模块: 实战篇</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98.html#id63">结束语</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/principles/%E8%B6%A3%E8%B0%88%20Linux%20%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html">趣谈 Linux 操作系统</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E8%B6%A3%E8%B0%88%20Linux%20%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html#id2">第二部分 系统初始化 (4 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E8%B6%A3%E8%B0%88%20Linux%20%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html#id10">第三部分 进程管理 (10 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E8%B6%A3%E8%B0%88%20Linux%20%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html#id34">第四部分 内存管理 (7 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E8%B6%A3%E8%B0%88%20Linux%20%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html#id51">第五部分 文件系统 (4 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E8%B6%A3%E8%B0%88%20Linux%20%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html#id60">第六部分 输入输出系统 (5 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E8%B6%A3%E8%B0%88%20Linux%20%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html#id69">第七部分 进程间通信 (7 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E8%B6%A3%E8%B0%88%20Linux%20%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html#id83">第八部分 网络系统 (7 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E8%B6%A3%E8%B0%88%20Linux%20%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html#id90">第九部分 虚拟化 (7 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E8%B6%A3%E8%B0%88%20Linux%20%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html#id100">第十部分 容器化 (4 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E8%B6%A3%E8%B0%88%20Linux%20%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html#id105">实战串讲篇 (9 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E8%B6%A3%E8%B0%88%20Linux%20%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html#id106">学习攻略</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html">编译原理实战课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#id4">语法分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#id7">语义分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#id10">运行时机制</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#ir">中间代码 IR</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#id11">代码优化</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#id12">代码生成</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#ast">解析树和 AST 的区别</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#golang">Golang</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#erlang">Erlang</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#id15">并发</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#meta-programming">元编程-Meta-Programming</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#id19">泛型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#id20">函数式编程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#id21">远程办公</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#id22">如何学习</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#id23">收集</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#id24">参考</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/principles/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98.html">操作系统实战</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98.html#id4">整体设计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98.html#id6">程序的基石：硬件</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98.html#id7">同步原语</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98.html#id8">参考</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/principles/%E6%89%8B%E6%8A%8A%E6%89%8B%E5%B8%A6%E4%BD%A0%E5%86%99%E4%B8%80%E9%97%A8%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80.html">手把手带你写一门编程语言</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E6%89%8B%E6%8A%8A%E6%89%8B%E5%B8%A6%E4%BD%A0%E5%86%99%E4%B8%80%E9%97%A8%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80.html#id4">开篇</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E6%89%8B%E6%8A%8A%E6%89%8B%E5%B8%A6%E4%BD%A0%E5%86%99%E4%B8%80%E9%97%A8%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80.html#id5">词法分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E6%89%8B%E6%8A%8A%E6%89%8B%E5%B8%A6%E4%BD%A0%E5%86%99%E4%B8%80%E9%97%A8%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80.html#id6">语法分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E6%89%8B%E6%8A%8A%E6%89%8B%E5%B8%A6%E4%BD%A0%E5%86%99%E4%B8%80%E9%97%A8%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80.html#id7">语义分析</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/principles/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E8%AF%BE.html">计算机基础实战课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E8%AF%BE.html#id3">课程设计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E8%AF%BE.html#id4">01以史为鉴 (3讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E8%AF%BE.html#mini-cpu-9">02硬件-芯片(手写mini CPU) (9讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E8%AF%BE.html#id11">03环境准备 (2讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E8%AF%BE.html#id12">04语言与指令 (9讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E8%AF%BE.html#id13">05应用与内存 (8讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E8%AF%BE.html#id30">06国庆策划 (3讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E8%AF%BE.html#io-6">07IO与文件 (6讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E8%AF%BE.html#id36">08综合应用 (6讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E8%AF%BE.html#id44">09结束语 (4讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/principles/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E8%AF%BE.html#id45">10技术雷达 (5讲)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../geeks/architecture.html">架构相关</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/architectures/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E.html">左耳听风-陈皓</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E.html#id4">程序员如何用技术变现</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E.html#id19">05 _ 何为技术领导力</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E.html#id25">06 _ 如何才能拥有技术领导力</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/architectures/%E8%AE%B8%E5%BC%8F%E4%BC%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html">许式伟的架构课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E8%AE%B8%E5%BC%8F%E4%BC%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id4">编程语言</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E8%AE%B8%E5%BC%8F%E4%BC%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id9">操作系统</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E8%AE%B8%E5%BC%8F%E4%BC%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id10">外置存储</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E8%AE%B8%E5%BC%8F%E4%BC%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id11">需求分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E8%AE%B8%E5%BC%8F%E4%BC%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id12">详细设计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E8%AE%B8%E5%BC%8F%E4%BC%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id13">导致故障的因素</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E8%AE%B8%E5%BC%8F%E4%BC%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id14">软件架构</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E8%AE%B8%E5%BC%8F%E4%BC%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id15">架构设计文档</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E8%AE%B8%E5%BC%8F%E4%BC%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id20">软件质量管理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E8%AE%B8%E5%BC%8F%E4%BC%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id21">软件工程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E8%AE%B8%E5%BC%8F%E4%BC%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id22">架构设计的优劣</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E8%AE%B8%E5%BC%8F%E4%BC%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id23">参考</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/architectures/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E4%B9%8B%E7%BE%8E.html">软件工程之美</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/md/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E4%B9%8B%E7%BE%8Esummary.html">软件工程之美summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/md/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E4%B9%8B%E7%BE%8E.html">软件工程之美</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E4%B9%8B%E7%BE%8E.html#id3">基础理论 (9 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E4%B9%8B%E7%BE%8E.html#id20">需求分析篇</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E4%B9%8B%E7%BE%8E.html#id26">系统设计篇</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E4%B9%8B%E7%BE%8E.html#id31">开发编码篇 (7 讲)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/architectures/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%BE%8E.html">设计模式之美</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/architectures/DDD%20%E5%AE%9E%E6%88%98%E8%AF%BE.html">DDD 实战课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/DDD%20%E5%AE%9E%E6%88%98%E8%AF%BE.html#id3">开篇词</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/DDD%20%E5%AE%9E%E6%88%98%E8%AF%BE.html#id8">基础篇 (5 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/DDD%20%E5%AE%9E%E6%88%98%E8%AF%BE.html#id30">02进阶篇 (6 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/DDD%20%E5%AE%9E%E6%88%98%E8%AF%BE.html#id61">03实战篇 (10 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/DDD%20%E5%AE%9E%E6%88%98%E8%AF%BE.html#id107">结束语</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/architectures/%E6%9E%B6%E6%9E%84%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E8%A7%A3%E6%9E%90.html">架构实战案例解析</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E6%9E%B6%E6%9E%84%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E8%A7%A3%E6%9E%90.html#id4">01概述篇 (2 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E6%9E%B6%E6%9E%84%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E8%A7%A3%E6%9E%90.html#id12">02业务架构篇 (9 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E6%9E%B6%E6%9E%84%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E8%A7%A3%E6%9E%90.html#id47">03技术架构篇 (9 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E6%9E%B6%E6%9E%84%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E8%A7%A3%E6%9E%90.html#id79">总结篇 (2 讲)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/architectures/%E4%B9%94%E6%96%B0%E4%BA%AE%E7%9A%84%20CTO%20%E6%88%90%E9%95%BF%E5%A4%8D%E7%9B%98.html">乔新亮的 CTO 成长复盘</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E4%B9%94%E6%96%B0%E4%BA%AE%E7%9A%84%20CTO%20%E6%88%90%E9%95%BF%E5%A4%8D%E7%9B%98.html#id3">00开篇词</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E4%B9%94%E6%96%B0%E4%BA%AE%E7%9A%84%20CTO%20%E6%88%90%E9%95%BF%E5%A4%8D%E7%9B%98.html#id4">01对个人认知的复盘 (6 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E4%B9%94%E6%96%B0%E4%BA%AE%E7%9A%84%20CTO%20%E6%88%90%E9%95%BF%E5%A4%8D%E7%9B%98.html#id11">02对管理工作的复盘 (10 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E4%B9%94%E6%96%B0%E4%BA%AE%E7%9A%84%20CTO%20%E6%88%90%E9%95%BF%E5%A4%8D%E7%9B%98.html#id22">03对专业成长的复盘 (10 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E4%B9%94%E6%96%B0%E4%BA%AE%E7%9A%84%20CTO%20%E6%88%90%E9%95%BF%E5%A4%8D%E7%9B%98.html#id34">结束语</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/architectures/%E5%A6%82%E4%BD%95%E8%90%BD%E5%9C%B0%E4%B8%9A%E5%8A%A1%E5%BB%BA%E6%A8%A1.html">如何落地业务建模</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E5%A6%82%E4%BD%95%E8%90%BD%E5%9C%B0%E4%B8%9A%E5%8A%A1%E5%BB%BA%E6%A8%A1.html#id3">开篇词</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E5%A6%82%E4%BD%95%E8%90%BD%E5%9C%B0%E4%B8%9A%E5%8A%A1%E5%BB%BA%E6%A8%A1.html#id4">旧约: “前云时代” 的领域驱动设计 (11 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E5%A6%82%E4%BD%95%E8%90%BD%E5%9C%B0%E4%B8%9A%E5%8A%A1%E5%BB%BA%E6%A8%A1.html#id6">深度答疑专题 (4 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E5%A6%82%E4%BD%95%E8%90%BD%E5%9C%B0%E4%B8%9A%E5%8A%A1%E5%BB%BA%E6%A8%A1.html#id7">新约: 云时代的业务建模 (2 讲)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/architectures/%E9%83%AD%E4%B8%9C%E7%99%BD%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html">郭东白的架构课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E9%83%AD%E4%B8%9C%E7%99%BD%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id3">我的收获</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E9%83%AD%E4%B8%9C%E7%99%BD%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id4">课程设计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E9%83%AD%E4%B8%9C%E7%99%BD%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id5">00开篇词|没有战略意图,就成不了一个顶尖的架构师</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E9%83%AD%E4%B8%9C%E7%99%BD%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id6">01模块一:生存法则 (15 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E9%83%AD%E4%B8%9C%E7%99%BD%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id45">02模块二:创造价值 (21讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E9%83%AD%E4%B8%9C%E7%99%BD%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id98">03模块三:职业成长 (9讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E9%83%AD%E4%B8%9C%E7%99%BD%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id113">04模块四:思考力 (11讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E9%83%AD%E4%B8%9C%E7%99%BD%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id138">05结束语</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/architectures/%E9%83%AD%E4%B8%9C%E7%99%BD%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id139">06加餐</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/architectures/%E6%9D%8E%E6%99%BA%E6%85%A7%20%C2%B7%20%E9%AB%98%E5%B9%B6%E5%8F%91%E6%9E%B6%E6%9E%84%E5%AE%9E%E6%88%98%E8%AF%BE.html">李智慧 · 高并发架构实战课</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../geeks/secure.html">安全</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html">实用密码学</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id4">00开篇词 _ 人人都要会点密码学</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id5">01 | 学习密码学有什么用</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id6">02 | 单向散列函数: 如何保证信息完整性</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id7">03 | 如何设置合适的安全强度</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id11">04 | 选择哈希算法应该考虑哪些因素</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id14">05|如何有效避免长度延展攻击</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id15">06|对称密钥: 如何保护私密数据</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id18">07 | 怎么选择对称密钥算法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#ecb">09 | 为什么ECB模式不安全</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#cbc">10 | 怎么防止数据重放攻击CBC</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id32">11 | 怎么利用解密端攻击</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id39">12 | 怎么利用加密端攻击</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id45">13 | 如何防止数据被调包</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id50">14 | 加密数据能够自我验证吗</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#aead">15 | AEAD 有哪些安全陷阱</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id57">16 | 为什么说随机数都是骗人的</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id65">17 | 加密密钥是怎么来的</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id69">18 | 如何管理对称密钥</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id74">19|量子时代,你准备好了吗</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id78">结束语</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/secures/Web%20%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E5%AE%9E%E6%88%98.html">Web 安全攻防实战</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/secures/Web%20%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E5%AE%9E%E6%88%98.html#id2">1. 前端基础</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/secures/Web%20%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E5%AE%9E%E6%88%98.html#id5">2. Web安全之后端安全</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../geeks/testing.html">测试相关</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/testings/%E6%8E%A5%E5%8F%A3%E6%B5%8B%E8%AF%95%E5%85%A5%E9%97%A8%E8%AF%BE.html">接口测试入门课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/testings/%E6%8E%A5%E5%8F%A3%E6%B5%8B%E8%AF%95%E5%85%A5%E9%97%A8%E8%AF%BE.html#id3">点评</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/testings/%E6%8E%A5%E5%8F%A3%E6%B5%8B%E8%AF%95%E5%85%A5%E9%97%A8%E8%AF%BE.html#id4">开篇词 | 把接口测试这件小事做深/做透</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/testings/%E6%8E%A5%E5%8F%A3%E6%B5%8B%E8%AF%95%E5%85%A5%E9%97%A8%E8%AF%BE.html#id5">01 | 基础: 跳出细节看全局</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/testings/%E6%8E%A5%E5%8F%A3%E6%B5%8B%E8%AF%95%E5%85%A5%E9%97%A8%E8%AF%BE.html#id6">02 | 方法论: 没有任何文档, 怎么才能快速了解接口的信息</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/testings/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%B5%8B%E8%AF%95%E8%AF%BE.html">程序员的测试课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/testings/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%B5%8B%E8%AF%95%E8%AF%BE.html#id3">开篇词</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/testings/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%B5%8B%E8%AF%95%E8%AF%BE.html#id5">基础篇 (11 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/testings/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%B5%8B%E8%AF%95%E8%AF%BE.html#id36">应用篇 (5 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/testings/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%B5%8B%E8%AF%95%E8%AF%BE.html#id40">03扩展篇 (2 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/testings/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%B5%8B%E8%AF%95%E8%AF%BE.html#id41">结束语</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/testings/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%2052%20%E8%AE%B2.html">软件测试 52 讲</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/testings/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%2052%20%E8%AE%B2.html#id3">01测试基础知识篇 (11讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/testings/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%2052%20%E8%AE%B2.html#gui-10">02GUI自动化测试篇 (10讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/testings/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%2052%20%E8%AE%B2.html#api-3">03API自动化测试篇 (3讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/testings/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%2052%20%E8%AE%B2.html#id14">04代码测试篇 (3讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/testings/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%2052%20%E8%AE%B2.html#id16">05性能测试篇 (7讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/testings/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%2052%20%E8%AE%B2.html#id17">06测试数据准备篇 (4讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/testings/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%2052%20%E8%AE%B2.html#id18">07测试基础架构篇 (4讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/testings/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%2052%20%E8%AE%B2.html#id19">08测试新技术篇 (5讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/testings/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%2052%20%E8%AE%B2.html#id24">09测试人员的互联网架构核心知识篇 (5讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/testings/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%2052%20%E8%AE%B2.html#id25">10特别放送篇 (8讲)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../geeks/cloudnative.html">云原生</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/cloudnatives/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE.html">容器实战高手课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/cloudnatives/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE.html#namespace">Namespace</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/cloudnatives/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE.html#cgroups">Cgroups</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/cloudnatives/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE.html#linux-kernel">Linux Kernel</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/cloudnatives/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE.html#load-average">Load Average</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/cloudnatives/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE.html#memory-cgroup">Memory Cgroup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/cloudnatives/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE.html#id4">存储</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/cloudnatives/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE.html#network">Network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/cloudnatives/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE.html#id5">容器安全</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/cloudnatives/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE.html#k8s">k8s</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/cloudnatives/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE.html#id6">思考</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../geeks/manager.html">管理&amp;长成</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/managers/%E8%B7%9F%E7%9D%80%E9%AB%98%E6%89%8B%E5%AD%A6%E5%A4%8D%E7%9B%98.html">跟着高手学复盘</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E8%B7%9F%E7%9D%80%E9%AB%98%E6%89%8B%E5%AD%A6%E5%A4%8D%E7%9B%98.html#id3">01基础概念篇 (3 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E8%B7%9F%E7%9D%80%E9%AB%98%E6%89%8B%E5%AD%A6%E5%A4%8D%E7%9B%98.html#id8">02实操流程篇 (9 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E8%B7%9F%E7%9D%80%E9%AB%98%E6%89%8B%E5%AD%A6%E5%A4%8D%E7%9B%98.html#id64">03实战案例篇 (7 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E8%B7%9F%E7%9D%80%E9%AB%98%E6%89%8B%E5%AD%A6%E5%A4%8D%E7%9B%98.html#id76">结束语</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E8%B7%9F%E7%9D%80%E9%AB%98%E6%89%8B%E5%AD%A6%E5%A4%8D%E7%9B%98.html#id77">春节荐书</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/managers/%E7%A8%8B%E5%BA%8F%E5%91%98%E8%BF%9B%E9%98%B6%E6%94%BB%E7%95%A5.html">程序员进阶攻略</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E7%A8%8B%E5%BA%8F%E5%91%98%E8%BF%9B%E9%98%B6%E6%94%BB%E7%95%A5.html#id4">启程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E7%A8%8B%E5%BA%8F%E5%91%98%E8%BF%9B%E9%98%B6%E6%94%BB%E7%95%A5.html#id7">修炼</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E7%A8%8B%E5%BA%8F%E5%91%98%E8%BF%9B%E9%98%B6%E6%94%BB%E7%95%A5.html#id22">修行</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E7%A8%8B%E5%BA%8F%E5%91%98%E8%BF%9B%E9%98%B6%E6%94%BB%E7%95%A5.html#id92">徘徊</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E7%A8%8B%E5%BA%8F%E5%91%98%E8%BF%9B%E9%98%B6%E6%94%BB%E7%95%A5.html#id124">寻路</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E7%A8%8B%E5%BA%8F%E5%91%98%E8%BF%9B%E9%98%B6%E6%94%BB%E7%95%A5.html#id137">蜕变</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/managers/10x%20%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B7%A5%E4%BD%9C%E6%B3%95.html">10x 程序员工作法</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/10x%20%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B7%A5%E4%BD%9C%E6%B3%95.html#id3">思考框架</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/10x%20%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B7%A5%E4%BD%9C%E6%B3%95.html#id4">四个思考原则</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/10x%20%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B7%A5%E4%BD%9C%E6%B3%95.html#id5">总结</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/10x%20%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B7%A5%E4%BD%9C%E6%B3%95.html#id6">一. 以终为始</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/10x%20%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B7%A5%E4%BD%9C%E6%B3%95.html#id12">二. 任务分解</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/10x%20%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B7%A5%E4%BD%9C%E6%B3%95.html#id17">三. 沟通反馈</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/10x%20%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B7%A5%E4%BD%9C%E6%B3%95.html#id18">四. 自动化</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/10x%20%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B7%A5%E4%BD%9C%E6%B3%95.html#id19">五. 综合运用</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/10x%20%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B7%A5%E4%BD%9C%E6%B3%95.html#id20">好书推荐</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/10x%20%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B7%A5%E4%BD%9C%E6%B3%95.html#id28">提问</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html">大厂晋升指南</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id4">晋升原则</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id5">晋升逻辑</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id6">能力模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id7">职级档次</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#p7">P7</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#p8">P8</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#p9">P9</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#p10-p11">P10/P11</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#ppt">面评技巧-PPT框架</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id18">面评技巧-PPT 讲解</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id19">面评技巧-PPT 答辩</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id20">面评技巧-注意点</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id24">面评技巧-技术大会</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id25">面评技巧-其他</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id26">学习方法-指导原则</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id27">学习方法-找时间：海绵学习法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id28">学习方法-学什么：三段分解法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id29">学习方法-怎么学</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id33">学习方法-保证效果</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id34">做事方法-总</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#kpi-okr">做事方法-KPI&amp;OKR</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#c">做事方法-3C 方案设计法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#pdca">做事方法-PDCA执行法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#w">做事方法-5W根因分析法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#s">做事方法-5S 问题处理法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#d">做事方法-4D 总结法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id35">做事方法-金字塔汇报法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id37">做事方法-四线复盘法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id38">专项提升-业务</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#w1h8c1d">专项提升-业务:5W1H8C1D 分析法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#aarrr">专项提升-业务:AARRR 漏斗模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id39">专项提升-业务:宝洁战略模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id40">专项提升-管理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id41">专项提升-管理:管理四象限</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id42">专项提升-管理:管理五模式</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id43">别人的心得</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id44">其他</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id46">10000小时定律</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id47">领域分层图</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id48">参考</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id53">其他</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../geeks/analysis.html">数据分析</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2.html">数据分析实战 45 讲</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2.html#id4">思维导图</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2.html#id5">开篇词 | 你为什么需要数据分析能力</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2.html#id10">01基础篇 (16 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2.html#id24">02算法篇 (20 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2.html#id37">03实战篇 (7 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2.html#id44">04工作篇 (2 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2.html#id47">结束语</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%80%9D%E7%BB%B4%E8%AF%BE.html">数据分析思维课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%80%9D%E7%BB%B4%E8%AF%BE.html#id4">思维导图</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%80%9D%E7%BB%B4%E8%AF%BE.html#id5">00开篇词 (2 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%80%9D%E7%BB%B4%E8%AF%BE.html#id7">01数据分析基础 (11 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%80%9D%E7%BB%B4%E8%AF%BE.html#id34">02数据算法基础 (9 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%80%9D%E7%BB%B4%E8%AF%BE.html#id50">03如何用数据说话 (6 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%80%9D%E7%BB%B4%E8%AF%BE.html#id68">04分析工具 (5 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%80%9D%E7%BB%B4%E8%AF%BE.html#id74">05特别放送 (6 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%80%9D%E7%BB%B4%E8%AF%BE.html#id75">其他</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../geeks/ai.html">AI 相关</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/ais/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80%E8%AF%BE.html">人工智能基础课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80%E8%AF%BE.html#id4">数学基础</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80%E8%AF%BE.html#id12">机器学习</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/ais/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F.html">推荐系统三十六式</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F.html#id4">内容推荐</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F.html#id9">近邻推荐</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F.html#id18">矩阵分解</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F.html#id19">个人成长</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/ais/AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E7%BE%8E.html">AI 大模型之美</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E7%BE%8E.html#id2">课前必读 (2 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E7%BE%8E.html#id5">基础知识篇: 探索大型语言模型的能力 (8 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E7%BE%8E.html#nlp-10">实战提高篇一: 利用NLP技术完成高级任务 (10讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E7%BE%8E.html#id42">实战提高篇(二) 大型语音与图像模型的应用 (9讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E7%BE%8E.html#id55">扩展</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/ais/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2040%20%E8%AE%B2.html">机器学习 40 讲</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2040%20%E8%AE%B2.html#id3">01机器学习概观 (10 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2040%20%E8%AE%B2.html#id5">02统计机器学习模型 (18 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2040%20%E8%AE%B2.html#id6">03概率图模型 (14 讲)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/ais/PyTorch%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98.html">PyTorch 深度学习实战</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/PyTorch%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98.html#id2">开篇词 | 如何高效入门 PyTorch</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/PyTorch%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98.html#id3">01基础篇 (5 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/PyTorch%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98.html#id5">02模型训练篇 (12 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/PyTorch%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98.html#id26">03实战篇 (9 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/PyTorch%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98.html#id56">加餐| 基础模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/PyTorch%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98.html#id60">结束语| 人生充满选择, 选择与努力同样重要</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/ais/%E9%9B%B6%E5%9F%BA%E7%A1%80%20GPT%20%E5%BA%94%E7%94%A8%E5%85%A5%E9%97%A8%E8%AF%BE.html">零基础 GPT 应用入门课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/%E9%9B%B6%E5%9F%BA%E7%A1%80%20GPT%20%E5%BA%94%E7%94%A8%E5%85%A5%E9%97%A8%E8%AF%BE.html#id2">开篇词</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/%E9%9B%B6%E5%9F%BA%E7%A1%80%20GPT%20%E5%BA%94%E7%94%A8%E5%85%A5%E9%97%A8%E8%AF%BE.html#id7">基础速通 (3讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/%E9%9B%B6%E5%9F%BA%E7%A1%80%20GPT%20%E5%BA%94%E7%94%A8%E5%85%A5%E9%97%A8%E8%AF%BE.html#id10">黄金密钥 (7讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/%E9%9B%B6%E5%9F%BA%E7%A1%80%20GPT%20%E5%BA%94%E7%94%A8%E5%85%A5%E9%97%A8%E8%AF%BE.html#id18">综合实战 (6讲)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/ais/AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98.html">AI 大模型系统实战</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98.html#id2">热身篇 (4讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98.html#id6">架构基础篇 (6讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98.html#id33">技术原理篇 (5讲)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/ais/AI%20%E7%BB%98%E7%94%BB%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98.html">AI 绘画核心技术与实战</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/AI%20%E7%BB%98%E7%94%BB%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98.html#id2">开篇词 (2讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/AI%20%E7%BB%98%E7%94%BB%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98.html#ai-4">热身篇:AI 绘画初体验 (4讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/AI%20%E7%BB%98%E7%94%BB%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98.html#ai-9">基础篇:AI 绘画原理揭秘 (9讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/AI%20%E7%BB%98%E7%94%BB%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98.html#dall-e-2-stable-diffusion-5">进阶篇:从 DALL-E 2 到 Stable Diffusion (5讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/AI%20%E7%BB%98%E7%94%BB%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98.html#ai-8">综合演练篇:AI 绘画高手养成计划 (8讲)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/ais/%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html">零基础实战机器学习</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/ais/%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html#id3">08 | 模型优化1: 怎么用特征工程提高模型效率</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../geeks/blockchain.html">区块链</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/blockchains/%E8%AF%B4%E9%80%8F%E5%8C%BA%E5%9D%97%E9%93%BE.html">说透区块链</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/blockchains/%E8%AF%B4%E9%80%8F%E5%8C%BA%E5%9D%97%E9%93%BE.html#id3">数字人民币</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/blockchains/%E8%AF%B4%E9%80%8F%E5%8C%BA%E5%9D%97%E9%93%BE.html#id4">书籍</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../geeks/coding.html">代码精进</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/codings/%E4%BB%A3%E7%A0%81%E4%B9%8B%E4%B8%91.html">代码之丑</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/codings/%E4%BB%A3%E7%A0%81%E4%B9%8B%E4%B8%91.html#id3">开篇词</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/codings/%E4%BB%A3%E7%A0%81%E4%B9%8B%E4%B8%91.html#id4">13 类典型坏味道 (13 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/codings/%E4%BB%A3%E7%A0%81%E4%B9%8B%E4%B8%91.html#id5">延伸阅读 (4 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/codings/%E4%BB%A3%E7%A0%81%E4%B9%8B%E4%B8%91.html#id10">参考</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/codings/%E8%BD%AF%E4%BB%B6%E8%AE%BE%E8%AE%A1%E4%B9%8B%E7%BE%8E.html">软件设计之美</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/codings/md/%E8%BD%AF%E4%BB%B6%E8%AE%BE%E8%AE%A1%E4%B9%8B%E7%BE%8E.html">软件设计之美</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/codings/%E4%BB%A3%E7%A0%81%E7%B2%BE%E8%BF%9B%E4%B9%8B%E8%B7%AF.html">代码精进之路</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/codings/%E4%BB%A3%E7%A0%81%E7%B2%BE%E8%BF%9B%E4%B9%8B%E8%B7%AF.html#id3">01第一模块: 代码 “规范” 篇 (16 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/codings/%E4%BB%A3%E7%A0%81%E7%B2%BE%E8%BF%9B%E4%B9%8B%E8%B7%AF.html#id19">02第二模块: 代码 “经济” 篇 (14 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/codings/%E4%BB%A3%E7%A0%81%E7%B2%BE%E8%BF%9B%E4%B9%8B%E8%B7%AF.html#id48">03第三模块: 代码 “安全” 篇 (14 讲)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../geeks/lang.html">编程语言</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/langs/Go%E8%AF%AD%E8%A8%80%E6%A0%B8%E5%BF%8336%E8%AE%B2.html">Go 语言核心 36 讲</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/langs/Tony-Bai-Go-%E8%AF%AD%E8%A8%80%E7%AC%AC%E4%B8%80%E8%AF%BE.html">TonyBai Go语言第一课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/langs/Tony-Bai-Go-%E8%AF%AD%E8%A8%80%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id2">课程设计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/langs/Tony-Bai-Go-%E8%AF%AD%E8%A8%80%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id3">00开篇</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/langs/Tony-Bai-Go-%E8%AF%AD%E8%A8%80%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id5">01入门篇: 勤加练手 (7 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/langs/Tony-Bai-Go-%E8%AF%AD%E8%A8%80%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id6">02基础篇: “脑勤” 多理解 (20 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/langs/Tony-Bai-Go-%E8%AF%AD%E8%A8%80%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id8">03核心篇: “脑勤 +” 洞彻核心 (5 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/langs/Tony-Bai-Go-%E8%AF%AD%E8%A8%80%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id16">04实战篇: 打通“最后一公里” (4讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/langs/Tony-Bai-Go-%E8%AF%AD%E8%A8%80%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id17">大咖助阵</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/langs/Tony-Bai-Go-%E8%AF%AD%E8%A8%80%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id18">加餐</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/langs/Tony-Bai-Go-%E8%AF%AD%E8%A8%80%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id26">泛型</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/langs/Python%20%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98.html">Python 核心技术与实战</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../geeks/product.html">产品&amp;运营</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/products/%E6%A2%81%E5%AE%81%E3%83%BB%E4%BA%A7%E5%93%81%E6%80%9D%E7%BB%B4%2030%20%E8%AE%B2.html">梁宁-产品思维 30 讲</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/products/%E6%A2%81%E5%AE%81%E3%83%BB%E4%BA%A7%E5%93%81%E6%80%9D%E7%BB%B4%2030%20%E8%AE%B2.html#id4">发刊词</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/products/%E6%A2%81%E5%AE%81%E3%83%BB%E4%BA%A7%E5%93%81%E6%80%9D%E7%BB%B4%2030%20%E8%AE%B2.html#id7">模块一: 同理心</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/products/%E6%A2%81%E5%AE%81%E3%83%BB%E4%BA%A7%E5%93%81%E6%80%9D%E7%BB%B4%2030%20%E8%AE%B2.html#id23">模块二: 机会判断</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/products/%E6%A2%81%E5%AE%81%E3%83%BB%E4%BA%A7%E5%93%81%E6%80%9D%E7%BB%B4%2030%20%E8%AE%B2.html#id31">模块三: 系统能力</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/products/%E6%A2%81%E5%AE%81%E3%83%BB%E4%BA%A7%E5%93%81%E6%80%9D%E7%BB%B4%2030%20%E8%AE%B2.html#id45">模块四: 用户体验</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/products/%E6%A2%81%E5%AE%81%E3%83%BB%E4%BA%A7%E5%93%81%E6%80%9D%E7%BB%B4%2030%20%E8%AE%B2.html#id66">模块五: 创新模式</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/products/%E6%A2%81%E5%AE%81%E3%83%BB%E4%BA%A7%E5%93%81%E6%80%9D%E7%BB%B4%2030%20%E8%AE%B2.html#id73">产品世界观</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/products/%E6%A2%81%E5%AE%81%E3%83%BB%E4%BA%A7%E5%93%81%E6%80%9D%E7%BB%B4%2030%20%E8%AE%B2.html#id80">彩蛋</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/products/%E6%A2%81%E5%AE%81%E3%83%BB%E4%BA%A7%E5%93%81%E6%80%9D%E7%BB%B4%2030%20%E8%AE%B2.html#id90">参考</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../geeks/interview.html">面试</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/interviews/%E5%90%8E%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E9%AB%98%E9%98%B6%E9%9D%A2%E7%BB%8F.html">后端工程师的高阶面经</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/interviews/%E5%90%8E%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E9%AB%98%E9%98%B6%E9%9D%A2%E7%BB%8F.html#id3">开篇词</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/interviews/%E5%90%8E%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E9%AB%98%E9%98%B6%E9%9D%A2%E7%BB%8F.html#id5">01微服务架构 (10讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/interviews/%E5%90%8E%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E9%AB%98%E9%98%B6%E9%9D%A2%E7%BB%8F.html#mysql-13">数据库与MySQL (13讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/interviews/%E5%90%8E%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E9%AB%98%E9%98%B6%E9%9D%A2%E7%BB%8F.html#id269">消息队列 (10讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/interviews/%E5%90%8E%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E9%AB%98%E9%98%B6%E9%9D%A2%E7%BB%8F.html#id321">缓存 (9讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/interviews/%E5%90%8E%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E9%AB%98%E9%98%B6%E9%9D%A2%E7%BB%8F.html#nosql-5">NoSQL (5讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/interviews/%E5%90%8E%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E9%AB%98%E9%98%B6%E9%9D%A2%E7%BB%8F.html#id394">结束语</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../geeks/softengineering.html">软件工程</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/softengineers/%E8%AF%B4%E9%80%8F%E6%95%8F%E6%8D%B7.html">说透敏捷</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/softengineers/%E8%AF%B4%E9%80%8F%E6%95%8F%E6%8D%B7.html#id3">开篇词</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/softengineers/%E8%AF%B4%E9%80%8F%E6%95%8F%E6%8D%B7.html#id4">原理篇 (2 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/softengineers/%E8%AF%B4%E9%80%8F%E6%95%8F%E6%8D%B7.html#id14">实战篇 (4 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/softengineers/%E8%AF%B4%E9%80%8F%E6%95%8F%E6%8D%B7.html#id26">策略篇 (2 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/softengineers/%E8%AF%B4%E9%80%8F%E6%95%8F%E6%8D%B7.html#id29">管理篇 (2 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/softengineers/%E8%AF%B4%E9%80%8F%E6%95%8F%E6%8D%B7.html#id32">结束语</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../geeks/other.html">其它</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html">互联网人的英语私教课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#ksa">KSA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id4">独立主格结构</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id5">介词</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id6">收集</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id8">关键英语</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#vs">并列句 VS 复杂句</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id9">单词</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id10">英语谚语</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id11">常用短语</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id12">口语专用词汇</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id13">好的英文网站</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id15">其他</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id16">会不会阅读</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id17">词汇学习</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#paraphrase">paraphrase</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id18">动词</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id19">其他</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id20">参考</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/others/%E4%BB%8E%200%20%E6%89%93%E9%80%A0%E9%9F%B3%E8%A7%86%E9%A2%91%E7%9B%B4%E6%92%AD%E7%B3%BB%E7%BB%9F.html">从 0 打造音视频直播系统</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%BB%8E%200%20%E6%89%93%E9%80%A0%E9%9F%B3%E8%A7%86%E9%A2%91%E7%9B%B4%E6%92%AD%E7%B3%BB%E7%BB%9F.html#webrtc-1-1-23">WebRTC 1 对 1 通话 (23 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%BB%8E%200%20%E6%89%93%E9%80%A0%E9%9F%B3%E8%A7%86%E9%A2%91%E7%9B%B4%E6%92%AD%E7%B3%BB%E7%BB%9F.html#webrtc-7">WebRTC 多人音视频实时通话 (7 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%BB%8E%200%20%E6%89%93%E9%80%A0%E9%9F%B3%E8%A7%86%E9%A2%91%E7%9B%B4%E6%92%AD%E7%B3%BB%E7%BB%9F.html#id22">支持上万人同时在线的直播系统 (8 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%BB%8E%200%20%E6%89%93%E9%80%A0%E9%9F%B3%E8%A7%86%E9%A2%91%E7%9B%B4%E6%92%AD%E7%B3%BB%E7%BB%9F.html#id27">其他</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/others/%E5%BF%AB%E6%89%8B%C2%B7%E9%9F%B3%E8%A7%86%E9%A2%91%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8%E8%AF%BE.html">快手·音视频技术入门课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E5%BF%AB%E6%89%8B%C2%B7%E9%9F%B3%E8%A7%86%E9%A2%91%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8%E8%AF%BE.html#id3">开篇基础 (4讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E5%BF%AB%E6%89%8B%C2%B7%E9%9F%B3%E8%A7%86%E9%A2%91%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8%E8%AF%BE.html#id29">流媒体技术速成 (5讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E5%BF%AB%E6%89%8B%C2%B7%E9%9F%B3%E8%A7%86%E9%A2%91%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8%E8%AF%BE.html#ffmpeg-api-4">FFmpeg API 应用 (4讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E5%BF%AB%E6%89%8B%C2%B7%E9%9F%B3%E8%A7%86%E9%A2%91%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8%E8%AF%BE.html#ffmpeg-2">FFmpeg 社区“玩法” (2讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E5%BF%AB%E6%89%8B%C2%B7%E9%9F%B3%E8%A7%86%E9%A2%91%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8%E8%AF%BE.html#id55">结束语 | 音视频技术更宠爱脚踏实地的人</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/others/%E6%94%BB%E5%85%8B%E8%A7%86%E9%A2%91%E6%8A%80%E6%9C%AF.html">攻克视频技术</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E6%94%BB%E5%85%8B%E8%A7%86%E9%A2%91%E6%8A%80%E6%9C%AF.html#id3">图像基础和前处理 (3 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E6%94%BB%E5%85%8B%E8%A7%86%E9%A2%91%E6%8A%80%E6%9C%AF.html#id12">视频编码 (5讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E6%94%BB%E5%85%8B%E8%A7%86%E9%A2%91%E6%8A%80%E6%9C%AF.html#id22">参考</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E6%94%BB%E5%85%8B%E8%A7%86%E9%A2%91%E6%8A%80%E6%9C%AF.html#id23">评论</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/others/%E6%90%9E%E5%AE%9A%E9%9F%B3%E9%A2%91%E6%8A%80%E6%9C%AF.html">搞定音频技术</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E6%90%9E%E5%AE%9A%E9%9F%B3%E9%A2%91%E6%8A%80%E6%9C%AF.html#id3">音频基础 (4 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E6%90%9E%E5%AE%9A%E9%9F%B3%E9%A2%91%E6%8A%80%E6%9C%AF.html#id13">02音频降噪 (2 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E6%90%9E%E5%AE%9A%E9%9F%B3%E9%A2%91%E6%8A%80%E6%9C%AF.html#id15">03回声消除 (2 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E6%90%9E%E5%AE%9A%E9%9F%B3%E9%A2%91%E6%8A%80%E6%9C%AF.html#id18">04音频网络传输 (3 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E6%90%9E%E5%AE%9A%E9%9F%B3%E9%A2%91%E6%8A%80%E6%9C%AF.html#id22">05空间音频 (2 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E6%90%9E%E5%AE%9A%E9%9F%B3%E9%A2%91%E6%8A%80%E6%9C%AF.html#id24">06音频特效生成与算法 (3 讲)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/others/%E4%B8%93%E5%88%A9%E5%86%99%E4%BD%9C%E7%AC%AC%E4%B8%80%E8%AF%BE.html">专利写作第一课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%B8%93%E5%88%A9%E5%86%99%E4%BD%9C%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id3">开篇词 | 写专利, 将是知识工作者的核心产出</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%B8%93%E5%88%A9%E5%86%99%E4%BD%9C%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id4">01 _ 为什么我推荐互联网人要积极写专利</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%B8%93%E5%88%A9%E5%86%99%E4%BD%9C%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id5">02 _ 奖金是专利写作中最不值得一提的事儿</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%B8%93%E5%88%A9%E5%86%99%E4%BD%9C%E7%AC%AC%E4%B8%80%E8%AF%BE.html#keyperson">03 _ 找到KeyPerson利益点, 提升专利通过率</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%B8%93%E5%88%A9%E5%86%99%E4%BD%9C%E7%AC%AC%E4%B8%80%E8%AF%BE.html#prd-1">04 _ 像写PRD一样, 撰写专利交底书1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%B8%93%E5%88%A9%E5%86%99%E4%BD%9C%E7%AC%AC%E4%B8%80%E8%AF%BE.html#prd-2">05 _ 像写PRD一样, 撰写专利交底书2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%B8%93%E5%88%A9%E5%86%99%E4%BD%9C%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id14">06 _ 如何把常见的生活问题变成专利(案例-节假日不响起闹钟)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%B8%93%E5%88%A9%E5%86%99%E4%BD%9C%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id23">07 _ 专利创新的步伐不必迈得特别大</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%B8%93%E5%88%A9%E5%86%99%E4%BD%9C%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id28">08 _ 那些异想天开的专利是怎么诞生的</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/%E4%B8%93%E5%88%A9%E5%86%99%E4%BD%9C%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id32">答疑 _ 专利申请十大常见问题</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/others/WebAssembly%20%E5%85%A5%E9%97%A8%E8%AF%BE.html">WebAssembly 入门课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/WebAssembly%20%E5%85%A5%E9%97%A8%E8%AF%BE.html#id2">课前必读</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/WebAssembly%20%E5%85%A5%E9%97%A8%E8%AF%BE.html#id9">01核心原理篇 (6 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/WebAssembly%20%E5%85%A5%E9%97%A8%E8%AF%BE.html#id21">02应用篇 (6 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../geeks/others/WebAssembly%20%E5%85%A5%E9%97%A8%E8%AF%BE.html#id22">03实战篇 (6 讲)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../geeks/others/other.html">其他</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../matter.html">Matter 协议</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../matters/matter.html">Matter Core</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/matter.html#chapter-1-introduction">Chapter 1. Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/matter.html#chapter-2-architecture">Chapter 2. Architecture</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#overview">2.1. Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#layered-architecture">2.2. Layered Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#network-topology">2.3. Network Topology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#scoped-names">2.4. Scoped names</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#identifiers">2.5. Identifiers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#device-identity">2.6. Device identity</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#security">2.7. Security</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#device-commissioning">2.8. Device Commissioning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#sleepy-end-device-sed">2.9. Sleepy End Device (SED)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#data-model-root">2.10. Data Model Root</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#stack-limits">2.11. Stack Limits</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#list-of-provisional-items">2.12. List of Provisional Items</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/matter.html#chapter-3-cryptographic-primitives">Chapter 3. Cryptographic Primitives</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/matter.html#chapter-4-secure-channel">Chapter 4. Secure Channel</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#general-description">4.1. General Description</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#ipv6-reachability">4.2. IPv6 Reachability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#discovery">4.3. Discovery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#message-frame-format">4.4. Message Frame Format</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#message-counters">4.5. Message Counters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#message-processing">4.6. Message Processing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#message-security">4.7. Message Security</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#message-privacy">4.8. Message Privacy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#message-exchanges">4.9. Message Exchanges</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#secure-channel-protocol">4.10. Secure Channel Protocol</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#message-reliability-protocol-mrp">4.11. Message Reliability Protocol (MRP)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#unicast-communication">4.12. Unicast Communication</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#session-establishment">4.13. Session Establishment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#group-communication">4.14. Group Communication</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#group-key-management">4.15. Group Key Management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#message-counter-synchronization-protocol-mcsp">4.16. Message Counter Synchronization Protocol(MCSP)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#bluetooth-transport-protocol-btp">4.17. Bluetooth Transport Protocol (BTP)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/matter.html#chapter-5-commissioning">Chapter 5. Commissioning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#onboarding-payload">5.1. Onboarding Payload</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#initiating-commissioning">5.2. Initiating Commissioning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#user-directed-commissioning">5.3. User Directed Commissioning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#device-discovery">5.4. Device Discovery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#commissioning-flows">5.5. Commissioning Flows</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#administrator-assisted-commissioning-flows">5.6. Administrator Assisted Commissioning Flows</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#device-commissioning-flows">5.7. Device Commissioning Flows</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#in-field-upgrade-to-matter">5.8. In-field Upgrade to Matter</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/matter.html#chapter-6-device-attestation-and-operational-credentials">Chapter 6. Device Attestation and Operational Credentials</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#common-conventions">6.1. Common Conventions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#device-attestation">6.2. Device Attestation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#certification-declaration">6.3. Certification Declaration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#node-operational-credentials-specification">6.4. Node Operational Credentials Specification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#operational-certificate-encoding">6.5. Operational Certificate Encoding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#access-control">6.6. Access Control</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/matter.html#chapter-7-data-model-specification">Chapter 7. Data Model Specification</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#practical-information">7.1. Practical Information</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#data-qualities">7.2. Data Qualities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#conformance">7.3. Conformance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#element">7.4. Element</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#fabric">7.5. Fabric</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#access">7.6. Access</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#other-qualities">7.7. Other Qualities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#node">7.8. Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#endpoint">7.9. Endpoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#cluster">7.10. Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#command">7.11. Command</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#attribute">7.12. Attribute</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#global-elements">7.13. Global Elements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#event">7.14. Event</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#device-type">7.15. Device Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#non-standard">7.16. Non-Standard</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#data-field">7.17. Data Field</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#data-types">7.18. Data Types</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#manufacturer-specific-extensions">7.19. Manufacturer Specific Extensions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/matter.html#chapter-8-interaction-model-specification">Chapter 8. Interaction Model Specification</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#id17">8.1. Practical Information</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#concepts">8.2. Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#status-and-interaction">8.3. Status and Interaction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#read-interaction">8.4. Read Interaction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#subscribe-interaction">8.5. Subscribe Interaction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#report-transaction">8.6. Report Transaction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#write-interaction">8.7. Write Interaction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#invoke-interaction">8.8. Invoke Interaction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#common-action-information-blocks-and-paths">8.9. Common Action Information Blocks and Paths</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#status-codes">8.10. Status Codes</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/matter.html#chapter-9-system-model-specification">Chapter 9. System Model Specification</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#id18">9.1. Practical Information</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#endpoint-composition">9.2. Endpoint Composition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#interaction-model-relationships">9.3. Interaction Model Relationships</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#binding-relationship">9.4. Binding Relationship</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#descriptor-cluster">9.5. Descriptor Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#binding-cluster">9.6. Binding Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#label-cluster">9.7. Label Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#fixed-label-cluster">9.8. Fixed Label Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#user-label-cluster">9.9. User Label Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#access-control-cluster">9.10. Access Control Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#group-relationship">9.11. Group Relationship</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#bridge-for-non-matter-devices">9.12. Bridge for non-Matter devices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#bridged-device-basic-information-cluster">9.13. Bridged Device Basic Information Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#actions-cluster">9.14. Actions Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#proxy-architecture">9.15. Proxy Architecture</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/matter.html#chapter-10-interaction-model-encoding-specification">Chapter 10. Interaction Model Encoding Specification</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#id23">10.1. Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#messages">10.2. Messages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#id24">10.3. Data Types</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#sample-cluster">10.4. Sample Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#information-blocks">10.5. Information Blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#message-definitions">10.6. Message Definitions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/matter.html#chapter-11-service-and-device-management">Chapter 11. Service and Device Management</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#basic-information-cluster">11.1. Basic Information Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#group-key-management-cluster">11.2. Group Key Management Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#localization-configuration-cluster">11.3. Localization Configuration Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#time-format-localization-cluster">11.4. Time Format Localization Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#unit-localization-cluster">11.5. Unit Localization Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#power-source-configuration-cluster">11.6. Power Source Configuration Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#power-source-cluster">11.7. Power Source Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#network-commissioning-cluster">11.8. Network Commissioning Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#general-commissioning-cluster">11.9. General Commissioning Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#diagnostic-logs-cluster">11.10. Diagnostic Logs Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#general-diagnostics-cluster">11.11. General Diagnostics Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#software-diagnostics-cluster">11.12. Software Diagnostics Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#thread-network-diagnostics-cluster">11.13. Thread Network Diagnostics Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#wi-fi-network-diagnostics-cluster">11.14. Wi-Fi Network Diagnostics Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#ethernet-network-diagnostics-cluster">11.15. Ethernet Network Diagnostics Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#time-synchronization">11.16. Time Synchronization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#node-operational-credentials-cluster">11.17. Node Operational Credentials Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#administrator-commissioning-cluster">11.18. Administrator Commissioning Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#over-the-air-ota-software-update">11.19. Over-the-Air (OTA) Software Update</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#over-the-air-ota-software-update-file-format">11.20. Over-the-Air (OTA) Software Update File Format</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#bulk-data-exchange-protocol-bdx">11.21. Bulk Data Exchange Protocol (BDX)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#distributed-compliance-ledger">11.22. Distributed Compliance Ledger</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/matter.html#chapter-12-multiple-fabrics">Chapter 12. Multiple Fabrics</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#multiple-fabrics">12.1. Multiple Fabrics</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/matter.html#chapter-13-security-requirements">Chapter 13. Security Requirements</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#device-vs-node">13.2. Device vs. Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#factory-reset">13.4. Factory Reset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#threats-and-countermeasures">13.7. Threats and Countermeasures</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/matter.html#appendix-a-tag-length-value-tlv-encoding-format">Appendix A: Tag-length-value (TLV) Encoding Format</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#a-1-scope-purpose">A.1. Scope &amp; Purpose</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#a-2-tags">A.2. Tags</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#a-9-length-encoding">A.9. Length Encoding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#a-10-end-of-container-encoding">A.10. End of Container Encoding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#a-11-value-encodings">A.11. Value Encodings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#a-12-tlv-encoding-examples">A.12. TLV Encoding Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/matter.html#appendix-b-tag-length-value-tlv-schema-definitions">Appendix B: Tag-length-value (TLV) Schema Definitions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#b-1-introduction">B.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#b-2-definitions">B.2. Definitions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#b-3-types">B.3. Types</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#b-4-pseudo-types">B.4. Pseudo-Types</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#b-5-qualifiers">B.5. Qualifiers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/matter.html#appendix-c-tag-length-value-tlv-payload-text-representation-format">Appendix C: Tag-length-value (TLV) Payload Text Representation Format</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#c-1-introduction">C.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#c-3-examples">C.3. Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/matter.html#appendix-d-status-report-messages">Appendix D: Status Report Messages</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/matter.html#d-3-message-format">D.3. Message Format</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/matter.html#appendix-e-matter-specific-asn-1-object-identifiers-oids">Appendix E: Matter-Specific ASN.1 Object Identifiers (OIDs)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/matter.html#appendix-f-cryptographic-test-vectors-for-some-procedures">Appendix F: Cryptographic test vectors for some procedures</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/matter.html#appendix-g-minimal-resource-requirements">Appendix G: Minimal Resource Requirements</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../matters/Matter%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90.html">Matter协议分析</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/Matter%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90.html#id2">简介</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/Matter%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90.html#id3">算法</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/Matter%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90.html#ecc">椭圆曲线密码学 (ECC) 原理</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/Matter%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90.html#bridge">Bridge</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/Matter%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90.html#factory-data">Factory Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/Matter%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90.html#id4">安全</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/Matter%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90.html#pase">PASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/Matter%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90.html#id5">配网过程</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/Matter%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90.html#case">CASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/Matter%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90.html#group">Group</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/Matter%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90.html#cluster">cluster</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/Matter%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90.html#ota">OTA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/Matter%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90.html#id6">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../matters/chatgpt.html">chatGPT学习</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/chatgpt.html#chapter-01-introduction-document">Chapter 01 — Introduction Document</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/chatgpt.html#chapter-02-architecture-document">Chapter 02 — Architecture Document</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/chatgpt.html#chapter-03-cryptographic-primitives-document">Chapter 03 — Cryptographic Primitives Document</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/chatgpt.html#chapter-04-secure-channel-document">Chapter 04 — Secure Channel Document</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/chatgpt.html#chapter-05-commissioning-document">Chapter 05 — Commissioning Document</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/chatgpt.html#chapter-06-device-attestation-document">Chapter 06 — Device Attestation Document</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/chatgpt.html#chapter-07-data-model-document">Chapter 07 — Data Model Document</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/chatgpt.html#chapter-08-interaction-model-document">Chapter 08 — Interaction Model Document</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/chatgpt.html#chapter-09-system-model-document">Chapter 09 — System Model Document</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/chatgpt.html#id2">概述和定义</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/chatgpt.html#id3">设备类型和服务类型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/chatgpt.html#id4">特征</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/chatgpt.html#id5">系统模型实例</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/chatgpt.html#chapter-10-interaction-encoding-document">Chapter 10 — Interaction Encoding Document</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/chatgpt.html#id6">概述和定义</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/chatgpt.html#id7">数据类型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/chatgpt.html#id8">交互编码格式</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/chatgpt.html#chapter-11-device-management-document">Chapter 11 — Device Management Document</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/chatgpt.html#id9">概述和定义</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/chatgpt.html#id10">设备组成</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/chatgpt.html#id11">设备状态</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../matters/chatgpt.html#id12">设备操作</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/chatgpt.html#chapter-12-multiple-fabrics-document">Chapter 12 — Multiple Fabrics Document</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/chatgpt.html#chapter-13-security-requirements-document">Chapter 13 — Security Requirements Document</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/chatgpt.html#appendix-a-tag-length-value-tlv-encoding-format">Appendix A: Tag-length-value (TLV) Encoding Format</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/chatgpt.html#appendix-b-tag-length-value-tlv-schema-definitions">Appendix B: Tag-length-value (TLV) Schema Definitions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/chatgpt.html#appendix-c-tag-length-value-tlv-payload-text-representation-format">Appendix C: Tag-length-value (TLV) Payload Text Representation Format</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../matters/chatgpt.html#appendix-d-status-report-messages">Appendix D: Status Report Messages</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../rfc.html">rfc</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/ips/rfc0791-IP%20Spec.html">RFC791: IP: INTERNET PROTOCOL</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ips/rfc0791-IP%20Spec.html#preface">PREFACE</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ips/rfc0791-IP%20Spec.html#introduction">1.  INTRODUCTION</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ips/rfc0791-IP%20Spec.html#overview">2.  OVERVIEW</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ips/rfc0791-IP%20Spec.html#relation-to-other-protocols">2.1.  Relation to Other Protocols</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ips/rfc0791-IP%20Spec.html#model-of-operation">2.2.  Model of Operation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ips/rfc0791-IP%20Spec.html#function-description">2.3.  Function Description</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ips/rfc0791-IP%20Spec.html#gateways">2.4.  Gateways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ips/rfc0791-IP%20Spec.html#specification">3.  SPECIFICATION</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ips/rfc0791-IP%20Spec.html#internet-header-format">3.1.  Internet Header Format</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ips/rfc0791-IP%20Spec.html#discussion">3.2  Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ips/rfc0791-IP%20Spec.html#interfaces">3.3  Interfaces</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ips/rfc0791-IP%20Spec.html#appendix-a-examples-scenarios">APPENDIX A:  Examples &amp; Scenarios</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ips/rfc0791-IP%20Spec.html#minimal-data-carrying-internet-datagram">minimal data carrying internet datagram</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ips/rfc0791-IP%20Spec.html#moderate-size-internet-datagram-452-data-octets">moderate size internet datagram (452 data octets)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ips/rfc0791-IP%20Spec.html#datagram-containing-options">datagram containing options</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ips/rfc0791-IP%20Spec.html#appendix-b-data-transmission-order">APPENDIX B:  Data Transmission Order</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ips/rfc0791-IP%20Spec.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/ips/rfc0792-ICMP.html">RFC792: ICMP</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ips/rfc0792-ICMP.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/ips/rfc3569-SSM.html">RFC3569: An Overview of Source-Specific Multicast (SSM)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ips/rfc3569-SSM.html#introduction">1.  Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ips/rfc3569-SSM.html#terminology">2.  Terminology</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ips/rfc3569-SSM.html#any-source-multicast-asm">Any-Source Multicast (ASM)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ips/rfc3569-SSM.html#source-specific-multicast-ssm">Source-Specific Multicast (SSM)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ips/rfc3569-SSM.html#source-filtered-multicast-sfm">Source-Filtered Multicast (SFM)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ips/rfc3569-SSM.html#the-igmp-pim-sm-msdp-mbgp-protocol-suite-for-asm">3.  The IGMP/PIM-SM/MSDP/MBGP Protocol Suite for ASM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ips/rfc3569-SSM.html#problems-with-current-architecture">4.  Problems with Current Architecture</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ips/rfc3569-SSM.html#source-specific-multicast-ssm-benefits-and-requirements">5.  Source Specific Multicast (SSM): Benefits and Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ips/rfc3569-SSM.html#ssm-framework">6.  SSM Framework</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ips/rfc3569-SSM.html#address-allocation">6.1.  Address Allocation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ips/rfc3569-SSM.html#session-description-and-channel-discovery">6.2.  Session Description and Channel Discovery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ips/rfc3569-SSM.html#ssm-aware-applications">6.3.  SSM-Aware Applications</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ips/rfc3569-SSM.html#igmpv3-mldv2-host-reporting-and-querier">6.4.  IGMPv3/MLDv2 Host Reporting and Querier</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ips/rfc3569-SSM.html#pim-ssm-routing">6.5.  PIM-SSM Routing</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ips/rfc3569-SSM.html#interoperability-with-existing-multicast-service-models">7.  Interoperability with Existing Multicast Service Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ips/rfc3569-SSM.html#id2">应用</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ips/rfc3569-SSM.html#ssm">SSM示例</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ips/rfc3569-SSM.html#id3">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/ips/rfc4301.html">RFC4301: Security Architecture for the IP</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ips/rfc4301.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/ips/rfc4302-IP%20Authentication%20Header.html">RFC4302: IP Authentication Header</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ips/rfc4302-IP%20Authentication%20Header.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/ips/rfc4303.html">RFC4303: IP Encapsulating Security Payload (ESP)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ips/rfc4303.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/ips/rfc4693-CIDR.html">RFC4693: Classless Inter-domain Routing (CIDR)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/ipv6/rfc3306-Unicast-Prefix-based%20IPv6%20Multicast%20Addresses.html">RFC3306: Unicast-Prefix-based IPv6 Multicast Addresses</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc3306-Unicast-Prefix-based%20IPv6%20Multicast%20Addresses.html#ipv6">IPv6 多播地址中前缀长度的取值范围</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc3306-Unicast-Prefix-based%20IPv6%20Multicast%20Addresses.html#id2">多播地址的分配规则</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc3306-Unicast-Prefix-based%20IPv6%20Multicast%20Addresses.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc3306-Unicast-Prefix-based%20IPv6%20Multicast%20Addresses.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc3306-Unicast-Prefix-based%20IPv6%20Multicast%20Addresses.html#motivation">2. Motivation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc3306-Unicast-Prefix-based%20IPv6%20Multicast%20Addresses.html#multicast-address-format">4. Multicast Address Format</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc3306-Unicast-Prefix-based%20IPv6%20Multicast%20Addresses.html#ssm-source-specific-multicast-addresses">6. SSM(Source-Specific Multicast Addresses)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc3306-Unicast-Prefix-based%20IPv6%20Multicast%20Addresses.html#examples">7. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc3306-Unicast-Prefix-based%20IPv6%20Multicast%20Addresses.html#id3">参考</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/ipv6/rfc4007-IPv6%20Scoped%20Address%20Architecture.html">RFC4007: IPv6 Scoped Address Architecture</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc4007-IPv6%20Scoped%20Address%20Architecture.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc4007-IPv6%20Scoped%20Address%20Architecture.html#introduction">1.  Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc4007-IPv6%20Scoped%20Address%20Architecture.html#address-scope">4.  Address Scope</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc4007-IPv6%20Scoped%20Address%20Architecture.html#scope-zones">5.  Scope Zones</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc4007-IPv6%20Scoped%20Address%20Architecture.html#zone-indices">6.  Zone Indices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc4007-IPv6%20Scoped%20Address%20Architecture.html#sending-packets">7.  Sending Packets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc4007-IPv6%20Scoped%20Address%20Architecture.html#receiving-packets">8.  Receiving Packets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc4007-IPv6%20Scoped%20Address%20Architecture.html#forwarding">9.  Forwarding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc4007-IPv6%20Scoped%20Address%20Architecture.html#routing">10.  Routing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc4007-IPv6%20Scoped%20Address%20Architecture.html#textual-representation">11.  Textual Representation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc4007-IPv6%20Scoped%20Address%20Architecture.html#examples">Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc4007-IPv6%20Scoped%20Address%20Architecture.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html">RFC4291: IP Version 6 Addressing Architecture</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#id2">学习</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#keypoints">keypoints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#id3">地址类型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#id4">地址分配</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#introduction">1.  Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#ipv6-addressing">2.  IPv6 Addressing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#addressing-model">2.1.  Addressing Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#text-representation-of-addresses">2.2.  Text Representation of Addresses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#text-representation-of-address-prefixes">2.3.  Text Representation of Address Prefixes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#address-type-identification">2.4. Address Type Identification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#unicast-addresses">2.5.  Unicast Addresses</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#anycast-addresses">2.6.  Anycast Addresses</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#multicast-addresses">2.7.  Multicast Addresses</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#pre-defined-multicast-addresses">2.7.1.  Pre-Defined Multicast Addresses</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#a-node-s-required-addresses">2.8. A Node’s Required Addresses</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#security-considerations">3. Security Considerations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#appendix-a-creating-modified-eui-64-format-interface-identifiers">Appendix A: Creating Modified EUI-64 Format Interface Identifiers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#links-or-nodes-with-ieee-eui-64-identifiers">Links or Nodes with IEEE EUI-64 Identifiers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#links-or-nodes-with-ieee-802-48-bit-macs">Links or Nodes with IEEE 802 48-bit MACs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#links-with-other-kinds-of-identifiers">Links with Other Kinds of Identifiers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#links-without-identifiers">Links without Identifiers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#id5">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/ipv6/rfc6437.html">RFC6437: IPv6 Flow Label Specification</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc6437.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/ipv6/rfc7346-IPv6%20Multicast%20Address%20Scopes.html">RFC7346: IPv6 Multicast Address Scopes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc7346-IPv6%20Multicast%20Address%20Scopes.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc7346-IPv6%20Multicast%20Address%20Scopes.html#introduction">1.  Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc7346-IPv6%20Multicast%20Address%20Scopes.html#definition-of-ipv6-multicast-address-scopes-updates-rfc-4291">2.  Definition of IPv6 Multicast Address Scopes (Updates RFC 4291)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc7346-IPv6%20Multicast%20Address%20Scopes.html#definition-of-realm-local-scopes">3.  Definition of Realm-Local Scopes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc7346-IPv6%20Multicast%20Address%20Scopes.html#definition-of-realm-local-scope-for-ieee-802-15-4">5.  Definition of Realm-Local Scope for IEEE 802.15.4</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc7346-IPv6%20Multicast%20Address%20Scopes.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/ipv6/rfc7707.html">RFC7707: Network Reconnaissance in IPv6 Networks</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc7707.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html">RFC8200 Internet Protocol, Version 6 (IPv6) Specification</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#introduction">1.  Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#changes-from-ipv4-to-ipv6">changes from IPv4 to IPv6</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#related-rfc">related RFC</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#terminology">2.  Terminology</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#ipv6-header-format">3.  IPv6 Header Format</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#ipv6-extension-headers">4.  IPv6 Extension Headers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#extension-header-order">4.1.  Extension Header Order</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#options">4.2.  Options</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#hop-by-hop-options-header">4.3.  Hop-by-Hop Options Header</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#routing-header">4.4.  Routing Header</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#fragment-header">4.5.  Fragment Header</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#destination-options-header">4.6.  Destination Options Header</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#no-next-header">4.7.  No Next Header</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#defining-new-extension-headers-and-options">4.8.  Defining New Extension Headers and Options</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#packet-size-issues">5.  Packet Size Issues</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#flow-labels">6.  Flow Labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#traffic-classes">7.  Traffic Classes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#upper-layer-protocol-issues">8.  Upper-Layer Protocol Issues</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#upper-layer-checksums">8.1.  Upper-Layer Checksums</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#maximum-packet-lifetime">8.2.  Maximum Packet Lifetime</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#maximum-upper-layer-payload-size">8.3.  Maximum Upper-Layer Payload Size</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#responding-to-packets-carrying-routing-headers">8.4.  Responding to Packets Carrying Routing Headers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#iana-considerations">9.  IANA Considerations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#security-considerations">10. Security Considerations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#same-with-ipv4">same with ipv4</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#compare-with-ipv4">compare with ipv4</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#references">11. References</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#appendix-a-formatting-guidelines-for-options">Appendix A.  Formatting Guidelines for Options</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#appendix-b-changes-since-rfc-2460">Appendix B.  Changes Since RFC 2460</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/ipv6/rfc8201.html">RFC8201: Path MTU Discovery for IP version 6</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/ipv6/rfc8201.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/tcps/rfc9293-TCP.html">RFC9293: Transmission Control Protocol (TCP)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/tcps/rfc9293-TCP.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/tcps/rfc0768-UDP.html">RFC0768: User Datagram Protocol</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/tcps/rfc0768-UDP.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html">rfc7230: HTTP/1.1: Message Syntax and Routing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#id2">定义</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#hop-by-hop-and-end-to-end">hop-by-hop and end-to-end</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#inbound-and-outbound">Inbound and Outbound</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#head-of-line-hol-blocking-problem">head-of-line (HOL) blocking problem</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#abnf">ABNF语法</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#introduction">1.  Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#syntax-notation">1.2.  Syntax Notation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#architecture">2.  Architecture</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#client-server-messaging">2.1.  Client/Server Messaging</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#implementation-diversity">2.2.  Implementation Diversity</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#intermediaries">2.3.  Intermediaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#caches">2.4.  Caches</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#conformance-and-error-handling">2.5.  Conformance and Error Handling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#protocol-versioning">2.6. Protocol Versioning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#uniform-resource-identifiers">2.7. Uniform Resource Identifiers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#message-format">3. Message Format</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#start-line">3.1. Start Line</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#header-fields">3.2. Header Fields</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#message-body">3.3. Message Body</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#handling-incomplete-messages">3.4. Handling Incomplete Messages</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#transfer-codings">4. Transfer Codings</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#chunked-transfer-coding">4.1.  Chunked Transfer Coding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#compression-codings">4.2. Compression Codings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#te">4.3. TE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#trailer">4.4. Trailer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#message-routing">5. Message Routing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#identifying-a-target-resource">5.1.  Identifying a Target Resource</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#connecting-inbound">5.2.  Connecting Inbound</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#request-target">5.3.  Request Target</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#host">5.4. Host</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#effective-request-uri">5.5. Effective Request URI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#associating-a-response-to-a-request">5.6. Associating a Response to a Request</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#message-forwarding">5.7. Message Forwarding</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#connection-management">6. Connection Management</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#connection">6.1.  Connection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#establishment">6.2. Establishment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#persistence">6.3. Persistence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#concurrency">6.4. Concurrency</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#failures-and-timeouts">6.5. Failures and Timeouts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#tear-down">6.6. Tear-down</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#upgrade">6.7. Upgrade</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#abnf-list-extension-rule">7. ABNF List Extension: #rule</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#iana-considerations">8.  IANA Considerations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#header-field-registration">8.1.  Header Field Registration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#uri-scheme-registration">8.2.  URI Scheme Registration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#internet-media-type-registration">8.3.  Internet Media Type Registration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#transfer-coding-registry">8.4.  Transfer Coding Registry</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#content-coding-registration">8.5.  Content Coding Registration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#upgrade-token-registry">8.6.  Upgrade Token Registry</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7231%20HTTP-Semantics%20and%20Content.html">rfc7231: HTTP/1.1: Semantics and Content</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7232%20HTTP-Conditional%20Requests.html">rfc7232: HTTP/1.1: Conditional Requests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7233%20HTTP-Range%20Requests.html">rfc7233: HTTP/1.1: Range Requests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7234%20HTTP-Caching.html">rfc7234: HTTP/1.1: Caching</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/http/obsoleted-rfc7235%20HTTP-Authentication.html">rfc7235: HTTP/1.1: Authentication</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/http/rfc9110-HTTP%20Semantics.html">rfc9110: HTTP Semantics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/http/rfc9110-HTTP%20Semantics.html#introduction">1. Introduction</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/http/rfc9111-HTTP%20Caching.html">rfc9111: HTTP Caching</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/http/rfc9112-HTTP1.1.html">rfc9112: HTTP/1.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/http3/rfc9000.html">RFC9000: QUIC: A UDP-Based Multiplexed and Secure Transport</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/http3/rfc9000.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/http3/rfc9001.html">RFC9001: Using TLS to Secure QUIC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/http3/rfc9002.html">RFC9002: QUIC Loss Detection and Congestion Control</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/http3/rfc9002.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/http3/rfc9114.html">RFC9114: HTTP/3</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/http3/rfc9114.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/http3/rfc9204.html">RFC9204: QPACK: Field Compression for HTTP/3</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/http3/rfc9204.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/dns/rfc1035.html">RFC1035: DOMAIN NAMES-IMPLEMENTATION AND SPECIFICATION</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/dns/rfc2782.html">RFC2782: DNS SRV</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html">RFC6762: mDNS</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#id2">收集</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#chatgpt">chatGPT</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#id3">规范和要求</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#id4">实现和应用</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#id5">安全性</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#id6">性能和可扩展性</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#introduction">1.  Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#mdns-names">3.  mDNS Names</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#reverse-address-mapping">4. Reverse Address Mapping</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#querying">5. Querying</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#one-shot-mdns-queries">5.1.  One-Shot mDNS Queries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#continuous-mdns-querying">5.2.  Continuous mDNS Querying</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#multiple-questions-per-query">5.3.  Multiple Questions per Query</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#questions-requesting-unicast-responses">5.4.  Questions Requesting Unicast Responses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#direct-unicast-queries-to-port-5353">5.5.  Direct Unicast Queries to Port 5353</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#responding">6. Responding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#common">common</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#negative-responses">6.1.  Negative Responses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#responding-to-address-queries">6.2.  Responding to Address Queries</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#traffic-reduction">7. Traffic Reduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#probing-and-announcing-on-startup">8. Probing and Announcing on Startup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#conflict-resolution">9. Conflict Resolution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#resource-record-ttl-values-and-cache-coherency">10. Resource Record TTL Values and Cache Coherency</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#source-address-check">11.  Source Address Check</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#special-characteristics-of-mdns-domains">12.  Special Characteristics of mDNS Domains</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#enabling-and-disabling-mdns">13.  Enabling and Disabling mDNS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#considerations-for-multiple-interfaces">14.  Considerations for Multiple Interfaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#considerations-for-multiple-responders-on-the-same-machine">15.  Considerations for Multiple Responders on the Same Machine</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#mdns-character-set">16.  mDNS Character Set</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#mdns-message-size">17.  mDNS Message Size</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#mdns-message-format">18.  mDNS Message Format</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#id-query-identifier">18.1.  ID (Query Identifier)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#qr-query-response-bit">18.2.  QR (Query/Response) Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#opcode">18.3.  OPCODE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#aa-authoritative-answer-bit">18.4.  AA (Authoritative Answer) Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#tc-truncated-bit">18.5.  TC (Truncated) Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#rd-recursion-desired-bit">18.6.  RD (Recursion Desired) Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#ra-recursion-available-bit">18.7.  RA (Recursion Available) Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#z-zero-bit">18.8.  Z (Zero) Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#ad-authentic-data-bit">18.9.  AD (Authentic Data) Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#cd-checking-disabled-bit">18.10.  CD (Checking Disabled) Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#rcode-response-code">18.11.  RCODE (Response Code)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#repurposing-of-top-bit-of-qclass-in-question-section">18.12.  Repurposing of Top Bit of qclass in Question Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#repurposing-of-top-bit-of-rrclass-in-resource-record-sections">18.13.  Repurposing of Top Bit of rrclass in Resource Record Sections</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#name-compression">18.14.  Name Compression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#id7">18.5.  TC (Truncated) Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#id8">18.6.  RD (Recursion Desired) Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#id9">18.7.  RA (Recursion Available) Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#id10">18.8.  Z (Zero) Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#id11">18.9.  AD (Authentic Data) Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#id12">18.10.  CD (Checking Disabled) Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#id13">18.11.  RCODE (Response Code)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#id14">18.12.  Repurposing of Top Bit of qclass in Question Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#id15">18.13.  Repurposing of Top Bit of rrclass in Resource Record Sections</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#id16">18.14.  Name Compression</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#summary-of-differences-between-mdns-and-unicast-dns">19.  Summary of Differences between mDNS and Unicast DNS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#ipv6-considerations">20.  IPv6 Considerations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#security-considerations">21.  Security Considerations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#iana-considerations">22. IANA Considerations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#appendix-a-design-rationale-for-choice-of-udp-port-number">Appendix A. Design Rationale for Choice of UDP Port Number</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#appendix-b-design-rationale-for-not-using-hashed-multicast-addresses">Appendix B. Design Rationale for Not Using Hashed Multicast Addresses</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#appendix-c-design-rationale-for-maximum-multicast-dns-name-length">Appendix C. Design Rationale for Maximum Multicast DNS Name Length</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#appendix-d-benefits-of-multicast-responses">Appendix D. Benefits of Multicast Responses</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#appendix-e-design-rationale-for-encoding-negative-responses">Appendix E. Design Rationale for Encoding Negative Responses</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#appendix-f-use-of-utf-8">Appendix F. Use of UTF-8</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#appendix-g-private-dns-namespaces">Appendix G. Private DNS Namespaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#appendix-h-deployment-history">Appendix H.  Deployment History</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6762.html#id17">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html">RFC6763: DNS-Based Service Discovery</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#id2">收集</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#introduction">1.  Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#design-goals">3.  Design Goals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#service-instance-enumeration-browsing">4.  Service Instance Enumeration (Browsing)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#structured-service-instance-names">4.1.  Structured Service Instance Names</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#user-interface-presentation">4.2.  User Interface Presentation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#internal-handling-of-names">4.3.  Internal Handling of Names</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#service-instance-resolution">5. Service Instance Resolution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#data-syntax-for-dns-sd-txt-records">6. Data Syntax for DNS-SD TXT Records</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#general-format-rules-for-dns-txt-records">6.1. General Format Rules for DNS TXT Records</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#dns-sd-txt-record-size">6.2. DNS-SD TXT Record Size</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#dns-txt-record-format-rules-for-use-in-dns-sd">6.3. DNS TXT Record Format Rules for Use in DNS-SD</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#rules-for-keys-in-dns-sd-key-value-pairs">6.4. Rules for Keys in DNS-SD Key/Value Pairs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#rules-for-values-in-dns-sd-key-value-pairs">6.5. Rules for Values in DNS-SD Key/Value Pairs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#example-txt-record">6.6. Example TXT Record</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#version-tag">6.7. Version Tag</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#service-instances-with-multiple-txt-records">6.8. Service Instances with Multiple TXT Records</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#id3">7. Service Names</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#selective-instance-enumeration-subtypes">7.1. Selective Instance Enumeration (Subtypes)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#service-name-length-limits">7.2. Service Name Length Limits</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#flagship-naming">8. Flagship Naming</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#service-type-enumeration">9. Service Type Enumeration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#populating-the-dns-with-information">10. Populating the DNS with Information</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#domain-enumeration">11. Domain Enumeration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#dns-additional-record-generation">12.  DNS Additional Record Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#ptr-records">12.1.  PTR Records</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#srv-records">12.2.  SRV Records</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#txt-records">12.3.  TXT Records</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#other-record-types">12.4.  Other Record Types</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#working-examples">13.  Working Examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#ipv6-considerations">14.  IPv6 Considerations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#security-considerations">15.  Security Considerations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#iana-considerations">16.  IANA Considerations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#appendix-a-rationale-for-using-dns-as-a-basis-for-service-discovery">Appendix A.  Rationale for Using DNS as a Basis for Service Discovery</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#appendix-b-ordering-of-service-instance-name-components">Appendix B.  Ordering of Service Instance Name Components</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#b-1-semantic-structure">B.1.  Semantic Structure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#b-2-network-efficiency">B.2.  Network Efficiency</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#b-3-operational-flexibility">B.3.  Operational Flexibility</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#appendix-c-what-you-see-is-what-you-get">Appendix C.  What You See Is What You Get</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#appendix-d-choice-of-factory-default-names">Appendix D.  Choice of Factory-Default Names</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#appendix-e-name-encodings-in-the-domain-name-system">Appendix E.  Name Encodings in the Domain Name System</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#appendix-f-continuous-live-update-browsing-model">Appendix F.  “Continuous Live Update” Browsing Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc6763.html#id4">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/dns/rfc8766.html">RFC8766: Discovery Proxy for Multicast DNS-Based Service Discovery</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/dns/rfc8766.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/streamings/rfc2974-Session%20Announcement%20Protocol.html">RFC2974: Session Announcement Protocol</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html">RFC3261: SIP: Session Initiation Protocol</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#introduction">1 Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#overview-of-sip-functionality">2 Overview of SIP Functionality</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#overview-of-operation">4 Overview of Operation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#structure-of-the-protocol">5 Structure of the Protocol</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#definitions">6 Definitions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#sip-messages">7 SIP Messages</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#requests">7.1 Requests</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#responses">7.2 Responses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#header-fields">7.3 Header Fields</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#bodies">7.4 Bodies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#framing-sip-messages">7.5 Framing SIP Messages</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#general-user-agent-behavior">8 General User Agent Behavior</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#uac-behavior">8.1 UAC Behavior</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#uas-behavior">8.2 UAS Behavior</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#redirect-servers">8.3 Redirect Servers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#canceling-a-request">9 Canceling a Request</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#client-behavior">9.1 Client Behavior</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#server-behavior">9.2 Server Behavior</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#registrations">10 Registrations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#overview">10.1 Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#constructing-the-register-request">10.2 Constructing the REGISTER Request</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#processing-register-requests">10.3 Processing REGISTER Requests</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#querying-for-capabilities">11 Querying for Capabilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#dialogs">12 Dialogs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#creation-of-a-dialog">12.1 Creation of a Dialog</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#requests-within-a-dialog">12.2 Requests within a Dialog</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#termination-of-a-dialog">12.3 Termination of a Dialog</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#initiating-a-session">13 Initiating a Session</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#id3">13.1 Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#uac-processing">13.2 UAC Processing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#uas-processing">13.3 UAS Processing</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#modifying-an-existing-session">14 Modifying an Existing Session</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#id4">14.1 UAC Behavior</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#id5">14.2 UAS Behavior</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#terminating-a-session">15 Terminating a Session</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#terminating-a-session-with-a-bye-request">15.1 Terminating a Session with a BYE Request</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#proxy-behavior">16 Proxy Behavior</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#id8">16.1 Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#stateful-proxy">16.2 Stateful Proxy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#request-validation">16.3 Request Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#route-information-preprocessing">16.4 Route Information Preprocessing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#determining-request-targets">16.5 Determining Request Targets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#request-forwarding">16.6 Request Forwarding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#response-processing">16.7 Response Processing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#processing-timer-c">16.8 Processing Timer C</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#handling-transport-errors">16.9 Handling Transport Errors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#cancel-processing">16.10 CANCEL Processing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#stateless-proxy">16.11 Stateless Proxy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#summary-of-proxy-route-processing">16.12 Summary of Proxy Route Processing</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#transactions">17 Transactions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#client-transaction">17.1 Client Transaction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#server-transaction">17.2 Server Transaction</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#transport">18 Transport</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#common-message-components">19 Common Message Components</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#sip-and-sips-uniform-resource-indicators">19.1 SIP and SIPS Uniform Resource Indicators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#option-tags">19.2 Option Tags</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#tags">19.3 Tags</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#id10">20 Header Fields</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#accept">20.1 Accept</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#accept-encoding">20.2 Accept-Encoding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#accept-language">20.3 Accept-Language</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#alert-info">20.4 Alert-Info</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#allow">20.5 Allow</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#authentication-info">20.6 Authentication-Info</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#authorization">20.7 Authorization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#call-id">20.8 Call-ID</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#call-info">20.9 Call-Info</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#contact">20.10 Contact</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#content-disposition">20.11 Content-Disposition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#content-encoding">20.12 Content-Encoding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#content-language">20.13 Content-Language</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#content-length">20.14 Content-Length</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#content-type">20.15 Content-Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#cseq">20.16 CSeq</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#date">20.17 Date</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#error-info">20.18 Error-Info</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#expires">20.19 Expires</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#from">20.20 From</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#in-reply-to">20.21 In-Reply-To</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#max-forwards">20.22 Max-Forwards</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#min-expires">20.23 Min-Expires</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#mime-version">20.24 MIME-Version</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#organization">20.25 Organization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#priority">20.26 Priority</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#proxy-authenticate">20.27 Proxy-Authenticate</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#proxy-authorization">20.28 Proxy-Authorization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#proxy-require">20.29 Proxy-Require</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#record-route">20.30 Record-Route</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#reply-to">20.31 Reply-To</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#id11">20.32 Require</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#retry-after">20.33 Retry-After</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#route">20.34 Route</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#server">20.35 Server</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#subject">20.36 Subject</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#supported">20.37 Supported</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#timestamp">20.38 Timestamp</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#to">20.39 To</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#unsupported">20.40 Unsupported</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#user-agent">20.41 User-Agent</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#via">20.42 Via</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#warning">20.43 Warning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#www-authenticate">20.44 WWW-Authenticate</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#response-codes">21 Response Codes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#provisional-1xx">21.1 Provisional 1xx</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#successful-2xx">21.2 Successful 2xx</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#redirection-3xx">21.3 Redirection 3xx</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#request-failure-4xx">21.4 Request Failure 4xx</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#server-failure-5xx">21.5 Server Failure 5xx</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#global-failures-6xx">21.6 Global Failures 6xx</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#usage-of-http-authentication">22 Usage of HTTP Authentication</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#framework">22.1 Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#user-to-user-authentication">22.2 User-to-User Authentication</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#proxy-to-user-authentication">22.3 Proxy-to-User Authentication</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#the-digest-authentication-scheme">22.4 The Digest Authentication Scheme</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#s-mime">23 S/MIME</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#s-mime-certificates">23.1 S/MIME Certificates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#s-mime-key-exchange">23.2 S/MIME Key Exchange</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#securing-mime-bodies">23.3 Securing MIME bodies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#sip-header-privacy-and-integrity-using-s-mime-tunneling-sip">23.4 SIP Header Privacy and Integrity using S/MIME: Tunneling SIP</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#id12">24 Examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#registration">24.1 Registration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#session-setup">24.2 Session Setup</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#augmented-bnf-for-the-sip-protocol">25 Augmented BNF for the SIP Protocol</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#security-considerations-threat-model-and-security-usage-recommendations">26 Security Considerations: Threat Model and Security Usage Recommendations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#iana-considerations">27 IANA Considerations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#changes-from-rfc-2543">28 Changes From RFC 2543</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#major-functional-changes">28.1 Major Functional Changes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#minor-functional-changes">28.2 Minor Functional Changes</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#a-table-of-timer-values">A Table of Timer Values</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html">RFC3550: RTP: A Transport Protocol for Real-Time Applications</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#introduction">1. Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#rtp-use-scenarios">2. RTP Use Scenarios</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#simple-multicast-audio-conference">2.1 Simple Multicast Audio Conference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#audio-and-video-conference">2.2 Audio and Video Conference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#mixers-and-translators">2.3 Mixers and Translators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#layered-encodings">2.4 Layered Encodings</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#definitions">3. Definitions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#byte-order-alignment-and-time-format">4. Byte Order, Alignment, and Time Format</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#rtp-data-transfer-protocol">5. RTP Data Transfer Protocol</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#rtp-fixed-header-fields">5.1 RTP Fixed Header Fields</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#multiplexing-rtp-sessions">5.2 Multiplexing RTP Sessions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#profile-specific-modifications-to-the-rtp-header">5.3  Profile-Specific Modifications to the RTP Header</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#rtp-control-protocol-rtcp">6.  RTP Control Protocol – RTCP</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#rtcp-packet-format">6.1  RTCP Packet Format</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#rtcp-transmission-interval">6.2  RTCP Transmission Interval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#rtcp-packet-send-and-receive-rules">6.3  RTCP Packet Send and Receive Rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#sender-and-receiver-reports">6.4  Sender and Receiver Reports</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#sdes-source-description-rtcp-packet">6.5  SDES: Source Description RTCP Packet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#bye-goodbye-rtcp-packet">6.6  BYE: Goodbye RTCP Packet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#app-application-defined-rtcp-packet">6.7  APP: Application-Defined RTCP Packet</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#rtp-translators-and-mixers">7.  RTP Translators and Mixers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#general-description">7.1  General Description</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#rtcp-processing-in-translators">7.2  RTCP Processing in Translators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#rtcp-processing-in-mixers">7.3  RTCP Processing in Mixers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#cascaded-mixers">7.4  Cascaded Mixers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#ssrc-identifier-allocation-and-use">8.  SSRC Identifier Allocation and Use</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#security">9.  Security</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#confidentiality">9.1 Confidentiality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#authentication-and-message-integrity">9.2 Authentication and Message Integrity</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#congestion-control">10. Congestion Control</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#rtp-over-network-and-transport-protocols">11. RTP over Network and Transport Protocols</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#summary-of-protocol-constants">12. Summary of Protocol Constants</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#rtcp-packet-types">12.1 RTCP Packet Types</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#sdes-types">12.2 SDES Types</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#rtp-profiles-and-payload-format-specifications">13. RTP Profiles and Payload Format Specifications</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#appendix-a-algorithms">Appendix A.   Algorithms</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#appendix-b-changes-from-rfc-1889">Appendix B.   Changes from RFC 1889</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html">RFC3551: RTP Profile for Audio and Video Conferences with Minimal Control</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#introduction">1. Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#rtp-and-rtcp-packet-forms-and-protocol-behavior">2. RTP and RTCP Packet Forms and Protocol Behavior</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#registering-additional-encodings">3.  Registering Additional Encodings</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#audio">4.  Audio</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#encoding-independent-rules">4.1  Encoding-Independent Rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#operating-recommendations">4.2  Operating Recommendations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#guidelines-for-sample-based-audio-encodings">4.3  Guidelines for Sample-Based Audio Encodings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#guidelines-for-frame-based-audio-encodings">4.4  Guidelines for Frame-Based Audio Encodings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#audio-encodings">4.5 Audio Encodings</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#video">5.  Video</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#payload-type-definitions">6.  Payload Type Definitions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#rtp-over-tcp-and-similar-byte-stream-protocols">7.  RTP over TCP and Similar Byte Stream Protocols</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#port-assignment">8.  Port Assignment</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#changes-from-rfc-1890">9.  Changes from RFC 1890</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html">RFC6184: RTP Payload Format for H.264 Video</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#introduction">1. Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#the-h-264-codec">1.1.  The H.264 Codec</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#parameter-set-concept">1.2.  Parameter Set Concept</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#network-abstraction-layer-unit-types">1.3.  Network Abstraction Layer Unit Types</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#conventions">2. Conventions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#scope">3. Scope</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#definitions-and-abbreviations">4. Definitions and Abbreviations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#definitions">4.1.  Definitions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#abbreviations">4.2.  Abbreviations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#rtp-payload-format">5. RTP Payload Format</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#rtp-header-usage">5.1.  RTP Header Usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#payload-structures">5.2.  Payload Structures</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#nal-unit-header-usage">5.3.  NAL Unit Header Usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#packetization-modes">5.4.  Packetization Modes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#decoding-order-number-don">5.5.  Decoding Order Number (DON)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#single-nal-unit-packet">5.6.  Single NAL Unit Packet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#aggregation-packets">5.7.  Aggregation Packets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#fragmentation-units-fus">5.8.  Fragmentation Units (FUs)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#packetization-rules">6. Packetization Rules</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#de-packetization-process">7. De-Packetization Process</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#payload-format-parameters">8. Payload Format Parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#media-type-registration">8.1.  Media Type Registration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#sdp-parameters">8.2.  SDP Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#examples">8.3.  Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#parameter-set-considerations">8.4.  Parameter Set Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#decoder-refresh-point-procedure-using-in-band-transport-of-parameter-sets-informative">8.5.  Decoder Refresh Point Procedure Using In-Band Transport of Parameter Sets (Informative)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#informative-appendix-application-examples">12. Informative Appendix: Application Examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#video-telephony-according-to-annex-a-of-itu-t-recommendation-h-241">12.1.  Video Telephony According to Annex A of ITU-T Recommendation H.241</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#video-telephony-no-slice-data-partitioning-no-nal-unit-aggregation">12.2.  Video Telephony, No Slice Data Partitioning, No NAL Unit Aggregation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#video-telephony-interleaved-packetization-using-nal-unit-aggregation">12.3.  Video Telephony, Interleaved Packetization Using NAL Unit Aggregation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#video-telephony-with-data-partitioning">12.4.  Video Telephony with Data Partitioning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#video-telephony-or-streaming-with-fus-and-forward-error-correction">12.5.  Video Telephony or Streaming with FUs and Forward Error Correction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#low-bitrate-streaming">12.6.  Low Bitrate Streaming</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#robust-packet-scheduling-in-video-streaming">12.7.  Robust Packet Scheduling in Video Streaming</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#informative-appendix-rationale-for-decoding-order-number">13. Informative Appendix: Rationale for Decoding Order Number</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#example-of-robust-packet-scheduling">13.3.  Example of Robust Packet Scheduling</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html">RFC7826: Real-Time Streaming Protocol</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#introduction">1.  Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#protocol-overview">2.  Protocol Overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#presentation-description">2.1.  Presentation Description</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#session-establishment">2.2.  Session Establishment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#media-delivery-control">2.3.  Media Delivery Control</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#session-parameter-manipulations">2.4. Session Parameter Manipulations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#media-delivery">2.5. Media Delivery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#session-maintenance-and-termination">2.6. Session Maintenance and Termination</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#extending-rtsp">2.7. Extending RTSP</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#document-conventions">3. Document Conventions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#terminology">3.2. Terminology</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#protocol-parameters">4. Protocol Parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#rtsp-version">4.1.  RTSP Version</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#rtsp-iri-and-uri">4.2.  RTSP IRI and URI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#session-identifiers">4.3.  Session Identifiers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#media-time-formats">4.4.  Media-Time Formats</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#feature-tags">4.5.  Feature Tags</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#message-body-tags">4.6.  Message Body Tags</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#media-properties">4.7.  Media Properties</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#rtsp-message">5. RTSP Message</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#message-types">5.1. Message Types</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#message-headers">5.2. Message Headers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#message-body">5.3. Message Body</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#message-length">5.4. Message Length</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#general-header-fields">6. General-Header Fields</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#request">7. Request</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#request-line">7.1.  Request Line</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#request-header-fields">7.2.  Request-Header Fields</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#response">8. Response</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#status-line">8.1.  Status-Line</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#response-headers">8.2.  Response Headers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#id2">9. Message Body</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#message-body-header-fields">9.1.  Message Body Header Fields</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#id3">9.2. Message Body</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#message-body-format-negotiation">9.3. Message Body Format Negotiation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#connections">10. Connections</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#reliability-and-acknowledgements">10.1. Reliability and Acknowledgements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#using-connections">10.2. Using Connections</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#closing-connections">10.3. Closing Connections</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#timing-out-connections-and-rtsp-messages">10.4.  Timing Out Connections and RTSP Messages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#showing-liveness">10.5.  Showing Liveness</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#use-of-ipv6">10.6.  Use of IPv6</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#overload-control">10.7.  Overload Control</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#capability-handling">11. Capability Handling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#pipelining-support">12. Pipelining Support</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#method-definitions">13. Method Definitions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#options">13.1.  OPTIONS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#describe">13.2. DESCRIBE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#setup">13.3.  SETUP</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#play">13.4.  PLAY</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#play-notify">13.5.  PLAY_NOTIFY</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#pause">13.6.  PAUSE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#teardown">13.7.  TEARDOWN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#get-parameter">13.8.  GET_PARAMETER</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#redirect">13.10.  REDIRECT</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#embedded-interleaved-binary-data">14. Embedded (Interleaved) Binary Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#proxies">15. Proxies</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#proxies-and-protocol-extensions">15.1.  Proxies and Protocol Extensions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#multiplexing-and-demultiplexing-of-messages">15.2.  Multiplexing and Demultiplexing of Messages</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#caching">16. Caching</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#validation-model">16.1.  Validation Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#invalidation-after-updates-or-deletions">16.2.  Invalidation after Updates or Deletions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#status-code-definitions">17. Status Code Definitions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#header-field-definitions">18. Header Field Definitions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#pipelined-requests">18.33.  Pipelined-Requests</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#security-framework">19. Security Framework</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#rtsp-and-http-authentication">19.1.  RTSP and HTTP Authentication</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#rtsp-over-tls">19.2. RTSP over TLS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#security-and-proxies">19.3. Security and Proxies</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#syntax">20. Syntax</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#base-syntax">20.1.  Base Syntax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#rtsp-protocol-definition">20.2.  RTSP Protocol Definition</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#security-considerations">21. Security Considerations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#signaling-protocol-threats">21.1.  Signaling Protocol Threats</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#appendix-a-examples">Appendix A.  Examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#a-1-media-on-demand-unicast">A.1.  Media on Demand (Unicast)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#a-2-media-on-demand-using-pipelining">A.2.  Media on Demand Using Pipelining</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#a-3-secured-media-session-for-on-demand-content">A.3.  Secured Media Session for On-Demand Content</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#a-4-media-on-demand-unicast">A.4.  Media on Demand (Unicast)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#a-5-single-stream-container-files">A.5.  Single-Stream Container Files</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#a-6-live-media-presentation-using-multicast">A.6.  Live Media Presentation Using Multicast</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#a-7-capability-negotiation">A.7.  Capability Negotiation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#appendix-b-rtsp-protocol-state-machine">Appendix B.  RTSP Protocol State Machine</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#b-1-states">B.1.  States</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#b-2-state-variables">B.2.  State Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#b-3-abbreviations">B.3.  Abbreviations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#b-4-state-tables">B.4.  State Tables</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#appendix-c-media-transport-alternatives">Appendix C.  Media-Transport Alternatives</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#c-1-rtp">C.1.  RTP</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#c-2-rtp-over-tcp">C.2. RTP over TCP</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#c-3-handling-media-clock-time-jumps-in-the-rtp-media-layer">C.3.  Handling Media-Clock Time Jumps in the RTP Media Layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#c-4-handling-rtp-timestamps-after-pause">C.4. Handling RTP Timestamps after PAUSE</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#c-5-rtsp-rtp-integration">C.5.  RTSP/RTP Integration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#c-6-scaling-with-rtp">C.6.  Scaling with RTP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#c-7-maintaining-npt-synchronization-with-rtp-timestamps">C.7.  Maintaining NPT Synchronization with RTP Timestamps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#c-8-continuous-audio">C.8.  Continuous Audio</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#c-9-multiple-sources-in-an-rtp-session">C.9.  Multiple Sources in an RTP Session</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#c-10-usage-of-ssrcs-and-the-rtcp-bye-message-during-an-rtsp-session">C.10.  Usage of SSRCs and the RTCP BYE Message during an RTSP Session</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#c-11-future-additions">C.11.  Future Additions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#appendix-d-use-of-sdp-for-rtsp-session-descriptions">Appendix D. Use of SDP for RTSP Session Descriptions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#d-1-definitions">D.1.  Definitions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#d-2-aggregate-control-not-available">D.2.  Aggregate Control Not Available</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#d-3-aggregate-control-available">D.3.  Aggregate Control Available</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#d-4-grouping-of-media-lines-in-sdp">D.4.  Grouping of Media Lines in SDP</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#d-5-rtsp-external-sdp-delivery">D.5.  RTSP External SDP Delivery</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#appendix-e-rtsp-use-cases">Appendix E. RTSP Use Cases</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#e-1-on-demand-playback-of-stored-content">E.1.  On-Demand Playback of Stored Content</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#e-2-unicast-distribution-of-live-content">E.2.  Unicast Distribution of Live Content</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#e-3-on-demand-playback-using-multicast">E.3.  On-Demand Playback Using Multicast</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#e-4-inviting-an-rtsp-server-into-a-conference">E.4.  Inviting an RTSP Server into a Conference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#e-5-live-content-using-multicast">E.5.  Live Content Using Multicast</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#appendix-f-text-format-for-parameters">Appendix F.  Text Format for Parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#appendix-g-requirements-for-unreliable-transport-of-rtsp">Appendix G.  Requirements for Unreliable Transport of RTSP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#appendix-h-backwards-compatibility-considerations">Appendix H.  Backwards-Compatibility Considerations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#h-1-play-request-in-play-state">H.1.  Play Request in Play State</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#h-2-using-persistent-connections">H.2.  Using Persistent Connections</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#appendix-i-changes">Appendix I.  Changes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#i-1-brief-overview">I.1.  Brief Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#i-2-detailed-list-of-changes">I.2.  Detailed List of Changes</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html">RFC8866: SDP-Session Description Protocol</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#introduction">1. Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#glossary-of-terms">2. Glossary of Terms</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#examples-of-sdp-usage">3. Examples of SDP Usage</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#session-initiation">3.1. Session Initiation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#streaming-media">3.2. Streaming Media</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#email-and-the-world-wide-web">3.3. Email and the World Wide Web</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#multicast-session-announcement">3.4. Multicast Session Announcement</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#requirements-and-recommendations">4. Requirements and Recommendations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#media-and-transport-information">4.1. Media and Transport Information</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#timing-information">4.2. Timing Information</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#sdp-specification">5. SDP Specification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#protocol-version-v">5.1. Protocol Version (“v=”)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#origin-o">5.2. Origin (“o=”)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#session-name-s">5.3. Session Name (“s=”)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#session-information-i">5.4. Session Information (“i=”)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#uri-u">5.5. URI (“u=”)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#email-address-and-phone-number-e-and-p">5.6. Email Address and Phone Number (“e=” and “p=”)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#connection-information-c">5.7. Connection Information (“c=”)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#bandwidth-information-b">5.8. Bandwidth Information (“b=”)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#time-active-t">5.9. Time Active (“t=”)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#repeat-times-r">5.10. Repeat Times (“r=”)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#time-zone-adjustment-z">5.11. Time Zone Adjustment (“z=”)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#encryption-keys-k">5.12. Encryption Keys (“k=”)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#attributes-a">5.13. Attributes (“a=”)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#media-descriptions-m">5.14. Media Descriptions (“m=”)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#sdp-attributes">6. SDP Attributes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#cat-category">6.1. cat (Category)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#keywds-keywords">6.2. keywds (Keywords)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#tool">6.3. tool</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#ptime-packet-time">6.4. ptime (Packet Time)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#maxptime-maximum-packet-time">6.5. maxptime (Maximum Packet Time)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#rtpmap">6.6. rtpmap</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#media-direction-attributes">6.7. Media Direction Attributes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#orient-orientation">6.8. orient (Orientation)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#type-conference-type">6.9. type (Conference Type)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#charset-character-set">6.10. charset (Character Set)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#sdplang-sdp-language">6.11. sdplang (SDP Language)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#lang-language">6.12. lang (Language)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#framerate-frame-rate">6.13. framerate (Frame Rate)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#quality">6.14. quality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#fmtp-format-parameters">6.15. fmtp (Format Parameters)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#security-considerations">7. Security Considerations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#iana-considerations">8. IANA Considerations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#sdp-grammar">9. SDP Grammar</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#summary-of-changes-from-rfc-4566">10. Summary of Changes from RFC 4566</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/STUNs/rfc7350.html">rfc7350: DTLS as Transport for STUN</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/STUNs/rfc5769.html">RFC5769: Test Vectors for STUN</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/STUNs/rfc5780.html">rfc5780: NAT Behavior Discovery Using STUN</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/STUNs/rfc7443.html">rfc7443: ALPN Labels for STUN Usages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/STUNs/rfc7635.html">rfc7635: STUN Extension for Third-Party Authorization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/STUNs/rfc8489.html">RFC8489: STUN - Session Traversal Utilities for NAT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/x.509/rfc5280.html">RFC5280: Internet X.509 PKIC and CRL Profile</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/x.509/rfc5280.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/x.509/rfc5652.html">RFC5652: Cryptographic Message Syntax (CMS)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/x.509/rfc5652.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/x.509/rfc5912.html">RFC5912: New ASN.1 Modules for the PKIX</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/x.509/rfc5912.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/MIME/rfc2045-MIME1.html">RFC2045: (MIME) Part One: Format of Internet Message Bodies</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2045-MIME1.html#introduction">1.  Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2045-MIME1.html#definitions-conventions-and-generic-bnf-grammar">2.  Definitions, Conventions, and Generic BNF Grammar</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2045-MIME1.html#mime-header-fields">3.  MIME Header Fields</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2045-MIME1.html#mime-version-header-field">4.  MIME-Version Header Field</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2045-MIME1.html#id2">示例</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2045-MIME1.html#content-type-header-field">5.  Content-Type Header Field</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2045-MIME1.html#syntax-of-the-content-type-header-field">5.1 Syntax of the Content-Type Header Field</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2045-MIME1.html#content-type-defaults">5.2 Content-Type Defaults</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2045-MIME1.html#content-transfer-encoding-header-field">6. Content-Transfer-Encoding Header Field</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2045-MIME1.html#content-transfer-encoding-syntax">6.1.  Content-Transfer-Encoding Syntax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2045-MIME1.html#content-transfer-encodings-semantics">6.2.  Content-Transfer-Encodings Semantics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2045-MIME1.html#new-content-transfer-encodings">6.3.  New Content-Transfer-Encodings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2045-MIME1.html#interpretation-and-use">6.4.  Interpretation and Use</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2045-MIME1.html#translating-encodings">6.5.  Translating Encodings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2045-MIME1.html#canonical-encoding-model">6.6.  Canonical Encoding Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2045-MIME1.html#quoted-printable-content-transfer-encoding">6.7.  Quoted-Printable Content-Transfer-Encoding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2045-MIME1.html#base64-content-transfer-encoding">6.8.  Base64 Content-Transfer-Encoding</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2045-MIME1.html#content-id-header-field">7.  Content-ID Header Field</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2045-MIME1.html#content-description-header-field">8.  Content-Description Header Field</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2045-MIME1.html#additional-mime-header-fields">9.  Additional MIME Header Fields</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2045-MIME1.html#appendix-a-collected-grammar">Appendix A – Collected Grammar</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2045-MIME1.html#content">content</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2045-MIME1.html#encoding">encoding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2045-MIME1.html#id">id</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2045-MIME1.html#description">description</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2045-MIME1.html#mime-extension-field">MIME-extension-field</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2045-MIME1.html#id3">通用</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/MIME/rfc2046-MIME2.html">RFC2046: (MIME) Part Two: Media Types</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2046-MIME2.html#overview-of-the-initial-top-level-media-types">3. Overview Of The Initial Top-Level Media Types</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2046-MIME2.html#discrete-media-type-values">4. Discrete Media Type Values</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2046-MIME2.html#text-media-type">4.1.  Text Media Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2046-MIME2.html#image-media-type">4.2.  Image Media Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2046-MIME2.html#audio-media-type">4.3.  Audio Media Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2046-MIME2.html#video-media-type">4.4.  Video Media Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2046-MIME2.html#application-media-type">4.5.  Application Media Type</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2046-MIME2.html#composite-media-type-values">5. Composite Media Type Values</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2046-MIME2.html#multipart-media-type">5.1.  Multipart Media Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2046-MIME2.html#message-media-type">5.2 Message Media Type</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2046-MIME2.html#experimental-media-type-values">6.  Experimental Media Type Values</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/MIME/rfc2047-MIME3.html">RFC2047: (MIME) Part Three: Message Header Extensions for Non-ASCII Text</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2047-MIME3.html#introduction">1. Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2047-MIME3.html#syntax-of-encoded-words">2. Syntax of encoded-words</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2047-MIME3.html#character-sets">3. Character sets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2047-MIME3.html#encodings">4. Encodings</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2047-MIME3.html#use-of-encoded-words-in-message-headers">5. Use of encoded-words in message headers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2047-MIME3.html#support-of-encoded-word-s-by-mail-readers">6. Support of ‘encoded-word’s by mail readers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2047-MIME3.html#conformance">7. Conformance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2047-MIME3.html#examples">8. Examples</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/MIME/rfc2048-MIME4.html">RFC2048: (MIME) Part Four: Registration Procedures</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2048-MIME4.html#introduction">1. Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2048-MIME4.html#media-type-registration">2. Media Type Registration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2048-MIME4.html#registration-trees-and-subtype-names">2.1.  Registration Trees and Subtype Names</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2048-MIME4.html#registration-requirements">2.2 Registration Requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2048-MIME4.html#registration-procedure">2.3 Registration Procedure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2048-MIME4.html#comments-on-media-type-registrations">2.4 Comments on Media Type Registrations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2048-MIME4.html#location-of-registered-media-type-list">2.5 Location of Registered Media Type List</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2048-MIME4.html#iana-procedures-for-registering-media-types">2.6.  IANA Procedures for Registering Media Types</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2048-MIME4.html#change-control">2.7.  Change Control</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rfcs/MIME/rfc2048-MIME4.html#registration-template">2.8 Registration Template</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2048-MIME4.html#external-body-access-types">3. External Body Access Types</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2048-MIME4.html#transfer-encodings">4. Transfer Encodings</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/MIME/rfc2049-MIME5.html">RFC2049: (MIME) Part Five: Conformance Criteria and Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2049-MIME5.html#introduction">1. Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2049-MIME5.html#mime-conformance">2.  MIME Conformance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2049-MIME5.html#guidelines-for-sending-email-data">3.  Guidelines for Sending Email Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2049-MIME5.html#canonical-encoding-model">4.  Canonical Encoding Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/MIME/rfc2049-MIME5.html#appendix-a-a-complex-multipart-example">Appendix A – A Complex Multipart Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/rfc1123.html">rfc1123</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/rfc3232.html">RFC3232: ASSIGNED NUMBERS</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/rfc3232.html#rfc1700">RFC1700</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/rfc3339.html">rfc3339</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/rfc3339.html#id3">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rfcs/rfc5234-ABNF.html">RFC5234: Augmented BNF for Syntax Specifications: ABNF</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rfcs/rfc5234-ABNF.html#id2">示例</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../iana.html">iana</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../IEEE.html">IEEE</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../IEEEs/normal.html">常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../IEEEs/754.html">IEEE 754</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../IEEEs/754.html#id1">工具</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../IEEEs/754.html#id2">📦 IEEE 754 定义的内容包括：</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../IEEEs/754.html#id3">✅ 1. <strong>浮点数格式</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../IEEEs/754.html#id4">✅ 2. <strong>浮点数结构（三部分）</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../IEEEs/754.html#id5">✅ 3. <strong>特殊值支持</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../IEEEs/754.html#id6">📚 衍生标准（对深度学习重要）</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../IEEEs/754.html#fp4">FP4</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../IEEEs/802.3.html">IEEE 802.3</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../IEEEs/802.3.html#ethernet-ii">Ethernet II</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../IEEEs/802.11.html">802.11: Wireless LAN &amp; Mesh</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../IEEEs/802.11.html#protocol">Protocol</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../IEEEs/802.11.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../IEEEs/802.15.html">802.15: Wireless PAN</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../IEEEs/802.15.html#low-rate-wireless-pan">802.15.4: Low-Rate wireless PAN</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../ITU.html">ITU</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../ITUs/normal.html">常用</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../ITUs/normal.html#id3">电信标准化</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../ITUs/normal.html#id4">研究组</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../ITUs/X%20Series.html">X-Series</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../ITUs/X%20Series.html#directory">DIRECTORY</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ITUs/X%20Series.html#asn-1">ASN.1</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ITUs/X%20Series.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../ITUs/G%20Series.html">G-Series</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../ITUs/G%20Series.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../ITUs/H%20Series.html">H-Series</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../ITUs/H%20Series.html#id2">参考</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../ISO.html">ISO</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../ISOs/normal.html">常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../ISOs/iso10646.html">ISO/IEC 10646: Universal coded character set (UCS)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../ISOs/iso13818.html">ISO/IEC 13818</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../ISOs/iso13818.html#part-1-systems">Part 1: Systems</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ISOs/iso13818.html#part-6-extensions-for-dsm-cc">Part 6: Extensions for DSM-CC</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../GB.html">中标</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../GBs/T28181.html">GB/T28181安全技术视频监控联网系统信息传输, 交换, 控制技术要求</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../pep.html">pep</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../peps/pep-3333.html">pep-3333</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../peps/pep-3333.html#id3">背景与动机</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../peps/pep-3333.html#id4">pep-3333主要变化</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../peps/pep-3333.html#id5">规范概述</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../peps/pep-3333.html#id6">应用程序端</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../peps/pep-3333.html#id7">服务器端</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../peps/pep-3333.html#id8">中间件</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../peps/pep-0440.html">pep-0440</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../peps/pep-0440.html#id2">简介</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../peps/pep-0440.html#id3">基本格式</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../peps/pep-0440.html#id4">版本号的比较</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../peps/pep-0420.html">PEP 420 – Implicit Namespace Packages</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../peps/pep-0420.html#id2">核心要点</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../peps/pep-0420.html#id3">主要优势</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../peps/pep-0420.html#id4">当前现有方案</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../peps/pep-0420.html#pkgutil-style-namespace-packages">pkgutil-style namespace packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../peps/pep-0420.html#pkg-resources-style-namespace-packages">pkg_resources-style namespace packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../peps/pep-0420.html#id5">两方案的不足</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../peps/pep-0420.html#specification">Specification 规范</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../peps/pep-0420.html#id6">说明</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../peps/pep-0420.html#id7">命名空间包和常规包之间的区别</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../peps/pep-0420.html#examples">Examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../peps/pep-0420.html#nested-namespace-packages">Nested namespace packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../peps/pep-0420.html#dynamic-path-computation">Dynamic path computation</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../tmp.html">临时</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../tmps/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95.html">学习记录</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tmps/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95.html#id3">局域网内的服务发现会有什么方法</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tmps/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95.html#mdns">mDNS协议</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tmps/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95.html#id4">命令工具</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tmps/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95.html#id5">组播&amp;广播</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tmps/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95.html#ipv4">IPv4多播转发</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tmps/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95.html#id6">多播功能</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tmps/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95.html#id7">任播</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">新溪-gordon</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../../book.html">书籍</a> &raquo;</li>
        
          <li><a href="../../ai.html">ai</a> &raquo;</li>
        
      <li>动手学深度学习(Dive into Deep Learning)</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../../_sources/books/ais/2024/Dive_into_Deep_Learning.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            <nav id="local-table-of-contents" role="navigation" aria-labelledby="local-table-of-contents-title">
              <h4 id="local-table-of-contents-title">On This Page</h4>
              <ul>
<li><a class="reference internal" href="#">动手学深度学习(Dive into Deep Learning)</a><ul>
<li><a class="reference internal" href="#id2">前言</a><ul>
<li><a class="reference internal" href="#notation">Notation</a><ul>
<li><a class="reference internal" href="#numerical-objects">Numerical Objects:</a></li>
<li><a class="reference internal" href="#set-theory">Set Theory</a></li>
<li><a class="reference internal" href="#functions-and-operators">Functions and Operators</a></li>
<li><a class="reference internal" href="#calculus">Calculus</a></li>
<li><a class="reference internal" href="#probability-and-information-theory">Probability and Information Theory</a></li>
<li><a class="reference internal" href="#id3">额外的</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#part-1-basics-and-preliminaries">Part 1: Basics and Preliminaries</a><ul>
<li><a class="reference internal" href="#introduction">1. Introduction</a><ul>
<li><a class="reference internal" href="#key-components">Key Components</a></li>
<li><a class="reference internal" href="#kinds-of-machine-learning-problems">Kinds of Machine Learning Problems</a><ul>
<li><a class="reference internal" href="#supervised-learning">Supervised Learning</a></li>
<li><a class="reference internal" href="#unsupervised-and-self-supervised-learning">Unsupervised and Self-Supervised Learning</a></li>
<li><a class="reference internal" href="#interacting-with-an-environment">Interacting with an Environment</a></li>
<li><a class="reference internal" href="#reinforcement-learning">Reinforcement Learning</a></li>
</ul>
</li>
<li><a class="reference internal" href="#roots">Roots</a></li>
<li><a class="reference internal" href="#the-road-to-deep-learning">The Road to Deep Learning</a></li>
</ul>
</li>
<li><a class="reference internal" href="#preliminaries">2. Preliminaries</a><ul>
<li><a class="reference internal" href="#data-manipulation">2.1 Data Manipulation</a></li>
<li><a class="reference internal" href="#data-preprocessing">2.2. Data Preprocessing</a></li>
<li><a class="reference internal" href="#linear-algebra">2.3. Linear Algebra(线性代数)</a><ul>
<li><a class="reference internal" href="#hadamard-product">Hadamard product</a></li>
<li><a class="reference internal" href="#dot-product">点积(Dot Product)</a></li>
<li><a class="reference internal" href="#matrixvector-products">矩阵-向量积(Matrix–Vector Products)</a></li>
<li><a class="reference internal" href="#matrixmatrix-multiplication">矩阵-矩阵乘法(Matrix–Matrix Multiplication)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id4">2.4. Calculus(微积分)</a><ul>
<li><a class="reference internal" href="#derivatives-and-differentiation">Derivatives and Differentiation(导数和微分)</a></li>
<li><a class="reference internal" href="#partial-derivatives">Partial Derivatives(偏导数)</a></li>
<li><a class="reference internal" href="#gradients">Gradients(梯度)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#automatic-differentiation">2.5. Automatic Differentiation(自动微分)</a><ul>
<li><a class="reference internal" href="#backward-for-non-scalar-variables">Backward for Non-Scalar Variables</a></li>
<li><a class="reference internal" href="#detaching-computation">Detaching Computation</a></li>
<li><a class="reference internal" href="#gradients-and-python-control-flow">Gradients and Python Control Flow</a></li>
</ul>
</li>
<li><a class="reference internal" href="#probability-and-statistics">2.6 Probability and Statistics</a><ul>
<li><a class="reference internal" href="#id5">基本概率论</a><ul>
<li><a class="reference internal" href="#id6">概率论公理</a></li>
<li><a class="reference internal" href="#id7">随机变量</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id8">处理多个随机变量</a><ul>
<li><a class="reference internal" href="#id9">联合概率</a></li>
<li><a class="reference internal" href="#id10">条件概率</a></li>
<li><a class="reference internal" href="#id11">贝叶斯定理</a></li>
<li><a class="reference internal" href="#id12">边际化</a></li>
<li><a class="reference internal" href="#id13">独立性</a></li>
<li><a class="reference internal" href="#id14">应用示例</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id15">期望和方差</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#linear-neural-networks-for-regression">3. Linear Neural Networks for Regression</a><ul>
<li><a class="reference internal" href="#linear-regression">3.1. Linear Regression</a><ul>
<li><a class="reference internal" href="#basics">Basics</a><ul>
<li><a class="reference internal" href="#model">Model</a></li>
<li><a class="reference internal" href="#loss-function">Loss Function</a></li>
<li><a class="reference internal" href="#analytic-solution">Analytic Solution(解析解)</a></li>
<li><a class="reference internal" href="#minibatch-stochastic-gradient-descent">Minibatch Stochastic Gradient Descent</a></li>
<li><a class="reference internal" href="#predictions">Predictions(预测)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#vectorization-for-speed">Vectorization for Speed</a></li>
<li><a class="reference internal" href="#the-normal-distribution-and-squared-loss">The Normal Distribution and Squared Loss</a></li>
<li><a class="reference internal" href="#linear-regression-as-a-neural-network">Linear Regression as a Neural Network</a></li>
</ul>
</li>
<li><a class="reference internal" href="#object-oriented-design-for-implementation">3.2. Object-Oriented Design for Implementation</a></li>
<li><a class="reference internal" href="#synthetic-regression-data">3.3. Synthetic Regression Data</a></li>
<li><a class="reference internal" href="#linear-regression-implementation-from-scratch">3.4. Linear Regression Implementation from Scratch</a><ul>
<li><a class="reference internal" href="#defining-the-model">3.4.1. Defining the Model</a></li>
<li><a class="reference internal" href="#defining-the-loss-function">3.4.2. Defining the Loss Function</a></li>
<li><a class="reference internal" href="#defining-the-optimization-algorithm">3.4.3. Defining the Optimization Algorithm</a></li>
<li><a class="reference internal" href="#training">3.4.4. Training</a></li>
</ul>
</li>
<li><a class="reference internal" href="#concise-implementation-of-linear-regression">3.5. Concise Implementation of Linear Regression</a><ul>
<li><a class="reference internal" href="#id16">3.5.1. Defining the Model</a></li>
<li><a class="reference internal" href="#id17">3.5.2. Defining the Loss Function</a></li>
<li><a class="reference internal" href="#id18">3.5.3. Defining the Optimization Algorithm</a></li>
<li><a class="reference internal" href="#id19">3.5.4. Training</a></li>
</ul>
</li>
<li><a class="reference internal" href="#generalization">3.6. Generalization</a><ul>
<li><a class="reference internal" href="#training-error-and-generalization-error">3.6.1. Training Error and Generalization Error</a></li>
<li><a class="reference internal" href="#underfitting-or-overfitting">3.6.2. Underfitting or Overfitting?</a></li>
<li><a class="reference internal" href="#model-selection">3.6.3. Model Selection</a></li>
<li><a class="reference internal" href="#summary">3.6.4. Summary</a></li>
</ul>
</li>
<li><a class="reference internal" href="#weight-decay">3.7. Weight Decay</a><ul>
<li><a class="reference internal" href="#norms-and-weight-decay">3.7.1. Norms and Weight Decay</a></li>
<li><a class="reference internal" href="#high-dimensional-linear-regression">3.7.2. High-Dimensional Linear Regression</a></li>
<li><a class="reference internal" href="#implementation-from-scratch">3.7.3. Implementation from Scratch</a><ul>
<li><a class="reference internal" href="#defining-l2-norm-penalty">3.7.3.1. Defining L2 Norm Penalty</a></li>
<li><a class="reference internal" href="#id20">3.7.3.2. Defining the Model</a></li>
<li><a class="reference internal" href="#training-without-regularization">3.7.3.3. Training without Regularization</a></li>
<li><a class="reference internal" href="#using-weight-decay">3.7.3.4. Using Weight Decay</a></li>
</ul>
</li>
<li><a class="reference internal" href="#concise-implementation">3.7.4. Concise Implementation</a></li>
<li><a class="reference internal" href="#id21">3.7.5. Summary</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#linear-neural-networks-for-classification">4. Linear Neural Networks for Classification</a><ul>
<li><a class="reference internal" href="#softmax-regression">4.1. Softmax Regression</a><ul>
<li><a class="reference internal" href="#classification">4.1.1. Classification</a><ul>
<li><a class="reference internal" href="#linear-model">4.1.1.1. Linear Model</a></li>
<li><a class="reference internal" href="#the-softmax">4.1.1.2. The Softmax</a></li>
<li><a class="reference internal" href="#vectorization">4.1.1.3. Vectorization</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id22">4.1.2. Loss Function</a><ul>
<li><a class="reference internal" href="#log-likelihood">4.1.2.1. Log-Likelihood(对数似然)</a></li>
<li><a class="reference internal" href="#softmax-and-cross-entropy-loss">4.1.2.2. Softmax and Cross-Entropy Loss</a><ul>
<li><a class="reference internal" href="#id23">1. 交叉熵损失的推导过程</a></li>
<li><a class="reference internal" href="#id24">2. 梯度推导 (反向传播的核心)</a></li>
<li><a class="reference internal" href="#id25">3. 更一般的情况: 标签分布为概率分布</a></li>
<li><a class="reference internal" href="#id26">4. 交叉熵损失的意义: 信息论解释</a></li>
<li><a class="reference internal" href="#id27">5. 关键信息总结</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#information-theory-basics">4.1.3. Information Theory Basics</a><ul>
<li><a class="reference internal" href="#entropy">4.1.3.1. Entropy(熵)</a></li>
<li><a class="reference internal" href="#surprisal">4.1.3.2. Surprisal(惊讶度)</a><ul>
<li><a class="reference internal" href="#id28">1. 压缩与预测的联系</a></li>
<li><a class="reference internal" href="#id29">2. 预测失败与“惊讶度”</a></li>
<li><a class="reference internal" href="#id30">3. 熵: 期望的惊讶度</a></li>
<li><a class="reference internal" href="#id31">4. 交叉熵: 预测与真实分布的差距</a></li>
<li><a class="reference internal" href="#id32">5. 直观例子</a></li>
</ul>
</li>
<li><a class="reference internal" href="#cross-entropy-revisited">4.1.3.3. Cross-Entropy Revisited</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#the-image-classification-dataset">4.2. The Image Classification Dataset</a></li>
<li><a class="reference internal" href="#the-base-classification-model">4.3. The Base Classification Model</a><ul>
<li><a class="reference internal" href="#the-classifier-class">4.3.1. The Classifier Class</a></li>
<li><a class="reference internal" href="#accuracy">4.3.2. Accuracy</a></li>
</ul>
</li>
<li><a class="reference internal" href="#softmax-regression-implementation-from-scratch">4.4. Softmax Regression Implementation from Scratch</a><ul>
<li><a class="reference internal" href="#id33">4.4.1. The Softmax</a></li>
<li><a class="reference internal" href="#the-model">4.4.2. The Model</a></li>
<li><a class="reference internal" href="#the-cross-entropy-loss">4.4.3. The Cross-Entropy Loss</a></li>
<li><a class="reference internal" href="#id34">4.4.4. Training</a></li>
<li><a class="reference internal" href="#prediction">4.4.5. Prediction</a></li>
</ul>
</li>
<li><a class="reference internal" href="#concise-implementation-of-softmax-regression">4.5. Concise Implementation of Softmax Regression</a><ul>
<li><a class="reference internal" href="#id35">4.5.1. Defining the Model</a></li>
<li><a class="reference internal" href="#softmax-revisited">4.5.2. Softmax Revisited</a></li>
<li><a class="reference internal" href="#id36">4.5.3. Training</a></li>
</ul>
</li>
<li><a class="reference internal" href="#generalization-in-classification">4.6. Generalization in Classification</a><ul>
<li><a class="reference internal" href="#the-test-set">4.6.1. The Test Set</a><ul>
<li><a class="reference internal" href="#empirical-error">1. 经验误差 (Empirical Error)</a></li>
<li><a class="reference internal" href="#population-error">2. 总体误差 (Population Error)</a></li>
<li><a class="reference internal" href="#clt">3. 中心极限定理 (CLT) 和误差收敛速度</a></li>
<li><a class="reference internal" href="#hoeffding">4. Hoeffding 不等式和有限样本误差界</a></li>
</ul>
</li>
<li><a class="reference internal" href="#test-set-reuse">4.6.2. Test Set Reuse</a><ul>
<li><a class="reference internal" href="#id37">核心观点</a></li>
<li><a class="reference internal" href="#id38">1) 假发现率问题</a></li>
<li><a class="reference internal" href="#id39">2) 自适应过拟合</a></li>
<li><a class="reference internal" href="#id40">缓解策略与实践建议</a></li>
</ul>
</li>
<li><a class="reference internal" href="#statistical-learning-theory">4.6.3. Statistical Learning Theory</a><ul>
<li><a class="reference internal" href="#id41">核心观点</a></li>
<li><a class="reference internal" href="#id42">主要问题拆解</a></li>
<li><a class="reference internal" href="#vc">解决思路:一致收敛性与VC维度</a><ul>
<li><a class="reference internal" href="#uniform-convergence">1) 一致收敛性(Uniform Convergence)</a></li>
<li><a class="reference internal" href="#vapnik-chervonenkis-vc">2) Vapnik-Chervonenkis (VC) 维度</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id43">现实意义与应用</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#environment-and-distribution-shift">4.7. Environment and Distribution Shift</a><ul>
<li><a class="reference internal" href="#types-of-distribution-shift">4.7.1. Types of Distribution Shift</a><ul>
<li><a class="reference internal" href="#covariate-shift">4.7.1.1. Covariate Shift</a></li>
<li><a class="reference internal" href="#label-shift">4.7.1.2. Label Shift</a></li>
<li><a class="reference internal" href="#concept-shift">4.7.1.3. Concept Shift</a></li>
</ul>
</li>
<li><a class="reference internal" href="#examples-of-distribution-shift">4.7.2. Examples of Distribution Shift</a><ul>
<li><a class="reference internal" href="#medical-diagnostics">4.7.2.1. Medical Diagnostics</a></li>
<li><a class="reference internal" href="#self-driving-cars">4.7.2.2. Self-Driving Cars</a></li>
<li><a class="reference internal" href="#nonstationary-distributions">4.7.2.3. Nonstationary Distributions</a></li>
</ul>
</li>
<li><a class="reference internal" href="#correction-of-distribution-shift">4.7.3. Correction of Distribution Shift</a><ul>
<li><a class="reference internal" href="#empirical-risk-and-risk">4.7.3.1. Empirical Risk and Risk</a><ul>
<li><a class="reference internal" href="#empirical-risk">1. 经验风险 (Empirical Risk)</a></li>
<li><a class="reference internal" href="#true-risk">2. 真实风险 (True Risk)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#covariate-shift-correction">4.7.3.2. Covariate Shift Correction</a></li>
<li><a class="reference internal" href="#label-shift-correction">4.7.3.3. Label Shift Correction</a></li>
<li><a class="reference internal" href="#concept-shift-correction">4.7.3.4. Concept Shift Correction</a></li>
</ul>
</li>
<li><a class="reference internal" href="#a-taxonomy-of-learning-problems">4.7.4. A Taxonomy of Learning Problems</a><ul>
<li><a class="reference internal" href="#batch-learning">4.7.4.1. Batch Learning</a></li>
<li><a class="reference internal" href="#online-learning">4.7.4.2. Online Learning</a></li>
<li><a class="reference internal" href="#bandits">4.7.4.3. Bandits</a></li>
<li><a class="reference internal" href="#control">4.7.4.4. Control</a></li>
<li><a class="reference internal" href="#id44">4.7.4.5. Reinforcement Learning</a></li>
<li><a class="reference internal" href="#considering-the-environment">4.7.4.6. Considering the Environment</a></li>
<li><a class="reference internal" href="#id45">总结</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#multilayer-perceptrons">5. Multilayer Perceptrons</a><ul>
<li><a class="reference internal" href="#id46">5.1. Multilayer Perceptrons</a><ul>
<li><a class="reference internal" href="#hidden-layers">5.1.1. Hidden Layers</a><ul>
<li><a class="reference internal" href="#limitations-of-linear-models">5.1.1.1. Limitations of Linear Models</a></li>
<li><a class="reference internal" href="#incorporating-hidden-layers">5.1.1.2. Incorporating Hidden Layers</a></li>
<li><a class="reference internal" href="#from-linear-to-nonlinear">5.1.1.3. From Linear to Nonlinear</a></li>
<li><a class="reference internal" href="#universal-approximators">5.1.1.4. Universal Approximators</a></li>
</ul>
</li>
<li><a class="reference internal" href="#activation-functions">5.1.2. Activation Functions</a></li>
</ul>
</li>
<li><a class="reference internal" href="#implementation-of-multilayer-perceptrons">5.2. Implementation of Multilayer Perceptrons</a><ul>
<li><a class="reference internal" href="#id47">5.2.1. Implementation from Scratch</a></li>
<li><a class="reference internal" href="#id48">5.2.2. Concise Implementation</a></li>
</ul>
</li>
<li><a class="reference internal" href="#forward-propagation-backward-propagation-and-computational-graphs">5.3. Forward Propagation, Backward Propagation, and Computational Graphs</a><ul>
<li><a class="reference internal" href="#forward-propagation">5.3.1. Forward Propagation</a><ul>
<li><a class="reference internal" href="#id49">1. 输入与权重矩阵</a></li>
<li><a class="reference internal" href="#id50">2. 激活函数与隐藏层输出</a></li>
<li><a class="reference internal" href="#id51">3. 输出层计算</a></li>
<li><a class="reference internal" href="#id52">4. 计算损失</a></li>
<li><a class="reference internal" href="#id53">5. 正则化项</a></li>
<li><a class="reference internal" href="#id54">6. 目标函数</a></li>
</ul>
</li>
<li><a class="reference internal" href="#computational-graph-of-forward-propagation">5.3.2. Computational Graph of Forward Propagation</a></li>
<li><a class="reference internal" href="#backpropagation">5.3.3. Backpropagation</a><ul>
<li><a class="reference internal" href="#id55">1. 链式法则</a></li>
<li><a class="reference internal" href="#id56">2. 反向传播目标</a></li>
<li><a class="reference internal" href="#id57">3. 逐步计算过程</a></li>
<li><a class="reference internal" href="#id58">小结</a></li>
</ul>
</li>
<li><a class="reference internal" href="#training-neural-networks">5.3.4. Training Neural Networks</a><ul>
<li><a class="reference internal" href="#id59">训练过程的交替进行</a></li>
<li><a class="reference internal" href="#id60">内存占用</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id61">5.3.5. Summary</a></li>
</ul>
</li>
<li><a class="reference internal" href="#numerical-stability-and-initialization">5.4. Numerical Stability and Initialization</a><ul>
<li><a class="reference internal" href="#vanishing-and-exploding-gradients">5.4.1. Vanishing and Exploding Gradients</a><ul>
<li><a class="reference internal" href="#id62">1. 数学背景与直观理解</a></li>
<li><a class="reference internal" href="#vanishing-gradient">2. 梯度消失(Vanishing Gradient)</a></li>
<li><a class="reference internal" href="#exploding-gradient">3. 梯度爆炸(Exploding Gradient)</a></li>
<li><a class="reference internal" href="#breaking-symmetry">4. 对称性破坏问题(Breaking Symmetry)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#parameter-initialization">5.4.2. Parameter Initialization</a><ul>
<li><a class="reference internal" href="#default-initialization">5.4.2.1. Default Initialization</a></li>
<li><a class="reference internal" href="#xavier-initialization">5.4.2.2. Xavier Initialization</a><ul>
<li><a class="reference internal" href="#id63">实操</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#id64">5.4.3. Summary</a></li>
</ul>
</li>
<li><a class="reference internal" href="#generalization-in-deep-learning">5.5. Generalization in Deep Learning</a><ul>
<li><a class="reference internal" href="#revisiting-overfitting-and-regularization">5.5.1. Revisiting Overfitting and Regularization</a><ul>
<li><a class="reference internal" href="#id65">引入背景与传统认知</a></li>
<li><a class="reference internal" href="#id66">深度学习的反常现象</a></li>
<li><a class="reference internal" href="#id67">挑战传统理论</a></li>
<li><a class="reference internal" href="#id68">关键词解析</a></li>
</ul>
</li>
<li><a class="reference internal" href="#inspiration-from-nonparametrics">5.5.2. Inspiration from Nonparametrics</a><ul>
<li><a class="reference internal" href="#id69">深度学习的参数化与非参数化对比</a></li>
<li><a class="reference internal" href="#id70">非参数模型的定义</a></li>
<li><a class="reference internal" href="#id71">度量函数和归纳偏置</a></li>
<li><a class="reference internal" href="#id72">神经网络的“非参数性”</a></li>
<li><a class="reference internal" href="#id73">神经切线核理论</a></li>
<li><a class="reference internal" href="#id74">结论</a></li>
</ul>
</li>
<li><a class="reference internal" href="#early-stopping">5.5.3. Early Stopping</a><ul>
<li><a class="reference internal" href="#id75">早停法的动机与背景</a></li>
<li><a class="reference internal" href="#id76">早停法的机制</a></li>
<li><a class="reference internal" href="#id77">早停法的优点</a></li>
<li><a class="reference internal" href="#id78">适用场景</a></li>
<li><a class="reference internal" href="#id79">关键词解析</a></li>
<li><a class="reference internal" href="#id80">结论</a></li>
</ul>
</li>
<li><a class="reference internal" href="#classical-regularization-methods-for-deep-networks">5.5.4. Classical Regularization Methods for Deep Networks</a><ul>
<li><a class="reference internal" href="#id81">经典正则化方法的回顾</a></li>
<li><a class="reference internal" href="#id82">深度学习中的应用与挑战</a></li>
<li><a class="reference internal" href="#id83">对正则化方法的新解释</a></li>
<li><a class="reference internal" href="#id84">正则化方法的扩展与创新</a></li>
<li><a class="reference internal" href="#id85">关键词解析</a></li>
<li><a class="reference internal" href="#id86">结论</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#dropout">5.6. Dropout</a><ul>
<li><a class="reference internal" href="#dropout-in-practice">5.6.1. Dropout in Practice</a></li>
<li><a class="reference internal" href="#id87">5.6.2. Implementation from Scratch</a><ul>
<li><a class="reference internal" href="#id88">5.6.2.1. Defining the Model</a></li>
<li><a class="reference internal" href="#id89">5.6.2.2. Training</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id90">5.6.3. Concise Implementation</a></li>
<li><a class="reference internal" href="#id91">5.6.4. Summary</a></li>
</ul>
</li>
<li><a class="reference internal" href="#predicting-house-prices-on-kaggle">5.7. Predicting House Prices on Kaggle</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#part-2-modern-deep-learning-techniques">Part 2: Modern Deep Learning Techniques</a><ul>
<li><a class="reference internal" href="#builders-guide">6. Builders’ Guide</a><ul>
<li><a class="reference internal" href="#layers-and-modules">6.1. Layers and Modules</a></li>
<li><a class="reference internal" href="#parameter-management">6.2. Parameter Management</a><ul>
<li><a class="reference internal" href="#parameter-access">6.2.1. Parameter Access</a><ul>
<li><a class="reference internal" href="#targeted-parameters">6.2.1.1. Targeted Parameters</a></li>
<li><a class="reference internal" href="#all-parameters-at-once">6.2.1.2. All Parameters at Once</a></li>
</ul>
</li>
<li><a class="reference internal" href="#tied-parameters">6.2.2. Tied Parameters</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id92">6.3. Parameter Initialization</a><ul>
<li><a class="reference internal" href="#built-in-initialization">6.3.1. Built-in Initialization</a></li>
</ul>
</li>
<li><a class="reference internal" href="#lazy-initialization">6.4. Lazy Initialization</a></li>
<li><a class="reference internal" href="#custom-layers">6.5. Custom Layers</a><ul>
<li><a class="reference internal" href="#layers-without-parameters">6.5.1. Layers without Parameters</a></li>
<li><a class="reference internal" href="#layers-with-parameters">6.5.2. Layers with Parameters</a></li>
</ul>
</li>
<li><a class="reference internal" href="#file-i-o">6.6. File I/O</a><ul>
<li><a class="reference internal" href="#loading-and-saving-tensors">6.6.1. Loading and Saving Tensors</a></li>
<li><a class="reference internal" href="#loading-and-saving-model-parameters">6.6.2. Loading and Saving Model Parameters</a></li>
</ul>
</li>
<li><a class="reference internal" href="#gpus">6.7. GPUs</a><ul>
<li><a class="reference internal" href="#computing-devices">6.7.1. Computing Devices</a></li>
<li><a class="reference internal" href="#tensors-and-gpus">6.7.2. Tensors and GPUs</a><ul>
<li><a class="reference internal" href="#storage-on-the-gpu">6.7.2.1. Storage on the GPU</a></li>
<li><a class="reference internal" href="#copying">6.7.2.2. Copying</a></li>
</ul>
</li>
<li><a class="reference internal" href="#neural-networks-and-gpus">6.7.3. Neural Networks and GPUs</a></li>
<li><a class="reference internal" href="#id93">6.7.4. Summary</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#convolutional-neural-networks">7. Convolutional Neural Networks</a><ul>
<li><a class="reference internal" href="#from-fully-connected-layers-to-convolutions">7.1. From Fully Connected Layers to Convolutions</a><ul>
<li><a class="reference internal" href="#invariance">7.1.1. Invariance(不变性)</a><ul>
<li><a class="reference internal" href="#id94">定义</a></li>
<li><a class="reference internal" href="#cnn">CNN 如何实现这种不变性</a></li>
</ul>
</li>
<li><a class="reference internal" href="#constraining-the-mlp">7.1.2. Constraining the MLP</a><ul>
<li><a class="reference internal" href="#id95">整体</a><ul>
<li><a class="reference internal" href="#mlp">理解 MLP 对二维图像的建模</a></li>
<li><a class="reference internal" href="#id96">权重矩阵到权重张量的切换</a></li>
<li><a class="reference internal" href="#id97">卷积的引入与参数重索引</a></li>
<li><a class="reference internal" href="#id98">参数量爆炸问题</a></li>
<li><a class="reference internal" href="#id99">问题的根源与解决思路</a></li>
<li><a class="reference internal" href="#id100">小结</a></li>
</ul>
</li>
<li><a class="reference internal" href="#translation-invariance">7.1.2.1. Translation Invariance</a><ul>
<li><a class="reference internal" href="#id101">数学解释</a></li>
</ul>
</li>
<li><a class="reference internal" href="#locality">7.1.2.2. Locality</a></li>
<li><a class="reference internal" href="#id102">总结与启示</a></li>
<li><a class="reference internal" href="#id103">CNN的优势</a></li>
</ul>
</li>
<li><a class="reference internal" href="#convolutions">7.1.3. Convolutions</a><ul>
<li><a class="reference internal" href="#id104">定义</a></li>
<li><a class="reference internal" href="#id105">数学定义</a><ul>
<li><a class="reference internal" href="#id106">连续卷积公式</a></li>
<li><a class="reference internal" href="#id107">离散卷积公式(一维)</a></li>
<li><a class="reference internal" href="#id108">二维卷积公式</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id109">卷积和交叉相关的区别</a></li>
<li><a class="reference internal" href="#id110">卷积的实际意义</a></li>
</ul>
</li>
<li><a class="reference internal" href="#channels">7.1.4. Channels</a><ul>
<li><a class="reference internal" href="#id111">1. 图像的多通道特性</a></li>
<li><a class="reference internal" href="#id112">2. 为什么需要多通道卷积</a></li>
<li><a class="reference internal" href="#id113">3. 数学定义</a></li>
<li><a class="reference internal" href="#id114">4. 直观理解</a></li>
<li><a class="reference internal" href="#feature-maps">5. 隐藏表示和特征图 (Feature Maps)</a></li>
<li><a class="reference internal" href="#id115">6. 多层卷积的特征提取机制</a></li>
<li><a class="reference internal" href="#id116">7. 通道的现实意义</a></li>
<li><a class="reference internal" href="#id117">8. 关键点总结</a></li>
</ul>
</li>
<li><a class="reference internal" href="#summary-and-discussion">7.1.5. Summary and Discussion</a><ul>
<li><a class="reference internal" href="#id118">关键点</a></li>
<li><a class="reference internal" href="#id119">理解</a></li>
<li><a class="reference internal" href="#id120">降低复杂度与参数数量</a></li>
<li><a class="reference internal" href="#id121">引入通道 (Channels) 增强模型能力</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#convolutions-for-images">7.2. Convolutions for Images</a><ul>
<li><a class="reference internal" href="#the-cross-correlation-operation">7.2.1. The Cross-Correlation Operation</a></li>
<li><a class="reference internal" href="#convolutional-layers">7.2.2. Convolutional Layers</a></li>
<li><a class="reference internal" href="#object-edge-detection-in-images">7.2.3. Object Edge Detection in Images</a></li>
<li><a class="reference internal" href="#learning-a-kernel">7.2.4. Learning a Kernel</a></li>
<li><a class="reference internal" href="#cross-correlation-and-convolution">7.2.5. Cross-Correlation and Convolution</a></li>
<li><a class="reference internal" href="#feature-map-and-receptive-field">7.2.6. Feature Map and Receptive Field</a></li>
<li><a class="reference internal" href="#id122">7.2.7. Summary</a></li>
</ul>
</li>
<li><a class="reference internal" href="#padding-and-stride">7.3. Padding and Stride</a><ul>
<li><a class="reference internal" href="#padding">7.3.1. Padding</a></li>
<li><a class="reference internal" href="#stride">7.3.2. Stride</a></li>
<li><a class="reference internal" href="#id123">计算输出尺寸</a></li>
<li><a class="reference internal" href="#id124">总结</a></li>
</ul>
</li>
<li><a class="reference internal" href="#multiple-input-and-multiple-output-channels">7.4. Multiple Input and Multiple Output Channels</a><ul>
<li><a class="reference internal" href="#multiple-input-channels">7.4.1. Multiple Input Channels</a><ul>
<li><a class="reference internal" href="#id125">核心要点</a></li>
</ul>
</li>
<li><a class="reference internal" href="#multiple-output-channels">7.4.2. Multiple Output Channels</a></li>
<li><a class="reference internal" href="#x1-convolutional-layer">7.4.3. 1x1 Convolutional Layer</a></li>
<li><a class="reference internal" href="#discussion">7.4.4. Discussion</a></li>
</ul>
</li>
<li><a class="reference internal" href="#pooling">7.5. Pooling</a><ul>
<li><a class="reference internal" href="#maximum-pooling-and-average-pooling">7.5.1. Maximum Pooling and Average Pooling</a></li>
<li><a class="reference internal" href="#id126">7.5.2. Padding and Stride</a></li>
<li><a class="reference internal" href="#multiple-channels">7.5.3. Multiple Channels</a></li>
<li><a class="reference internal" href="#id127">7.5.4. Summary</a></li>
</ul>
</li>
<li><a class="reference internal" href="#convolutional-neural-networks-lenet">7.6. Convolutional Neural Networks (LeNet)</a><ul>
<li><a class="reference internal" href="#lenet">7.6.1. LeNet</a></li>
<li><a class="reference internal" href="#id128">7.6.2. Training</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#modern-convolutional-neural-networks">8. Modern Convolutional Neural Networks</a><ul>
<li><a class="reference internal" href="#deep-convolutional-neural-networks-alexnet">8.1. Deep Convolutional Neural Networks (AlexNet)</a><ul>
<li><a class="reference internal" href="#representation-learning">8.1.1. Representation Learning</a></li>
<li><a class="reference internal" href="#alexnet">8.1.2. AlexNet</a></li>
<li><a class="reference internal" href="#id129">8.1.3. Training</a></li>
</ul>
</li>
<li><a class="reference internal" href="#networks-using-blocks-vgg">8.2. Networks Using Blocks (VGG)</a><ul>
<li><a class="reference internal" href="#id130">背景和概念演进</a></li>
<li><a class="reference internal" href="#vgg">VGG 的核心设计</a><ul>
<li><a class="reference internal" href="#vgg-blocks">8.2.1. VGG Blocks</a></li>
<li><a class="reference internal" href="#vgg-network">8.2.2. VGG Network</a></li>
<li><a class="reference internal" href="#id131">8.2.3. Training</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id132">意义和扩展</a></li>
<li><a class="reference internal" href="#id133">总结</a></li>
</ul>
</li>
<li><a class="reference internal" href="#network-in-network-nin">8.3. Network in Network (NiN)</a><ul>
<li><a class="reference internal" href="#nin-blocks">8.3.1. NiN Blocks</a></li>
<li><a class="reference internal" href="#nin-model">8.3.2. NiN Model</a></li>
<li><a class="reference internal" href="#id134">8.3.3. Training</a></li>
<li><a class="reference internal" href="#id135">8.3.4. Summary</a></li>
</ul>
</li>
<li><a class="reference internal" href="#multi-branch-networks-googlenet">8.4. Multi-Branch Networks (GoogLeNet)</a><ul>
<li><a class="reference internal" href="#id136">设计概述</a></li>
<li><a class="reference internal" href="#inception-blocks">8.4.1. Inception Blocks</a></li>
<li><a class="reference internal" href="#googlenet-model">8.4.2. GoogLeNet Model</a></li>
<li><a class="reference internal" href="#id137">8.4.3. Training</a></li>
<li><a class="reference internal" href="#id138">8.4.4. Discussion</a></li>
</ul>
</li>
<li><a class="reference internal" href="#batch-normalization">8.5. Batch Normalization</a><ul>
<li><a class="reference internal" href="#training-deep-networks">8.5.1. Training Deep Networks</a></li>
<li><a class="reference internal" href="#batch-normalization-layers">8.5.2. Batch Normalization Layers</a><ul>
<li><a class="reference internal" href="#fully-connected-layers">8.5.2.1. Fully Connected Layers</a></li>
<li><a class="reference internal" href="#id139">8.5.2.2. Convolutional Layers</a></li>
<li><a class="reference internal" href="#layer-normalization">8.5.2.3. Layer Normalization</a></li>
<li><a class="reference internal" href="#batch-normalization-during-prediction">8.5.2.4. Batch Normalization During Prediction</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id140">8.5.3. Implementation from Scratch</a></li>
<li><a class="reference internal" href="#lenet-with-batch-normalization">8.5.4. LeNet with Batch Normalization</a></li>
<li><a class="reference internal" href="#id141">8.5.5. Concise Implementation</a></li>
</ul>
</li>
<li><a class="reference internal" href="#residual-networks-resnet-and-resnext">8.6. Residual Networks (ResNet) and ResNeXt</a></li>
<li><a class="reference internal" href="#densely-connected-networks-densenet">8.7. Densely Connected Networks (DenseNet)</a><ul>
<li><a class="reference internal" href="#id142">核心概念</a></li>
<li><a class="reference internal" href="#id143">关键组成部分</a></li>
<li><a class="reference internal" href="#densenet">DenseNet 的优点</a></li>
</ul>
</li>
<li><a class="reference internal" href="#designing-convolution-network-architectures">8.8. Designing Convolution Network Architectures</a><ul>
<li><a class="reference internal" href="#id144">传统架构设计的直觉性</a></li>
<li><a class="reference internal" href="#nas">神经架构搜索(NAS)</a></li>
<li><a class="reference internal" href="#regnet">RegNet 与设计空间优化</a></li>
<li><a class="reference internal" href="#anynet">AnyNet 设计空间</a></li>
<li><a class="reference internal" href="#id145">分布优化与假设</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#recurrent-neural-networks">9. Recurrent Neural Networks</a><ul>
<li><a class="reference internal" href="#working-with-sequences">9.1. Working with Sequences</a><ul>
<li><a class="reference internal" href="#id146">1. 序列数据的特点</a></li>
<li><a class="reference internal" href="#id147">2. 序列建模的目标</a></li>
<li><a class="reference internal" href="#id148">3. 序列建模的基本方法</a><ul>
<li><a class="reference internal" href="#autoregressive-models">9.1.1. Autoregressive Models</a></li>
<li><a class="reference internal" href="#sequence-models-markov-models">9.1.2. Sequence Models(Markov Models)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id149">4. 语言模型与序列模型</a><ul>
<li><a class="reference internal" href="#language-model">语言模型 (Language Model)</a></li>
<li><a class="reference internal" href="#id150">解码顺序</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#id151">5. 实际应用</a></li>
<li><a class="reference internal" href="#converting-raw-text-into-sequence-data">9.2. Converting Raw Text into Sequence Data</a><ul>
<li><a class="reference internal" href="#reading-the-dataset">9.2.1. Reading the Dataset</a></li>
<li><a class="reference internal" href="#tokenization">9.2.2. Tokenization</a></li>
<li><a class="reference internal" href="#vocabulary">9.2.3. Vocabulary</a></li>
<li><a class="reference internal" href="#putting-it-all-together">9.2.4. Putting It All Together</a></li>
<li><a class="reference internal" href="#exploratory-language-statistics">9.2.5. Exploratory Language Statistics</a></li>
<li><a class="reference internal" href="#id152">9.2.6. Summary</a></li>
</ul>
</li>
<li><a class="reference internal" href="#language-models">9.3. Language Models</a><ul>
<li><a class="reference internal" href="#learning-language-models">9.3.1. Learning Language Models</a><ul>
<li><a class="reference internal" href="#markov-models-and-n-grams">9.3.1.1. Markov Models and n-grams</a></li>
<li><a class="reference internal" href="#word-frequency">9.3.1.2. Word Frequency</a></li>
<li><a class="reference internal" href="#laplace-smoothing">9.3.1.3. Laplace Smoothing</a></li>
</ul>
</li>
<li><a class="reference internal" href="#perplexity">9.3.2. Perplexity</a></li>
<li><a class="reference internal" href="#partitioning-sequences">9.3.3. Partitioning Sequences</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id153">9.4. Recurrent Neural Networks</a><ul>
<li><a class="reference internal" href="#id154">1. 语言模型的局限性与改进</a></li>
<li><a class="reference internal" href="#id155">2. 隐藏状态的定义与作用</a></li>
<li><a class="reference internal" href="#rnn">3. RNN的计算逻辑</a></li>
<li><a class="reference internal" href="#rnnmlp">4. RNN与MLP的区别</a></li>
<li><a class="reference internal" href="#id156">5. RNN的应用</a></li>
<li><a class="reference internal" href="#id157">6. RNN的优点与局限</a></li>
<li><a class="reference internal" href="#id158">总结</a></li>
</ul>
</li>
<li><a class="reference internal" href="#recurrent-neural-network-implementation-from-scratch">9.5. Recurrent Neural Network Implementation from Scratch</a><ul>
<li><a class="reference internal" href="#rnn-model">9.5.1. RNN Model</a></li>
<li><a class="reference internal" href="#rnn-based-language-model">9.5.2. RNN-Based Language Model</a><ul>
<li><a class="reference internal" href="#one-hot-encoding">9.5.2.1. One-Hot Encoding</a></li>
<li><a class="reference internal" href="#transforming-rnn-outputs">9.5.2.2. Transforming RNN Outputs</a></li>
</ul>
</li>
<li><a class="reference internal" href="#gradient-clipping">9.5.3. Gradient Clipping</a></li>
<li><a class="reference internal" href="#id159">9.5.4. Training</a></li>
<li><a class="reference internal" href="#decoding">9.5.5. Decoding</a></li>
</ul>
</li>
<li><a class="reference internal" href="#concise-implementation-of-recurrent-neural-networks">9.6. Concise Implementation of Recurrent Neural Networks</a><ul>
<li><a class="reference internal" href="#id160">9.6.1. Defining the Model</a></li>
<li><a class="reference internal" href="#training-and-predicting">9.6.2. Training and Predicting</a></li>
</ul>
</li>
<li><a class="reference internal" href="#backpropagation-through-time">9.7. Backpropagation Through Time</a><ul>
<li><a class="reference internal" href="#id161">应对梯度问题的方法</a></li>
<li><a class="reference internal" href="#id162">数学分析</a></li>
<li><a class="reference internal" href="#id163">总结与实践意义</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#modern-recurrent-neural-networks">10. Modern Recurrent Neural Networks</a><ul>
<li><a class="reference internal" href="#long-short-term-memory-lstm">10.1. Long Short-Term Memory (LSTM)</a><ul>
<li><a class="reference internal" href="#gated-memory-cell">10.1.1. Gated Memory Cell</a><ul>
<li><a class="reference internal" href="#gated-hidden-state">10.1.1.1. Gated Hidden State</a></li>
<li><a class="reference internal" href="#input-gate-forget-gate-and-output-gate">10.1.1.2. Input Gate, Forget Gate, and Output Gate</a></li>
<li><a class="reference internal" href="#input-node">10.1.1.3. Input Node</a></li>
<li><a class="reference internal" href="#memory-cell-internal-state">10.1.1.4. Memory Cell Internal State</a></li>
<li><a class="reference internal" href="#hidden-state">10.1.1.5. Hidden State</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id164">10.1.2. Implementation from Scratch</a><ul>
<li><a class="reference internal" href="#initializing-model-parameters">10.1.2.1. Initializing Model Parameters</a></li>
<li><a class="reference internal" href="#training-and-prediction">10.1.2.2. Training and Prediction</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id165">10.1.3. Concise Implementation</a></li>
<li><a class="reference internal" href="#id166">10.1.4. Summary</a></li>
</ul>
</li>
<li><a class="reference internal" href="#gated-recurrent-units-gru">10.2. Gated Recurrent Units (GRU)</a><ul>
<li><a class="reference internal" href="#reset-gate-and-update-gate">10.2.1. Reset Gate and Update Gate</a></li>
<li><a class="reference internal" href="#candidate-hidden-state">10.2.2. Candidate Hidden State</a></li>
<li><a class="reference internal" href="#id167">10.2.3. Hidden State</a></li>
<li><a class="reference internal" href="#id168">10.2.4. Implementation from Scratch</a><ul>
<li><a class="reference internal" href="#id169">10.2.4.1. Initializing Model Parameters</a></li>
<li><a class="reference internal" href="#id170">10.2.4.2. Defining the Model</a></li>
<li><a class="reference internal" href="#id171">10.2.4.3. Training</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id172">10.2.5. Concise Implementation</a></li>
<li><a class="reference internal" href="#id173">10.2.6. Summary</a></li>
</ul>
</li>
<li><a class="reference internal" href="#deep-recurrent-neural-networks">10.3. Deep Recurrent Neural Networks</a><ul>
<li><a class="reference internal" href="#id174">10.3.1. Implementation from Scratch</a></li>
<li><a class="reference internal" href="#id175">10.3.2. Concise Implementation</a></li>
<li><a class="reference internal" href="#id176">10.3.3. Summary</a></li>
</ul>
</li>
<li><a class="reference internal" href="#bidirectional-recurrent-neural-networks">10.4. Bidirectional Recurrent Neural Networks</a><ul>
<li><a class="reference internal" href="#id177">10.4.1. Implementation from Scratch</a></li>
<li><a class="reference internal" href="#id178">10.4.2. Concise Implementation</a></li>
<li><a class="reference internal" href="#id179">10.4.3. Summary</a></li>
</ul>
</li>
<li><a class="reference internal" href="#machine-translation-and-the-dataset">10.5. Machine Translation and the Dataset</a><ul>
<li><a class="reference internal" href="#downloading-and-preprocessing-the-dataset">10.5.1. Downloading and Preprocessing the Dataset</a></li>
<li><a class="reference internal" href="#id180">10.5.2. Tokenization</a></li>
<li><a class="reference internal" href="#loading-sequences-of-fixed-length">10.5.3. Loading Sequences of Fixed Length</a></li>
<li><a class="reference internal" href="#id181">10.5.4. Reading the Dataset</a></li>
<li><a class="reference internal" href="#id182">10.5.5. Summary</a></li>
</ul>
</li>
<li><a class="reference internal" href="#the-encoderdecoder-architecture">10.6. The Encoder–Decoder Architecture</a><ul>
<li><a class="reference internal" href="#encoder">10.6.1. Encoder</a></li>
<li><a class="reference internal" href="#decoder">10.6.2. Decoder</a></li>
<li><a class="reference internal" href="#putting-the-encoder-and-decoder-together">10.6.3. Putting the Encoder and Decoder Together</a></li>
<li><a class="reference internal" href="#id183">10.6.4. Summary</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sequence-to-sequence-learning-for-machine-translation">10.7. Sequence-to-Sequence Learning for Machine Translation</a><ul>
<li><a class="reference internal" href="#teacher-forcing">10.7.1. Teacher Forcing</a></li>
<li><a class="reference internal" href="#id184">10.7.2. Encoder</a></li>
<li><a class="reference internal" href="#id185">10.7.3. Decoder</a></li>
<li><a class="reference internal" href="#encoderdecoder-for-sequence-to-sequence-learning">10.7.4. Encoder–Decoder for Sequence-to-Sequence Learning</a></li>
<li><a class="reference internal" href="#loss-function-with-masking">10.7.5. Loss Function with Masking</a></li>
<li><a class="reference internal" href="#id186">10.7.6. Training</a></li>
<li><a class="reference internal" href="#id187">10.7.7. Prediction</a></li>
<li><a class="reference internal" href="#evaluation-of-predicted-sequences">10.7.8. Evaluation of Predicted Sequences</a></li>
</ul>
</li>
<li><a class="reference internal" href="#beam-search">10.8. Beam Search</a><ul>
<li><a class="reference internal" href="#greedy-search">10.8.1. Greedy Search</a></li>
<li><a class="reference internal" href="#exhaustive-search">10.8.2. Exhaustive Search</a></li>
<li><a class="reference internal" href="#id188">10.8.3. Beam Search</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#attention-mechanisms-and-transformers">11. Attention Mechanisms and Transformers</a><ul>
<li><a class="reference internal" href="#queries-keys-and-values">11.1. Queries, Keys, and Values</a><ul>
<li><a class="reference internal" href="#visualization">11.1.1. Visualization</a></li>
<li><a class="reference internal" href="#id189">11.1.2. Summary</a></li>
</ul>
</li>
<li><a class="reference internal" href="#attention-pooling-by-similarity">11.2. Attention Pooling by Similarity</a><ul>
<li><a class="reference internal" href="#fromgpt">核心点-fromGPT</a><ul>
<li><a class="reference internal" href="#id190">核心概念</a></li>
<li><a class="reference internal" href="#id191">关键见解</a></li>
<li><a class="reference internal" href="#id192">关键总结</a></li>
<li><a class="reference internal" href="#id193">为什么重要</a></li>
</ul>
</li>
<li><a class="reference internal" href="#kernels-and-data">11.2.1. Kernels and Data</a></li>
<li><a class="reference internal" href="#attention-pooling-via-nadarayawatson-regression">11.2.2. Attention Pooling via Nadaraya–Watson Regression</a></li>
<li><a class="reference internal" href="#adapting-attention-pooling">11.2.3. Adapting Attention Pooling</a></li>
<li><a class="reference internal" href="#id194">11.2.4. Summary</a></li>
</ul>
</li>
<li><a class="reference internal" href="#attention-scoring-functions">11.3. Attention Scoring Functions</a><ul>
<li><a class="reference internal" href="#id195">核心点-fromGPT</a></li>
<li><a class="reference internal" href="#dot-product-attention">11.3.1. Dot Product Attention</a></li>
<li><a class="reference internal" href="#convenience-functions">11.3.2. Convenience Functions</a><ul>
<li><a class="reference internal" href="#masked-softmax-operation">11.3.2.1. Masked Softmax Operation</a></li>
<li><a class="reference internal" href="#batch-matrix-multiplication">11.3.2.2. Batch Matrix Multiplication</a></li>
</ul>
</li>
<li><a class="reference internal" href="#scaled-dot-product-attention">11.3.3. Scaled Dot Product Attention</a></li>
<li><a class="reference internal" href="#additive-attention">11.3.4. Additive Attention</a></li>
</ul>
</li>
<li><a class="reference internal" href="#the-bahdanau-attention-mechanism">11.4. The Bahdanau Attention Mechanism</a><ul>
<li><a class="reference internal" href="#id196">核心点-fromGPT</a><ul>
<li><a class="reference internal" href="#id197">关键点分析</a></li>
<li><a class="reference internal" href="#id198">关键概念</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id199">11.4.1. Model</a></li>
<li><a class="reference internal" href="#defining-the-decoder-with-attention">11.4.2. Defining the Decoder with Attention</a></li>
<li><a class="reference internal" href="#id200">11.4.3. Training</a></li>
<li><a class="reference internal" href="#id201">11.4.4. Summary</a></li>
</ul>
</li>
<li><a class="reference internal" href="#multi-head-attention">11.5. Multi-Head Attention</a><ul>
<li><a class="reference internal" href="#id202">核心点-fromGPT</a><ul>
<li><a class="reference internal" href="#id203">关键点分析</a></li>
<li><a class="reference internal" href="#id204">关键概念</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id205">11.5.1. Model</a></li>
<li><a class="reference internal" href="#implementation">11.5.2. Implementation</a></li>
<li><a class="reference internal" href="#id206">11.5.3. Summary</a></li>
</ul>
</li>
<li><a class="reference internal" href="#self-attention-and-positional-encoding">11.6. Self-Attention and Positional Encoding</a><ul>
<li><a class="reference internal" href="#self-attention">11.6.1. Self-Attention</a></li>
<li><a class="reference internal" href="#comparing-cnns-rnns-and-self-attention">11.6.2. Comparing CNNs, RNNs, and Self-Attention</a></li>
<li><a class="reference internal" href="#positional-encoding">11.6.3. Positional Encoding</a><ul>
<li><a class="reference internal" href="#absolute-positional-information">11.6.3.1. Absolute Positional Information</a></li>
<li><a class="reference internal" href="#relative-positional-information">11.6.3.2. Relative Positional Information</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id207">11.6.4. Summary</a></li>
</ul>
</li>
<li><a class="reference internal" href="#the-transformer-architecture">11.7. The Transformer Architecture</a><ul>
<li><a class="reference internal" href="#id208">11.7.1. Model</a></li>
<li><a class="reference internal" href="#positionwise-feed-forward-networks">11.7.2. Positionwise Feed-Forward Networks</a></li>
<li><a class="reference internal" href="#residual-connection-and-layer-normalization">11.7.3. Residual Connection and Layer Normalization</a></li>
<li><a class="reference internal" href="#id209">11.7.4. Encoder</a></li>
<li><a class="reference internal" href="#id210">11.7.5. Decoder</a></li>
<li><a class="reference internal" href="#id211">11.7.6. Training</a></li>
<li><a class="reference internal" href="#id212">11.7.7. Summary</a></li>
</ul>
</li>
<li><a class="reference internal" href="#transformers-for-vision">11.8. Transformers for Vision</a></li>
<li><a class="reference internal" href="#large-scale-pretraining-with-transformers">11.9. Large-Scale Pretraining with Transformers</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#part-3-scalability-efficiency-and-applications">Part 3: Scalability, Efficiency, and Applications</a></li>
</ul>
</li>
</ul>

            </nav>
  <table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference external" href="/index.html">主页</a></p></td>
<td><p><a class="reference internal" href="../../../genindex.html"><span class="std std-ref">索引</span></a></p></td>
<td><p><a class="reference internal" href="../../../py-modindex.html"><span class="std std-ref">模块索引</span></a></p></td>
<td><p><a class="reference internal" href="../../../search.html"><span class="std std-ref">搜索页面</span></a></p></td>
</tr>
</tbody>
</table>
<section id="dive-into-deep-learning">
<h1>动手学深度学习(Dive into Deep Learning)<a class="headerlink" href="#dive-into-deep-learning" title="此标题的永久链接">¶</a></h1>
<ul class="simple">
<li><p>英文版: <a class="reference external" href="https://d2l.ai/">https://d2l.ai/</a></p></li>
<li><p>GitHub开源地址: <a class="reference external" href="https://github.com/d2l-ai/d2l-en">https://github.com/d2l-ai/d2l-en</a></p></li>
<li><p>中文版: <a class="reference external" href="https://zh.d2l.ai/">https://zh.d2l.ai/</a></p></li>
<li><p>GitHub开源地址: <a class="reference external" href="https://github.com/d2l-ai/d2l-zh">https://github.com/d2l-ai/d2l-zh</a></p></li>
<li><p>发布于2021年(大模型真正兴起前)</p></li>
</ul>
<section id="id2">
<h2>前言<a class="headerlink" href="#id2" title="此标题的永久链接">¶</a></h2>
<ul class="simple">
<li><dl class="simple">
<dt>第 1 部分：基础知识和预备知识。</dt><dd><ul>
<li><p>第 1 节 是深度学习的简介。</p></li>
<li><p>第 2 节，我们将快速带您了解实践深度学习所需的先决条件，例如如何存储和操作数据，以及如何应用基于线性代数、微积分和概率的基本概念的各种数值运算。</p></li>
<li><p>第 3 节到第 5 节涵盖深度学习中最基本的概念和技术，包括回归和分类；线性模型；多层感知器；以及过度拟合和正则化。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>第 2 部分：现代深度学习技术。</dt><dd><ul>
<li><p>第 6 节描述了关键的计算深度学习系统的组成部分，并为我们的更复杂模型的后续实现。</p></li>
<li><p>第 7 条和第 8 条存在 卷积神经网络 (CNN) 是构成 大多数现代计算机视觉系统的支柱。</p></li>
<li><p>第 9 节和第 10 节介绍 循环神经网络 (RNN)，利用顺序模型 数据中的（例如，时间）结构，通常用于自然语言处理和时间序列预测。</p></li>
<li><p>第 11 节，我们描述了一类相对较新的模型，基于所谓的注意力机制，它已经取代 RNN 成为大多数自然语言处理任务的主导架构。这些部分将带您快速了解深度学习从业者广泛使用的最强大、最通用的工具。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>第 3 部分：可扩展性、效率和应用程序。</dt><dd><ul>
<li><p>在第 12 章中，我们讨论了几种用于训练深度学习模型的常见优化算法。</p></li>
<li><p>在第 13 章中，我们研究了影响深度学习代码计算性能的几个关键因素。</p></li>
<li><p>在第 14 章中，我们将说明深度学习在计算机视觉中的主要应用。</p></li>
<li><p>在第 15 章和第 16 章中，我们演示了如何预训练语言表示模型并将其应用于自然语言处理任务。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<section id="notation">
<h3>Notation<a class="headerlink" href="#notation" title="此标题的永久链接">¶</a></h3>
<section id="numerical-objects">
<h4>Numerical Objects:<a class="headerlink" href="#numerical-objects" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>x: a scalar</p></li>
<li><p><strong>x</strong>: a vector</p></li>
<li><p><strong>X</strong>: a matrix</p></li>
<li><p>X: a general tensor</p></li>
<li><p><strong>I</strong>: the identity matrix (of some given dimension), i.e., a square matrix with 1 on all diagonal entries and 0 on all off-diagonals</p></li>
<li><p><span class="math notranslate nohighlight">\(x_i, [x]_i\)</span>, : the <span class="math notranslate nohighlight">\(i^{th}\)</span> element of vector</p></li>
<li><p><span class="math notranslate nohighlight">\(x_{ij}, x_{i,j}, [X]_{ij}, [X]_{i,j}\)</span>: the element of matrix <strong>X</strong> at row i and column j.</p></li>
</ul>
</section>
<section id="set-theory">
<h4>Set Theory<a class="headerlink" href="#set-theory" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>X: a set</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbb{Z}\)</span>  : the set of integers</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbb{Z}^{+}\)</span> : the set of positive integers</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbb{R}\)</span>  : the set of real numbers</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbb{R}^{n}\)</span>  : the set of  n-dimensional vectors of real numbers</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbb{R}^{a \times b}\)</span>  : The set of matrices of real numbers with  a  rows and  b  columns</p></li>
<li><p><span class="math notranslate nohighlight">\(|\mathcal{X}|\)</span>  : cardinality (number of elements) of set  <span class="math notranslate nohighlight">\(\mathcal{X}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal{A} \cup \mathcal{B}\)</span>  : union of sets  <span class="math notranslate nohighlight">\(\mathcal{A}\)</span>  and  <span class="math notranslate nohighlight">\(\mathcal{B}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal{A} \cap \mathcal{B}\)</span>  : intersection of sets  <span class="math notranslate nohighlight">\(\mathcal{A}\)</span>  and  <span class="math notranslate nohighlight">\(\mathcal{B}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal{A} \backslash \mathcal{B}\)</span>  : set subtraction of  <span class="math notranslate nohighlight">\(\mathcal{B}\)</span>  from  <span class="math notranslate nohighlight">\(\mathcal{A}\)</span>  (contains only those elements of  <span class="math notranslate nohighlight">\(\mathcal{A}\)</span>  that do not belong to  <span class="math notranslate nohighlight">\(\mathcal{B}\)</span>  )</p></li>
</ul>
</section>
<section id="functions-and-operators">
<h4>Functions and Operators<a class="headerlink" href="#functions-and-operators" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(f(\cdot)\)</span> :  a function</p></li>
<li><p><span class="math notranslate nohighlight">\(\log (\cdot)\)</span>  : the natural logarithm (base  e  )</p></li>
<li><p><span class="math notranslate nohighlight">\(\log _{2}(\cdot)\)</span>  : logarithm to base 2</p></li>
<li><p><span class="math notranslate nohighlight">\(\exp (\cdot)\)</span>  : the exponential function</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{1}(\cdot)\)</span>  : the indicator function; evaluates to 1 if the boolean argument is true, and 0 otherwise</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{1}_{\mathcal{X}}(z)\)</span>  : the set-membership indicator function; evaluates to 1 if the element  z  belongs to the set  mathcal{X}  and 0 otherwise</p></li>
<li><p><span class="math notranslate nohighlight">\((\cdot)^{\top}\)</span>  : transpose of a vector or a matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{X}^{-1}\)</span>  : inverse of matrix  mathbf{X}</p></li>
<li><p><span class="math notranslate nohighlight">\(\odot\)</span>  : Hadamard (elementwise) product</p></li>
<li><p><span class="math notranslate nohighlight">\([\cdot, . ]\)</span> : concatenation</p></li>
<li><p><span class="math notranslate nohighlight">\(\|\cdot\|_{p}: \ell_{p}\)</span>  norm</p></li>
<li><p><span class="math notranslate nohighlight">\(\|\cdot\|: \ell_{2}\)</span>  norm</p></li>
<li><p><span class="math notranslate nohighlight">\(\langle\mathbf{x}, \mathbf{y}\rangle\)</span> : inner (dot) product of vectors  <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>  and  <span class="math notranslate nohighlight">\(\mathbf{y}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\sum\)</span>  : summation over a collection of elements</p></li>
<li><p><span class="math notranslate nohighlight">\(\Pi\)</span>  : product over a collection of elements</p></li>
<li><p>=: an equality asserted as a definition of the symbol on the left-hand side</p></li>
</ul>
</section>
<section id="calculus">
<h4>Calculus<a class="headerlink" href="#calculus" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\frac{d y}{d x}\)</span>  : derivative of  y  with respect to  x</p></li>
<li><p><span class="math notranslate nohighlight">\(\frac{\partial y}{\partial x}\)</span>  : partial derivative of  y  with respect to  x</p></li>
<li><p><span class="math notranslate nohighlight">\(\nabla_{\mathrm{x}} y\)</span>  : gradient of  y  with respect to  x</p></li>
<li><p><span class="math notranslate nohighlight">\(\int_{a}^{b} f(x) d x\)</span>  : definite integral of  f  from  a  to  b  with respect to  x</p></li>
<li><p><span class="math notranslate nohighlight">\(\int f(x) d x\)</span>  : indefinite integral of  f  with respect to  x</p></li>
</ul>
</section>
<section id="probability-and-information-theory">
<h4>Probability and Information Theory<a class="headerlink" href="#probability-and-information-theory" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>X  : a random variable</p></li>
<li><p>P  : a probability distribution</p></li>
<li><p><span class="math notranslate nohighlight">\(X \sim P\)</span>  : the random variable  X  follows distribution  P</p></li>
<li><p><span class="math notranslate nohighlight">\(X \sim N(μ,σ^2 )\)</span> :随机变量 X 服从均值为 μ，方差为 σ^2  的高斯分布(正态分布)</p></li>
<li><p><span class="math notranslate nohighlight">\(\epsilon \sim \mathcal{N}\left(0, 0.01^{2}\right)\)</span> : 随机变量 ϵ 服从一个高斯（正态）分布，其均值（mean）为 0，方差（variance）为 <span class="math notranslate nohighlight">\(0.01 ^ 2\)</span></p></li>
<li><p>P(X=x)  : the probability assigned to the event where random variable  X  takes value  x</p></li>
<li><p><span class="math notranslate nohighlight">\(P(X \mid Y)\)</span>  : the conditional probability distribution of  X  given  Y</p></li>
<li><p><span class="math notranslate nohighlight">\(p(\cdot)\)</span>  : a probability density function (PDF) associated with distribution  P</p></li>
<li><p>E[X]  : expectation of a random variable  X</p></li>
<li><p><span class="math notranslate nohighlight">\(X \perp Y\)</span>  : random variables  X  and  Y  are independent</p></li>
<li><p><span class="math notranslate nohighlight">\(X \perp Y \mid Z\)</span>  : random variables  X  and  Y  are conditionally independent given  Z</p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma_{X}\)</span>  : standard deviation of random variable  X</p></li>
<li><p><span class="math notranslate nohighlight">\(\operatorname{Var}(X)\)</span>  : variance of random variable  X , equal to  sigma_{X}^{2}</p></li>
<li><p><span class="math notranslate nohighlight">\(\operatorname{Cov}(X, Y)\)</span>  : covariance of random variables  X  and  Y</p></li>
</ul>
</section>
<section id="id3">
<h4>额外的<a class="headerlink" href="#id3" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\rho(X, Y)\)</span>  : the Pearson correlation coefficient between  X  and  Y , equals <span class="math notranslate nohighlight">\(\frac{\operatorname{Cov}(X, Y)}{\sigma_{X} \sigma_{Y}}\)</span></p></li>
<li><p>H(X) : entropy of random variable  X</p></li>
<li><p>H(P, Q): cross-entropy from P to Q</p></li>
<li><p><span class="math notranslate nohighlight">\(D_{\mathrm{KL}}(P \| Q)\)</span>  : the KL-divergence (or relative entropy) from distribution  Q  to distribution  P</p></li>
<li><p><span class="math notranslate nohighlight">\(P(y=i) \propto \exp o_{i}\)</span> : 表示类别 y 是 i 的概率与 <span class="math notranslate nohighlight">\(o^i\)</span> 的指数函数成正比(这儿 <span class="math notranslate nohighlight">\(o^i\)</span> 通常指的是模型输出的未经归一化的对数几率（logits），即模型对于每个类别的原始预测值)</p></li>
<li><p><span class="math notranslate nohighlight">\(R\)</span> : 表示风险或误差，表示泛化误差 (Generalization Error)</p></li>
<li><p><span class="math notranslate nohighlight">\(R_{\text{emp}}\)</span> : 表示 经验风险 (Empirical Risk)，也称为 训练误差 (Training Error)</p></li>
</ul>
</section>
</section>
</section>
<section id="part-1-basics-and-preliminaries">
<h2>Part 1: Basics and Preliminaries<a class="headerlink" href="#part-1-basics-and-preliminaries" title="此标题的永久链接">¶</a></h2>
<section id="introduction">
<h3>1. Introduction<a class="headerlink" href="#introduction" title="此标题的永久链接">¶</a></h3>
<section id="key-components">
<h4>Key Components<a class="headerlink" href="#key-components" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>Data</p></li>
<li><p>Model</p></li>
<li><p>Function that quantifies how well (or badly) the model is doing</p></li>
<li><p>Algorithm to adjust the model’s parameters to optimize the objective function.</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>特征（协变量或 输入）-----&gt; 标签（或目标）
features (covariates or inputs) -----&gt; label (or target)
</pre></div>
</div>
</section>
<section id="kinds-of-machine-learning-problems">
<h4>Kinds of Machine Learning Problems<a class="headerlink" href="#kinds-of-machine-learning-problems" title="此标题的永久链接">¶</a></h4>
<section id="supervised-learning">
<h5>Supervised Learning<a class="headerlink" href="#supervised-learning" title="此标题的永久链接">¶</a></h5>
<figure class="align-default" id="id214">
<img alt="https://img.zhaoweiguo.com/uPic/2024/12/IJaPfO.png" src="https://img.zhaoweiguo.com/uPic/2024/12/IJaPfO.png" />
<figcaption>
<p><span class="caption-text">Fig. 1.3.1 Supervised learning.</span><a class="headerlink" href="#id214" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Regression</p></li>
<li><p>Classification</p></li>
<li><p>Tagging</p></li>
<li><p>Search(e.g. PageRank)</p></li>
<li><p>Recommender Systems</p></li>
<li><dl class="simple">
<dt>Sequence Learning</dt><dd><ul>
<li><p>Tagging and Parsing(标记和解析): 如词性（PoS）标记, 命名实体识别</p></li>
<li><p>Automatic Speech Recognition(自动语音识别)</p></li>
<li><p>Text to Speech(文字转语音)</p></li>
<li><p>Machine Translation(机器翻译)</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<figure class="align-default" id="id215">
<img alt="https://img.zhaoweiguo.com/uPic/2024/12/rOICXJ.png" src="https://img.zhaoweiguo.com/uPic/2024/12/rOICXJ.png" />
<figcaption>
<p><span class="caption-text">[Tagging]当分类器遇到这种图像时，我们自己就会遇到麻烦。学习预测不互斥的类的问题称为多标签分类。自动标记问题通常最好用多标签分类来描述。</span><a class="headerlink" href="#id215" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
</section>
<section id="unsupervised-and-self-supervised-learning">
<h5>Unsupervised and Self-Supervised Learning<a class="headerlink" href="#unsupervised-and-self-supervised-learning" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>无监督学习的进一步发展是: 自我监督学习</p></li>
<li><p>自我监督学习：利用某些方面的技术，使用未标记的数据提供监督。</p></li>
<li><p>对于文本，我们可以训练模型 通过使用它们预测随机屏蔽的单词来“填空” 大语料库中的周围单词（上下文），无需任何标记工作</p></li>
<li><p>对于图像，我们可以训练模型 告诉同一图像的两个裁剪区域之间的相对位置，基于图像的剩余部分来预测图像的被遮挡部分，或者预测两个示例是否是同一底层图像的变动版本。</p></li>
</ul>
</section>
<section id="interacting-with-an-environment">
<h5>Interacting with an Environment<a class="headerlink" href="#interacting-with-an-environment" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>前面的监督和无监督学习都会预先获取大量数据，然后启动模式识别机器，而无需再次与环境交互。</p></li>
<li><p>因为所有的学习都是在算法与环境断开连接之后进行的，所以这有时被称为离线学习</p></li>
</ul>
<figure class="align-default" id="id216">
<img alt="https://img.zhaoweiguo.com/uPic/2024/12/K3Ulip.png" src="https://img.zhaoweiguo.com/uPic/2024/12/K3Ulip.png" />
<figcaption>
<p><span class="caption-text">Fig. 1.3.6 Collecting data for supervised learning from an environment.</span><a class="headerlink" href="#id216" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
</section>
<section id="reinforcement-learning">
<h5>Reinforcement Learning<a class="headerlink" href="#reinforcement-learning" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>强化学习给出了一个非常笼统的问题描述，其中代理通过一系列时间步骤与环境进行交互。在每个时间步，代理都会从环境中接收一些观察结果，并且必须选择随后传输的操作 通过某种机制（有时称为 执行器），当每次循环之后，代理收到来自环境的奖励。然后，代理接收后续观察，并选择后续操作，依此类推。强化学习代理的行为受策略控制。简而言之，一个 政策只是将环境观察映射到行动的函数。强化学习的目标是产生好的政策。</p></li>
</ul>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2024/12/Tqv5o7.png" src="https://img.zhaoweiguo.com/uPic/2024/12/Tqv5o7.png" />
</figure>
<ul class="simple">
<li><p>强化学习框架的通用性怎么强调都不为过。一般的强化学习问题有一个非常通用的设置。行动会影响随后的观察。仅当奖励与所选操作相对应时才会观察到奖励。</p></li>
<li><p>当环境被充分观察时，我们将强化学习问题称为``马尔可夫决策过程(Markov decision process)``</p></li>
<li><p>当状态不依赖于先前的动作时，我们将其称为 <code class="docutils literal notranslate"><span class="pre">上下文强盗问题(contextual</span> <span class="pre">bandit</span> <span class="pre">problem)</span></code></p></li>
<li><p>当没有状态，只有一组初始奖励未知的可用动作时，我们就会遇到经典的 <code class="docutils literal notranslate"><span class="pre">多臂老虎机问题(multi-armed</span> <span class="pre">bandit</span> <span class="pre">problem)</span></code></p></li>
</ul>
</section>
</section>
<section id="roots">
<h4>Roots<a class="headerlink" href="#roots" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>对于一系列不同的机器学习问题，深度学习 学习为他们的解决方案提供了强大的工具。虽然很多深 学习方法是最近的发明，学习背后的核心思想 几个世纪以来，人们一直在研究数据。事实上，人类已经掌握了 渴望分析数据并预测未来的结果，并且它 这种愿望是许多自然科学的根源 数学。两个例子是伯努利分布，以 雅各布·伯努利（Jacob Bernoulli，1655-1705） ，以及卡尔·弗里德里希·高斯（Carl Friedrich Gauss，1777-1855）发现的高斯分布。</p></li>
<li><p>随着数据的可用性和收集，统计数据真正起飞。它的先驱之一罗纳德·费希尔（Ronald Fisher，1890-1962）对其理论及其在遗传学中的应用做出了重大贡献。他的许多算法（例如线性判别分析）和概念（例如费舍尔信息矩阵）仍然在现代统计学的基础中占有重要地位。Fisher 于 1936 年发布的 Iris 数据集有时仍用于演示机器学习算法。</p></li>
<li><p>对机器学习的其他影响来自克劳德·香农（1916-2001）的信息论和艾伦·图灵（1912-1954）提出的计算理论。</p></li>
<li><p>进一步的影响来自神经科学和心理学。毕竟， 人类明显表现出智能行为。很多学者都问过 是否可以解释并可能对这种能力进行逆向工程。 第一个受生物学启发的算法是由 唐纳德·赫布 (1904–1985) 。在他的开创性著作《行为的组织》（ Hebb，1949 ）中，他假设神经元通过正强化进行学习。这被称为赫布学习规则。这些想法启发了后来的工作，例如罗森布拉特的感知器学习算法，并为当今深度学习的许多随机梯度下降算法奠定了基础：强化期望的行为并减少不良行为，以获得神经网络中参数的良好设置。</p></li>
<li><p>神经网络的名字来源于生物学灵感。一个多世纪以来（可以追溯到 1873 年 Alexander Bain 和 1890 年 James Sherrington 的模型），研究人员一直试图组装类似于相互作用神经元网络的计算电路。</p></li>
</ul>
</section>
<section id="the-road-to-deep-learning">
<h4>The Road to Deep Learning<a class="headerlink" href="#the-road-to-deep-learning" title="此标题的永久链接">¶</a></h4>
<figure class="align-default" id="id217">
<img alt="https://img.zhaoweiguo.com/uPic/2024/12/MeU9NJ.png" src="https://img.zhaoweiguo.com/uPic/2024/12/MeU9NJ.png" />
<figcaption>
<p><span class="caption-text">表1.5.1 数据集vs计算机内存和计算能力</span><a class="headerlink" href="#id217" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>机器学习和统计的最佳结合点 从（广义）线性模型和核方法转向深度神经网络 网络。这也是很多中流砥柱的原因之一 深度学习，例如多层感知器 （ McCulloch 和 Pitts，1943 ） ，卷积神经网络 （ LeCun等，1998 ） ，长短期记忆 （ Hochreiter 和 Schmidhuber，1997 ）和 Q-Learning （ Watkins 和 Dayan，1992 ）</p></li>
<li><dl class="simple">
<dt>下面列举了帮助研究人员在过去十年中取得巨大进步的想法</dt><dd><ul>
<li><p>新的容量控制方法，如dropout (Srivastava et al., 2014)，有助于减轻过拟合的危险。这是通过在整个神经网络中应用噪声注入 (Bishop, 1995) 来实现的，出于训练目的，用随机变量来代替权重。</p></li>
<li><p>注意力机制解决了困扰统计学一个多世纪的问题：如何在不增加可学习参数的情况下增加系统的记忆和复杂性。</p></li>
<li><p>多阶段设计。例如，存储器网络 (Sukhbaatar et al., 2015) 和神经编程器-解释器 (Reed and De Freitas, 2015)。它们允许统计建模者描述用于推理的迭代方法。</p></li>
<li><p>生成对抗网络 (Goodfellow et al., 2014) 。传统模型中，密度估计和生成模型的统计方法侧重于找到合适的概率分布（通常是近似的）和抽样算法。因此，这些算法在很大程度上受到统计模型固有灵活性的限制。生成式对抗性网络的关键创新是用具有可微参数的任意算法代替采样器。然后对这些数据进行调整，使得鉴别器（实际上是一个双样本测试）不能区分假数据和真实数据。通过使用任意算法生成数据的能力，它为各种技术打开了密度估计的大门。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
</section>
<section id="preliminaries">
<h3>2. Preliminaries<a class="headerlink" href="#preliminaries" title="此标题的永久链接">¶</a></h3>
<p>survival skills:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">1</span><span class="p">)</span> <span class="n">techniques</span> <span class="k">for</span> <span class="n">storing</span> <span class="ow">and</span> <span class="n">manipulating</span> <span class="n">data</span><span class="p">;</span>
<span class="mi">2</span><span class="p">)</span> <span class="n">libraries</span> <span class="k">for</span> <span class="n">ingesting</span> <span class="ow">and</span> <span class="n">preprocessing</span> <span class="n">data</span> <span class="kn">from</span><span class="w"> </span><span class="nn">a</span> <span class="n">variety</span> <span class="n">of</span> <span class="n">sources</span><span class="p">;</span>
<span class="mi">3</span><span class="p">)</span> <span class="n">knowledge</span> <span class="n">of</span> <span class="n">the</span> <span class="n">basic</span> <span class="n">linear</span> <span class="n">algebraic</span> <span class="n">operations</span> <span class="n">that</span> <span class="n">we</span> <span class="n">apply</span> <span class="n">to</span> <span class="n">high</span><span class="o">-</span><span class="n">dimensional</span> <span class="n">data</span> <span class="n">elements</span><span class="p">;</span>
<span class="mi">4</span><span class="p">)</span> <span class="n">just</span> <span class="n">enough</span> <span class="n">calculus</span> <span class="n">to</span> <span class="n">determine</span> <span class="n">which</span> <span class="n">direction</span> <span class="n">to</span> <span class="n">adjust</span> <span class="n">each</span> <span class="n">parameter</span> <span class="ow">in</span> <span class="n">order</span> <span class="n">to</span> <span class="n">decrease</span> <span class="n">the</span> <span class="n">loss</span> <span class="n">function</span><span class="p">;</span>
<span class="mi">5</span><span class="p">)</span> <span class="n">the</span> <span class="n">ability</span> <span class="n">to</span> <span class="n">automatically</span> <span class="n">compute</span> <span class="n">derivatives</span> <span class="n">so</span> <span class="n">that</span> <span class="n">you</span> <span class="n">can</span> <span class="n">forget</span> <span class="n">much</span> <span class="n">of</span> <span class="n">the</span> <span class="n">calculus</span> <span class="n">you</span> <span class="n">just</span> <span class="n">learned</span><span class="p">;</span>
<span class="mi">6</span><span class="p">)</span> <span class="n">some</span> <span class="n">basic</span> <span class="n">fluency</span> <span class="ow">in</span> <span class="n">probability</span><span class="p">,</span> <span class="n">our</span> <span class="n">primary</span> <span class="n">language</span> <span class="k">for</span> <span class="n">reasoning</span> <span class="n">under</span> <span class="n">uncertainty</span><span class="p">;</span> <span class="ow">and</span>
<span class="mi">7</span><span class="p">)</span> <span class="n">some</span> <span class="n">aptitude</span> <span class="k">for</span> <span class="n">finding</span> <span class="n">answers</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">official</span> <span class="n">documentation</span> <span class="n">when</span> <span class="n">you</span> <span class="n">get</span> <span class="n">stuck</span><span class="o">.</span>
</pre></div>
</div>
<section id="data-manipulation">
<h4>2.1 Data Manipulation<a class="headerlink" href="#data-manipulation" title="此标题的永久链接">¶</a></h4>
<ul>
<li><p>广播机制</p></li>
<li><p>索引和切片</p></li>
<li><p>转换为其他Python对象:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
                     <span class="p">[</span> <span class="mi">4</span><span class="p">,</span>  <span class="mi">5</span><span class="p">,</span>  <span class="mi">6</span><span class="p">,</span>  <span class="mi">7</span><span class="p">],</span>
                     <span class="p">[</span> <span class="mi">8</span><span class="p">,</span>  <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">]])</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="nb">type</span><span class="p">(</span><span class="n">A</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="c1"># (numpy.ndarray, torch.Tensor)</span>


<span class="c1"># 将大小为1的张量转换为Python标量</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">3.5</span><span class="p">])</span>
<span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="nb">float</span><span class="p">(</span><span class="n">a</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="c1"># (array([3.5]), 3.5, 3.5, 3)</span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="data-preprocessing">
<h4>2.2. Data Preprocessing<a class="headerlink" href="#data-preprocessing" title="此标题的永久链接">¶</a></h4>
<ul>
<li><p>读取数据集</p></li>
<li><p>处理缺失值</p></li>
<li><p>转换为张量格式:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">))</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="linear-algebra">
<h4>2.3. Linear Algebra(线性代数)<a class="headerlink" href="#linear-algebra" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>Scalars(标量)</p></li>
<li><p>Vectors(向量)</p></li>
<li><p>Matrices(矩阵)</p></li>
<li><p>Tensors(张量)</p></li>
</ul>
<section id="hadamard-product">
<h5>Hadamard product<a class="headerlink" href="#hadamard-product" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>The elementwise product of two matrices is called their Hadamard product (denoted  <span class="math notranslate nohighlight">\(\odot\)</span>  ).</p></li>
<li><p>two matrices  <span class="math notranslate nohighlight">\(\mathbf{A}, \mathbf{B} \in \mathbb{R}^{m \times n}\)</span></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf{A} \odot \mathbf{B}= \left[\begin{array}{cccc}
    a_{11} b_{11} &amp; a_{12} b_{12} &amp; \ldots &amp; a_{1 n} b_{1 n} \\
    a_{21} b_{21} &amp; a_{22} b_{22} &amp; \ldots &amp; a_{2 n} b_{2 n} \\
    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
    a_{m 1} b_{m 1} &amp; a_{m 2} b_{m 2} &amp; \ldots &amp; a_{m n} b_{m n} \\
\end{array}\right] .\end{split}\]</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>  <span class="c1"># Assign a copy of A to B by allocating new memory</span>
<span class="n">A</span> <span class="o">*</span> <span class="n">B</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">16.</span><span class="p">,</span> <span class="mf">25.</span><span class="p">]])</span>
</pre></div>
</div>
</section>
<section id="dot-product">
<h5>点积(Dot Product)<a class="headerlink" href="#dot-product" title="此标题的永久链接">¶</a></h5>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span>
<span class="c1"># (tensor([0., 1., 2.]), tensor([1., 1., 1.]))</span>

<span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">y</span><span class="p">)</span>
<span class="c1"># (tensor(3.), tensor(3.))</span>
<span class="c1"># 过程:</span>
<span class="c1"># 0*1 + 1*1 + 2*1 = 3</span>
</pre></div>
</div>
</section>
<section id="matrixvector-products">
<h5>矩阵-向量积(Matrix–Vector Products)<a class="headerlink" href="#matrixvector-products" title="此标题的永久链接">¶</a></h5>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf{A}=\left[\begin{array}{c}
\mathbf{a}_{1}^{\top} \\
\mathbf{a}_{2}^{\top} \\
\vdots \\
\mathbf{a}_{m}^{\top} \\
\end{array}\right]\end{split}\]</div>
<ul class="simple">
<li><p>where each  <span class="math notranslate nohighlight">\(\mathbf{a}_{i}^{\top} \in \mathbb{R}^{n}\)</span>  is a row vector representing the  <span class="math notranslate nohighlight">\(i^{\text {th }}\)</span>  row of the matrix  <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> .</p></li>
<li><p>The matrix-vector product  <span class="math notranslate nohighlight">\(\mathbf{A x}\)</span>  is simply a column vector of length  m , whose  <span class="math notranslate nohighlight">\(i^{\text {th }}\)</span>  element is the dot product  <span class="math notranslate nohighlight">\(\mathbf{a}_{i}^{\top} \mathbf{x}\)</span></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf{A} \mathbf{x}=\left[\begin{array}{c}
\mathbf{a}_{1}^{\top} \\
\mathbf{a}_{2}^{\top} \\
\vdots \\
\mathbf{a}_{m}^{\top} \\
\end{array}\right] \mathbf{x}=\left[\begin{array}{c}
\mathbf{a}_{1}^{\top} \mathbf{x} \\
\mathbf{a}_{2}^{\top} \mathbf{x} \\
\vdots \\
\mathbf{a}_{m}^{\top} \mathbf{x} \\
\end{array}\right]\end{split}\]</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="c1"># tensor([[0, 1, 2],</span>
<span class="c1">#         [3, 4, 5]])</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="c1"># tensor([0, 1, 2])</span>

<span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
<span class="c1"># (torch.Size([2, 3]), torch.Size([3])</span>

<span class="n">torch</span><span class="o">.</span><span class="n">mv</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="n">A</span><span class="nd">@x</span>
<span class="c1"># tensor([ 5., 14.]), tensor([ 5., 14.]))</span>
<span class="c1"># 过程:</span>
<span class="c1"># torch.dot([0, 1, 2], [0, 1, 2]) = 0*0+1*1+2*2=5</span>
<span class="c1"># torch.dot([3, 4, 5], [0, 1, 2]) = 0*3+1*4+2*5=14</span>
</pre></div>
</div>
</section>
<section id="matrixmatrix-multiplication">
<h5>矩阵-矩阵乘法(Matrix–Matrix Multiplication)<a class="headerlink" href="#matrixmatrix-multiplication" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>Say that we have two matrices  <span class="math notranslate nohighlight">\(\mathbf{A} \in \mathbb{R}^{n \times k}\)</span>  and  <span class="math notranslate nohighlight">\(\mathbf{B} \in \mathbb{R}^{k \times m}\)</span> .</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf{A}=\left[\begin{array}{cccc}
a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1 k} \\
a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2 k} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
a_{n 1} &amp; a_{n 2} &amp; \cdots &amp; a_{n k} \\
\end{array}\right], \quad \mathbf{B}=\left[\begin{array}{cccc}
b_{11} &amp; b_{12} &amp; \cdots &amp; b_{1 m} \\
b_{21} &amp; b_{22} &amp; \cdots &amp; b_{2 m} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
b_{k 1} &amp; b_{k 2} &amp; \cdots &amp; b_{k m}
\end{array}\right] .\end{split}\]</div>
<ul class="simple">
<li><p>Let  <span class="math notranslate nohighlight">\(\mathbf{a}_{i}^{\top} \in \mathbb{R}^{k}\)</span>  denote the row vector representing the  <span class="math notranslate nohighlight">\(i^{\text {th }}\)</span>  row of the matrix  <span class="math notranslate nohighlight">\(\mathbf{A}\)</span>  and let  <span class="math notranslate nohighlight">\(\mathbf{b}_{j} \in \mathbb{R}^{k}\)</span>  denote the column vector from the  <span class="math notranslate nohighlight">\(j^{\text {th }}\)</span>  column of the matrix B:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf{A}=\left[\begin{array}{c}
\mathbf{a}_{1}^{\top} \\
\mathbf{a}_{2}^{\top} \\
\vdots \\
\mathbf{a}_{n}^{\top}
\end{array}\right], \quad \mathbf{B}=\left[\begin{array}{llll}
\mathbf{b}_{1} &amp; \mathbf{b}_{2} &amp; \cdots &amp; \mathbf{b}_{m}
\end{array}\right]\end{split}\]</div>
<p>To form the matrix product  <span class="math notranslate nohighlight">\(\mathbf{C} \in \mathbb{R}^{n \times m}\)</span> , we simply compute each element  <span class="math notranslate nohighlight">\(c_{i j}\)</span>  as the dot product between the  <span class="math notranslate nohighlight">\(i^{\text {th }}\)</span>  row of  <span class="math notranslate nohighlight">\(\mathbf{A}\)</span>  and the  <span class="math notranslate nohighlight">\(j^{\text {th }}\)</span>  column of  <span class="math notranslate nohighlight">\(\mathbf{B}\)</span> , i.e.,  <span class="math notranslate nohighlight">\(\mathbf{a}_{i}^{\top} \mathbf{b}_{j}\)</span>  :</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf{C}=\mathbf{A B}=\left[\begin{array}{c}
\mathbf{a}_{1}^{\top} \\
\mathbf{a}_{2}^{\top} \\
\vdots \\
\mathbf{a}_{n}^{\top}
\end{array}\right]\left[\begin{array}{llll}
\mathbf{b}_{1} &amp; \mathbf{b}_{2} &amp; \cdots &amp; \mathbf{b}_{m}
\end{array}\right]=\left[\begin{array}{cccc}
\mathbf{a}_{1}^{\top} \mathbf{b}_{1} &amp; \mathbf{a}_{1}^{\top} \mathbf{b}_{2} &amp; \cdots &amp; \mathbf{a}_{1}^{\top} \mathbf{b}_{m} \\
\mathbf{a}_{2}^{\top} \mathbf{b}_{1} &amp; \mathbf{a}_{2}^{\top} \mathbf{b}_{2} &amp; \cdots &amp; \mathbf{a}_{2}^{\top} \mathbf{b}_{m} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\mathbf{a}_{n}^{\top} \mathbf{b}_{1} &amp; \mathbf{a}_{n}^{\top} \mathbf{b}_{2} &amp; \cdots &amp; \mathbf{a}_{n}^{\top} \mathbf{b}_{m}
\end{array}\right]\end{split}\]</div>
<ul class="simple">
<li><p>我们可以将矩阵-矩阵乘法 <strong>AB</strong> 看作简单地执行 m 次矩阵-向量积，并将结果拼接在一起，形成一个 n*m 矩阵。</p></li>
<li><p>在下面的代码中，我们在A和B上执行矩阵乘法。 这里的A是一个5行4列的矩阵，B是一个4行3列的矩阵。 两者相乘后，我们得到了一个5行3列的矩阵。</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">,</span>  <span class="mf">7.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">8.</span><span class="p">,</span>  <span class="mf">9.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">,</span> <span class="mf">11.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">12.</span><span class="p">,</span> <span class="mf">13.</span><span class="p">,</span> <span class="mf">14.</span><span class="p">,</span> <span class="mf">15.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">16.</span><span class="p">,</span> <span class="mf">17.</span><span class="p">,</span> <span class="mf">18.</span><span class="p">,</span> <span class="mf">19.</span><span class="p">]])</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>
<span class="c1"># 输出</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">6.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">22.</span><span class="p">,</span> <span class="mf">22.</span><span class="p">,</span> <span class="mf">22.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">38.</span><span class="p">,</span> <span class="mf">38.</span><span class="p">,</span> <span class="mf">38.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">54.</span><span class="p">,</span> <span class="mf">54.</span><span class="p">,</span> <span class="mf">54.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">70.</span><span class="p">,</span> <span class="mf">70.</span><span class="p">,</span> <span class="mf">70.</span><span class="p">]])</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p><code class="docutils literal notranslate"><span class="pre">矩阵-矩阵乘法(matrix–matrix</span> <span class="pre">multiplication)</span></code> 可以简单地称为 <code class="docutils literal notranslate"><span class="pre">矩阵乘法(matrix</span> <span class="pre">multiplication)</span></code> ，不应与 <code class="docutils literal notranslate"><span class="pre">Hadamard积(Hadamard</span> <span class="pre">product)</span></code> 混淆。</p>
</div>
</section>
</section>
<section id="id4">
<h4>2.4. Calculus(微积分)<a class="headerlink" href="#id4" title="此标题的永久链接">¶</a></h4>
<figure class="align-default" id="id218">
<img alt="https://img.zhaoweiguo.com/uPic/2024/12/Ovvwmt.png" src="https://img.zhaoweiguo.com/uPic/2024/12/Ovvwmt.png" />
<figcaption>
<p><span class="caption-text">逼近法就是积分(integral calculus)的起源</span><a class="headerlink" href="#id218" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>微分(differential calculus)被发明出来。 在微分学最重要的应用是优化问题，即考虑如何把事情做到最好</p></li>
</ul>
<p>将拟合模型的任务分解为两个关键问题:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>1. 优化(optimization): 用模型拟合观测数据的过程
2. 泛化(generalization): 数学原理和实践者的智慧，能够指导我们生成出有效性超出用于训练的数据集本身的模型
</pre></div>
</div>
<section id="derivatives-and-differentiation">
<h5>Derivatives and Differentiation(导数和微分)<a class="headerlink" href="#derivatives-and-differentiation" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>Put simply, a <code class="docutils literal notranslate"><span class="pre">derivative</span></code> is the rate of change in a function with respect to changes in its arguments. Derivatives can tell us how rapidly a loss function would increase or decrease were we to increase or decrease each parameter by an infinitesimally small amount.</p></li>
<li><p>简而言之，对于每个参数， 如果我们把这个参数增加或减少一个无穷小的量，可以知道损失会以多快的速度增加或减少</p></li>
<li><p>假设我们有一个函数 <span class="math notranslate nohighlight">\(f: \mathbb{R} \rightarrow \mathbb{R}\)</span> , 其输入和输出都是标量。如果  f  的导数存在, 这个极限被定义为</p></li>
</ul>
<div class="math notranslate nohighlight">
\[f^{\prime}(x)=\lim _{h \rightarrow 0} \frac{f(x+h)-f(x)}{h}\]</div>
<ul class="simple">
<li><p>如果 <span class="math notranslate nohighlight">\(f^{\prime}(a)\)</span> 存在，则称 <code class="docutils literal notranslate"><span class="pre">f</span></code> 在 <code class="docutils literal notranslate"><span class="pre">a</span></code> 处是可微（differentiable）的</p></li>
<li><p>如果 <code class="docutils literal notranslate"><span class="pre">f</span></code> 在一个区间内的每个数上都是可微的，则此函数在此区间中是可微的</p></li>
<li><p>可以将上面公式中的导数 <span class="math notranslate nohighlight">\(f^{\prime}(a)\)</span> 解释为 <code class="docutils literal notranslate"><span class="pre">f(x)</span></code> 相对于 <code class="docutils literal notranslate"><span class="pre">x</span></code> 的瞬时（instantaneous）变化率</p></li>
<li><p>所谓的瞬时变化率是基于 <code class="docutils literal notranslate"><span class="pre">x</span></code> 中的变化 <code class="docutils literal notranslate"><span class="pre">h</span></code> ，且 <code class="docutils literal notranslate"><span class="pre">h</span></code> 接近 <code class="docutils literal notranslate"><span class="pre">0</span></code></p></li>
<li><p>导数的几个等价符号：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[f^{\prime}(x)=y^{\prime}=\frac{d y}{d x}=\frac{d f}{d x}=\frac{d}{d x} f(x)=D f(x)=D_{x} f(x),\]</div>
<p>其中符号  <span class="math notranslate nohighlight">\(\frac{d}{d x}\)</span>  和  <strong>D</strong>  是微分运算符, 表示微分操作。我们可以使用以下规则来对常见函数求微分：</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(D C=0\)</span>  (  C  是一个常数)</p></li>
<li><p><span class="math notranslate nohighlight">\(D x^{n}=n x^{n-1}\)</span>  (幂律（power rule）,  n  是任意实数）</p></li>
<li><p><span class="math notranslate nohighlight">\(D e^{x}=e^{x}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(D \ln (x)=1 / x\)</span></p></li>
</ul>
</div></blockquote>
<ul class="simple">
<li><p>为了微分一个由一些常见函数组成的函数, 下面的一些法则方便使用。假设函数  <code class="docutils literal notranslate"><span class="pre">f</span></code>  和  <code class="docutils literal notranslate"><span class="pre">g</span></code>  都是可微的,  <code class="docutils literal notranslate"><span class="pre">C</span></code>  是一个常数, 则:</p></li>
<li><p>常数相乘法则</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\frac{d}{d x}[C f(x)]=C \frac{d}{d x} f(x),\]</div>
<ul class="simple">
<li><p>加法法则</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\frac{d}{d x}[f(x)+g(x)]=\frac{d}{d x} f(x)+\frac{d}{d x} g(x)\]</div>
<p>乘法法则</p>
<div class="math notranslate nohighlight">
\[\frac{d}{d x}[f(x) g(x)]=f(x) \frac{d}{d x}[g(x)]+g(x) \frac{d}{d x}[f(x)],\]</div>
<p>除法法则</p>
<div class="math notranslate nohighlight">
\[\frac{d}{d x}\left[\frac{f(x)}{g(x)}\right]=\frac{g(x) \frac{d}{d x}[f(x)]-f(x) \frac{d}{d x}[g(x)]}{[g(x)]^{2}} .\]</div>
<ul class="simple">
<li><p>现在我们可以应用上述几个法则来计算 <span class="math notranslate nohighlight">\(u=f(x)=3x^2-4x\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(u^{\prime}=f^{\prime}(x)=3 \frac{d}{d x} x^{2}-4 \frac{d}{d x}x = 6x-4\)</span></p></li>
<li><p>令  x=1 , 我们有  <span class="math notranslate nohighlight">\(u^{\prime}=2\)</span></p></li>
<li><p>当  x=1  时, 此导数也是曲线  u=f(x)  切线的斜率。</p></li>
</ul>
</section>
<section id="partial-derivatives">
<h5>Partial Derivatives(偏导数)<a class="headerlink" href="#partial-derivatives" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>在深度学习中，函数通常依赖于许多变量。 因此，我们需要将微分的思想推广到多元函数（multivariate function）上</p></li>
<li><p>设  <span class="math notranslate nohighlight">\(y=f\left(x_{1}, x_{2}, \ldots, x_{n}\right)\)</span>  是一个具有  n  个变量的函数。  y  关于第  i  个参数  <span class="math notranslate nohighlight">\(x_{i}\)</span>  的偏导数（partial derivative）为:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\frac{\partial y}{\partial x_{i}}=
    \lim_{h \rightarrow 0} \frac{f\left(x_{1}, \ldots, x_{i-1}, x_{i}+h, x_{i+1}, \ldots, x_{n}\right)-f\left(x_{1}, \ldots, x_{i}, \ldots, x_{n}\right)}{h}\]</div>
<ul class="simple">
<li><p>为了计算  <span class="math notranslate nohighlight">\(\frac{\partial y}{\partial x_{i}}\)</span> , 我们可以简单地将  <span class="math notranslate nohighlight">\(x_{1}, \ldots, x_{i-1}, x_{i+1}, \ldots, x_{n}\)</span>  看作常数, 并计算  y  关于  <span class="math notranslate nohighlight">\(x_{i}\)</span>  的导数。对于偏导数的表示, 以下是等价的:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\frac{\partial y}{\partial x_{i}}=\frac{\partial f}{\partial x_{i}}=f_{x_{i}}=f_{i}=D_{i} f=D_{x_{i}} f .\]</div>
</section>
<section id="gradients">
<h5>Gradients(梯度)<a class="headerlink" href="#gradients" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>我们可以连结一个多元函数对其所有变量的偏导数, 以得到该函数的梯度（gradient）向量。</p></li>
<li><p>具体而言，设函数  <span class="math notranslate nohighlight">\(f: \mathbb{R}^{n} \rightarrow \mathbb{R}\)</span>  的输入是一个  n  维向量  <span class="math notranslate nohighlight">\(\mathbf{x}=\left[x_{1}, x_{2}, \ldots, x_{n}\right]^{\top}\)</span> , 并且输出是一个标量。</p></li>
<li><p>函数  <span class="math notranslate nohighlight">\(f(\mathbf{x})\)</span>  相对于  <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>  的梯度是一个包含  n  个偏导数的向量:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\nabla_{\mathbf{x}} f(\mathbf{x})=\left[\frac{\partial f(\mathbf{x})}{\partial x_{1}}, \frac{\partial f(\mathbf{x})}{\partial x_{2}}, \ldots, \frac{\partial f(\mathbf{x})}{\partial x_{n}}\right]^{\top}\]</div>
<ul class="simple">
<li><p>其中  <span class="math notranslate nohighlight">\(\nabla_{\mathbf{x}} f(\mathbf{x})\)</span>  通常在没有歧义时被  <span class="math notranslate nohighlight">\(\nabla f(\mathbf{x})\)</span>  取代。</p></li>
<li><dl class="simple">
<dt>假设 x 为  n  维向量, 在微分多元函数时经常使用以下规则:</dt><dd><ul>
<li><p>对于所有  <span class="math notranslate nohighlight">\(\mathbf{A} \in \mathbb{R}^{m \times n}\)</span>  ，都有  <span class="math notranslate nohighlight">\(\nabla_{\mathbf{x}} \mathbf{A} \mathbf{x}=\mathbf{A}^{\top}\)</span></p></li>
<li><p>对于所有  <span class="math notranslate nohighlight">\(\mathbf{A} \in \mathbb{R}^{n \times m}\)</span>  ，都有  <span class="math notranslate nohighlight">\(\nabla_{\mathbf{x}} \mathbf{x}^{\top} \mathbf{A}=\mathbf{A}\)</span></p></li>
<li><p>对于所有  <span class="math notranslate nohighlight">\(\mathbf{A} \in \mathbb{R}^{n \times n}\)</span>  ，都有  <span class="math notranslate nohighlight">\(\nabla_{\mathbf{x}} \mathbf{x}^{\top} \mathbf{A} \mathbf{x}=\left(\mathbf{A}+\mathbf{A}^{\top}\right) \mathbf{x}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\nabla_{\mathbf{x}}\|\mathbf{x}\|^{2}=\nabla_{\mathbf{x}} \mathbf{x}^{\top} \mathbf{x}=2 \mathbf{x}\)</span></p></li>
</ul>
</dd>
</dl>
</li>
<li><p><span class="math notranslate nohighlight">\(|\mathbf{x}\|^{2} = \mathbf{x}^{\top} \mathbf{x}\)</span> 是向量 <strong>𝑥</strong> 的二范数平方</p></li>
<li><p>同样，对于任何矩阵  <span class="math notranslate nohighlight">\(\mathbf{X}\)</span>  ，都有  <span class="math notranslate nohighlight">\(\nabla_{\mathbf{X}}\|\mathbf{X}\|_{F}^{2}=2 \mathbf{X}\)</span> ，其中 <span class="math notranslate nohighlight">\(\|\mathbf{X}\|_{F}\)</span> 是 <strong>矩阵 Frobenius 范数</strong></p></li>
</ul>
</section>
</section>
<section id="automatic-differentiation">
<h4>2.5. Automatic Differentiation(自动微分)<a class="headerlink" href="#automatic-differentiation" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>深度学习框架通过自动计算导数，即自动微分（automatic differentiation）来加快求导。 实际中，根据设计好的模型，系统会构建一个计算图（computational graph）， 来跟踪计算是哪些数据通过哪些操作组合起来产生输出。 自动微分使系统能够随后反向传播梯度。 这里，反向传播（backpropagate）意味着跟踪整个计算图，填充关于每个参数的偏导数。</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>grad can be implicitly created only for scalar outputs 梯度默认给标量输出创建，就是说 y 应该是个标量</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">4.0</span><span class="p">)</span>       <span class="c1">#  tensor([0., 1., 2., 3.])</span>
<span class="n">x</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>      <span class="c1"># 等价于x=torch.arange(4.0,requires_grad=True)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;====1: </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>   <span class="c1"># None</span>
<span class="n">y</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;====2: y:</span><span class="si">{</span><span class="n">y</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>      <span class="c1"># tensor(28., grad_fn=&lt;MulBackward0&gt;)</span>
<span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;====3: x.grad:</span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>    <span class="c1"># tensor([ 0.,  4.,  8., 12.])</span>


<span class="c1"># 在默认情况下，PyTorch会累积梯度，我们需要清除之前的值</span>
<span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>  <span class="c1"># grad can be implicitly created only for scalar outputs</span>
<span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">x</span><span class="o">.</span><span class="n">grad</span>          <span class="c1"># tensor([1., 1., 1., 1.])</span>
</pre></div>
</div>
<section id="backward-for-non-scalar-variables">
<h5>Backward for Non-Scalar Variables<a class="headerlink" href="#backward-for-non-scalar-variables" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt>在数学中，当 𝑦 是一个向量，𝑥 也是一个向量时，𝑦 对 𝑥 的导数是一个 Jacobian 矩阵。</dt><dd><ul>
<li><p>Jacobian 矩阵的每个元素表示 𝑦 的每个分量对 𝑥 的每个分量的偏导数。</p></li>
<li><p>如果 𝑦 和 𝑥 的维度都很高，求导的结果会是一个更高阶的张量。</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>但在深度学习中，我们通常不需要直接计算 Jacobian 矩阵，而是希望将结果进行汇总，最终得到一个和 𝑥 形状相同的向量（即梯度）</p></li>
</ul>
<p>PyTorch 的处理方式:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>如果对 非标量张量直接调用 .backward()，会报错。
    RuntimeError: grad can be implicitly created only for scalar outputs
因为框架无法自动决定如何将非标量处理成标量。
我们需要提供一个向量（通常称为 gradient 参数），来告诉 PyTorch如何汇总梯度
    y = x * x  # 假设 y 是一个向量
    y.backward(gradient=torch.ones(len(y)))
实际上更快的方式是直接对 𝑦 求和后再调用 .backward()
    y.sum().backward()
</pre></div>
</div>
<p>示例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>
<span class="go">tensor([0., 1., 2., 3.], requires_grad=True)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="o">.</span><span class="n">grad</span>
<span class="go">tensor([0., 2., 4., 6.])</span>
<span class="go"># 说明</span>
<span class="go">#   y = x1*x1 + x2*x2 + ... + xi*xi</span>
<span class="go">#   导数: [2x1, 2x2, ..., 2xi]</span>
<span class="go">#   即: [0, 2, 4, 6]</span>


<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="o">.</span><span class="n">grad</span>
<span class="go">tensor([0.0000, 0.5000, 1.0000, 1.5000])</span>
<span class="go"># 说明</span>
<span class="go">#   y = 1/i(x1*x1 + x2*x2 + ... + xi*xi)</span>
<span class="go">#   导数: 1/i([2x1, 2x2, ..., 2xi])</span>
<span class="go">#   即: 1/4([0, 2, 4, 6])</span>
<span class="go">#       [0.0000, 0.5000, 1.0000, 1.5000]</span>
</pre></div>
</div>
</section>
<section id="detaching-computation">
<h5>Detaching Computation<a class="headerlink" href="#detaching-computation" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>有时，我们希望将某些计算移动到记录的计算图之外。</p></li>
<li><p>例如，假设y是作为x的函数计算的，而z则是作为y和x的函数计算的。</p></li>
<li><p>想计算z关于x的梯度，但由于某种原因，希望将y视为一个常数， 并且只考虑到x在y被计算后发挥的作用。</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">4.0</span><span class="p">,</span><span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">x</span>
<span class="c1"># tensor([0., 1., 2., 3.], requires_grad=True)</span>

<span class="c1"># 梯度计算分离y</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">u</span> <span class="o">*</span> <span class="n">x</span>
<span class="n">z</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">x</span><span class="o">.</span><span class="n">grad</span>
<span class="c1"># tensor([0., 1., 4., 9.])</span>

<span class="c1"># 梯度计算不分离y</span>
<span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
<span class="n">z</span><span class="o">=</span><span class="n">y</span> <span class="o">*</span> <span class="n">x</span>
<span class="n">z</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">x</span><span class="o">.</span><span class="n">grad</span>
<span class="c1"># tensor([ 0.,  3., 12., 27.])</span>
</pre></div>
</div>
</section>
<section id="gradients-and-python-control-flow">
<h5>Gradients and Python Control Flow<a class="headerlink" href="#gradients-and-python-control-flow" title="此标题的永久链接">¶</a></h5>
<ul>
<li><p>使用自动微分的一个好处是： 即使构建函数的计算图需要通过Python控制流（例如，条件、循环或任意函数调用），我们仍然可以计算得到的变量的梯度</p></li>
<li><p>示例-while循环的迭代次数和if语句的结果都取决于输入a的值:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">f</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="mi">2</span>
    <span class="k">while</span> <span class="n">b</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">1000</span><span class="p">:</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">b</span> <span class="o">*</span> <span class="mi">2</span>
    <span class="k">if</span> <span class="n">b</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">b</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">c</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">b</span>
    <span class="k">return</span> <span class="n">c</span>
</pre></div>
</div>
</li>
</ul>
<p>计算梯度:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>    <span class="c1"># tensor(0.0412, requires_grad=True)</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>                                        <span class="c1"># tensor(1350.7505, grad_fn=&lt;MulBackward0&gt;)</span>
<span class="n">d</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">a</span><span class="o">.</span><span class="n">grad</span>
<span class="c1"># tensor(32768.)</span>
<span class="n">a</span><span class="o">.</span><span class="n">grad</span> <span class="o">==</span> <span class="n">d</span> <span class="o">/</span> <span class="n">a</span>     <span class="c1"># 不管怎么算，对a的梯度就是除a外的常数,因为f(a)=常数*a</span>
<span class="c1"># tensor(True)</span>
</pre></div>
</div>
</section>
</section>
<section id="probability-and-statistics">
<h4>2.6 Probability and Statistics<a class="headerlink" href="#probability-and-statistics" title="此标题的永久链接">¶</a></h4>
<section id="id5">
<h5>基本概率论<a class="headerlink" href="#id5" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>在统计学中，我们把从概率分布中抽取样本的过程称为抽样（sampling）</p></li>
</ul>
<section id="id6">
<h6>概率论公理<a class="headerlink" href="#id6" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>在处理骰子掷出示例时，我们将集合 <code class="docutils literal notranslate"><span class="pre">S={1,2,3,4,5,6}</span></code> 称为 <strong>样本空间（sample space）或结果空间（outcome space）</strong> ， 其中每个元素都是结果（outcome）。</p></li>
<li><p><strong>事件（event）</strong> 是一组给定样本空间的随机结果。 例如，“看到5”（ <code class="docutils literal notranslate"><span class="pre">{5}</span></code> ）和“看到奇数”（ <code class="docutils literal notranslate"><span class="pre">{1,3,5}</span></code> ）都是掷出骰子的有效事件。 注意，如果一个随机实验的结果在 <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> 中，则事件 <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> 已经发生。 也就是说，如果投掷出 3 点，因为 <span class="math notranslate nohighlight">\(3 \in {1,3,5}\)</span> ，我们可以说，“看到奇数”的事件发生了。</p></li>
<li><dl class="simple">
<dt><strong>概率（probability）</strong> 可以被认为是将集合映射到真实值的函数。在给定的样本空间  <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>  中, 事件  <span class="math notranslate nohighlight">\(\mathcal{A}\)</span>  的概率, 表示为  <span class="math notranslate nohighlight">\(P(\mathcal{A})\)</span> , 满足以下属性：</dt><dd><ul>
<li><p>对于任意事件  <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> , 其概率从不会是负数, 即  <span class="math notranslate nohighlight">\(P(\mathcal{A}) \geq 0\)</span> ;</p></li>
<li><p>整个样本空间的概率为 1 , 即 <span class="math notranslate nohighlight">\(P(\mathcal{S})=1\)</span> ;</p></li>
<li><p>对于互斥（mutually exclusive）事件（对于所有  <span class="math notranslate nohighlight">\(i \neq j\)</span>  都有  <span class="math notranslate nohighlight">\(\mathcal{A}_{i} \cap \mathcal{A}_{j}=\emptyset\)</span>  ）的任意一个可数序列 <span class="math notranslate nohighlight">\(\mathcal{A}_{1}, \mathcal{A}_{2}, \ldots\)</span> ，序列中任意一个事件发生的概率等于它们各自发生的概率之和, 即  <span class="math notranslate nohighlight">\(P\left(\bigcup_{i=1}^{\infty} \mathcal{A}_{i}\right)=\sum_{i=1}^{\infty} P\left(\mathcal{A}_{i}\right)\)</span>  。</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>上面这个就是概率论的公理，由科尔莫戈罗夫于1933年提出</p></li>
</ul>
</section>
<section id="id7">
<h6>随机变量<a class="headerlink" href="#id7" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>随机变量（random variable）</p></li>
<li><p><span class="math notranslate nohighlight">\(P(\mathcal{X} = a)\)</span> 我们区分了随机变量 <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> 和这个随机变量可以采取的值（例如a）</p></li>
<li><p>为了简化符号</p></li>
<li><p>一方面，我们可以将 <code class="docutils literal notranslate"><span class="pre">P(X)</span></code> 表示为随机变量 <code class="docutils literal notranslate"><span class="pre">X</span></code> 上的分布（distribution）： 分布告诉我们 <code class="docutils literal notranslate"><span class="pre">X</span></code> 获得某一值的概率；另一方面，我们可以简单用 <code class="docutils literal notranslate"><span class="pre">P(a)</span></code> 表示随机变量取值 a 的概率</p></li>
<li><p>一方面，我们可以将 <code class="docutils literal notranslate"><span class="pre">P(1&lt;=X&lt;=3)</span></code> 表示事件 <code class="docutils literal notranslate"><span class="pre">{1&lt;=X&lt;=3}</span></code> 的概率；另一方面， <code class="docutils literal notranslate"><span class="pre">P(1&lt;=X&lt;=3)</span></code> 表示随机变量 <code class="docutils literal notranslate"><span class="pre">X</span></code> 从 <cite>{1,2,3}</cite> 中取值的概率</p></li>
<li><p>注意：离散（discrete）随机变量（如骰子的每一面） 和连续（continuous）随机变量（如人的体重和身高）之间存在微妙的区别</p></li>
</ul>
</section>
</section>
<section id="id8">
<h5>处理多个随机变量<a class="headerlink" href="#id8" title="此标题的永久链接">¶</a></h5>
<section id="id9">
<h6>联合概率<a class="headerlink" href="#id9" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>联合概率（joint probability）  <code class="docutils literal notranslate"><span class="pre">P(A=a,</span> <span class="pre">B=b)</span></code> : 给定任意值  a  和  b , 联合概率可以回答:  A=a  和  B=b  同时满足的概率是多少?</p></li>
<li><p>请注意, 对于任何  a  和  b  的取值,  <span class="math notranslate nohighlight">\(P(A=a, B=b) \leq P(A=a)\)</span>  。 这点是确定的, 因为要同时发生  <code class="docutils literal notranslate"><span class="pre">A=a</span>&#160; <span class="pre">和</span>&#160; <span class="pre">B=b</span></code> , <code class="docutils literal notranslate"><span class="pre">A=a</span></code>  就必须发生</p></li>
</ul>
</section>
<section id="id10">
<h6>条件概率<a class="headerlink" href="#id10" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>联合概率的不等式带给我们一个有趣的比率： <span class="math notranslate nohighlight">\(0 \leq \frac{P(A=a, B=b)}{P(A=a)} \leq 1\)</span></p></li>
<li><p>我们称这个比率为条件概率（conditional probability）, 并用  <span class="math notranslate nohighlight">\(P(B=b \mid A=a)\)</span>  表示它：在 <code class="docutils literal notranslate"><span class="pre">A=b</span></code> 前提下  <code class="docutils literal notranslate"><span class="pre">B=b</span></code>  的概率。</p></li>
</ul>
</section>
<section id="id11">
<h6>贝叶斯定理<a class="headerlink" href="#id11" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>使用条件概率的定义，我们可以得出统计学中最有用的方程之一： <strong>贝叶斯定理（Bayes’ theorem）</strong></p></li>
<li><p>根据 <strong>乘法法则（multiplication rule）</strong> 可得到  <span class="math notranslate nohighlight">\(P(A, B)=P(B \mid A) P(A)\)</span></p></li>
<li><p>根据对称性, 可得到  <span class="math notranslate nohighlight">\(P(A, B)=P(A \mid B) P(B)\)</span>  。假设  <code class="docutils literal notranslate"><span class="pre">P(B)&gt;0</span></code> , 求解其中一个条件变量, 我们得到</p></li>
</ul>
<div class="math notranslate nohighlight">
\[P(A \mid B)=\frac{P(B \mid A) P(A)}{P(B)}\]</div>
<ul class="simple">
<li><p>P(A, B)  是一个联合分布（joint distribution）</p></li>
<li><p>P(A mid B)  是一个条件分布（conditional distribution）</p></li>
</ul>
</section>
<section id="id12">
<h6>边际化<a class="headerlink" href="#id12" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>边际化(marginalization)：为了能进行事件概率求和, 我们需要 <code class="docutils literal notranslate"><span class="pre">求和法则</span> <span class="pre">(sum</span> <span class="pre">rule)</span></code> , 即  B  的概率相当于计算  A  的所有可能选择, 并将所有选择的联合概率聚合在一起:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[P(B)=\sum_{A} P(A, B)\]</div>
<ul class="simple">
<li><p>边际化结果的概率或分布称为边际概率（marginal probability） 或边际分布（marginal distribution）。</p></li>
</ul>
</section>
<section id="id13">
<h6>独立性<a class="headerlink" href="#id13" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>另一个有用属性是依赖（dependence）与独立（independence）。</p></li>
<li><p>如果两个随机变量  A  和  B  是独立的，意味着事件  A  的发生跟  B  事件的发生无关。在这种情况下，统计学家通常将这一点表述为  <span class="math notranslate nohighlight">\(A \perp B\)</span></p></li>
<li><p>根据贝叶斯定理，马上就能同样得到  <span class="math notranslate nohighlight">\(P(A \mid B)=P(A)\)</span></p></li>
<li><p>在所有其他情况下，我们称  A  和  B  依赖。</p></li>
<li><p>比如，两次连续抛出一个骰子的事件是相互独立的。相比之下，灯开关的位置和房间的亮度并不是（因为可能存在灯泡坏掉、电源故障，或者开关故障）</p></li>
<li><p>如果 A  和  B  是独立的，则 <span class="math notranslate nohighlight">\(P(A \mid B)=\frac{P(A, B)}{P(B)}=P(A)\)</span>  等价于  <span class="math notranslate nohighlight">\(P(A, B)=P(A) P(B)\)</span> =》结论：当且仅当两个随机变量是独立的，两个随机变量的联合分布是其各自分布的乘积</p></li>
<li><p>同样地, 给定另一个随机变量  C  时, 两个随机变量  A  和  B  是条件独立的（conditionally independent），有 <span class="math notranslate nohighlight">\(P(A, B \mid C)=P(A \mid C) P(B \mid C)\)</span></p></li>
<li><p>这个情况表示为  <span class="math notranslate nohighlight">\(A \perp B \mid C\)</span></p></li>
</ul>
</section>
<section id="id14">
<h6>应用示例<a class="headerlink" href="#id14" title="此标题的永久链接">¶</a></h6>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>条件概率</p></th>
<th class="head"><p>H=1</p></th>
<th class="head"><p>H=0</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(P(D_1 = 1 \mid H)\)</span></p></td>
<td><p>1</p></td>
<td><p>0.01</p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(P(D_1 = 0 \mid H)\)</span></p></td>
<td><p>0</p></td>
<td><p>0.99</p></td>
</tr>
</tbody>
</table>
<ul class="simple">
<li><p>如果 <span class="math notranslate nohighlight">\(P(H=1) = 0.0015\)</span></p></li>
<li><p>运用边际化和乘法法则来确定</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
&amp;P(D_1 = 1) \\
=&amp; P(D_1=1, H=0) + P(D_1=1, H=1)  \\
=&amp; P(D_1=1 \mid H=0) P(H=0) + P(D_1=1 \mid H=1) P(H=1) \\
=&amp; 0.01 * (1-0.0015) + 1*0.0015
=&amp; 0.011485.
\end{aligned}\end{split}\]</div>
<ul class="simple">
<li><p>于是</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    &amp;P(H = 1 \mid D_1 = 1)\\
    =&amp; \frac{P(D_1=1 \mid H=1) P(H=1)}{P(D_1=1)} \\
    =&amp; (1*0.0015)/0.011485
    =&amp; 0.1306
\end{aligned}\end{split}\]</div>
<ul class="simple">
<li><p>第2次的测试概率</p></li>
</ul>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>条件概率</p></th>
<th class="head"><p>H=1</p></th>
<th class="head"><p>H=0</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(P(D_2 = 1 \mid H)\)</span></p></td>
<td><p>0.98</p></td>
<td><p>0.03</p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(P(D_2 = 0 \mid H)\)</span></p></td>
<td><p>0.02</p></td>
<td><p>0.97</p></td>
</tr>
</tbody>
</table>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
&amp;P(D_1 = 1, D_2 = 1 \mid H = 0) \\
=&amp; P(D_1 = 1 \mid H = 0) P(D_2 = 1 \mid H = 0)  \\
=&amp; 0.01*0.03
=&amp; 0.0003,
\end{aligned}\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
&amp;P(D_1 = 1, D_2 = 1 \mid H = 1) \\
=&amp; P(D_1 = 1 \mid H = 1) P(D_2 = 1 \mid H = 1)  \\
=&amp; 1*0.98
=&amp; 0.98.
\end{aligned}\end{split}\]</div>
<ul class="simple">
<li><p>现在我们可以应用边际化和乘法规则：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
&amp;P(D_1 = 1, D_2 = 1) \\
=&amp; P(D_1 = 1, D_2 = 1, H = 0) + P(D_1 = 1, D_2 = 1, H = 1)  \\
=&amp; P(D_1 = 1, D_2 = 1 \mid H = 0)P(H=0) + P(D_1 = 1, D_2 = 1 \mid H = 1)P(H=1)\\
=&amp; 0.0003*(1-0.0015) + 0.98*0.0015
=&amp; 0.00176955.
\end{aligned}\end{split}\]</div>
<ul class="simple">
<li><p>最后，鉴于存在两次阳性检测，患者患有艾滋病的概率为</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
&amp;P(H = 1 \mid D_1 = 1, D_2 = 1)\\
=&amp; \frac{P(D_1 = 1, D_2 = 1 \mid H=1) P(H=1)}{P(D_1 = 1, D_2 = 1)} \\
=&amp; 0.98*0.0015/0.00176955
=&amp; 0.8307.
\end{aligned}\end{split}\]</div>
</section>
</section>
<section id="id15">
<h5>期望和方差<a class="headerlink" href="#id15" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt>假设某项投资有：</dt><dd><ul>
<li><p>50% 的概率会失败</p></li>
<li><p>40% 的概率它可能提供 2倍回报</p></li>
<li><p>10% 的概率它可能会提供 10 倍回报 。</p></li>
<li><p>计算预期回报，我们总结了所有回报，将每个回报乘以它们发生的概率。</p></li>
<li><p>期望= <code class="docutils literal notranslate"><span class="pre">0.5*0</span> <span class="pre">+</span> <span class="pre">0.4*2</span> <span class="pre">+</span> <span class="pre">0.1*10</span></code></p></li>
<li><p>因此 预期回报率为1.8</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<p>一个随机变量 X 的 <strong>期望(expectation)/平均值(average)</strong> 表示为</p>
<div class="math notranslate nohighlight">
\[E[X] = E_{x \sim P}[x] =  \sum_{x} x P(X = x).\]</div>
<ul class="simple">
<li><p>当函数 <code class="docutils literal notranslate"><span class="pre">f(x)</span></code> 的输入是从分布 <code class="docutils literal notranslate"><span class="pre">P</span></code> 中抽取的随机变量时， <code class="docutils literal notranslate"><span class="pre">f(x)</span></code> 的期望值为</p></li>
</ul>
<div class="math notranslate nohighlight">
\[E_{x \sim P}[f(x)] = \sum_x f(x) P(x)\]</div>
<p>一个随机变量 X 的 <strong>密度</strong></p>
<ul class="simple">
<li><p>在许多情况下，我们希望衡量随机变量 <strong>X</strong> 与其期望值的偏置。这可以通过方差来量化</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\mathrm{Var}[X] = E\left[(X - E[X])^2\right] =
E[X^2] - E[X]^2\]</div>
<ul class="simple">
<li><p>方差的平方根被称为 <strong>标准差(standard deviation)</strong></p></li>
<li><p>随机变量函数的方差衡量的是：当从该随机变量分布中采样不同值 x 时，</p></li>
<li><p>函数值偏离该函数的期望的程度：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\mathrm{Var}[f(x)] = E\left[\left(f(x) - E[f(x)]\right)^2\right]\]</div>
</section>
</section>
</section>
<section id="linear-neural-networks-for-regression">
<h3>3. Linear Neural Networks for Regression<a class="headerlink" href="#linear-neural-networks-for-regression" title="此标题的永久链接">¶</a></h3>
<section id="linear-regression">
<h4>3.1. Linear Regression<a class="headerlink" href="#linear-regression" title="此标题的永久链接">¶</a></h4>
<section id="basics">
<h5>Basics<a class="headerlink" href="#basics" title="此标题的永久链接">¶</a></h5>
<section id="model">
<h6>Model<a class="headerlink" href="#model" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>在机器学习中，我们通常使用高维数据集，在这种情况下使用紧凑的线性代数表示法会更方便</p></li>
<li><p>当我们的输入由 d 特征组成时，我们可以为每个特征分配一个索引（在 1 和 d 之间）并表达我们的预测 <span class="math notranslate nohighlight">\(\hat{y}\)</span></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\hat{y} = w_1x_1 + \cdot + w_dx_d + b\]</div>
<ul class="simple">
<li><p>将所有 <strong>特征</strong> 收集到向量 <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathbb{R}^d\)</span> 中，并将所有 <strong>权重</strong> 收集到向量 <span class="math notranslate nohighlight">\(\mathbf{w} \in \mathbb{R}^d\)</span> 中，我们可以通过 <strong>x</strong> 和 <strong>w</strong> 向量的点积简洁的表达</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\hat{y} = \mathbf{w}^{\top}\mathbf{x} + b\]</div>
<ul class="simple">
<li><p>通过设计矩阵 <span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{n \times d}\)</span> 引用 n 个示例的整个数据集的特征很方便。这里， <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 包含每个示例(行)和每个功能(列)。对于特征集合 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> ，预测 <span class="math notranslate nohighlight">\(\hat{y} \in \mathbb{R}^n\)</span> 可以通过矩阵向量积表示</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\hat{y} = \mathbf{X}\mathbf{w} + b\]</div>
</section>
<section id="loss-function">
<h6>Loss Function<a class="headerlink" href="#loss-function" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>损失函数量化目标的实际值和预测值之间的距离。损失通常是一个非负数，其中值越小越好，完美的预测会导致损失为 0。</p></li>
<li><p>对于回归问题，最常见的损失函数是平方误差。</p></li>
<li><p>对示例 i 的预测为 <span class="math notranslate nohighlight">\(\hat{y}^{(i)}\)</span> 且相应的真实标签为 <span class="math notranslate nohighlight">\(y^{(i)}\)</span> 时，平方误差由下式给出：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[l^{(i)}(\mathbf{w}, b) = \frac{1}{2} \left(\hat{y}^{(i)}-y^{(i)}\right)^2\]</div>
<p>注意，由于其二次方形式，估计  <span class="math notranslate nohighlight">\(\hat{y}^{(i)}\)</span> 和目标 <span class="math notranslate nohighlight">\(y^{(i)}\)</span> 之间的巨大差异会导致对损失的影响更大（这种二次方的特性可能是一把双刃剑；虽然它鼓励模型以避免大错误，也可能导致对异常数据过度敏感）。为了衡量
n 个示例的数据集上的整体模型质量，我们只需对训练集上的损失进行平均即可</p>
<div class="math notranslate nohighlight">
\[L(\mathbf{w}, b)=\frac{1}{n} \sum_{i=1}^{n} l^{(i)}(\mathbf{w}, b)
                =\frac{1}{n} \sum_{i=1}^{n} \frac{1}{2} \left(\hat{y}^{(i)}-y^{(i)}\right)^{2}
                =\frac{1}{n} \sum_{i=1}^{n} \frac{1}{2}\left(\mathbf{w}^{\top} \mathbf{x}^{(i)}+b-y^{(i)}\right)^{2}\]</div>
<p>训练模型时, 我们寻求能够最小化所有训练示例的总损失的参数  <span class="math notranslate nohighlight">\(\left(\mathbf{w}^{*}, b^{*}\right)\)</span> :</p>
<div class="math notranslate nohighlight">
\[\mathbf{w}^{*}, b^{*}=\underset{\mathbf{w}, b}{\operatorname{argmin}} L(\mathbf{w}, b) .\]</div>
</section>
<section id="analytic-solution">
<h6>Analytic Solution(解析解)<a class="headerlink" href="#analytic-solution" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>线性回归的解可以用一个公式简单地表达出来， 这类解叫作解析解（analytical solution）。</p></li>
<li><p>线性回归的目标是找到一组参数 <strong>w</strong> 和偏置 b，使得预测值与真实值之间的误差最小化。为了简化问题，可以将偏置项 b 合并到参数向量 <strong>w</strong> 中，方法是在设计矩阵 <strong>X</strong> 的每一行末尾添加一个1，从而将偏置视为权重的一部分。</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>像线性回归这样的简单问题存在解析解，但并不是所有的问题都存在解析解。 解析解可以进行很好的数学分析，但解析解对问题的限制很严格，导致它无法广泛应用在深度学习里。</p>
</div>
</section>
<section id="minibatch-stochastic-gradient-descent">
<h6>Minibatch Stochastic Gradient Descent<a class="headerlink" href="#minibatch-stochastic-gradient-descent" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>梯度下降（gradient descent）：它通过不断地在损失函数递减的方向上更新参数来降低误差。梯度下降最简单的用法是计算损失函数（数据集中所有样本的损失均值） 关于模型参数的导数（在这里也可以称为梯度）</p></li>
<li><p>小批量随机梯度下降（minibatch stochastic gradient descent）：在每次需要计算更新的时候随机抽取一小批样本的梯度下降。使用小批量随机梯度下降是因为梯度下降在实际中的执行可能会非常慢：原因是在每一次更新参数之前，我们必须遍历整个数据集。</p></li>
</ul>
<p>在每次迭代中，我们首先随机抽样一个小批量 <span class="math notranslate nohighlight">\(\mathcal{B}\)</span> ， 它是由固定数量的训练样本组成的。 然后，我们计算小批量的平均损失关于模型参数的导数（也可以称为梯度）。 最后，我们将梯度乘以一个预先确定的正数 <span class="math notranslate nohighlight">\(\eta\)</span> ，并从当前参数的值中减掉。</p>
<ul class="simple">
<li><p>我们用下面的数学公式来表示这一更新过程（  <span class="math notranslate nohighlight">\(\partial\)</span>  表示偏导数）：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[(\mathbf{w}, b) \leftarrow(\mathbf{w}, b)-\frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \partial_{(\mathbf{w}, b)} l^{(i)}(\mathbf{w}, b) .\]</div>
<p>总结一下，算法的步骤如下：（1）初始化模型参数的值，如随机初始化；（2）从数据集中随机抽取小批量样本且在负梯度的方向上更新参数，并不断迭代这一步骤。对于平方损失和仿射变换，我们可以明确地写成如下形式:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\mathbf{w} &amp; \leftarrow \mathbf{w}-\frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \partial_{\mathbf{w}} l^{(i)}(\mathbf{w}, b)=\mathbf{w}-\frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \mathbf{x}^{(i)}\left(\mathbf{w}^{\top} \mathbf{x}^{(i)}+b-y^{(i)}\right) \\
b &amp; \leftarrow b-\frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \partial_{b} l^{(i)}(\mathbf{w}, b)=b-\frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}}\left(\mathbf{w}^{\top} \mathbf{x}^{(i)}+b-y^{(i)}\right)
\end{aligned}\end{split}\]</div>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>更艰巨的任务是找到能够对以前未见过的数据进行准确预测的参数，这一挑战称为泛化。The more formidable task is to find parameters that lead to accurate predictions on previously unseen data, a challenge called generalization.</p>
</div>
</section>
<section id="predictions">
<h6>Predictions(预测)<a class="headerlink" href="#predictions" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>给定模型 <span class="math notranslate nohighlight">\(\hat{\mathbf{w}}^{\top}\mathbf{x} + \hat{b}\)</span> ，我们现在可以对新示例进行预测(有时也称推理)</p></li>
</ul>
</section>
</section>
<section id="vectorization-for-speed">
<h5>Vectorization for Speed<a class="headerlink" href="#vectorization-for-speed" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>使用torch向量库比直接使用for循环要快3个数量级</p></li>
</ul>
</section>
<section id="the-normal-distribution-and-squared-loss">
<h5>The Normal Distribution and Squared Loss<a class="headerlink" href="#the-normal-distribution-and-squared-loss" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>正态分布的公式</p></li>
</ul>
<div class="math notranslate nohighlight">
\[f(x)=\frac{1}{\sqrt{2 \pi \sigma^2}} e^{-\frac{(x-\mu)^2}{2 \sigma^2}}\]</div>
<p>其中:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>μ：均值（mean），表示分布的中心。
𝜎^2 ：方差（variance），表示分布的宽度，反映数据的离散程度

𝜎 越大，分布越宽、越平
𝜎 越小，分布越窄、越尖
</pre></div>
</div>
</section>
<section id="linear-regression-as-a-neural-network">
<h5>Linear Regression as a Neural Network<a class="headerlink" href="#linear-regression-as-a-neural-network" title="此标题的永久链接">¶</a></h5>
<figure class="align-default" id="id219">
<img alt="https://img.zhaoweiguo.com/uPic/2024/12/LjmKJJ.png" src="https://img.zhaoweiguo.com/uPic/2024/12/LjmKJJ.png" />
<figcaption>
<p><span class="caption-text">由树突（dendrites，输入终端）、 细胞核（nucleus，CPU）组成的生物神经元图片。 轴突（axon，输出线）和轴突端子（axon terminal，输出端子） 通过突触（synapse）与其他神经元连接。consisting of <code class="docutils literal notranslate"><span class="pre">dendrites</span></code> (input terminals), the <code class="docutils literal notranslate"><span class="pre">nucleus</span></code> (CPU), the <code class="docutils literal notranslate"><span class="pre">axon</span></code> (output wire), and the <code class="docutils literal notranslate"><span class="pre">axon</span> <span class="pre">terminals</span></code> (output terminals), enabling connections to other neurons via <code class="docutils literal notranslate"><span class="pre">synapses</span></code>.</span><a class="headerlink" href="#id219" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>过程：来自其他神经元（或环境传感器）的信息 <span class="math notranslate nohighlight">\(x_i\)</span> 在树突中被接收。特别是，该信息通过突触权重 <span class="math notranslate nohighlight">\(w_i\)</span> 进行加权，确定输入的效果，例如通过产品 <span class="math notranslate nohighlight">\(x_i w_i\)</span> 激活或抑制。来自多个源的加权输入在核中聚合为加权和 <span class="math notranslate nohighlight">\(y=\sum_i{x_i w_i} + b\)</span> ，可能通过函数 <span class="math notranslate nohighlight">\(\sigma(y)\)</span> 进行一些非线性后处理。然后，该信息通过轴突发送到轴突末端，在那里到达目的地（例如肌肉等执行器），或者通过树突馈送到另一个神经元。</p>
</div>
</section>
</section>
<section id="object-oriented-design-for-implementation">
<h4>3.2. Object-Oriented Design for Implementation<a class="headerlink" href="#object-oriented-design-for-implementation" title="此标题的永久链接">¶</a></h4>
<p>实现了几个对象类:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">HyperParameters</span>
<span class="n">ProgressBoard</span>
<span class="n">Module</span>
<span class="n">DataModule</span>
<span class="n">Trainer</span>
</pre></div>
</div>
</section>
<section id="synthetic-regression-data">
<h4>3.3. Synthetic Regression Data<a class="headerlink" href="#synthetic-regression-data" title="此标题的永久链接">¶</a></h4>
<ul>
<li><p>分别介绍了使用 <strong>生成数据集</strong> 和 <strong>读取数据集</strong></p></li>
<li><p>还介绍了使用 <code class="docutils literal notranslate"><span class="pre">torch.utils.data.TensorDataset</span></code> 和 <code class="docutils literal notranslate"><span class="pre">torch.utils.data.DataLoader</span></code> 的简洁实现</p></li>
<li><p>实现数据加载器对象类:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">SyntheticRegressionData</span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="linear-regression-implementation-from-scratch">
<h4>3.4. Linear Regression Implementation from Scratch<a class="headerlink" href="#linear-regression-implementation-from-scratch" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>从头开始实现整个方法，包括（i）模型； (ii) 损失函数； (iii) 小批量随机梯度下降优化器； (iv) 将所有这些部分拼接在一起的训练函数。</p></li>
</ul>
<section id="defining-the-model">
<h5>3.4.1. Defining the Model<a class="headerlink" href="#defining-the-model" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 从平均值为 0、标准差为 0.01 的正态分布中抽取随机数来初始化权重</span>
<span class="c1"># 魔法数字 0.01 在实践中通常效果很好</span>
<span class="k">class</span><span class="w"> </span><span class="nc">LinearRegressionScratch</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The linear regression model implemented from scratch.&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># 生成的 forward 方法</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span>
</pre></div>
</div>
</section>
<section id="defining-the-loss-function">
<h5>3.4.2. Defining the Loss Function<a class="headerlink" href="#defining-the-loss-function" title="此标题的永久链接">¶</a></h5>
<p>返回小批量中所有示例的平均损失值(使用平方损失函数):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">LinearRegressionScratch</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">l</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_hat</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="mi">2</span>
    <span class="k">return</span> <span class="n">l</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="defining-the-optimization-algorithm">
<h5>3.4.3. Defining the Optimization Algorithm<a class="headerlink" href="#defining-the-optimization-algorithm" title="此标题的永久链接">¶</a></h5>
<p>SGD(随机梯度下降) 优化器:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">SGD</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">HyperParameters</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Minibatch stochastic gradient descent.&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">lr</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">:</span>
            <span class="n">param</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">*</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
</pre></div>
</div>
<p>定义 configure_optimizers 方法，它返回 SGD 类的实例:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">LinearRegressionScratch</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">SGD</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="training">
<h5>3.4.4. Training<a class="headerlink" href="#training" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt>执行以下循环（小批量随机梯度下降）</dt><dd><ul>
<li><p>Initialize parameters  <span class="math notranslate nohighlight">\((\mathbf{w}, b)\)</span></p></li>
<li><dl class="simple">
<dt>Repeat until done</dt><dd><ul>
<li><p>Compute gradient <span class="math notranslate nohighlight">\(\mathbf{g} \leftarrow \partial_{(\mathbf{w}, b)} \frac{1}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} l\left(\mathbf{x}^{(i)}, y^{(i)}, \mathbf{w}, b\right)\)</span></p></li>
<li><p>Update parameters <span class="math notranslate nohighlight">\((\mathbf{w}, b) \leftarrow(\mathbf{w}, b)-\eta \mathbf{g}\)</span></p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
</ul>
<ul class="simple">
<li><p>在每个 epoch 传递一次验证数据加载器来测量模型性能</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Trainer</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">prepare_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">batch</span>

<span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Trainer</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">fit_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">training_step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prepare_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gradient_clip_val</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># To be discussed later</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradients</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gradient_clip_val</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_batch_idx</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_dataloader</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_dataloader</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prepare_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_batch_idx</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>
</div>
<p>使用学习率 <code class="docutils literal notranslate"><span class="pre">lr=0.03</span></code> 训练模型并设置 <code class="docutils literal notranslate"><span class="pre">max_epochs=3</span></code></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegressionScratch</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.03</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">SyntheticRegressionData</span><span class="p">(</span><span class="n">w</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.4</span><span class="p">]),</span> <span class="n">b</span><span class="o">=</span><span class="mf">4.2</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;error in estimating w: </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">w</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">model</span><span class="o">.</span><span class="n">w</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;error in estimating b: </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">b</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">model</span><span class="o">.</span><span class="n">b</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="c1"># error in estimating w: tensor([ 0.1408, -0.1493])</span>
<span class="c1"># error in estimating b: tensor([0.2130])</span>
</pre></div>
</div>
</section>
</section>
<section id="concise-implementation-of-linear-regression">
<h4>3.5. Concise Implementation of Linear Regression<a class="headerlink" href="#concise-implementation-of-linear-regression" title="此标题的永久链接">¶</a></h4>
<section id="id16">
<h5>3.5.1. Defining the Model<a class="headerlink" href="#id16" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">LinearRegression</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The linear regression model implemented with high-level APIs.&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id17">
<h5>3.5.2. Defining the Loss Function<a class="headerlink" href="#id17" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">LinearRegression</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id18">
<h5>3.5.3. Defining the Optimization Algorithm<a class="headerlink" href="#id18" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">LinearRegression</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id19">
<h5>3.5.4. Training<a class="headerlink" href="#id19" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.03</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">SyntheticRegressionData</span><span class="p">(</span><span class="n">w</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.4</span><span class="p">]),</span> <span class="n">b</span><span class="o">=</span><span class="mf">4.2</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>估计参数与其真实的对应参数的对比</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">LinearRegression</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_w_b</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="n">w</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_w_b</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;error in estimating w: </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">w</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">w</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;error in estimating b: </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">b</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">b</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="generalization">
<h4>3.6. Generalization<a class="headerlink" href="#generalization" title="此标题的永久链接">¶</a></h4>
<section id="training-error-and-generalization-error">
<h5>3.6.1. Training Error and Generalization Error<a class="headerlink" href="#training-error-and-generalization-error" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>训练误差表示为总和(训练数据集上计算的统计量)</p></li>
<li><p>训练误差是在训练集上计算的误差，是一个统计量。</p></li>
<li><p>它反映模型在训练集上的拟合程度。</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}R_{\mathrm{emp}}[\mathbf{X}, \mathbf{y}, f]=\frac{1}{n} \sum_{i=1}^{n} l\left(\mathbf{x}^{(i)}, y^{(i)}, f\left(\mathbf{x}^{(i)}\right)\right)\\\end{split}\]</div>
<ul class="simple">
<li><p>泛化误差则表示为积分(integral)</p></li>
<li><p>泛化误差是在真实分布上的误差，是一个期望。</p></li>
<li><p>泛化误差是对无限多数据样本的期望。</p></li>
<li><p>泛化误差是对基础分布的预期: 可以将泛化错误视为如果您将模型应用于从同一基础数据分布中提取的无限附加数据示例流</p></li>
</ul>
<div class="math notranslate nohighlight">
\[R[p, f]=E_{(\mathbf{x}, y) \sim P}[l(\mathbf{x}, y, f(\mathbf{x}))]=\iint l(\mathbf{x}, y, f(\mathbf{x})) p(\mathbf{x}, y) d \mathbf{x} d y\]</div>
<ul class="simple">
<li><p>有问题的是，我们永远无法准确计算泛化误差 <span class="math notranslate nohighlight">\(R\)</span></p></li>
<li><p>真实数据分布 <span class="math notranslate nohighlight">\(p(\mathbf{x}, y)\)</span> 是未知的，我们无法直接得到真实分布。</p></li>
<li><p>无法获取无限数据，只能在有限的训练集和测试集上进行评估。</p></li>
<li><p>因此，泛化误差只能通过测试集近似估计，而非精确计算。</p></li>
<li><p>在实践中，我们必须通过将我们的模型应用到一个独立的测试集来估计泛化误差，该测试集由随机选择的示例 <span class="math notranslate nohighlight">\(X‘\)</span> 和从我们的训练集中保留的标签 <span class="math notranslate nohighlight">\(y‘\)</span> 组成。这包括将用于计算经验训练误差的相同公式应用于测试集 <span class="math notranslate nohighlight">\(X‘, y‘\)</span> 。</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>请注意，我们最终得到的模型明确取决于训练集的选择，因此训练误差通常是对基础总体真实误差的有偏估计。泛化的核心问题是我们什么时候应该期望我们的训练误差接近总体误差（以及泛化误差）。</p>
</div>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>【总结】训练误差是对训练数据的拟合程度，而泛化误差反映模型在真实分布上的表现。泛化误差无法直接计算，但可以通过测试集估计。泛化的核心问题是如何使训练误差与泛化误差尽可能接近，从而确保模型在新数据上的表现良好。</p>
</div>
</section>
<section id="underfitting-or-overfitting">
<h5>3.6.2. Underfitting or Overfitting?<a class="headerlink" href="#underfitting-or-overfitting" title="此标题的永久链接">¶</a></h5>
<figure class="align-default" id="id220">
<img alt="https://img.zhaoweiguo.com/uPic/2024/12/AhEHKr.png" src="https://img.zhaoweiguo.com/uPic/2024/12/AhEHKr.png" />
<figcaption>
<p><span class="caption-text">Fig. 3.6.1 Influence of model complexity on underfitting and overfitting.¶</span><a class="headerlink" href="#id220" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
</section>
<section id="model-selection">
<h5>3.6.3. Model Selection<a class="headerlink" href="#model-selection" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>通常，我们只有在评估了多个不同方面（不同的架构、训练目标、选定的特征、数据预处理、学习率等）的模型后才选择最终模型。在众多模型中进行选择被恰当地称为模型选择。</p></li>
<li><p>【Cross-Validation】当训练数据稀缺时，我们甚至可能无法提供足够的数据来构成适当的验证集。此问题的一种流行解决方案是采用 K 折叠交叉验证。这里，原始训练数据被分成 K 个不重叠的子集。然后执行模型训练和验证 K 次，每次对 K-1 子集进行训练并在不同的子集（该轮中未用于训练的子集）上进行验证。最后，通过对 K 实验结果进行平均来估计训练和验证误差。</p></li>
</ul>
</section>
<section id="summary">
<h5>3.6.4. Summary<a class="headerlink" href="#summary" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt>经验法则</dt><dd><ul>
<li><p>使用验证集（或 K-折叠交叉验证, k-fold cross-validation）进行模型选择；</p></li>
<li><p>更复杂的模型通常需要更多的数据；</p></li>
<li><p>复杂性的相关概念包括参数的数量和它们允许采用的值的范围；</p></li>
<li><p>在其他条件相同的情况下，更多的数据几乎总是能带来更好的概括；</p></li>
<li><p>在讨论模型的泛化能力时，通常假设训练数据和测试数据是独立同分布（IID）的。如果放宽这一假设，允许训练和测试期间的数据分布发生变化（即分布漂移），那么在没有其他（可能更弱的）假设的情况下，我们无法对模型的泛化能力做出任何保证。</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>独立同分布（IID）假设：是许多统计学习理论的基础。它假定训练数据和测试数据来自相同的分布，且各个样本之间相互独立。</p></li>
<li><p>在这种假设下，可以推导出模型在新数据上的表现（泛化能力）。然而，在实际应用中，训练和测试数据的分布可能不同（称为分布漂移），这违反了IID假设。在这种情况下，传统的泛化理论可能不再适用，需要引入新的假设或方法来分析和保证模型的泛化能力。</p></li>
</ul>
</section>
</section>
<section id="weight-decay">
<h4>3.7. Weight Decay<a class="headerlink" href="#weight-decay" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>our first <strong>regularization</strong> technique</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>参见： <code class="docutils literal notranslate"><span class="pre">【知识体系】权重衰减(L2正则化)</span></code></p>
</div>
<section id="norms-and-weight-decay">
<h5>3.7.1. Norms and Weight Decay<a class="headerlink" href="#norms-and-weight-decay" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>权重衰减不是直接操纵参数的数量，而是通过限制参数可以取的值来进行操作。</p></li>
<li><dl class="simple">
<dt>在深度学习领域，权重衰减通常被称为L2正则化。它是一种通过限制模型参数的取值范围来防止过拟合的技术。</dt><dd><ul>
<li><p>与直接减少参数数量不同，权重衰减通过在损失函数中添加参数值的平方和作为惩罚项，鼓励模型学习较小的权重，从而降低模型复杂度。</p></li>
<li><p>这种方法的直观动机是：在所有函数中，恒等于零的函数 <code class="docutils literal notranslate"><span class="pre">f=0</span></code> 被认为是最简单的。因此，可以通过参数值偏离零的程度来衡量函数的复杂度。</p></li>
<li><p>然而，如何精确地度量函数与零之间的距离并没有唯一的答案。事实上，数学中的某些分支（如泛函分析和Banach空间理论）专门研究此类问题。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>【我的理解】前面说了「复杂性的相关概念包括参数的数量和它们允许采用的值的范围」这儿说了「权重衰减不是直接操纵参数的数量，而是通过限制参数可以取的值来进行操作」。所以 <strong>权重衰减是通过降低参数的取值范围来降低模型的复杂度</strong> 。</p>
</div>
<ul class="simple">
<li><p>【from gpt】当权重特别大时，模型会倾向于去记住数据的每一个细节（包括噪声和随机性），这样它的“复杂度”就会变得很高。但现实世界的数据往往包含噪声，我们希望模型只学到主要规律，而不是所有细节。</p></li>
<li><p>【from gpt】较小的权重意味着模型不能对数据中的每一个小特征都过度“记住”，只能学习到大体规律，避免过度拟合。</p></li>
<li><p>【from gpt】较小的权重降低了模型对数据的敏感度，让模型的行为更“平滑”，更少受到噪声的干扰，因此降低了模型的复杂度。这种方法通过限制模型的“表达能力”来帮助模型更好地泛化。你可以把较小的权重想象成给模型带上了“安全帽”，不让它太随意地对数据做出过度反应。</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>在实践中，权重衰减已成为训练参数化机器学习模型时最广泛使用的正则化技术之一。通过在损失函数中添加L2正则项，模型的权重被迫减小，从而限制模型的复杂度，提升泛化能力。这在一定程度上减少了模型过拟合的问题。</p>
</div>
<ul class="simple">
<li><p>【小结】权重衰减作为一种正则化技术，通过限制模型参数的大小，帮助提高模型的泛化能力，减少过拟合现象。</p></li>
<li><p>新的损失函数</p></li>
</ul>
<div class="math notranslate nohighlight">
\[L_{reg}(\mathbf{w}, b) = L(\mathbf{w}, b) + \frac{\lambda}{2} \|\mathbf{w}\|\]</div>
<ul class="simple">
<li><p>L2正则化回归的小批量随机梯度下降的 <strong>权重更新</strong></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{aligned}
\mathbf{w} &amp; \leftarrow \left(1- \eta\lambda \right) \mathbf{w} - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \mathbf{x}^{(i)} \left(\mathbf{w}^\top \mathbf{x}^{(i)} + b - y^{(i)}\right)
\end{aligned}\]</div>
</section>
<section id="high-dimensional-linear-regression">
<h5>3.7.2. High-Dimensional Linear Regression<a class="headerlink" href="#high-dimensional-linear-regression" title="此标题的永久链接">¶</a></h5>
<div class="math notranslate nohighlight">
\[\begin{split}y=0.05+\sum_{i=1}^{d} 0.01 x_{i}+\epsilon \\
\text { where } \epsilon \sim \mathcal{N}\left(0, 0.01^{2}\right) .\end{split}\]</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Data</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">DataModule</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_train</span><span class="p">,</span> <span class="n">num_val</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">num_train</span> <span class="o">+</span> <span class="n">num_val</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">)</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span>
        <span class="n">w</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">num_inputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span> <span class="o">+</span> <span class="n">noise</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train</span><span class="p">):</span>
        <span class="n">i</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_train</span><span class="p">)</span> <span class="k">if</span> <span class="n">train</span> <span class="k">else</span> <span class="nb">slice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_train</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_tensorloader</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">],</span> <span class="n">train</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="implementation-from-scratch">
<h5>3.7.3. Implementation from Scratch<a class="headerlink" href="#implementation-from-scratch" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>从头开始实现权重衰减</p></li>
</ul>
<section id="defining-l2-norm-penalty">
<h6>3.7.3.1. Defining L2 Norm Penalty<a class="headerlink" href="#defining-l2-norm-penalty" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>最方便的方法是将所有项平方并求和</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">l2_penalty</span><span class="p">(</span><span class="n">w</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">w</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="mi">2</span>
</pre></div>
</div>
</section>
<section id="id20">
<h6>3.7.3.2. Defining the Model<a class="headerlink" href="#id20" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>唯一的变化是我们的损失现在包括了惩罚项。</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">WeightDecayScratch</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">LinearRegressionScratch</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">,</span> <span class="n">lambd</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">+</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lambd</span> <span class="o">*</span> <span class="n">l2_penalty</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">))</span>
</pre></div>
</div>
<p>在包含 20 个示例的训练集上拟合我们的模型，并在包含 100 个示例的验证集上对其进行评估（说明：这儿是想说在较少的训练集上适合用权重衰减）:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">Data</span><span class="p">(</span><span class="n">num_train</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">num_val</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">num_inputs</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">train_scratch</span><span class="p">(</span><span class="n">lambd</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">WeightDecayScratch</span><span class="p">(</span><span class="n">num_inputs</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">lambd</span><span class="o">=</span><span class="n">lambd</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">board</span><span class="o">.</span><span class="n">yscale</span><span class="o">=</span><span class="s1">&#39;log&#39;</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;L2 norm of w:&#39;</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="n">l2_penalty</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">w</span><span class="p">)))</span>
</pre></div>
</div>
</section>
<section id="training-without-regularization">
<h6>3.7.3.3. Training without Regularization<a class="headerlink" href="#training-without-regularization" title="此标题的永久链接">¶</a></h6>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">train_scratch</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># L2 norm of w: 0.009948714636266232</span>
</pre></div>
</div>
</section>
<section id="using-weight-decay">
<h6>3.7.3.4. Using Weight Decay<a class="headerlink" href="#using-weight-decay" title="此标题的永久链接">¶</a></h6>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">train_scratch</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="c1"># L2 norm of w: 0.0017270983662456274</span>
</pre></div>
</div>
</section>
</section>
<section id="concise-implementation">
<h5>3.7.4. Concise Implementation<a class="headerlink" href="#concise-implementation" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>默认情况下，PyTorch 同时衰减权重和偏差，但我们可以配置优化器根据不同的策略处理不同的参数。</p></li>
<li><p>在这里，我们只为权重（ net.weight 参数）设置 weight_decay ，因此偏差（ net.bias 参数）不会衰减。</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">WeightDecay</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">wd</span><span class="p">,</span> <span class="n">lr</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wd</span> <span class="o">=</span> <span class="n">wd</span>   <span class="c1"># weight_decay</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">([</span>
            <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">wd</span><span class="p">},</span>
            <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">bias</span><span class="p">}],</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>
</pre></div>
</div>
<p>这个版本运行速度更快，更容易实现:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">WeightDecay</span><span class="p">(</span><span class="n">wd</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">board</span><span class="o">.</span><span class="n">yscale</span><span class="o">=</span><span class="s1">&#39;log&#39;</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;L2 norm of w:&#39;</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="n">l2_penalty</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">get_w_b</span><span class="p">()[</span><span class="mi">0</span><span class="p">])))</span>
<span class="c1"># L2 norm of w: 0.013779522851109505</span>
</pre></div>
</div>
</section>
<section id="id21">
<h5>3.7.5. Summary<a class="headerlink" href="#id21" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>正则化是处理过拟合的常用方法。</p></li>
<li><p>经典正则化技术在损失函数中添加惩罚项（训练时）以降低学习模型的复杂性。</p></li>
<li><p>保持模型简单的一种特殊选择是使用 L2 惩罚。这导致小批量随机梯度下降算法的更新步骤中的权重衰减。</p></li>
<li><p>在实践中，权重衰减功能是在深度学习框架的优化器中提供的。在同一训练循环中，不同的参数集可以有不同的更新行为。</p></li>
</ul>
</section>
</section>
</section>
<section id="linear-neural-networks-for-classification">
<h3>4. Linear Neural Networks for Classification<a class="headerlink" href="#linear-neural-networks-for-classification" title="此标题的永久链接">¶</a></h3>
<section id="softmax-regression">
<h4>4.1. Softmax Regression<a class="headerlink" href="#softmax-regression" title="此标题的永久链接">¶</a></h4>
<section id="classification">
<h5>4.1.1. Classification<a class="headerlink" href="#classification" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>统计学家很久以前就发明了一种表示分类数据的简单方法：one-hot 编码。 one-hot 编码是一个向量，其分量与类别一样多。与特定实例类别相对应的组件设置为 1，所有其他组件设置为 0。</p></li>
</ul>
<section id="linear-model">
<h6>4.1.1.1. Linear Model<a class="headerlink" href="#linear-model" title="此标题的永久链接">¶</a></h6>
<figure class="align-default" id="id221">
<img alt="https://img.zhaoweiguo.com/uPic/2024/12/CbhiVl.png" src="https://img.zhaoweiguo.com/uPic/2024/12/CbhiVl.png" />
<figcaption>
<p><span class="caption-text">Fig. 4.1.1 Softmax regression is a single-layer neural network.</span><a class="headerlink" href="#id221" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<p>更简洁的表示法:</p>
<div class="math notranslate nohighlight">
\[\mathbf{o} = \mathbf{Wx} + \mathbf{b}\]</div>
</section>
<section id="the-softmax">
<h6>4.1.1.2. The Softmax<a class="headerlink" href="#the-softmax" title="此标题的永久链接">¶</a></h6>
<ul>
<li><p>未规范化的预测 o 不能直接视作输出的原因：</p>
<blockquote>
<div><ul class="simple">
<li><p>没有限制这些输出数字的总和为1</p></li>
<li><p>输出可能为负值</p></li>
</ul>
</div></blockquote>
</li>
<li><p>实现此目标（并确保非负性）的一种方法是 使用指数函数 <span class="math notranslate nohighlight">\(P(y=i) \propto \exp o_{i}\)</span> 。这确实满足了条件类别概率随着 <span class="math notranslate nohighlight">\(o_i\)</span> 增加而增加的要求，它是单调的，并且所有概率都是非负的。然后我们可以转换这些值，使它们相加为 <code class="docutils literal notranslate"><span class="pre">1</span></code> ：将每个除以它们的总和。这个过程称为 <strong>标准化</strong></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\hat{\mathbf{y}}=\operatorname{softmax}(\mathbf{o}) \quad \\
\text { where } \quad \hat{y}_{i}=\frac{\exp \left(o_{i}\right)}{\sum_{j} \exp \left(o_{j}\right)} \\\end{split}\]</div>
<ul class="simple">
<li><p>说明：向量 <span class="math notranslate nohighlight">\(\mathbf{o}\)</span> 的最大坐标对应于预测概率分布 <span class="math notranslate nohighlight">\(\hat{\mathbf{y}}\)</span> 中最可能的类别。</p></li>
<li><p>此外，由于 softmax 操作会保留输入之间的排序关系，我们实际上并不需要真正计算 softmax 的结果，就可以确定哪个类别被分配了最高的概率。</p></li>
<li><p>所以如果选择最有可能的类别的话，可以省略 softmax 步骤，即：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\underset{j}{\operatorname{argmax}} \hat{y}_{j}=\underset{j}{\operatorname{argmax}} o_{j} .\]</div>
</section>
<section id="vectorization">
<h6>4.1.1.3. Vectorization<a class="headerlink" href="#vectorization" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>为了提高计算效率并且充分利用GPU, 我们通常会对小批量样本的数据执行矢量化计算(vectorize calculations)。</p></li>
<li><p>假设我们读取了一个批量的样本  <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> , 其中特征维度（输入数量）为  d , 批量大小为  n  。</p></li>
<li><p>此外, 假设我们在输出中有  q  个类别。</p></li>
<li><p>那么小批量样本的特征为  <span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{n \times d}\)</span> , 权重为  <span class="math notranslate nohighlight">\(\mathbf{W} \in \mathbb{R}^{d \times q}\)</span> , 偏置为  <span class="math notranslate nohighlight">\(\mathbf{b} \in \mathbb{R}^{1 \times q}\)</span></p></li>
<li><p>softmax回归的矢量计算表达式为:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{l}
\mathbf{O}=\mathbf{X W}+\mathbf{b} \\
\hat{\mathbf{Y}}=\operatorname{softmax}(\mathbf{O})
\end{array}\end{split}\]</div>
</section>
</section>
<section id="id22">
<h5>4.1.2. Loss Function<a class="headerlink" href="#id22" title="此标题的永久链接">¶</a></h5>
<section id="log-likelihood">
<h6>4.1.2.1. Log-Likelihood(对数似然)<a class="headerlink" href="#log-likelihood" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>softmax 函数给我们一个向量 <span class="math notranslate nohighlight">\(\hat{\mathbf{y}}\)</span> ，我们可以将其视为“对给定任意输入 <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> 的每个类的条件概率”。</p></li>
<li><p>例如 <span class="math notranslate nohighlight">\(\hat{y}_1 = P(y=\textrm{cat} \mid \mathbf{x})\)</span> 。</p></li>
<li><p>假设对于具有特征的数据集 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 对应的标签 <span class="math notranslate nohighlight">\(\mathbf{Y}\)</span> （即整个数据集 <span class="math notranslate nohighlight">\({\mathbf \{X, Y\}}\)</span> ）具有 n 个样本。</p></li>
<li><p>其中索引 i 的样本由：特征向量 <span class="math notranslate nohighlight">\(\mathbf{x}^{(i)}\)</span> 和使用 one-hot 编码的标签向量 <span class="math notranslate nohighlight">\(\mathbf{y}^{(i)}\)</span> 表示。</p></li>
<li><p>计算整个数据集的联合概率(假设每个标签 <span class="math notranslate nohighlight">\(𝑦^{(𝑖)}\)</span> 都是独立从条件分布 <span class="math notranslate nohighlight">\(𝑃(𝑦∣𝑥^{(𝑖)})\)</span> 中抽取的)，用于评估模型对整个数据集的预测能力：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[P(\mathbf{Y} \mid \mathbf{X}) = \prod_{i=1}^n P(\mathbf{y}^{(i)} \mid \mathbf{x}^{(i)}).\]</div>
<ul class="simple">
<li><p>目标：我们希望最大化 <code class="docutils literal notranslate"><span class="pre">𝑃(𝑌∣𝑋)</span></code> ，这实际上是最大似然估计的目标。</p></li>
<li><p>根据最大似然估计，我们最大化 <span class="math notranslate nohighlight">\(P(\mathbf{Y} | \mathbf{X})\)</span> ，相当于最小化负对数似然</p></li>
</ul>
<div class="math notranslate nohighlight">
\[-\log P(\mathbf{Y} \mid \mathbf{X}) = \sum_{i=1}^n -\log P(\mathbf{y}^{(i)} \mid \mathbf{x}^{(i)})
= \sum_{i=1}^n l(\mathbf{y}^{(i)}, \hat{\mathbf{y}}^{(i)}),\]</div>
<p>这其中任意一对标签 <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> 和模型预测 <span class="math notranslate nohighlight">\(\hat{\mathbf{y}}\)</span> 在 q 个分类上，损失函数 l 是</p>
<div class="math notranslate nohighlight">
\[l(\mathbf{y}, \hat{\mathbf{y}}) = - \sum_{j=1}^q y_j \log \hat{y}_j\]</div>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>注意这儿的 <strong>y</strong> 是 one-hot 编码</p>
</div>
<ul class="simple">
<li><p>上面这个损失函数通常被叫 <strong>交叉熵损失（cross-entropy loss）</strong></p></li>
</ul>
</section>
<section id="softmax-and-cross-entropy-loss">
<h6>4.1.2.2. Softmax and Cross-Entropy Loss<a class="headerlink" href="#softmax-and-cross-entropy-loss" title="此标题的永久链接">¶</a></h6>
<section id="id23">
<h6 aria-level="7">1. 交叉熵损失的推导过程<a class="headerlink" href="#id23" title="此标题的永久链接">¶</a></h6>
<ol class="arabic simple">
<li><p>softmax 输出的形式：</p></li>
</ol>
<div class="math notranslate nohighlight">
\[\begin{split}\hat{\mathbf{y}} = \frac{\exp \left(o_{j}\right)}{\sum_{k=1}^{q} \exp \left(o_{k}\right)} \\
其中 o_j 是模型对类别 𝑗 的原始输出 (logits)\end{split}\]</div>
<ol class="arabic simple" start="2">
<li><p>将 softmax 代入交叉熵损失的定义：</p></li>
</ol>
<div class="math notranslate nohighlight">
\[\begin{aligned}
l(\mathbf{y}, \hat{\mathbf{y}}) &amp; =-\sum_{j=1}^{q} y_{j} \log \frac{\exp \left(o_{j}\right)}{\sum_{k=1}^{q} \exp \left(o_{k}\right)}
\end{aligned}\]</div>
<ol class="arabic simple" start="3">
<li><p>拆分对数：</p></li>
</ol>
<div class="math notranslate nohighlight">
\[l(\mathbf{y}, \hat{\mathbf{y}}) =\sum_{j=1}^{q} y_{j} \log \sum_{k=1}^{q} \exp \left(o_{k}\right)-\sum_{j=1}^{q} y_{j} o_{j}\]</div>
<ol class="arabic simple" start="4">
<li><p>由于标签 𝑦 是 one-hot 编码或概率分布，标签向量的所有元素加起来总是等于 1，所以可以进一步简化：</p></li>
</ol>
<div class="math notranslate nohighlight">
\[l(\mathbf{y}, \hat{\mathbf{y}}) =\log \sum_{k=1}^{q} \exp \left(o_{k}\right)-\sum_{j=1}^{q} y_{j} o_{j} .\]</div>
</section>
<section id="id24">
<h6 aria-level="7">2. 梯度推导 (反向传播的核心)<a class="headerlink" href="#id24" title="此标题的永久链接">¶</a></h6>
<p>对任何 <span class="math notranslate nohighlight">\(o_{j}\)</span> 求导, 我们得到:</p>
<div class="math notranslate nohighlight">
\[\partial_{o_{j}} l(\mathbf{y}, \hat{\mathbf{y}}) = \frac{\exp \left(o_{j}\right)}{\sum_{k=1}^{q} \exp \left(o_{k}\right)}-y_{j}\]</div>
<p>简化：</p>
<div class="math notranslate nohighlight">
\[\partial_{o_{j}} l(\mathbf{y}, \hat{\mathbf{y}}) =\operatorname{softmax}(\mathbf{o})_{j}-y_{j}\]</div>
<ul class="simple">
<li><dl class="simple">
<dt>直观理解：</dt><dd><ul>
<li><p><span class="math notranslate nohighlight">\(softmax(𝑜_𝑗)\)</span> 是模型对类别 𝑗 预测的概率。</p></li>
<li><p><span class="math notranslate nohighlight">\(𝑦_𝑗\)</span> 是真实标签（one-hot编码），如果 𝑗 是真实类别，则 <span class="math notranslate nohighlight">\(𝑦_𝑗=1\)</span> ，否则 <span class="math notranslate nohighlight">\(𝑦_𝑗=0\)</span></p></li>
<li><p>梯度表示模型的预测概率与真实标签之间的差距，即误差信号</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="id25">
<h6 aria-level="7">3. 更一般的情况: 标签分布为概率分布<a class="headerlink" href="#id25" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>通常我们假设标签是 one-hot 编码的，如 (0,0,1)。但在某些任务中，标签可能是一个概率分布，如 (0.1,0.2,0.7)</p></li>
<li><p>这种情况下，交叉熵损失的计算方式不变：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[l(\mathbf{y}, \hat{\mathbf{y}}) = - \sum_{j=1}^q y_j \log \hat{y}_j\]</div>
<ul class="simple">
<li><p>唯一的区别是 𝑦_𝑗 不再是 0 或 1，而是一个概率值。这种形式更具一般性，允许模型处理更复杂的任务，如知识蒸馏或多标签分类问题。</p></li>
</ul>
</section>
<section id="id26">
<h6 aria-level="7">4. 交叉熵损失的意义: 信息论解释<a class="headerlink" href="#id26" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><dl class="simple">
<dt>交叉熵损失可以从信息论角度理解：</dt><dd><ul>
<li><p>它衡量了真实分布 𝑦 与模型预测分布 <span class="math notranslate nohighlight">\(\hat{𝑦}\)</span> 之间的差异。</p></li>
<li><p>直观理解：模型越准确，交叉熵损失越小，因为模型输出分布与真实分布越接近。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>举例说明：</dt><dd><ul>
<li><p>如果真实分布是 (0,0,1)，模型预测 (0.1,0.2,0.7)，损失较小。</p></li>
<li><p>如果模型预测为 (0.7,0.2,0.1)，损失较大，因为模型输出偏离真实类别更远。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="id27">
<h6 aria-level="7">5. 关键信息总结<a class="headerlink" href="#id27" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>交叉熵损失的推导来自最大似然估计，通过 softmax 和对数运算得出。</p></li>
<li><p>梯度的形式是模型预测概率与真实标签之间的差距，这是模型参数更新的核心。</p></li>
<li><p>信息论角度解释：交叉熵损失衡量模型对真实标签的编码效率，模型越准确，编码代价越小。</p></li>
<li><p>泛化性：交叉熵损失不仅适用于 one-hot 标签，还可以处理概率标签，适应更复杂的任务。</p></li>
</ul>
</section>
</section>
</section>
<section id="information-theory-basics">
<h5>4.1.3. Information Theory Basics<a class="headerlink" href="#information-theory-basics" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>Information theory(信息论) deals with the problem of encoding, decoding, transmitting, and manipulating information (also known as data).</p></li>
</ul>
<section id="entropy">
<h6>4.1.3.1. Entropy(熵)<a class="headerlink" href="#entropy" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>信息论的核心思想是量化数据中的信息内容。</p></li>
<li><p>在信息论中，该数值被称为分布 P 的熵（entropy）。</p></li>
<li><p>可以通过以下方程得到：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[H[P] = \sum_j{-P(j)logP(j)}\]</div>
<ul class="simple">
<li><p>One of the fundamental theorems of information theory states that in order to encode data drawn randomly from the distribution P, we need at least  <code class="docutils literal notranslate"><span class="pre">H[P]“nats”</span></code> to encode it (Shannon, 1948).</p></li>
<li><p>If you wonder what a “nat” is, it is the equivalent of bit but when using a code with base e rather than one with base 2. Thus, one nat is <span class="math notranslate nohighlight">\(\frac{1}{log(2)} \approx 1.44\)</span> bit.</p></li>
</ul>
</section>
<section id="surprisal">
<h6>4.1.3.2. Surprisal(惊讶度)<a class="headerlink" href="#surprisal" title="此标题的永久链接">¶</a></h6>
<section id="id28">
<h6 aria-level="7">1. 压缩与预测的联系<a class="headerlink" href="#id28" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>压缩(compression)与预测(prediction)的关系</p></li>
<li><p>核心观点：如果一个数据流很容易预测，那么它也很容易压缩。</p></li>
<li><p>例子：举一个极端的例子，流中的每个标记始终采用相同的值。</p></li>
<li><dl class="simple">
<dt>解释：</dt><dd><ul>
<li><p>容易预测：由于数据有很强的规律性，我们可以准确地预测下一个符号是什么。</p></li>
<li><p>容易压缩：压缩算法只需记录这个规律，而不用传输大量冗余数据。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>结论：</dt><dd><ul>
<li><p>“易预测” ⟹ “易压缩”</p></li>
<li><p>“难预测” ⟹ “难压缩”</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="id29">
<h6 aria-level="7">2. 预测失败与“惊讶度”<a class="headerlink" href="#id29" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>解释：当一个低概率事件发生时，我们会感到“惊讶”。</p></li>
<li><p>示例：掷骰子，结果是 7。这会非常令人惊讶，因为 𝑃(7)=0</p></li>
<li><p>量化惊讶度-克劳德·香农 (Claude Shannon) 提出了一个公式来衡量这种惊讶程度(Surprisal)：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[惊讶度(surprisal) = \log \frac{1}{P(j)} = -\log P(j)\]</div>
<ul class="simple">
<li><p>概率越小，惊讶度越大。</p></li>
<li><p>如果 <code class="docutils literal notranslate"><span class="pre">𝑃(𝑗)=1</span></code> ，即事件必然发生，惊讶度为 0</p></li>
<li><p>如果 <code class="docutils literal notranslate"><span class="pre">𝑃(𝑗)=0.01</span></code> ，惊讶度较大。</p></li>
</ul>
</section>
<section id="id30">
<h6 aria-level="7">3. 熵: 期望的惊讶度<a class="headerlink" href="#id30" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>定义：熵 (Entropy) 是所有可能事件的“平均惊讶度”：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[H(p) = - \sum_j{P(j)logP(j)}\]</div>
<ul class="simple">
<li><p>解释：熵衡量了一个系统的“不确定性”。如果系统的熵很高，说明事件分布很分散，难以预测。</p></li>
<li><dl class="simple">
<dt>极端例子：</dt><dd><ul>
<li><p>如果一个事件总是发生 (概率为 1)，熵为 0（完全可预测）。</p></li>
<li><p>如果所有事件概率均等，熵达到最大（最不确定，最难预测）。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="id31">
<h6 aria-level="7">4. 交叉熵: 预测与真实分布的差距<a class="headerlink" href="#id31" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><dl class="simple">
<dt>为什么交叉熵是损失函数：交叉熵衡量模型预测分布 <span class="math notranslate nohighlight">\(\hat{y}\)</span> 和真实分布 𝑦 之间的差异：</dt><dd><ul>
<li><p>如果模型预测与真实分布接近，交叉熵较小。</p></li>
<li><p>如果模型预测远离真实分布，交叉熵较大。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="id32">
<h6 aria-level="7">5. 直观例子<a class="headerlink" href="#id32" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>假设</p></li>
<li><p>真实概率分布 y=(0,0,0,0,0,1) 表示只会掷出 6</p></li>
<li><p>模型预测分布为 <span class="math notranslate nohighlight">\(\hat{y} =(0.1,0.1,0.1,0.1,0.1,0.5)\)</span></p></li>
<li><p>计算交叉熵损失：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}H(y, \hat{y}) = - \sum_{j=1}^6{y_j log{\hat{y}_j}} \\
    - log(0.5) = 0.693\end{split}\]</div>
</section>
</section>
<section id="cross-entropy-revisited">
<h6>4.1.3.3. Cross-Entropy Revisited<a class="headerlink" href="#cross-entropy-revisited" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>结合上面的惊讶度(Surprisal)的理解</p></li>
<li><dl class="simple">
<dt>可以把 <strong>熵H(P)</strong> 看成 <code class="docutils literal notranslate"><span class="pre">一个知道真实概率的人在经历概率事件时的惊讶度(Surprisal)</span></code></dt><dd><ul>
<li><p>直观理解：</p></li>
<li><p>如果我们对数据的分布非常了解 (即 𝑃 是我们预测的分布)，那么熵就是我们对未来事件的“平均惊讶度”。</p></li>
<li><p>这是最佳压缩的理论极限。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>那么 <strong>交叉熵H(P, Q)</strong> 描述的是我们用主观概率分布 𝑄 预测真实分布 𝑃 数据时的平均惊讶度。</dt><dd><ul>
<li><p>直观解释：</p></li>
<li><p>真实分布 𝑃 表示实际发生的情况，而模型预测 𝑄 代表我们对数据的“主观理解”。</p></li>
<li><p>如果模型 𝑄 偏离了真实分布 𝑃，我们在看到真实数据时会感到更“惊讶”。</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>【示例】</p></li>
<li><p>真实分布 𝑃：骰子掷出每个面的概率均为 𝑃(𝑗)=1/6</p></li>
<li><p>模型分布 𝑄 (预测分布)：模型错误地认为骰子掷出6的概率是 𝑄(6)=0.5，其他面的概率是 𝑄(𝑗)=0.1。</p></li>
<li><dl class="simple">
<dt>计算熵和交叉熵：</dt><dd><ul>
<li><p>熵: <span class="math notranslate nohighlight">\(H(P)=-\sum_{j=1}^6{\frac{1}{6}log{\frac{1}{6}}} = log6\)</span></p></li>
<li><p>交叉熵:  <span class="math notranslate nohighlight">\(H(P, Q) = -\sum_{j=1}^6{\frac{1}{6}log{Q(j)}} = -\frac{5}{6}log{0.1} -\frac{1}{6}log{0.5} = \frac{5}{6}log10 + \frac{1}{6}log2\)</span></p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># 熵(1.7918)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">6</span><span class="p">))</span>

<span class="c1"># 交叉熵(2.0343)</span>
<span class="o">-</span><span class="mi">5</span><span class="o">/</span><span class="mi">6</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.1</span><span class="p">))</span> <span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="mi">6</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>
<span class="mi">5</span><span class="o">/</span><span class="mi">6</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="mi">6</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>【解读】当 𝑃=𝑄(模型预测准确) 时，交叉熵达到最小值，此时：𝐻(𝑃,𝑃)=𝐻(𝑃) ❇️=》也就是说：真实分布和预测分布一致时，交叉熵等于熵。</p>
</div>
<ul class="simple">
<li><dl class="simple">
<dt>以从两个角度理解交叉熵分类目标函数：</dt><dd><ul>
<li><p>最大化观察到的数据的似然 (likelihood)；</p></li>
<li><p>最小化模型对真实标签的惊讶度（即减少编码标签所需的比特数）。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
</section>
</section>
<section id="the-image-classification-dataset">
<h4>4.2. The Image Classification Dataset<a class="headerlink" href="#the-image-classification-dataset" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>主要讲了 torchvision 的基本使用</p></li>
</ul>
</section>
<section id="the-base-classification-model">
<h4>4.3. The Base Classification Model<a class="headerlink" href="#the-base-classification-model" title="此标题的永久链接">¶</a></h4>
<section id="the-classifier-class">
<h5>4.3.1. The Classifier Class<a class="headerlink" href="#the-classifier-class" title="此标题的永久链接">¶</a></h5>
<p>定义Classifier类</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Classifier</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The base class of classification models.&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="n">Y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="o">*</span><span class="n">batch</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">Y_hat</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="s1">&#39;acc&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">accuracy</span><span class="p">(</span><span class="n">Y_hat</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>使用随机梯度下降优化器，在小批量上运行</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="accuracy">
<h5>4.3.2. Accuracy<a class="headerlink" href="#accuracy" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">Classifier</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">accuracy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Y_hat</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">averaged</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the number of correct predictions.&quot;&quot;&quot;</span>
    <span class="n">Y_hat</span> <span class="o">=</span> <span class="n">Y_hat</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">Y_hat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">Y_hat</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">compare</span> <span class="o">=</span> <span class="p">(</span><span class="n">preds</span> <span class="o">==</span> <span class="n">Y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">compare</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="k">if</span> <span class="n">averaged</span> <span class="k">else</span> <span class="n">compare</span>
</pre></div>
</div>
</section>
</section>
<section id="softmax-regression-implementation-from-scratch">
<h4>4.4. Softmax Regression Implementation from Scratch<a class="headerlink" href="#softmax-regression-implementation-from-scratch" title="此标题的永久链接">¶</a></h4>
<section id="id33">
<h5>4.4.1. The Softmax<a class="headerlink" href="#id33" title="此标题的永久链接">¶</a></h5>
<p>计算 softmax 需要三个步骤:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>i) 每一项求幂
ii) 每行求和以计算每个示例的归一化常数
iii) 将每一行除以其归一化常数，确保结果总和为 1
</pre></div>
</div>
</section>
<section id="the-model">
<h5>4.4.2. The Model<a class="headerlink" href="#the-model" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">SoftmaxRegressionScratch</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Classifier</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">),</span>
                              <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_outputs</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">]</span>
</pre></div>
</div>
<p>网络如何将每个输入映射到输出:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">SoftmaxRegressionScratch</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="k">return</span> <span class="n">softmax</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="the-cross-entropy-loss">
<h5>4.4.3. The Cross-Entropy Loss<a class="headerlink" href="#the-cross-entropy-loss" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>创建了示例数据y_hat其中包含 2 个示例 预测 3 个类别的概率及其相应的标签 y</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]])</span>
<span class="n">y_hat</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">]</span>
<span class="c1"># tensor([0.1000, 0.5000])</span>
</pre></div>
</div>
<p>对所选概率的对数进行平均来实现交叉熵损失函数：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">cross_entropy</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">y2</span> <span class="o">=</span> <span class="n">y_hat</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_hat</span><span class="p">))),</span> <span class="n">y</span><span class="p">]</span>   <span class="c1"># tensor([0.1000, 0.5000])</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">cross_entropy</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="c1"># tensor(1.4979)</span>
</pre></div>
</div>
<ul>
<li><p>定义损失函数:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">SoftmaxRegressionScratch</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">cross_entropy</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="id34">
<h5>4.4.4. Training<a class="headerlink" href="#id34" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SoftmaxRegressionScratch</span><span class="p">(</span><span class="n">num_inputs</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">num_outputs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="prediction">
<h5>4.4.5. Prediction<a class="headerlink" href="#prediction" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">val_dataloader</span><span class="p">()))</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">preds</span><span class="o">.</span><span class="n">shape</span>
<span class="c1"># torch.Size([256])</span>
</pre></div>
</div>
<p>我们对错误标记的图像更感兴趣。通过将它们的实际标签（文本输出的第一行）与模型的预测（文本输出的第二行）进行比较来可视化它们:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">wrong</span> <span class="o">=</span> <span class="n">preds</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="o">!=</span> <span class="n">y</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">wrong</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">wrong</span><span class="p">],</span> <span class="n">preds</span><span class="p">[</span><span class="n">wrong</span><span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="o">+</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">+</span><span class="n">b</span> <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
    <span class="n">data</span><span class="o">.</span><span class="n">text_labels</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">data</span><span class="o">.</span><span class="n">text_labels</span><span class="p">(</span><span class="n">preds</span><span class="p">))]</span>
<span class="n">data</span><span class="o">.</span><span class="n">visualize</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2024/12/o23wtV.png" src="https://img.zhaoweiguo.com/uPic/2024/12/o23wtV.png" />
</figure>
</section>
</section>
<section id="concise-implementation-of-softmax-regression">
<h4>4.5. Concise Implementation of Softmax Regression<a class="headerlink" href="#concise-implementation-of-softmax-regression" title="此标题的永久链接">¶</a></h4>
<section id="id35">
<h5>4.5.1. Defining the Model<a class="headerlink" href="#id35" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>内置的__call__方法就会调用forward</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">SoftmaxRegression</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Classifier</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The softmax regression model.&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">lr</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
                                 <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">num_outputs</span><span class="p">))</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="softmax-revisited">
<h5>4.5.2. Softmax Revisited<a class="headerlink" href="#softmax-revisited" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt>原始 softmax 计算方式在实际实现中可能存在数值稳定性问题，主要包括：</dt><dd><ul>
<li><p>上溢 (Overflow)：如果 <span class="math notranslate nohighlight">\(o_k\)</span> 非常大，<span class="math notranslate nohighlight">\(\exp(o_k)\)</span> 可能超出计算机能表示的最大值，导致溢出。</p></li>
<li><p>下溢 (Underflow)：如果所有 <span class="math notranslate nohighlight">\(o_k\)</span> 都非常小 (负数很大)， <span class="math notranslate nohighlight">\(\exp(o_k)\)</span> 会趋近于 0，可能导致下溢。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>数值不稳定性的具体原因</dt><dd><ul>
<li><p>计算机表示浮点数的范围有限。例如，单精度浮点数的表示范围约为 <span class="math notranslate nohighlight">\(10^{-38}\)</span> 到 <span class="math notranslate nohighlight">\(10^{38}\)</span></p></li>
<li><p>如果最大的 <span class="math notranslate nohighlight">\(o_k\)</span> 超出区间 <code class="docutils literal notranslate"><span class="pre">[-90,</span> <span class="pre">90]</span></code>，结果就会变得不稳定。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>解决方案</dt><dd><ul>
<li><p>核心思想：为了避免溢出或下溢，可以通过平移 logits，使得最大的 logits 变为 0，从而让所有 logits 都位于一个较小的范围内。</p></li>
<li><dl class="simple">
<dt>具体方法：</dt><dd><ul>
<li><p>设 <span class="math notranslate nohighlight">\(\bar{o}=\max_k{o_k}\)</span></p></li>
<li><p>从所有 logits 中减去 <span class="math notranslate nohighlight">\(\bar{o}\)</span> ：</p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{y}_{j}=\frac{\exp \left(o_{j}-\bar{o}\right)}{\sum_{k} \exp \left(o_{k}-\bar{o}\right)}\)</span></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>分析</dt><dd><ul>
<li><p>防止上溢：因为 <span class="math notranslate nohighlight">\(\exp(0) = 1\)</span> ，而 <span class="math notranslate nohighlight">\(\exp(负数)\)</span> 的值始终介于 <code class="docutils literal notranslate"><span class="pre">(0,</span> <span class="pre">1]</span></code></p></li>
<li><p>防止下溢：如果 <span class="math notranslate nohighlight">\(o_j - \bar{o}\)</span> 非常小， <span class="math notranslate nohighlight">\(\exp(o_j - \bar{o})\)</span> 可能趋近 0，但不会溢出，最多导致 <span class="math notranslate nohighlight">\(\hat y_j = 0\)</span></p></li>
<li><p>但我们可以利用 softmax 和交叉熵的组合，避免直接计算 <span class="math notranslate nohighlight">\(\hat{y}_j\)</span> ，而是计算： <span class="math notranslate nohighlight">\(log{\hat{y}_i} = o_j - \bar{o} - log{\sum_k{\exp(o_k - \bar{o})}}\)</span></p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
<li><p>推理过程</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{l}
\hat{y}_{j}=\frac{\exp \left(o_{j}-\bar{o}\right)}{\sum_{k} \exp \left(o_{k}-\bar{o}\right)} \\
\text{两边求对数=&gt;}  \\
\log \hat{y}_i = o_j - \bar{o} - log{\sum_k{\exp (o_k - \bar{o})}}
\end{array}\end{split}\]</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Classifier</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Y_hat</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">averaged</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">Y_hat</span> <span class="o">=</span> <span class="n">Y_hat</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">Y_hat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,))</span>
    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span>
        <span class="n">Y_hat</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span> <span class="k">if</span> <span class="n">averaged</span> <span class="k">else</span> <span class="s1">&#39;none&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id36">
<h5>4.5.3. Training<a class="headerlink" href="#id36" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SoftmaxRegression</span><span class="p">(</span><span class="n">num_outputs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="generalization-in-classification">
<h4>4.6. Generalization in Classification<a class="headerlink" href="#generalization-in-classification" title="此标题的永久链接">¶</a></h4>
<section id="the-test-set">
<h5>4.6.1. The Test Set<a class="headerlink" href="#the-test-set" title="此标题的永久链接">¶</a></h5>
<section id="empirical-error">
<h6>1. 经验误差 (Empirical Error)<a class="headerlink" href="#empirical-error" title="此标题的永久链接">¶</a></h6>
<p>公式解析：</p>
<div class="math notranslate nohighlight">
\[\epsilon_\mathcal{D}(f) = \frac{1}{n}\sum_{i=1}^n \mathbf{1}(f(\mathbf{x}^{(i)}) \neq y^{(i)})\]</div>
<ul class="simple">
<li><p>其中</p></li>
<li><p><span class="math notranslate nohighlight">\(\epsilon_\mathcal{D}(f)\)</span> : 在测试集 <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> 上的分类误差</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{1}(\cdot)\)</span> 是指示函数 (indicator function)， <span class="math notranslate nohighlight">\(\mathbf{1}(\text{condition})\)</span> 的值只有两个可能：如果条件为真， <span class="math notranslate nohighlight">\(\mathbf{1}(\text{condition}) = 1\)</span> ;如果条件为 假， <span class="math notranslate nohighlight">\(\mathbf{1}(\text{condition}) = 0\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{1}(f(\mathbf{x}^{(i)}) \neq y^{(i)})\)</span> ：如果预测 <span class="math notranslate nohighlight">\(f(\mathbf{x}^{(i)})\)</span> 与真实标签 <span class="math notranslate nohighlight">\(y^{(i)}\)</span> 不一致，则输出 <strong>1</strong>，否则输出 <strong>0</strong></p></li>
<li><p>含义：模型在测试集 <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> 上预测错误的比例，即模型在实际数据上的表现。</p></li>
<li><p>指示函数的直观理解： <span class="math notranslate nohighlight">\(\mathbf{1}\)</span> 相当于一个开关，用来判断是否满足某个条件：满足条件就“打开” (1)，不满足条件就“关闭” (0)。在误差计算中，它帮助统计模型在测试集上的错误样本数量。</p></li>
</ul>
</section>
<section id="population-error">
<h6>2. 总体误差 (Population Error)<a class="headerlink" href="#population-error" title="此标题的永久链接">¶</a></h6>
<p>公式解析：</p>
<div class="math notranslate nohighlight">
\[\begin{split}\epsilon(f) =  E_{(\mathbf{x}, y) \sim P} \mathbf{1}(f(\mathbf{x}) \neq y) \\
= \int\int \mathbf{1}(f(\mathbf{x}) \neq y) p(\mathbf{x}, y) \;d\mathbf{x} dy\end{split}\]</div>
<ul class="simple">
<li><p>其中</p></li>
<li><p><span class="math notranslate nohighlight">\(\epsilon(f)\)</span> ：模型在真实数据分布下的期望误差，是理想状态下模型真正的误差。</p></li>
<li><p><span class="math notranslate nohighlight">\(p(\mathbf{x}, y)\)</span> ：数据分布的概率密度函数。</p></li>
<li><p>含义：模型在整个潜在数据分布中分类错误的期望概率。</p></li>
<li><p>问题：无法直接计算，因为真实分布 <span class="math notranslate nohighlight">\(p(\mathbf{x}, y)\)</span> 通常未知。</p></li>
<li><p>由于测试集 <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> 在统计上代表了潜在总体，我们可以将 <span class="math notranslate nohighlight">\(\epsilon_\mathcal{D}(f)\)</span> 视为总体误差 <span class="math notranslate nohighlight">\(\epsilon(f)\)</span> 的统计估计量。</p></li>
<li><p>此外，由于我们感兴趣的量 <span class="math notranslate nohighlight">\(\epsilon(f)\)</span> 是随机变量 <span class="math notranslate nohighlight">\(\mathbf{1}(f(X) \neq Y)\)</span> 的期望值，对应的估计量 <span class="math notranslate nohighlight">\(\epsilon_\mathcal{D}(f)\)</span> 是样本均值，因此估计总体误差其实是一个经典的均值估计问题。</p></li>
</ul>
</section>
<section id="clt">
<h6>3. 中心极限定理 (CLT) 和误差收敛速度<a class="headerlink" href="#clt" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>我们关心的随机变量 <span class="math notranslate nohighlight">\(\mathbf{1}(f(X) \neq Y)\)</span> 只能取 0 和 1 两个值，因此是一个伯努利随机变量，其参数表示该变量取值为 1 的概率。</p></li>
<li><p>Bernoulli 分布的随机变量单个样本误差的方差是： <span class="math notranslate nohighlight">\(\sigma^2=\epsilon(f)(1-\epsilon(f))\)</span></p></li>
<li><p>虽然 <span class="math notranslate nohighlight">\(\epsilon(f)\)</span> 最初是未知的，但我们知道它不会大于 1。进一步分析这个函数会发现，当 <span class="math notranslate nohighlight">\(\epsilon(f) \approx 0.5\)</span> 时方差最大，而当 <span class="math notranslate nohighlight">\(\epsilon(f)\)</span> 接近 0 或 1 时方差较小。这表明，估计量 <span class="math notranslate nohighlight">\(\epsilon_\mathcal{D}(f)\)</span> 的渐近标准差不会超过： <span class="math notranslate nohighlight">\(\sqrt{\frac{0.25}{N}}\)</span></p></li>
<li><p>中心极限定理表明，当样本量 <span class="math notranslate nohighlight">\(n \to \infty\)</span> 时，测试误差 <span class="math notranslate nohighlight">\(\epsilon_\mathcal{D}(f)\)</span> 将以速率 <span class="math notranslate nohighlight">\(\mathcal{O}(1/\sqrt{n})\)</span> 收敛到真实误差 <span class="math notranslate nohighlight">\(\epsilon(f)\)</span></p></li>
<li><dl class="simple">
<dt>直观含义：</dt><dd><ul>
<li><p>想把测试误差减少一半，需要 4 倍的样本量。</p></li>
<li><p>如果要将误差减少 100 倍，需要 10,000 倍的样本量。</p></li>
<li><dl class="simple">
<dt>例如，如果希望误差的估计精确到 <code class="docutils literal notranslate"><span class="pre">±0.01</span></code> ，大约需要 2,500 个样本。</dt><dd><ul>
<li><p>Bernoulli 分布的随机变量单个样本误差的方差是： <span class="math notranslate nohighlight">\(\sigma^2=\epsilon(f)(1-\epsilon(f))\)</span></p></li>
<li><p>方差 <span class="math notranslate nohighlight">\(\sigma^2\)</span> 在 <span class="math notranslate nohighlight">\(\epsilon(f) = 0.5\)</span> 时达到最大值 0.25</p></li>
<li><p>如果希望误差波动在 $±0.01$ 以内，则需要满足</p></li>
<li><p><span class="math notranslate nohighlight">\(\sqrt{\frac{0.25}{n}}=0.01\)</span></p></li>
<li><p>解得 n=2500</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
<li><p>通常情况下，这种 <span class="math notranslate nohighlight">\(\mathcal{O}(1/\sqrt{n})\)</span> 的速率是统计学中我们能期望的最优速率。</p></li>
<li><p>中心极限定理的核心思想：中心极限定理告诉我们，无论总体分布如何，如果从总体中抽取大量独立同分布的随机样本，并计算样本均值，这个样本均值的分布将近似服从正态分布 (Normal Distribution)，只要样本数量足够大。</p></li>
</ul>
</section>
<section id="hoeffding">
<h6>4. Hoeffding 不等式和有限样本误差界<a class="headerlink" href="#hoeffding" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>前面的分析主要针对渐近情况，即随着样本数量趋近无穷时的行为。</p></li>
<li><p>然而，幸运的是，由于我们的随机变量是有界的，我们可以通过 Hoeffding (1963) 提出的一个不等式得到有限样本下的有效界限：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[P(\epsilon_\mathcal{D}(f) - \epsilon(f) \geq t) &lt; \exp\left( - 2n t^2 \right)\]</div>
<ul class="simple">
<li><p>为确保在 95% 置信水平下， <span class="math notranslate nohighlight">\(\epsilon_\mathcal{D}(f)\)</span> 与 <span class="math notranslate nohighlight">\(\epsilon(f)\)</span> 之间的距离不超过 0.01，我们需要的最小样本量大约为 15,000，略多于渐近分析得出的 10,000。</p></li>
<li><p>这种趋势在统计学中普遍存在。适用于有限样本的保证通常比渐近分析更保守一些。然而，这两者给出的数值差距不大，反映出渐近分析在实际应用中仍然具有相当的参考价值，即使它们无法提供完全的保证。</p></li>
<li><p>解释：这条不等式提供了在有限样本下的误差估计。</p></li>
<li><p>t 表示允许误差的容忍范围。</p></li>
<li><p>当 <code class="docutils literal notranslate"><span class="pre">t</span> <span class="pre">=</span> <span class="pre">0.01</span></code> （即希望误差在 <code class="docutils literal notranslate"><span class="pre">±0.01</span></code> 范围内）时，需要约 15,000 个样本，比中心极限定理估计的 10,000 样本略多。</p></li>
<li><p>结论：有限样本下的误差估计比无穷样本下略保守，但两者差距不大，表明中心极限定理提供了很好的估计。</p></li>
</ul>
</section>
</section>
<section id="test-set-reuse">
<h5>4.6.2. Test Set Reuse<a class="headerlink" href="#test-set-reuse" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>分析：测试集重用问题与风险</p></li>
</ul>
<section id="id37">
<h6>核心观点<a class="headerlink" href="#id37" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><dl class="simple">
<dt>测试集是机器学习模型评估的基准，但重用测试集可能带来严重的问题，主要涉及到：</dt><dd><ul>
<li><p>假发现率（False Discovery Rate）问题</p></li>
<li><p>自适应过拟合（Adaptive Overfitting）风险</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="id38">
<h6>1) 假发现率问题<a class="headerlink" href="#id38" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>背景：在评估模型 <span class="math notranslate nohighlight">\(f_1\)</span> 之后，用户可能继续开发新模型 <span class="math notranslate nohighlight">\(f_2, f_3, ..., f_k\)</span> ，并在相同的测试集上评估它们的性能。</p></li>
<li><dl class="simple">
<dt>风险：</dt><dd><ul>
<li><p>每次模型评估都存在 5% 的误导风险（置信水平95%）。</p></li>
<li><p>如果在相同测试集上评估 k 个模型，即使每个模型独立地有95%置信度，整体出现至少一个误导结果的概率大大增加。</p></li>
<li><p>举例：当 <span class="math notranslate nohighlight">\(k = 20\)</span> 时，至少一个模型误导的概率 <span class="math notranslate nohighlight">\(= 1 - (0.95)^{20} \approx 64%\)</span>。</p></li>
<li><p>影响：错误的模型可能被误选为最佳模型，导致实际性能不佳。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="id39">
<h6>2) 自适应过拟合<a class="headerlink" href="#id39" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>背景：如果模型 <span class="math notranslate nohighlight">\(f_2\)</span> 是在观察 <span class="math notranslate nohighlight">\(f_1\)</span> 的测试集结果后设计的，那么 <span class="math notranslate nohighlight">\(f_2\)</span> 的性能已受到测试集信息的影响。</p></li>
<li><dl class="simple">
<dt>风险：</dt><dd><ul>
<li><p>测试集在评估 <span class="math notranslate nohighlight">\(f_2\)</span> 时已不再是真正的“未知数据”，使得模型评估的结果偏乐观。</p></li>
<li><p>这破坏了机器学习模型评估的核心原则，即模型不能“见过”测试集数据。</p></li>
<li><p>例子：在 Kaggle 比赛中，如果多次在私有测试集上提交模型并调整参数，最终的模型可能只是在测试集上表现很好，而在真实场景中表现较差。</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>本质：模型不断根据测试集反馈优化，测试集逐渐退化为训练集的延伸，无法有效反映模型的真实泛化能力。</p></li>
</ul>
</section>
<section id="id40">
<h6>缓解策略与实践建议<a class="headerlink" href="#id40" title="此标题的永久链接">¶</a></h6>
<ol class="arabic simple">
<li><p>避免重复使用同一测试集。策略：构建多个独立的测试集，每轮评估后将旧测试集降级为验证集，避免反复使用同一批数据。</p></li>
<li><p>考虑多重假设检验。方法：在评估多个模型时，采用 <strong>Bonferroni校正</strong> 等方法降低假发现率。例如，对于 k 个模型评估，将置信水平调整为 <span class="math notranslate nohighlight">\(1 - \frac{0.05}{k}\)</span> ，确保整体误导概率维持在 5% 左右。</p></li>
<li><p>限制对测试集的访问频率。实践：设置明确的测试集访问次数上限（如最多3次），严格记录每次访问目的。在重大模型评估前，尽量减少对测试集的接触，仅在最终模型准备发布前使用测试集。</p></li>
<li><p>加大数据集规模。理由：大数据集更能抵抗过拟合风险，即使有一定程度的信息泄露，大规模数据仍能提供可靠评估。</p></li>
</ol>
</section>
</section>
<section id="statistical-learning-theory">
<h5>4.6.3. Statistical Learning Theory<a class="headerlink" href="#statistical-learning-theory" title="此标题的永久链接">¶</a></h5>
<section id="id41">
<h6>核心观点<a class="headerlink" href="#id41" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>模型泛化的根本难题在于如何保证训练误差接近真实误差。</p></li>
<li><p>解决路径：通过数学工具（如VC维度）建立泛化误差的上界，量化模型复杂性与数据样本数量之间的关系。</p></li>
<li><p>目标：实现一致收敛性，确保模型在训练集和测试集上的误差差距在可控范围内。</p></li>
</ul>
</section>
<section id="id42">
<h6>主要问题拆解<a class="headerlink" href="#id42" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><ol class="arabic simple">
<li><p>泛化问题的本质：“测试集是我们唯一的参考”：机器学习模型的性能评估依赖于测试集，但测试集的结果仅能反映事后泛化能力，无法提供事前泛化保证。困难点：即使一个模型在测试集上表现良好，也无法保证下一个模型（f_2, f_3, …）能持续泛化。</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="2">
<li><p>泛化误差与样本误差的差距：核心问题：经验误差 <span class="math notranslate nohighlight">\(\epsilon_\mathcal{S}\)</span> 接近真实误差 <span class="math notranslate nohighlight">\(\epsilon\)</span> 吗？如果模型仅在训练集上表现优秀，但在测试集或真实数据上效果不佳，就发生了过拟合。</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="3">
<li><p>模型类 <span class="math notranslate nohighlight">\(\mathcal{F}\)</span> 的复杂性：挑战：如何在复杂模型类中挑选既能拟合训练集又能泛化的模型？线性分类器通常泛化良好，但复杂的深度学习模型（函数集合非常大，$|mathcal{F}| = infty$）更容易过拟合。</p></li>
</ol>
</li>
</ul>
</section>
<section id="vc">
<h6>解决思路:一致收敛性与VC维度<a class="headerlink" href="#vc" title="此标题的永久链接">¶</a></h6>
<section id="uniform-convergence">
<h6 aria-level="7">1) 一致收敛性(Uniform Convergence)<a class="headerlink" href="#uniform-convergence" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>目标：确保所有模型在训练集和真实分布上的误差收敛到同一个小范围内。</p></li>
<li><p>定义：对于模型类中的所有模型 <span class="math notranslate nohighlight">\(f \in \mathcal{F}\)</span> ，希望以高概率保证：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[|\epsilon(f)-\epsilon_{\mathcal{S}}(f)| &lt; \alpha \quad \text { (for all } f \in \mathcal{F})\]</div>
<ul class="simple">
<li><p>其中 <span class="math notranslate nohighlight">\(\alpha\)</span> 是误差界限</p></li>
<li><dl class="simple">
<dt>挑战：</dt><dd><ul>
<li><p>过于灵活的模型类（如记忆机，能记住训练集上所有数据但泛化性极差）很难满足一致收敛性。</p></li>
<li><p>过于刚性的模型类则风险在于欠拟合，难以捕捉训练数据的规律。</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>平衡：学习理论的目标是在 <strong>模型灵活性（高方差）和模型刚性（高偏差）</strong> 之间找到平衡点。</p></li>
</ul>
</section>
<section id="vapnik-chervonenkis-vc">
<h6 aria-level="7">2) Vapnik-Chervonenkis (VC) 维度<a class="headerlink" href="#vapnik-chervonenkis-vc" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>VC 维度：衡量模型类的复杂性，反映模型拟合任意数据点的能力。</p></li>
<li><p>VC 维度提供了一种量化模型类复杂性的方法，但在实际应用中可能过于保守。</p></li>
</ul>
</section>
</section>
<section id="id43">
<h6>现实意义与应用<a class="headerlink" href="#id43" title="此标题的永久链接">¶</a></h6>
<ol class="arabic simple">
<li><dl class="simple">
<dt>经验误差 vs. 泛化误差</dt><dd><ul class="simple">
<li><p>小数据场景：训练误差低并不代表模型能泛化，可能是过拟合。</p></li>
<li><p>大数据场景：随着数据量 <code class="docutils literal notranslate"><span class="pre">n</span></code> 增加，经验误差逐渐收敛到真实误差。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>工程实践</dt><dd><ul class="simple">
<li><p>深度学习：复杂模型往往需要大量样本，即使训练集误差接近 0，也不能简单假设泛化误差很低。</p></li>
<li><p>自动驾驶等领域：高风险场景下通常采用更大的数据集和多重交叉验证，降低泛化误差的不确定性。</p></li>
</ul>
</dd>
</dl>
</li>
</ol>
</section>
</section>
</section>
<section id="environment-and-distribution-shift">
<h4>4.7. Environment and Distribution Shift<a class="headerlink" href="#environment-and-distribution-shift" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>分布漂移（Distribution Shift）</p></li>
</ul>
<section id="types-of-distribution-shift">
<h5>4.7.1. Types of Distribution Shift<a class="headerlink" href="#types-of-distribution-shift" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt>引言：</dt><dd><ul>
<li><p>提出分布漂移的概念，指出训练数据和测试数据可能来自不同的分布，直接影响模型性能。</p></li>
<li><p>强调在缺乏关于分布关系的假设下，鲁棒分类器的学习是不可能的。</p></li>
<li><p>通过二分类问题（猫狗分类）引出一个极端例子：如果输入分布保持不变，但标签完全反转，将无法区分分布是否发生变化。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>转折：</dt><dd><ul>
<li><p>说明在适当假设下，可以检测分布漂移，并可能动态调整模型以提升性能。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>核心思想</dt><dd><ul>
<li><p>分布漂移不可避免，但在合理假设下，可以检测和适应漂移。</p></li>
<li><p>关键是理解漂移来源（特征变化、标签变化或标签定义变化），并选择合适的算法来应对。</p></li>
<li><p>协变量漂移是最常研究的方向，因为特征分布变化直观且更易被监测到。</p></li>
<li><p>标签漂移更具挑战，通常需要在低维标签空间中操作，而不是直接在高维特征空间中处理漂移。</p></li>
<li><p>概念漂移最复杂，通常依赖外部知识或元学习方法来逐渐适应。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<section id="covariate-shift">
<h6>4.7.1.1. Covariate Shift<a class="headerlink" href="#covariate-shift" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>定义： 特征的分布 <span class="math notranslate nohighlight">\(p(\mathbf{x})\)</span> 发生变化，但标签条件分布 <span class="math notranslate nohighlight">\(P(y \mid \mathbf{x})\)</span> 保持不变。</p></li>
<li><p>示例：训练集是实物照片，测试集是卡通图像，特征分布（图片风格）变了，但猫狗的本质定义不变。</p></li>
<li><p>解释：协变量漂移常见于因果关系中，特征 <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> 影响标签 y 。需要重点关注模型如何适应新分布的特征。</p></li>
</ul>
</section>
<section id="label-shift">
<h6>4.7.1.2. Label Shift<a class="headerlink" href="#label-shift" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>定义： 标签分布 <span class="math notranslate nohighlight">\(P(y)\)</span> 发生变化，但类条件特征分布 <span class="math notranslate nohighlight">\(P(\mathbf{x} \mid y)\)</span> 保持不变。</p></li>
<li><p>示例：不同疾病的患病率变化，但疾病表现出的症状不变。</p></li>
<li><dl class="simple">
<dt>解释：</dt><dd><ul>
<li><p>标签漂移通常出现在标签 y 影响特征 <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> 的因果关系中。</p></li>
<li><p>操作标签的模型（低维）通常更易处理这种情况，而操作特征的模型（高维）难度较大。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="concept-shift">
<h6>4.7.1.3. Concept Shift<a class="headerlink" href="#concept-shift" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>定义： 标签本身的定义发生变化，即 <span class="math notranslate nohighlight">\(P(y \mid \mathbf{x})\)</span> 变化。</p></li>
<li><dl class="simple">
<dt>示例：</dt><dd><ul>
<li><p>不同地区对同一种软饮料有不同称呼（如 “pop” 和 “soda”）。</p></li>
<li><p>疾病诊断标准或时尚趋势随时间和地域变化。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>解释：</dt><dd><ul>
<li><p>概念漂移难以察觉，因为标签定义可能随时间或地理位置逐渐变化。</p></li>
<li><p>在自然语言处理或机器翻译中，概念漂移尤为明显。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
</section>
<section id="examples-of-distribution-shift">
<h5>4.7.2. Examples of Distribution Shift<a class="headerlink" href="#examples-of-distribution-shift" title="此标题的永久链接">¶</a></h5>
<section id="medical-diagnostics">
<h6>4.7.2.1. Medical Diagnostics<a class="headerlink" href="#medical-diagnostics" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>医疗诊断（Medical Diagnostics）</p></li>
<li><p>背景：目标是开发癌症检测算法，使用健康人和病人的血液样本进行训练。</p></li>
<li><p>问题：由于健康男性样本难以收集，创业公司选择了大学生血样作为对照组。</p></li>
<li><p>结果：分类器可以轻松区分健康和病人群体，但这是因为大学生和老年病人之间存在大量无关变量（年龄、激素水平、生活方式等）差异，而非疾病相关特征。</p></li>
<li><p>本质：极端协变量漂移（Covariate Shift），健康对照组和真实病人群体特征存在巨大差异，导致模型在真实世界表现不佳。</p></li>
<li><p>启示：数据采样过程必须匹配真实应用环境。不能仅为解决数据稀缺问题随意选择不具代表性的样本。</p></li>
</ul>
</section>
<section id="self-driving-cars">
<h6>4.7.2.2. Self-Driving Cars<a class="headerlink" href="#self-driving-cars" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>背景：公司希望用游戏引擎合成数据训练道路探测器，以减少标注数据的成本。</p></li>
<li><p>问题：在引擎测试数据上表现良好，但在真实环境中完全失败。</p></li>
<li><p>原因：道路纹理在游戏引擎中过于简单，并且所有道路都使用相同纹理。模型学习到的是纹理差异，而非真正的道路特征。</p></li>
<li><p>类似案例：美军曾试图通过航拍照片训练坦克探测器，但模型实际上只是学会了区分早晨和中午的树影差异。</p></li>
<li><p>本质：概念漂移或协变量漂移， 模型学到了错误特征，导致真实场景下表现不佳。</p></li>
<li><p>启示：合成数据需尽量贴近现实。避免训练数据和实际应用场景间存在严重差距。需要混合多种真实和合成数据来源，以减少模型对无关特征的依赖。</p></li>
</ul>
</section>
<section id="nonstationary-distributions">
<h6>4.7.2.3. Nonstationary Distributions<a class="headerlink" href="#nonstationary-distributions" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>非平稳分布（Nonstationary Distributions）</p></li>
<li><p>定义： 分布随时间缓慢变化，模型未能及时更新。</p></li>
<li><dl class="simple">
<dt>典型案例：</dt><dd><ul>
<li><p>广告模型未及时更新，新设备（如iPad）推出后未纳入训练，模型失效。</p></li>
<li><p>垃圾邮件过滤器过时，新型垃圾邮件逃过检测。</p></li>
<li><p>产品推荐系统滞后，仍推荐圣诞帽，未能适应季节变化。</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>本质：分布缓慢漂移， 随着时间推移模型性能逐渐下降。</p></li>
<li><p>启示：模型需要定期更新和重新训练 以适应环境变化。引入在线学习机制，使模型可以持续学习新数据。</p></li>
</ul>
</section>
</section>
<section id="correction-of-distribution-shift">
<h5>4.7.3. Correction of Distribution Shift<a class="headerlink" href="#correction-of-distribution-shift" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>本节是比较高级的功能，不理解也不影响后面章节的学习</p></li>
</ul>
<section id="empirical-risk-and-risk">
<h6>4.7.3.1. Empirical Risk and Risk<a class="headerlink" href="#empirical-risk-and-risk" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>风险定义与训练目标：训练模型时，我们的目标是使模型在训练数据上的损失最小化。</p></li>
</ul>
<section id="empirical-risk">
<h6 aria-level="7">1. 经验风险 (Empirical Risk)<a class="headerlink" href="#empirical-risk" title="此标题的永久链接">¶</a></h6>
<div class="math notranslate nohighlight">
\[\operatorname{minimize}_{f} \frac{1}{n} \sum_{i=1}^{n} l\left(f\left(\mathbf{x}_{i}\right), y_{i}\right)\]</div>
<ul class="simple">
<li><p>经验风险最小化, 即在训练数据集上计算损失并最小化平均损失。</p></li>
</ul>
</section>
<section id="true-risk">
<h6 aria-level="7">2. 真实风险 (True Risk)<a class="headerlink" href="#true-risk" title="此标题的永久链接">¶</a></h6>
<div class="math notranslate nohighlight">
\[E_{p(\mathbf{x}, y)}[l(f(\mathbf{x}), y)]=\iint l(f(\mathbf{x}), y) p(\mathbf{x}, y) d \mathbf{x} d y\]</div>
<ul class="simple">
<li><p>真实风险考虑的是整个数据分布 <span class="math notranslate nohighlight">\(p(\mathbf{x}, y)\)</span> ，但实际情况中无法获取整个分布，所以只能使用经验风险近似最小化真实风险。</p></li>
</ul>
</section>
</section>
<section id="covariate-shift-correction">
<h6>4.7.3.2. Covariate Shift Correction<a class="headerlink" href="#covariate-shift-correction" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>定义：特征的分布 <span class="math notranslate nohighlight">\(p(\mathbf{x})\)</span> 发生变化，但条件分布 <span class="math notranslate nohighlight">\(p(y|\mathbf{x})\)</span> 保持不变。</p></li>
<li><p>问题：训练数据来自源分布 <span class="math notranslate nohighlight">\(q(\mathbf{x})\)</span> ，但测试数据来自目标分布 <span class="math notranslate nohighlight">\(p(\mathbf{x})\)</span> 。如果源分布和目标分布不同，模型在测试集上的表现可能很差。</p></li>
<li><p>解决方案：通过重加权 (Re-weighting) 技术调整训练数据的权重，使其更符合目标分布。</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{aligned}
\int\int l(f(\mathbf{x}), y) p(y \mid \mathbf{x})p(\mathbf{x}) \;d\mathbf{x}dy =
\int\int l(f(\mathbf{x}), y) q(y \mid \mathbf{x})q(\mathbf{x})\frac{p(\mathbf{x})}{q(\mathbf{x})} \;d\mathbf{x}dy.
\end{aligned}\]</div>
<ul class="simple">
<li><p>即，将每个样本的权重乘以 <span class="math notranslate nohighlight">\(\beta_i = \frac{p(\mathbf{x}_i)}{q(\mathbf{x}_i)}\)</span> ，从而校正协变量漂移。</p></li>
<li><dl class="simple">
<dt>实际操作步骤：</dt><dd><ul>
<li><p>训练一个分类器，区分目标分布 <span class="math notranslate nohighlight">\(p(\mathbf{x})\)</span>  和源分布 <span class="math notranslate nohighlight">\(q(\mathbf{x})\)</span>  的样本。</p></li>
<li><p>使用逻辑回归计算 <span class="math notranslate nohighlight">\(\beta_i = \exp(h(\mathbf{x}_i))\)</span> ，得到校正权重。</p></li>
<li><p>在模型训练时，对每个样本 <span class="math notranslate nohighlight">\((\mathbf{x}_i, y_i)\)</span>  乘以 <span class="math notranslate nohighlight">\(\beta_i\)</span>  进行加权经验风险最小化。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="label-shift-correction">
<h6>4.7.3.3. Label Shift Correction<a class="headerlink" href="#label-shift-correction" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>解决方案：通过计算标签分布 p(y) 和 q(y) 的比值 <span class="math notranslate nohighlight">\(\beta_i = \frac{p(y_i)}{q(y_i)}\)</span> 进行校正。</p></li>
<li><p>公式推导：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{aligned}
\int\int l(f(\mathbf{x}), y) p(\mathbf{x} \mid y)p(y) \;d\mathbf{x}dy =
\int\int l(f(\mathbf{x}), y) q(\mathbf{x} \mid y)q(y)\frac{p(y)}{q(y)} \;d\mathbf{x}dy.
\end{aligned}\]</div>
</section>
<section id="concept-shift-correction">
<h6>4.7.3.4. Concept Shift Correction<a class="headerlink" href="#concept-shift-correction" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>问题：例如，从区分猫和狗转变为区分白色和黑色动物，这种变化很难通过简单的方法校正。</p></li>
<li><dl class="simple">
<dt>解决方案：</dt><dd><ul>
<li><p>对于渐变的漂移，可以在现有模型上进行少量更新，而非从头训练新模型。</p></li>
<li><p>对于剧烈的漂移，通常需要重新收集数据和标签，重新训练模型。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>实际应用示例：</dt><dd><ul>
<li><p>广告推荐：用户兴趣变化，新产品上线。</p></li>
<li><p>交通摄像头：镜头老化导致图像质量下降。</p></li>
<li><p>新闻推荐：新闻内容不断更新，新事件出现。</p></li>
<li><p>通过持续学习 (Continual Learning) 或迁移学习 (Transfer Learning) 应对概念漂移。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
</section>
<section id="a-taxonomy-of-learning-problems">
<h5>4.7.4. A Taxonomy of Learning Problems<a class="headerlink" href="#a-taxonomy-of-learning-problems" title="此标题的永久链接">¶</a></h5>
<section id="batch-learning">
<h6>4.7.4.1. Batch Learning<a class="headerlink" href="#batch-learning" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><dl class="simple">
<dt>概念：在批量学习中，我们拥有一个完整的训练数据集 <span class="math notranslate nohighlight">\({(\mathbf{x}_1, y_1), \dots, (\mathbf{x}_n, y_n)}\)</span></dt><dd><ul>
<li><p>模型 :math`f(mathbf{x})` 是在所有数据都已知的情况下训练完成的。</p></li>
<li><p>训练完成后，模型部署在真实环境中，不再进行更新（除非有重大错误或特殊情况）。</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>示例：训练一个猫狗分类器，用于智能猫门。当模型训练完成并安装在客户家中后，它不会再改变或学习新的数据。</p></li>
<li><dl class="simple">
<dt>特点：</dt><dd><ul>
<li><p>训练和推理是分开的。</p></li>
<li><p>适用于静态、不经常变化的任务。</p></li>
<li><p>训练数据与未来数据分布一致时效果最好。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="online-learning">
<h6>4.7.4.2. Online Learning<a class="headerlink" href="#online-learning" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><dl class="simple">
<dt>概念：数据逐个到达，模型需要逐步学习，每次接收一个样本 <span class="math notranslate nohighlight">\((\mathbf{x}_i, y_i)\)</span></dt><dd><ul>
<li><p>在观察到标签 <span class="math notranslate nohighlight">\(y_i\)</span> 之前，模型先基于 <span class="math notranslate nohighlight">\(\mathbf{x}_i\)</span> 给出预测。</p></li>
<li><p>在得到标签后，模型根据损失进行更新，逐渐变得更好。</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>示例：股票价格预测：每天预测第二天的股价，等到实际价格出来后，再更新模型，调整预测方式。</p></li>
<li><dl class="simple">
<dt>流程：</dt><dd><ul>
<li><p>使用模型 <span class="math notranslate nohighlight">\(f_t\)</span> 对新的数据 <span class="math notranslate nohighlight">\(\mathbf{x}_t\)</span> 进行预测。</p></li>
<li><p>观察真实标签 <span class="math notranslate nohighlight">\(y_t\)</span> 并计算损失。</p></li>
<li><p>更新模型 <span class="math notranslate nohighlight">\(f_{t+1}\)</span> 以改进下一次预测。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<div class="math notranslate nohighlight">
\[f_t \rightarrow \mathbf{x}_t \rightarrow f_t(\mathbf{x}_t) \rightarrow y_t \rightarrow l(y_t, f_t(\mathbf{x}_t)) \rightarrow f_{t+1}\]</div>
<ul class="simple">
<li><dl class="simple">
<dt>特点：</dt><dd><ul>
<li><p>持续学习和更新模型</p></li>
<li><p>适用于环境动态变化、数据不断流入的场景</p></li>
<li><p>可应对概念漂移（concept shift）</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="bandits">
<h6>4.7.4.3. Bandits<a class="headerlink" href="#bandits" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><dl class="simple">
<dt>概念：</dt><dd><ul>
<li><p>多臂老虎机是一类特殊的在线学习问题</p></li>
<li><p>不同于连续参数模型（如神经网络），Bandit 只有有限个动作或选择</p></li>
<li><p>目标是找到收益最高的“拉杆”或动作</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>示例：</dt><dd><ul>
<li><p>在线广告推荐：在多个广告中选择一个展示，观察点击率，不断调整选择策略。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>特点：</dt><dd><ul>
<li><p>只需在有限选项中进行决策</p></li>
<li><p>通常具有较强的理论保证和优化策略</p></li>
<li><p>算法更简单，但问题范围更狭窄</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="control">
<h6>4.7.4.4. Control<a class="headerlink" href="#control" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><dl class="simple">
<dt>概念：</dt><dd><ul>
<li><p>环境会记住模型的决策，下一次的观测值依赖于之前的行为。</p></li>
<li><p>不一定是对抗性的，但模型的行为会影响未来状态。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>示例：</dt><dd><ul>
<li><p>咖啡机的温度控制器：是否继续加热取决于当前温度以及之前的加热状态。</p></li>
<li><p>新闻推荐系统：用户是否点击新闻取决于之前推荐的内容。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>特点：</dt><dd><ul>
<li><p>模型需要记忆和考虑过去的行为。</p></li>
<li><p>经常使用控制理论方法，如 PID 控制器。</p></li>
<li><p>可用于环境交互式决策问题。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="id44">
<h6>4.7.4.5. Reinforcement Learning<a class="headerlink" href="#id44" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><dl class="simple">
<dt>概念：</dt><dd><ul>
<li><p>强化学习是在复杂环境中进行决策的更高级形式。</p></li>
<li><p>环境可能是合作的（例如多玩家合作游戏），也可能是竞争的（如象棋、围棋）。</p></li>
<li><p>模型需要通过与环境交互，不断学习以最大化累积奖励。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>示例：</dt><dd><ul>
<li><p>游戏 AI：在象棋、围棋或电子竞技游戏中，自主学习对抗策略。</p></li>
<li><p>自动驾驶：其他车辆的行为会受到自动驾驶车辆的影响。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>特点：</dt><dd><ul>
<li><p>适用于复杂、有记忆的动态环境。</p></li>
<li><p>强调长期策略和累积奖励。</p></li>
<li><p>环境的反馈（奖励或惩罚）决定模型更新方式。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="considering-the-environment">
<h6>4.7.4.6. Considering the Environment<a class="headerlink" href="#considering-the-environment" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><dl class="simple">
<dt>核心思想：</dt><dd><ul>
<li><p>不同环境下，模型的表现和策略可能完全不同</p></li>
<li><p>在静态环境中，一个有效的策略可能在动态环境中失效</p></li>
<li><p>环境的变化速度和方式，决定了需要使用哪种学习方法</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>示例：</dt><dd><ul>
<li><p>金融市场：套利机会一旦被发现并利用，市场会迅速调整，套利机会消失。</p></li>
<li><p>推荐系统：用户兴趣随时间变化，需要动态更新模型。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>解决方法：</dt><dd><ul>
<li><dl class="simple">
<dt>缓慢变化的环境：</dt><dd><ul>
<li><p>约束模型的更新速度，使其缓慢适应环境变化。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>快速但偶尔变化的环境：</dt><dd><ul>
<li><p>在环境突然变化时允许模型迅速调整，但日常变化较少。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="id45">
<h6>总结<a class="headerlink" href="#id45" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>批量学习：静态、一次性训练。</p></li>
<li><p>在线学习：逐步更新模型，适应动态环境。</p></li>
<li><p>Bandit：有限动作选择问题，优化奖励。</p></li>
<li><p>控制：环境会记住模型的行为，状态依赖历史。</p></li>
<li><p>强化学习：复杂动态环境中通过奖励学习策略。</p></li>
</ul>
</section>
</section>
</section>
</section>
<section id="multilayer-perceptrons">
<h3>5. Multilayer Perceptrons<a class="headerlink" href="#multilayer-perceptrons" title="此标题的永久链接">¶</a></h3>
<section id="id46">
<h4>5.1. Multilayer Perceptrons<a class="headerlink" href="#id46" title="此标题的永久链接">¶</a></h4>
<section id="hidden-layers">
<h5>5.1.1. Hidden Layers<a class="headerlink" href="#hidden-layers" title="此标题的永久链接">¶</a></h5>
<section id="limitations-of-linear-models">
<h6>5.1.1.1. Limitations of Linear Models<a class="headerlink" href="#limitations-of-linear-models" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>线性模型的局限性：线性模型假输出是输入的线性变换。这种假设太强，导致模型难以拟合复杂关系。</p></li>
<li><p>如：预测贷款偿还概率时，收入增长对偿还概率的影响并非线性（收入从 0 美元增加到 5 万美元可能比从 100 万美元增加到 105 万美元对应的还款可能性更大）。</p></li>
<li><p>如：体温与健康关系：对于正常体温高于 37°C (98.6°F) 的人来说，温度越高表明风险越大。然而，如果体温低于37°C，较低的温度表明风险更大！</p></li>
<li><p>如：图像分类问题：简单线性模型假设像素强度与输出类别直接相关，这对于复杂任务（如猫狗分类）效果很差。</p></li>
</ul>
</section>
<section id="incorporating-hidden-layers">
<h6>5.1.1.2. Incorporating Hidden Layers<a class="headerlink" href="#incorporating-hidden-layers" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>多层感知机引入隐藏层</p></li>
<li><p>通过叠加隐藏层，使模型学习数据复杂的非线性关系。</p></li>
<li><p>MLP由多个全连接层组成，前面几层负责学习特征表示，最后一层执行线性预测。</p></li>
</ul>
<figure class="align-default" id="id222">
<img alt="https://img.zhaoweiguo.com/uPic/2024/12/5DOnFP.png" src="https://img.zhaoweiguo.com/uPic/2024/12/5DOnFP.png" />
<figcaption>
<p><span class="caption-text">Fig. 5.1.1 An MLP(multilayer perceptron) with a hidden layer of five hidden units.</span><a class="headerlink" href="#id222" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
</section>
<section id="from-linear-to-nonlinear">
<h6>5.1.1.3. From Linear to Nonlinear<a class="headerlink" href="#from-linear-to-nonlinear" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>激活函数的必要性</p></li>
<li><p>如果隐藏层仅仅是线性变换，模型仍然等效于单层线性模型，无法真正提升表达能力。</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf{O} = (\mathbf{X} \mathbf{W}^{(1)} + \mathbf{b}^{(1)})\mathbf{W}^{(2)} + \mathbf{b}^{(2)} \\
           = \mathbf{X} \mathbf{W}^{(1)}\mathbf{W}^{(2)} + \mathbf{b}^{(1)} \mathbf{W}^{(2)} + \mathbf{b}^{(2)} \\
           = \mathbf{X} \mathbf{W} + \mathbf{b}.\end{split}\]</div>
<ul class="simple">
<li><p>解决方法：在每个隐藏单元后引入非线性激活函数（如ReLU），破除线性限制，使模型具备拟合复杂函数的能力。</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    \mathbf{H} &amp; = \sigma(\mathbf{X} \mathbf{W}^{(1)} + \mathbf{b}^{(1)}), \\
    \mathbf{O} &amp; = \mathbf{H}\mathbf{W}^{(2)} + \mathbf{b}^{(2)}.\\
\end{aligned}\end{split}\]</div>
<ul class="simple">
<li><p>为了构建更通用的 MLP，我们可以继续堆叠这样的隐藏层</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf{H}^{(1)} = \sigma_1(\mathbf{X} \mathbf{W}^{(1)} + \mathbf{b}^{(1)}) \\
\mathbf{H}^{(2)} = \sigma_2(\mathbf{H}^{(1)} \mathbf{W}^{(2)} + \mathbf{b}^{(2)})\end{split}\]</div>
</section>
<section id="universal-approximators">
<h6>5.1.1.4. Universal Approximators<a class="headerlink" href="#universal-approximators" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>通用逼近定理：即使只有一个隐藏层，只要神经元足够多，MLP可以逼近任意复杂函数。</p></li>
<li><p>深度网络的优势：尽管单隐藏层能拟合任意函数，但更深的网络可以用更少的参数表达复杂函数，更高效、更易训练。</p></li>
<li><p>MLP是解决复杂任务的基石，但设计深度和宽度需权衡。</p></li>
<li><p>实际中，MLP与卷积网络、递归网络等结合，进一步提升模型表现。</p></li>
</ul>
</section>
</section>
<section id="activation-functions">
<h5>5.1.2. Activation Functions<a class="headerlink" href="#activation-functions" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>激活函数通过计算加权和并进一步添加偏差来决定是否应该激活神经元。</p></li>
<li><p>它们是可微分算子，用于将输入信号转换为输出，但大多数都增加了非线性。</p></li>
<li><p>5.1.2.1. ReLU Function</p></li>
<li><p>5.1.2.2. Sigmoid Function</p></li>
<li><p>5.1.2.3. Tanh Function</p></li>
</ul>
</section>
</section>
<section id="implementation-of-multilayer-perceptrons">
<h4>5.2. Implementation of Multilayer Perceptrons<a class="headerlink" href="#implementation-of-multilayer-perceptrons" title="此标题的永久链接">¶</a></h4>
<section id="id47">
<h5>5.2.1. Implementation from Scratch<a class="headerlink" href="#id47" title="此标题的永久链接">¶</a></h5>
<p>5.2.1.1. Initializing Model Parameters:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">MLPScratch</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Classifier</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span> <span class="o">*</span> <span class="n">sigma</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">)</span> <span class="o">*</span> <span class="n">sigma</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_outputs</span><span class="p">))</span>
</pre></div>
</div>
<p>5.2.1.2. Model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">relu</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>

<span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">MLPScratch</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_inputs</span><span class="p">))</span>
    <span class="n">H</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W1</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W2</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b2</span>
</pre></div>
</div>
<p>5.2.1.3. Training:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># 训练循环与 softmax 回归完全相同</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MLPScratch</span><span class="p">(</span><span class="n">num_inputs</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">num_outputs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id48">
<h5>5.2.2. Concise Implementation<a class="headerlink" href="#id48" title="此标题的永久链接">¶</a></h5>
<p>5.2.2.1. Model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># 和之前的区别是这儿有两个全连接层(第一个隐藏层，第二个输出层)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">MLP</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Classifier</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">lr</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">num_outputs</span><span class="p">)</span>
        <span class="p">)</span>
</pre></div>
</div>
<p>5.2.2.2. Training:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># 与实现 softmax 回归时完全相同。这种模块化使我们能够将有关模型架构的问题与其他无关的因素分离开来</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">num_outputs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="forward-propagation-backward-propagation-and-computational-graphs">
<h4>5.3. Forward Propagation, Backward Propagation, and Computational Graphs<a class="headerlink" href="#forward-propagation-backward-propagation-and-computational-graphs" title="此标题的永久链接">¶</a></h4>
<section id="forward-propagation">
<h5>5.3.1. Forward Propagation<a class="headerlink" href="#forward-propagation" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>前向传播是神经网络的核心计算步骤，它指的是按照从输入层到输出层的顺序，计算和存储中间变量（包括输出）。简单来说，就是把输入数据一层层地传递，最终得到输出结果。</p></li>
</ul>
<section id="id49">
<h6>1. 输入与权重矩阵<a class="headerlink" href="#id49" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>假设我们有一个输入样本 <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathbb{R}^d\)</span> ，表示 d 维特征的数据。</p></li>
<li><p>隐藏层的权重矩阵 <span class="math notranslate nohighlight">\(\mathbf{W}^{(1)} \in \mathbb{R}^{h \times d}\)</span> 将输入 <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> 映射到隐藏层：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\mathbf{z} = \mathbf{W}^{(1)}\mathbf{x}\]</div>
<ul class="simple">
<li><p><strong>z</strong> 是隐藏层的线性变换结果，长度为 h，表示隐藏层有 h 个神经元</p></li>
</ul>
</section>
<section id="id50">
<h6>2. 激活函数与隐藏层输出<a class="headerlink" href="#id50" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>应用一个激活函数 <span class="math notranslate nohighlight">\(\phi\)</span> ：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\mathbf{h} = \phi(\mathbf{z})\]</div>
<ul class="simple">
<li><p><strong>h</strong> 是隐藏层的激活输出，长度为 h</p></li>
<li><p>激活函数 <span class="math notranslate nohighlight">\(\phi\)</span> 引入了非线性，确保模型能学习复杂的非线性关系</p></li>
</ul>
</section>
<section id="id51">
<h6>3. 输出层计算<a class="headerlink" href="#id51" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>隐藏层输出 <span class="math notranslate nohighlight">\(\mathbf{h}\)</span> 再次经过输出层的权重矩阵 <span class="math notranslate nohighlight">\(\mathbf{W}^{(2)} \in \mathbb{R}^{q \times h}\)</span> 变换，生成最终输出：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\mathbf{o} = \mathbf{W}^{(2)}\mathbf{h}\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{o}\)</span> 是输出层的结果，长度为 q，表示有 q 个输出单元。</p></li>
</ul>
</section>
<section id="id52">
<h6>4. 计算损失<a class="headerlink" href="#id52" title="此标题的永久链接">¶</a></h6>
<p>输出 <span class="math notranslate nohighlight">\(\mathbf{o}\)</span> 通过损失函数 l 与真实标签 y 计算损失：</p>
<div class="math notranslate nohighlight">
\[L = l(\mathbf{o}, y)\]</div>
<ul class="simple">
<li><p>L 是单个样本的损失值，反映了模型输出与真实值之间的差距。</p></li>
</ul>
</section>
<section id="id53">
<h6>5. 正则化项<a class="headerlink" href="#id53" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>为了防止过拟合，我们可以引入 <span class="math notranslate nohighlight">\(\ell_2\)</span> 正则化项：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[s = \frac{\lambda}{2} \left( \|\mathbf{W}^{(1)}\|_F^2 + \|\mathbf{W}^{(2)}\|_F^2 \right)\]</div>
<ul class="simple">
<li><p>其中 <span class="math notranslate nohighlight">\(\lambda\)</span> 是正则化强度的超参数。</p></li>
<li><p><span class="math notranslate nohighlight">\(\|\mathbf{W}^{(1)}\|_F^2\)</span> 和 <span class="math notranslate nohighlight">\(\|\mathbf{W}^{(2)}\|_F^2\)</span> 分别是权重矩阵的 Frobenius 范数，相当于将矩阵展平后计算 <span class="math notranslate nohighlight">\(\ell_2\)</span> 范数。</p></li>
</ul>
</section>
<section id="id54">
<h6>6. 目标函数<a class="headerlink" href="#id54" title="此标题的永久链接">¶</a></h6>
<p>最终的目标函数是：</p>
<div class="math notranslate nohighlight">
\[𝐽 = 𝐿 + 𝑠\]</div>
<ul class="simple">
<li><p>J 表示带正则化的损失函数，是模型需要最小化的目标</p></li>
<li><p>在训练过程中，我们优化的是 J，以便在损失与模型复杂度之间取得平衡</p></li>
</ul>
</section>
</section>
<section id="computational-graph-of-forward-propagation">
<h5>5.3.2. Computational Graph of Forward Propagation<a class="headerlink" href="#computational-graph-of-forward-propagation" title="此标题的永久链接">¶</a></h5>
<figure class="align-default" id="id223">
<img alt="https://img.zhaoweiguo.com/uPic/2024/12/BvIxOt.png" src="https://img.zhaoweiguo.com/uPic/2024/12/BvIxOt.png" />
<figcaption>
<p><span class="caption-text">Fig. 5.3.1 Computational graph of forward propagation.</span><a class="headerlink" href="#id223" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>其中正方形表示变量，圆圈表示运算符。</p></li>
<li><p>左下角表示输入，右上角表示 输出。</p></li>
</ul>
</section>
<section id="backpropagation">
<h5>5.3.3. Backpropagation<a class="headerlink" href="#backpropagation" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>反向传播是神经网络中用于计算参数梯度的方法。</p></li>
<li><p>简单来说，它是通过从输出层向输入层的反向遍历，根据微积分中的链式法则逐步计算梯度的过程。</p></li>
</ul>
<section id="id55">
<h6>1. 链式法则<a class="headerlink" href="#id55" title="此标题的永久链接">¶</a></h6>
<div class="math notranslate nohighlight">
\[\frac{\partial \mathsf{Z}}{\partial \mathsf{X}} = \textrm{prod}\left(\frac{\partial \mathsf{Z}}{\partial \mathsf{Y}}, \frac{\partial \mathsf{Y}}{\partial \mathsf{X}}\right)\]</div>
</section>
<section id="id56">
<h6>2. 反向传播目标<a class="headerlink" href="#id56" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>假设一个简单的单隐藏层神经网络，参数包括：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}隐藏层权重矩阵： \mathbf{W}^{(1)} \\
输出层权重矩阵： \mathbf{W}^{(2)} \\\end{split}\\\begin{split}目标是计算梯度： \\
\partial J / \partial \mathbf{W}^{(1)} \\
\partial J / \partial \mathbf{W}^{(2)}\end{split}\end{aligned}\end{align} \]</div>
</section>
<section id="id57">
<h6>3. 逐步计算过程<a class="headerlink" href="#id57" title="此标题的永久链接">¶</a></h6>
<ol class="arabic simple">
<li><p>计算目标函数对损失项和正则化项的梯度</p></li>
</ol>
<div class="math notranslate nohighlight">
\[\frac{\partial J}{\partial L} = 1 \quad \text{和} \quad \frac{\partial J}{\partial s} = 1\]</div>
<ol class="arabic simple" start="2">
<li><p>计算对输出层变量 <span class="math notranslate nohighlight">\(\mathbf{o}\)</span> 的梯度</p></li>
</ol>
<div class="math notranslate nohighlight">
\[\frac{\partial J}{\partial \mathbf{o}} = \frac{\partial L}{\partial \mathbf{o}} \in \mathbb{R}^q\]</div>
<ol class="arabic simple" start="3">
<li><p>计算正则化项对参数的梯度</p></li>
</ol>
<div class="math notranslate nohighlight">
\[\frac{\partial s}{\partial \mathbf{W}^{(1)}} = \lambda \mathbf{W}^{(1)} \quad \text{和} \quad \frac{\partial s}{\partial \mathbf{W}^{(2)}} = \lambda \mathbf{W}^{(2)}\]</div>
<ol class="arabic simple" start="4">
<li><p>计算输出层参数 <span class="math notranslate nohighlight">\(\mathbf{W}^{(2)}\)</span> 的梯度</p></li>
</ol>
<div class="math notranslate nohighlight">
\[\frac{\partial J}{\partial \mathbf{W}^{(2)}} = \frac{\partial J}{\partial \mathbf{o}} \mathbf{h}^\top + \lambda \mathbf{W}^{(2)}\]</div>
<ul class="simple">
<li><p>输出层权重梯度等于 <strong>损失对输出的梯度</strong> 乘以 <strong>隐藏层激活输出</strong> ，再加上 <strong>正则化项</strong></p></li>
</ul>
<ol class="arabic simple" start="5">
<li><p>计算隐藏层输出 <span class="math notranslate nohighlight">\(\mathbf{h}\)</span> 的梯度</p></li>
</ol>
<div class="math notranslate nohighlight">
\[\frac{\partial J}{\partial \mathbf{h}} = {\mathbf{W}^{(2)}}^\top \frac{\partial J}{\partial \mathbf{o}}\]</div>
<ol class="arabic simple" start="6">
<li><p>计算隐藏层激活前变量 <span class="math notranslate nohighlight">\(\mathbf{z}\)</span> 的梯度</p></li>
</ol>
<div class="math notranslate nohighlight">
\[\frac{\partial J}{\partial \mathbf{z}} = \frac{\partial J}{\partial \mathbf{h}} \odot \phi'(\mathbf{z})\]</div>
<ul class="simple">
<li><p>这里使用逐元素乘法 <span class="math notranslate nohighlight">\(\odot\)</span> ，表示对激活函数的导数。</p></li>
</ul>
<ol class="arabic simple" start="7">
<li><p>计算输入层参数 <span class="math notranslate nohighlight">\(\mathbf{W}^{(1)}\)</span> 的梯度</p></li>
</ol>
<div class="math notranslate nohighlight">
\[\frac{\partial J}{\partial \mathbf{W}^{(1)}} = \frac{\partial J}{\partial \mathbf{z}} \mathbf{x}^\top + \lambda \mathbf{W}^{(1)}\]</div>
<ul class="simple">
<li><p>最终，输入层权重的梯度是损失对 <span class="math notranslate nohighlight">\(\mathbf{z}\)</span>  的梯度乘以输入 <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> ，再加上正则化项。</p></li>
</ul>
</section>
<section id="id58">
<h6>小结<a class="headerlink" href="#id58" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>反向传播逐层计算梯度，从输出层反向回溯到输入层。</p></li>
<li><p>每一步都应用链式法则，将损失项和正则化项对参数的梯度进行累积。</p></li>
<li><p>最终计算出的梯度用于更新模型参数，逐步降低目标函数 J，实现模型优化。</p></li>
</ul>
</section>
</section>
<section id="training-neural-networks">
<h5>5.3.4. Training Neural Networks<a class="headerlink" href="#training-neural-networks" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>训练神经网络时，前向传播和后向传播相互依赖。</p></li>
<li><p>正向传播：按计算图的依赖关系，从输入层开始，一直到输出层，计算并存储中间变量。</p></li>
<li><p>反向传播：在反方向上，从输出层回到输入层，利用正向传播中存储的中间变量计算梯度。</p></li>
</ul>
<section id="id59">
<h6>训练过程的交替进行<a class="headerlink" href="#id59" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>模型初始化：先初始化模型参数。</p></li>
<li><dl class="simple">
<dt>交替进行：</dt><dd><ul>
<li><p>正向传播：计算输出和损失函数，存储中间变量。</p></li>
<li><p>反向传播：利用存储的中间变量，计算梯度并更新模型参数。</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>关键点：反向传播重用正向传播存储的中间变量，避免重复计算。</p></li>
</ul>
</section>
<section id="id60">
<h6>内存占用<a class="headerlink" href="#id60" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>中间变量的保留：正向传播产生的中间变量需要保留，直到反向传播完成。这是训练阶段内存占用较高的主要原因之一。</p></li>
<li><dl class="simple">
<dt>内存消耗的影响因素：</dt><dd><ul>
<li><p>网络层数：层数越多，中间变量越多，占用的内存越大。</p></li>
<li><p>批大小 (batch size)：批量大小越大，中间变量的数量和大小也会增加。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>在训练神经网络时，一旦模型参数初始化，我们就交替前向传播和反向传播，使用反向传播给出的梯度来更新模型参数。请注意，反向传播重用前向传播中存储的中间值以避免重复计算。结果之一是我们需要保留中间值，直到反向传播完成。这也是训练比普通预测需要更多内存的原因之一。</p>
</div>
</section>
</section>
<section id="id61">
<h5>5.3.5. Summary<a class="headerlink" href="#id61" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>前向传播顺序计算并存储神经网络定义的计算图中的中间变量。它从输入层进行到输出层。</p></li>
<li><p>反向传播以相反的顺序顺序计算并存储神经网络内中间变量和参数的梯度。</p></li>
<li><p>在训练深度学习模型时，前向传播和反向传播是相互依赖的，并且训练需要的内存明显多于预测。</p></li>
</ul>
</section>
</section>
<section id="numerical-stability-and-initialization">
<h4>5.4. Numerical Stability and Initialization<a class="headerlink" href="#numerical-stability-and-initialization" title="此标题的永久链接">¶</a></h4>
<section id="vanishing-and-exploding-gradients">
<h5>5.4.1. Vanishing and Exploding Gradients<a class="headerlink" href="#vanishing-and-exploding-gradients" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>核心问题：在深度神经网络中，随着网络层数增加，反向传播过程中梯度可能变得非常小（消失）或非常大（爆炸）。这会导致模型难以收敛或学习速度极慢。</p></li>
</ul>
<section id="id62">
<h6>1. 数学背景与直观理解<a class="headerlink" href="#id62" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>考虑一个深度网络 <code class="docutils literal notranslate"><span class="pre">L</span> <span class="pre">layers</span></code> ，输入 <strong>x</strong> 和输出 <strong>o</strong> 。</p></li>
<li><p>With each layer l defined by a transformation <span class="math notranslate nohighlight">\(f_l\)</span> parametrized by weights <span class="math notranslate nohighlight">\(\mathbf{W}^{(l)}\)</span></p></li>
<li><p>其隐藏层输出为 <span class="math notranslate nohighlight">\(\mathbf{h}^{(l)}\)</span> （让 <span class="math notranslate nohighlight">\(\mathbf{h}^{(0)} = \mathbf{x}\)</span> ），我们的网络可以表示为：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}\mathbf{h}^{(l)} = f_l (\mathbf{h}^{(l-1)}) \\
因此: \mathbf{o} = f_L \circ \cdots \circ f_1(\mathbf{x}) \\\end{split}\\\mathbf{h}^{(l)} 表示第 $l$ 层的输出，$\mathbf{W}^{(l)}$ 是第 $l$ 层的权重\end{aligned}\end{align} \]</div>
<ul class="simple">
<li><p>如果所有隐藏层的输出和输入都是向量，我们可以写成 <span class="math notranslate nohighlight">\(\mathbf{o}\)</span> 相对于任何一组参数 <span class="math notranslate nohighlight">\(\mathbf{W}^{(l)}\)</span> 的梯度</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\partial_{\mathbf{W}^{(l)}} \mathbf{o} = \underbrace{\partial_{\mathbf{h}^{(L-1)}} \mathbf{h}^{(L)}}_{ \mathbf{M}^{(L)} \stackrel{\textrm{def}}{=}} \cdots \underbrace{\partial_{\mathbf{h}^{(l)}} \mathbf{h}^{(l+1)}}_{ \mathbf{M}^{(l+1)} \stackrel{\textrm{def}}{=}} \underbrace{\partial_{\mathbf{W}^{(l)}} \mathbf{h}^{(l)}}_{ \mathbf{v}^{(l)} \stackrel{\textrm{def}}{=}}\]</div>
<p>直观理解:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>梯度爆炸：梯度非常大，参数更新太剧烈，模型无法收敛，甚至损坏。
梯度消失：梯度接近零，参数更新缓慢或不更新，学习停滞。
</pre></div>
</div>
</section>
<section id="vanishing-gradient">
<h6>2. 梯度消失(Vanishing Gradient)<a class="headerlink" href="#vanishing-gradient" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><dl class="simple">
<dt>主要原因：激活函数的选择，尤其是 sigmoid 函数。</dt><dd><ul>
<li><p>sigmoid 函数在输入值非常大或非常小时，导数接近零。</p></li>
<li><p>导致反向传播过程中，梯度层层相乘，最终趋近于零。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>解决方案：</dt><dd><ul>
<li><p>使用 ReLU（Rectified Linear Unit）激活函数：</p></li>
<li><p>ReLU 函数在正区间梯度为 1，在负区间梯度为 0，避免了梯度消失问题。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="exploding-gradient">
<h6>3. 梯度爆炸(Exploding Gradient)<a class="headerlink" href="#exploding-gradient" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><dl class="simple">
<dt>主要原因：权重矩阵 <span class="math notranslate nohighlight">\(\mathbf{W}^{(l)}\)</span> 的初始值不合适，或者网络太深。</dt><dd><ul>
<li><p>层与层之间权重矩阵乘积可能导致梯度指数级增长。</p></li>
<li><p>权重矩阵的特征值较大，导致整体梯度爆炸。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<p>示例-多次相乘后，矩阵值爆炸:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">M</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">M</span> <span class="o">@</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
<span class="c1"># 输出</span>
<span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">7.9222e+22</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1940e+23</span><span class="p">,</span>  <span class="mf">1.0915e+23</span><span class="p">,</span>  <span class="mf">1.0751e+23</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">3.8837e+22</span><span class="p">,</span>  <span class="mf">5.8528e+22</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.3505e+22</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.2693e+22</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.9618e+22</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.9577e+22</span><span class="p">,</span>  <span class="mf">2.7037e+22</span><span class="p">,</span>  <span class="mf">2.6641e+22</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">3.0163e+22</span><span class="p">,</span>  <span class="mf">4.5455e+22</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.1554e+22</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.0923e+22</span><span class="p">]])</span>
</pre></div>
</div>
<ul class="simple">
<li><dl class="simple">
<dt>解决方案：</dt><dd><ul>
<li><p>梯度裁剪（Gradient Clipping）：设置梯度阈值，超过阈值的梯度会被缩放。</p></li>
<li><p>权重初始化：使用 Xavier 初始化或 He 初始化，保持初始梯度稳定。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="breaking-symmetry">
<h6>4. 对称性破坏问题(Breaking Symmetry)<a class="headerlink" href="#breaking-symmetry" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><dl class="simple">
<dt>问题描述：</dt><dd><ul>
<li><p>网络初始化时，如果所有权重相等，隐藏层神经元将输出相同的值。</p></li>
<li><p>这种对称性会导致网络只能学习到有限的特征，浪费网络容量。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>解决方案：</dt><dd><ul>
<li><p>在初始化时，引入随机性，确保权重不同。</p></li>
<li><p>Dropout 正则化方法可以帮助打破对称性，使不同神经元学习不同的特征。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
</section>
<section id="parameter-initialization">
<h5>5.4.2. Parameter Initialization<a class="headerlink" href="#parameter-initialization" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>解决（或至少减轻）上述问题的一种方法是对神经网络中的参数初始化方法的处理。</p></li>
</ul>
<section id="default-initialization">
<h6>5.4.2.1. Default Initialization<a class="headerlink" href="#default-initialization" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>如果不特别指定，深度学习框架会使用默认的随机初始化，通常是从正态分布中随机抽取权重。这个方法在中等规模问题中效果不错，但对于非常深的网络可能会导致梯度问题。</p></li>
</ul>
</section>
<section id="xavier-initialization">
<h6>5.4.2.2. Xavier Initialization<a class="headerlink" href="#xavier-initialization" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>Xavier初始化（或Glorot初始化）是一种专门设计来保持前向和反向传播中输出的方差相对稳定的方法。</p></li>
<li><p>目标：防止信号在层与层之间传递时逐渐消失或爆炸。</p></li>
<li><dl class="simple">
<dt>方法推导：</dt><dd><ul>
<li><p>假设一个无激活函数的全连接层，输出 <span class="math notranslate nohighlight">\(o_i = \sum_{j=1}^{n_\text{in}} w_{ij} x_j\)</span></p></li>
<li><p>假设权重 <span class="math notranslate nohighlight">\(w_{ij}\)</span> 服从均值为0、方差为 <span class="math notranslate nohighlight">\(\sigma^2\)</span> 的分布</p></li>
<li><p>输入 <span class="math notranslate nohighlight">\(x_j\)</span> 也具有均值0、方差 <span class="math notranslate nohighlight">\(\gamma^2\)</span> ，且 <span class="math notranslate nohighlight">\(x_j\)</span> 和 <span class="math notranslate nohighlight">\(w_{ij}\)</span> 相互独立</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<p>计算输出方差：</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    E[o_i] &amp; = \sum_{j=1}^{n_\textrm{in}} E[w_{ij} x_j] \\
    &amp;= \sum_{j=1}^{n_\textrm{in}} E[w_{ij}] E[x_j] \\
    &amp;= 0
\end{aligned}\end{split}\]</div>
<p>and the variance:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    \textrm{Var}[o_i] &amp; = E[o_i^2] - (E[o_i])^2 \\
        &amp; = \sum_{j=1}^{n_\textrm{in}} E[w^2_{ij} x^2_j] - 0 \\
        &amp; = \sum_{j=1}^{n_\textrm{in}} E[w^2_{ij}] E[x^2_j] \\
        &amp; = n_\textrm{in} \sigma^2 \gamma^2.
\end{aligned}\end{split}\]</div>
<ul class="simple">
<li><p>为了保持输出的方差固定，需要满足条件： <span class="math notranslate nohighlight">\(n_\textrm{in} \sigma^2 = 1\)</span></p></li>
<li><p>在反向传播时，类似的方差条件需要满足： <span class="math notranslate nohighlight">\(n_\textrm{out} \sigma^2 = 1\)</span></p></li>
<li><p>由于无法同时满足两个条件，Xavier初始化取折中：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    \frac{1}{2} (n_\textrm{in} + n_\textrm{out}) \sigma^2 = 1 \\
    \textrm{ 于是得到： } \\
    \sigma = \sqrt{\frac{2}{n_\textrm{in} + n_\textrm{out}}}
\end{aligned}\end{split}\]</div>
<section id="id63">
<h6 aria-level="7">实操<a class="headerlink" href="#id63" title="此标题的永久链接">¶</a></h6>
<p>如果从正态分布中抽取权重：</p>
<div class="math notranslate nohighlight">
\[\mathbb{N}\left(0, \frac{2}{n_\textrm{in}+n_\textrm{out}}\right)\]</div>
<p>如果使用均匀分布 <span class="math notranslate nohighlight">\(U(-a, a)\)</span> 则这儿的 <span class="math notranslate nohighlight">\(a\)</span> 为</p>
<div class="math notranslate nohighlight">
\[a = \sqrt{\frac{6}{n_\textrm{in}+n_\textrm{out}}}\]</div>
<ul class="simple">
<li><dl class="simple">
<dt>实践效果</dt><dd><ul>
<li><p>尽管推导假设没有使用激活函数，但在实际网络中，即使有非线性激活，Xavier初始化依然表现良好。</p></li>
<li><p>它解决了一部分梯度消失/爆炸问题，使得网络更容易收敛。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
</section>
</section>
<section id="id64">
<h5>5.4.3. Summary<a class="headerlink" href="#id64" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>梯度消失和爆炸是深度网络中的常见问题。</p></li>
<li><p>在参数初始化时需要非常小心，以确保梯度和参数保持良好的控制。需要初始化启发法来确保初始梯度既不太大也不太小。随机初始化是确保优化之前打破对称性的关键。</p></li>
<li><p>Xavier 初始化表明，对于每一层，任何输出的方差不受输入数量的影响，并且任何梯度的方差不受输出数量的影响。 ReLU 激活函数缓解了梯度消失问题。这可以加速收敛。</p></li>
</ul>
</section>
</section>
<section id="generalization-in-deep-learning">
<h4>5.5. Generalization in Deep Learning<a class="headerlink" href="#generalization-in-deep-learning" title="此标题的永久链接">¶</a></h4>
<section id="revisiting-overfitting-and-regularization">
<h5>5.5.1. Revisiting Overfitting and Regularization<a class="headerlink" href="#revisiting-overfitting-and-regularization" title="此标题的永久链接">¶</a></h5>
<section id="id65">
<h6>引入背景与传统认知<a class="headerlink" href="#id65" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><dl class="simple">
<dt>“无免费午餐定理”（no free lunch theorem）</dt><dd><ul>
<li><p>强调所有学习算法在某些分布上表现更好，而在其他分布上表现更差。</p></li>
<li><p>根据Wolpert（1995）提出的这一理论，任何学习算法在某些数据分布上会表现得更好，在其他分布上则可能更差。</p></li>
<li><p>这意味着对于有限的训练集，模型需要依赖于一些假设来达到人类级别的性能，而这些假设被称为归纳偏好。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>归纳偏置（inductive biases）</dt><dd><ul>
<li><p>它指的是模型对具有某些特性的解决方案的偏好。例如，深层多层感知器（MLP）倾向于通过组合简单函数来构建复杂函数。</p></li>
<li><p>为了弥补有限训练数据的局限性），即类似人类对世界的思考方式，从而偏向具有特定性质的解决方案。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>两阶段训练</dt><dd><ul>
<li><p>首先是使模型尽可能好地拟合训练数据，其次是在保留的测试数据集上估计泛化误差。</p></li>
<li><p>泛化差距是指训练误差与测试误差之间的差异；当这个差距较大时，表示模型过拟合了训练数据。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>过拟合</dt><dd><ul>
<li><p>经典观点：如果模型过于复杂，可能会导致过拟合。此时可以通过减少特征数量、非零参数的数量或参数大小来解决这个问题。</p></li>
<li><p>过拟合是训练误差和测试误差之间的差距，当模型复杂度过高时，容易发生过拟合。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="id66">
<h6>深度学习的反常现象<a class="headerlink" href="#id66" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><dl class="simple">
<dt>深度学习中的过拟合：</dt><dd><ul>
<li><p>不同于经典的观点，深度学习打破了经典的“模型复杂度 vs. 误差”的简单关系。深度学习模型往往足够表达力强，以至于可以完美拟合每个训练样本。</p></li>
<li><p>尽管如此，我们仍可以通过增加模型的表达能力（如添加层数、节点数或延长训练周期）来减少泛化误差，这与传统认知相悖。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>反直觉现象</dt><dd><ul>
<li><p>传统观点认为，模型在复杂度轴的极端位置时，泛化误差会增加，因此需要通过正则化或降低模型复杂度来减少过拟合。</p></li>
<li><p>在深度学习中，即使模型完全拟合训练数据，增加模型复杂度（如增加层数或节点）反而可能减少泛化误差。</p></li>
<li><p>这种现象被称为双重下降（double descent）。</p></li>
<li><p>双重下降现象：随着模型复杂度的增加，泛化差距起初会增大，但之后又会减小。这种现象表明，模型复杂度与泛化性能之间的关系并非单调。</p></li>
<li><p>深度学习实践者的工具包：包括一些看似限制模型的方法（如正则化），以及一些看似增强模型表达能力的方法，所有这些都是为了减轻过拟合的问题。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="id67">
<h6>挑战传统理论<a class="headerlink" href="#id67" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>深度学习的成功使得传统学习理论难以解释其泛化能力。尽管可以使用 <span class="math notranslate nohighlight">\(\ell_2\)</span> 正则化等方法优化使用，但传统复杂度度量（如VC维或Rademacher复杂度）仍无法有效解释深度神经网络为何具有良好的泛化性能。</p></li>
<li><p>关键矛盾在于，神经网络即使能够拟合任意标签数据，实际测试误差依然可能较低，说明现有理论存在局限性。</p></li>
<li><p>这表明，对于深度学习模型，我们需要新的理论框架来理解其泛化能力。</p></li>
</ul>
</section>
<section id="id68">
<h6>关键词解析<a class="headerlink" href="#id68" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>Inductive Bias：模型在学习过程中偏向于特定类型的解决方案或假设，有助于提高泛化能力。</p></li>
<li><p>Generalization Gap：训练误差与测试误差之间的差距。</p></li>
<li><p>Double Descent：模型复杂度增加时，误差先下降再上升，随后再次下降的现象，打破了经典“U型”误差曲线的概念。</p></li>
<li><p>VC Dimension/Rademacher Complexity：衡量模型复杂度的经典理论工具，在深度学习领域面临解释能力不足的问题。</p></li>
</ul>
</section>
</section>
<section id="inspiration-from-nonparametrics">
<h5>5.5.2. Inspiration from Nonparametrics<a class="headerlink" href="#inspiration-from-nonparametrics" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>探讨了深度学习与非参数模型（nonparametric models）之间的关系，挑战了将深度神经网络仅视为参数化模型的直觉，并展示了如何从非参数视角来看待神经网络的行为。</p></li>
</ul>
<section id="id69">
<h6>深度学习的参数化与非参数化对比<a class="headerlink" href="#id69" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>深度学习模型拥有大量的参数，因此直观上看，它们是参数化模型。在训练过程中，模型的参数不断更新，保存时也写入参数。</p></li>
<li><p>然而，文本指出，尽管神经网络有大量参数，从某些角度来看，它们的行为更像是非参数模型。这种思维方式可以帮助我们更好地理解神经网络的泛化能力和训练机制。</p></li>
</ul>
</section>
<section id="id70">
<h6>非参数模型的定义<a class="headerlink" href="#id70" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>非参数模型的复杂度通常随着数据量的增加而增加。经典的非参数模型例子是 <strong>k-最近邻算法</strong> （k-nearest neighbor，KNN）。</p></li>
<li><p>KNN模型在训练阶段只是记住数据集，而在预测时，通过寻找最接近的训练点来进行分类或回归。</p></li>
<li><p>当 <code class="docutils literal notranslate"><span class="pre">k=1</span></code> 时，KNN模型可以实现零训练误差，但这并不意味着它没有泛化能力。事实上，在某些条件下， <code class="docutils literal notranslate"><span class="pre">1-最近邻算法</span></code> 会随着数据量的增加而收敛到最优预测器。</p></li>
</ul>
</section>
<section id="id71">
<h6>度量函数和归纳偏置<a class="headerlink" href="#id71" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>1-最近邻算法的关键是距离函数（distance function），也即如何将数据转换为特征向量（featurizing data）。</p></li>
<li><p>不同的距离度量代表不同的归纳偏置，即对数据底层结构的假设。选择不同的度量方式将影响模型的泛化能力。</p></li>
</ul>
</section>
<section id="id72">
<h6>神经网络的“非参数性”<a class="headerlink" href="#id72" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>神经网络的特点是过度参数化（over-parameterized），即拥有远多于训练数据所需的参数。由于过度参数化，神经网络在训练数据上常常能够完美拟合（interpolate），这种行为与非参数模型相似。</p></li>
<li><p>深度学习的最新理论研究表明，大型神经网络与非参数方法，特别是核方法（kernel methods），之间有深刻的联系。</p></li>
<li><p>具体来说，神经切线核（neural tangent kernel）理论表明，当多层感知机（MLP）的宽度趋于无穷大时，它们的行为趋近于非参数的核方法。</p></li>
</ul>
</section>
<section id="id73">
<h6>神经切线核理论<a class="headerlink" href="#id73" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>神经切线核（neural tangent kernel，NTK）是一种特殊的核函数，用来描述深度神经网络的行为。</p></li>
<li><p>尽管当前的NTK模型可能不能完全解释现代深度网络的行为，但它为分析过度参数化的深度神经网络提供了有力的工具，并强调了非参数建模在理解深度网络行为中的重要性。</p></li>
</ul>
</section>
<section id="id74">
<h6>结论<a class="headerlink" href="#id74" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>通过对比传统的参数化和非参数化模型，强调了神经网络在某些方面表现得像非参数模型。</p></li>
<li><p>尽管神经网络有大量参数，但其过度参数化的特性使其在训练数据上的拟合方式与非参数方法类似，尤其是在训练数据量增大时。通过神经切线核的理论，研究表明神经网络与核方法之间有着深刻的联系，这一理论为理解现代深度学习模型提供了新的视角。</p></li>
</ul>
</section>
</section>
<section id="early-stopping">
<h5>5.5.3. Early Stopping<a class="headerlink" href="#early-stopping" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>本文探讨了 <strong>早停法（Early Stopping）</strong> 在深度学习中的作用及其在处理标签噪声（label noise）问题上的重要性。</p></li>
</ul>
<section id="id75">
<h6>早停法的动机与背景<a class="headerlink" href="#id75" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>深度神经网络具备拟合任意标签的能力，即使标签是随机分配或错误的。然而，这种拟合能力通常需要多次训练迭代后才会显现。</p></li>
<li><p>研究发现，神经网络在训练过程中，首先拟合干净的标签数据，随后逐步拟合带噪声的标签数据。这意味着，如果训练在模型拟合干净数据后停止，模型仍能保持良好的泛化能力。</p></li>
<li><p>当模型只拟合干净数据，而未完全拟合随机标签时，实际上可以确保模型具备良好的泛化能力。</p></li>
</ul>
</section>
<section id="id76">
<h6>早停法的机制<a class="headerlink" href="#id76" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>早停法是一种经典的正则化技术，与直接约束权重值不同，它通过 <strong>限制训练的迭代次数（epoch）</strong> 来防止模型过拟合。</p></li>
<li><p>早停的典型方法是监控验证集误差，在训练过程中，每个epoch结束后评估一次验证集误差。当验证误差在连续多个epoch内未显著减少（减少幅度小于 <span class="math notranslate nohighlight">\(epsilon\)</span> ），训练就会提前终止。这种策略被称为耐心准则（patience criterion）。</p></li>
</ul>
</section>
<section id="id77">
<h6>早停法的优点<a class="headerlink" href="#id77" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>提高泛化能力：特别是在标签存在噪声或标签固有不确定性的场景下，早停能防止模型过度拟合带噪声数据，进而提升泛化能力。</p></li>
<li><p>节约计算资源：早停可以显著减少训练时间。对于大型模型（如GPT等），训练可能需要数天且消耗大量GPU资源，早停能够节省大量计算成本。</p></li>
</ul>
</section>
<section id="id78">
<h6>适用场景<a class="headerlink" href="#id78" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>标签存在噪声或不确定性：例如医疗领域的死亡率预测，患者数据通常带有不确定性和噪声，早停尤为关键。</p></li>
<li><p>真实可分数据集（realizable datasets）：例如区分猫和狗的任务，如果数据集无标签噪声且类别完全可分，早停对泛化能力的提升 <strong>不显著</strong> 。</p></li>
<li><p>错误做法：如果继续训练直到模型完全拟合带噪声的数据，通常会导致模型泛化能力下降，表现出较高的测试误差。</p></li>
</ul>
</section>
<section id="id79">
<h6>关键词解析<a class="headerlink" href="#id79" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>Label Noise（标签噪声）：训练数据中存在错误或随机分配的标签，常见于真实世界的数据集中。</p></li>
<li><p>Generalization（泛化）：模型在未见过的新数据上的表现能力。</p></li>
<li><p>Patience Criterion（耐心准则）：在验证误差多次不降低后停止训练的策略，用于防止模型在带噪声数据上继续拟合。</p></li>
</ul>
</section>
<section id="id80">
<h6>结论<a class="headerlink" href="#id80" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>早停法是应对深度学习中过拟合问题的重要手段，尤其在标签噪声存在的情况下，它能够有效提升模型的泛化能力，同时降低训练时间和成本。</p></li>
<li><p>虽然在理想、无噪声的数据集上效果有限，但在现实中，标签噪声和数据的不确定性使得早停法成为深度学习训练的常见技巧之一。</p></li>
</ul>
</section>
</section>
<section id="classical-regularization-methods-for-deep-networks">
<h5>5.5.4. Classical Regularization Methods for Deep Networks<a class="headerlink" href="#classical-regularization-methods-for-deep-networks" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>本节探讨了深度学习中的经典正则化方法，主要围绕 <strong>权重衰减（weight decay）</strong> 和正则化技术在防止过拟合中的作用和局限性。</p></li>
</ul>
<section id="id81">
<h6>经典正则化方法的回顾<a class="headerlink" href="#id81" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>在传统机器学习中，正则化通过在损失函数中添加惩罚项来限制模型复杂度，从而防止过拟合。</p></li>
<li><dl class="simple">
<dt>主要方法包括：</dt><dd><ul>
<li><p>岭回归（ridge regularization）：惩罚 <span class="math notranslate nohighlight">\(\ell_2\)</span> 范数，限制权重的平方和。</p></li>
<li><p>套索回归（lasso regularization）：惩罚 <span class="math notranslate nohighlight">\(\ell_1\)</span> 范数，使部分权重趋于零，促进稀疏性。</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>这些方法通常足够强大，可以防止模型拟合随机标签（即防止模型学到噪声）。</p></li>
</ul>
</section>
<section id="id82">
<h6>深度学习中的应用与挑战<a class="headerlink" href="#id82" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><dl class="simple">
<dt>在深度学习中，权重衰减依然是流行的正则化工具。然而，研究表明：</dt><dd><ul>
<li><p>典型的 <span class="math notranslate nohighlight">\(\ell_2\)</span> 正则化强度不足，无法完全防止神经网络对训练数据的插值（即完全拟合训练集，甚至拟合噪声标签）。</p></li>
<li><p>换句话说，单独依靠权重衰减可能无法有效抑制过拟合。</p></li>
<li><p>其真正的价值可能体现在与 <strong>早停法（early stopping）</strong> 的组合使用中，形成双重正则化策略。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="id83">
<h6>对正则化方法的新解释<a class="headerlink" href="#id83" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>在深度学习中，正则化方法的作用可能与传统理论不同。</p></li>
<li><p>即使正则化不能直接限制模型的拟合能力，它可能通过引入**归纳偏置（inductive biases）**来促进模型对数据内在模式的学习。</p></li>
<li><p>类比于k近邻算法中距离度量的选择，不同的正则化方法可能更多地是通过改变模型的学习方式，而非显著限制模型复杂度来提升泛化能力。</p></li>
</ul>
</section>
<section id="id84">
<h6>正则化方法的扩展与创新<a class="headerlink" href="#id84" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><dl class="simple">
<dt>深度学习研究者不仅继续使用传统正则化方法，还基于这些方法发展了新的技术，如：</dt><dd><ul>
<li><p>在模型输入上添加噪声：这可以在训练过程中增加模型的鲁棒性，减少对训练数据的过度依赖。</p></li>
<li><p>Dropout：通过随机丢弃一部分神经元的输出，防止神经网络对特定路径过度依赖，是深度学习中最流行的正则化方法之一。</p></li>
<li><p>即使dropout的理论基础尚不完全清晰，它在实践中的有效性已被广泛验证。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="id85">
<h6>关键词解析<a class="headerlink" href="#id85" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>Weight Decay（权重衰减）：通过在损失函数中添加 <span class="math notranslate nohighlight">\(\ell_2\)</span> 或 <span class="math notranslate nohighlight">\(\ell_1\)</span> 惩罚项，防止模型参数无限增大，从而减少过拟合风险。</p></li>
<li><p>Inductive Bias（归纳偏置）：模型在学习过程中表现出的倾向性或假设，有助于模型更好地理解数据分布。</p></li>
<li><p>Dropout：训练过程中随机丢弃神经元输出，减少神经元之间的共适应性，降低过拟合风险。</p></li>
</ul>
</section>
<section id="id86">
<h6>结论<a class="headerlink" href="#id86" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>这段文字强调了深度学习对经典正则化方法的借鉴和创新。</p></li>
<li><p>尽管传统正则化方法如权重衰减仍然广泛使用，但在深度学习中，它们的作用机制可能更复杂，且往往需要与其他策略（如早停法）结合使用。</p></li>
<li><p>未来，探索这些正则化方法背后的理论基础，将是理解深度学习泛化能力的重要方向。</p></li>
</ul>
</section>
</section>
</section>
<section id="dropout">
<h4>5.6. Dropout<a class="headerlink" href="#dropout" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>这部分介绍了Dropout，一种在训练神经网络时防止过拟合的正则化技术。</p></li>
</ul>
<ol class="arabic">
<li><p>为什么需要Dropout:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>简化模型是提高泛化能力的核心思路之一：
    减少模型参数的维度。
    使用权重衰减（L2正则化），限制参数的大小。
    提高模型的平滑性，使模型对输入的小扰动不敏感。
直观解释：在图像分类任务中，如果输入图像的像素增加了一些随机噪声，模型仍应给出相同的分类结果。
</pre></div>
</div>
</li>
<li><p>Dropout的提出:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Dropout 源自Bishop提出的一个理论：
    在输入中加入随机噪声，相当于Tikhonov正则化，可以提高模型对输入扰动的鲁棒性。

Srivastava等人将这一思想推广到网络的内部层，提出了Dropout方法。
    Dropout的核心思想：
        在每次前向传播时，随机“丢弃”一部分神经元，即将它们的输出置零。
        训练过程中，每次迭代都会对不同的神经元进行随机屏蔽。

这种方法打破了神经网络中过度依赖特定激活模式的问题，防止神经元之间形成共适应（co-adaptation）。
    作者将其类比于生物的有性繁殖打破基因共适应的过程。
</pre></div>
</div>
</li>
<li><p>Dropout的实现:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>在前向传播中，神经元以概率$p$被丢弃（置零），其余神经元以概率$1-p$保留。
为了保持输出期望不变，保留的神经元的输出被除以$(1-p)$进行缩放。
</pre></div>
</div>
</li>
</ol>
<p>公式：</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
h' =
\begin{cases}
    0 &amp; \textrm{ with probability } p \\
    \frac{h}{1-p} &amp; \textrm{ otherwise}
\end{cases}
\end{aligned}\end{split}\]</div>
<ul class="simple">
<li><p>其中</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">h</span></code> 是原始激活值</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">h'</span></code> 是Dropout后的激活值</p></li>
<li><p>这样设计的目的是确保期望不变</p></li>
</ul>
<p>小结:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Dropout是一种简单而有效的正则化方法，在大多数深度学习框架中已成为标准做法。
它可以有效地减少过拟合，使模型对输入数据的微小扰动更加鲁棒。
Dropout打破了神经元之间的共适应关系，提高了模型的泛化能力。
</pre></div>
</div>
<section id="dropout-in-practice">
<h5>5.6.1. Dropout in Practice<a class="headerlink" href="#dropout-in-practice" title="此标题的永久链接">¶</a></h5>
<figure class="align-default" id="id224">
<img alt="https://img.zhaoweiguo.com/uPic/2024/12/Q2aH1f.png" src="https://img.zhaoweiguo.com/uPic/2024/12/Q2aH1f.png" />
<figcaption>
<p><span class="caption-text">Fig. 5.6.1 MLP before and after dropout. <span class="math notranslate nohighlight">\(h_2\)</span> 和 <span class="math notranslate nohighlight">\(h_5\)</span> 被删除。因此，输出的计算不再依赖于 <span class="math notranslate nohighlight">\(h_2\)</span> 或 <span class="math notranslate nohighlight">\(h_5\)</span> ，并且在执行反向传播时它们各自的梯度也会消失。这样，输出层的计算就不能过度依赖于 <span class="math notranslate nohighlight">\(h_1, ..., h_5\)</span> 的任何一个元素。</span><a class="headerlink" href="#id224" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
</section>
<section id="id87">
<h5>5.6.2. Implementation from Scratch<a class="headerlink" href="#id87" title="此标题的永久链接">¶</a></h5>
<ul>
<li><p>实现了一个 dropout_layer 函数，该函数以 dropout 概率丢弃张量输入 X 中的元素，并按上述方式重新调整余数：除以 1.0-dropout 的幸存者:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">dropout_layer</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">dropout</span> <span class="o">&lt;=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">dropout</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span> <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">dropout</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">mask</span> <span class="o">*</span> <span class="n">X</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">dropout</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
<p>将输入 X 通过 dropout 操作传递，概率分别为 0、0.5 和 1:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dropout_p = 0:&#39;</span><span class="p">,</span> <span class="n">dropout_layer</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dropout_p = 0.5:&#39;</span><span class="p">,</span> <span class="n">dropout_layer</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dropout_p = 1:&#39;</span><span class="p">,</span> <span class="n">dropout_layer</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="c1"># 输出</span>
<span class="c1"># dropout_p = 0: tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],</span>
<span class="c1">#         [ 8.,  9., 10., 11., 12., 13., 14., 15.]])</span>
<span class="c1"># dropout_p = 0.5: tensor([[ 0.,  2.,  0.,  6.,  8.,  0.,  0.,  0.],</span>
<span class="c1">#         [16., 18., 20., 22., 24., 26., 28., 30.]])</span>
<span class="c1"># dropout_p = 1: tensor([[0., 0., 0., 0., 0., 0., 0., 0.],</span>
<span class="c1">#         [0., 0., 0., 0., 0., 0., 0., 0.]])</span>
</pre></div>
</div>
<section id="id88">
<h6>5.6.2.1. Defining the Model<a class="headerlink" href="#id88" title="此标题的永久链接">¶</a></h6>
<p>下面的模型将 dropout 应用于每个隐藏层的输出（在激活函数之后）:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">DropoutMLPScratch</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Classifier</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">num_hiddens_1</span><span class="p">,</span> <span class="n">num_hiddens_2</span><span class="p">,</span>
                 <span class="n">dropout_1</span><span class="p">,</span> <span class="n">dropout_2</span><span class="p">,</span> <span class="n">lr</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">num_hiddens_1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">num_hiddens_2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">num_outputs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">H1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lin1</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">))))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="n">H1</span> <span class="o">=</span> <span class="n">dropout_layer</span><span class="p">(</span><span class="n">H1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_1</span><span class="p">)</span>
        <span class="n">H2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lin2</span><span class="p">(</span><span class="n">H1</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="n">H2</span> <span class="o">=</span> <span class="n">dropout_layer</span><span class="p">(</span><span class="n">H2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout_2</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">lin3</span><span class="p">(</span><span class="n">H2</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id89">
<h6>5.6.2.2. Training<a class="headerlink" href="#id89" title="此标题的永久链接">¶</a></h6>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hparams</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;num_outputs&#39;</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span> <span class="s1">&#39;num_hiddens_1&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span> <span class="s1">&#39;num_hiddens_2&#39;</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span>
           <span class="s1">&#39;dropout_1&#39;</span><span class="p">:</span><span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;dropout_2&#39;</span><span class="p">:</span><span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span><span class="mf">0.1</span><span class="p">}</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">DropoutMLPScratch</span><span class="p">(</span><span class="o">**</span><span class="n">hparams</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2024/12/aeAT6f.png" src="https://img.zhaoweiguo.com/uPic/2024/12/aeAT6f.png" />
</figure>
</section>
</section>
<section id="id90">
<h5>5.6.3. Concise Implementation<a class="headerlink" href="#id90" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>在每个全连接层之后添加一个 Dropout 层，将 dropout 概率作为唯一参数传递给其构造函数</p></li>
<li><p>在训练过程中， Dropout 层将根据指定的丢弃概率随机丢弃前一层的输出（或等效地，后续层的输入）。</p></li>
<li><p>当不处于训练模式时， Dropout 层仅在测试期间传递数据。</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">DropoutMLP</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Classifier</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">num_hiddens_1</span><span class="p">,</span> <span class="n">num_hiddens_2</span><span class="p">,</span>
                 <span class="n">dropout_1</span><span class="p">,</span> <span class="n">dropout_2</span><span class="p">,</span> <span class="n">lr</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">num_hiddens_1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">num_hiddens_2</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_2</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">num_outputs</span><span class="p">))</span>
</pre></div>
</div>
<p>训练模型:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">DropoutMLP</span><span class="p">(</span><span class="o">**</span><span class="n">hparams</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id91">
<h5>5.6.4. Summary<a class="headerlink" href="#id91" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>除了控制维数和权重向量的大小之外，dropout 是避免过度拟合的另一种工具。</p></li>
<li><p>通常，工具是联合使用的。</p></li>
<li><p>请注意，dropout 仅在训练期间使用：它将激活 h 替换为具有预期值 h 的随机变量</p></li>
</ul>
</section>
</section>
<section id="predicting-house-prices-on-kaggle">
<h4>5.7. Predicting House Prices on Kaggle<a class="headerlink" href="#predicting-house-prices-on-kaggle" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>以一个 Kaggle 上的示例进行讲解</p></li>
</ul>
</section>
</section>
</section>
<section id="part-2-modern-deep-learning-techniques">
<h2>Part 2: Modern Deep Learning Techniques<a class="headerlink" href="#part-2-modern-deep-learning-techniques" title="此标题的永久链接">¶</a></h2>
<section id="builders-guide">
<h3>6. Builders’ Guide<a class="headerlink" href="#builders-guide" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p>除了庞大的数据集和强大的硬件之外，还有出色的软件工具 在深度学习的快速进展中发挥了不可或缺的作用 学习。</p></li>
<li><p>在本章中，我们将深入挖掘深度学习计算的关键组成部分，即模型构建、参数访问和初始化、设计自定义层和块、将模型读写到磁盘，以及利用 GPU 实现梦幻般的加速。</p></li>
<li><p>虽然本章没有介绍任何新模型或数据集，但接下来的高级建模章节在很大程度上依赖于这些技术。</p></li>
</ul>
<section id="layers-and-modules">
<h4>6.1. Layers and Modules<a class="headerlink" href="#layers-and-modules" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>Individual layers can be modules.</p></li>
<li><p>Many layers can comprise a module.</p></li>
<li><p>Many modules can comprise a module.</p></li>
</ul>
</section>
<section id="parameter-management">
<h4>6.2. Parameter Management<a class="headerlink" href="#parameter-management" title="此标题的永久链接">¶</a></h4>
<p>示例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="mi">8</span><span class="p">),</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="c1"># torch.Size([2, 1])</span>
</pre></div>
</div>
<section id="parameter-access">
<h5>6.2.1. Parameter Access<a class="headerlink" href="#parameter-access" title="此标题的永久链接">¶</a></h5>
<p>检查第二个全连接层的参数:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span># 执行 net(X) 前
$ net[2].state_dict()
# OrderedDict([(&#39;weight&#39;, &lt;UninitializedParameter&gt;),
         (&#39;bias&#39;, &lt;UninitializedParameter&gt;)])

# 执行 net(X) 后
$ net[2].state_dict()
# OrderedDict([(&#39;weight&#39;,
          tensor([[-0.1649,  0.0605,  0.1694, -0.2524,  0.3526, -0.3414, -0.2322,  0.0822]])),
         (&#39;bias&#39;, tensor([0.0709]))])
</pre></div>
</div>
<section id="targeted-parameters">
<h6>6.2.1.1. Targeted Parameters<a class="headerlink" href="#targeted-parameters" title="此标题的永久链接">¶</a></h6>
<p>从第二个神经网络层提取偏差，该层返回参数类实例，并进一步访问该参数的值:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ type(net[2].bias), net[2].bias.data
# (torch.nn.parameter.Parameter, tensor([0.0709]))

$ net[2].weight
Parameter containing:
tensor([[ 0.0205, -0.1554, -0.2950,  0.1296, -0.2784,  0.1173, -0.0230, -0.1530]],
       requires_grad=True)
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>参数是复杂的对象，包含值、梯度和附加信息。</p>
</div>
</section>
<section id="all-parameters-at-once">
<h6>6.2.1.2. All Parameters at Once<a class="headerlink" href="#all-parameters-at-once" title="此标题的永久链接">¶</a></h6>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ [(name, param.shape) for name, param in net.named_parameters()]
# [(&#39;0.weight&#39;, torch.Size([8, 4])),
   (&#39;0.bias&#39;, torch.Size([8])),
   (&#39;2.weight&#39;, torch.Size([1, 8])),
   (&#39;2.bias&#39;, torch.Size([1]))]
</pre></div>
</div>
</section>
</section>
<section id="tied-parameters">
<h5>6.2.2. Tied Parameters<a class="headerlink" href="#tied-parameters" title="此标题的永久链接">¶</a></h5>
<p>跨多个层共享参数:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># We need to give the shared layer a name so that we can refer to its parameters</span>
<span class="n">shared</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="mi">8</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                    <span class="n">shared</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                    <span class="n">shared</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

<span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="c1"># Check whether the parameters are the same</span>
<span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">net</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">net</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">100</span>
<span class="c1"># Make sure that they are actually the same object rather than just having the</span>
<span class="c1"># same value</span>
<span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">net</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="c1"># 输出</span>
<span class="c1"># tensor([True, True, True, True, True, True, True, True])</span>
<span class="c1"># tensor([True, True, True, True, True, True, True, True])</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>由于模型参数包含梯度，因此在反向传播时将第二隐藏层和第三隐藏层的梯度相加。</p>
</div>
</section>
</section>
<section id="id92">
<h4>6.3. Parameter Initialization<a class="headerlink" href="#id92" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>使用内置和自定义初始化程序来初始化参数。</p></li>
</ul>
<p>示例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="mi">8</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
<section id="built-in-initialization">
<h5>6.3.1. Built-in Initialization<a class="headerlink" href="#built-in-initialization" title="此标题的永久链接">¶</a></h5>
<p>初使状态:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="c1"># Out[27]: (tensor([ 0.4112, -0.0801,  0.4687,  0.3344]), tensor(-0.1189))</span>
</pre></div>
</div>
<p>示例1-将所有权重参数初始化为标准差为 0.01 的高斯随机变量，而偏差参数则清除为零:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">init_normal</span><span class="p">(</span><span class="n">module</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">module</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

<span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_normal</span><span class="p">)</span>
<span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="c1"># 输出</span>
<span class="c1"># (tensor([-0.0082,  0.0074,  0.0116, -0.0061]), tensor(0.))</span>
</pre></div>
</div>
<p>示例2-将所有参数初始化为给定的常量值（例如 1）:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">init_constant</span><span class="p">(</span><span class="n">module</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">module</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

<span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_constant</span><span class="p">)</span>
<span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="c1"># 输出</span>
<span class="p">(</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]),</span> <span class="n">tensor</span><span class="p">(</span><span class="mf">0.</span><span class="p">))</span>
</pre></div>
</div>
<p>示例3-为某些块应用不同的初始化器。例如，下面我们使用 Xavier 初始化器初始化第一层，并将第二层初始化为常量值 42:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">init_xavier</span><span class="p">(</span><span class="n">module</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">module</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">init_42</span><span class="p">(</span><span class="n">module</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">module</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mi">42</span><span class="p">)</span>

<span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_xavier</span><span class="p">)</span>
<span class="n">net</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_42</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="c1"># 输出</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.0974</span><span class="p">,</span>  <span class="mf">0.1707</span><span class="p">,</span>  <span class="mf">0.5840</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5032</span><span class="p">])</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">42.</span><span class="p">,</span> <span class="mf">42.</span><span class="p">,</span> <span class="mf">42.</span><span class="p">,</span> <span class="mf">42.</span><span class="p">,</span> <span class="mf">42.</span><span class="p">,</span> <span class="mf">42.</span><span class="p">,</span> <span class="mf">42.</span><span class="p">,</span> <span class="mf">42.</span><span class="p">]])</span>
</pre></div>
</div>
</section>
</section>
<section id="lazy-initialization">
<h4>6.4. Lazy Initialization<a class="headerlink" href="#lazy-initialization" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>延迟初始化很方便，允许框架自动推断参数形状，从而可以轻松修改架构并消除一种常见的错误源。我们可以通过模型传递数据来让框架最终初始化参数。</p></li>
</ul>
<p>实例化一个 MLP:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
<p>尝试访问以下参数进行确认:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span>
<span class="c1"># 输出</span>
<span class="o">&lt;</span><span class="n">UninitializedParameter</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>通过网络传递数据，让框架最终初始化参数:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<p>一旦知道所有参数形状，框架就可以最终初始化参数:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span>
<span class="c1"># 输出</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">256</span><span class="p">,</span> <span class="mi">20</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section id="custom-layers">
<h4>6.5. Custom Layers<a class="headerlink" href="#custom-layers" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>通过基本图层类来设计自定义图层。</p></li>
<li><p>这使我们能够定义灵活的新层，其行为与库中任何现有层不同。一旦定义，自定义层就可以在任意上下文和架构中调用。层可以具有本地参数，可以通过内置函数创建这些参数。</p></li>
</ul>
<section id="layers-without-parameters">
<h5>6.5.1. Layers without Parameters<a class="headerlink" href="#layers-without-parameters" title="此标题的永久链接">¶</a></h5>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">CenteredLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">X</span> <span class="o">-</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
<p>使用:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">layer</span> <span class="o">=</span> <span class="n">CenteredLayer</span><span class="p">()</span>
<span class="n">layer</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]))</span>
<span class="c1"># 输出</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">2.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">])</span>
</pre></div>
</div>
<p>incorporate our layer as a component in constructing more complex models:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="mi">128</span><span class="p">),</span> <span class="n">CenteredLayer</span><span class="p">())</span>
</pre></div>
</div>
<p>使用:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Y</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">Y</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="layers-with-parameters">
<h5>6.5.2. Layers with Parameters<a class="headerlink" href="#layers-with-parameters" title="此标题的永久链接">¶</a></h5>
<p>具有可通过训练调整的参数的层:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">MyLinear</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_units</span><span class="p">,</span> <span class="n">units</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">in_units</span><span class="p">,</span> <span class="n">units</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">units</span><span class="p">,))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">linear</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="file-i-o">
<h4>6.6. File I/O<a class="headerlink" href="#file-i-o" title="此标题的永久链接">¶</a></h4>
<section id="loading-and-saving-tensors">
<h5>6.6.1. Loading and Saving Tensors<a class="headerlink" href="#loading-and-saving-tensors" title="此标题的永久链接">¶</a></h5>
<p>对于单个张量，我们可以直接调用load和save 分别读取和写入它们的函数:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;x-file&#39;</span><span class="p">)</span>

<span class="n">x2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;x-file&#39;</span><span class="p">)</span>
<span class="n">x2</span>
<span class="c1"># 输出</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
</pre></div>
</div>
<p>存储张量列表并将它们读回内存:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span><span class="s1">&#39;x-files&#39;</span><span class="p">)</span>
<span class="n">x2</span><span class="p">,</span> <span class="n">y2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;x-files&#39;</span><span class="p">)</span>
<span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">y2</span><span class="p">)</span>
</pre></div>
</div>
<p>编写和读取从字符串映射到张量的字典:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mydict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;x&#39;</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">:</span> <span class="n">y</span><span class="p">}</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">mydict</span><span class="p">,</span> <span class="s1">&#39;mydict&#39;</span><span class="p">)</span>
<span class="n">mydict2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;mydict&#39;</span><span class="p">)</span>
<span class="n">mydict2</span>
</pre></div>
</div>
</section>
<section id="loading-and-saving-model-parameters">
<h5>6.6.2. Loading and Saving Model Parameters<a class="headerlink" href="#loading-and-saving-model-parameters" title="此标题的永久链接">¶</a></h5>
<p>模型示例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">MLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="mi">256</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<p>将模型的参数存储为名为“mlp.params”的文件:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;mlp.params&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>恢复模型:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">clone</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">()</span>
<span class="n">clone</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;mlp.params&#39;</span><span class="p">))</span>
<span class="n">clone</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="c1"># 输出</span>
<span class="n">MLP</span><span class="p">(</span>
  <span class="p">(</span><span class="n">hidden</span><span class="p">):</span> <span class="n">LazyLinear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="p">(</span><span class="n">output</span><span class="p">):</span> <span class="n">LazyLinear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>可以通过参数字典保存和加载网络的整套参数。保存架构必须通过代码而不是参数来完成。</p>
</div>
</section>
</section>
<section id="gpus">
<h4>6.7. GPUs<a class="headerlink" href="#gpus" title="此标题的永久链接">¶</a></h4>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>要运行本节中的程序，您至少需要两个 GPU。</p>
</div>
<section id="computing-devices">
<h5>6.7.1. Computing Devices<a class="headerlink" href="#computing-devices" title="此标题的永久链接">¶</a></h5>
<p>指定用于存储和计算的设备:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">cpu</span><span class="p">():</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the CPU device.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">gpu</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get a GPU device.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;cuda:</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">cpu</span><span class="p">(),</span> <span class="n">gpu</span><span class="p">(),</span> <span class="n">gpu</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># 输出</span>
<span class="p">(</span><span class="n">device</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">),</span>
 <span class="n">device</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
 <span class="n">device</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<p>查询可用GPU的数量:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">num_gpus</span><span class="p">():</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the number of available GPUs.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span>

<span class="n">num_gpus</span><span class="p">()</span>
</pre></div>
</div>
<p>工具(GPU不存在则使用CPU):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">try_gpu</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Return gpu(i) if exists, otherwise return cpu().&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">num_gpus</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">gpu</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">cpu</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">try_all_gpus</span><span class="p">():</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Return all available GPUs, or [cpu(),] if no GPU exists.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">gpu</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_gpus</span><span class="p">())]</span>

<span class="n">try_gpu</span><span class="p">(),</span> <span class="n">try_gpu</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">try_all_gpus</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="tensors-and-gpus">
<h5>6.7.2. Tensors and GPUs<a class="headerlink" href="#tensors-and-gpus" title="此标题的永久链接">¶</a></h5>
<section id="storage-on-the-gpu">
<h6>6.7.2.1. Storage on the GPU<a class="headerlink" href="#storage-on-the-gpu" title="此标题的永久链接">¶</a></h6>
<p>使用第一个GPU:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">try_gpu</span><span class="p">())</span>
<span class="n">X</span>
<span class="c1"># 输出</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>如果有两个GPU:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">try_gpu</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">Y</span>
<span class="c1"># 输出</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">0.0022</span><span class="p">,</span> <span class="mf">0.5723</span><span class="p">,</span> <span class="mf">0.2890</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.1456</span><span class="p">,</span> <span class="mf">0.3537</span><span class="p">,</span> <span class="mf">0.7359</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:1&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="copying">
<h6>6.7.2.2. Copying<a class="headerlink" href="#copying" title="此标题的永久链接">¶</a></h6>
<figure class="align-default" id="id225">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/OCgG4P.png" src="https://img.zhaoweiguo.com/uPic/2025/01/OCgG4P.png" />
<figcaption>
<p><span class="caption-text">Fig. 6.7.1 Copy data to perform an operation on the same device.</span><a class="headerlink" href="#id225" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<p>由于 Y 位于第二个 GPU 上，因此我们需要将 X 移动到那里，然后才能将两者相加:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Z</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
<span class="c1"># 输出</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:1&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>现在数据（ Z 和 Y ）都在同一个 GPU 上:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Y</span> <span class="o">+</span> <span class="n">Z</span>
<span class="c1"># 输出</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">1.0022</span><span class="p">,</span> <span class="mf">1.5723</span><span class="p">,</span> <span class="mf">1.2890</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.1456</span><span class="p">,</span> <span class="mf">1.3537</span><span class="p">,</span> <span class="mf">1.7359</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda:1&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="neural-networks-and-gpus">
<h5>6.7.3. Neural Networks and GPUs<a class="headerlink" href="#neural-networks-and-gpus" title="此标题的永久链接">¶</a></h5>
<p>神经网络模型可以指定设备。以下代码将模型参数放在 GPU 上:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">try_gpu</span><span class="p">())</span>
</pre></div>
</div>
<p>Let the trainer support GPU:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Trainer</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_epochs</span><span class="p">,</span> <span class="n">num_gpus</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">gradient_clip_val</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">gpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">d2l</span><span class="o">.</span><span class="n">gpu</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">num_gpus</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">num_gpus</span><span class="p">()))]</span>

<span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Trainer</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">prepare_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gpus</span><span class="p">:</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gpus</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">batch</span>

<span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Trainer</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">prepare_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="bp">self</span>
    <span class="n">model</span><span class="o">.</span><span class="n">board</span><span class="o">.</span><span class="n">xlim</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_epochs</span><span class="p">]</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gpus</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gpus</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
</pre></div>
</div>
</section>
<section id="id93">
<h5>6.7.4. Summary<a class="headerlink" href="#id93" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>默认情况下，数据在主存中创建，然后使用CPU进行计算。</p></li>
<li><p>深度学习框架要求计算的所有输入数据都位于同一设备上，无论是CPU还是同一个GPU。</p></li>
<li><p>如果不小心移动数据，您可能会损失显着的性能。</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>一个典型的错误如下：计算 GPU 上每个小批量的损失并在命令行上将其报告给用户（或将其记录在 NumPy ndarray 中）将触发全局解释器锁定，该锁定会停止所有 GPU。最好在 GPU 内部分配内存用于日志记录，并且只移动较大的日志。</p>
</div>
<ul class="simple">
<li><p>跨设备传输数据会导致性能损失。比如，数据从 CPU 传到 GPU，或者在多个 GPU 之间频繁传输，都会增加开销。关键点是： <strong>尽量避免不必要的数据传输，尤其是小批量数据的频繁移动。</strong></p></li>
<li><p>错误示例：在 GPU 上计算每个小批量（minibatch）的损失（loss），然后将其传回 CPU 并转换为 NumPy 数组进行记录或显示。 问题：这种方式会触发全局解释器锁（Global Interpreter Lock，GIL），导致 GPU 暂停，等待 CPU 完成操作，从而降低计算效率。</p></li>
<li><p>优化建议：最佳做法是直接在 GPU 上分配内存记录日志，减少数据在 CPU 和 GPU 之间频繁移动。等日志累积到足够大的批次时，再将其移动到 CPU 进行后续处理或显示。</p></li>
</ul>
</section>
</section>
</section>
<section id="convolutional-neural-networks">
<h3>7. Convolutional Neural Networks<a class="headerlink" href="#convolutional-neural-networks" title="此标题的永久链接">¶</a></h3>
<section id="from-fully-connected-layers-to-convolutions">
<h4>7.1. From Fully Connected Layers to Convolutions<a class="headerlink" href="#from-fully-connected-layers-to-convolutions" title="此标题的永久链接">¶</a></h4>
<section id="invariance">
<h5>7.1.1. Invariance(不变性)<a class="headerlink" href="#invariance" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>解释 CNN 如何通过平移不变性和局部性来减少模型复杂度，提高对图像中物体位置的鲁棒性（即使位置变化也能识别）。</p></li>
<li><p>CNN 通过模拟人类视觉的逐层处理方式，能够有效学习图像特征，并在不同位置进行一致识别。</p></li>
</ul>
<section id="id94">
<h6>定义<a class="headerlink" href="#id94" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>目标：识别图像中的对象时，希望模型对对象在图像中的具体位置不敏感。</p></li>
<li><p>核心思想是：识别一个对象时，关注对象的特征，而不是其位置。</p></li>
<li><p>比如，无论一只猪出现在图像顶部还是底部，我们都应该能够识别出它是一只猪。这种位置不敏感性就是不变性（invariance）。</p></li>
</ul>
</section>
<section id="cnn">
<h6>CNN 如何实现这种不变性<a class="headerlink" href="#cnn" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><dl class="simple">
<dt>(1)平移不变性（Translation Invariance）：</dt><dd><ul>
<li><p>无论图像的某个局部区域（patch）出现在什么位置，网络都应该对它有相似的响应。</p></li>
<li><p>卷积层通过在图像上滑动一个滤波器（kernel）来实现这一点，即使物体的位置发生变化，滤波器依然可以检测到它。</p></li>
<li><p>例子：在一张猫的图片中，滤波器在猫的耳朵上或猫的爪子上滑动时，都会产生相应的激活，从而检测到猫的存在。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>(2)局部性原则（Locality）：</dt><dd><ul>
<li><p>在网络的前几层，卷积操作主要关注局部区域（local region），而不考虑图像中远处的内容。</p></li>
<li><p>这种方法模拟了人类视觉系统中对局部特征（如边缘、角等）的关注。</p></li>
<li><p>意义：每次只处理一小部分图像，有助于减少计算量，并捕捉基本特征。最终，通过不断堆叠卷积层和池化层，模型可以聚合这些局部特征，形成对整个图像的理解。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>(3)深层特征提取：</dt><dd><ul>
<li><p>随着网络逐渐加深，感受野（receptive field）变大，网络可以学习到更长距离的特征关系，类似于更高级别的视觉感知。</p></li>
<li><p>这种方式使得 CNN 能够捕捉更复杂、更抽象的图像特征。</p></li>
<li><p>例子：在浅层，网络可能学习到边缘和纹理等简单特征，而在更深的层中，网络可能学习到眼睛、鼻子等复杂特征，最终能够识别出整个脸部。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
</section>
<section id="constraining-the-mlp">
<h5>7.1.2. Constraining the MLP<a class="headerlink" href="#constraining-the-mlp" title="此标题的永久链接">¶</a></h5>
<section id="id95">
<h6>整体<a class="headerlink" href="#id95" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>本节探讨的是如何将多层感知机（MLP）应用到二维图像上，并分析了这样做带来的挑战和参数爆炸问题。</p></li>
<li><p>在传统的 MLP 中，输入是一个扁平的向量，但对于图像来说，我们希望保留空间结构（spatial structure），即图像的二维形状。</p></li>
</ul>
<section id="mlp">
<h6 aria-level="7">理解 MLP 对二维图像的建模<a class="headerlink" href="#mlp" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>假设输入图像 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 和隐藏层表示 <span class="math notranslate nohighlight">\(\mathbf{H}\)</span> 都是二维矩阵，且二者形状相同（例如 <span class="math notranslate nohighlight">\(1000 \times 1000\)</span> 像素）。</p></li>
<li><p><span class="math notranslate nohighlight">\([\mathbf{X}]{i,j}\)</span> 代表输入图像在 (i,j) 位置的像素值，而 <span class="math notranslate nohighlight">\(\mathbf{H}]{i,j}\)</span> 代表隐藏层在 (i,j) 位置的激活值。</p></li>
</ul>
</section>
<section id="id96">
<h6 aria-level="7">权重矩阵到权重张量的切换<a class="headerlink" href="#id96" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>传统 MLP：在传统 MLP 中，隐藏层的每个神经元与输入层的所有像素相连，连接权重用一个二维矩阵 <span class="math notranslate nohighlight">\(\mathsf{W}\)</span> 表示。</p></li>
<li><dl class="simple">
<dt>二维图像 MLP：</dt><dd><ul>
<li><p>如果将每个隐藏单元都连接到输入图像的所有像素，我们需要一个四阶权重张量 <span class="math notranslate nohighlight">\(\mathsf{W}_{i,j,k,l}\)</span></p></li>
<li><p>这个四阶张量表示从输入图像位置 (k,l) 到隐藏层位置 (i,j) 的权重。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<p>公式解释：</p>
<div class="math notranslate nohighlight">
\[\left[\mathbf{H}\right]_{i, j} &amp;= [\mathbf{U}]_{i, j} + \sum_k \sum_l[\mathsf{W}]_{i, j, k, l}  [\mathbf{X}]_{k, l}\]</div>
<ul class="simple">
<li><p>位置 (i,j) 处的隐藏单元 <span class="math notranslate nohighlight">\(\mathbf{H}{i,j}\)</span> 是输入图像所有像素的加权和，再加上偏置 :math:mathbf{U}{i,j}`</p></li>
</ul>
</section>
<section id="id97">
<h6 aria-level="7">卷积的引入与参数重索引<a class="headerlink" href="#id97" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>为了减少复杂度，我们引入卷积的思想，将权重矩阵 <span class="math notranslate nohighlight">\(\mathsf{W}\)</span> 重新表示为 <span class="math notranslate nohighlight">\(\mathsf{V}\)</span> ，如下所示：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\left[\mathbf{H}\right]_{i, j} &amp;= [\mathbf{U}]_{i, j} + \sum_a \sum_b [\mathsf{V}]_{i, j, a, b}  [\mathbf{X}]_{i+a, j+b}\]</div>
<ul class="simple">
<li><p>这里的 <span class="math notranslate nohighlight">\(\mathsf{V}\)</span> 代表一个局部权重窗口，表示卷积核，只关注图像中与位置 (i,j) 相邻的局部区域。</p></li>
<li><p>权重索引变化：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[[\mathsf{V}]_{i, j, a, b} = [\mathsf{W}]_{i, j, i+a, j+k}\]</div>
<ul class="simple">
<li><p>这个索引变换意味着：卷积核以 (i,j) 为中心，采样相邻偏移量 (a,b) 处的像素。</p></li>
</ul>
</section>
<section id="id98">
<h6 aria-level="7">参数量爆炸问题<a class="headerlink" href="#id98" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>假设输入图像大小为 <span class="math notranslate nohighlight">\(1000 \times 1000\)</span> ，隐藏层表示同样为 <span class="math notranslate nohighlight">\(1000 \times 1000\)</span></p></li>
<li><p>如果每个像素都与所有像素相连，权重张量 <span class="math notranslate nohighlight">\(\mathsf{W}\)</span> 需要 <span class="math notranslate nohighlight">\(1000 \times 1000 \times 1000 \times 1000 = 10^{12}\)</span> 个参数！</p></li>
<li><p>这种参数量远远超出了计算机的处理能力。</p></li>
</ul>
</section>
<section id="id99">
<h6 aria-level="7">问题的根源与解决思路<a class="headerlink" href="#id99" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>问题根源： MLP 的全连接结构使每个隐藏单元都与所有输入像素相连，导致参数量爆炸。</p></li>
<li><dl class="simple">
<dt>解决方法：</dt><dd><ul>
<li><p>局部感受野（local receptive field）： 仅让隐藏单元与输入图像的局部区域相连，而非整个图像。</p></li>
<li><p>共享权重： 通过卷积层的方式，减少参数数量并增强平移不变性。</p></li>
<li><p>池化层（pooling）： 进一步降低分辨率，减少计算量。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="id100">
<h6 aria-level="7">小结<a class="headerlink" href="#id100" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>核心思想是：直接将 MLP 应用于高维图像会导致参数量巨大，不具备实际可行性。</p></li>
<li><p>通过引入卷积的概念，限制感受野范围，可以有效减少参数量，并保持对图像空间结构的敏感性。</p></li>
<li><p>这种方法构成了卷积神经网络（CNN）的基础，极大提升了模型的计算效率和识别能力。</p></li>
</ul>
</section>
</section>
<section id="translation-invariance">
<h6>7.1.2.1. Translation Invariance<a class="headerlink" href="#translation-invariance" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>平移不变性（Translation Invariance）：</p></li>
<li><p>定义： 平移不变性意味着：如果输入图像发生平移，隐藏层的输出也应发生同样的平移，而不会改变特征本身的性质。</p></li>
<li><p>直观理解： 如果在图像的不同位置看到相同的特征（如边缘或角），网络应当能识别它，而不在意特征的具体位置。</p></li>
</ul>
<section id="id101">
<h6 aria-level="7">数学解释<a class="headerlink" href="#id101" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>原始表示方式中，权重 <span class="math notranslate nohighlight">\(\mathsf{V}\)</span> 依赖于像素位置 (i,j) ，即 <span class="math notranslate nohighlight">\([\mathsf{V}]_{i,j,a,b}\)</span> 表示在位置 (i,j) 的权重可能与其他位置不同。</p></li>
<li><p>引入平移不变性后： 权重只与相对偏移量 (a,b) 有关，不再依赖具体位置：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[[\mathsf{V}]_{i,j,a,b} = [\mathsf{V}]_{a,b}\]</div>
<ul>
<li><p>偏置 <span class="math notranslate nohighlight">\(\mathbf{U}\)</span> 简化为常数 u。</p>
<blockquote>
<div><p>left[mathbf{H}right]_{i, j} &amp;= u + sum_a sum_b [mathsf{V}]_{a, b}  [mathbf{X}]_{i+a, j+b}</p>
</div></blockquote>
</li>
</ul>
</section>
</section>
<section id="locality">
<h6>7.1.2.2. Locality<a class="headerlink" href="#locality" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>局部感受野（Locality）</p></li>
<li><p>定义： 局部感受野意味着：隐藏层的每个神经元只关注输入图像的局部区域，而非整个图像。</p></li>
<li><p>动机： 在图像中，远离当前像素的区域对理解该位置像素的影响较小。因此，感受野可以限制在较小范围内。</p></li>
<li><p>实现方式： 在距离超过 <span class="math notranslate nohighlight">\(\Delta\)</span> 的地方，将权重设为 0：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[[\mathbf{V}]_{a, b} =0   \text{if} |a| &gt; \Delta \text{or} |b| &gt; \Delta\]</div>
<ul class="simple">
<li><p>公式表示：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[[\mathbf{H}]_{i, j} = u + \sum_{a = -\Delta}^{\Delta} \sum_{b = -\Delta}^{\Delta} [\mathbf{V}]_{a, b}  [\mathbf{X}]_{i+a, j+b}\]</div>
<ul class="simple">
<li><p>引入局部感受野后，卷积核尺寸从 <span class="math notranslate nohighlight">\(2000 \times 2000\)</span>  减少到一个较小值 <span class="math notranslate nohighlight">\(\Delta \times \Delta`（通常 :math:\)</span>Delta &lt; 10` ）。</p></li>
<li><p>这将参数量进一步减少到：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[4\Delta^2\]</div>
<ul class="simple">
<li><p>结果： 参数量减少了四个数量级，使得卷积层更加高效。</p></li>
</ul>
</section>
<section id="id102">
<h6>总结与启示<a class="headerlink" href="#id102" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>卷积核的作用： 提取图像局部特征，减少参数量，提升网络对图像的空间敏感性。</p></li>
<li><p>平移不变性的代价： 卷积核只能感知局部特征，在处理全局信息时需要更深的网络结构（更多层的卷积+池化）。</p></li>
<li><p>深层网络： 通过堆叠多层卷积层，可以逐层捕获更复杂、更抽象的特征，实现对整幅图像的理解。</p></li>
<li><p>直观类比：可以把 CNN 的卷积核想象成放大镜或探测器，它在图像中移动，寻找感兴趣的特征。通过限制探测器的大小和移动范围，我们既减少了复杂度，又提高了模型的效率和泛化能力。</p></li>
</ul>
</section>
<section id="id103">
<h6>CNN的优势<a class="headerlink" href="#id103" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>参数高效： CNN 只需少量参数即可处理高分辨率图像。</p></li>
<li><p>鲁棒性强： CNN 对图像的平移和局部变化具有较强的鲁棒性，能够更好地泛化到新数据。</p></li>
<li><p>特征层次化： 通过多层卷积，可以逐步学习低级（如边缘）到高级（如物体）特征。</p></li>
<li><p>计算高效： 卷积操作易于并行计算，适合 GPU 加速。</p></li>
</ul>
</section>
</section>
<section id="convolutions">
<h5>7.1.3. Convolutions<a class="headerlink" href="#convolutions" title="此标题的永久链接">¶</a></h5>
<section id="id104">
<h6>定义<a class="headerlink" href="#id104" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>卷积是信号处理和图像处理中常用的数学操作。</p></li>
<li><p>本质上，它是一种滑动窗口操作，计算两个函数或矩阵的重叠程度。</p></li>
<li><p>卷积的关键在于一个函数或矩阵在另一个函数或矩阵上进行滑动，并计算在每个位置上的重叠量。</p></li>
</ul>
</section>
<section id="id105">
<h6>数学定义<a class="headerlink" href="#id105" title="此标题的永久链接">¶</a></h6>
<section id="id106">
<h6 aria-level="7">连续卷积公式<a class="headerlink" href="#id106" title="此标题的永久链接">¶</a></h6>
<div class="math notranslate nohighlight">
\[(f * g)(\mathbf{x}) = \int f(\mathbf{z}) g(\mathbf{x}-\mathbf{z}) d\mathbf{z}\]</div>
<ul class="simple">
<li><dl class="simple">
<dt>解释</dt><dd><ul>
<li><p>f(z)：原始信号或图像。</p></li>
<li><p>𝑔(𝑥−𝑧)：滤波器 (或核函数) 在位置 𝑥 处翻转后平移的结果。</p></li>
<li><p>积分表示对所有可能的重叠进行累加。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>直观理解：</dt><dd><ul>
<li><p>类似将一个图形 𝑔 翻转后，在图形 𝑓 上逐个位置滑动，计算重叠区域的面积。</p></li>
<li><p>每个滑动位置都生成一个数值，表示该位置的匹配程度。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="id107">
<h6 aria-level="7">离散卷积公式(一维)<a class="headerlink" href="#id107" title="此标题的永久链接">¶</a></h6>
<div class="math notranslate nohighlight">
\[(f * g)(i) = \sum_a f(a) g(i-a)\]</div>
<ul class="simple">
<li><p>在离散场景下，积分变为求和。滑动窗口在每个位置 𝑖 上计算 𝑓 和 𝑔 的内积。</p></li>
</ul>
</section>
<section id="id108">
<h6 aria-level="7">二维卷积公式<a class="headerlink" href="#id108" title="此标题的永久链接">¶</a></h6>
<div class="math notranslate nohighlight">
\[(f * g)(i, j) = \sum_a\sum_b f(a, b) g(i-a, j-b)\]</div>
<ul class="simple">
<li><p>二维卷积扩展了概念，在 𝑎,𝑏 方向滑动滤波器，计算二维图像与滤波器的重叠程度。</p></li>
</ul>
</section>
</section>
<section id="id109">
<h6>卷积和交叉相关的区别<a class="headerlink" href="#id109" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><dl class="simple">
<dt>交叉相关 (Cross-correlation)：</dt><dd><ul>
<li><p>滤波器 𝑔 在滑动时不进行翻转，直接平移和累加。</p></li>
<li><p>卷积核和原始图像在相同方向滑动。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<div class="math notranslate nohighlight">
\[(f * g)(i, j) = \sum_a\sum_b f(a, b) g(i+a, j+b)\]</div>
<ul class="simple">
<li><dl class="simple">
<dt>卷积 (Convolution)：</dt><dd><ul>
<li><p>卷积的滤波器 𝑔(𝑖−𝑎,𝑗−𝑏) 是翻转后的版本。</p></li>
<li><p>实际深度学习中，通常使用交叉相关的形式，称之为“卷积”。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>为什么使用交叉相关？</dt><dd><ul>
<li><p>计算效率高，结果相似。</p></li>
<li><p>翻转操作在实现中可忽略，因此深度学习框架默认使用交叉相关。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="id110">
<h6>卷积的实际意义<a class="headerlink" href="#id110" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><dl class="simple">
<dt>卷积可在图像中提取局部特征，例如：</dt><dd><ul>
<li><p>检测边缘、角点、纹理等。</p></li>
<li><p>在不同层中逐渐捕捉更复杂的模式，从低级特征 (边缘) 到高级特征 (物体轮廓或类别)。</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>卷积是构建卷积神经网络 (CNN) 的核心操作</p></li>
</ul>
</section>
</section>
<section id="channels">
<h5>7.1.4. Channels<a class="headerlink" href="#channels" title="此标题的永久链接">¶</a></h5>
<section id="id111">
<h6>1. 图像的多通道特性<a class="headerlink" href="#id111" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>实际图像通常有 三通道：红 (R)、绿 (G)、蓝 (B)。</p></li>
<li><p>每个像素点不仅包含一个灰度值，而是一个向量，表示不同颜色的组合。</p></li>
<li><p>因此，图像是三阶张量 1024×1024×3，表示高度、宽度和通道数。</p></li>
</ul>
</section>
<section id="id112">
<h6>2. 为什么需要多通道卷积<a class="headerlink" href="#id112" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>简单的二维卷积只能处理灰度图像。</p></li>
<li><dl class="simple">
<dt>多通道卷积可以：</dt><dd><ul>
<li><p>处理复杂的彩色图像。</p></li>
<li><p>在每个通道上分别提取特征，最终结合生成更丰富的特征表达。</p></li>
<li><p>允许不同滤波器学习捕捉图像的不同方面，例如边缘、纹理和颜色分布。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="id113">
<h6>3. 数学定义<a class="headerlink" href="#id113" title="此标题的永久链接">¶</a></h6>
<p>多通道卷积公式：</p>
<div class="math notranslate nohighlight">
\[[\mathsf{H}]_{i,j,d} = \sum_{a = -\Delta}^{\Delta} \sum_{b = -\Delta}^{\Delta} \sum_c [\mathsf{V}]_{a, b, c, d} [\mathsf{X}]_{i+a, j+b, c}\]</div>
<ul class="simple">
<li><p>i,j：表示卷积在图像上的空间位置。</p></li>
<li><p>𝑐：输入通道索引。</p></li>
<li><p>𝑑：输出通道索引 (不同滤波器产生不同的输出通道)。</p></li>
<li><p>核 𝑉 是一个四阶张量，维度为 𝑎,𝑏,𝑐,𝑑，即滤波器大小和输入输出通道数。</p></li>
</ul>
</section>
<section id="id114">
<h6>4. 直观理解<a class="headerlink" href="#id114" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>将滤波器在每个通道上分别滑动，然后在所有通道上的结果相加，得到最终的输出特征。</p></li>
<li><p>这种方式类似于对图像的不同部分进行特征组合，生成更加复杂的表达。</p></li>
</ul>
</section>
<section id="feature-maps">
<h6>5. 隐藏表示和特征图 (Feature Maps)<a class="headerlink" href="#feature-maps" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>每个卷积层的输出也是多通道的，即隐藏表示 𝐻 也是三阶张量。</p></li>
<li><dl class="simple">
<dt>每个隐藏通道捕捉不同类型的特征。例如：</dt><dd><ul>
<li><p>第一个通道检测边缘。</p></li>
<li><p>第二个通道检测角点。</p></li>
<li><p>第三个通道检测纹理或复杂形状。</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>这些输出通道常称为“特征图”或“特征通道”。</p></li>
</ul>
</section>
<section id="id115">
<h6>6. 多层卷积的特征提取机制<a class="headerlink" href="#id115" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>低层卷积层： 提取简单特征 (如边缘)。</p></li>
<li><p>中层卷积层： 组合低层特征，提取更复杂的形状或结构。</p></li>
<li><p>高层卷积层： 识别物体或场景中的高级特征，如人脸或特定物体。</p></li>
</ul>
</section>
<section id="id116">
<h6>7. 通道的现实意义<a class="headerlink" href="#id116" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>多通道卷积帮助模型捕捉更复杂的视觉特征，提高模型表达能力。</p></li>
<li><p>深度卷积网络 (CNN) 在图像分类、目标检测和分割等任务中表现卓越，部分原因在于多通道卷积的强大能力。</p></li>
</ul>
</section>
<section id="id117">
<h6>8. 关键点总结<a class="headerlink" href="#id117" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>通道允许卷积层处理彩色图像或多维特征，使CNN在实际应用中表现更强大。</p></li>
<li><p>多通道输出表示不同层次的特征组合，为网络提供更全面的图像表示能力。</p></li>
</ul>
</section>
</section>
<section id="summary-and-discussion">
<h5>7.1.5. Summary and Discussion<a class="headerlink" href="#summary-and-discussion" title="此标题的永久链接">¶</a></h5>
<section id="id118">
<h6>关键点<a class="headerlink" href="#id118" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>平移不变性 (Translation Invariance)：图像中的物体无论出现在图像的哪个位置，卷积操作都能以相同的方式处理它。这种不变性是 CNN 设计的重要原则之一。</p></li>
<li><p>局部性 (Locality)：每个卷积核仅关注图像的小区域 (局部感受野)，并通过滑动窗口机制逐个位置计算特征，逐步构建全局理解。</p></li>
</ul>
</section>
<section id="id119">
<h6>理解<a class="headerlink" href="#id119" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>解释：CNN 的核心优势在于能够高效地提取局部特征，并保持对位置信息的不敏感性，这种设计使 CNN 适用于图像分类、目标检测等任务。</p></li>
<li><p>类比：想象一个人观察一张图片时，通常不会一次性关注整张图像，而是逐个区域观察并理解细节。这种局部关注和逐步汇总的方式与 CNN 的工作方式相似。</p></li>
</ul>
</section>
<section id="id120">
<h6>降低复杂度与参数数量<a class="headerlink" href="#id120" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>问题：大规模图像或高维数据通常具有极高的维度，直接建模计算量巨大且参数过多，容易导致模型过拟合或计算不可行。</p></li>
<li><p>解决方案：CNN 通过卷积操作，强制模型只关注局部区域，减少参数数量，同时保留足够的表达能力。这种策略将复杂的计算问题转化为可行的模型，避免了计算和统计上的不可行性。</p></li>
<li><p>示例：假设原始图像大小为 1024×1024×3，如果直接使用全连接层，参数量非常庞大。而卷积核通常大小为 3×3 或 5×5，参数数量显著减少。</p></li>
<li><p>理解要点：降维和特征提取的同时不丢失关键信息，是 CNN 在高效处理复杂数据时的重要特性。</p></li>
</ul>
</section>
<section id="id121">
<h6>引入通道 (Channels) 增强模型能力<a class="headerlink" href="#id121" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>背景：卷积核的局部性和平移不变性在降低复杂度的同时，也限制了模型的表达能力。</p></li>
<li><p>解决方法：引入多个通道 (如 RGB)，允许模型学习更复杂和多样的特征，弥补了局部卷积带来的表达能力损失。</p></li>
<li><dl class="simple">
<dt>进一步扩展：图像中常见的三个通道 (红、绿、蓝)，是基本的颜色信息。然而，实际应用中可能存在更多通道。例如：</dt><dd><ul>
<li><p>卫星图像： 可能包含几十甚至上百个通道 (多光谱或高光谱图像)，记录不同波长的反射数据。</p></li>
<li><p>医学成像： MRI 或 CT 扫描中不同通道可能代表不同的层面或组织特性。</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>理解：通过引入额外通道，CNN 可以处理更复杂的数据，学习多维度的特征表示，从而提升模型的表现力和泛化能力。</p></li>
</ul>
</section>
</section>
</section>
<section id="convolutions-for-images">
<h4>7.2. Convolutions for Images<a class="headerlink" href="#convolutions-for-images" title="此标题的永久链接">¶</a></h4>
<section id="the-cross-correlation-operation">
<h5>7.2.1. The Cross-Correlation Operation<a class="headerlink" href="#the-cross-correlation-operation" title="此标题的永久链接">¶</a></h5>
<figure class="align-default" id="id226">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/vuP5GV.png" src="https://img.zhaoweiguo.com/uPic/2025/01/vuP5GV.png" />
<figcaption>
<p><span class="caption-text">输入是一个高度为3、宽度为3的二维张量。我们将张量的形状标记为 <code class="docutils literal notranslate"><span class="pre">3x3</span> <span class="pre">或</span> <span class="pre">(3，3）</span></code>。kernel的高度和宽度都是2。kernel window (or convolution window)的形状由内核的高度和宽度给出（这里是 <code class="docutils literal notranslate"><span class="pre">2x2</span></code> ）。</span><a class="headerlink" href="#id226" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>在二维互相关运算(two-dimensional cross-correlation operation)中，我们从位于输入张量左上角的卷积窗口开始，并将其从左到右、从上到下滑动穿过输入张量。</p></li>
<li><p>当卷积窗口滑动到某个位置时，该窗口中包含的输入子张量与内核张量按元素相乘，并将所得张量相加，生成单个标量值。</p></li>
<li><p>该结果给出了相应位置处的输出张量的值。</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}0\times0+1\times1+3\times2+4\times3=19,\\
1\times0+2\times1+4\times2+5\times3=25,\\
3\times0+4\times1+6\times2+7\times3=37,\\
4\times0+5\times1+7\times2+8\times3=43.\end{split}\]</div>
<ul class="simple">
<li><p>输出大小由输入大小 <span class="math notranslate nohighlight">\(n_h \times n_w\)</span> 减去 kernel 大小 <span class="math notranslate nohighlight">\(k_h \times k_w\)</span></p></li>
</ul>
<div class="math notranslate nohighlight">
\[(n_h - k_h +1) \times (n_w - k_w +1)\]</div>
<p>代码:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">corr2d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">K</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute 2D cross-correlation.&quot;&quot;&quot;</span>
    <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">h</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">w</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">h</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span><span class="n">j</span> <span class="o">+</span> <span class="n">w</span><span class="p">]</span> <span class="o">*</span> <span class="n">K</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">Y</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span>
                  <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">],</span>
                  <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">]])</span>
<span class="n">K</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]])</span>
<span class="n">corr2d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">K</span><span class="p">)</span>
<span class="c1"># 输出</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">19.</span><span class="p">,</span> <span class="mf">25.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">37.</span><span class="p">,</span> <span class="mf">43.</span><span class="p">]])</span>
</pre></div>
</div>
</section>
<section id="convolutional-layers">
<h5>7.2.2. Convolutional Layers<a class="headerlink" href="#convolutional-layers" title="此标题的永久链接">¶</a></h5>
<p>前向传播方法:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Conv2D</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">corr2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span>
</pre></div>
</div>
</section>
<section id="object-edge-detection-in-images">
<h5>7.2.3. Object Edge Detection in Images<a class="headerlink" href="#object-edge-detection-in-images" title="此标题的永久链接">¶</a></h5>
<p>构建一个 6x8 像素的“图像”。中间四列是黑色（ 0 ），其余是白色（ 1 ）:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">X</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">6</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">X</span>
<span class="c1"># 输出</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]])</span>
</pre></div>
</div>
<ul>
<li><p>构造一个高度为1、宽度为2的 kernel K</p></li>
<li><p>此内核是有限差分运算符的特例: At location <span class="math notranslate nohighlight">\((i,j)\)</span> it computes <span class="math notranslate nohighlight">\(x_{i,j} - x_{(i+1),j}\)</span> ，即计算水平相邻像素的值之间的差异</p></li>
<li><p>代码实现:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">K</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">]])</span>
</pre></div>
</div>
</li>
</ul>
<p>参数 X （我们的 input） 和 K （我们的 kernel） 执行 cross-correlation operation:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Y</span> <span class="o">=</span> <span class="n">corr2d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">K</span><span class="p">)</span>
<span class="n">Y</span>
<span class="c1"># 输出</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">]])</span>
</pre></div>
</div>
<p>将内核应用于转置图像。正如预期的那样，它消失了。内核 K 仅检测垂直边缘:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">corr2d</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">t</span><span class="p">(),</span> <span class="n">K</span><span class="p">)</span>
<span class="c1"># 输出</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]])</span>
</pre></div>
</div>
</section>
<section id="learning-a-kernel">
<h5>7.2.4. Learning a Kernel<a class="headerlink" href="#learning-a-kernel" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Construct a two-dimensional convolutional layer with 1 output channel and a kernel of shape (1, 2).</span>
<span class="c1"># For the sake of simplicity, we ignore the bias here</span>
<span class="n">conv2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># The two-dimensional convolutional layer uses four-dimensional input and output in the format of (example, channel, height, width),</span>
<span class="c1"># where the batch size (number of examples in the batch) and the number of channels are both 1</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">3e-2</span>  <span class="c1"># Learning rate</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">Y_hat</span> <span class="o">=</span> <span class="n">conv2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">l</span> <span class="o">=</span> <span class="p">(</span><span class="n">Y_hat</span> <span class="o">-</span> <span class="n">Y</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
    <span class="n">conv2d</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">l</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="c1"># Update the kernel</span>
    <span class="n">conv2d</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">[:]</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">conv2d</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">grad</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;epoch </span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">, loss </span><span class="si">{</span><span class="n">l</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="c1"># 输出</span>
<span class="n">epoch</span> <span class="mi">2</span><span class="p">,</span> <span class="n">loss</span> <span class="mf">16.481</span>
<span class="n">epoch</span> <span class="mi">4</span><span class="p">,</span> <span class="n">loss</span> <span class="mf">5.069</span>
<span class="n">epoch</span> <span class="mi">6</span><span class="p">,</span> <span class="n">loss</span> <span class="mf">1.794</span>
<span class="n">epoch</span> <span class="mi">8</span><span class="p">,</span> <span class="n">loss</span> <span class="mf">0.688</span>
<span class="n">epoch</span> <span class="mi">10</span><span class="p">,</span> <span class="n">loss</span> <span class="mf">0.274</span>
</pre></div>
</div>
<p>学习的 kernel tensor:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># 与我们之前定义的核张量 K 非常接近</span>
<span class="n">conv2d</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="c1"># 输出</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">1.0398</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9328</span><span class="p">]])</span>
</pre></div>
</div>
</section>
<section id="cross-correlation-and-convolution">
<h5>7.2.5. Cross-Correlation and Convolution<a class="headerlink" href="#cross-correlation-and-convolution" title="此标题的永久链接">¶</a></h5>
<p>交叉相关 (Cross-Correlation) 与卷积 (Convolution) 的关系:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>核心差异：
    交叉相关 (Cross-Correlation)： 不翻转卷积核，直接在输入上滑动并计算加权和。
    卷积 (Convolution)： 在执行交叉相关之前，先将卷积核水平和垂直翻转，然后再进行滑动和计算。
</pre></div>
</div>
<ul class="simple">
<li><p>交叉相关公式</p></li>
</ul>
<div class="math notranslate nohighlight">
\[(f * g)(t) = \sum_x{f(x)g(x+t)}\]</div>
<ul class="simple">
<li><p>卷积公式</p></li>
</ul>
<div class="math notranslate nohighlight">
\[(f * g)(t) = \sum_x{f(x)g(t-x)}\]</div>
<ul class="simple">
<li><dl class="simple">
<dt>核心区别：</dt><dd><ul>
<li><p>交叉相关不对信号进行翻转，只是简单地滑动并计算重叠部分的内积。</p></li>
<li><p>卷积对信号进行翻转（即 <code class="docutils literal notranslate"><span class="pre">𝑔(𝑡)→𝑔(−𝑡)</span></code> ），然后滑动并计算内积。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>为什么深度学习中交叉相关和卷积无实质区别::</dt><dd><ul>
<li><p>在深度学习中，卷积核 (filter) 是从数据中学习的。</p></li>
<li><p>不论卷积层执行的是严格卷积还是交叉相关，卷积核的学习过程都会自动调整，使得输出结果一致。</p></li>
<li><p>直观理解：卷积核在训练过程中是动态调整的，即便在数学上交叉相关和卷积稍有不同，训练后最终得到的卷积核已经隐含这种差异，使得两种操作的输出一致。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>深度学习术语的约定俗成</dt><dd><ul>
<li><p>尽管在严格意义上，交叉相关和卷积存在差异，但在深度学习文献中，交叉相关通常也直接被称为“卷积”。</p></li>
<li><p>这种约定使得术语更加简洁，避免在描述模型架构时反复强调二者的区别。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>总结要点：</dt><dd><ul>
<li><p>交叉相关与卷积： 数学上存在差异，卷积涉及卷积核的翻转，但在深度学习中通常不加以区分。</p></li>
<li><p>实质影响： 卷积核在训练过程中自动调整，因此不论执行交叉相关还是严格卷积，输出结果保持一致。</p></li>
<li><p>术语约定： 深度学习文献中，交叉相关操作通常直接称为卷积。</p></li>
<li><p>简化理解： 深度学习模型实现卷积层时，关注点在于卷积核的学习和特征提取效果，而非严格的数学定义差异。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="feature-map-and-receptive-field">
<h5>7.2.6. Feature Map and Receptive Field<a class="headerlink" href="#feature-map-and-receptive-field" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt>特征图 (Feature Map) 与感受野 (Receptive Field) 的定义</dt><dd><ul>
<li><p>特征图 (Feature Map)：特征图是卷积层的输出，它可以被看作是对输入空间维度（如宽度和高度）的学习表示。特征图在每一层提取输入数据的不同特征，供后续层进一步处理。</p></li>
<li><p>感受野 (Receptive Field)：感受野是指卷积网络中某个元素 (如特征图中的一个像素) 受到前面哪些输入元素影响的范围。换句话说，感受野表示了输出中某个元素在输入中“看到”的区域大小。</p></li>
<li><dl class="simple">
<dt>关键点：</dt><dd><ul>
<li><p>感受野不仅取决于当前层，还取决于所有前面层的累积影响。</p></li>
<li><p>感受野可以比输入本身更大，表示该位置的特征汇集了更大区域的信息。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>直观理解：</dt><dd><ul>
<li><p>每堆叠一层卷积，输出的感受野都会扩大，使得网络能够捕捉更广泛的空间信息。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>总结要点：</dt><dd><ul>
<li><p>特征图： 是卷积层输出的空间表示，用于提取输入的局部特征。</p></li>
<li><p>感受野： 指卷积层输出中某个元素在输入中“看到”的区域大小。感受野可以随着网络深度增加而扩大，帮助模型捕捉更大范围的信息。</p></li>
<li><p>层次特征提取： 较低层提取边缘和简单形状，高层提取复杂模式和语义特征。</p></li>
<li><p>生物启发： 卷积的设计灵感源于视觉皮层的研究，证明了卷积在生物和计算机视觉领域的有效性。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="id122">
<h5>7.2.7. Summary<a class="headerlink" href="#id122" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt>卷积层核心计算：</dt><dd><ul>
<li><p>卷积层的核心计算是互相关 (cross-correlation) 操作。</p></li>
<li><p>计算互相关非常简单，使用一个嵌套的 for 循环即可完成，这表明卷积操作的计算是直接且局部的 (local)。</p></li>
<li><dl class="simple">
<dt>关键点：</dt><dd><ul>
<li><p>局部性： 互相关只涉及输入数据的局部区域，这种局部操作在硬件优化方面非常重要。</p></li>
<li><p>矩阵运算： 当有多个输入和输出通道时，卷积层的计算相当于在通道之间进行矩阵乘法操作，进一步强调了计算的简洁性和局部性。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>卷积的应用场景：</dt><dd><ul>
<li><p>边缘检测 (Edge Detection)： 识别图像中的边缘和轮廓。</p></li>
<li><p>线条检测 (Line Detection)： 提取图像中的线条和形状。</p></li>
<li><p>图像模糊 (Blurring)： 平滑图像，减少噪声。</p></li>
<li><p>图像锐化 (Sharpening)： 增强图像的细节和对比度。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>卷积核学习：</dt><dd><ul>
<li><p>传统方法需要人工设计滤波器（如 Sobel 滤波器或 Canny 边缘检测），但卷积神经网络 (CNN) 能够直接从数据中学习最优的滤波器。</p></li>
<li><p>这种方式避免了复杂的特征工程，通过数据驱动的方法自动学习特征，极大提高了模型的表现能力。</p></li>
<li><p>核心优势：取代了手工设计特征的启发式方法，转而使用基于数据的统计方法来学习有效特征。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
</section>
<section id="padding-and-stride">
<h4>7.3. Padding and Stride<a class="headerlink" href="#padding-and-stride" title="此标题的永久链接">¶</a></h4>
<section id="padding">
<h5>7.3.1. Padding<a class="headerlink" href="#padding" title="此标题的永久链接">¶</a></h5>
<figure class="align-default" id="id227">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/MRcs2k.png" src="https://img.zhaoweiguo.com/uPic/2025/01/MRcs2k.png" />
<figcaption>
<p><span class="caption-text">Fig. 7.3.1 Pixel utilization for convolutions of size 1x1, 2x2, and 3x3 respectively.</span><a class="headerlink" href="#id227" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<figure class="align-default" id="id228">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/DfsuXi.png" src="https://img.zhaoweiguo.com/uPic/2025/01/DfsuXi.png" />
<figcaption>
<p><span class="caption-text">Fig. 7.3.2 Two-dimensional cross-correlation with padding.</span><a class="headerlink" href="#id228" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>In general, if we add a total of <span class="math notranslate nohighlight">\(p_h\)</span> rows of padding (roughly half on top and half on bottom) and a total of <span class="math notranslate nohighlight">\(p_w\)</span> columns of padding (roughly half on the left and half on the right), the output shape will be:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[(n_h - k_h + p_h +1) \times (n_w - k_w + p_w +1)\]</div>
<ul class="simple">
<li><p>In many cases, we will want to set <span class="math notranslate nohighlight">\(p_h = k_h -1\)</span> and <span class="math notranslate nohighlight">\(p_w = k_w -1\)</span> to give the input and output the same height and width.</p></li>
<li><p>This will make it easier to predict the output shape of each layer when constructing the network.</p></li>
<li><p>所以，CNN 通常使用高度和宽度值为奇数的卷积核( <span class="math notranslate nohighlight">\(k_h \time k_w\)</span> )，例如 1、3、5 或 7。选择奇数的内核大小的好处是，我们可以在顶部和底部使用相同的行数，左侧和右侧具有相同数量的列数进行填充时保持维度（因为Kernel是奇数时，Padding是偶数）。</p></li>
</ul>
<p>创建一个高度和宽度均为 3 的二维卷积层，并在所有侧面应用 1 个像素的填充。给定一个 height 和 width 为 8 的输入，我们发现输出的 height 和 width 也是 8</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># We define a helper function to calculate convolutions.</span>
<span class="c1"># It initializes the convolutional layer weights and performs corresponding dimensionality elevations and reductions on the input and output</span>
<span class="k">def</span><span class="w"> </span><span class="nf">comp_conv2d</span><span class="p">(</span><span class="n">conv2d</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="c1"># (1, 1) indicates that batch size and the number of channels are both 1</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">conv2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="c1"># Strip the first two dimensions: examples and channels</span>
    <span class="k">return</span> <span class="n">Y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>

<span class="c1"># 1 row and column is padded on either side, so a total of 2 rows or columns are added</span>
<span class="n">conv2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">comp_conv2d</span><span class="p">(</span><span class="n">conv2d</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
<p>当卷积核的高度和宽度不同时，我们可以通过为 height 和 width 设置不同的填充数来使 output 和 input 具有相同的 height 和 width:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># We use a convolution kernel with height 5 and width 3.</span>
<span class="c1"># The padding on either side of the height and width are 2 and 1, respectively</span>
<span class="n">conv2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">comp_conv2d</span><span class="p">(</span><span class="n">conv2d</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
<ul class="simple">
<li><dl class="simple">
<dt>填充的作用和意义</dt><dd><ul>
<li><p>核心作用：填充通过在输入图像的边缘添加额外像素（通常是零）来增加输出的高度和宽度。</p></li>
<li><dl class="simple">
<dt>目的：</dt><dd><ul>
<li><p>防止输出尺寸缩小： 在卷积过程中，每次卷积都会导致输出尺寸缩小。如果不希望输出变小，可以使用填充保持输入和输出的尺寸一致。</p></li>
<li><p>保持所有像素的平等使用： 在无填充的情况下，边缘像素的使用频率较低。填充确保边缘像素与中心像素一样频繁地参与计算，从而提升模型对边缘特征的学习能力。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>常见方式：</dt><dd><ul>
<li><p>对称填充： 在输入图像的高度和宽度两侧均匀添加相同数量的像素，记作 <span class="math notranslate nohighlight">\((𝑝_ℎ,𝑝_𝑤)\)</span></p></li>
<li><p>简化记法： 如果垂直和水平填充相等，直接记作 p</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>零填充的优点</dt><dd><ul>
<li><p>计算简单： 直接在图像边缘补零，计算和实现都很简单，硬件优化更容易。</p></li>
<li><p>隐含位置信息： CNN可以学习到填充值的分布，从而理解图像的边缘和中心区域的差异。</p></li>
<li><p>内存友好： 不需要额外分配大量内存，可以在卷积操作中隐式完成。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>非零填充的情况</dt><dd><ul>
<li><p>存在多种非零填充方法： 虽然零填充是最常用的，但也有其他方式（如镜像填充、重复边缘值等）。</p></li>
<li><p>使用场景： 通常只有在发现零填充带来不良的视觉或特征提取效果时，才会考虑使用其他类型的填充。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="stride">
<h5>7.3.2. Stride<a class="headerlink" href="#stride" title="此标题的永久链接">¶</a></h5>
<figure class="align-default" id="id229">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/XbNI1B.png" src="https://img.zhaoweiguo.com/uPic/2025/01/XbNI1B.png" />
<figcaption>
<p><span class="caption-text">Fig. 7.3.3 Cross-correlation with strides of 3 and 2 for height and width, respectively.</span><a class="headerlink" href="#id229" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<p>改变步长的作用:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>计算效率： 较大的步长可以减少计算量，因为滑动窗口覆盖的位置更少，输出张量的尺寸也更小。
下采样 (Downsampling)： 较大的步长可以对输入进行下采样，减少分辨率的同时保留关键信息。
大卷积核： 如果卷积核较大，它本身已能捕获大范围的特征，此时使用较大步长可以减少冗余计算。
</pre></div>
</div>
<p>当 height 的 stride 为 <span class="math notranslate nohighlight">\(s_h\)</span> 且 width 的 stride 为 <span class="math notranslate nohighlight">\(s_w\)</span> 时，输出形状为</p>
<div class="math notranslate nohighlight">
\[\lfloor\frac{(n_\textrm{h}-k_\textrm{h}+p_\textrm{h}+s_\textrm{h})}{s_\textrm{h}}\rfloor \times \lfloor\frac{(n_\textrm{w}-k_\textrm{w}+p_\textrm{w}+s_\textrm{w})}{s_\textrm{w}}\rfloor\]</div>
<ul class="simple">
<li><p>If we set <span class="math notranslate nohighlight">\(p_\textrm{h}=k_\textrm{h}-1\)</span> and <span class="math notranslate nohighlight">\(p_\textrm{w}=k_\textrm{w}-1\)</span> , then the output shape can be simplified to <span class="math notranslate nohighlight">\(\lfloor\frac{(n_\textrm{h}+s_\textrm{h}-1)}{s_\textrm{h}}\rfloor \times \lfloor\frac{(n_\textrm{w}+s_\textrm{w}-1)}{s_\textrm{w}}\rfloor\)</span> .</p></li>
<li><p>进一步简化，输出尺寸 <strong>约</strong> 等于 <span class="math notranslate nohighlight">\((n_\textrm{h}/s_\textrm{h}) \times (n_\textrm{w}/s_\textrm{w})\)</span> .</p></li>
</ul>
<p>将 height 和 width 的步幅都设置为 2，从而将输入的 height 和 width 减半:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="n">conv2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">comp_conv2d</span><span class="p">(</span><span class="n">conv2d</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="c1"># 输出</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="c1"># shape计算过程</span>
<span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="n">k</span><span class="o">+</span><span class="n">s</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">s</span> <span class="o">=</span> <span class="p">(</span><span class="mi">8</span><span class="o">-</span><span class="mi">3</span><span class="o">+</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span> <span class="o">=</span> <span class="mi">4</span>
</pre></div>
</div>
<p>稍微复杂一点的例子:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conv2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">comp_conv2d</span><span class="p">(</span><span class="n">conv2d</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="c1"># 输出</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="c1"># 说明</span>
<span class="n">第一维</span><span class="p">:</span> <span class="p">(</span><span class="mi">8</span><span class="o">-</span><span class="mi">3</span><span class="o">+</span><span class="mi">0</span><span class="o">+</span><span class="mi">3</span><span class="p">)</span><span class="o">/</span><span class="mi">3</span> <span class="o">=</span> <span class="mf">2.67</span>   <span class="o">-&gt;</span> <span class="mi">2</span>
<span class="n">第二维</span><span class="p">:</span> <span class="p">(</span><span class="mi">8</span><span class="o">-</span><span class="mi">5</span><span class="o">+</span><span class="mi">2</span><span class="o">+</span><span class="mi">4</span><span class="p">)</span><span class="o">/</span><span class="mi">4</span> <span class="o">=</span> <span class="mf">2.25</span>   <span class="o">-&gt;</span> <span class="mi">2</span>
</pre></div>
</div>
<ul class="simple">
<li><dl class="simple">
<dt>步幅的作用和意义</dt><dd><ul>
<li><p>核心作用：步幅控制卷积窗口在输入图像上滑动的步长（移动距离）。</p></li>
<li><dl class="simple">
<dt>目的：</dt><dd><ul>
<li><p>降低输出分辨率： 步幅大于1时，每次卷积窗口滑动会跳过部分位置，从而减少输出尺寸。例如，步幅为2时，输出的尺寸是输入的 1/2。</p></li>
<li><p>加速计算： 大步幅减少了卷积计算次数，提高了计算效率。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>常见方式：</dt><dd><ul>
<li><p>对称步幅： 如果水平和垂直步幅相同，直接记作 𝑠</p></li>
<li><p>默认设置： 填充默认为0，步幅默认为1，即不填充且滑动一个像素。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="id123">
<h5>计算输出尺寸<a class="headerlink" href="#id123" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>GPT的输出（好像不对，待确定）</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{l}
H_{\text {out }}=\left\lfloor\frac{H_{\text {in }}+2 \times \text { padding }- \text { dilation } \times(\text { kernel_size }-1)-1}{\text { stride }}+1\right\rfloor \\
W_{\text {out }}=\left\lfloor\frac{W_{\text {in }}+2 \times \text { padding }- \text { dilation } \times(\text { kernel_size }-1)-1}{\text { stride }}+1\right\rfloor
\end{array}\end{split}\]</div>
<ul class="simple">
<li><p>输入高度和宽度：H_in = 32, W_in = 32</p></li>
<li><p>卷积核大小：kernel_size = 3</p></li>
<li><p>步幅：stride = 1</p></li>
<li><p>填充：padding = 1</p></li>
<li><p>扩张率：dilation = 1</p></li>
</ul>
</section>
<section id="id124">
<h5>总结<a class="headerlink" href="#id124" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt>填充和步幅是卷积层的重要超参数，它们影响输出尺寸、计算效率和特征提取效果。</dt><dd><ul>
<li><p>填充： 保持尺寸一致，防止边缘信息丢失。</p></li>
<li><p>步幅： 控制分辨率，减少计算量。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
</section>
<section id="multiple-input-and-multiple-output-channels">
<h4>7.4. Multiple Input and Multiple Output Channels<a class="headerlink" href="#multiple-input-and-multiple-output-channels" title="此标题的永久链接">¶</a></h4>
<section id="multiple-input-channels">
<h5>7.4.1. Multiple Input Channels<a class="headerlink" href="#multiple-input-channels" title="此标题的永久链接">¶</a></h5>
<section id="id125">
<h6>核心要点<a class="headerlink" href="#id125" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><dl class="simple">
<dt>多通道输入的卷积核心要求：</dt><dd><ul>
<li><p>当输入数据有多个通道（channels）时，卷积核的通道数需要和输入数据的通道数相同，才能进行逐通道的交叉相关运算。</p></li>
<li><p>如果输入数据有 <span class="math notranslate nohighlight">\(𝑐_{in}\)</span>  个通道，那么卷积核也需要有 <span class="math notranslate nohighlight">\(𝑐_{in}\)</span> 个通道。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>卷积核的结构：</dt><dd><ul>
<li><p>当输入数据只有一个通道（ <span class="math notranslate nohighlight">\(𝑐_{in}=1\)</span> ），卷积核是一个简单的二维张量，形状是 <span class="math notranslate nohighlight">\(𝑘_h \times 𝑘_w\)</span></p></li>
<li><p>当输入数据有多个通道（ <span class="math notranslate nohighlight">\(𝑐_{in}&gt;1\)</span> ），卷积核对每个输入通道都有一个二维张量，最终的卷积核形状为 <span class="math notranslate nohighlight">\(𝑐_{in} \times 𝑘_h \times 𝑘_w\)</span></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>多通道卷积计算方式：</dt><dd><ul>
<li><p>对每个通道分别进行二维交叉相关操作，然后将每个通道的结果相加，得到最终的输出。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<figure class="align-default" id="id230">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/QkorY1.png" src="https://img.zhaoweiguo.com/uPic/2025/01/QkorY1.png" />
<figcaption>
<p><span class="caption-text">Fig. 7.4.1 Cross-correlation computation with two input channels.</span><a class="headerlink" href="#id230" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<p>实现具有多个 input 通道的交叉相关操作:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">corr2d_multi_in</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">K</span><span class="p">):</span>
    <span class="c1"># Iterate through the 0th dimension (channel) of K first, then add them up</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">corr2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">K</span><span class="p">))</span>
</pre></div>
</div>
<p>构造与图 7.4.1 中的值 K 相对应的输入张量 X 和核张量，以验证互相关运算的输出:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">]],</span>
                  <span class="p">[[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">7.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">]]])</span>
<span class="n">K</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]],</span>
                  <span class="p">[[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]]])</span>
<span class="n">corr2d_multi_in</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">K</span><span class="p">)</span>
<span class="c1"># 输出</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">56.</span><span class="p">,</span>  <span class="mf">72.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">104.</span><span class="p">,</span> <span class="mf">120.</span><span class="p">]])</span>
<span class="c1"># 计算: n-k+1 = 3-2+1 = 2</span>
<span class="c1"># shape: torch.Size([2, 2])</span>
</pre></div>
</div>
</section>
</section>
<section id="multiple-output-channels">
<h5>7.4.2. Multiple Output Channels<a class="headerlink" href="#multiple-output-channels" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>要产生多个输出通道，需要为每个输出通道创建一个单独的卷积核。</p></li>
<li><p>此时，卷积核成为一个 4 维张量，形状为 ( <span class="math notranslate nohighlight">\(c_o \times c_i \times k_h \times k_w\)</span> )</p></li>
<li><p>其中 ( <span class="math notranslate nohighlight">\(c_o, c_i\)</span> ) 是输出和输入通道的数量； ( <span class="math notranslate nohighlight">\(k_h, k_w\)</span> ) 是内核的高度和宽度</p></li>
<li><p>每个输出通道的结果都由其对应的卷积核计算得出，并从所有输入通道获取输入。</p></li>
</ul>
<p>实现一个互相关函数来计算多个通道的输出:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">corr2d_multi_in_out</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">K</span><span class="p">):</span>
    <span class="c1"># Iterate through the 0th dimension of K, and each time, perform cross-correlation operations with input X.</span>
    <span class="c1"># All of the results are stacked together</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">corr2d_multi_in</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">K</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>We construct a trivial convolution kernel with three output channels by concatenating the kernel tensor for K with K+1 and K+2:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">K</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">K</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">K</span> <span class="o">+</span> <span class="mi">2</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">K</span><span class="o">.</span><span class="n">shape</span>
<span class="c1"># 输出</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
<p>对 X 具有核张量的输入张量执行互相关运算 K:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">corr2d_multi_in_out</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">K</span><span class="p">)</span>
<span class="c1"># 输出</span>
<span class="n">tensor</span><span class="p">([[[</span> <span class="mf">56.</span><span class="p">,</span>  <span class="mf">72.</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">104.</span><span class="p">,</span> <span class="mf">120.</span><span class="p">]],</span>

        <span class="p">[[</span> <span class="mf">76.</span><span class="p">,</span> <span class="mf">100.</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">148.</span><span class="p">,</span> <span class="mf">172.</span><span class="p">]],</span>

        <span class="p">[[</span> <span class="mf">96.</span><span class="p">,</span> <span class="mf">128.</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">192.</span><span class="p">,</span> <span class="mf">224.</span><span class="p">]]])</span>
<span class="c1"># shape计算过程</span>

<span class="c1"># shape: torch.Size([3, 2, 2])</span>
</pre></div>
</div>
</section>
<section id="x1-convolutional-layer">
<h5>7.4.3. 1x1 Convolutional Layer<a class="headerlink" href="#x1-convolutional-layer" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>1x1 卷积核不考虑高度和宽度维度上的相邻像素，仅在通道维度上进行操作。</p></li>
<li><p>它对输入图像中相同位置的元素进行线性组合。</p></li>
<li><p>可以将其视为在每个像素位置应用的全连接层，将 ( <span class="math notranslate nohighlight">\(c_i\)</span> ) 个输入值转换为 ( <span class="math notranslate nohighlight">\(c_o\)</span> ) 个输出值，但权重在像素位置之间共享。</p></li>
<li><p>它需要 ( <span class="math notranslate nohighlight">\(c_o \times c_i\)</span> ) 个权重（加上偏置）</p></li>
</ul>
<figure class="align-default" id="id231">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/m0G1zI.png" src="https://img.zhaoweiguo.com/uPic/2025/01/m0G1zI.png" />
<figcaption>
<p><span class="caption-text">Fig. 7.4.2 The cross-correlation computation uses the convolution kernel with three input channels and two output channels. The input and output have the same height and width.</span><a class="headerlink" href="#id231" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<p>使用全连接层实现 1x1 卷积:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">corr2d_multi_in_out_1x1</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">K</span><span class="p">):</span>
    <span class="n">c_i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">c_o</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">c_i</span><span class="p">,</span> <span class="n">h</span> <span class="o">*</span> <span class="n">w</span><span class="p">))</span>
    <span class="n">K</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">c_o</span><span class="p">,</span> <span class="n">c_i</span><span class="p">))</span>
    <span class="c1"># Matrix multiplication in the fully connected layer</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Y</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">c_o</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">))</span>
</pre></div>
</div>
<p>用一些示例数据来检查:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">K</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">Y1</span> <span class="o">=</span> <span class="n">corr2d_multi_in_out_1x1</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">K</span><span class="p">)</span>
<span class="n">Y2</span> <span class="o">=</span> <span class="n">corr2d_multi_in_out</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">K</span><span class="p">)</span>
<span class="k">assert</span> <span class="nb">float</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">Y1</span> <span class="o">-</span> <span class="n">Y2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span> <span class="o">&lt;</span> <span class="mf">1e-6</span>
</pre></div>
</div>
</section>
<section id="discussion">
<h5>7.4.4. Discussion<a class="headerlink" href="#discussion" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt>计算成本</dt><dd><ul>
<li><dl class="simple">
<dt>卷积操作复杂度：</dt><dd><ul>
<li><dl class="simple">
<dt>给定一个大小为 <code class="docutils literal notranslate"><span class="pre">ℎ×𝑤</span></code> 的图像，使用一个 <code class="docutils literal notranslate"><span class="pre">𝑘×𝑘</span></code> 的卷积核</dt><dd><ul>
<li><p>计算复杂度是： <span class="math notranslate nohighlight">\(𝑂(ℎ⋅𝑤⋅𝑘^2)\)</span></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>如果输入通道数是 <span class="math notranslate nohighlight">\(𝑐_i\)</span> ，输出通道数是 <span class="math notranslate nohighlight">\(𝑐_o\)</span></dt><dd><ul>
<li><p>复杂度增加为： <span class="math notranslate nohighlight">\(𝑂(ℎ⋅𝑤⋅𝑘^2⋅𝑐_i⋅𝑐_o)\)</span></p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>计算示例：</dt><dd><ul>
<li><p>对一个 256×256 的图像，使用 5×5 的卷积核，输入和输出通道数均为 128，计算量超过 530 亿次操作（乘法和加法分开计算）。</p></li>
<li><p>这是因为卷积操作不仅需要遍历整个图像，还要在所有通道上进行运算，计算量会迅速增加。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>关键理解：</dt><dd><ul>
<li><p>多通道增加了模型的表达能力，但也带来了计算成本的上升。</p></li>
<li><p>设计 CNN 结构时，需要在计算复杂度和模型表达能力之间找到平衡。</p></li>
<li><p>未来的模型设计中，降低计算成本是重要的研究方向之一。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
</section>
<section id="pooling">
<h4>7.5. Pooling<a class="headerlink" href="#pooling" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><dl class="simple">
<dt>池化的目的:</dt><dd><ul>
<li><p>减少卷积层对输入特征精确位置的敏感性，即提高平移不变性。这意味着即使特征稍微移动，模型仍然可以检测到它。</p></li>
<li><p>在空间上对特征表示进行下采样。这会降低特征图的空间分辨率，从而减少表示的大小，并加快计算速度</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<section id="maximum-pooling-and-average-pooling">
<h5>7.5.1. Maximum Pooling and Average Pooling<a class="headerlink" href="#maximum-pooling-and-average-pooling" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>池化操作使用 <strong>固定形状的窗口（池化窗口）</strong> 在输入上滑动</p></li>
<li><p>与卷积层中 inputs 和 kernel 的互相关计算不同，池化层不包含任何参数（没有 kernel ）</p></li>
<li><p>最大池化 (max-pooling) 计算每个池化窗口内的最大值</p></li>
<li><p>平均池化 (average pooling) 计算每个池化窗口内的平均值</p></li>
<li><p>在大多数情况下，最大池化优于平均池化。最大池化的概念源于认知神经科学，用于描述对象识别中信息的层级聚合</p></li>
<li><p>平均池化可以看作是对图像进行下采样的一种方式，通过组合多个相邻像素的信息来提高信噪比</p></li>
<li><dl class="simple">
<dt>池化如何工作:</dt><dd><ul>
<li><p>池化窗口从左到右、从上到下滑动输入张量。</p></li>
<li><p>在每个位置，它计算窗口内输入子张量的最大值或平均值.</p></li>
<li><p>一个 ( <span class="math notranslate nohighlight">\(p \times q\)</span> ) 的池化层会在该尺寸的区域上进行聚合。例如，对输入张量 [,,] 进行 (2times 2) 最大池化，会产生输出</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<figure class="align-default" id="id232">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/5x5Tif.png" src="https://img.zhaoweiguo.com/uPic/2025/01/5x5Tif.png" />
<figcaption>
<p><span class="caption-text">Fig. 7.5.1 Max-pooling with a pooling window shape of 2x2. The shaded portions are the first output element as well as the input tensor elements used for the output computation: <code class="docutils literal notranslate"><span class="pre">max(0,1,3,4)=4</span></code> .说明：2x2滑动容器的最大池化就是，这获取4个元素里面的最大值</span><a class="headerlink" href="#id232" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<p>池化层的正向传播(不需要内核，将输出计算为输入中每个区域的最大值或平均值):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">pool2d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pool_size</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;max&#39;</span><span class="p">):</span>
    <span class="n">p_h</span><span class="p">,</span> <span class="n">p_w</span> <span class="o">=</span> <span class="n">pool_size</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">p_h</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">p_w</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;max&#39;</span><span class="p">:</span>
                <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">p_h</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="n">j</span> <span class="o">+</span> <span class="n">p_w</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
            <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;avg&#39;</span><span class="p">:</span>
                <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">p_h</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="n">j</span> <span class="o">+</span> <span class="n">p_w</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">Y</span>
</pre></div>
</div>
<p>验证二维最大池化层的输出:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span>
                  <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">],</span>
                  <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">]])</span>
<span class="n">pool2d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="c1"># 输出</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">7.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">]])</span>
</pre></div>
</div>
<p>平均池化层:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pool2d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s1">&#39;avg&#39;</span><span class="p">)</span>
<span class="c1"># 输出</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">]])</span>
</pre></div>
</div>
</section>
<section id="id126">
<h5>7.5.2. Padding and Stride<a class="headerlink" href="#id126" title="此标题的永久链接">¶</a></h5>
<p>用内置的二维 max-pooling 层来演示 padding 和 strides 在池化层中的使用:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">X</span>
<span class="c1"># 输出</span>
<span class="n">tensor</span><span class="p">([[[[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">,</span>  <span class="mf">7.</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">8.</span><span class="p">,</span>  <span class="mf">9.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">,</span> <span class="mf">11.</span><span class="p">],</span>
          <span class="p">[</span><span class="mf">12.</span><span class="p">,</span> <span class="mf">13.</span><span class="p">,</span> <span class="mf">14.</span><span class="p">,</span> <span class="mf">15.</span><span class="p">]]]])</span>
</pre></div>
</div>
<p>深度学习框架默认匹配池化窗口大小和步幅(if we use a pooling window of shape (3, 3) we get a stride shape of (3, 3) by default):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pool2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="c1"># Pooling has no model parameters, hence it needs no initialization</span>
<span class="n">pool2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="c1"># 输出</span>
<span class="n">tensor</span><span class="p">([[[[</span><span class="mf">10.</span><span class="p">]]]])</span>
</pre></div>
</div>
<p>手动指定步幅和填充来覆盖框架默认值:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pool2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">pool2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="c1"># 输出</span>
<span class="n">tensor</span><span class="p">([[[[</span> <span class="mf">5.</span><span class="p">,</span>  <span class="mf">7.</span><span class="p">],</span>
          <span class="p">[</span><span class="mf">13.</span><span class="p">,</span> <span class="mf">15.</span><span class="p">]]]])</span>
</pre></div>
</div>
<p>指定一个任意高度和宽度的任意矩形池化窗口:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pool2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">pool2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="c1"># 输出</span>
<span class="n">tensor</span><span class="p">([[[[</span> <span class="mf">5.</span><span class="p">,</span>  <span class="mf">7.</span><span class="p">],</span>
          <span class="p">[</span><span class="mf">13.</span><span class="p">,</span> <span class="mf">15.</span><span class="p">]]]])</span>
</pre></div>
</div>
</section>
<section id="multiple-channels">
<h5>7.5.3. Multiple Channels<a class="headerlink" href="#multiple-channels" title="此标题的永久链接">¶</a></h5>
<ul>
<li><p>在处理多通道 input 数据时，pooling layer 单独池化每个 input 通道，而不是像卷积层那样在 channels 上对 inputs 求和。这意味着池化层的输出通道数与输入通道数相同</p></li>
<li><p>连接张 X 量 和 X + 1 通道维度，以构造具有两个通道的输入:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">X</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">X</span>
<span class="c1"># 输出</span>
<span class="n">tensor</span><span class="p">([[[[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">4.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">,</span>  <span class="mf">7.</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">8.</span><span class="p">,</span>  <span class="mf">9.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">,</span> <span class="mf">11.</span><span class="p">],</span>
          <span class="p">[</span><span class="mf">12.</span><span class="p">,</span> <span class="mf">13.</span><span class="p">,</span> <span class="mf">14.</span><span class="p">,</span> <span class="mf">15.</span><span class="p">]],</span>

         <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">5.</span><span class="p">,</span>  <span class="mf">6.</span><span class="p">,</span>  <span class="mf">7.</span><span class="p">,</span>  <span class="mf">8.</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">9.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">,</span> <span class="mf">11.</span><span class="p">,</span> <span class="mf">12.</span><span class="p">],</span>
          <span class="p">[</span><span class="mf">13.</span><span class="p">,</span> <span class="mf">14.</span><span class="p">,</span> <span class="mf">15.</span><span class="p">,</span> <span class="mf">16.</span><span class="p">]]]])</span>
</pre></div>
</div>
</li>
</ul>
<p>pooling 后 output channels 的数量仍然是 2:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pool2d</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">pool2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="c1"># tensor([[[[ 5.,  7.],</span>
            <span class="p">[</span><span class="mf">13.</span><span class="p">,</span> <span class="mf">15.</span><span class="p">]],</span>

           <span class="p">[[</span> <span class="mf">6.</span><span class="p">,</span>  <span class="mf">8.</span><span class="p">],</span>
            <span class="p">[</span><span class="mf">14.</span><span class="p">,</span> <span class="mf">16.</span><span class="p">]]]])</span>
</pre></div>
</div>
</section>
<section id="id127">
<h5>7.5.4. Summary<a class="headerlink" href="#id127" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>池化是一个非常简单的操作。</p></li>
<li><p>pooling 与 channels 无关，即，它保持 channels 数量不变，并且分别应用于每个 channel。</p></li>
<li><p>在两种流行的池化选项中，max-pooling 比 average pooling 更可取，因为它为 output 赋予了一定程度的不变性。</p></li>
<li><p>一种常见的选择是选择池化窗口大小 2x2 ，以将输出的原空间分辨率的四分之一。</p></li>
<li><dl class="simple">
<dt>扩展</dt><dd><ul>
<li><p>stochastic pooling (Zeiler and Fergus, 2013)</p></li>
<li><p>fractional max-pooling (Graham, 2014)</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
</section>
<section id="convolutional-neural-networks-lenet">
<h4>7.6. Convolutional Neural Networks (LeNet)<a class="headerlink" href="#convolutional-neural-networks-lenet" title="此标题的永久链接">¶</a></h4>
<section id="lenet">
<h5>7.6.1. LeNet<a class="headerlink" href="#lenet" title="此标题的永久链接">¶</a></h5>
<figure class="align-default" id="id233">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/jCTEhQ.png" src="https://img.zhaoweiguo.com/uPic/2025/01/jCTEhQ.png" />
<figcaption>
<p><span class="caption-text">Fig. 7.6.1 Data flow in LeNet. The input is a handwritten digit, the output is a probability over 10 possible outcomes.</span><a class="headerlink" href="#id233" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>The basic units in each <strong>convolutional</strong> block are a convolutional layer, a sigmoid activation function, and a subsequent average pooling operation.</p></li>
<li><p>Each convolutional layer uses a 5x5 kernel and a sigmoid activation function.</p></li>
<li><p>这些层将空间排列的输入映射到许多二维特征图，通常会增加通道的数量。第一个卷积层有 6 个输出通道，而第二个卷积层有 16 个输出通道。</p></li>
</ul>
<p>代码实现此类模型:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">init_cnn</span><span class="p">(</span><span class="n">module</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialize weights for CNNs.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">module</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span> <span class="ow">or</span> <span class="nb">type</span><span class="p">(</span><span class="n">module</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">:</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>

<span class="k">class</span><span class="w"> </span><span class="nc">LeNet</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Classifier</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The LeNet-5 model.&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="mi">120</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="mi">84</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">num_classes</span><span class="p">))</span>
</pre></div>
</div>
<figure class="align-default" id="id234">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/fsDzSL.png" src="https://img.zhaoweiguo.com/uPic/2025/01/fsDzSL.png" />
<figcaption>
<p><span class="caption-text">Fig. 7.6.2 Compressed notation for LeNet-5.</span><a class="headerlink" href="#id234" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Classifier</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">layer_summary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_shape</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">X_shape</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="s1">&#39;output shape:</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LeNet</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">layer_summary</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span>
<span class="c1"># 输出</span>
<span class="n">Conv2d</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>         <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">])</span>
<span class="n">Sigmoid</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>        <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">])</span>
<span class="n">AvgPool2d</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>      <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">14</span><span class="p">])</span>
<span class="n">Conv2d</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>         <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="n">Sigmoid</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>        <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="n">AvgPool2d</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>      <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">Flatten</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>        <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">400</span><span class="p">])</span>
<span class="n">Linear</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>         <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">120</span><span class="p">])</span>
<span class="n">Sigmoid</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>        <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">120</span><span class="p">])</span>
<span class="n">Linear</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>         <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">84</span><span class="p">])</span>
<span class="n">Sigmoid</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>        <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">84</span><span class="p">])</span>
<span class="n">Linear</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>         <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section id="id128">
<h5>7.6.2. Training<a class="headerlink" href="#id128" title="此标题的永久链接">¶</a></h5>
<p>计算成本比类似深度的 MLP 更高:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LeNet</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">apply_init</span><span class="p">([</span><span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">get_dataloader</span><span class="p">(</span><span class="kc">True</span><span class="p">)))[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">init_cnn</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="modern-convolutional-neural-networks">
<h3>8. Modern Convolutional Neural Networks<a class="headerlink" href="#modern-convolutional-neural-networks" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p>现代 CNN 不仅可以被使用 直接用于视觉任务，但它们也作为基本特征 用于更高级任务（例如跟踪）的生成器 （ Zhang et al. ，2021 ） ，分割 （ Long et al. ，2015 ） ，物体检测 （ Redmon 和 Farhadi，2018 ） ，或风格转变 （盖蒂斯等人，2016 ） 。</p></li>
<li><p>从 AlexNet 开始现代 CNN 之旅 （ Krizhevsky et al. ，2012 ） ，第一个大规模部署网络以击败传统计算机视觉方法 大规模的视力挑战；</p></li>
<li><p>VGG网络 （ Simonyan 和 Zisserman，2014 ） ，它利用了一些 重复的元素块；</p></li>
<li><p>网络中的网络 (NiN) 在输入上逐块卷积整个神经网络 （林等人，2013 ） ；</p></li>
<li><p>GoogLeNet 使用多分支卷积网络（ Szegedy等人，2015 ） ；</p></li>
<li><p>残差网络（ResNet） （ He et al. ，2016 ） ，它仍然是计算机视觉中最流行的现成架构之一； ResNeXt 块（ Xie et al. , 2017 ）用于稀疏连接；</p></li>
<li><p>DenseNet （ Huang et al. ，2017 ）用于残差架构的泛化。</p></li>
</ul>
<section id="deep-convolutional-neural-networks-alexnet">
<h4>8.1. Deep Convolutional Neural Networks (AlexNet)<a class="headerlink" href="#deep-convolutional-neural-networks-alexnet" title="此标题的永久链接">¶</a></h4>
<section id="representation-learning">
<h5>8.1.1. Representation Learning<a class="headerlink" href="#representation-learning" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>在 AlexNet 出现之前，卷积神经网络（CNN）在计算机视觉领域并未占据主导地位。尽管 LeNet 在早期的小型数据集上取得了不错的效果，但在更大的、更真实的数据集上训练 CNN 的性能和可行性尚未得到证实。</p></li>
<li><p>第一个现代 CNN（Krizhevsky 等人，2012）以其发明者之一 Alex Krizhevsky 的名字命名为 AlexNet，很大程度上是对 LeNet 的进化改进。它在2012年ImageNet挑战赛中取得了优异的表现。</p></li>
<li><p>AlexNet (2012) 及其前身 LeNet (1995) 共享许多架构元素。这就引出了一个问题：为什么花了这么长时间？一个关键的区别是，在过去的二十年里，可用的数据量和计算能力显着增加。因此，AlexNet 规模要大得多：与 1995 年可用的 CPU 相比，它使用更多的数据和更快的 GPU 进行训练。</p></li>
</ul>
</section>
<section id="alexnet">
<h5>8.1.2. AlexNet<a class="headerlink" href="#alexnet" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>AlexNet 采用 8 层 CNN，以大幅优势赢得了 2012 年 ImageNet 大规模视觉识别挑战赛 (Russakovsky et al., 2013)。该网络首次表明，通过学习获得的特征可以超越人工设计的特征，打破了计算机视觉以往的范式。</p></li>
</ul>
<figure class="align-default" id="id235">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/tGioru.png" src="https://img.zhaoweiguo.com/uPic/2025/01/tGioru.png" />
<figcaption>
<p><span class="caption-text">Fig. 8.1.2 From LeNet (left) to AlexNet (right).</span><a class="headerlink" href="#id235" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">AlexNet</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Classifier</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="mi">4096</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="mi">4096</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">num_classes</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">init_cnn</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">layer_summary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_shape</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">X_shape</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="s1">&#39;output shape:</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<p>构造一个高和宽均为224的单通道数据示例来观察每一层的输出形状:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">AlexNet</span><span class="p">()</span><span class="o">.</span><span class="n">layer_summary</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
<span class="c1"># 输出</span>
<span class="n">Conv2d</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>         <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="mi">54</span><span class="p">,</span> <span class="mi">54</span><span class="p">])</span>
<span class="n">ReLU</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>   <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="mi">54</span><span class="p">,</span> <span class="mi">54</span><span class="p">])</span>
<span class="n">MaxPool2d</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>      <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="mi">26</span><span class="p">,</span> <span class="mi">26</span><span class="p">])</span>
<span class="n">Conv2d</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>         <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">26</span><span class="p">,</span> <span class="mi">26</span><span class="p">])</span>
<span class="n">ReLU</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>   <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">26</span><span class="p">,</span> <span class="mi">26</span><span class="p">])</span>
<span class="n">MaxPool2d</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>      <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">])</span>
<span class="n">Conv2d</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>         <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">])</span>
<span class="n">ReLU</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>   <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">])</span>
<span class="n">Conv2d</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>         <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">])</span>
<span class="n">ReLU</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>   <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">])</span>
<span class="n">Conv2d</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>         <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">])</span>
<span class="n">ReLU</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>   <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">])</span>
<span class="n">MaxPool2d</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>      <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">Flatten</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>        <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6400</span><span class="p">])</span>
<span class="n">Linear</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>         <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4096</span><span class="p">])</span>
<span class="n">ReLU</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>   <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4096</span><span class="p">])</span>
<span class="n">Dropout</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>        <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4096</span><span class="p">])</span>
<span class="n">Linear</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>         <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4096</span><span class="p">])</span>
<span class="n">ReLU</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>   <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4096</span><span class="p">])</span>
<span class="n">Dropout</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>        <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4096</span><span class="p">])</span>
<span class="n">Linear</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>         <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section id="id129">
<h5>8.1.3. Training<a class="headerlink" href="#id129" title="此标题的永久链接">¶</a></h5>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">AlexNet</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">resize</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>  <span class="c1"># 使用 resize 参数执行此大小调整，为了适配模型改造的数据</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/yeTMvt.png" src="https://img.zhaoweiguo.com/uPic/2025/01/yeTMvt.png" />
</figure>
</section>
</section>
<section id="networks-using-blocks-vgg">
<h4>8.2. Networks Using Blocks (VGG)<a class="headerlink" href="#networks-using-blocks-vgg" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>VGG (Visual Geometry Group)</p></li>
</ul>
<section id="id130">
<h5>背景和概念演进<a class="headerlink" href="#id130" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt>深度网络设计的演变</dt><dd><ul>
<li><p>AlexNet 证明了深度卷积神经网络（CNN）的有效性，但没有提供通用的设计模板。</p></li>
<li><p>随着研究的发展，网络设计逐渐从单个神经元扩展到整层，再到如今的“模块化设计”，即基于重复模式的块（blocks）。这种模块化理念源自芯片设计领域中逻辑单元到逻辑块的抽象过程。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>VGG 的提出</dt><dd><ul>
<li><p>VGG 是由牛津大学的视觉几何组（Visual Geometry Group）提出的网络，其核心创新是通过重复的卷积块设计深度网络。</p></li>
<li><p>VGG 的设计旨在探索深层网络与宽网络的性能差异，最终验证了深而窄的网络在性能上优于浅而宽的网络。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="vgg">
<h5>VGG 的核心设计<a class="headerlink" href="#vgg" title="此标题的永久链接">¶</a></h5>
<section id="vgg-blocks">
<h6>8.2.1. VGG Blocks<a class="headerlink" href="#vgg-blocks" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>一个 VGG 块由多个 3x3 的卷积层组成，每个卷积层后接一个非线性激活（如 ReLU），再接一个 2x2 的最大池化层（stride 为 2）。</p></li>
<li><p>使用多个 3x3 卷积层替代单个较大卷积（如 5x5 或 7x7），既能减少参数数量，又能提高性能。</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">vgg_block</span><span class="p">(</span><span class="n">num_convs</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">):</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_convs</span><span class="p">):</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
    <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="vgg-network">
<h6>8.2.2. VGG Network<a class="headerlink" href="#vgg-network" title="此标题的永久链接">¶</a></h6>
<figure class="align-default" id="id236">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/WFgQj9.png" src="https://img.zhaoweiguo.com/uPic/2025/01/WFgQj9.png" />
<figcaption>
<p><span class="caption-text">Fig. 8.2.1 From AlexNet to VGG. The key difference is that VGG consists of blocks of layers, whereas AlexNet’s layers are all designed individually.</span><a class="headerlink" href="#id236" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><dl class="simple">
<dt>VGG 网络可以划分为两部分：</dt><dd><ul>
<li><p>卷积部分：由多个 VGG 块组成，逐渐减少空间分辨率。</p></li>
<li><p>全连接部分：与 AlexNet 类似，包含多个全连接层。</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>原始 VGG-11 网络包括 5 个卷积块，最初的两个块各有 1 层卷积，后三个块各有 2 层卷积。每个块的输出通道数逐步翻倍，从 64 增加到 512。</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">VGG</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Classifier</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arch</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
        <span class="n">conv_blks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">num_convs</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span> <span class="ow">in</span> <span class="n">arch</span><span class="p">:</span>
            <span class="n">conv_blks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vgg_block</span><span class="p">(</span><span class="n">num_convs</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="o">*</span><span class="n">conv_blks</span><span class="p">,</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="mi">4096</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="mi">4096</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">num_classes</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">init_cnn</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id131">
<h6>8.2.3. Training<a class="headerlink" href="#id131" title="此标题的永久链接">¶</a></h6>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">VGG</span><span class="p">(</span><span class="n">arch</span><span class="o">=</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">128</span><span class="p">)),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">resize</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">apply_init</span><span class="p">([</span><span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">get_dataloader</span><span class="p">(</span><span class="kc">True</span><span class="p">)))[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">d2l</span><span class="o">.</span><span class="n">init_cnn</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="id132">
<h5>意义和扩展<a class="headerlink" href="#id132" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt>VGG 的贡献</dt><dd><ul>
<li><p>VGG 是首个真正现代化的 CNN 网络，引入了“模块化设计”的理念，通过深而窄的架构显著提升性能。</p></li>
<li><p>它开创了设计“网络家族”的趋势，即通过调整块的数量和参数，形成具有不同性能和复杂度的网络变体。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>性能权衡</dt><dd><ul>
<li><p>在实际应用中，设计者可以根据需要在速度和精度之间找到适合的平衡点。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>新方向</dt><dd><ul>
<li><p>最近的研究（如 ParNet）表明，通过更多并行计算，浅层网络也可以实现竞争性性能，这可能为未来的网络架构设计提供新思路。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="id133">
<h5>总结<a class="headerlink" href="#id133" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>VGG 的设计不仅奠定了现代深度学习网络的基础，也为深度学习的普及和快速实现提供了便利。其模块化设计思想至今仍被后续研究广泛借鉴。</p></li>
</ul>
</section>
</section>
<section id="network-in-network-nin">
<h4>8.3. Network in Network (NiN)<a class="headerlink" href="#network-in-network-nin" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>NiN 网络在 LeNet、AlexNet 和 VGG 的基础上进一步改进</p></li>
<li><p>VGG 等这些网络通过卷积层和池化层提取空间特征，并通过全连接层进行后续处理。</p></li>
<li><dl class="simple">
<dt>这种设计存在两个主要问题：</dt><dd><ul>
<li><p>全连接层参数量大：传统的全连接层需要大量的参数和内存，例如 VGG-11 的全连接层就占据了近 400MB 内存。这在移动设备和嵌入式设备上难以实现。</p></li>
<li><p>无法在网络早期引入全连接层：在网络早期引入全连接层会破坏空间结构，同时还会进一步增加内存需求。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>NiN 的创新点</dt><dd><ul>
<li><p>1x1 卷积：作为局部全连接层，在不改变空间维度的情况下为每个像素位置添加非线性。</p></li>
<li><p>全局平均池化：在网络最后一层通过全局平均池化整合空间信息，完全替代全连接层，大幅减少参数量。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<section id="nin-blocks">
<h5>8.3.1. NiN Blocks<a class="headerlink" href="#nin-blocks" title="此标题的永久链接">¶</a></h5>
<figure class="align-default" id="id237">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/8X2MQC.png" src="https://img.zhaoweiguo.com/uPic/2025/01/8X2MQC.png" />
<figcaption>
<p><span class="caption-text">Fig. 8.3.1 Comparing the architectures of VGG and NiN, and of their blocks.</span><a class="headerlink" href="#id237" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>注意 NiN 块中的差异（初始卷积后面是 1x1 卷积，而 VGG 保留 3x3 卷积）以及最后我们不再需要巨大的全连接层。</p></li>
<li><dl class="simple">
<dt>结构特点</dt><dd><ul>
<li><p>卷积设计：初始卷积层与 AlexNet 类似，使用 11x11、5x5 和 3x3 的卷积核。</p></li>
<li><p>NiN 块：每个块包含一个标准卷积层，后接两个 1x1 卷积层，提升特征提取效率。</p></li>
<li><p>全局平均池化：在最后的特征表示层通过全局平均池化代替全连接层，用于生成分类的 logits。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>优势</dt><dd><ul>
<li><p>参数量显著减少：不需要大型的全连接层，适合内存受限的设备。</p></li>
<li><p>提升平移不变性：全局平均池化增强了模型对平移的鲁棒性。</p></li>
<li><p>提高非线性建模能力：通过 1x1 卷积在每个位置捕获通道间的交互，提高网络表达能力。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">nin_block</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
</pre></div>
</div>
</section>
<section id="nin-model">
<h5>8.3.2. NiN Model<a class="headerlink" href="#nin-model" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>NiN 与 AlexNet 和 VGG 之间的第二个显着区别是 NiN 完全避免了全连接层。</p></li>
<li><p>NiN 使用 NiN 块，其输出通道数等于标签类的数量，后跟全局平均池化层，产生 logits 向量。这种设计显着减少了所需模型参数的数量，但代价是可能会增加训练时间。</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">NiN</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Classifier</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nin_block</span><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nin_block</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nin_block</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
            <span class="n">nin_block</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">init_cnn</span><span class="p">)</span>
</pre></div>
</div>
<p>创建一个数据示例来查看每个块的输出形状:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">NiN</span><span class="p">()</span><span class="o">.</span><span class="n">layer_summary</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
<span class="c1"># 输出</span>
<span class="n">Sequential</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>     <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="mi">54</span><span class="p">,</span> <span class="mi">54</span><span class="p">])</span>
<span class="n">MaxPool2d</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>      <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="mi">26</span><span class="p">,</span> <span class="mi">26</span><span class="p">])</span>
<span class="n">Sequential</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>     <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">26</span><span class="p">,</span> <span class="mi">26</span><span class="p">])</span>
<span class="n">MaxPool2d</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>      <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">])</span>
<span class="n">Sequential</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>     <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">])</span>
<span class="n">MaxPool2d</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>      <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">Dropout</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>        <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">Sequential</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>     <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">AdaptiveAvgPool2d</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>      <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">Flatten</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>        <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section id="id134">
<h5>8.3.3. Training<a class="headerlink" href="#id134" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">NiN</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">resize</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">apply_init</span><span class="p">([</span><span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">get_dataloader</span><span class="p">(</span><span class="kc">True</span><span class="p">)))[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">d2l</span><span class="o">.</span><span class="n">init_cnn</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id135">
<h5>8.3.4. Summary<a class="headerlink" href="#id135" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>NiN 的参数比 AlexNet 和 VGG 少得多。这主要源于这样一个事实：它不需要巨大的全连接层。相反，它使用全局平均池来聚合网络主体最后阶段之后的所有图像位置。这消除了对昂贵的（学习的）归约操作的需要，并用简单的平均值代替它们。</p></li>
<li><p>选择较少的宽核卷积并将其替换为 1x1 卷积有助于进一步减少参数。它可以满足任何给定位置内跨通道的大量非线性。 1x1 卷积和全局平均池化都显着影响了后续的 CNN 设计。</p></li>
<li><p>【影响】NiN 的 1x1 卷积和全局平均池化设计对后续的 CNN 网络架构产生了深远影响，使得模型在保持高准确率的同时变得更加高效。</p></li>
</ul>
</section>
</section>
<section id="multi-branch-networks-googlenet">
<h4>8.4. Multi-Branch Networks (GoogLeNet)<a class="headerlink" href="#multi-branch-networks-googlenet" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>2014 年，GoogLeNet 赢得了 ImageNet 挑战赛（Szegedy 等人，2015 年），其结构结合了 NiN（Lin 等人，2013 年）、重复块（Simonyan 和 Zisserman，2014 年）以及混合卷积的优点内核。</p></li>
<li><p>GoogLeNet 的关键贡献是网络主体的设计。它巧妙地解决了卷积核选择的问题。</p></li>
</ul>
<section id="id136">
<h5>设计概述<a class="headerlink" href="#id136" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt>创新点</dt><dd><ul>
<li><p><strong>NiN（Network in Network）</strong> 的思想，即利用 1x1 卷积来提取特征并减少计算量。</p></li>
<li><p>重复模块的设计，类似于VGG网络的模块化思想。</p></li>
<li><p>多种卷积核的结合，通过多分支结构同时使用不同大小的卷积核，而不是单独选择某一种。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>GoogLeNet首次明确了卷积神经网络的三部分结构：</dt><dd><ul>
<li><dl class="simple">
<dt>Stem(输入部分):</dt><dd><ul>
<li><p>前两三个卷积层，用于提取低级特征。</p></li>
<li><p>以AlexNet和LeNet为基础的 7x7 卷积和最大池化。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Body(主体部分):</dt><dd><ul>
<li><p>多个卷积块，用于深层次特征提取。</p></li>
<li><p>每组包含多个Inception块，依次增加通道数。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Head(输出部分):</dt><dd><ul>
<li><p>将提取的特征映射到特定的任务（分类、检测等）。</p></li>
<li><p>通过全局平均池化，直接输出分类结果。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="inception-blocks">
<h5>8.4.1. Inception Blocks<a class="headerlink" href="#inception-blocks" title="此标题的永久链接">¶</a></h5>
<figure class="align-default" id="id238">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/hLbjyp.png" src="https://img.zhaoweiguo.com/uPic/2025/01/hLbjyp.png" />
<figcaption>
<p><span class="caption-text">Fig. 8.4.1 Structure of the Inception block.(GoogLeNet 中的基本卷积块称为 Inception 块)</span><a class="headerlink" href="#id238" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><dl class="simple">
<dt>起始块由四个并行分支组成。</dt><dd><ul>
<li><p>使用 1x1 卷积提取低级特征。</p></li>
<li><p>使用 1x1 卷积降维后，再用 3x3 卷积提取中等尺度特征。</p></li>
<li><p>使用 1x1 卷积降维后，再用 5x5 卷积提取更大尺度特征。</p></li>
<li><p>使用 3x3 最大池化后，再用 1x1 卷积改变通道数。</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>最后，每个分支的输出沿着通道维度连接并构成块的输出。</p></li>
<li><p>关键超参数：每层的输出通道数，决定了不同分支分配的容量大小。</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Inception</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="c1"># c1--c4 are the number of output channels for each branch</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">c1</span><span class="p">,</span> <span class="n">c2</span><span class="p">,</span> <span class="n">c3</span><span class="p">,</span> <span class="n">c4</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Inception</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="c1"># Branch 1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b1_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="n">c1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># Branch 2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b2_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="n">c2</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b2_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="n">c2</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># Branch 3</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b3_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="n">c3</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b3_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="n">c3</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="c1"># Branch 4</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b4_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b4_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="n">c4</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">b1</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b1_1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">b2</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b2_2</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b2_1</span><span class="p">(</span><span class="n">x</span><span class="p">))))</span>
        <span class="n">b3</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b3_2</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b3_1</span><span class="p">(</span><span class="n">x</span><span class="p">))))</span>
        <span class="n">b4</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b4_2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b4_1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">b1</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">b3</span><span class="p">,</span> <span class="n">b4</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="googlenet-model">
<h5>8.4.2. GoogLeNet Model<a class="headerlink" href="#googlenet-model" title="此标题的永久链接">¶</a></h5>
<figure class="align-default" id="id239">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/bXEC5A.png" src="https://img.zhaoweiguo.com/uPic/2025/01/bXEC5A.png" />
<figcaption>
<p><span class="caption-text">Fig. 8.4.2 The GoogLeNet architecture.</span><a class="headerlink" href="#id239" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>GoogLeNet 使用总共 9 个初始块的堆栈，分为三组，中间有最大池化，头部有全局平均池化来生成估计。</p></li>
<li><p>初始块之间的最大池化降低了维度。</p></li>
</ul>
<p>第一个模块使用 64 通道 7x7 卷积层:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">GoogleNet</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Classifier</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">b1</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<p>第二个模块使用两个卷积层：首先是 64 通道 1x1 卷积层，然后是通道数量增加三倍的 3x3 卷积层:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">GoogleNet</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">b2</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="mi">192</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<p>第三个模块串联两个完整的Inception块:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># 第一个 Inception 块的输出通道数为:  64+128+32+32 = 256</span>
<span class="c1"># 第二个 Inception 块的输出通道数为: 128+192+96+64 = 480</span>
<span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">GoogleNet</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">b3</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">Inception</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="mi">32</span><span class="p">),</span>
                         <span class="n">Inception</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">192</span><span class="p">),</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">96</span><span class="p">),</span> <span class="mi">64</span><span class="p">),</span>
                         <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<p>第四个模块比较复杂。它串联连接了五个 Inception 块:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">GoogleNet</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">b4</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">Inception</span><span class="p">(</span><span class="mi">192</span><span class="p">,</span> <span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="mi">208</span><span class="p">),</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">48</span><span class="p">),</span> <span class="mi">64</span><span class="p">),</span>
                         <span class="n">Inception</span><span class="p">(</span><span class="mi">160</span><span class="p">,</span> <span class="p">(</span><span class="mi">112</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span> <span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="mi">64</span><span class="p">),</span>
                         <span class="n">Inception</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> <span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="mi">64</span><span class="p">),</span>
                         <span class="n">Inception</span><span class="p">(</span><span class="mi">112</span><span class="p">,</span> <span class="p">(</span><span class="mi">144</span><span class="p">,</span> <span class="mi">288</span><span class="p">),</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="mi">64</span><span class="p">),</span>
                         <span class="n">Inception</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="p">(</span><span class="mi">160</span><span class="p">,</span> <span class="mi">320</span><span class="p">),</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="mi">128</span><span class="p">),</span>
                         <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<p>第五个模块带有两个 Inception 块:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">GoogleNet</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">b5</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">Inception</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="p">(</span><span class="mi">160</span><span class="p">,</span> <span class="mi">320</span><span class="p">),</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="mi">128</span><span class="p">),</span>
                         <span class="n">Inception</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="p">(</span><span class="mi">192</span><span class="p">,</span> <span class="mi">384</span><span class="p">),</span> <span class="p">(</span><span class="mi">48</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="mi">128</span><span class="p">),</span>
                         <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
</pre></div>
</div>
<p>将它们全部组装成一个完整的网络:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">GoogleNet</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">GoogleNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b1</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">b2</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">b3</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">b4</span><span class="p">(),</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">b5</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">num_classes</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">init_cnn</span><span class="p">)</span>
</pre></div>
</div>
<p>看看各个模块之间输出形状的变化:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">GoogleNet</span><span class="p">()</span><span class="o">.</span><span class="n">layer_summary</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="mi">96</span><span class="p">))</span>
<span class="c1"># 输出</span>
<span class="n">Sequential</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>     <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">24</span><span class="p">])</span>
<span class="n">Sequential</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>     <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">192</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">])</span>
<span class="n">Sequential</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>     <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">480</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="n">Sequential</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>     <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">832</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">Sequential</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>     <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1024</span><span class="p">])</span>
<span class="n">Linear</span> <span class="n">output</span> <span class="n">shape</span><span class="p">:</span>         <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section id="id137">
<h5>8.4.3. Training<a class="headerlink" href="#id137" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">GoogleNet</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">resize</span><span class="o">=</span><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="mi">96</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">apply_init</span><span class="p">([</span><span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">get_dataloader</span><span class="p">(</span><span class="kc">True</span><span class="p">)))[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">d2l</span><span class="o">.</span><span class="n">init_cnn</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id138">
<h5>8.4.4. Discussion<a class="headerlink" href="#id138" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>GoogLeNet 的一个关键特征是，它的计算成本实际上比其前身更便宜，同时提供更高的准确性。</p></li>
<li><p>现在，您可以自豪地实现了可以说是第一个真正现代的 CNN。</p></li>
<li><dl class="simple">
<dt>优势</dt><dd><ul>
<li><p>多尺度特征提取：通过并行使用不同大小的卷积核，能够有效捕获图像的细节和全局信息。</p></li>
<li><p>参数高效：利用 1x1 卷积降维和全局平均池化，显著减少了参数量。</p></li>
<li><p>模块化设计：方便扩展和调整，适合深度学习模型的快速迭代。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
</section>
<section id="batch-normalization">
<h4>8.5. Batch Normalization<a class="headerlink" href="#batch-normalization" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>训练深度神经网络很难，特别是在收敛速度和稳定性上。</p></li>
<li><p>批量归一化通过标准化中间层的激活值，解决了激活分布漂移的问题，从而加速训练并提高模型稳定性。</p></li>
<li><p>它还有额外的正则化效果，可以减少过拟合。</p></li>
</ul>
<section id="training-deep-networks">
<h5>8.5.1. Training Deep Networks<a class="headerlink" href="#training-deep-networks" title="此标题的永久链接">¶</a></h5>
<p>批量归一化通过在每个训练步骤中对输入进行标准化，得到零均值和单位方差：</p>
<div class="math notranslate nohighlight">
\[\textrm{BN}(\mathbf{x}) = \boldsymbol{\gamma} \odot \frac{\mathbf{x} - \hat{\boldsymbol{\mu}}_\mathcal{B}}{\hat{\boldsymbol{\sigma}}_\mathcal{B}} + \boldsymbol{\beta}\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\hat{\boldsymbol{\mu}}\mathcal{B}\)</span> 和 <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\sigma}}\mathcal{B}\)</span> 是基于当前小批量计算的均值和标准差。</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{\gamma}\)</span> 和 <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span> 是需要训练的缩放和偏移参数，恢复丢失的自由度。</p></li>
<li><dl class="simple">
<dt>批量归一化具有以下优点：</dt><dd><ul>
<li><p>预处理：标准化激活值，减少梯度爆炸或消失问题。</p></li>
<li><p>数值稳定性：使优化器能使用更大的学习率。</p></li>
<li><p>正则化：引入了噪声，有效减少过拟合。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="batch-normalization-layers">
<h5>8.5.2. Batch Normalization Layers<a class="headerlink" href="#batch-normalization-layers" title="此标题的永久链接">¶</a></h5>
<section id="fully-connected-layers">
<h6>8.5.2.1. Fully Connected Layers<a class="headerlink" href="#fully-connected-layers" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>通常应用在仿射变换之后，激活函数之前：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\mathbf{h} = \phi(\textrm{BN}(\mathbf{W}\mathbf{x} + \mathbf{b}) )\]</div>
</section>
<section id="id139">
<h6>8.5.2.2. Convolutional Layers<a class="headerlink" href="#id139" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>对于卷积层，我们可以在卷积之后但非线性激活函数之前应用批量归一化。与全连接层中的批量归一化的主要区别在于，我们在所有位置的每个通道的基础上应用该操作。</p></li>
<li><dl class="simple">
<dt>对每个通道独立标准化：</dt><dd><ul>
<li><p>汇总所有空间位置的值（例如卷积输出的高度和宽度）来计算均值和方差。</p></li>
<li><p>每个通道有自己的缩放和偏移参数。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="layer-normalization">
<h6>8.5.2.3. Layer Normalization<a class="headerlink" href="#layer-normalization" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>针对小批量（甚至批量大小为1）或序列任务，层归一化对每个样本的所有特征进行标准化：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\mathbf{x} \rightarrow \textrm{LN}(\mathbf{x}) =  \frac{\mathbf{x} - \hat{\mu}}{\hat\sigma}\]</div>
<ul class="simple">
<li><p>独立于批量大小，适用于单样本场景。</p></li>
<li><p>避免了因小批量引入的不稳定性。</p></li>
</ul>
</section>
<section id="batch-normalization-during-prediction">
<h6>8.5.2.4. Batch Normalization During Prediction<a class="headerlink" href="#batch-normalization-during-prediction" title="此标题的永久链接">¶</a></h6>
</section>
</section>
<section id="id140">
<h5>8.5.3. Implementation from Scratch<a class="headerlink" href="#id140" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">batch_norm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">moving_mean</span><span class="p">,</span> <span class="n">moving_var</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">momentum</span><span class="p">):</span>
    <span class="c1"># Use is_grad_enabled to determine whether we are in training mode</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_grad_enabled</span><span class="p">():</span>
        <span class="c1"># In prediction mode, use mean and variance obtained by moving average</span>
        <span class="n">X_hat</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">moving_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">moving_var</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="c1"># When using a fully connected layer, calculate the mean and</span>
            <span class="c1"># variance on the feature dimension</span>
            <span class="n">mean</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">var</span> <span class="o">=</span> <span class="p">((</span><span class="n">X</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># When using a two-dimensional convolutional layer, calculate the</span>
            <span class="c1"># mean and variance on the channel dimension (axis=1). Here we</span>
            <span class="c1"># need to maintain the shape of X, so that the broadcasting</span>
            <span class="c1"># operation can be carried out later</span>
            <span class="n">mean</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">var</span> <span class="o">=</span> <span class="p">((</span><span class="n">X</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># In training mode, the current mean and variance are used</span>
        <span class="n">X_hat</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>
        <span class="c1"># Update the mean and variance using moving average</span>
        <span class="n">moving_mean</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">momentum</span><span class="p">)</span> <span class="o">*</span> <span class="n">moving_mean</span> <span class="o">+</span> <span class="n">momentum</span> <span class="o">*</span> <span class="n">mean</span>
        <span class="n">moving_var</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">momentum</span><span class="p">)</span> <span class="o">*</span> <span class="n">moving_var</span> <span class="o">+</span> <span class="n">momentum</span> <span class="o">*</span> <span class="n">var</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">X_hat</span> <span class="o">+</span> <span class="n">beta</span>  <span class="c1"># Scale and shift</span>
    <span class="k">return</span> <span class="n">Y</span><span class="p">,</span> <span class="n">moving_mean</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">moving_var</span><span class="o">.</span><span class="n">data</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">BatchNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="c1"># num_features: the number of outputs for a fully connected layer</span>
    <span class="c1">#       or the number of output channels for a convolutional layer.</span>
    <span class="c1"># num_dims: 2 for a fully connected layer and 4 for a convolutional layer</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_features</span><span class="p">,</span> <span class="n">num_dims</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">num_dims</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_features</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_features</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># The scale parameter and the shift parameter (model parameters) are initialized to 1 and 0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">))</span>
        <span class="c1"># The variables that are not model parameters are initialized to 0 and 1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">moving_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">moving_var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="c1"># If X is not on the main memory, copy moving_mean and moving_var to the device where X is located</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">moving_mean</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">moving_mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">moving_mean</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">moving_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">moving_var</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="c1"># Save the updated moving_mean and moving_var</span>
        <span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">moving_mean</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">moving_var</span> <span class="o">=</span> <span class="n">batch_norm</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">moving_mean</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">moving_var</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Y</span>
</pre></div>
</div>
</section>
<section id="lenet-with-batch-normalization">
<h5>8.5.4. LeNet with Batch Normalization<a class="headerlink" href="#lenet-with-batch-normalization" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">BNLeNetScratch</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Classifier</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span> <span class="n">BatchNorm</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">num_dims</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span> <span class="n">BatchNorm</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">num_dims</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="mi">120</span><span class="p">),</span>
            <span class="n">BatchNorm</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="n">num_dims</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="mi">84</span><span class="p">),</span>
            <span class="n">BatchNorm</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="n">num_dims</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">num_classes</span><span class="p">))</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">BNLeNetScratch</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">apply_init</span><span class="p">([</span><span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">get_dataloader</span><span class="p">(</span><span class="kc">True</span><span class="p">)))[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">d2l</span><span class="o">.</span><span class="n">init_cnn</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">net</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,)),</span> <span class="n">model</span><span class="o">.</span><span class="n">net</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,))</span>
</pre></div>
</div>
</section>
<section id="id141">
<h5>8.5.5. Concise Implementation<a class="headerlink" href="#id141" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">BNLeNet</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Classifier</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyBatchNorm2d</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">LazyConv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyBatchNorm2d</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="mi">120</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyBatchNorm1d</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="mi">84</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyBatchNorm1d</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">num_classes</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">BNLeNet</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">apply_init</span><span class="p">([</span><span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">get_dataloader</span><span class="p">(</span><span class="kc">True</span><span class="p">)))[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">d2l</span><span class="o">.</span><span class="n">init_cnn</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="residual-networks-resnet-and-resnext">
<h4>8.6. Residual Networks (ResNet) and ResNeXt<a class="headerlink" href="#residual-networks-resnet-and-resnext" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>残差网络 (ResNet)</p></li>
<li><p>何凯明等人2016年提出的残差网络（ResNet），该网络引入了残差块（residual block），其核心思想是让每一层除了学习到期望的底层映射外，还能更轻松地包含恒等映射作为一个元素。这解决了非常深的网络难以训练的问题，并且ResNet在2015年的ImageNet大规模视觉识别挑战赛中取得了胜利。此设计对后续深度神经网络的发展有着深远的影响。</p></li>
<li><p>残差块的工作原理：输入可以直接跳过某些层传递到后面的层，形成所谓的“残差连接”或“捷径连接”。这样做的好处是可以使网络更容易学习到恒等映射，因为当需要学习的映射为恒等映射时，网络只需将权重调整为零即可。</p></li>
</ul>
</section>
<section id="densely-connected-networks-densenet">
<h4>8.7. Densely Connected Networks (DenseNet)<a class="headerlink" href="#densely-connected-networks-densenet" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>主要讲了DenseNet（密集连接网络）相较于 ResNet 的特点、数学原理以及实现方式。</p></li>
</ul>
<section id="id142">
<h5>核心概念<a class="headerlink" href="#id142" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>密集连接模式：DenseNet 的每一层与之前所有层相连接。这种连接方式通过 <strong>特征级拼接(concatenation)</strong> 来保留和复用特征，而不是像 ResNet 中通过相加（addition）连接。</p></li>
<li><p>特征复用：每一层的输出作为后续层的输入，这样可以确保每层都能直接访问最初输入和每层中间结果，从而减少信息丢失。</p></li>
</ul>
</section>
<section id="id143">
<h5>关键组成部分<a class="headerlink" href="#id143" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt>Dense Block（密集块）：</dt><dd><ul>
<li><p>每个 Dense Block 包括多个卷积块，输入和每个卷积块的输出在通道维度上拼接。</p></li>
<li><p>生长率：每个 Dense Block 增加输出通道数的速率。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Transition Layer（过渡层）：</dt><dd><ul>
<li><p>控制模型复杂度，减少通道数并通过平均池化降低分辨率。</p></li>
<li><p>使用 <span class="math notranslate nohighlight">\(1 \times 1\)</span> 卷积减少通道数，确保通道增长不会过快。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="densenet">
<h5>DenseNet 的优点<a class="headerlink" href="#densenet" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>高效特征复用：每层的特征都直接提供给后续层，减少冗余计算。</p></li>
<li><p>更轻的模型：相比 ResNet，DenseNet 在参数量上更高效。</p></li>
<li><p>缓解梯度消失问题：密集连接模式提供了更短的梯度传播路径。</p></li>
</ul>
</section>
</section>
<section id="designing-convolution-network-architectures">
<h4>8.8. Designing Convolution Network Architectures<a class="headerlink" href="#designing-convolution-network-architectures" title="此标题的永久链接">¶</a></h4>
<figure class="align-default" id="id240">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/mcdubD.png" src="https://img.zhaoweiguo.com/uPic/2025/01/mcdubD.png" />
<figcaption>
<p><span class="caption-text">Fig. 8.8.1 The AnyNet design space.</span><a class="headerlink" href="#id240" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>The numbers <span class="math notranslate nohighlight">\((\mathit{c}, \mathit{r})\)</span> along each arrow indicate the number of channels <code class="docutils literal notranslate"><span class="pre">c</span></code> and the resolution <span class="math notranslate nohighlight">\(\mathit{r} \times \mathit{r}\)</span> of the images at that point.</p></li>
<li><dl class="simple">
<dt>From left to right: generic network structure composed of <code class="docutils literal notranslate"><span class="pre">stem</span></code> , <code class="docutils literal notranslate"><span class="pre">body</span></code> , and <code class="docutils literal notranslate"><span class="pre">head</span></code> ;</dt><dd><ul>
<li><p>body composed of four stages;</p></li>
<li><p>detailed structure of a stage;</p></li>
<li><dl class="simple">
<dt>two alternative structures for blocks,</dt><dd><ul>
<li><p>one without downsampling and one that halves the resolution in each dimension.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Design choices include</dt><dd><ul>
<li><p>depth <span class="math notranslate nohighlight">\(\mathit{d_i}\)</span> ,</p></li>
<li><p>the number of output channels <span class="math notranslate nohighlight">\(\mathit{c_i}\)</span> ,</p></li>
<li><p>the number of groups $mathit{g_i}$,</p></li>
<li><p>and bottleneck ratio $mathit{k_i}$ for any stage $mathit{i}$.](../img/anynet.svg)</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
</ul>
<section id="id144">
<h5>传统架构设计的直觉性<a class="headerlink" href="#id144" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>早期的 CNN 架构（如 AlexNet 和 VGG）依赖科学家的直觉设计。</p></li>
<li><p>常见方法包括堆叠卷积层（如 3x3 卷积）来增加深度，以提升网络性能。</p></li>
<li><p>NiN 引入了 1x1 卷积，解决了局部非线性问题，并优化了信息聚合。</p></li>
<li><p>GoogLeNet 的多分支设计（Inception 模块）结合了 VGG 和 NiN 的优点。</p></li>
<li><p>ResNet 改变了归纳偏置，通过引入残差连接使得训练更深的网络成为可能。</p></li>
<li><p>SENet 和 ResNeXt 等后续架构进一步优化了网络计算效率和参数权衡。</p></li>
</ul>
</section>
<section id="nas">
<h5>神经架构搜索(NAS)<a class="headerlink" href="#nas" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>NAS 是通过自动化方法（如遗传算法、强化学习）探索最佳网络架构。</p></li>
<li><p>虽然 NAS 能生成高性能网络（如 EfficientNets），但其计算成本极高。</p></li>
</ul>
</section>
<section id="regnet">
<h5>RegNet 与设计空间优化<a class="headerlink" href="#regnet" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>相比寻找“单一最佳网络”，探索整个网络设计空间更有价值。</p></li>
<li><p>Radosavovic 等人提出了一种结合手动设计和 NAS 优势的方法，通过优化网络分布，而非单一实例，得到了 RegNet 系列。</p></li>
<li><p>RegNet 提供了性能良好的 CNN 设计指导原则，强调在设计过程中既要科学探索，又要保证计算成本低廉。</p></li>
</ul>
</section>
<section id="anynet">
<h5>AnyNet 设计空间<a class="headerlink" href="#anynet" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>AnyNet 是一个通用的设计模板，由“stem”（初始处理）、“body”（核心计算）和“head”（输出层）组成。</p></li>
<li><p>设计的核心在于“body”，它通过多个阶段和模块（如 ResNeXt 块）逐步提取特征。</p></li>
<li><p>为了有效探索设计空间，需要调整诸多参数（如通道数、深度、分组数等）并优化它们的组合。</p></li>
</ul>
</section>
<section id="id145">
<h5>分布优化与假设<a class="headerlink" href="#id145" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>网络性能优化的目标从寻找单一最佳参数，转为寻找“好的参数分布”。</p></li>
<li><dl class="simple">
<dt>假设包括：</dt><dd><ul>
<li><p>好的设计原则存在，并适用于多个网络。</p></li>
<li><p>不需要完全训练网络，早期性能可以提供指导。</p></li>
<li><p>小规模实验结果可以推广到大规模网络。</p></li>
<li><p>设计问题可以分解成相对独立的模块。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
</section>
</section>
<section id="recurrent-neural-networks">
<h3>9. Recurrent Neural Networks<a class="headerlink" href="#recurrent-neural-networks" title="此标题的永久链接">¶</a></h3>
<figure class="align-default" id="id241">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/2Rj2To.png" src="https://img.zhaoweiguo.com/uPic/2025/01/2Rj2To.png" />
<figcaption>
<p><span class="caption-text">Fig. 9.1 On the left recurrent connections are depicted via cyclic edges. On the right, we unfold the RNN over time steps. Here, recurrent edges span adjacent time steps, while conventional connections are computed synchronously.</span><a class="headerlink" href="#id241" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>RNN 在 2010 年代开始流行（Graves 等人，2008 年） ）、机器翻译（Sutskever 等人，2014）以及识别医疗诊断（Lipton 等人，2016）。</p></li>
</ul>
<section id="working-with-sequences">
<h4>9.1. Working with Sequences<a class="headerlink" href="#working-with-sequences" title="此标题的永久链接">¶</a></h4>
<section id="id146">
<h5>1. 序列数据的特点<a class="headerlink" href="#id146" title="此标题的永久链接">¶</a></h5>
<ul>
<li><p>传统单输入模型：之前我们讨论的模型输入是单一特征向量 <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathbb{R}^d\)</span> 。</p></li>
<li><p>序列输入的区别：序列输入由一组按时间顺序排列的特征向量 <span class="math notranslate nohighlight">\(\mathbf{x}_1, \dots, \mathbf{x}_T\)</span> 组成，每个特征向量 <span class="math notranslate nohighlight">\(\mathbf{x}_t\)</span> 有时间步(time step) t 的索引。</p></li>
<li><p>序列数据的例子包括：</p>
<blockquote>
<div><ul class="simple">
<li><p>文档序列：每个文档是一组单词序列。</p></li>
<li><p>医院患者数据：一个住院过程由一系列事件组成。</p></li>
<li><p>股票价格序列：按时间记录的股价数据。</p></li>
</ul>
</div></blockquote>
</li>
<li><p>在序列数据中，相邻时间步的数据通常存在依赖关系（如单词之间的上下文关系或患者治疗方案的时间顺序），而不是独立采样的。</p></li>
</ul>
</section>
<section id="id147">
<h5>2. 序列建模的目标<a class="headerlink" href="#id147" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>预测固定目标：如根据影评文本判断情感（正向或负向）。</p></li>
<li><p>预测序列目标：如根据图片生成描述文本。</p></li>
<li><p>序列到序列建模：如机器翻译，将一个语言的句子转换为另一语言。</p></li>
</ul>
</section>
<section id="id148">
<h5>3. 序列建模的基本方法<a class="headerlink" href="#id148" title="此标题的永久链接">¶</a></h5>
<section id="autoregressive-models">
<h6>9.1.1. Autoregressive Models<a class="headerlink" href="#autoregressive-models" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>目标：通过历史数据 <span class="math notranslate nohighlight">\(\mathbf{x}_{t-1}, \dots, \mathbf{x}_1\)</span> 预测下一个时间步的数据 <span class="math notranslate nohighlight">\(\mathbf{x}_t\)</span></p></li>
<li><p>问题：历史数据的长度随着时间增长，输入特征的数量也随之越来越长。</p></li>
<li><dl class="simple">
<dt>解决方法：</dt><dd><ul>
<li><p>限制窗口大小：仅考虑固定长度窗口 <span class="math notranslate nohighlight">\(\tau\)</span> 的历史数据，如 <span class="math notranslate nohighlight">\(\mathbf{x}{t-1}, \dots, \mathbf{x}{t-\tau}\)</span> 。</p></li>
<li><p>隐变量表示：用一个隐藏状态 <span class="math notranslate nohighlight">\(h_t\)</span> 总结历史信息，并通过更新公式 <span class="math notranslate nohighlight">\(h_t = g(h_{t-1}, x_{t-1})\)</span> 动态维护。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="sequence-models-markov-models">
<h6>9.1.2. Sequence Models(Markov Models)<a class="headerlink" href="#sequence-models-markov-models" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>如果可以仅依赖最近的 <span class="math notranslate nohighlight">\(\tau\)</span> 个时间步的信息预测未来，则满足马尔科夫条件。</p></li>
<li><p>一阶马尔科夫模型：只考虑最近的一个时间步 <span class="math notranslate nohighlight">\(x_{t-1}\)</span> ，预测 <span class="math notranslate nohighlight">\(P(x_t \mid x_{t-1})\)</span></p></li>
<li><p>虽然实际数据可能不完全符合马尔科夫条件，但在实际应用中，这种近似简化了计算。</p></li>
</ul>
</section>
</section>
<section id="id149">
<h5>4. 语言模型与序列模型<a class="headerlink" href="#id149" title="此标题的永久链接">¶</a></h5>
<section id="language-model">
<h6>语言模型 (Language Model)<a class="headerlink" href="#language-model" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>用于估计整个序列（如句子）的联合概率 <span class="math notranslate nohighlight">\(P(x_1, \dots, x_T)\)</span></p></li>
<li><p>利用链式法则，将联合概率分解为条件概率的乘积：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[P(x_1, \ldots, x_T) = P(x_1) \prod_{t=2}^T P(x_t \mid x_{t-1}, \ldots, x_1)\]</div>
<ul class="simple">
<li><p>语言模型可用于自然语言生成、语音识别、机器翻译等任务。</p></li>
</ul>
</section>
<section id="id150">
<h6>解码顺序<a class="headerlink" href="#id150" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>一般从左到右建模（与阅读习惯一致），因为预测相邻单词更容易。</p></li>
<li><p>未来事件可能影响后续结果，但不会影响过去。</p></li>
</ul>
</section>
</section>
</section>
<section id="id151">
<h4>5. 实际应用<a class="headerlink" href="#id151" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>股票价格预测：如通过历史股价数据预测下一时刻价格。</p></li>
<li><p>患者病程建模：根据前几天的治疗方案，预测第十天的用药。</p></li>
<li><p>文本生成与补全：基于已知前缀，预测可能的后续文本。</p></li>
</ul>
</section>
<section id="converting-raw-text-into-sequence-data">
<h4>9.2. Converting Raw Text into Sequence Data<a class="headerlink" href="#converting-raw-text-into-sequence-data" title="此标题的永久链接">¶</a></h4>
<p>Typical preprocessing pipelines execute the following steps:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">1.</span> <span class="n">Load</span> <span class="n">text</span> <span class="k">as</span> <span class="n">strings</span> <span class="n">into</span> <span class="n">memory</span><span class="o">.</span>
<span class="mf">2.</span> <span class="n">Split</span> <span class="n">the</span> <span class="n">strings</span> <span class="n">into</span> <span class="n">tokens</span> <span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">g</span><span class="o">.</span><span class="p">,</span> <span class="n">words</span> <span class="ow">or</span> <span class="n">characters</span><span class="p">)</span><span class="o">.</span>
<span class="mf">3.</span> <span class="n">Build</span> <span class="n">a</span> <span class="n">vocabulary</span> <span class="n">dictionary</span> <span class="n">to</span> <span class="n">associate</span> <span class="n">each</span> <span class="n">vocabulary</span> <span class="n">element</span> <span class="k">with</span> <span class="n">a</span> <span class="n">numerical</span> <span class="n">index</span><span class="o">.</span>
<span class="mf">4.</span> <span class="n">Convert</span> <span class="n">the</span> <span class="n">text</span> <span class="n">into</span> <span class="n">sequences</span> <span class="n">of</span> <span class="n">numerical</span> <span class="n">indices</span><span class="o">.</span>
</pre></div>
</div>
<section id="reading-the-dataset">
<h5>9.2.1. Reading the Dataset<a class="headerlink" href="#reading-the-dataset" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">TimeMachine</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">DataModule</span><span class="p">):</span> <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The Time Machine dataset.&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_download</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">fname</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">DATA_URL</span> <span class="o">+</span> <span class="s1">&#39;timemachine.txt&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">,</span>
                             <span class="s1">&#39;090b5e7e70c295757f55df93cb0a180b9691891a&#39;</span><span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">TimeMachine</span><span class="p">()</span>
<span class="n">raw_text</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">_download</span><span class="p">()</span>
<span class="n">raw_text</span><span class="p">[:</span><span class="mi">60</span><span class="p">]</span>

<span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">TimeMachine</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;[^A-Za-z]+&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

<span class="n">text</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">_preprocess</span><span class="p">(</span><span class="n">raw_text</span><span class="p">)</span>
<span class="n">text</span><span class="p">[:</span><span class="mi">60</span><span class="p">]</span>
<span class="c1"># 输出</span>
<span class="c1"># &#39;the time machine by h g wells i the time traveller for so it&#39;</span>
</pre></div>
</div>
</section>
<section id="tokenization">
<h5>9.2.2. Tokenization<a class="headerlink" href="#tokenization" title="此标题的永久链接">¶</a></h5>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">TimeMachine</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

<span class="n">tokens</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">[:</span><span class="mi">30</span><span class="p">])</span>
<span class="c1"># 输出</span>
<span class="c1"># &#39;t,h,e, ,t,i,m,e, ,m,a,c,h,i,n,e, ,b,y, ,h, ,g, ,w,e,l,l,s, &#39;</span>
</pre></div>
</div>
</section>
<section id="vocabulary">
<h5>9.2.3. Vocabulary<a class="headerlink" href="#vocabulary" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Vocab</span><span class="p">:</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Vocabulary for text.&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="o">=</span><span class="p">[],</span> <span class="n">min_freq</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">reserved_tokens</span><span class="o">=</span><span class="p">[]):</span>
        <span class="c1"># Flatten a 2D list if needed</span>
        <span class="k">if</span> <span class="n">tokens</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">line</span><span class="p">]</span>
        <span class="c1"># Count token frequencies</span>
        <span class="n">counter</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">Counter</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token_freqs</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">counter</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                  <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># The list of unique tokens</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">idx_to_token</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">([</span><span class="s1">&#39;&lt;unk&gt;&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">reserved_tokens</span> <span class="o">+</span> <span class="p">[</span>
            <span class="n">token</span> <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">freq</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_freqs</span> <span class="k">if</span> <span class="n">freq</span> <span class="o">&gt;=</span> <span class="n">min_freq</span><span class="p">])))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token_to_idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">token</span><span class="p">:</span> <span class="n">idx</span>
                             <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">idx_to_token</span><span class="p">)}</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">idx_to_token</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_to_idx</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">unk</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="fm">__getitem__</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">to_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="s1">&#39;__len__&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">idx_to_token</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">index</span><span class="p">)]</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx_to_token</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">unk</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>  <span class="c1"># Index for the unknown token</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_to_idx</span><span class="p">[</span><span class="s1">&#39;&lt;unk&gt;&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>使用:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">vocab</span> <span class="o">=</span> <span class="n">Vocab</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">vocab</span><span class="p">[</span><span class="n">tokens</span><span class="p">[:</span><span class="mi">10</span><span class="p">]]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;indices:&#39;</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;words:&#39;</span><span class="p">,</span> <span class="n">vocab</span><span class="o">.</span><span class="n">to_tokens</span><span class="p">(</span><span class="n">indices</span><span class="p">))</span>
<span class="c1"># 输出</span>
<span class="c1">#    indices: [21, 9, 6, 0, 21, 10, 14, 6, 0, 14]</span>
<span class="c1">#    words: [&#39;t&#39;, &#39;h&#39;, &#39;e&#39;, &#39; &#39;, &#39;t&#39;, &#39;i&#39;, &#39;m&#39;, &#39;e&#39;, &#39; &#39;, &#39;m&#39;]</span>
</pre></div>
</div>
</section>
<section id="putting-it-all-together">
<h5>9.2.4. Putting It All Together<a class="headerlink" href="#putting-it-all-together" title="此标题的永久链接">¶</a></h5>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">TimeMachine</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">raw_text</span><span class="p">,</span> <span class="n">vocab</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_preprocess</span><span class="p">(</span><span class="n">raw_text</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">vocab</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">vocab</span> <span class="o">=</span> <span class="n">Vocab</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
    <span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">vocab</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">corpus</span><span class="p">,</span> <span class="n">vocab</span>

<span class="n">corpus</span><span class="p">,</span> <span class="n">vocab</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">raw_text</span><span class="p">)</span>
<span class="nb">len</span><span class="p">(</span><span class="n">corpus</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>
<span class="c1"># (173428, 28)</span>
</pre></div>
</div>
</section>
<section id="exploratory-language-statistics">
<h5>9.2.5. Exploratory Language Statistics<a class="headerlink" href="#exploratory-language-statistics" title="此标题的永久链接">¶</a></h5>
<p>使用真实的语料库和针对单词定义的 Vocab 类:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">words</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="n">Vocab</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
<span class="n">vocab</span><span class="o">.</span><span class="n">token_freqs</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
<span class="c1"># 输出</span>
<span class="p">[(</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="mi">2261</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;i&#39;</span><span class="p">,</span> <span class="mi">1267</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;and&#39;</span><span class="p">,</span> <span class="mi">1245</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;of&#39;</span><span class="p">,</span> <span class="mi">1155</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="mi">816</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="mi">695</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;was&#39;</span><span class="p">,</span> <span class="mi">552</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;in&#39;</span><span class="p">,</span> <span class="mi">541</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;that&#39;</span><span class="p">,</span> <span class="mi">443</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;my&#39;</span><span class="p">,</span> <span class="mi">440</span><span class="p">)]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bigram_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;--&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pair</span><span class="p">)</span> <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">words</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">words</span><span class="p">[</span><span class="mi">1</span><span class="p">:])]</span>
<span class="n">bigram_vocab</span> <span class="o">=</span> <span class="n">Vocab</span><span class="p">(</span><span class="n">bigram_tokens</span><span class="p">)</span>
<span class="n">bigram_vocab</span><span class="o">.</span><span class="n">token_freqs</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
<span class="c1"># 输出</span>
<span class="p">[(</span><span class="s1">&#39;of--the&#39;</span><span class="p">,</span> <span class="mi">309</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;in--the&#39;</span><span class="p">,</span> <span class="mi">169</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;i--had&#39;</span><span class="p">,</span> <span class="mi">130</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;i--was&#39;</span><span class="p">,</span> <span class="mi">112</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;and--the&#39;</span><span class="p">,</span> <span class="mi">109</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;the--time&#39;</span><span class="p">,</span> <span class="mi">102</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;it--was&#39;</span><span class="p">,</span> <span class="mi">99</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;to--the&#39;</span><span class="p">,</span> <span class="mi">85</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;as--i&#39;</span><span class="p">,</span> <span class="mi">78</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;of--a&#39;</span><span class="p">,</span> <span class="mi">73</span><span class="p">)]</span>
</pre></div>
</div>
</section>
<section id="id152">
<h5>9.2.6. Summary<a class="headerlink" href="#id152" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>文本是深度学习中最常见的序列数据形式之一。</p></li>
<li><p>构成标记的常见选择是字符、单词和单词片段。</p></li>
<li><dl class="simple">
<dt>为了预处理文本，我们通常</dt><dd><ul>
<li><ol class="lowerroman simple">
<li><p>将文本拆分为标记；</p></li>
</ol>
</li>
<li><ol class="lowerroman simple" start="2">
<li><p>构建词汇表以将标记字符串映射到数字索引；</p></li>
</ol>
</li>
<li><ol class="lowerroman simple" start="3">
<li><p>将文本数据转换为标记索引以供模型操作。</p></li>
</ol>
</li>
</ul>
</dd>
</dl>
</li>
<li><p>在实践中，单词的频率往往遵循齐普夫定律。这不仅适用于单个单词（一元语法），也适用于 n-gram</p></li>
</ul>
</section>
</section>
<section id="language-models">
<h4>9.3. Language Models<a class="headerlink" href="#language-models" title="此标题的永久链接">¶</a></h4>
<section id="learning-language-models">
<h5>9.3.1. Learning Language Models<a class="headerlink" href="#learning-language-models" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>语言模型的基础公式</p></li>
</ul>
<div class="math notranslate nohighlight">
\[P(x_1, x_2, \ldots, x_T) = \prod_{t=1}^T P(x_t  \mid  x_1, \ldots, x_{t-1})\]</div>
<p>例如，包含四个单词的文本序列的概率(联合概率)如下：</p>
<div class="math notranslate nohighlight">
\[\begin{split}P(\textrm{deep}, \textrm{learning}, \textrm{is}, \textrm{fun}) \\
=&amp;P(\textrm{deep}) P(\textrm{learning}  \mid  \textrm{deep}) P(\textrm{is}  \mid  \textrm{deep}, \textrm{learning}) P(\textrm{fun}  \mid  \textrm{deep}, \textrm{learning}, \textrm{is})\end{split}\]</div>
<section id="markov-models-and-n-grams">
<h6>9.3.1.1. Markov Models and n-grams<a class="headerlink" href="#markov-models-and-n-grams" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><dl class="simple">
<dt>为了简化计算，语言模型通常假设序列满足马尔可夫性质，即只考虑有限长度的上下文：</dt><dd><ul>
<li><p>Unigram（单词独立）: <span class="math notranslate nohighlight">\(P(x_1, x_2, x_3, x_4) = P(x_1)P(x_2)P(x_3)P(x_4)\)</span></p></li>
<li><p>Bigram（二元组）: <span class="math notranslate nohighlight">\(P(x_4 \mid x_3)\)</span></p></li>
<li><p>Trigram（三元组）: <span class="math notranslate nohighlight">\(P(x_4 \mid x_2, x_3)\)</span></p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="word-frequency">
<h6>9.3.1.2. Word Frequency<a class="headerlink" href="#word-frequency" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>在大规模语料库（如Wikipedia或Project Gutenberg）中，词的概率可以通过频率计算：</p></li>
<li><p><span class="math notranslate nohighlight">\(P(\textrm{deep})\)</span> ：文本中单词“deep”的出现次数占比。</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\hat{P}(\textrm{learning} \mid \textrm{deep}) = \frac{n(\textrm{deep, learning})}{n(\textrm{deep})}\]</div>
</section>
<section id="laplace-smoothing">
<h6>9.3.1.3. Laplace Smoothing<a class="headerlink" href="#laplace-smoothing" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>拉普拉斯平滑</p></li>
<li><dl class="simple">
<dt>为了解决低频或未见词组的问题，使用平滑方法在计数中加入小常数 <span class="math notranslate nohighlight">\(\epsilon\)</span> ：</dt><dd><ul>
<li><p>单词概率： <span class="math notranslate nohighlight">\(\hat{P}(x) = \frac{n(x) + \epsilon/m}{n + \epsilon}\)</span></p></li>
<li><p>二元组概率： <span class="math notranslate nohighlight">\(\hat{P}(x' \mid x) = \frac{n(x, x') + \epsilon}{n(x) + \epsilon}\)</span></p></li>
</ul>
</dd>
</dl>
</li>
<li><p>尽管平滑方法有效，它依然有局限性，例如高阶组合的稀疏性和存储成本问题。</p></li>
</ul>
</section>
</section>
<section id="perplexity">
<h5>9.3.2. Perplexity<a class="headerlink" href="#perplexity" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>困惑度衡量语言模型对文本预测的好坏：</p></li>
<li><p>定义为交叉熵的指数形式：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[Perplexity = \exp\left(-\frac{1}{n} \sum_{t=1}^n \log P(x_t \mid x_{t-1}, \ldots, x_1)\right)\]</div>
<ul class="simple">
<li><dl class="simple">
<dt>理解：</dt><dd><ul>
<li><p>最优模型：困惑度=1（完美预测）。</p></li>
<li><p>随机模型：困惑度接近词汇表大小。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="partitioning-sequences">
<h5>9.3.3. Partitioning Sequences<a class="headerlink" href="#partitioning-sequences" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>训练语言模型时，将长序列分割成多个子序列，并将输入与目标错开一位。</p></li>
<li><dl class="simple">
<dt>例如：</dt><dd><ul>
<li><p>输入： <span class="math notranslate nohighlight">\([x_1, x_2, x_3, x_4, x_5]\)</span></p></li>
<li><p>目标： <span class="math notranslate nohighlight">\([x_2, x_3, x_4, x_5, x_6]\)</span></p></li>
</ul>
</dd>
</dl>
</li>
<li><p>这种分区方式使模型能够学习预测下一个词的能力。</p></li>
</ul>
</section>
</section>
<section id="id153">
<h4>9.4. Recurrent Neural Networks<a class="headerlink" href="#id153" title="此标题的永久链接">¶</a></h4>
<section id="id154">
<h5>1. 语言模型的局限性与改进<a class="headerlink" href="#id154" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt>传统的 n元(n-grams)模型假设一个时间步 t 的词 <span class="math notranslate nohighlight">\(x_t\)</span> 只依赖于前 n-1 个词。</dt><dd><ul>
<li><p>缺点：如果要捕捉更长的上下文信息，需要增加 n ，但这样参数数量会指数级增长（ <span class="math notranslate nohighlight">\(|\mathcal{V}|^n\)</span> ， <span class="math notranslate nohighlight">\(\mathcal{V}\)</span> 是词汇表）。</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>解决方案：引入隐变量模型，用一个“隐藏状态” h_{t-1} 来存储从 t-1 之前的序列信息：</p></li>
</ul>
</section>
<section id="id155">
<h5>2. 隐藏状态的定义与作用<a class="headerlink" href="#id155" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>隐藏状态（hidden state）： <span class="math notranslate nohighlight">\(h_t\)</span> 根据当前输入 <span class="math notranslate nohighlight">\(x_t\)</span> 和前一个隐藏状态 <span class="math notranslate nohighlight">\(h_{t-1}\)</span> 计算得出：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[H_t = f(X_t, h_{t-1})\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(h_t\)</span> 可以视为一个“记忆单元”，它记录了从序列开始到当前时间步 t 的历史信息。</p></li>
<li><p>好处：相比 n-grams 模型，隐藏状态允许我们在参数不随时间步增加的情况下捕获长程依赖。</p></li>
</ul>
<figure class="align-default" id="id242">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/TGFa1e.png" src="https://img.zhaoweiguo.com/uPic/2025/01/TGFa1e.png" />
<figcaption>
<p><span class="caption-text">Fig. 9.4.1 An RNN with a hidden state.</span><a class="headerlink" href="#id242" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
</section>
<section id="rnn">
<h5>3. RNN的计算逻辑<a class="headerlink" href="#rnn" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><ol class="loweralpha simple">
<li><p>RNN的隐藏层输出（即隐藏状态）公式：</p></li>
</ol>
</li>
</ul>
<div class="math notranslate nohighlight">
\[\mathbf{H}_t = \phi(\mathbf{X}_t \mathbf{W}_{\textrm{xh}} + \mathbf{H}_{t-1} \mathbf{W}_{\textrm{hh}}  + \mathbf{b}_\textrm{h})\]</div>
<ul class="simple">
<li><dl class="simple">
<dt>其中</dt><dd><ul>
<li><p><span class="math notranslate nohighlight">\(\mathbf{X}_t\)</span> ：当前时间步的输入。</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{H}_{t-1}\)</span> ：前一个时间步的隐藏状态。</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{W}{\text{xh}}, \mathbf{W}{\text{hh}}\)</span> ：权重矩阵，分别用于处理输入和隐藏状态。</p></li>
<li><p><span class="math notranslate nohighlight">\(\phi\)</span> ：激活函数（例如ReLU或tanh）。</p></li>
</ul>
</dd>
</dl>
</li>
<li><ol class="loweralpha simple" start="2">
<li><p>输出层的计算：</p></li>
</ol>
</li>
</ul>
<div class="math notranslate nohighlight">
\[\mathbf{O}_t = \mathbf{H}_t \mathbf{W}_{\textrm{hq}} + \mathbf{b}_\textrm{q}\]</div>
<ul class="simple">
<li><dl class="simple">
<dt>c.特点：</dt><dd><ul>
<li><p>隐藏状态的计算是递归的（recurrent）。</p></li>
<li><p>参数( <span class="math notranslate nohighlight">\(\mathbf{W}\)</span> 和 <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> )在所有时间步之间共享，参数数量与时间步数无关。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="rnnmlp">
<h5>4. RNN与MLP的区别<a class="headerlink" href="#rnnmlp" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt>MLP（多层感知机）：</dt><dd><ul>
<li><p>每个输入样本独立处理，不考虑时间步之间的关联。</p></li>
<li><p>隐藏层的输出公式： <span class="math notranslate nohighlight">\(𝐻=𝜙(𝑋𝑊_{xh}+𝑏_h)\)</span></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>RNN：</dt><dd><ul>
<li><p>利用隐藏状态捕获时间步之间的依赖关系。</p></li>
<li><p>隐藏状态递归计算，具备“记忆”能力。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="id156">
<h5>5. RNN的应用<a class="headerlink" href="#id156" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt>字符级语言模型（character-level language model）：</dt><dd><ul>
<li><p>输入序列（如“machin”）的每个字符作为一个时间步的输入。</p></li>
<li><p>输出序列是预测的下一个字符（如“achine”）。</p></li>
<li><p>RNN通过隐藏状态捕捉历史上下文信息，并逐步预测下一个字符。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<figure class="align-default" id="id243">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/TJg72T.png" src="https://img.zhaoweiguo.com/uPic/2025/01/TJg72T.png" />
<figcaption>
<p><span class="caption-text">Fig. 9.4.2 A character-level language model based on the RNN. The input and target sequences are “machin” and “achine”, respectively.</span><a class="headerlink" href="#id243" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
</section>
<section id="id157">
<h5>6. RNN的优点与局限<a class="headerlink" href="#id157" title="此标题的永久链接">¶</a></h5>
<p>优点:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>捕获序列数据的依赖关系。
参数共享，适合处理长序列。
</pre></div>
</div>
<p>局限:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>可能存在梯度消失或梯度爆炸问题，特别是处理长序列时。
为此，通常会改进为LSTM或GRU等变种模型。
</pre></div>
</div>
</section>
<section id="id158">
<h5>总结<a class="headerlink" href="#id158" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>RNN是一种能够捕获序列信息的神经网络，通过递归计算隐藏状态，实现了对时间序列数据的有效建模。</p></li>
<li><p>它的关键思想在于共享模型参数并利用隐藏状态记录序列历史信息，在语言模型等任务中具有广泛的应用。</p></li>
</ul>
</section>
</section>
<section id="recurrent-neural-network-implementation-from-scratch">
<h4>9.5. Recurrent Neural Network Implementation from Scratch<a class="headerlink" href="#recurrent-neural-network-implementation-from-scratch" title="此标题的永久链接">¶</a></h4>
<section id="rnn-model">
<h5>9.5.1. RNN Model<a class="headerlink" href="#rnn-model" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">RNNScratch</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The RNN model implemented from scratch.&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_xh</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span> <span class="o">*</span> <span class="n">sigma</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_hh</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span> <span class="o">*</span> <span class="n">sigma</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b_h</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">))</span>

<span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">RNNScratch</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">state</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Initial state with shape: (batch_size, num_hiddens)</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">),</span>
                          <span class="n">device</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">state</span><span class="p">,</span> <span class="o">=</span> <span class="n">state</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">X</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>  <span class="c1"># Shape of inputs: (num_steps, batch_size, num_inputs)</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_xh</span><span class="p">)</span> <span class="o">+</span>
                         <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_hh</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_h</span><span class="p">)</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">state</span>
</pre></div>
</div>
<p>应用:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">100</span>
<span class="n">rnn</span> <span class="o">=</span> <span class="n">RNNScratch</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">num_steps</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">))</span>
<span class="n">outputs</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">rnn</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">check_len</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Check the length of a list.&quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">==</span> <span class="n">n</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;list</span><span class="se">\&#39;</span><span class="s1">s length </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">)</span><span class="si">}</span><span class="s1"> != expected length </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s1">&#39;</span>

<span class="k">def</span><span class="w"> </span><span class="nf">check_shape</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Check the shape of a tensor.&quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">shape</span><span class="p">,</span> \
            <span class="sa">f</span><span class="s1">&#39;tensor</span><span class="se">\&#39;</span><span class="s1">s shape </span><span class="si">{</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1"> != expected shape </span><span class="si">{</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span>

<span class="n">check_len</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>
<span class="n">check_shape</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">))</span>
<span class="n">check_shape</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="rnn-based-language-model">
<h5>9.5.2. RNN-Based Language Model<a class="headerlink" href="#rnn-based-language-model" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">RNNLMScratch</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Classifier</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The RNN-based language model implemented from scratch.&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rnn</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_params</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">init_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_hq</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">sigma</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b_q</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="n">l</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">(</span><span class="o">*</span><span class="n">batch</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">batch</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="s1">&#39;ppl&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">l</span><span class="p">),</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">l</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="n">l</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">(</span><span class="o">*</span><span class="n">batch</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">batch</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="s1">&#39;ppl&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">l</span><span class="p">),</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<section id="one-hot-encoding">
<h6>9.5.2.1. One-Hot Encoding<a class="headerlink" href="#one-hot-encoding" title="此标题的永久链接">¶</a></h6>
<p>示例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">F</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="mi">5</span><span class="p">)</span>
<span class="c1"># 输出</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">RNNLMScratch</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">one_hot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="c1"># Output shape: (num_steps, batch_size, vocab_size)</span>
    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="transforming-rnn-outputs">
<h6>9.5.2.2. Transforming RNN Outputs<a class="headerlink" href="#transforming-rnn-outputs" title="此标题的永久链接">¶</a></h6>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">RNNLMScratch</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">output_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rnn_outputs</span><span class="p">):</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_hq</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_q</span> <span class="k">for</span> <span class="n">H</span> <span class="ow">in</span> <span class="n">rnn_outputs</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">RNNLMScratch</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">rnn_outputs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">embs</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="p">(</span><span class="n">rnn_outputs</span><span class="p">)</span>
</pre></div>
</div>
<p>检查前向计算是否产生具有正确形状的输出:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">RNNLMScratch</span><span class="p">(</span><span class="n">rnn</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span>
<span class="n">check_shape</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">))</span>
</pre></div>
</div>
</section>
</section>
<section id="gradient-clipping">
<h5>9.5.3. Gradient Clipping<a class="headerlink" href="#gradient-clipping" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>梯度截断（gradient clipping）</p></li>
<li><p>【序列长度与深度】神经网络之所以被称为“深”网络，是因为它们通常有许多层从输入到输出的传递。而在RNN中，由于处理的是时间序列数据，序列的长度引入了一种新的“深度”概念。具体来说，RNN不仅仅是处理输入到输出的网络，它还需要在时间维度上跨越多个时间步长，因此在一个输入序列的前期时间步上的信息必须通过每一个时间步的“层”逐步传递，以影响最终的输出。</p></li>
<li><p>【反向传播中的时间维度】在反向传播过程中，梯度是通过时间反向传播的，也就是说，不仅是网络的层之间传递信息，还涉及每个时间步之间的传播。随着时间步数的增加，反向传播需要通过的矩阵乘法链条长度为 T（时间步长），这使得梯度的计算变得更复杂，可能导致数值不稳定。</p></li>
<li><p>【梯度剪切（Gradient Clipping）】为了解决梯度爆炸问题，一种常用的“hack”是梯度剪切。梯度剪切通过对梯度进行限制，确保它们的范数不会超过一个设定的最大值 <span class="math notranslate nohighlight">\(\theta\)</span> 。这样做的好处是即使梯度在某些时间步长上突然变大，也不会对训练造成严重影响。</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Trainer</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">clip_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">grad_clip_val</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">]</span>
    <span class="n">norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">params</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">norm</span> <span class="o">&gt;</span> <span class="n">grad_clip_val</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
            <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="p">[:]</span> <span class="o">*=</span> <span class="n">grad_clip_val</span> <span class="o">/</span> <span class="n">norm</span>
</pre></div>
</div>
</section>
<section id="id159">
<h5>9.5.4. Training<a class="headerlink" href="#id159" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">TimeMachine</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">rnn</span> <span class="o">=</span> <span class="n">RNNScratch</span><span class="p">(</span><span class="n">num_inputs</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">vocab</span><span class="p">),</span> <span class="n">num_hiddens</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">RNNLMScratch</span><span class="p">(</span><span class="n">rnn</span><span class="p">,</span> <span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">vocab</span><span class="p">),</span> <span class="n">lr</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">gradient_clip_val</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="decoding">
<h5>9.5.5. Decoding<a class="headerlink" href="#decoding" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">RNNLMScratch</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prefix</span><span class="p">,</span> <span class="n">num_preds</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">state</span><span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="p">[</span><span class="n">vocab</span><span class="p">[</span><span class="n">prefix</span><span class="p">[</span><span class="mi">0</span><span class="p">]]]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">prefix</span><span class="p">)</span> <span class="o">+</span> <span class="n">num_preds</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="n">outputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="n">embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">rnn_outputs</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">embs</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">prefix</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Warm-up period</span>
            <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vocab</span><span class="p">[</span><span class="n">prefix</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]])</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># Predict num_preds steps</span>
            <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="p">(</span><span class="n">rnn_outputs</span><span class="p">)</span>
            <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">)))</span>
    <span class="k">return</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">vocab</span><span class="o">.</span><span class="n">idx_to_token</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="s1">&#39;it has&#39;</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">vocab</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">())</span>
<span class="c1"># 输出</span>
<span class="s1">&#39;it has in the the the the &#39;</span>
</pre></div>
</div>
</section>
</section>
<section id="concise-implementation-of-recurrent-neural-networks">
<h4>9.6. Concise Implementation of Recurrent Neural Networks<a class="headerlink" href="#concise-implementation-of-recurrent-neural-networks" title="此标题的永久链接">¶</a></h4>
<section id="id160">
<h5>9.6.1. Defining the Model<a class="headerlink" href="#id160" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">RNN</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The RNN model implemented with high-level APIs.&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">H</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>

<span class="k">class</span><span class="w"> </span><span class="nc">RNNLM</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">RNNLMScratch</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The RNN-based language model implemented with high-level APIs.&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">init_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">output_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hiddens</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">hiddens</span><span class="p">)</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="training-and-predicting">
<h5>9.6.2. Training and Predicting<a class="headerlink" href="#training-and-predicting" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">TimeMachine</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">rnn</span> <span class="o">=</span> <span class="n">RNN</span><span class="p">(</span><span class="n">num_inputs</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">vocab</span><span class="p">),</span> <span class="n">num_hiddens</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">RNNLM</span><span class="p">(</span><span class="n">rnn</span><span class="p">,</span> <span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">vocab</span><span class="p">),</span> <span class="n">lr</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="s1">&#39;it has&#39;</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>
<span class="c1"># 输出</span>
<span class="s1">&#39;it hasoadd dd dd dd dd dd &#39;</span>
</pre></div>
</div>
<p>训练:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">gradient_clip_val</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<p>训练后推理:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="s1">&#39;it has&#39;</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">vocab</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">())</span>
</pre></div>
</div>
</section>
</section>
<section id="backpropagation-through-time">
<h4>9.7. Backpropagation Through Time<a class="headerlink" href="#backpropagation-through-time" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>时间反向传播（Backpropagation Through Time, BPTT）</p></li>
</ul>
<section id="id161">
<h5>应对梯度问题的方法<a class="headerlink" href="#id161" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt>全计算（Full Computation）：完整计算所有时间步的梯度。</dt><dd><ul>
<li><dl class="simple">
<dt>缺点：</dt><dd><ul>
<li><p>计算代价高。</p></li>
<li><p>容易受到梯度爆炸和数值不稳定的影响。</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>实际上很少使用。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>时间步截断（Truncating Time Steps）：只计算最近 <span class="math notranslate nohighlight">\(\tau\)</span> 个时间步的梯度，忽略更早的时间步。</dt><dd><ul>
<li><dl class="simple">
<dt>优点：</dt><dd><ul>
<li><p>简化计算，避免梯度爆炸。</p></li>
<li><p>偏向短期依赖，有一定正则化效果。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>缺点：</dt><dd><ul>
<li><p>可能丢失长期依赖的信息。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>随机截断（Randomized Truncation）：用随机变量替代部分梯度计算，以截断序列长度。</dt><dd><ul>
<li><dl class="simple">
<dt>优点：</dt><dd><ul>
<li><p>截断位置随机化，可能提升训练的泛化能力。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>缺点：</dt><dd><ul>
<li><p>增加梯度估计的方差，实际效果不显著。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="id162">
<h5>数学分析<a class="headerlink" href="#id162" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt>每个时间步的隐藏状态和输出是</dt><dd><ul>
<li><p>f 是隐藏层的变换</p></li>
<li><p>g 是输出层的变换</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    h_t &amp;= f(x_t, h_{t-1}, w_\textrm{h}),\\
    o_t &amp;= g(h_t, w_\textrm{o}),
\end{aligned}\end{split}\]</div>
<ul class="simple">
<li><dl class="simple">
<dt>前向传播相当简单</dt><dd><ul>
<li><p>通过所有 T 时间步长的目标函数来评估输出 <span class="math notranslate nohighlight">\(o_t\)</span> 与所需目标 <span class="math notranslate nohighlight">\(y_t\)</span> 之间的差异</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<div class="math notranslate nohighlight">
\[L(x_1, \ldots, x_T, y_1, \ldots, y_T, w_\textrm{h}, w_\textrm{o}) = \frac{1}{T}\sum_{t=1}^T l(y_t, o_t)\]</div>
<ul class="simple">
<li><dl class="simple">
<dt>反向传播，事情有点棘手</dt><dd><ul>
<li><p>根据链式法则</p></li>
<li><p>乘积的第一和第二因子很容易计算。第三个因素 <span class="math notranslate nohighlight">\(\partial h_t/\partial w_\textrm{h}\)</span> 是事情变得棘手的地方，因为需要递归地累积每个时间步对 <span class="math notranslate nohighlight">\(w_\text{h}\)</span> 的影响。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    \frac{\partial L}{\partial w_\textrm{h}}
        &amp; = \frac{1}{T}\sum_{t=1}^T \frac{\partial l(y_t, o_t)}{\partial w_\textrm{h}}  \\
        &amp; = \frac{1}{T}\sum_{t=1}^T \frac{\partial l(y_t, o_t)}{\partial o_t} \frac{\partial g(h_t, w_\textrm{o})}{\partial h_t}  \frac{\partial h_t}{\partial w_\textrm{h}}
\end{aligned}\end{split}\]</div>
<p>为了导出上述梯度，假设我们有三个序列 <span class="math notranslate nohighlight">\(\{a_{t}\},\{b_{t}\},\{c_{t}\}\)</span> 对于 <span class="math notranslate nohighlight">\(t=1, 2,\ldots\)</span> 满足 <span class="math notranslate nohighlight">\(a_{0}=0\)</span> and <span class="math notranslate nohighlight">\(a_{t}=b_{t}+c_{t}a_{t-1}\)</span> .那么对于 <span class="math notranslate nohighlight">\(t\geq 1\)</span> , 很容易得出</p>
<div class="math notranslate nohighlight">
\[a_{t}=b_{t}+\sum_{i=1}^{t-1}\left(\prod_{j=i+1}^{t}c_{j}\right)b_{i}\]</div>
<p>由于：</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    a_t &amp;= \frac{\partial h_t}{\partial w_\textrm{h}},\\
    b_t &amp;= \frac{\partial f(x_{t},h_{t-1},w_\textrm{h})}{\partial w_\textrm{h}}, \\
    c_t &amp;= \frac{\partial f(x_{t},h_{t-1},w_\textrm{h})}{\partial h_{t-1}}
\end{aligned}$$\end{split}\]</div>
<p>把上面两公式代入一起，即可删除循环计算可得如下公式</p>
<div class="math notranslate nohighlight">
\[\frac{\partial h_t}{\partial w_\textrm{h}}
    =\frac{\partial f(x_{t},h_{t-1},w_\textrm{h})}{\partial w_\textrm{h}}
        +\sum_{i=1}^{t-1}\left(\prod_{j=i+1}^{t} \frac{\partial f(x_{j},h_{j-1},w_\textrm{h})}{\partial h_{j-1}} \right)
            \frac{\partial f(x_{i},h_{i-1},w_\textrm{h})}{\partial w_\textrm{h}}\]</div>
</section>
<section id="id163">
<h5>总结与实践意义<a class="headerlink" href="#id163" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>在实际中，时间步截断（Truncated BPTT）是最常用的方法，它在计算效率和模型稳定性之间达成了平衡。</p></li>
<li><p>对于处理长序列数据的任务（如文本序列），这种方法既能捕获短期依赖，又能避免梯度问题带来的训练困难。</p></li>
</ul>
</section>
</section>
</section>
<section id="modern-recurrent-neural-networks">
<h3>10. Modern Recurrent Neural Networks<a class="headerlink" href="#modern-recurrent-neural-networks" title="此标题的永久链接">¶</a></h3>
<section id="long-short-term-memory-lstm">
<h4>10.1. Long Short-Term Memory (LSTM)<a class="headerlink" href="#long-short-term-memory-lstm" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>虽然梯度裁剪有助于梯度爆炸，但处理梯度消失似乎需要更复杂的解决方案。</p></li>
<li><p>Hochreiter 和 Schmidhuber (1997) 提出的解决梯度消失问题的第一个也是最成功的技术之一是长短期记忆 (LSTM) 模型。</p></li>
<li><p>LSTM 类似于标准的循环神经网络，但这里每个普通的循环节点都被一个记忆单元取代。</p></li>
<li><p>每个记忆单元包含一个内部状态，即具有固定权重1的自连接循环边的节点，确保梯度可以跨越许多时间步而不会消失或爆炸。</p></li>
<li><dl class="simple">
<dt>“长短期记忆”一词来自以下直觉:</dt><dd><ul>
<li><dl class="simple">
<dt>简单的循环神经网络具有权重形式的长期记忆。</dt><dd><ul>
<li><p>权重在训练过程中缓慢变化，编码有关数据的一般知识。</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>它们还具有短暂激活形式的短期记忆，从每个节点传递到连续的节点。</p></li>
<li><p>LSTM 模型通过记忆单元引入了中间类型的存储。</p></li>
<li><p>存储单元是一个复合单元，由特定连接模式中的简单节点构建而成，并新颖地包含乘法节点。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<section id="gated-memory-cell">
<h5>10.1.1. Gated Memory Cell<a class="headerlink" href="#gated-memory-cell" title="此标题的永久链接">¶</a></h5>
<section id="gated-hidden-state">
<h6>10.1.1.1. Gated Hidden State<a class="headerlink" href="#gated-hidden-state" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>普通 RNN 和 LSTM 之间的主要区别在于后者支持隐藏状态的门控。</p></li>
<li><p>这意味着我们有专门的机制来确定何时应该更新隐藏状态以及何时应该重置隐藏状态。</p></li>
</ul>
</section>
<section id="input-gate-forget-gate-and-output-gate">
<h6>10.1.1.2. Input Gate, Forget Gate, and Output Gate<a class="headerlink" href="#input-gate-forget-gate-and-output-gate" title="此标题的永久链接">¶</a></h6>
<figure class="align-default" id="id244">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/nDlrQH.png" src="https://img.zhaoweiguo.com/uPic/2025/01/nDlrQH.png" />
<figcaption>
<p><span class="caption-text">Fig. 10.1.1 Computing the input gate, the forget gate, and the output gate in an LSTM model.</span><a class="headerlink" href="#id244" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>The data feeding into the LSTM gates are the <code class="docutils literal notranslate"><span class="pre">input</span></code> at the current time step and the <code class="docutils literal notranslate"><span class="pre">hidden</span> <span class="pre">state</span></code> of the previous time step</p></li>
<li><p>The  <code class="docutils literal notranslate"><span class="pre">input</span></code> gate determines how much of the input node’s value should be added to the current memory cell internal state.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">forget</span></code> gate determines whether to keep the current value of the memory or flush it.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">output</span></code> gate determines whether the memory cell should influence the output at the current time step.</p></li>
<li><p>从数学上讲，假设有 h 个隐藏单元，批量大小为 n ，输入数量为 d</p></li>
<li><p>因此，输入是 <span class="math notranslate nohighlight">\(\mathbf{X}_t \in \mathbb{R}^{n \times d}\)</span> ，前一个时间步的隐藏状态是 <span class="math notranslate nohighlight">\(\mathbf{H}_{t-1} \in \mathbb{R}^{n \times h}\)</span></p></li>
<li><dl class="simple">
<dt>Correspondingly, the gates at time step <code class="docutils literal notranslate"><span class="pre">t</span></code> are defined as follows:</dt><dd><ul>
<li><p>the  input gate is <span class="math notranslate nohighlight">\(\mathbf{I}_t \in \mathbb{R}^{n \times h}\)</span> ,</p></li>
<li><p>the forget gate is <span class="math notranslate nohighlight">\(\mathbf{F}_t \in \mathbb{R}^{n \times h}\)</span> ,</p></li>
<li><p>the output gate is <span class="math notranslate nohighlight">\(\mathbf{O}_t \in \mathbb{R}^{n \times h}\)</span> .</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>公式：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    \mathbf{I}_t &amp;= \sigma(\mathbf{X}_t \mathbf{W}_{\textrm{xi}} + \mathbf{H}_{t-1} \mathbf{W}_{\textrm{hi}} + \mathbf{b}_\textrm{i}),\\
    \mathbf{F}_t &amp;= \sigma(\mathbf{X}_t \mathbf{W}_{\textrm{xf}} + \mathbf{H}_{t-1} \mathbf{W}_{\textrm{hf}} + \mathbf{b}_\textrm{f}),\\
    \mathbf{O}_t &amp;= \sigma(\mathbf{X}_t \mathbf{W}_{\textrm{xo}} + \mathbf{H}_{t-1} \mathbf{W}_{\textrm{ho}} + \mathbf{b}_\textrm{o}),
\end{aligned}\end{split}\]</div>
<ul class="simple">
<li><p>where <span class="math notranslate nohighlight">\(\mathbf{W}_{\textrm{xi}}, \mathbf{W}_{\textrm{xf}}, \mathbf{W}_{\textrm{xo}} \in \mathbb{R}^{d \times h}\)</span></p></li>
<li><p>and <span class="math notranslate nohighlight">\(\mathbf{W}_{\textrm{hi}}, \mathbf{W}_{\textrm{hf}}, \mathbf{W}_{\textrm{ho}} \in \mathbb{R}^{h \times h}\)</span> are weight parameters</p></li>
<li><p>and <span class="math notranslate nohighlight">\(\mathbf{b}_\textrm{i}, \mathbf{b}_\textrm{f}, \mathbf{b}_\textrm{o} \in \mathbb{R}^{1 \times h}\)</span> are bias parameters.</p></li>
</ul>
</section>
<section id="input-node">
<h6>10.1.1.3. Input Node<a class="headerlink" href="#input-node" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>公式和上述三个门类似，但使用取值范围为 (-1, 1) 的 <code class="docutils literal notranslate"><span class="pre">tanh</span></code> 函数作为激活函数。</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\tilde{\mathbf{C}}_t = \textrm{tanh}(\mathbf{X}_t \mathbf{W}_{\textrm{xc}} + \mathbf{H}_{t-1} \mathbf{W}_{\textrm{hc}} + \mathbf{b}_\textrm{c})\]</div>
<ul class="simple">
<li><p><em>input node</em> : <span class="math notranslate nohighlight">\(\tilde{\mathbf{C}}_t \in \mathbb{R}^{n \times h}\)</span></p></li>
<li><p>where <span class="math notranslate nohighlight">\(\mathbf{W}_{\textrm{xc}} \in \mathbb{R}^{d \times h}\)</span></p></li>
<li><p>and   <span class="math notranslate nohighlight">\(\mathbf{W}_{\textrm{hc}} \in \mathbb{R}^{h \times h}\)</span> are weight parameters and $mathbf{b}_textrm{c} in mathbb{R}^{1 times h}$ is a bias parameter.</p></li>
</ul>
<figure class="align-default" id="id245">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/HvpMT7.png" src="https://img.zhaoweiguo.com/uPic/2025/01/HvpMT7.png" />
<figcaption>
<p><span class="caption-text">Fig. 10.1.2 Computing the input node in an LSTM model.</span><a class="headerlink" href="#id245" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
</section>
<section id="memory-cell-internal-state">
<h6>10.1.1.4. Memory Cell Internal State<a class="headerlink" href="#memory-cell-internal-state" title="此标题的永久链接">¶</a></h6>
<figure class="align-default" id="id246">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/G2kAIc.png" src="https://img.zhaoweiguo.com/uPic/2025/01/G2kAIc.png" />
<figcaption>
<p><span class="caption-text">Fig. 10.1.3 Computing the memory cell internal state in an LSTM model.</span><a class="headerlink" href="#id246" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><dl class="simple">
<dt>In LSTMs, the input gate <span class="math notranslate nohighlight">\(\mathbf{I}_t\)</span> governs how much we take new data into account via <span class="math notranslate nohighlight">\(\tilde{\mathbf{C}}_t\)</span></dt><dd><ul>
<li><p>and the forget gate <span class="math notranslate nohighlight">\(\mathbf{F}_t\)</span> addresses how much of the old cell internal state <span class="math notranslate nohighlight">\(\mathbf{C}_{t-1} \in \mathbb{R}^{n \times h}\)</span> we retain.</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Using the Hadamard (elementwise) product operator <span class="math notranslate nohighlight">\(\odot\)</span> we arrive at the following update equation:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\mathbf{C}_t = \mathbf{F}_t \odot \mathbf{C}_{t-1} + \mathbf{I}_t \odot \tilde{\mathbf{C}}_t\]</div>
</section>
<section id="hidden-state">
<h6>10.1.1.5. Hidden State<a class="headerlink" href="#hidden-state" title="此标题的永久链接">¶</a></h6>
<figure class="align-default" id="id247">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/sMfLde.png" src="https://img.zhaoweiguo.com/uPic/2025/01/sMfLde.png" />
<figcaption>
<p><span class="caption-text">Fig. 10.1.4 Computing the hidden state in an LSTM model.</span><a class="headerlink" href="#id247" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<p>Now compute the output of the memory cell(the hidden state <span class="math notranslate nohighlight">\(\mathbf{H}_t \in \mathbb{R}^{n \times h}\)</span> )</p>
<div class="math notranslate nohighlight">
\[\mathbf{H}_t = \mathbf{O}_t \odot \tanh(\mathbf{C}_t)\]</div>
</section>
</section>
<section id="id164">
<h5>10.1.2. Implementation from Scratch<a class="headerlink" href="#id164" title="此标题的永久链接">¶</a></h5>
<section id="initializing-model-parameters">
<h6>10.1.2.1. Initializing Model Parameters<a class="headerlink" href="#initializing-model-parameters" title="此标题的永久链接">¶</a></h6>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">LSTMScratch</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>

        <span class="n">init_weight</span> <span class="o">=</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">shape</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">sigma</span><span class="p">)</span>
        <span class="n">triple</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="p">(</span><span class="n">init_weight</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">),</span>
                          <span class="n">init_weight</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">),</span>
                          <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_xi</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_hi</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_i</span> <span class="o">=</span> <span class="n">triple</span><span class="p">()</span>  <span class="c1"># Input gate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_xf</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_hf</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_f</span> <span class="o">=</span> <span class="n">triple</span><span class="p">()</span>  <span class="c1"># Forget gate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_xo</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_ho</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_o</span> <span class="o">=</span> <span class="n">triple</span><span class="p">()</span>  <span class="c1"># Output gate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_xc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_hc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_c</span> <span class="o">=</span> <span class="n">triple</span><span class="p">()</span>  <span class="c1"># Input node</span>

<span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">LSTMScratch</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">H_C</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">H_C</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Initial state with shape: (batch_size, num_hiddens)</span>
        <span class="n">H</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">),</span>
                      <span class="n">device</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">),</span>
                      <span class="n">device</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">H</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="n">H_C</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">X</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>
        <span class="n">I</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_xi</span><span class="p">)</span> <span class="o">+</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_hi</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_i</span><span class="p">)</span>
        <span class="n">F</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_xf</span><span class="p">)</span> <span class="o">+</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_hf</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_f</span><span class="p">)</span>
        <span class="n">O</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_xo</span><span class="p">)</span> <span class="o">+</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_ho</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_o</span><span class="p">)</span>
        <span class="n">C_tilde</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_xc</span><span class="p">)</span> <span class="o">+</span>
                           <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_hc</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_c</span><span class="p">)</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">F</span> <span class="o">*</span> <span class="n">C</span> <span class="o">+</span> <span class="n">I</span> <span class="o">*</span> <span class="n">C_tilde</span>
        <span class="n">H</span> <span class="o">=</span> <span class="n">O</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">H</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="training-and-prediction">
<h6>10.1.2.2. Training and Prediction<a class="headerlink" href="#training-and-prediction" title="此标题的永久链接">¶</a></h6>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">TimeMachine</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">lstm</span> <span class="o">=</span> <span class="n">LSTMScratch</span><span class="p">(</span><span class="n">num_inputs</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">vocab</span><span class="p">),</span> <span class="n">num_hiddens</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">RNNLMScratch</span><span class="p">(</span><span class="n">lstm</span><span class="p">,</span> <span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">vocab</span><span class="p">),</span> <span class="n">lr</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">gradient_clip_val</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="id165">
<h5>10.1.3. Concise Implementation<a class="headerlink" href="#id165" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">LSTM</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">RNN</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">):</span>
        <span class="n">d2l</span><span class="o">.</span><span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">H_C</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">H_C</span><span class="p">)</span>

<span class="n">lstm</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="n">num_inputs</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">vocab</span><span class="p">),</span> <span class="n">num_hiddens</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">RNNLM</span><span class="p">(</span><span class="n">lstm</span><span class="p">,</span> <span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">vocab</span><span class="p">),</span> <span class="n">lr</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<p>使用:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="s1">&#39;it has&#39;</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">vocab</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">())</span>
<span class="c1"># 输出</span>
<span class="s1">&#39;it has a the time travelly&#39;</span>
</pre></div>
</div>
</section>
<section id="id166">
<h5>10.1.4. Summary<a class="headerlink" href="#id166" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>LSTM 于 1997 年发布，但在 2000 年代中期的预测竞赛中取得了一些胜利，使其声名鹊起，并从 2011 年开始成为序列学习的主导模型，直到 2017 年开始 Transformer 模型的兴起。</p></li>
<li><p>LSTM 具有三种类型的门：输入门、遗忘门和控制信息流的输出门。 LSTM的隐藏层输出包括隐藏状态和记忆单元内部状态。只有隐藏状态被传递到输出层，而存储单元内部状态完全保持在内部。 LSTM 可以缓解梯度消失和爆炸。</p></li>
</ul>
</section>
</section>
<section id="gated-recurrent-units-gru">
<h4>10.2. Gated Recurrent Units (GRU)<a class="headerlink" href="#gated-recurrent-units-gru" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>门控循环单元 (GRU)（Cho 等人，2014）提供了 LSTM 存储单元的简化版本，通常可以实现相当的性能，但具有计算速度更快的优点（Chung 等人，2014）。</p></li>
</ul>
<section id="reset-gate-and-update-gate">
<h5>10.2.1. Reset Gate and Update Gate<a class="headerlink" href="#reset-gate-and-update-gate" title="此标题的永久链接">¶</a></h5>
<figure class="align-default" id="id248">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/yvWA3J.png" src="https://img.zhaoweiguo.com/uPic/2025/01/yvWA3J.png" />
<figcaption>
<p><span class="caption-text">Fig. 10.2.1 Computing the reset gate and the update gate in a GRU model. 给定当前时间步的输入和前一个时间步的隐藏状态。</span><a class="headerlink" href="#id248" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>LSTM 的三个门被替换为两个：重置门和更新门。</p></li>
<li><dl class="simple">
<dt>直观上，</dt><dd><ul>
<li><p>重置门控制着我们可能仍想记住多少先前的状态。</p></li>
<li><p>更新门将允许我们控制新状态中有多少只是旧状态的副本。</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Mathematically, for a given time step <code class="docutils literal notranslate"><span class="pre">t</span></code> , suppose that the input is a minibatch <span class="math notranslate nohighlight">\(\mathbf{X}_t \in \mathbb{R}^{n \times d}\)</span> (<code class="docutils literal notranslate"><span class="pre">number</span> <span class="pre">of</span> <span class="pre">examples</span> <span class="pre">=n;</span> <span class="pre">number</span> <span class="pre">of</span> <span class="pre">inputs</span> <span class="pre">=d</span></code>)</p></li>
<li><p>and the hidden state of the previous time step is <span class="math notranslate nohighlight">\(\mathbf{H}_{t-1} \in \mathbb{R}^{n \times h}\)</span> (<code class="docutils literal notranslate"><span class="pre">number</span> <span class="pre">of</span> <span class="pre">hidden</span> <span class="pre">units</span> <span class="pre">=h</span></code>).</p></li>
<li><p>Then the reset gate <span class="math notranslate nohighlight">\(\mathbf{R}_t \in \mathbb{R}^{n \times h}\)</span> and update gate <span class="math notranslate nohighlight">\(\mathbf{Z}_t \in \mathbb{R}^{n \times h}\)</span> are computed as follows:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    \mathbf{R}_t = \sigma(\mathbf{X}_t \mathbf{W}_{\textrm{xr}} + \mathbf{H}_{t-1} \mathbf{W}_{\textrm{hr}} + \mathbf{b}_\textrm{r}),\\
    \mathbf{Z}_t = \sigma(\mathbf{X}_t \mathbf{W}_{\textrm{xz}} + \mathbf{H}_{t-1} \mathbf{W}_{\textrm{hz}} + \mathbf{b}_\textrm{z}),
\end{aligned}\end{split}\]</div>
</section>
<section id="candidate-hidden-state">
<h5>10.2.2. Candidate Hidden State<a class="headerlink" href="#candidate-hidden-state" title="此标题的永久链接">¶</a></h5>
<figure class="align-default" id="id249">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/8A9kVr.png" src="https://img.zhaoweiguo.com/uPic/2025/01/8A9kVr.png" />
<figcaption>
<p><span class="caption-text">Fig. 10.2.2 Computing the candidate hidden state in a GRU model.</span><a class="headerlink" href="#id249" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<p>公式:</p>
<div class="math notranslate nohighlight">
\[\tilde{\mathbf{H}}_t = \tanh(\mathbf{X}_t \mathbf{W}_{\textrm{xh}} + \left(\mathbf{R}_t \odot \mathbf{H}_{t-1}\right) \mathbf{W}_{\textrm{hh}} + \mathbf{b}_\textrm{h})\]</div>
<ul class="simple">
<li><p>当重置门 <span class="math notranslate nohighlight">\(\mathbf{R}_t\)</span> 中的条目接近 1 时，我们就会恢复一个普通的 RNN</p></li>
<li><p>当重置门 <span class="math notranslate nohighlight">\(\mathbf{R}_t\)</span> 中的条目接近 0 时，候选隐藏状态是以 <span class="math notranslate nohighlight">\(\mathbf{X}_t\)</span> 作为输入的 MLP 的结果。</p></li>
</ul>
</section>
<section id="id167">
<h5>10.2.3. Hidden State<a class="headerlink" href="#id167" title="此标题的永久链接">¶</a></h5>
<figure class="align-default" id="id250">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/yy2z50.png" src="https://img.zhaoweiguo.com/uPic/2025/01/yy2z50.png" />
<figcaption>
<p><span class="caption-text">Fig. 10.2.3 Computing the hidden state in a GRU model.</span><a class="headerlink" href="#id250" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<div class="math notranslate nohighlight">
\[\mathbf{H}_t = \mathbf{Z}_t \odot \mathbf{H}_{t-1}  + (1 - \mathbf{Z}_t) \odot \tilde{\mathbf{H}}_t\]</div>
<ul class="simple">
<li><p>每当更新门 <span class="math notranslate nohighlight">\(\mathbf{Z}_t\)</span> 接近1时，返回前一个隐藏状态。在这种情况下，来自 <span class="math notranslate nohighlight">\(\mathbf{X}_t\)</span> 的信息将被忽略，从而有效地跳过依赖链中的时间步 t 。</p></li>
<li><p>相反，每当 <span class="math notranslate nohighlight">\(\mathbf{Z}_t\)</span> 接近 0 时，新的潜在状态 <span class="math notranslate nohighlight">\(\mathbf{H}_t\)</span> 就会接近候选潜在状态 <span class="math notranslate nohighlight">\(\tilde{\mathbf{H}}_t\)</span> 。</p></li>
<li><dl class="simple">
<dt>GRU有以下两个显着特征：</dt><dd><ul>
<li><p>Reset gates help capture short-term dependencies in sequences.</p></li>
<li><p>Update gates help capture long-term dependencies in sequences.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="id168">
<h5>10.2.4. Implementation from Scratch<a class="headerlink" href="#id168" title="此标题的永久链接">¶</a></h5>
<section id="id169">
<h6>10.2.4.1. Initializing Model Parameters<a class="headerlink" href="#id169" title="此标题的永久链接">¶</a></h6>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">GRUScratch</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>

        <span class="n">init_weight</span> <span class="o">=</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">shape</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">sigma</span><span class="p">)</span>
        <span class="n">triple</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="p">(</span><span class="n">init_weight</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">),</span>
                          <span class="n">init_weight</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">),</span>
                          <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_xz</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_hz</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_z</span> <span class="o">=</span> <span class="n">triple</span><span class="p">()</span>  <span class="c1"># Update gate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_xr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_hr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_r</span> <span class="o">=</span> <span class="n">triple</span><span class="p">()</span>  <span class="c1"># Reset gate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_xh</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_hh</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_h</span> <span class="o">=</span> <span class="n">triple</span><span class="p">()</span>  <span class="c1"># Candidate hidden state</span>
</pre></div>
</div>
</section>
<section id="id170">
<h6>10.2.4.2. Defining the Model<a class="headerlink" href="#id170" title="此标题的永久链接">¶</a></h6>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">GRUScratch</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">H</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">H</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Initial state with shape: (batch_size, num_hiddens)</span>
        <span class="n">H</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">),</span>
                      <span class="n">device</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">X</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>
        <span class="n">Z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_xz</span><span class="p">)</span> <span class="o">+</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_hz</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_z</span><span class="p">)</span>
        <span class="n">R</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_xr</span><span class="p">)</span> <span class="o">+</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_hr</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_r</span><span class="p">)</span>
        <span class="n">H_tilde</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_xh</span><span class="p">)</span> <span class="o">+</span>
                           <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">R</span> <span class="o">*</span> <span class="n">H</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_hh</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_h</span><span class="p">)</span>
        <span class="n">H</span> <span class="o">=</span> <span class="n">Z</span> <span class="o">*</span> <span class="n">H</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">Z</span><span class="p">)</span> <span class="o">*</span> <span class="n">H_tilde</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">H</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">H</span>
</pre></div>
</div>
</section>
<section id="id171">
<h6>10.2.4.3. Training<a class="headerlink" href="#id171" title="此标题的永久链接">¶</a></h6>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">TimeMachine</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">gru</span> <span class="o">=</span> <span class="n">GRUScratch</span><span class="p">(</span><span class="n">num_inputs</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">vocab</span><span class="p">),</span> <span class="n">num_hiddens</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">RNNLMScratch</span><span class="p">(</span><span class="n">gru</span><span class="p">,</span> <span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">vocab</span><span class="p">),</span> <span class="n">lr</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">gradient_clip_val</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="id172">
<h5>10.2.5. Concise Implementation<a class="headerlink" href="#id172" title="此标题的永久链接">¶</a></h5>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">GRU</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">RNN</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">):</span>
        <span class="n">d2l</span><span class="o">.</span><span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span>

<span class="n">gru</span> <span class="o">=</span> <span class="n">GRU</span><span class="p">(</span><span class="n">num_inputs</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">vocab</span><span class="p">),</span> <span class="n">num_hiddens</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">RNNLM</span><span class="p">(</span><span class="n">gru</span><span class="p">,</span> <span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">vocab</span><span class="p">),</span> <span class="n">lr</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<p>使用:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="s1">&#39;it has&#39;</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">vocab</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">())</span>
<span class="c1"># 输出</span>
<span class="s1">&#39;it has so it and the time &#39;</span>
</pre></div>
</div>
</section>
<section id="id173">
<h5>10.2.6. Summary<a class="headerlink" href="#id173" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>与 LSTM 相比，GRU 实现了相似的性能，但计算量往往更轻。</p></li>
<li><p>当重置门打开时，GRU 包含基本的 RNN 作为其极端情况。</p></li>
<li><p>当更新门打开时，可以用来跳过子序列。</p></li>
</ul>
</section>
</section>
<section id="deep-recurrent-neural-networks">
<h4>10.3. Deep Recurrent Neural Networks<a class="headerlink" href="#deep-recurrent-neural-networks" title="此标题的永久链接">¶</a></h4>
<figure class="align-default" id="id251">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/AmmtES.png" src="https://img.zhaoweiguo.com/uPic/2025/01/AmmtES.png" />
<figcaption>
<p><span class="caption-text">Fig. 10.3.1 Architecture of a deep RNN.</span><a class="headerlink" href="#id251" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>the hidden state of the <span class="math notranslate nohighlight">\(l^\textrm{th}\)</span> hidden layer ( <span class="math notranslate nohighlight">\(l=1,\ldots,L\)</span> ) be <span class="math notranslate nohighlight">\(\mathbf{H}_t^{(l)} \in \mathbb{R}^{n \times h}\)</span> (<code class="docutils literal notranslate"><span class="pre">number</span> <span class="pre">of</span> <span class="pre">hidden</span> <span class="pre">units</span> <span class="pre">=h</span></code>)</p></li>
<li><p>the output layer variable be <span class="math notranslate nohighlight">\(\mathbf{O}_t \in \mathbb{R}^{n \times q}\)</span> (<code class="docutils literal notranslate"><span class="pre">number</span> <span class="pre">of</span> <span class="pre">outputs:</span> <span class="pre">q</span></code>).</p></li>
<li><p>Setting <span class="math notranslate nohighlight">\(\mathbf{H}_t^{(0)} = \mathbf{X}_t\)</span></p></li>
<li><p>the hidden state of the <span class="math notranslate nohighlight">\(l^\textrm{th}\)</span> hidden layer that uses the activation function <span class="math notranslate nohighlight">\(\phi_l\)</span> is calculated as follows:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\mathbf{H}_t^{(l)} = \phi_l(\mathbf{H}_t^{(l-1)} \mathbf{W}_{\textrm{xh}}^{(l)} + \mathbf{H}_{t-1}^{(l)} \mathbf{W}_{\textrm{hh}}^{(l)}  + \mathbf{b}_\textrm{h}^{(l)})\]</div>
<p>最后，输出层的计算仅基于最终 <span class="math notranslate nohighlight">\(\mathbf{L}^{th}\)</span> 隐藏层的隐藏状态：</p>
<div class="math notranslate nohighlight">
\[\mathbf{O}_t = \mathbf{H}_t^{(L)} \mathbf{W}_{\textrm{hq}} + \mathbf{b}_\textrm{q}\]</div>
<section id="id174">
<h5>10.3.1. Implementation from Scratch<a class="headerlink" href="#id174" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">StackedRNNScratch</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnns</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">d2l</span><span class="o">.</span><span class="n">RNNScratch</span><span class="p">(</span>
            <span class="n">num_inputs</span> <span class="k">if</span> <span class="n">i</span><span class="o">==</span><span class="mi">0</span> <span class="k">else</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
                                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)])</span>

<span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">StackedRNNScratch</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">Hs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">inputs</span>
    <span class="k">if</span> <span class="n">Hs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">Hs</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">):</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="n">Hs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnns</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">outputs</span><span class="p">,</span> <span class="n">Hs</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">Hs</span>
</pre></div>
</div>
<p>使用(为了简单起见，我们将层数设置为 2):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">TimeMachine</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">rnn_block</span> <span class="o">=</span> <span class="n">StackedRNNScratch</span><span class="p">(</span><span class="n">num_inputs</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">vocab</span><span class="p">),</span>
                              <span class="n">num_hiddens</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">RNNLMScratch</span><span class="p">(</span><span class="n">rnn_block</span><span class="p">,</span> <span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">vocab</span><span class="p">),</span> <span class="n">lr</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">gradient_clip_val</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id175">
<h5>10.3.2. Concise Implementation<a class="headerlink" href="#id175" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">GRU</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">RNN</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The multilayer GRU model.&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="n">d2l</span><span class="o">.</span><span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span>
                          <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>

<span class="n">gru</span> <span class="o">=</span> <span class="n">GRU</span><span class="p">(</span><span class="n">num_inputs</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">vocab</span><span class="p">),</span> <span class="n">num_hiddens</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">RNNLM</span><span class="p">(</span><span class="n">gru</span><span class="p">,</span> <span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">vocab</span><span class="p">),</span> <span class="n">lr</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<p>使用:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="s1">&#39;it has&#39;</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">vocab</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">())</span>
<span class="c1"># 输出</span>
<span class="s1">&#39;it has for and the time th&#39;</span>
</pre></div>
</div>
</section>
<section id="id176">
<h5>10.3.3. Summary<a class="headerlink" href="#id176" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>在深度 RNN 中，隐藏状态信息被传递到当前层的下一个时间步和下一层的当前时间步。</p></li>
<li><p>存在许多不同风格的深度 RNN，例如 LSTM、GRU 或普通 RNN。</p></li>
</ul>
</section>
</section>
<section id="bidirectional-recurrent-neural-networks">
<h4>10.4. Bidirectional Recurrent Neural Networks<a class="headerlink" href="#bidirectional-recurrent-neural-networks" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>将任何单向 RNN 转换为双向 RNN（Schuster 和 Paliwal，1997）。</p></li>
<li><p>实现两个单向 RNN 层，它们以相反的方向链接在一起并作用于相同的输入</p></li>
<li><p>对于第一个 RNN 层，第一个输入是 <span class="math notranslate nohighlight">\(\mathbf{x}_1\)</span> ，最后一个输入是 <span class="math notranslate nohighlight">\(\mathbf{x}_T\)</span> ，但对于第二个 RNN 层，第一个输入是 <span class="math notranslate nohighlight">\(\mathbf{x}_T\)</span> ，最后一个输入是 <span class="math notranslate nohighlight">\(\mathbf{x}_1\)</span> ，最终的输入是 <span class="math notranslate nohighlight">\(\mathbf{x}_1\)</span> 。为了产生这个双向 RNN 层的输出，我们只需将两个底层单向 RNN 层的相应输出连接在一起。</p></li>
</ul>
<figure class="align-default" id="id252">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/iQf4dQ.png" src="https://img.zhaoweiguo.com/uPic/2025/01/iQf4dQ.png" />
<figcaption>
<p><span class="caption-text">Fig. 10.4.1 Architecture of a bidirectional RNN.</span><a class="headerlink" href="#id252" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<p>前向和后向隐藏状态更新：</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    \overrightarrow{\mathbf{H}}_t &amp;= \phi(\mathbf{X}_t \mathbf{W}_{\textrm{xh}}^{(f)} + \overrightarrow{\mathbf{H}}_{t-1} \mathbf{W}_{\textrm{hh}}^{(f)}  + \mathbf{b}_\textrm{h}^{(f)}),\\
    \overleftarrow{\mathbf{H}}_t &amp;= \phi(\mathbf{X}_t \mathbf{W}_{\textrm{xh}}^{(b)} + \overleftarrow{\mathbf{H}}_{t+1} \mathbf{W}_{\textrm{hh}}^{(b)}  + \mathbf{b}_\textrm{h}^{(b)}),
\end{aligned}\end{split}\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{H}_t \in \mathbb{R}^{n \times 2h}\)</span> 是把 <span class="math notranslate nohighlight">\(\overrightarrow{\mathbf{H}}_t\)</span> 和 <span class="math notranslate nohighlight">\(\overleftarrow{\mathbf{H}}_t\)</span> 合并起来得到</p></li>
<li><p>最后，输出层计算输出 <span class="math notranslate nohighlight">\(\mathbf{O}_t \in \mathbb{R}^{n \times q}\)</span> (<code class="docutils literal notranslate"><span class="pre">number</span> <span class="pre">of</span> <span class="pre">outputs</span> <span class="pre">=q</span></code>):</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\mathbf{O}_t = \mathbf{H}_t \mathbf{W}_{\textrm{hq}} + \mathbf{b}_\textrm{q}\]</div>
<section id="id177">
<h5>10.4.1. Implementation from Scratch<a class="headerlink" href="#id177" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">BiRNNScratch</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f_rnn</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">RNNScratch</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b_rnn</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">RNNScratch</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span> <span class="o">*=</span> <span class="mi">2</span>  <span class="c1"># The output dimension will be doubled</span>

<span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">BiRNNScratch</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">Hs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">f_H</span><span class="p">,</span> <span class="n">b_H</span> <span class="o">=</span> <span class="n">Hs</span> <span class="k">if</span> <span class="n">Hs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">f_outputs</span><span class="p">,</span> <span class="n">f_H</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_rnn</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">f_H</span><span class="p">)</span>
    <span class="n">b_outputs</span><span class="p">,</span> <span class="n">b_H</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">b_rnn</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="n">b_H</span><span class="p">)</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">f</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
        <span class="n">f_outputs</span><span class="p">,</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">b_outputs</span><span class="p">))]</span>
    <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="p">(</span><span class="n">f_H</span><span class="p">,</span> <span class="n">b_H</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id178">
<h5>10.4.2. Concise Implementation<a class="headerlink" href="#id178" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">BiGRU</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">RNN</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">):</span>
        <span class="n">d2l</span><span class="o">.</span><span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span> <span class="o">*=</span> <span class="mi">2</span>
</pre></div>
</div>
</section>
<section id="id179">
<h5>10.4.3. Summary<a class="headerlink" href="#id179" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>在双向 RNN 中，每个时间步的隐藏状态由当前时间步之前和之后的数据同时确定。</p></li>
<li><p>双向 RNN 最适用于序列编码和给定双向上下文的观测值估计。由于梯度链较长，双向 RNN 的训练成本非常高。</p></li>
</ul>
</section>
</section>
<section id="machine-translation-and-the-dataset">
<h4>10.5. Machine Translation and the Dataset<a class="headerlink" href="#machine-translation-and-the-dataset" title="此标题的永久链接">¶</a></h4>
<section id="downloading-and-preprocessing-the-dataset">
<h5>10.5.1. Downloading and Preprocessing the Dataset<a class="headerlink" href="#downloading-and-preprocessing-the-dataset" title="此标题的永久链接">¶</a></h5>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>class MTFraEng(d2l.DataModule):  #@save
    &quot;&quot;&quot;The English-French dataset.&quot;&quot;&quot;
    def _download(self):
        d2l.extract(d2l.download(
            d2l.DATA_URL+&#39;fra-eng.zip&#39;, self.root,
            &#39;94646ad1522d915e7b0f9296181140edcf86a4f5&#39;))
        with open(self.root + &#39;/fra-eng/fra.txt&#39;, encoding=&#39;utf-8&#39;) as f:
            return f.read()

data = MTFraEng()
raw_text = data._download()
print(raw_text[:75])

# 输出
Downloading ../data/fra-eng.zip from http://d2l-data.s3-accelerate.amazonaws.com/fra-eng.zip...
Go. Va !
Hi. Salut !
Run!        Cours !
Run!        Courez !
Who?        Qui ?
Wow!        Ça alors !
</pre></div>
</div>
<p>预处理(用空格替换不间断空格，将大写字母转换为小写字母，以及在单词和标点符号之间插入空格):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>@d2l.add_to_class(MTFraEng)  #@save
def _preprocess(self, text):
    # Replace non-breaking space with space
    text = text.replace(&#39;\u202f&#39;, &#39; &#39;).replace(&#39;\xa0&#39;, &#39; &#39;)
    # Insert space between words and punctuation marks
    no_space = lambda char, prev_char: char in &#39;,.!?&#39; and prev_char != &#39; &#39;
    out = [&#39; &#39; + char if i &gt; 0 and no_space(char, text[i - 1]) else char
           for i, char in enumerate(text.lower())]
    return &#39;&#39;.join(out)

text = data._preprocess(raw_text)
print(text[:80])

# 输出
go .        va !
hi .        salut !
run !       cours !
run !       courez !
who ?       qui ?
wow !       ça alors !
</pre></div>
</div>
</section>
<section id="id180">
<h5>10.5.2. Tokenization<a class="headerlink" href="#id180" title="此标题的永久链接">¶</a></h5>
<p>src[i] 是源语言（此处为英语）的文本序列中的标记列表， tgt[i] 是目标语言（此处为法语）的标记列表:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">MTFraEng</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">max_examples</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">src</span><span class="p">,</span> <span class="n">tgt</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">max_examples</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="n">max_examples</span><span class="p">:</span> <span class="k">break</span>
        <span class="n">parts</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parts</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="c1"># Skip empty tokens</span>
            <span class="n">src</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">t</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">parts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1"> &lt;eos&gt;&#39;</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span> <span class="k">if</span> <span class="n">t</span><span class="p">])</span>
            <span class="n">tgt</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">t</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">parts</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1"> &lt;eos&gt;&#39;</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span> <span class="k">if</span> <span class="n">t</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">src</span><span class="p">,</span> <span class="n">tgt</span>

<span class="n">src</span><span class="p">,</span> <span class="n">tgt</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="n">src</span><span class="p">[:</span><span class="mi">6</span><span class="p">],</span> <span class="n">tgt</span><span class="p">[:</span><span class="mi">6</span><span class="p">]</span>
<span class="c1"># 输出</span>
<span class="p">([[</span><span class="s1">&#39;go&#39;</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;eos&gt;&#39;</span><span class="p">],</span>
  <span class="p">[</span><span class="s1">&#39;hi&#39;</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;eos&gt;&#39;</span><span class="p">],</span>
  <span class="p">[</span><span class="s1">&#39;run&#39;</span><span class="p">,</span> <span class="s1">&#39;!&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;eos&gt;&#39;</span><span class="p">],</span>
  <span class="p">[</span><span class="s1">&#39;run&#39;</span><span class="p">,</span> <span class="s1">&#39;!&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;eos&gt;&#39;</span><span class="p">],</span>
  <span class="p">[</span><span class="s1">&#39;who&#39;</span><span class="p">,</span> <span class="s1">&#39;?&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;eos&gt;&#39;</span><span class="p">],</span>
  <span class="p">[</span><span class="s1">&#39;wow&#39;</span><span class="p">,</span> <span class="s1">&#39;!&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;eos&gt;&#39;</span><span class="p">]],</span>
 <span class="p">[[</span><span class="s1">&#39;va&#39;</span><span class="p">,</span> <span class="s1">&#39;!&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;eos&gt;&#39;</span><span class="p">],</span>
  <span class="p">[</span><span class="s1">&#39;salut&#39;</span><span class="p">,</span> <span class="s1">&#39;!&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;eos&gt;&#39;</span><span class="p">],</span>
  <span class="p">[</span><span class="s1">&#39;cours&#39;</span><span class="p">,</span> <span class="s1">&#39;!&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;eos&gt;&#39;</span><span class="p">],</span>
  <span class="p">[</span><span class="s1">&#39;courez&#39;</span><span class="p">,</span> <span class="s1">&#39;!&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;eos&gt;&#39;</span><span class="p">],</span>
  <span class="p">[</span><span class="s1">&#39;qui&#39;</span><span class="p">,</span> <span class="s1">&#39;?&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;eos&gt;&#39;</span><span class="p">],</span>
  <span class="p">[</span><span class="s1">&#39;ça&#39;</span><span class="p">,</span> <span class="s1">&#39;alors&#39;</span><span class="p">,</span> <span class="s1">&#39;!&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;eos&gt;&#39;</span><span class="p">]])</span>
</pre></div>
</div>
</section>
<section id="loading-sequences-of-fixed-length">
<h5>10.5.3. Loading Sequences of Fixed Length<a class="headerlink" href="#loading-sequences-of-fixed-length" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">MTFraEng</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span> <span class="n">num_train</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">num_val</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MTFraEng</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">arrays</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">src_vocab</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tgt_vocab</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_arrays</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_download</span><span class="p">())</span>

<span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">MTFraEng</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_build_arrays</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">raw_text</span><span class="p">,</span> <span class="n">src_vocab</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tgt_vocab</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_build_array</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">is_tgt</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">pad_or_trim</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">seq</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="p">(</span>
            <span class="n">seq</span><span class="p">[:</span><span class="n">t</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">t</span> <span class="k">else</span> <span class="n">seq</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">t</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">seq</span><span class="p">)))</span>
        <span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="n">pad_or_trim</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_steps</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">is_tgt</span><span class="p">:</span>
            <span class="n">sentences</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;&lt;bos&gt;&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">s</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">vocab</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">vocab</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Vocab</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">min_freq</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">array</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">vocab</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">])</span>
        <span class="n">valid_len</span> <span class="o">=</span> <span class="p">(</span><span class="n">array</span> <span class="o">!=</span> <span class="n">vocab</span><span class="p">[</span><span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">array</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">valid_len</span>
    <span class="n">src</span><span class="p">,</span> <span class="n">tgt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_preprocess</span><span class="p">(</span><span class="n">raw_text</span><span class="p">),</span>
                              <span class="bp">self</span><span class="o">.</span><span class="n">num_train</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_val</span><span class="p">)</span>
    <span class="n">src_array</span><span class="p">,</span> <span class="n">src_vocab</span><span class="p">,</span> <span class="n">src_valid_len</span> <span class="o">=</span> <span class="n">_build_array</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">src_vocab</span><span class="p">)</span>
    <span class="n">tgt_array</span><span class="p">,</span> <span class="n">tgt_vocab</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_build_array</span><span class="p">(</span><span class="n">tgt</span><span class="p">,</span> <span class="n">tgt_vocab</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">((</span><span class="n">src_array</span><span class="p">,</span> <span class="n">tgt_array</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">src_valid_len</span><span class="p">,</span> <span class="n">tgt_array</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]),</span>
            <span class="n">src_vocab</span><span class="p">,</span> <span class="n">tgt_vocab</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id181">
<h5>10.5.4. Reading the Dataset<a class="headerlink" href="#id181" title="此标题的永久链接">¶</a></h5>
<p>定义 get_dataloader 方法来返回数据迭代器:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">MTFraEng</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train</span><span class="p">):</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_train</span><span class="p">)</span> <span class="k">if</span> <span class="n">train</span> <span class="k">else</span> <span class="nb">slice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_train</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_tensorloader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">arrays</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span>
</pre></div>
</div>
<p>读取英语-法语数据集中的第一个小批量:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">MTFraEng</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">src</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">src_valid_len</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;source:&#39;</span><span class="p">,</span> <span class="n">src</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;decoder input:&#39;</span><span class="p">,</span> <span class="n">tgt</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;source len excluding pad:&#39;</span><span class="p">,</span> <span class="n">src_valid_len</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;label:&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
<span class="c1"># 输出</span>
<span class="n">source</span><span class="p">:</span> <span class="n">tensor</span><span class="p">([</span>
        <span class="p">[</span><span class="mi">117</span><span class="p">,</span> <span class="mi">182</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">3</span><span class="p">,</span>   <span class="mi">4</span><span class="p">,</span>   <span class="mi">4</span><span class="p">,</span>   <span class="mi">4</span><span class="p">,</span>   <span class="mi">4</span><span class="p">,</span>   <span class="mi">4</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">62</span><span class="p">,</span>  <span class="mi">72</span><span class="p">,</span>   <span class="mi">2</span><span class="p">,</span>   <span class="mi">3</span><span class="p">,</span>   <span class="mi">4</span><span class="p">,</span>   <span class="mi">4</span><span class="p">,</span>   <span class="mi">4</span><span class="p">,</span>   <span class="mi">4</span><span class="p">,</span>   <span class="mi">4</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">57</span><span class="p">,</span> <span class="mi">124</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">3</span><span class="p">,</span>   <span class="mi">4</span><span class="p">,</span>   <span class="mi">4</span><span class="p">,</span>   <span class="mi">4</span><span class="p">,</span>   <span class="mi">4</span><span class="p">,</span>   <span class="mi">4</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">decoder</span> <span class="nb">input</span><span class="p">:</span> <span class="n">tensor</span><span class="p">([</span>
        <span class="p">[</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">37</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span>  <span class="mi">58</span><span class="p">,</span> <span class="mi">160</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">4</span><span class="p">,</span>   <span class="mi">5</span><span class="p">,</span>   <span class="mi">5</span><span class="p">],</span>
        <span class="p">[</span>  <span class="mi">3</span><span class="p">,</span>   <span class="mi">6</span><span class="p">,</span>   <span class="mi">2</span><span class="p">,</span>   <span class="mi">4</span><span class="p">,</span>   <span class="mi">5</span><span class="p">,</span>   <span class="mi">5</span><span class="p">,</span>   <span class="mi">5</span><span class="p">,</span>   <span class="mi">5</span><span class="p">,</span>   <span class="mi">5</span><span class="p">],</span>
        <span class="p">[</span>  <span class="mi">3</span><span class="p">,</span> <span class="mi">180</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">4</span><span class="p">,</span>   <span class="mi">5</span><span class="p">,</span>   <span class="mi">5</span><span class="p">,</span>   <span class="mi">5</span><span class="p">,</span>   <span class="mi">5</span><span class="p">,</span>   <span class="mi">5</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">source</span> <span class="nb">len</span> <span class="n">excluding</span> <span class="n">pad</span><span class="p">:</span> <span class="n">tensor</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">label</span><span class="p">:</span> <span class="n">tensor</span><span class="p">([</span>
        <span class="p">[</span> <span class="mi">37</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span>  <span class="mi">58</span><span class="p">,</span> <span class="mi">160</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">4</span><span class="p">,</span>   <span class="mi">5</span><span class="p">,</span>   <span class="mi">5</span><span class="p">,</span>   <span class="mi">5</span><span class="p">],</span>
        <span class="p">[</span>  <span class="mi">6</span><span class="p">,</span>   <span class="mi">2</span><span class="p">,</span>   <span class="mi">4</span><span class="p">,</span>   <span class="mi">5</span><span class="p">,</span>   <span class="mi">5</span><span class="p">,</span>   <span class="mi">5</span><span class="p">,</span>   <span class="mi">5</span><span class="p">,</span>   <span class="mi">5</span><span class="p">,</span>   <span class="mi">5</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">180</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">4</span><span class="p">,</span>   <span class="mi">5</span><span class="p">,</span>   <span class="mi">5</span><span class="p">,</span>   <span class="mi">5</span><span class="p">,</span>   <span class="mi">5</span><span class="p">,</span>   <span class="mi">5</span><span class="p">,</span>   <span class="mi">5</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">MTFraEng</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src_sentences</span><span class="p">,</span> <span class="n">tgt_sentences</span><span class="p">):</span>
    <span class="n">raw_text</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">src</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="n">tgt</span> <span class="k">for</span> <span class="n">src</span><span class="p">,</span> <span class="n">tgt</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
        <span class="n">src_sentences</span><span class="p">,</span> <span class="n">tgt_sentences</span><span class="p">)])</span>
    <span class="n">arrays</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_arrays</span><span class="p">(</span>
        <span class="n">raw_text</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">src_vocab</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tgt_vocab</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">arrays</span>

<span class="n">src</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span>  <span class="n">_</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">build</span><span class="p">([</span><span class="s1">&#39;hi .&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;salut .&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;source:&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">src_vocab</span><span class="o">.</span><span class="n">to_tokens</span><span class="p">(</span><span class="n">src</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;target:&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">tgt_vocab</span><span class="o">.</span><span class="n">to_tokens</span><span class="p">(</span><span class="n">tgt</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)))</span>
<span class="c1"># 输出</span>
<span class="n">source</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;hi&#39;</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;eos&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">]</span>
<span class="n">target</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;&lt;bos&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;salut&#39;</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;eos&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">]</span>
</pre></div>
</div>
</section>
<section id="id182">
<h5>10.5.5. Summary<a class="headerlink" href="#id182" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>在自然语言处理中，机器翻译是指将源语言中表示文本字符串的序列自动映射到目标语言中表示合理翻译的字符串的任务。</p></li>
<li><p>使用单词级标记化，词汇量将明显大于使用字符级标记化，但序列长度会短得多。</p></li>
<li><p>为了减轻词汇量过大的影响，我们可以将不常见的标记视为一些“未知”标记。</p></li>
<li><p>我们可以截断和填充文本序列，以便所有文本序列都具有相同的长度以小批量加载。</p></li>
<li><p>现代实现通常对具有相似长度的序列进行存储，以避免在填充上浪费过多的计算。</p></li>
</ul>
</section>
</section>
<section id="the-encoderdecoder-architecture">
<h4>10.6. The Encoder–Decoder Architecture<a class="headerlink" href="#the-encoderdecoder-architecture" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>在一般的序列到序列问题中，例如机器翻译，输入和输出的长度不同且未对齐。</p></li>
<li><p>处理此类数据的标准方法是设计一个编码器-解码器架构</p></li>
<li><p>该架构由两个主要组件组成： 将可变长度序列作为输入的编码器，以及解码器充当条件语言模型，接收编码输入和目标序列的左侧上下文，并预测目标序列中的后续标记。</p></li>
<li><p>目标：通过将输入序列编码为固定形状的状态，再解码为输出序列，解决输入输出不对齐的问题。</p></li>
</ul>
<figure class="align-default" id="id253">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/P6Mywo.png" src="https://img.zhaoweiguo.com/uPic/2025/01/P6Mywo.png" />
<figcaption>
<p><span class="caption-text">Fig. 10.6.1 The encoder–decoder architecture.</span><a class="headerlink" href="#id253" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<section id="encoder">
<h5>10.6.1. Encoder<a class="headerlink" href="#encoder" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The base encoder interface for the encoder--decoder architecture.&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="c1"># Later there can be additional arguments (e.g., length excluding padding)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</pre></div>
</div>
<ul class="simple">
<li><dl class="simple">
<dt>Encoder 接口</dt><dd><ul>
<li><p>功能：接收输入序列（X），并将其转换为固定形状的状态。</p></li>
<li><p>方法：forward 或 call，由继承类实现具体逻辑。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="decoder">
<h5>10.6.2. Decoder<a class="headerlink" href="#decoder" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The base decoder interface for the encoder--decoder architecture.&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="c1"># Later there can be additional arguments (e.g., length excluding padding)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_all_outputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</pre></div>
</div>
<ul class="simple">
<li><dl class="simple">
<dt>Decoder 接口</dt><dd><ul>
<li><dl class="simple">
<dt>功能：</dt><dd><ul>
<li><p>初始化状态：将编码器的输出转换为解码器的初始状态。</p></li>
<li><p>序列生成：基于初始状态和当前输入（如上一步生成的词），逐步生成目标序列。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>方法：</dt><dd><ul>
<li><p>init_state：初始化状态。</p></li>
<li><p>forward 或 call：处理输入并生成输出。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="putting-the-encoder-and-decoder-together">
<h5>10.6.3. Putting the Encoder and Decoder Together<a class="headerlink" href="#putting-the-encoder-and-decoder-together" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">EncoderDecoder</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Classifier</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The base class for the encoder--decoder architecture.&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_X</span><span class="p">,</span> <span class="n">dec_X</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="n">enc_all_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">enc_X</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>
        <span class="n">dec_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">init_state</span><span class="p">(</span><span class="n">enc_all_outputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>
        <span class="c1"># Return decoder output only</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">dec_X</span><span class="p">,</span> <span class="n">dec_state</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</section>
<section id="id183">
<h5>10.6.4. Summary<a class="headerlink" href="#id183" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>编码器-解码器架构可以处理由可变长度序列组成的输入和输出，因此适用于序列到序列的问题，例如机器翻译。</p></li>
<li><p>编码器将可变长度序列作为输入，并将其转换为具有固定形状的状态。解码器将固定形状的编码状态映射到可变长度序列。</p></li>
<li><dl class="simple">
<dt>架构的优点</dt><dd><ul>
<li><p>适应性强：适用于任意长度的输入输出序列。</p></li>
<li><p>基础性：是后续复杂序列模型（如基于 RNN 的序列模型）的基础。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
</section>
<section id="sequence-to-sequence-learning-for-machine-translation">
<h4>10.7. Sequence-to-Sequence Learning for Machine Translation<a class="headerlink" href="#sequence-to-sequence-learning-for-machine-translation" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>在本节中，我们将演示编码器-解码器架构在机器翻译任务中的应用，其中编码器和解码器均实现为 RNN</p></li>
</ul>
<figure class="align-default" id="id254">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/fkaE89.png" src="https://img.zhaoweiguo.com/uPic/2025/01/fkaE89.png" />
<figcaption>
<p><span class="caption-text">Fig. 10.7.1 Sequence-to-sequence learning with an RNN encoder and an RNN decoder.</span><a class="headerlink" href="#id254" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>特点：输入和输出是长度可变的非对齐序列，例如机器翻译。</p></li>
<li><dl class="simple">
<dt>模型结构：</dt><dd><ul>
<li><p>编码器（Encoder）：RNN（如GRU）将可变长度的输入序列压缩为固定形状的隐藏状态，称为上下文变量（context variable）。</p></li>
<li><p>解码器（Decoder）：RNN从编码器生成的上下文变量和先前输出的目标序列中，逐步预测下一个输出标记。</p></li>
<li><p>注意机制的预告：未来章节会引入注意力机制，可以避免将整个输入压缩为固定长度，增强模型性能。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<section id="teacher-forcing">
<h5>10.7.1. Teacher Forcing<a class="headerlink" href="#teacher-forcing" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt>训练方法：Teacher Forcing</dt><dd><ul>
<li><p>解码器的输入为真实目标序列（即“ground truth”）的偏移版本，例如：&lt;bos&gt;、”Ils”、”regardent”、”.” 对应 “Ils”、”regardent”、”.”、&lt;eos&gt;。</p></li>
<li><p>通过这种方式，解码器始终以正确的先前标记作为输入，帮助模型更快收敛。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="id184">
<h5>10.7.2. Encoder<a class="headerlink" href="#id184" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt>接受输入序列，将每个时间步的特征向量( <span class="math notranslate nohighlight">\(\mathbf{x}_t\)</span> )和前一隐藏状态( <span class="math notranslate nohighlight">\(\mathbf{h}_{t-1}\)</span> ) 转换为当前隐藏状态( <span class="math notranslate nohighlight">\(\mathbf{h}_{t}\)</span> )。</dt><dd><ul>
<li><p>即: <span class="math notranslate nohighlight">\(\mathbf{h}_t = f(\mathbf{x}_t, \mathbf{h}_{t-1})\)</span></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>上下文变量可以是最后一个时间步的隐藏状态，或者经过自定义函数处理的所有隐藏状态。</dt><dd><ul>
<li><p>编码器通过自定义函数 q 将所有时间步的隐藏状态转换为上下文变量</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{c}=q(\mathbf{h}_1, \cdot, \mathbf{h}_T)\)</span></p></li>
</ul>
</dd>
</dl>
</li>
<li><p>可以使用单向或双向RNN，双向RNN可以捕获更多序列信息。</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">init_seq2seq</span><span class="p">(</span><span class="n">module</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialize weights for sequence-to-sequence learning.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">module</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
         <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">module</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">_flat_weights_names</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">&quot;weight&quot;</span> <span class="ow">in</span> <span class="n">param</span><span class="p">:</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">_parameters</span><span class="p">[</span><span class="n">param</span><span class="p">])</span>

<span class="k">class</span><span class="w"> </span><span class="nc">Seq2SeqEncoder</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Encoder</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The RNN encoder for sequence-to-sequence learning.&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_seq2seq</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="c1"># X shape: (batch_size, num_steps)</span>
        <span class="n">embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">t</span><span class="p">()</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span>
        <span class="c1"># embs shape: (num_steps, batch_size, embed_size)</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">embs</span><span class="p">)</span>
        <span class="c1"># outputs shape: (num_steps, batch_size, num_hiddens)</span>
        <span class="c1"># state shape: (num_layers, batch_size, num_hiddens)</span>
        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">state</span>
</pre></div>
</div>
<p>实例化一个两层 GRU 编码器，其隐藏单元数为 16。给定一个小批量序列输入 X （批量大小 =4 ；时间步数 =9 ）是一个形状张量（时间步数、批量大小、隐藏层数）单位）:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">2</span>
<span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">9</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">Seq2SeqEncoder</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">))</span>
<span class="n">enc_outputs</span><span class="p">,</span> <span class="n">enc_state</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">check_shape</span><span class="p">(</span><span class="n">enc_outputs</span><span class="p">,</span> <span class="p">(</span><span class="n">num_steps</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="id185">
<h5>10.7.3. Decoder<a class="headerlink" href="#id185" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt>输入包括先前时间步的输出序列( <span class="math notranslate nohighlight">\(y_1, y_2, \cdot, y_{T'}\)</span> )、上下文变量( <span class="math notranslate nohighlight">\(\mathbf{c}\)</span> )和前一隐藏状态( <span class="math notranslate nohighlight">\(\mathbf{s}_{t'}\)</span> )。</dt><dd><ul>
<li><p>用一个函数 g() 来表达解码器隐藏层的变换</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{s}_{t'} = g(y_{t'-1}, \mathbf{c}, \mathbf{s}_{t'-1})\)</span></p></li>
</ul>
</dd>
</dl>
</li>
<li><p>计算出新的隐藏状态后，通过softmax计算输出标记 <span class="math notranslate nohighlight">\(t'+1\)</span> 的预测分布 <span class="math notranslate nohighlight">\(p(y_{t^{\prime}+1} \mid y_1, \ldots, y_{t^\prime}, \mathbf{c})\)</span> 。</p></li>
<li><p>通常，解码器的初始隐藏状态由编码器的最终隐藏状态初始化。</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Seq2SeqDecoder</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Decoder</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The RNN decoder for sequence to sequence learning.&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span>
                 <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">embed_size</span><span class="o">+</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_seq2seq</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_all_outputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">enc_all_outputs</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="c1"># X shape: (batch_size, num_steps)</span>
        <span class="c1"># embs shape: (num_steps, batch_size, embed_size)</span>
        <span class="n">embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">t</span><span class="p">()</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
        <span class="n">enc_output</span><span class="p">,</span> <span class="n">hidden_state</span> <span class="o">=</span> <span class="n">state</span>
        <span class="c1"># context shape: (batch_size, num_hiddens)</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">enc_output</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># Broadcast context to (num_steps, batch_size, num_hiddens)</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">embs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># Concat at the feature dimension</span>
        <span class="n">embs_and_context</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">embs</span><span class="p">,</span> <span class="n">context</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="n">hidden_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">embs_and_context</span><span class="p">,</span> <span class="n">hidden_state</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># outputs shape: (batch_size, num_steps, vocab_size)</span>
        <span class="c1"># hidden_state shape: (num_layers, batch_size, num_hiddens)</span>
        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="p">[</span><span class="n">enc_output</span><span class="p">,</span> <span class="n">hidden_state</span><span class="p">]</span>
</pre></div>
</div>
<p>解码器的输出形状变为（批量大小、时间步数、词汇大小），其中张量的最终维度存储预测的标记分布:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">decoder</span> <span class="o">=</span> <span class="n">Seq2SeqDecoder</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">)</span>
<span class="n">state</span> <span class="o">=</span> <span class="n">decoder</span><span class="o">.</span><span class="n">init_state</span><span class="p">(</span><span class="n">encoder</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="n">dec_outputs</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">check_shape</span><span class="p">(</span><span class="n">dec_outputs</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">))</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">check_shape</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">))</span>
</pre></div>
</div>
<figure class="align-default" id="id255">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/gsE5N1.png" src="https://img.zhaoweiguo.com/uPic/2025/01/gsE5N1.png" />
<figcaption>
<p><span class="caption-text">Fig. 10.7.2 Layers in an RNN encoder–decoder model.</span><a class="headerlink" href="#id255" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
</section>
<section id="encoderdecoder-for-sequence-to-sequence-learning">
<h5>10.7.4. Encoder–Decoder for Sequence-to-Sequence Learning<a class="headerlink" href="#encoderdecoder-for-sequence-to-sequence-learning" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Seq2Seq</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">EncoderDecoder</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The RNN encoder--decoder for sequence to sequence learning.&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">tgt_pad</span><span class="p">,</span> <span class="n">lr</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="n">Y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="o">*</span><span class="n">batch</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">Y_hat</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Adam optimizer is used here</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="loss-function-with-masking">
<h5>10.7.5. Loss Function with Masking<a class="headerlink" href="#loss-function-with-masking" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">Seq2Seq</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Y_hat</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
    <span class="n">l</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">Seq2Seq</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">Y_hat</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">averaged</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tgt_pad</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">l</span> <span class="o">*</span> <span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
<ul class="simple">
<li><p>使用交叉熵损失函数，排除填充标记（padding tokens）的计算以避免对模型优化的干扰。</p></li>
<li><p>掩码机制通过将无关位置设置为零实现。</p></li>
</ul>
</section>
<section id="id186">
<h5>10.7.6. Training<a class="headerlink" href="#id186" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">MTFraEng</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
<span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.2</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">Seq2SeqEncoder</span><span class="p">(</span>
    <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">src_vocab</span><span class="p">),</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">Seq2SeqDecoder</span><span class="p">(</span>
    <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">tgt_vocab</span><span class="p">),</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Seq2Seq</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">tgt_pad</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">tgt_vocab</span><span class="p">[</span><span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">],</span>
                <span class="n">lr</span><span class="o">=</span><span class="mf">0.005</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">gradient_clip_val</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id187">
<h5>10.7.7. Prediction<a class="headerlink" href="#id187" title="此标题的永久链接">¶</a></h5>
<figure class="align-default" id="id256">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/zNoJ2d.png" src="https://img.zhaoweiguo.com/uPic/2025/01/zNoJ2d.png" />
<figcaption>
<p><span class="caption-text">Fig. 10.7.3 Predicting the output sequence token by token using an RNN encoder–decoder.</span><a class="headerlink" href="#id256" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><dl class="simple">
<dt>预测方法</dt><dd><ul>
<li><p>解码器在测试时基于已预测的标记作为输入逐步生成输出，直到预测到结束标记&lt;eos&gt;。</p></li>
<li><p>流程如图所示，逐个标记预测，直到序列结束。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">EncoderDecoder</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">predict_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">save_attention_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">]</span>
    <span class="n">src</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">src_valid_len</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">batch</span>
    <span class="n">enc_all_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">src_valid_len</span><span class="p">)</span>
    <span class="n">dec_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">init_state</span><span class="p">(</span><span class="n">enc_all_outputs</span><span class="p">,</span> <span class="n">src_valid_len</span><span class="p">)</span>
    <span class="n">outputs</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">tgt</span><span class="p">[:,</span> <span class="p">(</span><span class="mi">0</span><span class="p">)]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="p">],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_steps</span><span class="p">):</span>
        <span class="n">Y</span><span class="p">,</span> <span class="n">dec_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dec_state</span><span class="p">)</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="c1"># Save attention weights (to be covered later)</span>
        <span class="k">if</span> <span class="n">save_attention_weights</span><span class="p">:</span>
            <span class="n">attention_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">attention_weights</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">attention_weights</span>
</pre></div>
</div>
</section>
<section id="evaluation-of-predicted-sequences">
<h5>10.7.8. Evaluation of Predicted Sequences<a class="headerlink" href="#evaluation-of-predicted-sequences" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><dl class="simple">
<dt>BLEU: Bilingual Evaluation Understudy</dt><dd><ul>
<li><p>测量预测序列与目标序列之间的匹配度，基于 <cite>n-gram</cite> 的精确度计算。</p></li>
<li><dl class="simple">
<dt>权重机制：</dt><dd><ul>
<li><p>匹配更长的 <cite>n-gram</cite> 赋予更高权重。</p></li>
<li><p>短序列惩罚项防止模型生成过短的结果。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">bleu</span><span class="p">(</span><span class="n">pred_seq</span><span class="p">,</span> <span class="n">label_seq</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the BLEU.&quot;&quot;&quot;</span>
    <span class="n">pred_tokens</span><span class="p">,</span> <span class="n">label_tokens</span> <span class="o">=</span> <span class="n">pred_seq</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">),</span> <span class="n">label_seq</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span>
    <span class="n">len_pred</span><span class="p">,</span> <span class="n">len_label</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred_tokens</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">label_tokens</span><span class="p">)</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">len_label</span> <span class="o">/</span> <span class="n">len_pred</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">len_pred</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">num_matches</span><span class="p">,</span> <span class="n">label_subs</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">collections</span><span class="o">.</span><span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">len_label</span> <span class="o">-</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">label_subs</span><span class="p">[</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">label_tokens</span><span class="p">[</span><span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">n</span><span class="p">])]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">len_pred</span> <span class="o">-</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">label_subs</span><span class="p">[</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pred_tokens</span><span class="p">[</span><span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">n</span><span class="p">])]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">num_matches</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">label_subs</span><span class="p">[</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pred_tokens</span><span class="p">[</span><span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">n</span><span class="p">])]</span> <span class="o">-=</span> <span class="mi">1</span>
        <span class="n">score</span> <span class="o">*=</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">num_matches</span> <span class="o">/</span> <span class="p">(</span><span class="n">len_pred</span> <span class="o">-</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">score</span>
</pre></div>
</div>
<p>示例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">engs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;go .&#39;</span><span class="p">,</span> <span class="s1">&#39;i lost .&#39;</span><span class="p">,</span> <span class="s1">&#39;he</span><span class="se">\&#39;</span><span class="s1">s calm .&#39;</span><span class="p">,</span> <span class="s1">&#39;i</span><span class="se">\&#39;</span><span class="s1">m home .&#39;</span><span class="p">]</span>
<span class="n">fras</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;va !&#39;</span><span class="p">,</span> <span class="s1">&#39;j</span><span class="se">\&#39;</span><span class="s1">ai perdu .&#39;</span><span class="p">,</span> <span class="s1">&#39;il est calme .&#39;</span><span class="p">,</span> <span class="s1">&#39;je suis chez moi .&#39;</span><span class="p">]</span>
<span class="n">preds</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_step</span><span class="p">(</span>
    <span class="n">data</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">engs</span><span class="p">,</span> <span class="n">fras</span><span class="p">),</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">(),</span> <span class="n">data</span><span class="o">.</span><span class="n">num_steps</span><span class="p">)</span>
<span class="k">for</span> <span class="n">en</span><span class="p">,</span> <span class="n">fr</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">engs</span><span class="p">,</span> <span class="n">fras</span><span class="p">,</span> <span class="n">preds</span><span class="p">):</span>
    <span class="n">translation</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">tgt_vocab</span><span class="o">.</span><span class="n">to_tokens</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">token</span> <span class="o">==</span> <span class="s1">&#39;&lt;eos&gt;&#39;</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="n">translation</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">en</span><span class="si">}</span><span class="s1"> =&gt; </span><span class="si">{</span><span class="n">translation</span><span class="si">}</span><span class="s1">, bleu,&#39;</span>
          <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">bleu</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">translation</span><span class="p">),</span><span class="w"> </span><span class="n">fr</span><span class="p">,</span><span class="w"> </span><span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># 输出</span>
<span class="n">go</span> <span class="o">.</span> <span class="o">=&gt;</span> <span class="p">[</span><span class="s1">&#39;va&#39;</span><span class="p">,</span> <span class="s1">&#39;!&#39;</span><span class="p">],</span> <span class="n">bleu</span><span class="p">,</span><span class="mf">1.000</span>
<span class="n">i</span> <span class="n">lost</span> <span class="o">.</span> <span class="o">=&gt;</span> <span class="p">[</span><span class="s2">&quot;j&#39;ai&quot;</span><span class="p">,</span> <span class="s1">&#39;perdu&#39;</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">],</span> <span class="n">bleu</span><span class="p">,</span><span class="mf">1.000</span>
<span class="n">he</span><span class="s1">&#39;s calm . =&gt; [&#39;</span><span class="n">elle</span><span class="s1">&#39;, &#39;</span><span class="n">court</span><span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="s1">&#39;], bleu,0.000</span>
<span class="n">i</span><span class="s1">&#39;m home . =&gt; [&#39;</span><span class="n">je</span><span class="s1">&#39;, &#39;</span><span class="n">suis</span><span class="s1">&#39;, &#39;</span><span class="n">chez</span><span class="s1">&#39;, &#39;</span><span class="n">moi</span><span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="s1">&#39;], bleu,1.000</span>
</pre></div>
</div>
</section>
</section>
<section id="beam-search">
<h4>10.8. Beam Search<a class="headerlink" href="#beam-search" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>在序列生成任务中使用的三种搜索策略：贪婪搜索（Greedy Search）、穷举搜索（Exhaustive Search）和束搜索（Beam Search）。</p></li>
<li><p>前面章节只提到了贪婪策略</p></li>
</ul>
<section id="greedy-search">
<h5>10.8.1. Greedy Search<a class="headerlink" href="#greedy-search" title="此标题的永久链接">¶</a></h5>
<div class="math notranslate nohighlight">
\[y_{t'} = \operatorname*{argmax}_{y \in \mathcal{Y}} P(y \mid y_1, \ldots, y_{t'-1}, \mathbf{c})\]</div>
<ul class="simple">
<li><p>在任何时间步骤 t’ ，我们只需从 y 中选择条件概率最高的标记</p></li>
</ul>
<figure class="align-default" id="id257">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/bOIFny.png" src="https://img.zhaoweiguo.com/uPic/2025/01/bOIFny.png" />
<figcaption>
<p><span class="caption-text">Fig. 10.8.1 At each time step, greedy search selects the token with the highest conditional probability.</span><a class="headerlink" href="#id257" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>在每个时间步，贪婪搜索都会选择条件概率最高的标记。因此，将预测输出序列“A”、“B”、“C”和“”（图10.8.1）。该输出序列的条件概率为 <span class="math notranslate nohighlight">\(0.5\times0.4\times0.4\times0.6 = 0.048\)</span></p></li>
</ul>
<figure class="align-default" id="id258">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/88RudG.png" src="https://img.zhaoweiguo.com/uPic/2025/01/88RudG.png" />
<figcaption>
<p><span class="caption-text">Fig. 10.8.2 The four numbers under each time step represent the conditional probabilities of generating “A”, “B”, “C”, and “&lt;eos&gt;” at that time step. At time step 2, the token “C”, which has the second highest conditional probability, is selected.</span><a class="headerlink" href="#id258" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>输出序列“A”、“C”、“B”、“”的条件概率为 <span class="math notranslate nohighlight">\(0.5\times0.3 \times0.6\times0.6=0.054\)</span> ，大于图 10.8.1 中的贪心搜索。在本例中，贪心搜索得到的输出序列“A”、“B”、“C”和“”不是最优的。</p></li>
</ul>
</section>
<section id="exhaustive-search">
<h5>10.8.2. Exhaustive Search<a class="headerlink" href="#exhaustive-search" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>枚举所有可能的输出序列及其条件概率，然后输出预测概率最高的序列。</p></li>
<li><p>它会带来令人望而却步的计算成本 <span class="math notranslate nohighlight">\(\mathcal{O}(\left|\mathcal{Y}\right|^{T'})\)</span> ，序列长度呈指数级增长，并且词汇量大小给定了巨大的基础。</p></li>
<li><p>例如，当 <span class="math notranslate nohighlight">\(|\mathcal{Y}|=10000\)</span> 和 <span class="math notranslate nohighlight">\(T'=10\)</span> 与实际应用中的数字相比都较小时，我们需要评估 <span class="math notranslate nohighlight">\(10000^10 = 10^40\)</span> 序列，这已经超出了任何可预见的计算机的能力。</p></li>
<li><p>另一方面，贪婪搜索的计算成本是 <span class="math notranslate nohighlight">\(\mathcal{O}(\left|\mathcal{Y}\right|{T'})\)</span> ：非常便宜，但远非最优。</p></li>
<li><p>例如，当  <span class="math notranslate nohighlight">\(|\mathcal{Y}|=10000\)</span> 和 <span class="math notranslate nohighlight">\(T'=10\)</span> 时，我们只需要评估 <span class="math notranslate nohighlight">\(10000 \times 10 = 10^5\)</span> 序列。</p></li>
</ul>
</section>
<section id="id188">
<h5>10.8.3. Beam Search<a class="headerlink" href="#id188" title="此标题的永久链接">¶</a></h5>
<figure class="align-default" id="id259">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/0Juc3f.png" src="https://img.zhaoweiguo.com/uPic/2025/01/0Juc3f.png" />
<figcaption>
<p><span class="caption-text">Fig. 10.8.3 The process of beam search (beam size =2; maximum length of an output sequence =3). The candidate output sequences are A, C, AB, CE, ABD, and CED.</span><a class="headerlink" href="#id259" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>集束搜索的计算成本为 <span class="math notranslate nohighlight">\(\mathcal{O}(k\left|\mathcal{Y}\right|T')\)</span> 。这个结果介于贪婪搜索和穷举搜索之间。贪婪搜索可以被视为当波束大小设置为 1 时出现的波束搜索的特殊情况。</p></li>
</ul>
</section>
</section>
</section>
<section id="attention-mechanisms-and-transformers">
<h3>11. Attention Mechanisms and Transformers<a class="headerlink" href="#attention-mechanisms-and-transformers" title="此标题的永久链接">¶</a></h3>
<section id="queries-keys-and-values">
<h4>11.1. Queries, Keys, and Values<a class="headerlink" href="#queries-keys-and-values" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>【1. 传统网络的局限性（Fixed Input Size）】最初的神经网络（如CNN、RNN等）依赖于输入的大小是固定的，比如ImageNet中的图像大小是 <span class="math notranslate nohighlight">\(224 \times 224\)</span> 。即使在自然语言处理（NLP）中，RNN的输入大小也是固定的。这种方法在面对长度可变的输入时（如文本翻译或变长的序列）会遇到困难。特别是对于长序列，网络需要“记住”已生成或已查看的信息，这对模型的处理能力提出了较高要求。</p></li>
<li><dl class="simple">
<dt>【2. 数据库类比（Databases and Key-Value Pairs）】数据库通常包含由 <code class="docutils literal notranslate"><span class="pre">键（k）</span></code> 和 <code class="docutils literal notranslate"><span class="pre">值（v）</span></code> 组成的键值对。</dt><dd><ul>
<li><p>例如，假设有一组姓氏和名字的键值对。如果我们查询某个特定的键（如“Li”），我们会得到相应的值（“Mu”）。这里的 <code class="docutils literal notranslate"><span class="pre">查询（q）</span></code> 可以返回一个结果，也可以返回多个近似结果，具体取决于数据库中的内容。</p></li>
<li><dl class="simple">
<dt>重要的概念：</dt><dd><ul>
<li><p>查询可以不依赖于数据库的大小，这表明深度学习模型可以扩展到较大的数据集。</p></li>
<li><p>查询可以得到不同的答案，这与深度学习中的模型预测类似。</p></li>
<li><p>操作不需要对数据库进行复杂的压缩或简化。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
<li><p>【3. 引入注意力机制（Attention Mechanism）】随着深度学习的发展，注意力机制作为一个非常有用的工具被引入。它模拟了查询与一组键值对之间的关系，允许模型在进行决策时重点关注重要的键（ <code class="docutils literal notranslate"><span class="pre">k</span></code> ）及其对应的值（ <code class="docutils literal notranslate"><span class="pre">v</span></code> ）。</p></li>
<li><p>具体来说，注意力机制定义如下：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\textrm{Attention}(\mathbf{q}, \mathcal{D}) \stackrel{\textrm{def}}{=} \sum_{i=1}^m \alpha(\mathbf{q}, \mathbf{k}_i) \mathbf{v}_i\]</div>
<ul class="simple">
<li><p>这里的 <span class="math notranslate nohighlight">\(\alpha(\mathbf{q}, \mathbf{k}_i)\)</span> 是注意力权重，表示查询与每个键的相关性，而这些权重决定了对应值的重要性。</p></li>
<li><dl class="simple">
<dt>【4. 不同的权重分配方法（Weighting Mechanisms）】几种常见的权重分配方式：</dt><dd><ul>
<li><p>非负权重：权重 <span class="math notranslate nohighlight">\(\alpha(\mathbf{q}, \mathbf{k}_i)\)</span> 是非负的，这意味着结果是在值的凸锥中。</p></li>
<li><p>归一化权重：权重 <span class="math notranslate nohighlight">\(\alpha(\mathbf{q}, \mathbf{k}_i)\)</span> 形成一个凸组合，即所有权重之和为1。这是深度学习中最常见的设置。</p></li>
<li><p>精确匹配：只有一个权重为1，其余为0，这类似于传统的数据库查询。</p></li>
<li><p>平均池化：所有权重相等，这相当于对整个数据库进行平均池化。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<figure class="align-default" id="id260">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/GdvkVn.png" src="https://img.zhaoweiguo.com/uPic/2025/01/GdvkVn.png" />
<figcaption>
<p><span class="caption-text">Fig. 11.1.1 The attention mechanism computes a linear combination over values <span class="math notranslate nohighlight">\(\mathbf{v}_i\)</span> via attention pooling, where weights are derived according to the compatibility between a query <span class="math notranslate nohighlight">\(\mathbf{q}\)</span> and keys <span class="math notranslate nohighlight">\(\mathbf{k}_i\)</span></span><a class="headerlink" href="#id260" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<section id="visualization">
<h5>11.1.1. Visualization<a class="headerlink" href="#visualization" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>注意力机制的一个优势是其直观性，尤其是在权重为非负并且总和为1时。</p></li>
<li><p>通过观察注意力权重的分布，我们可以理解哪些部分对模型的预测最为重要。</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">show_heatmaps</span><span class="p">(</span><span class="n">matrices</span><span class="p">,</span> <span class="n">xlabel</span><span class="p">,</span> <span class="n">ylabel</span><span class="p">,</span> <span class="n">titles</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">),</span>
                  <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Reds&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Show heatmaps of matrices.&quot;&quot;&quot;</span>
    <span class="n">d2l</span><span class="o">.</span><span class="n">use_svg_display</span><span class="p">()</span>
    <span class="n">num_rows</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">matrices</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">num_rows</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">,</span>
                                 <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">squeeze</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">row_axes</span><span class="p">,</span> <span class="n">row_matrices</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="n">matrices</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">matrix</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">row_axes</span><span class="p">,</span> <span class="n">row_matrices</span><span class="p">)):</span>
            <span class="n">pcm</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">matrix</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">num_rows</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">xlabel</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">ylabel</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">titles</span><span class="p">:</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">titles</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">pcm</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">,</span> <span class="n">shrink</span><span class="o">=</span><span class="mf">0.6</span><span class="p">);</span>
</pre></div>
</div>
<p>使用:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">attention_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">show_heatmaps</span><span class="p">(</span><span class="n">attention_weights</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Keys&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Queries&#39;</span><span class="p">)</span>
</pre></div>
</div>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/8nu6AD.png" src="https://img.zhaoweiguo.com/uPic/2025/01/8nu6AD.png" />
</figure>
</section>
<section id="id189">
<h5>11.1.2. Summary<a class="headerlink" href="#id189" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>到目前为止，我们的讨论非常抽象，只是描述了一种池化数据的方法。</p></li>
<li><p>我们还没有解释这些神秘的查询、键和值可能从何而来。</p></li>
<li><p>一些直觉可能会有所帮助：例如，在回归设置中，查询可能对应于应执行回归的位置。键是观察过去数据的位置，值是（回归）值本身。</p></li>
</ul>
</section>
</section>
<section id="attention-pooling-by-similarity">
<h4>11.2. Attention Pooling by Similarity<a class="headerlink" href="#attention-pooling-by-similarity" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>Nadaraya–Watson estimators的核心依赖于一些将查询 <strong>q</strong> 与键 <strong>k</strong> 相关联的相似性内核 <span class="math notranslate nohighlight">\(\alpha(\mathbf{q}, \mathbf{k})\)</span></p></li>
<li><p>一些常见的内核：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\alpha(\mathbf{q}, \mathbf{k}) &amp; = \exp\left(-\frac{1}{2} \|\mathbf{q} - \mathbf{k}\|^2 \right) &amp;&amp; \textrm{Gaussian;} \\
\alpha(\mathbf{q}, \mathbf{k}) &amp; = 1 \textrm{ if } \|\mathbf{q} - \mathbf{k}\| \leq 1 &amp;&amp; \textrm{Boxcar;} \\
\alpha(\mathbf{q}, \mathbf{k}) &amp; = \mathop{\mathrm{max}}\left(0, 1 - \|\mathbf{q} - \mathbf{k}\|\right) &amp;&amp; \textrm{Epanechikov.}
\end{aligned}\end{split}\]</div>
<section id="fromgpt">
<h5>核心点-fromGPT<a class="headerlink" href="#fromgpt" title="此标题的永久链接">¶</a></h5>
<section id="id190">
<h6>核心概念<a class="headerlink" href="#id190" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>【Nadaraya-Watson 核回归】：统计学方法，用于回归和分类任务。该方法通过查询点与训练数据点之间的相似度（或核函数）来计算预测值。</p></li>
<li><p>【核函数】：核函数是计算两个点（查询点和键）之间相似度的函数。高斯核给出一个平滑的、随着距离增加而衰减的相似度，而 Boxcar 核仅对在某个特定范围内的点赋予非零相似度，Epanechikov 核的效果类似，但它的截断更加柔和。</p></li>
<li><p>【与注意力机制的联系】：在机器学习模型中，特别是深度学习中，注意力机制的工作方式与此相似：它根据不同输入对当前任务的相关性赋予不同的权重。在这里，”查询”是我们想要进行预测的点，”键”是训练数据点。每个训练点的注意力权重是通过查询点与训练点的相似度来计算的，这与 Nadaraya-Watson 回归中的核函数计算方式类似。</p></li>
</ul>
</section>
<section id="id191">
<h6>关键见解<a class="headerlink" href="#id191" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>无需训练: Nadaraya-Watson 回归不需要像传统机器学习模型那样进行训练，模型通过计算查询点与训练数据点的相似度来直接做出预测。这是一种简单的、非参数化的方法，与需要学习参数的复杂神经网络模型有所不同。</p></li>
<li><p>核函数的可调性: 核函数的宽度（尤其是高斯核）对估计函数的平滑度有重要影响。更窄的核函数会导致估计结果更加敏感于局部变化，而更宽的核函数则会平滑掉噪声。</p></li>
</ul>
</section>
<section id="id192">
<h6>关键总结<a class="headerlink" href="#id192" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>早期的注意力机制: Nadaraya-Watson 回归方法是现代注意力机制的前身之一，展示了如何基于数据点之间的相似性进行加权预测。</p></li>
<li><p>简单有效的估计: 这种方法是一种简单的非参数方法，适用于回归和分类任务，尤其在数据丰富时特别有效。</p></li>
<li><p>核函数的选择: 核函数的选择，尤其是核函数宽度的设置，能显著影响模型的表现。这与现代注意力机制对注意力函数结构的敏感性类似。</p></li>
</ul>
</section>
<section id="id193">
<h6>为什么重要<a class="headerlink" href="#id193" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>这一部分非常重要，因为它将经典的统计学方法与现代深度学习中的注意力机制联系起来。通过了解注意力机制的简单起源，读者可以更清楚地理解为什么注意力机制在深度学习中如此关键，并能够理解其演化过程。</p></li>
</ul>
</section>
</section>
<section id="kernels-and-data">
<h5>11.2.1. Kernels and Data<a class="headerlink" href="#kernels-and-data" title="此标题的永久链接">¶</a></h5>
<p>本节中定义的所有内核 <span class="math notranslate nohighlight">\(\alpha(\mathbf{q}, \mathbf{k})\)</span> 都是平移和旋转不变的；也就是说，如果我们以相同的方式移动和旋转 <strong>k</strong> 和 <strong>q</strong> ，则 <span class="math notranslate nohighlight">\(\alpha\)</span> 的值保持不变。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define some kernels</span>
<span class="k">def</span><span class="w"> </span><span class="nf">gaussian</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">boxcar</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">1.0</span>

<span class="k">def</span><span class="w"> </span><span class="nf">constant</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mf">1.0</span> <span class="o">+</span> <span class="mi">0</span> <span class="o">*</span> <span class="n">x</span>

<span class="k">def</span><span class="w"> </span><span class="nf">epanechikov</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="n">kernels</span> <span class="o">=</span> <span class="p">(</span><span class="n">gaussian</span><span class="p">,</span> <span class="n">boxcar</span><span class="p">,</span> <span class="n">constant</span><span class="p">,</span> <span class="n">epanechikov</span><span class="p">)</span>
<span class="n">names</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;Gaussian&#39;</span><span class="p">,</span> <span class="s1">&#39;Boxcar&#39;</span><span class="p">,</span> <span class="s1">&#39;Constant&#39;</span><span class="p">,</span> <span class="s1">&#39;Epanechikov&#39;</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="k">for</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">kernels</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">axes</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">kernel</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/ONIbtE.png" src="https://img.zhaoweiguo.com/uPic/2025/01/ONIbtE.png" />
</figure>
</section>
<section id="attention-pooling-via-nadarayawatson-regression">
<h5>11.2.2. Attention Pooling via Nadaraya–Watson Regression<a class="headerlink" href="#attention-pooling-via-nadarayawatson-regression" title="此标题的永久链接">¶</a></h5>
<figure class="align-default" id="id261">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/lVruiE.png" src="https://img.zhaoweiguo.com/uPic/2025/01/lVruiE.png" />
<figcaption>
<p><span class="caption-text">三个非平凡核（Gaussian、Boxcar 和 Epanechikov）都会产生相当可行的估计，与真实函数相差不远。</span><a class="headerlink" href="#id261" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
</section>
<section id="adapting-attention-pooling">
<h5>11.2.3. Adapting Attention Pooling<a class="headerlink" href="#adapting-attention-pooling" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>用不同宽度的核替换高斯核。也就是说，我们可以使用 <span class="math notranslate nohighlight">\(\alpha(\mathbf{q}, \mathbf{k}) = \exp\left(-\frac{1}{2 \sigma^2} \|\mathbf{q} - \mathbf{k}\|^2 \right)\)</span> ，其中 <span class="math notranslate nohighlight">\(\sigma^2\)</span> 确定内核的宽度</p></li>
</ul>
<figure class="align-default" id="id262">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/FVri41.png" src="https://img.zhaoweiguo.com/uPic/2025/01/FVri41.png" />
<figcaption>
<p><span class="caption-text">核越窄，估计就越不平滑。同时，它能更好地适应当地的变化。</span><a class="headerlink" href="#id262" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
</section>
<section id="id194">
<h5>11.2.4. Summary<a class="headerlink" href="#id194" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>学习这个半个多世纪历史的方法的原因：首先，它是现代注意力机制最早的先驱之一。其次，它非常适合可视化。第三，同样重要的是，它展示了手工注意力机制的局限性。更好的策略是通过学习查询和键的表示来学习该机制。</p></li>
<li><p>Nadaraya – Watson内核回归是当前注意机制的早期起源。它可以直接使用，几乎没有培训或调整，无论是用于分类还是回归。注意力的重量是根据查询和钥匙之间的相似性（或距离）分配的，并且根据有多少相似观察结果。</p></li>
</ul>
</section>
</section>
<section id="attention-scoring-functions">
<h4>11.3. Attention Scoring Functions<a class="headerlink" href="#attention-scoring-functions" title="此标题的永久链接">¶</a></h4>
<figure class="align-default" id="id263">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/IS0fQU.png" src="https://img.zhaoweiguo.com/uPic/2025/01/IS0fQU.png" />
<figcaption>
<p><span class="caption-text">Computing the output of attention pooling as a weighted average of values, where weights are computed with the attention scoring function <span class="math notranslate nohighlight">\(\mathit{a}\)</span> and the softmax operation.</span><a class="headerlink" href="#id263" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<section id="id195">
<h5>核心点-fromGPT<a class="headerlink" href="#id195" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>注意力评分函数（attention scoring functions）是计算注意力权重的核心函数，通常用于加权求和输入的值（values），从而产生输出。</p></li>
<li><p>两种常见的评分函数：点积注意力（Dot Product Attention）和加法注意力（Additive Attention）</p></li>
</ul>
</section>
<section id="dot-product-attention">
<h5>11.3.1. Dot Product Attention<a class="headerlink" href="#dot-product-attention" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>高斯内核(Gaussian kernel)的注意力评分函数</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}a(\mathbf{q}, \mathbf{k}_i) \\
    = -\frac{1}{2} \|\mathbf{q} - \mathbf{k}_i\|^2  \\
    = \mathbf{q}^\top \mathbf{k}_i -\frac{1}{2} \|\mathbf{k}_i\|^2  -\frac{1}{2} \|\mathbf{q}\|^2.\end{split}\]</div>
<ul class="simple">
<li><p>点积注意力是最常用的注意力机制之一，广泛应用于现代的Transformer架构。核心思想是通过计算查询（query）与键（key）之间的点积来评估它们的相似性。这个相似性得分再通过softmax函数归一化，得到注意力权重。</p></li>
<li><p>然后，通过变形公式简化得到点积注意力的公式：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[a(\mathbf{q}, \mathbf{k}_i) = \mathbf{q}^\top \mathbf{k}_i / \sqrt{d}\]</div>
<ul class="simple">
<li><p>其中，d 是查询向量和键向量的维度。这个公式表明，点积注意力的核心是计算查询和键的标准化点积。</p></li>
<li><p>最终，得到的注意力权重 <span class="math notranslate nohighlight">\(\alpha(\mathbf{q}, \mathbf{k}_i)\)</span> 需要通过softmax进行归一化：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\alpha(\mathbf{q}, \mathbf{k}_i) \\
    = \mathrm{softmax}(a(\mathbf{q}, \mathbf{k}_i)) \\
    = \frac{\exp(\mathbf{q}^\top \mathbf{k}_i / \sqrt{d})}{\sum_{j=1} \exp(\mathbf{q}^\top \mathbf{k}_j / \sqrt{d})}\end{split}\]</div>
<ul class="simple">
<li><p>这样做的好处是，可以保证所有的注意力权重是非负的，并且它们的和为1，确保了后续加权求和时的稳定性。</p></li>
</ul>
</section>
<section id="convenience-functions">
<h5>11.3.2. Convenience Functions<a class="headerlink" href="#convenience-functions" title="此标题的永久链接">¶</a></h5>
<section id="masked-softmax-operation">
<h6>11.3.2.1. Masked Softmax Operation<a class="headerlink" href="#masked-softmax-operation" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>在序列模型中，常常需要处理不同长度的序列。在这种情况下，我们需要掩蔽操作来忽略填充（padding）部分对注意力计算的影响。</p></li>
<li><p>例如，如果一个批次中有三个句子，其中一个句子较短，包含填充符 &lt;blank&gt;，我们需要确保这些填充部分不会影响最终的注意力计算。掩蔽操作通过将填充部分的注意力权重设置为非常小的负数（如 <span class="math notranslate nohighlight">\(-10^6\)</span> ），从而使得这些部分在计算中不会起作用。</p></li>
</ul>
</section>
<section id="batch-matrix-multiplication">
<h6>11.3.2.2. Batch Matrix Multiplication<a class="headerlink" href="#batch-matrix-multiplication" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>在实际应用中，通常会处理多个查询、键和值，因此需要对多个矩阵进行批量矩阵乘法（BMM）。BMM 是一种高效的操作，可以在一个步骤中同时计算多个查询与键的点积。</p></li>
<li><p>公式如下：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\textrm{BMM}(\mathbf{Q}, \mathbf{K}) \\
    = [\mathbf{Q}_1 \mathbf{K}_1, \mathbf{Q}_2 \mathbf{K}_2, \ldots, \mathbf{Q}_n \mathbf{K}_n]
        \in \mathbb{R}^{n \times a \times c}\end{split}\]</div>
</section>
</section>
<section id="scaled-dot-product-attention">
<h5>11.3.3. Scaled Dot Product Attention<a class="headerlink" href="#scaled-dot-product-attention" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>为了控制点积值的规模，通常使用“缩放”操作，将点积结果除以查询和键的维度的平方根</p></li>
<li><p>这种缩放有助于避免随着向量维度增加，点积值变得过大，导致梯度不稳定的问题。</p></li>
</ul>
</section>
<section id="additive-attention">
<h5>11.3.4. Additive Attention<a class="headerlink" href="#additive-attention" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>当查询向量和键向量的维度不一致时，可以使用加法注意力。加法注意力通过将查询和键向量结合（例如，使用一个权重矩阵）进行变换，之后再使用一个激活函数（通常是tanh）计算评分。</p></li>
<li><p>其评分函数为：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[a(\mathbf q, \mathbf k) = \mathbf w_v^\top \textrm{tanh}(\mathbf W_q\mathbf q + \mathbf W_k \mathbf k) \in \mathbb{R}\]</div>
<ul class="simple">
<li><p>其中</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{W_q}\)</span> 和 <span class="math notranslate nohighlight">\(\mathbf{W_k}\)</span> 是学习的参数</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{w_v}\)</span> 是用于生成最终得分的权重向量。</p></li>
<li><p>最后，通过softmax对得分进行归一化，得到最终的注意力权重。</p></li>
</ul>
</section>
</section>
<section id="the-bahdanau-attention-mechanism">
<h4>11.4. The Bahdanau Attention Mechanism<a class="headerlink" href="#the-bahdanau-attention-mechanism" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>在第10.7节中遇到机器翻译时，我们设计了一个基于两个RNN的序列到序列学习的 encoder–decoder 体系结构（Sutskever等，2014）。具体而言，RNN编码器将变量长度序列转换为固定形状上下文变量。然后，RNN解码器基于生成的令牌和上下文变量生成输出（目标）序列令牌。</p></li>
</ul>
<figure class="align-default" id="id264">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/qahW5M.png" src="https://img.zhaoweiguo.com/uPic/2025/01/qahW5M.png" />
<figcaption>
<p><span class="caption-text">Fig. 11.4.1 Sequence-to-sequence model. The state, as generated by the encoder, is the only piece of information shared between the encoder and the decoder.</span><a class="headerlink" href="#id264" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>这对于简短序列来说是很合理的，但很明显，对于长篇小说，例如章节甚至是很长的句子都是不可行的。毕竟，不久之后，中间表示中根本没有足够的“空间”来存储所有重要的内容。因此，解码器将无法翻译长而复杂的句子。</p></li>
</ul>
<section id="id196">
<h5>核心点-fromGPT<a class="headerlink" href="#id196" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>【定义】Bahdanau Attention Mechanism：是一个在序列到序列（sequence-to-sequence, seq2seq）模型中使用的注意力机制，它能够根据输入序列的不同部分选择性地聚焦（“注意”）最相关的信息，特别是在长序列的情况下。</p></li>
</ul>
<section id="id197">
<h6>关键点分析<a class="headerlink" href="#id197" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>背景（Sequence-to-Sequence模型）:在经典的seq2seq模型中，使用了两个RNN，一个是编码器（encoder），将输入序列编码成一个固定维度的状态变量；另一个是解码器（decoder），根据编码器的输出生成目标序列。这个固定维度的状态变量通常无法很好地处理长序列，因为它将整个输入序列压缩成一个向量，导致信息丢失。因此，模型对长句子的翻译效果较差。</p></li>
<li><p>Bahdanau Attention机制： <strong>问题</strong> : 当输入序列较长时，传统的seq2seq模型中的固定状态（context variable）无法包含足够的信息，导致解码器无法准确生成目标序列。 <strong>解决方案</strong> : Bahdanau Attention机制提出了在解码时，不是依赖固定的上下文向量，而是根据当前解码器的状态（即上一时刻的隐藏状态）动态选择输入序列中最相关的部分。具体来说，解码器每次生成一个新token时，会基于当前的解码器状态（上一时刻的隐藏状态）作为查询（query），在编码器的所有隐藏状态中计算注意力权重，选择最相关的部分来更新上下文向量。这个上下文向量（context variable）然后用于生成下一个token。</p></li>
</ul>
</section>
<section id="id198">
<h6>关键概念<a class="headerlink" href="#id198" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>注意力机制（Attention Mechanism）：通过动态计算和聚焦在输入的不同部分，让模型能够根据当前需要的信息来生成输出，而不是依赖一个固定的上下文向量。</p></li>
<li><p>加性注意力（Additive Attention）：通过计算当前查询和所有键之间的相关性，生成权重并对值进行加权求和，以此来动态调整上下文。</p></li>
<li><p>动态上下文（Dynamic Context）：不是使用固定的上下文，而是根据解码器的当前状态和编码器的输出动态更新上下文向量。</p></li>
</ul>
</section>
</section>
<section id="id199">
<h5>11.4.1. Model<a class="headerlink" href="#id199" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>context variable <span class="math notranslate nohighlight">\(\mathbf{c}\)</span></p></li>
<li><p>encoder hidden states <span class="math notranslate nohighlight">\(\mathbf{h}_{t}\)</span></p></li>
<li><p>decoder hidden states <span class="math notranslate nohighlight">\(\mathbf{s}_{t'-1}\)</span></p></li>
<li><p>The key idea is that instead of keeping the state, i.e., the <code class="docutils literal notranslate"><span class="pre">context</span> <span class="pre">variable</span></code> summarizing the source sentence, as fixed, we dynamically update it, as a function of both the original text ( <code class="docutils literal notranslate"><span class="pre">encoder</span> <span class="pre">hidden</span> <span class="pre">states</span></code> ) and the text that was already generated ( <code class="docutils literal notranslate"><span class="pre">decoder</span> <span class="pre">hidden</span> <span class="pre">states</span></code> ).</p></li>
<li><p>This yields <span class="math notranslate nohighlight">\(\mathbf{c}_{t'}\)</span> , which is updated after any decoding time step <span class="math notranslate nohighlight">\(t'\)</span> . Suppose that the input sequence is of length T . In this case the context variable is the output of attention pooling:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\mathbf{c}_{t'} = \sum_{t=1}^{T} \alpha(\mathbf{s}_{t' - 1}, \mathbf{h}_{t}) \mathbf{h}_{t}\]</div>
<ul class="simple">
<li><p>We used <span class="math notranslate nohighlight">\(\mathbf{s}_{t' - 1}\)</span> as the query, and <span class="math notranslate nohighlight">\(\mathbf{h}_{t}\)</span> as both the key and the value.</p></li>
<li><p>Note that <span class="math notranslate nohighlight">\(\mathbf{c}_{t'}\)</span> is then used to generate the state <span class="math notranslate nohighlight">\(\mathbf{s}_{t'}\)</span> and to generate a new token.</p></li>
<li><p>In particular, the attention weight <span class="math notranslate nohighlight">\(\alpha\)</span> is computed using the additive attention scoring function</p></li>
</ul>
<figure class="align-default" id="id265">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/F6i9sq.png" src="https://img.zhaoweiguo.com/uPic/2025/01/F6i9sq.png" />
<figcaption>
<p><span class="caption-text">Fig. 11.4.2 Layers in an RNN encoder–decoder model with the Bahdanau attention mechanism.</span><a class="headerlink" href="#id265" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
</section>
<section id="defining-the-decoder-with-attention">
<h5>11.4.2. Defining the Decoder with Attention<a class="headerlink" href="#defining-the-decoder-with-attention" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">AttentionDecoder</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Decoder</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The base attention-based decoder interface.&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">attention_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

<span class="k">class</span><span class="w"> </span><span class="nc">Seq2SeqAttentionDecoder</span><span class="p">(</span><span class="n">AttentionDecoder</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">AdditiveAttention</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">embed_size</span> <span class="o">+</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">init_seq2seq</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_outputs</span><span class="p">,</span> <span class="n">enc_valid_lens</span><span class="p">):</span>
        <span class="c1"># Shape of outputs: (num_steps, batch_size, num_hiddens).</span>
        <span class="c1"># Shape of hidden_state: (num_layers, batch_size, num_hiddens)</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="n">hidden_state</span> <span class="o">=</span> <span class="n">enc_outputs</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">hidden_state</span><span class="p">,</span> <span class="n">enc_valid_lens</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="c1"># Shape of enc_outputs: (batch_size, num_steps, num_hiddens).</span>
        <span class="c1"># Shape of hidden_state: (num_layers, batch_size, num_hiddens)</span>
        <span class="n">enc_outputs</span><span class="p">,</span> <span class="n">hidden_state</span><span class="p">,</span> <span class="n">enc_valid_lens</span> <span class="o">=</span> <span class="n">state</span>
        <span class="c1"># Shape of the output X: (num_steps, batch_size, embed_size)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_attention_weights</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">:</span>
            <span class="c1"># Shape of query: (batch_size, 1, num_hiddens)</span>
            <span class="n">query</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">hidden_state</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="c1"># Shape of context: (batch_size, 1, num_hiddens)</span>
            <span class="n">context</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">enc_outputs</span><span class="p">,</span> <span class="n">enc_outputs</span><span class="p">,</span> <span class="n">enc_valid_lens</span><span class="p">)</span>
            <span class="c1"># Concatenate on the feature dimension</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">context</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="c1"># Reshape x as (1, batch_size, embed_size + num_hiddens)</span>
            <span class="n">out</span><span class="p">,</span> <span class="n">hidden_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">hidden_state</span><span class="p">)</span>
            <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_attention_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">attention_weights</span><span class="p">)</span>
        <span class="c1"># After fully connected layer transformation, shape of outputs:</span>
        <span class="c1"># (num_steps, batch_size, vocab_size)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">outputs</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">[</span><span class="n">enc_outputs</span><span class="p">,</span> <span class="n">hidden_state</span><span class="p">,</span> <span class="n">enc_valid_lens</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">attention_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_attention_weights</span>
</pre></div>
</div>
<p>使用四个序列的小匹配来测试实现的解码器，每个序列长七个时间步长:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">2</span>
<span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">7</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Seq2SeqEncoder</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">Seq2SeqAttentionDecoder</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">state</span> <span class="o">=</span> <span class="n">decoder</span><span class="o">.</span><span class="n">init_state</span><span class="p">(</span><span class="n">encoder</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="kc">None</span><span class="p">)</span>
<span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">check_shape</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">))</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">check_shape</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">))</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">check_shape</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="id200">
<h5>11.4.3. Training<a class="headerlink" href="#id200" title="此标题的永久链接">¶</a></h5>
<p>指定超参数，实例化常规编码器和引起注意的解码器，然后将此模型训练以进行机器翻译:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">MTFraEng</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
<span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.2</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Seq2SeqEncoder</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">src_vocab</span><span class="p">),</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">Seq2SeqAttentionDecoder</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">tgt_vocab</span><span class="p">),</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Seq2Seq</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">tgt_pad</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">tgt_vocab</span><span class="p">[</span><span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.005</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">gradient_clip_val</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<p>将一些英语句子翻译成法语并计算其BLEU分数:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">engs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;go .&#39;</span><span class="p">,</span> <span class="s1">&#39;i lost .&#39;</span><span class="p">,</span> <span class="s1">&#39;he</span><span class="se">\&#39;</span><span class="s1">s calm .&#39;</span><span class="p">,</span> <span class="s1">&#39;i</span><span class="se">\&#39;</span><span class="s1">m home .&#39;</span><span class="p">]</span>
<span class="n">fras</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;va !&#39;</span><span class="p">,</span> <span class="s1">&#39;j</span><span class="se">\&#39;</span><span class="s1">ai perdu .&#39;</span><span class="p">,</span> <span class="s1">&#39;il est calme .&#39;</span><span class="p">,</span> <span class="s1">&#39;je suis chez moi .&#39;</span><span class="p">]</span>
<span class="n">preds</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_step</span><span class="p">(</span>
    <span class="n">data</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">engs</span><span class="p">,</span> <span class="n">fras</span><span class="p">),</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">(),</span> <span class="n">data</span><span class="o">.</span><span class="n">num_steps</span><span class="p">)</span>
<span class="k">for</span> <span class="n">en</span><span class="p">,</span> <span class="n">fr</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">engs</span><span class="p">,</span> <span class="n">fras</span><span class="p">,</span> <span class="n">preds</span><span class="p">):</span>
    <span class="n">translation</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">tgt_vocab</span><span class="o">.</span><span class="n">to_tokens</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">token</span> <span class="o">==</span> <span class="s1">&#39;&lt;eos&gt;&#39;</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="n">translation</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">en</span><span class="si">}</span><span class="s1"> =&gt; </span><span class="si">{</span><span class="n">translation</span><span class="si">}</span><span class="s1">, bleu,&#39;</span>
          <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">d2l</span><span class="o">.</span><span class="n">bleu</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">translation</span><span class="p">),</span><span class="w"> </span><span class="n">fr</span><span class="p">,</span><span class="w"> </span><span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="c1"># 输出</span>
<span class="n">go</span> <span class="o">.</span> <span class="o">=&gt;</span> <span class="p">[</span><span class="s1">&#39;va&#39;</span><span class="p">,</span> <span class="s1">&#39;!&#39;</span><span class="p">],</span> <span class="n">bleu</span><span class="p">,</span><span class="mf">1.000</span>
<span class="n">i</span> <span class="n">lost</span> <span class="o">.</span> <span class="o">=&gt;</span> <span class="p">[</span><span class="s2">&quot;j&#39;ai&quot;</span><span class="p">,</span> <span class="s1">&#39;perdu&#39;</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">],</span> <span class="n">bleu</span><span class="p">,</span><span class="mf">1.000</span>
<span class="n">he</span><span class="s1">&#39;s calm . =&gt; [&#39;</span><span class="n">il</span><span class="s1">&#39;, &#39;</span><span class="n">court</span><span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="s1">&#39;], bleu,0.000</span>
<span class="n">i</span><span class="s1">&#39;m home . =&gt; [&#39;</span><span class="n">je</span><span class="s1">&#39;, &#39;</span><span class="n">suis</span><span class="s1">&#39;, &#39;</span><span class="n">chez</span><span class="s1">&#39;, &#39;</span><span class="n">moi</span><span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="s1">&#39;], bleu,1.000</span>
</pre></div>
</div>
</section>
<section id="id201">
<h5>11.4.4. Summary<a class="headerlink" href="#id201" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>Bahdanau Attention机制的核心思想是在生成每个token时，解码器不再只依赖一个固定的上下文向量，而是通过注意力机制动态地选择和聚焦在输入序列的最相关部分。这使得模型能够更好地处理长序列，避免了传统seq2seq模型在处理长文本时遇到的瓶颈。</p></li>
</ul>
</section>
</section>
<section id="multi-head-attention">
<h4>11.5. Multi-Head Attention<a class="headerlink" href="#multi-head-attention" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>在实践中，给定相同的查询，键和值，我们可能希望我们的模型结合相同注意力机制的不同行为的知识，例如捕获各种范围的依赖性（例如，较短范围与较长范围）在序列中。因此，允许我们的注意机制共同使用查询，键和值的不同表示子空间可能是有益的。</p></li>
</ul>
<figure class="align-default" id="id266">
<img alt="https://img.zhaoweiguo.com/uPic/2025/01/BGyPHz.png" src="https://img.zhaoweiguo.com/uPic/2025/01/BGyPHz.png" />
<figcaption>
<p><span class="caption-text">Fig. 11.5.1 Multi-head attention, where multiple heads are concatenated then linearly transformed.</span><a class="headerlink" href="#id266" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>FC: fully connected layers</p></li>
</ul>
<section id="id202">
<h5>核心点-fromGPT<a class="headerlink" href="#id202" title="此标题的永久链接">¶</a></h5>
<section id="id203">
<h6>关键点分析<a class="headerlink" href="#id203" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>【背景和动机】：单头注意力机制通常用于从查询（query）、键（key）和值（value）中计算注意力。在实践中，我们可能希望模型能够从同一注意力机制中获得不同的行为表现，比如捕捉不同范围的依赖关系（例如，短程依赖和长程依赖）。为了实现这一目标，Multi-Head Attention机制让模型能够在多个子空间中并行计算不同的注意力，以便捕捉更多的信息。每个头（head）独立处理一个注意力池化过程，并且可以关注输入序列的不同部分。</p></li>
<li><p>【多头注意力的优势】：每个头可以关注输入的不同部分，从而能够捕捉到不同的信息，特别是在处理复杂的、长序列时，它能够有效地捕获不同的依赖关系。通过并行计算多个头，模型可以高效地同时学习多个表示子空间的信息，增强模型的表达能力。</p></li>
<li><p>【实现中的优化】：在实际实现中，选择缩放点积注意力（scaled dot product attention）作为每个头的注意力函数，以避免计算成本和参数量的剧烈增长。为了保证计算的高效性，查询、键和值的输出维度通常会设置为 <span class="math notranslate nohighlight">\(p_q = p_k = p_v = \frac{p_o}{h}\)</span> ，其中 <span class="math notranslate nohighlight">\(p_o\)</span> 是最终输出的维度， <span class="math notranslate nohighlight">\(h\)</span> 是头的数量。这样可以在并行计算时保持计算和内存效率。</p></li>
</ul>
</section>
<section id="id204">
<h6>关键概念<a class="headerlink" href="#id204" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>注意力头（Attention Head）：每个头独立计算一个注意力过程，关注输入序列的不同部分，最终将多个头的输出进行拼接并线性变换得到最终的结果。</p></li>
<li><p>多头注意力（Multi-Head Attention）：通过多个头的并行计算，可以在不同的子空间中学习到更多的信息，提高模型的表示能力。</p></li>
<li><p>缩放点积注意力（Scaled Dot Product Attention）：通常用于每个头的注意力计算，采用点积方式，并通过缩放因子来避免点积过大导致梯度消失的问题。</p></li>
</ul>
</section>
</section>
<section id="id205">
<h5>11.5.1. Model<a class="headerlink" href="#id205" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>【具体实现】：在多头注意力中，首先通过对查询、键和值进行线性变换，将它们映射到不同的子空间（这一步通过h个不同的线性变换实现），每个头会得到一个独立的查询、键和值。之后，将这些头的结果并行计算注意力。</p></li>
<li><p>query: <span class="math notranslate nohighlight">\(\mathbf{q} \in \mathbb{R}^{d_q}\)</span></p></li>
<li><p>key: <span class="math notranslate nohighlight">\(\mathbf{k} \in \mathbb{R}^{d_k}\)</span></p></li>
<li><p>value: <span class="math notranslate nohighlight">\(\mathbf{v} \in \mathbb{R}^{d_v}\)</span></p></li>
<li><p>attention head: <span class="math notranslate nohighlight">\(\mathbf{h}_i  (i = 1, \ldots, h)\)</span></p></li>
<li><p>计算过程的公式</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\mathbf{h}_i = f(\mathbf W_i^{(q)}\mathbf q, \mathbf W_i^{(k)}\mathbf k,\mathbf W_i^{(v)}\mathbf v) \in \mathbb R^{p_v}\]</div>
<ul class="simple">
<li><p>其中</p></li>
<li><p><span class="math notranslate nohighlight">\(f\)</span> is attention pooling,</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf W_i^{(q)}\in\mathbb R^{p_q\times d_q}, \mathbf W_i^{(k)}\in\mathbb R^{p_k\times d_k}, and \mathbf W_i^{(v)}\in\mathbb R^{p_v\times d_v}\)</span> are learnable parameters</p></li>
<li><p>最终的多头注意力输出是将所有头的输出拼接在一起后，再通过一个线性变换生成：</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf W_o \begin{bmatrix}
    \mathbf h_1\\\vdots\\\mathbf h_h
\end{bmatrix} \in \mathbb{R}^{p_o}\end{split}\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{W}_o\)</span> 是用于将拼接后的结果进行线性变换的权重矩阵</p></li>
</ul>
</section>
<section id="implementation">
<h5>11.5.2. Implementation<a class="headerlink" href="#implementation" title="此标题的永久链接">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Multi-head attention.&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">DotProductAttention</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_q</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_k</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_v</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_o</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">):</span>
        <span class="c1"># Shape of queries, keys, or values:</span>
        <span class="c1"># (batch_size, no. of queries or key-value pairs, num_hiddens)</span>
        <span class="c1"># Shape of valid_lens: (batch_size,) or (batch_size, no. of queries)</span>
        <span class="c1"># After transposing, shape of output queries, keys, or values:</span>
        <span class="c1"># (batch_size * num_heads, no. of queries or key-value pairs,</span>
        <span class="c1"># num_hiddens / num_heads)</span>
        <span class="n">queries</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_qkv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_q</span><span class="p">(</span><span class="n">queries</span><span class="p">))</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_qkv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_k</span><span class="p">(</span><span class="n">keys</span><span class="p">))</span>
        <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_qkv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_v</span><span class="p">(</span><span class="n">values</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">valid_lens</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># On axis 0, copy the first item (scalar or vector) for num_heads</span>
            <span class="c1"># times, then copy the next item, and so on</span>
            <span class="n">valid_lens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span>
                <span class="n">valid_lens</span><span class="p">,</span> <span class="n">repeats</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Shape of output: (batch_size * num_heads, no. of queries,</span>
        <span class="c1"># num_hiddens / num_heads)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">)</span>
        <span class="c1"># Shape of output_concat: (batch_size, no. of queries, num_hiddens)</span>
        <span class="n">output_concat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transpose_output</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_o</span><span class="p">(</span><span class="n">output_concat</span><span class="p">)</span>
</pre></div>
</div>
<p>为了允许多个头部的并行计算，上述 MultiHeadAttention 类使用下面定义的两个换位方法:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">MultiHeadAttention</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">transpose_qkv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transposition for parallel computation of multiple attention heads.&quot;&quot;&quot;</span>
    <span class="c1"># Shape of input X: (batch_size, no. of queries or key-value pairs,</span>
    <span class="c1"># num_hiddens). Shape of output X: (batch_size, no. of queries or</span>
    <span class="c1"># key-value pairs, num_heads, num_hiddens / num_heads)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># Shape of output X: (batch_size, num_heads, no. of queries or key-value</span>
    <span class="c1"># pairs, num_hiddens / num_heads)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="c1"># Shape of output: (batch_size * num_heads, no. of queries or key-value</span>
    <span class="c1"># pairs, num_hiddens / num_heads)</span>
    <span class="k">return</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>

<span class="nd">@d2l</span><span class="o">.</span><span class="n">add_to_class</span><span class="p">(</span><span class="n">MultiHeadAttention</span><span class="p">)</span>  <span class="c1">#@save</span>
<span class="k">def</span><span class="w"> </span><span class="nf">transpose_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Reverse the operation of transpose_qkv.&quot;&quot;&quot;</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>示例测试我们实现的 MultiHeadAttention 类:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">5</span>
<span class="n">attention</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">batch_size</span><span class="p">,</span> <span class="n">num_queries</span><span class="p">,</span> <span class="n">num_kvpairs</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span>
<span class="n">valid_lens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_queries</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">))</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_kvpairs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">))</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">check_shape</span><span class="p">(</span><span class="n">attention</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">),</span>
                <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_queries</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="id206">
<h5>11.5.3. Summary<a class="headerlink" href="#id206" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>多头注意力通过查询，键和值的不同表示子空间结合了相同注意力集合的知识。要平行计算多头注意的多个头部，需要进行适当的张量操作。</p></li>
<li><p>Multi-head Attention机制通过并行计算多个头来从不同的表示子空间中学习注意力，捕捉输入的多种特征和依赖关系，尤其在长序列的情况下具有重要作用。</p></li>
<li><p>通过适当的张量操作（tensor manipulation），可以高效地计算多个头，避免计算成本和参数量的过度增长。</p></li>
</ul>
</section>
</section>
<section id="self-attention-and-positional-encoding">
<h4>11.6. Self-Attention and Positional Encoding<a class="headerlink" href="#self-attention-and-positional-encoding" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>自注意力机制是Transformer模型的核心，广泛应用于自然语言处理等领域，而位置编码用于补偿自注意力机制无法捕捉序列中位置信息的不足。</p></li>
</ul>
<section id="self-attention">
<h5>11.6.1. Self-Attention<a class="headerlink" href="#self-attention" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>自注意力机制的关键是每个输入序列中的token都可以根据其查询（query）与其他所有token的键（key）进行计算，从而决定如何更新该token的表示。</p></li>
<li><p>具体来说，每个token的查询会与其他所有token的键进行匹配，得出兼容性分数，然后基于这些分数，按权重求和所有token的值（value），以生成最终的token表示。</p></li>
<li><dl class="simple">
<dt>自注意力机制的计算过程：</dt><dd><ul>
<li><p>给定输入序列 <span class="math notranslate nohighlight">\(\mathbf{x}_1, \ldots, \mathbf{x}_n\)</span> ，每个token的表示会结合整个序列中其他token的表示，计算其加权和。</p></li>
<li><p>输出是一个与输入长度相同的序列 <span class="math notranslate nohighlight">\(\mathbf{y}_1, \ldots, \mathbf{y}_n\)</span></p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="comparing-cnns-rnns-and-self-attention">
<h5>11.6.2. Comparing CNNs, RNNs, and Self-Attention<a class="headerlink" href="#comparing-cnns-rnns-and-self-attention" title="此标题的永久链接">¶</a></h5>
<figure class="align-default" id="id267">
<img alt="https://img.zhaoweiguo.com/uPic/2025/02/nTybnr.png" src="https://img.zhaoweiguo.com/uPic/2025/02/nTybnr.png" />
<figcaption>
<p><span class="caption-text">Fig. 11.6.1 Comparing CNN (padding tokens are omitted), RNN, and self-attention architectures.</span><a class="headerlink" href="#id267" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>自注意力的计算复杂度为 <span class="math notranslate nohighlight">\(\mathcal{O}(n^2d)\)</span> ，其中 n 是序列的长度，d 是每个token的维度。这使得自注意力在处理非常长的序列时变得非常慢，因为计算量是二次增长的。</p></li>
<li><dl class="simple">
<dt>CNN</dt><dd><ul>
<li><p>CNN主要用于处理局部特征，通过卷积操作捕捉局部上下文信息。</p></li>
<li><p>其计算复杂度为 <span class="math notranslate nohighlight">\(\mathcal{O}(knd^2)\)</span></p></li>
<li><p>其中 k 是卷积核的大小。</p></li>
<li><p>CNN具有较短的路径长度，但计算过程中存在层级结构，因此最大路径长度为 <span class="math notranslate nohighlight">\(\mathcal{O}(n/k)\)</span></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>RNN</dt><dd><ul>
<li><p>RNN按顺序处理每个token</p></li>
<li><p>其计算复杂度为 <span class="math notranslate nohighlight">\(\mathcal{O}(nd^2)\)</span></p></li>
<li><p>RNN的最大路径长度为 <span class="math notranslate nohighlight">\(\mathcal{O}(n)\)</span></p></li>
<li><p>由于其顺序依赖性，无法并行化计算。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Self-Attention</dt><dd><ul>
<li><p>相比于CNN和RNN，自注意力能够并行计算，并且每个token都能直接与其他token建立连接（即路径长度为 <span class="math notranslate nohighlight">\(\mathcal{O}(1)\)</span> ）</p></li>
<li><p>但是，计算复杂度是 <span class="math notranslate nohighlight">\(\mathcal{O}(n^2d)\)</span> ，因此对于长序列来说计算量非常大。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>All in all, both CNNs and self-attention enjoy parallel computation and self-attention has the shortest maximum path length. However, the quadratic computational complexity with respect to the sequence length makes self-attention prohibitively slow for very long sequences.</p>
</div>
</section>
<section id="positional-encoding">
<h5>11.6.3. Positional Encoding<a class="headerlink" href="#positional-encoding" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>自注意力机制不包含顺序信息，因此无法直接捕捉序列中token的相对位置。为了弥补这一点，引入了位置编码，它为每个token添加了额外的位置信息，使得模型可以感知序列的顺序。</p></li>
</ul>
<section id="absolute-positional-information">
<h6>11.6.3.1. Absolute Positional Information<a class="headerlink" href="#absolute-positional-information" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>一种基于正弦和余弦函数的固定位置编码的简单方案</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    p_{i, 2j} &amp;= \sin\left(\frac{i}{10000^{2j/d}}\right),\\
    p_{i, 2j+1} &amp;= \cos\left(\frac{i}{10000^{2j/d}}\right)
\end{aligned}\end{split}\]</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">PositionalEncoding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Positional encoding.&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="c1"># Create a long enough P</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">P</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">))</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
            <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span>
            <span class="mi">0</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_hiddens</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">[:,</span> <span class="p">:</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">:]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="relative-positional-information">
<h6>11.6.3.2. Relative Positional Information<a class="headerlink" href="#relative-positional-information" title="此标题的永久链接">¶</a></h6>
<ul class="simple">
<li><p>除了绝对位置编码，位置编码也能捕捉相对位置关系。</p></li>
<li><p>通过对位置编码进行线性变换，可以表示任意两个token之间的相对位置偏移，从而使模型更容易学习到基于相对位置的注意力模式。</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    \begin{bmatrix} \cos(\delta \omega_j) &amp; \sin(\delta \omega_j) \\  -\sin(\delta \omega_j) &amp; \cos(\delta \omega_j) \\ \end{bmatrix}
    \begin{bmatrix} p_{i, 2j} \\  p_{i, 2j+1} \\ \end{bmatrix}
    =&amp;\begin{bmatrix} \cos(\delta \omega_j) \sin(i \omega_j) + \sin(\delta \omega_j) \cos(i \omega_j) \\  -\sin(\delta \omega_j) \sin(i \omega_j) + \cos(\delta \omega_j) \cos(i \omega_j) \\ \end{bmatrix}\\
    =&amp;\begin{bmatrix} \sin\left((i+\delta) \omega_j\right) \\  \cos\left((i+\delta) \omega_j\right) \\ \end{bmatrix}\\
    =&amp;\begin{bmatrix} p_{i+\delta, 2j} \\  p_{i+\delta, 2j+1} \\ \end{bmatrix},
\end{aligned}\end{split}\]</div>
<ul class="simple">
<li><p>对于任何固定位置偏移 <span class="math notranslate nohighlight">\(\delta\)</span> ，位置 <span class="math notranslate nohighlight">\(i + \delta\)</span> 的位置编码可以用位置 <span class="math notranslate nohighlight">\(i\)</span> 的线性投影表示</p></li>
<li><p>其中 <span class="math notranslate nohighlight">\(\omega_j = 1/10000^{2j/d}\)</span></p></li>
<li><p>对于任何固定偏移 <span class="math notranslate nohighlight">\(\delta\)</span> 任何一对 <span class="math notranslate nohighlight">\((p_{i, 2j}, p_{i, 2j+1})\)</span> 可以线性地投影到 <span class="math notranslate nohighlight">\((p_{i+\delta, 2j}, p_{i+\delta, 2j+1})\)</span></p></li>
</ul>
</section>
</section>
<section id="id207">
<h5>11.6.4. Summary<a class="headerlink" href="#id207" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>自注意力机制使得每个token可以与其他所有token进行直接交互，从而捕捉长距离依赖。相比于CNN和RNN，自注意力计算可以并行化，最大路径长度最短，但由于计算复杂度是二次的，长序列处理的开销较大。</p></li>
<li><p>位置编码通过为每个token添加位置信息，使得自注意力机制能够处理顺序问题。位置编码可以是绝对的，也可以是相对的，帮助模型捕捉序列中的位置关系。</p></li>
<li><p>这两种机制结合起来，构成了Transformer的强大表达能力，使得它在许多自然语言处理任务中取得了显著的成功。</p></li>
</ul>
</section>
</section>
<section id="the-transformer-architecture">
<h4>11.7. The Transformer Architecture<a class="headerlink" href="#the-transformer-architecture" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>Transformer 就是 堆叠自注意力机制 + 残差连接 + 前馈网络，通过 Encoder 编码输入序列，再通过 Decoder 逐步自回归地生成输出序列，整套架构灵活且高度并行化，是现代大多数大型语言模型的基础。</p></li>
</ul>
<section id="id208">
<h5>11.7.1. Model<a class="headerlink" href="#id208" title="此标题的永久链接">¶</a></h5>
<figure class="align-default" id="id268">
<img alt="https://img.zhaoweiguo.com/uPic/2025/03/tlm6Qx.png" src="https://img.zhaoweiguo.com/uPic/2025/03/tlm6Qx.png" />
<figcaption>
<p><span class="caption-text">Fig. 11.7.1 The Transformer architecture.</span><a class="headerlink" href="#id268" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul>
<li><dl class="simple">
<dt>整体结构</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>Transformer 是一种 Encoder-Decoder 架构，整体分为两大块：</dt><dd><ul>
<li><p>Encoder（编码器）</p></li>
<li><p>Decoder（解码器）</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>它是 序列到序列学习（seq2seq learning） 的一种改进方法，相比于之前流行的 Bahdanau Attention（注意力机制），Transformer 完全基于自注意力（self-attention） 机制来处理输入和输出序列。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>输入处理</dt><dd><ul class="simple">
<li><p>输入的 source sequence（输入序列） 和 target sequence（输出序列） 都要 先经过 embedding（词向量嵌入）</p></li>
<li><p>然后，位置编码（Positional Encoding） 被加到 embedding 上，告诉模型单词在序列中的位置，因为 Transformer 本身不具备序列顺序感知能力</p></li>
<li><p>之后，这些加了位置编码的向量会分别被送进 Encoder 和 Decoder</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Encoder 结构</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>Encoder 是由 多个相同的层叠在一起，每一层包含 两个子层（sublayers）：</dt><dd><ol class="arabic simple">
<li><dl class="simple">
<dt>多头自注意力层（Multi-Head Self-Attention）</dt><dd><ul>
<li><p>自注意力机制，输入序列内部的各个词相互关注，捕捉上下文信息。</p></li>
<li><p>这里的 Query、Key、Value 都来自上一层 Encoder 的输出。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>前馈神经网络（Feed-Forward Network）</dt><dd><ul>
<li><p>逐位置应用的全连接网络，作用是增加模型的非线性表达能力。</p></li>
</ul>
</dd>
</dl>
</li>
</ol>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>残差连接（Residual Connection） 和 Layer Normalization</dt><dd><ul>
<li><p>每个子层外面都有一个 残差连接（和 ResNet 类似），形式是： <span class="math notranslate nohighlight">\(\mathbf{x} + \textrm{sublayer}(\mathbf{x})\)</span></p></li>
<li><p>保证输入和输出维度一致（ <span class="math notranslate nohighlight">\(\mathbb{R}^d\)</span> ），便于直接相加。</p></li>
<li><p>残差之后再做 LayerNorm，有助于训练稳定性。</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Encoder 最终输出：每个位置一个 d 维向量，表示输入序列中每个词的表示。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Decoder 结构</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>Decoder 也由 多个相同层堆叠，但它比 Encoder 多了一个子层，总共 三个子层：</dt><dd><ol class="arabic simple">
<li><dl class="simple">
<dt>Masked 多头自注意力层（Masked Multi-Head Self-Attention）</dt><dd><ul>
<li><p>也是 Query、Key、Value 都来自 Decoder 的前一层输出。</p></li>
<li><p>但加了 mask，防止模型看到当前时间步之后的 token，保证自回归（autoregressive）性质。</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Encoder-Decoder Attention
- 这是 Decoder 特有的。
- Query 来自 Decoder，而 Key 和 Value 来自 Encoder 输出，实现输入输出序列之间的联系。</p></li>
<li><p>前馈神经网络</p></li>
</ol>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>同样，每个子层也带有：</dt><dd><ul>
<li><p>残差连接（输入 + 子层输出）</p></li>
<li><p>Layer Normalization</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>总结</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>Transformer 整个设计理念：</dt><dd><ul>
<li><p>完全基于 Attention，没有 RNN/CNN</p></li>
<li><p>位置编码补充序列顺序信息</p></li>
<li><p>残差连接 + LayerNorm 保证训练深层网络时的稳定性</p></li>
<li><p>Encoder 用于理解输入序列，Decoder 用于生成输出序列</p></li>
<li><p>Decoder 的 Masked Attention 保证 自回归生成（只看当前和之前的 token）</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
<li><dl>
<dt>定义：残差连接(Residual Connection)</dt><dd><ul>
<li><p>深度神经网络中常用的一种技巧，特别是在 ResNet（残差网络） 和 Transformer 里用得很多</p></li>
<li><p>核心思想：残差连接就是“跳过一层”直接把输入加到输出上。</p></li>
<li><p>公式: <span class="math notranslate nohighlight">\(\mathbf{y} = \mathbf{x} + \textrm{F}(\mathbf{x})\)</span></p></li>
<li><dl>
<dt>直观理解: 模型学的不是直接输出，而是“输入和输出的差值”，即 residual（残差）</dt><dd><ul>
<li><p>传统网络:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>输入 x → 神经网络层 → 输出 y
</pre></div>
</div>
</li>
<li><p>残差连接:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>输入 x → 神经网络层 → 得到 F(x)
            ↘ 加上输入 x
输出：y = F(x) + x
</pre></div>
</div>
</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>为什么要这样设计</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>解决深度网络训练困难</dt><dd><ul>
<li><p>随着层数加深，容易出现 梯度消失或梯度爆炸，导致训练困难</p></li>
<li><p>残差连接可以让梯度 直接从后层传到前层，缓解这个问题</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>避免性能退化</dt><dd><ul>
<li><p>实际上，如果网络没学到什么有用的东西，残差连接至少可以让网络学到“恒等映射”（即输出和输入一样）</p></li>
<li><p>这样网络至少不会比浅层网络表现更差，避免“加层反而效果下降”的问题</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="positionwise-feed-forward-networks">
<h5>11.7.2. Positionwise Feed-Forward Networks<a class="headerlink" href="#positionwise-feed-forward-networks" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>位置前馈网络（Positionwise Feed-Forward Network）</p></li>
<li><dl class="simple">
<dt>为什么称为”positionwise”（位置前馈）</dt><dd><ul>
<li><dl class="simple">
<dt>关键点：</dt><dd><ul>
<li><p>每个位置的向量是独立、逐个位置处理的！</p></li>
<li><p>同一个 FFN（同样的参数 $W_1, b_1, W_2, b_2$）被应用到序列中的 每一个位置。</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>→ 这就叫 positionwise —— 对每个“位置”单独应用相同的 FFN。</dt><dd><ul>
<li><p>序列有很多 token，每个 token 有自己的表示（embedding 向量）。</p></li>
<li><p>所有 token 的向量都用同一个 FFN 进行处理，但每个 token 是单独处理，不考虑别的位置的信息。</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>输入和输出的形状：</dt><dd><ul>
<li><p>输入X的形状是(batch size, number of time steps or sequence length in tokens, number of hidden units or feature dimension)。</p></li>
<li><p>输出Y的形状是(batch size, number of time steps, ffn_num_outputs)</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<p>结构:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">PositionWiseFFN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The positionwise feed-forward network.&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">ffn_num_outputs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">ffn_num_hiddens</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">ffn_num_outputs</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dense1</span><span class="p">(</span><span class="n">X</span><span class="p">)))</span>
</pre></div>
</div>
<p>使用:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ffn</span> <span class="o">=</span> <span class="n">PositionWiseFFN</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<span class="n">ffn</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">ffn</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)))[</span><span class="mi">0</span><span class="p">]</span>
<span class="c1"># 输出</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mf">0.6300</span><span class="p">,</span>  <span class="mf">0.7739</span><span class="p">,</span>  <span class="mf">0.0278</span><span class="p">,</span>  <span class="mf">0.2508</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0519</span><span class="p">,</span>  <span class="mf">0.4881</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4105</span><span class="p">,</span>  <span class="mf">0.5163</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.6300</span><span class="p">,</span>  <span class="mf">0.7739</span><span class="p">,</span>  <span class="mf">0.0278</span><span class="p">,</span>  <span class="mf">0.2508</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0519</span><span class="p">,</span>  <span class="mf">0.4881</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4105</span><span class="p">,</span>  <span class="mf">0.5163</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.6300</span><span class="p">,</span>  <span class="mf">0.7739</span><span class="p">,</span>  <span class="mf">0.0278</span><span class="p">,</span>  <span class="mf">0.2508</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0519</span><span class="p">,</span>  <span class="mf">0.4881</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4105</span><span class="p">,</span>  <span class="mf">0.5163</span><span class="p">]],</span>
       <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">SelectBackward0</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="residual-connection-and-layer-normalization">
<h5>11.7.3. Residual Connection and Layer Normalization<a class="headerlink" href="#residual-connection-and-layer-normalization" title="此标题的永久链接">¶</a></h5>
<ul>
<li><p>通过层规范化和批量规范化比较了不同维度上的规范化:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ln</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">bn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyBatchNorm1d</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="c1"># Compute mean and variance from X in the training mode</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;layer norm:&#39;</span><span class="p">,</span> <span class="n">ln</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">batch norm:&#39;</span><span class="p">,</span> <span class="n">bn</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="id209">
<h5>11.7.4. Encoder<a class="headerlink" href="#id209" title="此标题的永久链接">¶</a></h5>
</section>
<section id="id210">
<h5>11.7.5. Decoder<a class="headerlink" href="#id210" title="此标题的永久链接">¶</a></h5>
</section>
<section id="id211">
<h5>11.7.6. Training<a class="headerlink" href="#id211" title="此标题的永久链接">¶</a></h5>
</section>
<section id="id212">
<h5>11.7.7. Summary<a class="headerlink" href="#id212" title="此标题的永久链接">¶</a></h5>
</section>
</section>
<section id="transformers-for-vision">
<h4>11.8. Transformers for Vision<a class="headerlink" href="#transformers-for-vision" title="此标题的永久链接">¶</a></h4>
<p>11.8.1. Model
11.8.2. Patch Embedding
11.8.3. Vision Transformer Encoder
11.8.4. Putting It All Together
11.8.5. Training
11.8.6. Summary and Discussion</p>
</section>
<section id="large-scale-pretraining-with-transformers">
<h4>11.9. Large-Scale Pretraining with Transformers<a class="headerlink" href="#large-scale-pretraining-with-transformers" title="此标题的永久链接">¶</a></h4>
<p>11.9.1. Encoder-Only
11.9.2. Encoder–Decoder
11.9.3. Decoder-Only
11.9.4. Scalability
11.9.5. Large Language Models
11.9.6. Summary and Discussion</p>
</section>
</section>
</section>
<section id="part-3-scalability-efficiency-and-applications">
<h2>Part 3: Scalability, Efficiency, and Applications<a class="headerlink" href="#part-3-scalability-efficiency-and-applications" title="此标题的永久链接">¶</a></h2>
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference external" href="/index.html">主页</a></p></td>
<td><p><a class="reference internal" href="../../../genindex.html"><span class="std std-ref">索引</span></a></p></td>
<td><p><a class="reference internal" href="../../../py-modindex.html"><span class="std std-ref">模块索引</span></a></p></td>
<td><p><a class="reference internal" href="../../../search.html"><span class="std std-ref">搜索页面</span></a></p></td>
</tr>
</tbody>
</table>
</section>
</section>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../../architecture.html" class="btn btn-neutral float-right" title="架构相关" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="Build_LLM_From_Scratch.html" class="btn btn-neutral" title="Build a Large Language Model (From Scratch)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>
  
  <div id="gitalk-container"></div>
  <div role="contentinfo">
    <p>
        &copy; Copyright 2010-2025, 新溪-gordon.

    </p>
  </div>
  <div>备案号 <a href="http://www.beian.miit.gov.cn">京ICP备16018553号</a></div><div>Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a></div>. 


</footer>

<script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?042289284b8eb33866001347a3e0b129";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
</script>     
        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../',
            VERSION:'V2025.11',
            LANGUAGE:'zh-CN',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../../../_static/doctools.js"></script>
      <script type="text/javascript" src="../../../_static/sphinx_highlight.js"></script>
      <script type="text/javascript" src="../../../_static/clipboard.min.js"></script>
      <script type="text/javascript" src="../../../_static/copybutton.js"></script>
      <script type="text/javascript" src="../../../_static/translations.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script type="text/javascript" src="../../../None"></script>
      <script type="text/javascript" src="https://fastly.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  

  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });


      // var gitalk = new Gitalk({
      //         clientID: '565177626b5d46427009',
      //         clientSecret: 'b2a36e67e1d2a73e43667f46d571c2624f8e1026',
      //         repo: 'knowledge',
      //         owner: 'zhaoweiguo',
      //         admin: ['zhaoweiguo'],
      //         id: location.pathname,      // Ensure uniqueness and length less than 50
      //         distractionFreeMode: false  // Facebook-like distraction free mode
      //       })
      // gitalk.render('gitalk-container')

  </script>


<script type="text/javascript" src="../../../_static/js/table-of-contents-sidebar.js"></script>
<!-- <script type="text/javascript" src="https://table-of-contents-sidebar.github.io/table-of-contents-sidebar-lib/table-of-contents-sidebar.js"></script> -->
<script type="text/javascript">
    window.onload = function(e){
        TableOfContents.init({
            basePath: "https://table-of-contents-sidebar.github.io/table-of-contents-sidebar-lib/",
            querySelector: "body" // or other css querySelector
        });
    }
</script> 

</body>
</html>