

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="zh-CN" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="zh-CN" > <!--<![endif]-->
<head>


<!-- start added 2025-04-14   增加对markdown中公式的支持 -->
<script>
window.MathJax = {
    tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true
    },
    options: {
        ignoreHtmlClass: "tex2jax_ignore|mathjax_ignore",
        processHtmlClass: "tex2jax_process|mathjax_process|math|output_area"
    }
};
</script>
<script defer="defer" src="https://fastly.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<!-- end added 2025-04-14   增加对markdown中公式的支持 -->


  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>AI 绘画核心技术与实战 &mdash; 新溪-gordon V2025.06 文档</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="搜索" href="../../search.html" />
    <link rel="next" title="零基础实战机器学习" href="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html" />
    <link rel="prev" title="AI 大模型系统实战" href="AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98.html" /> 

  
  <script src="../../_static/js/modernizr.min.js"></script>
  <script src="../../_static/js/jquery.min.js"></script>


<!-- 评论插件 gittalk start -->
<!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script> -->
<!-- 评论插件 gittalk end -->


</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> 新溪-gordon
          

          
          </a>

          
            
            
              <div class="version">
                V2025.06
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../book.html">书籍</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../books/bookreview.html">书</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../books/bookreviews/2021.html">2021年看的书</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../books/bookreviews/2021s/cryptography-graph.html">图解密码技术</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/bookreviews/2021s/deep-learning-with-python.html">Deep learning with Python</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/bookreviews/2021s/how-networks-work.html">网络是怎么连接的</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/bookreviews/2021s/building-microservices.html">微服务设计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/bookreviews/2021s/microservice_design_principle_and_architecture.html">微服务设计原理与架构</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/bookreviews/2021s/microservice-governance.html">微服务治理: 体系、架构及实践</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/bookreviews/2021s/TCPIP-ILLustrated-Volume1.html">TCP/IP ILLustrated Volume 1: The Protocols</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/bookreviews/2021s/SRE.html">SRE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/bookreviews/2021s/the-site-reliability-workbook.html">The Site Reliability Workbook</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/bookreviews/2021s/bitcoin-and-cryptocurrency-technologies.html">Bitcoin and Cryptocurrency Technologies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/bookreviews/2021s/other.html">其他</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../books/bookreviews/detail.html">详情</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../books/bookreviews/detail.html#id3">编码实践</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/bookreviews/detail.html#id4">设计模式</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/bookreviews/detail.html#id5">工程实践</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/bookreviews/detail.html#id6">领域驱动设计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/bookreviews/detail.html#id7">产品与需求</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/bookreviews/detail.html#id8">开发文化</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/bookreviews/detail.html#id9">管理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/bookreviews/detail.html#id10">科幻小说</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/bookreviews/detail.html#id11">其他相关</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../books/booklist.html">要看的书</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../books/booklists/classic.html">经典书</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../books/booklists/classic.html#it-core">IT Core</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/booklists/classic.html#id3">编译原理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/booklists/classic.html#id4">组成原理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/booklists/classic.html#it">IT 设计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/booklists/classic.html#id5">管理</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../books/booklists/AI.html">AI 相关</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../books/booklists/AI.html#id2">推荐系统</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../books/booklists/IT.html">IT相关</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../books/booklists/IT.html#id2">区块链</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/booklists/IT.html#id3">统计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/booklists/IT.html#id4">网络</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/booklists/IT.html#id5">实时协同</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../books/booklists/methodology.html">方法论</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../books/booklists/fiction.html">小说</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../books/booklists/fiction.html#science-fiction">科幻小说science fiction</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../books/booklists/source.html">书籍来源</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../books/booklists/sources/geek.html">极客来源</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../books/booklist.html#id3">数学基础</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../books/booklist.html#id4">语言经典</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../books/booklist.html#c">C 语言</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../books/booklist.html#id5">计算机经典</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../books/booklist.html#id6">计算机语言设计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../books/booklist.html#id7">其他</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../books/ai.html">ai</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../books/ais/Microsoft-AI-For-Beginners.html">Microsoft: AI-For-Beginners</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Microsoft-AI-For-Beginners.html#i-introduction-to-ai">I Introduction to AI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Microsoft-AI-For-Beginners.html#ii-symbolic-ai">II Symbolic AI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Microsoft-AI-For-Beginners.html#iii-introduction-to-neural-networks">III Introduction to Neural Networks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Microsoft-AI-For-Beginners.html#iv-computer-vision">IV Computer Vision</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Microsoft-AI-For-Beginners.html#v-nlp">V. NLP</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Microsoft-AI-For-Beginners.html#vi-other">VI. Other</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Microsoft-AI-For-Beginners.html#vii-ethics">VII. Ethics</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../books/ais/Microsoft-ML-for-Beginners.html">Microsoft: Machine Learning for Beginners</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Microsoft-ML-for-Beginners.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Microsoft-ML-for-Beginners.html#regression">2. Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Microsoft-ML-for-Beginners.html#web-app">3. Web-App</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Microsoft-ML-for-Beginners.html#classification">4. Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Microsoft-ML-for-Beginners.html#clustering">5. Clustering</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Microsoft-ML-for-Beginners.html#nlp">6. NLP</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Microsoft-ML-for-Beginners.html#timeseries">7. TimeSeries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Microsoft-ML-for-Beginners.html#reinforcement">8. Reinforcement</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Microsoft-ML-for-Beginners.html#real-world">9. Real-World</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../books/ais/Microsoft-Generative-AI-For-Beginners.html">Microsoft: Generative AI For Beginners</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Microsoft-Generative-AI-For-Beginners.html#id2">第一章: 简介</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Microsoft-Generative-AI-For-Beginners.html#llms">第二章: 不同的 LLMs对比</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Microsoft-Generative-AI-For-Beginners.html#ai">第三章: AI安全</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Microsoft-Generative-AI-For-Beginners.html#id3">第四章: 提示工程基础</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Microsoft-Generative-AI-For-Beginners.html#id4">第五章: 提示工程进阶</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Microsoft-Generative-AI-For-Beginners.html#id5">第八章: 创建搜索应用</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../books/ais/Getting-Started-with-OpenCV.html">Getting Started with OpenCV</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../books/ais/Microsoft-Learn-Introduction-to-PyTorch.html">Microsoft Learn: Introduction to PyTorch</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Microsoft-Learn-Introduction-to-PyTorch.html#id2">简介</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../books/ais/Microsoft-Learn-Introduction-to-NLP-with-PyTorch.html">Microsoft Learn: Introduction to NLP with PyTorch</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Microsoft-Learn-Introduction-to-NLP-with-PyTorch.html#id2">简介</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Microsoft-Learn-Introduction-to-NLP-with-PyTorch.html#representing-text-as-tensors">2. Representing text as Tensors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Microsoft-Learn-Introduction-to-NLP-with-PyTorch.html#bag-of-words-and-tf-idf-representations">3. Bag-of-Words and TF-IDF representations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Microsoft-Learn-Introduction-to-NLP-with-PyTorch.html#embeddings">4. Embeddings</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../books/ais/HuggingFace-Learn.html">HuggingFace: Learn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../books/ais/Kaggle-Learn.html">Kaggle Learn</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Kaggle-Learn.html#intermediate-machine-learning">Intermediate Machine Learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Kaggle-Learn.html#intro-to-deep-learning">Intro to Deep Learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/Kaggle-Learn.html#id4">参考</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../books/ais/scikit-learn.html">scikit-learn 1.3.2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../books/ais/2024/Build_LLM_From_Scratch.html">Build a Large Language Model (From Scratch)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/2024/Build_LLM_From_Scratch.html#understanding-llm">1. Understanding LLM</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/2024/Build_LLM_From_Scratch.html#working-with-text-data">2. Working with Text Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/2024/Build_LLM_From_Scratch.html#coding-attention-mechanisms">3. Coding Attention Mechanisms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/2024/Build_LLM_From_Scratch.html#implementing-a-gpt-model-from-scratch-to-generate-text">4 Implementing a GPT model from Scratch To Generate Text</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/2024/Build_LLM_From_Scratch.html#pretraining-on-unlabeled-data">5 Pretraining on Unlabeled Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/2024/Build_LLM_From_Scratch.html#fine-tuning-for-classification">6 Fine-tuning for classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/2024/Build_LLM_From_Scratch.html#fine-tuning-to-follow-instructions">7 Fine-tuning to follow instructions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/2024/Build_LLM_From_Scratch.html#appendix-a-introduction-to-pytorch">Appendix A. Introduction to PyTorch</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/2024/Build_LLM_From_Scratch.html#appendix-b-references-and-further-reading">Appendix B. References and Further Reading</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/2024/Build_LLM_From_Scratch.html#appendix-c-exercise-solutions">Appendix C. Exercise Solutions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/2024/Build_LLM_From_Scratch.html#appendix-d-adding-bells-and-whistles-to-the-training-loop">Appendix D. Adding Bells and Whistles to the Training Loop</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/2024/Build_LLM_From_Scratch.html#appendix-e-parameter-efficient-fine-tuning-with-lora">appendix E Parameter-efficient fine- tuning with LoRA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/2024/Build_LLM_From_Scratch.html#id8">其他</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../books/ais/2024/Dive_into_Deep_Learning.html">动手学深度学习(Dive into Deep Learning)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/2024/Dive_into_Deep_Learning.html#id2">前言</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/2024/Dive_into_Deep_Learning.html#part-1-basics-and-preliminaries">Part 1: Basics and Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/2024/Dive_into_Deep_Learning.html#part-2-modern-deep-learning-techniques">Part 2: Modern Deep Learning Techniques</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/ais/2024/Dive_into_Deep_Learning.html#part-3-scalability-efficiency-and-applications">Part 3: Scalability, Efficiency, and Applications</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../books/architecture.html">架构相关</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../books/architectures/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86%E4%B8%8E%E6%9E%B6%E6%9E%84.html">微服务设计原理与架构</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../books/architectures/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86%E4%B8%8E%E6%9E%B6%E6%9E%84.html#id3">微服务建模</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/architectures/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86%E4%B8%8E%E6%9E%B6%E6%9E%84.html#id17">服务拆分与集成</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/architectures/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86%E4%B8%8E%E6%9E%B6%E6%9E%84.html#id18">微服务架构关键要素</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/architectures/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86%E4%B8%8E%E6%9E%B6%E6%9E%84.html#id21">参考</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../books/architectures/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E7%B2%BE%E7%B2%B9.html">领域驱动设计精粹</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../books/architectures/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E7%B2%BE%E7%B2%B9.html#id4">第 2 章 运用限界上下文与通用语言进行战略设计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/architectures/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E7%B2%BE%E7%B2%B9.html#id6">第 3 章 运用子域进行战略设计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/architectures/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E7%B2%BE%E7%B2%B9.html#id7">第 4 章 运用上下文映射进行战略设计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/architectures/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E7%B2%BE%E7%B2%B9.html#id8">第 5 章 运用聚合进行战术设计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/architectures/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E7%B2%BE%E7%B2%B9.html#id9">第 6 章 运用领域事件进行战术设计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/architectures/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E7%B2%BE%E7%B2%B9.html#id10">第 7 章 加速和管理工具</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../books/architectures/%E5%AE%9E%E7%8E%B0%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1.html">实现领域驱动设计</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../books/architectures/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1.html">领域驱动设计</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../books/optimize.html">优化相关</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../books/optimizes/%E6%80%A7%E8%83%BD%E4%B9%8B%E5%B7%85.html">性能之巅</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../books/optimizes/%E6%80%A7%E8%83%BD%E4%B9%8B%E5%B7%85.html#id3">书评</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../books/protocol.html">协议相关</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html">UNIX 网络编程卷1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id3">第1章 简介</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#tcp-udpsctp">第2章 传输层: TCP, UDP和SCTP</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id8">第3章 套接字编程简介</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id14">第4章 基本TCP套接字编程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id16">第5章 TCP客户/服务器程序示例</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#i-o-selectpoll">第6章 I/O复用: select和poll函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id24">第7章 套接字选项</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#udp">第8章 基本UDP套接字编程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id26">第9章 基本SCTP套接字编程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id27">第11章 名字与地址转换</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#ipv4ipv6">第12章 IPv4与IPv6的互操作性</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#inetd">第13章 守护进程和inetd超级服务器</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id31">第14章 高级I/O函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#unix">第15章 Unix域协议</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id35">第16章 非阻塞式I/O</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#ioctl">第17章 ioctl操作</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id36">第18章 路由套接字</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id37">第19章 密钥管理套接字</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id38">第20章 广播</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id41">第21章 多播</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id47">第22章 高级UDP套接字编程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id51">第23章 高级SCTP套接字编程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id52">第24章 带外数据</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id57">第25章 信号驱动式I/O</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id58">第26章 线程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#ip">第27章 IP选项</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id66">第28章 原始套接字</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id70">第29章 数据链路访问</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id74">第30章 客户/服务器程序设计范式</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#a-ipv4-ipv6-icmpv4icmpv6">附录A IPv4, IPv6, ICMPv4和ICMPv6</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/UNIX%20%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8D%B71.html#id77">其他</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../books/protocols/TCP-IP%20%E8%AF%A6%E6%83%85%E5%8D%B71.html">TCP/IP 详情-卷1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/TCP-IP%20%E8%AF%A6%E6%83%85%E5%8D%B71.html#id3">第1章 概 述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/TCP-IP%20%E8%AF%A6%E6%83%85%E5%8D%B71.html#id4">第2章 链 路 层</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/TCP-IP%20%E8%AF%A6%E6%83%85%E5%8D%B71.html#ip">第3章 IP:网际协议</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/TCP-IP%20%E8%AF%A6%E6%83%85%E5%8D%B71.html#id15">其他</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../books/protocols/TCP-IP%20%E8%AF%A6%E6%83%85%E5%8D%B71-%E7%AC%AC2%E7%89%88.html">TCP:IP 详情卷1-第2版</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../books/protocols/TCP-IP%20%E8%AF%A6%E6%83%85%E5%8D%B71-%E7%AC%AC2%E7%89%88.html#id3">第1章 概 述</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../books/edge.html">边缘相关</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../books/edges/%E9%9B%BE%E8%AE%A1%E7%AE%97%E4%B8%8E%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%EF%BC%9A%E5%8E%9F%E7%90%86%E5%8F%8A%E8%8C%83%E5%BC%8F.html">雾计算与边缘计算: 原理及范式</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html">边缘计算入门 20 课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#id3">第 01 课: 边缘计算深度调研</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#id17">第 02 课: 云走向边缘, 云将无处不在</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#id27">第 03 课: 信通院-边缘计算发展现状与趋势展望</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#edgerec">第 04 课: EdgeRec: 边缘计算在推荐系统中的应用</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#id51">第 05 课: 阿里云边缘云原生应用实践应用实践</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#kubeedge-sedna-0-1">第 06 课: KubeEdge 子项目 Sedna 0.1 发布</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#superedge">第 07 课: 用 SuperEdge 统管边缘设备和机器</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#k8s-10">第 08 课: 如何使用 k8s 管理 10 万边缘节点</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#ai">第 09 课: 边云协同-打通 AI 最后一公里</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#edgeadm-k8s">第 10 课: 用 edgeadm 一键安装边缘 K8s 集群</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#kubeedge-10086">第 11 课: 基于 KubeEdge 实现 10086 客服云边协同平台</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#volcano">第 12 课: Volcano 架构设计与原理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#id57">第 13 课: 一文读懂 SuperEdge 的云边隧道</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#id58">第 14 课: 打破内网壁垒-从云端一次添加上千边缘节点</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#id59">第 15 课: 一文读懂 SuperEdge 边缘容器架构与原理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#id60">第 16 课: 2020 十大边缘计算开源项目</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#addon-superedge-k8s">第 17 课: Addon SuperEdge 让原生 K8s 管理边缘应用</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#id63">第 18 课: SuperEdge 云边隧道新特性</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#id64">第 19 课: 《深入理解边缘计算》</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#fabedge">第 20 课: FabEdge 边缘网络方案</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#id65">第 21 课: 边缘计算云原生开源方案选型比较</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%2020%20%E8%AF%BE.html#id66">参考</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5.html">边缘计算方法与工程实践</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5.html#id3">第1章 边缘计算综述</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5.html#id4">第2章 边缘计算基础资源架构技术</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5.html#id5">第3章 边缘计算软件架构</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5.html#id7">第4章 边缘计算安全管理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5.html#id23">第5章 边缘计算应用案例</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/edges/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%E4%B8%8E%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5.html#id39">第6章 边缘计算发展展望</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../books/iot.html">物联网相关</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../books/iots/%E5%9B%BE%E8%A7%A3%E7%89%A9%E8%81%94%E7%BD%91.html">图解物联网</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../books/iots/%E5%9B%BE%E8%A7%A3%E7%89%A9%E8%81%94%E7%BD%91.html#id3">第1章 物联网的基础知识</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/iots/%E5%9B%BE%E8%A7%A3%E7%89%A9%E8%81%94%E7%BD%91.html#id4">第 2 章 物联网的架构</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/iots/%E5%9B%BE%E8%A7%A3%E7%89%A9%E8%81%94%E7%BD%91.html#id5">第 3 章 物联网设备</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/iots/%E5%9B%BE%E8%A7%A3%E7%89%A9%E8%81%94%E7%BD%91.html#id9">第 4 章 先进的感测技术</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/iots/%E5%9B%BE%E8%A7%A3%E7%89%A9%E8%81%94%E7%BD%91.html#id12">第 5 章 物联网服务的系统开发</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/iots/%E5%9B%BE%E8%A7%A3%E7%89%A9%E8%81%94%E7%BD%91.html#id14">第 6 章 物联网与数据分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/iots/%E5%9B%BE%E8%A7%A3%E7%89%A9%E8%81%94%E7%BD%91.html#id15">第 7 章 物联网与可穿戴设备</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../books/iots/%E5%9B%BE%E8%A7%A3%E7%89%A9%E8%81%94%E7%BD%91.html#id16">第 8 章 物联网与机器人</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../books/iots/%E7%89%A9%E8%81%94%E7%BD%91%E8%AE%BE%E8%AE%A1.html">物联网设计</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../books/iots/%E7%89%A9%E8%81%94%E7%BD%91%E8%AE%BE%E8%AE%A1.html#id3">第一部分 原型阶段</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../books/iots/%E8%87%AA%E5%B7%B1%E5%8A%A8%E6%89%8B%E8%AE%BE%E8%AE%A1%E7%89%A9%E8%81%94%E7%BD%91.html">自己动手设计物联网</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../books/lang.html">编程语言相关</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../books/langs/C%20%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1.html">C 程序设计</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../../geek.html">极客时间</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../principle.html">[重要]编程基础</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../principles/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86.html">深入浅出计算机组成原理</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86.html#id4">指令和运算</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86.html#id15">处理器</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86.html#id35">书籍</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../principles/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98.html">网络编程实战</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98.html#id4">第一模块: 基础篇</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98.html#id28">第二模块: 提高篇</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98.html#id48">第三模块: 性能篇</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98.html#id62">第四模块: 实战篇</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98.html#id63">结束语</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../principles/%E8%B6%A3%E8%B0%88%20Linux%20%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html">趣谈 Linux 操作系统</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E8%B6%A3%E8%B0%88%20Linux%20%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html#id2">第二部分 系统初始化 (4 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E8%B6%A3%E8%B0%88%20Linux%20%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html#id10">第三部分 进程管理 (10 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E8%B6%A3%E8%B0%88%20Linux%20%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html#id34">第四部分 内存管理 (7 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E8%B6%A3%E8%B0%88%20Linux%20%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html#id51">第五部分 文件系统 (4 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E8%B6%A3%E8%B0%88%20Linux%20%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html#id60">第六部分 输入输出系统 (5 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E8%B6%A3%E8%B0%88%20Linux%20%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html#id69">第七部分 进程间通信 (7 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E8%B6%A3%E8%B0%88%20Linux%20%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html#id83">第八部分 网络系统 (7 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E8%B6%A3%E8%B0%88%20Linux%20%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html#id90">第九部分 虚拟化 (7 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E8%B6%A3%E8%B0%88%20Linux%20%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html#id100">第十部分 容器化 (4 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E8%B6%A3%E8%B0%88%20Linux%20%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html#id105">实战串讲篇 (9 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E8%B6%A3%E8%B0%88%20Linux%20%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html#id106">学习攻略</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html">编译原理实战课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#id4">语法分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#id7">语义分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#id10">运行时机制</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#ir">中间代码 IR</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#id11">代码优化</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#id12">代码生成</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#ast">解析树和 AST 的区别</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#golang">Golang</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#erlang">Erlang</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#id15">并发</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#meta-programming">元编程-Meta-Programming</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#id19">泛型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#id20">函数式编程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#id21">远程办公</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#id22">如何学习</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#id23">收集</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E5%AE%9E%E6%88%98%E8%AF%BE.html#id24">参考</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../principles/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98.html">操作系统实战</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98.html#id4">整体设计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98.html#id6">程序的基石：硬件</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98.html#id7">同步原语</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98.html#id8">参考</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../principles/%E6%89%8B%E6%8A%8A%E6%89%8B%E5%B8%A6%E4%BD%A0%E5%86%99%E4%B8%80%E9%97%A8%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80.html">手把手带你写一门编程语言</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E6%89%8B%E6%8A%8A%E6%89%8B%E5%B8%A6%E4%BD%A0%E5%86%99%E4%B8%80%E9%97%A8%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80.html#id4">开篇</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E6%89%8B%E6%8A%8A%E6%89%8B%E5%B8%A6%E4%BD%A0%E5%86%99%E4%B8%80%E9%97%A8%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80.html#id5">词法分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E6%89%8B%E6%8A%8A%E6%89%8B%E5%B8%A6%E4%BD%A0%E5%86%99%E4%B8%80%E9%97%A8%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80.html#id6">语法分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E6%89%8B%E6%8A%8A%E6%89%8B%E5%B8%A6%E4%BD%A0%E5%86%99%E4%B8%80%E9%97%A8%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80.html#id7">语义分析</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../principles/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E8%AF%BE.html">计算机基础实战课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E8%AF%BE.html#id3">课程设计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E8%AF%BE.html#id4">01以史为鉴 (3讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E8%AF%BE.html#mini-cpu-9">02硬件-芯片(手写mini CPU) (9讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E8%AF%BE.html#id11">03环境准备 (2讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E8%AF%BE.html#id12">04语言与指令 (9讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E8%AF%BE.html#id13">05应用与内存 (8讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E8%AF%BE.html#id30">06国庆策划 (3讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E8%AF%BE.html#io-6">07IO与文件 (6讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E8%AF%BE.html#id36">08综合应用 (6讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E8%AF%BE.html#id44">09结束语 (4讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../principles/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E8%AF%BE.html#id45">10技术雷达 (5讲)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../architecture.html">架构相关</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../architectures/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E.html">左耳听风-陈皓</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E.html#id4">程序员如何用技术变现</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E.html#id19">05 _ 何为技术领导力</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E5%B7%A6%E8%80%B3%E5%90%AC%E9%A3%8E.html#id25">06 _ 如何才能拥有技术领导力</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../architectures/%E8%AE%B8%E5%BC%8F%E4%BC%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html">许式伟的架构课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E8%AE%B8%E5%BC%8F%E4%BC%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id4">编程语言</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E8%AE%B8%E5%BC%8F%E4%BC%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id9">操作系统</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E8%AE%B8%E5%BC%8F%E4%BC%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id10">外置存储</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E8%AE%B8%E5%BC%8F%E4%BC%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id11">需求分析</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E8%AE%B8%E5%BC%8F%E4%BC%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id12">详细设计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E8%AE%B8%E5%BC%8F%E4%BC%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id13">导致故障的因素</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E8%AE%B8%E5%BC%8F%E4%BC%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id14">软件架构</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E8%AE%B8%E5%BC%8F%E4%BC%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id15">架构设计文档</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E8%AE%B8%E5%BC%8F%E4%BC%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id20">软件质量管理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E8%AE%B8%E5%BC%8F%E4%BC%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id21">软件工程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E8%AE%B8%E5%BC%8F%E4%BC%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id22">架构设计的优劣</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E8%AE%B8%E5%BC%8F%E4%BC%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id23">参考</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../architectures/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E4%B9%8B%E7%BE%8E.html">软件工程之美</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../architectures/md/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E4%B9%8B%E7%BE%8Esummary.html">软件工程之美summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/md/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E4%B9%8B%E7%BE%8E.html">软件工程之美</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E4%B9%8B%E7%BE%8E.html#id3">基础理论 (9 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E4%B9%8B%E7%BE%8E.html#id20">需求分析篇</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E4%B9%8B%E7%BE%8E.html#id26">系统设计篇</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E4%B9%8B%E7%BE%8E.html#id31">开发编码篇 (7 讲)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../architectures/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%BE%8E.html">设计模式之美</a></li>
<li class="toctree-l3"><a class="reference internal" href="../architectures/DDD%20%E5%AE%9E%E6%88%98%E8%AF%BE.html">DDD 实战课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../architectures/DDD%20%E5%AE%9E%E6%88%98%E8%AF%BE.html#id3">开篇词</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/DDD%20%E5%AE%9E%E6%88%98%E8%AF%BE.html#id8">基础篇 (5 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/DDD%20%E5%AE%9E%E6%88%98%E8%AF%BE.html#id30">02进阶篇 (6 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/DDD%20%E5%AE%9E%E6%88%98%E8%AF%BE.html#id61">03实战篇 (10 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/DDD%20%E5%AE%9E%E6%88%98%E8%AF%BE.html#id107">结束语</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../architectures/%E6%9E%B6%E6%9E%84%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E8%A7%A3%E6%9E%90.html">架构实战案例解析</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E6%9E%B6%E6%9E%84%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E8%A7%A3%E6%9E%90.html#id4">01概述篇 (2 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E6%9E%B6%E6%9E%84%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E8%A7%A3%E6%9E%90.html#id12">02业务架构篇 (9 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E6%9E%B6%E6%9E%84%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E8%A7%A3%E6%9E%90.html#id47">03技术架构篇 (9 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E6%9E%B6%E6%9E%84%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E8%A7%A3%E6%9E%90.html#id79">总结篇 (2 讲)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../architectures/%E4%B9%94%E6%96%B0%E4%BA%AE%E7%9A%84%20CTO%20%E6%88%90%E9%95%BF%E5%A4%8D%E7%9B%98.html">乔新亮的 CTO 成长复盘</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E4%B9%94%E6%96%B0%E4%BA%AE%E7%9A%84%20CTO%20%E6%88%90%E9%95%BF%E5%A4%8D%E7%9B%98.html#id3">00开篇词</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E4%B9%94%E6%96%B0%E4%BA%AE%E7%9A%84%20CTO%20%E6%88%90%E9%95%BF%E5%A4%8D%E7%9B%98.html#id4">01对个人认知的复盘 (6 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E4%B9%94%E6%96%B0%E4%BA%AE%E7%9A%84%20CTO%20%E6%88%90%E9%95%BF%E5%A4%8D%E7%9B%98.html#id11">02对管理工作的复盘 (10 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E4%B9%94%E6%96%B0%E4%BA%AE%E7%9A%84%20CTO%20%E6%88%90%E9%95%BF%E5%A4%8D%E7%9B%98.html#id22">03对专业成长的复盘 (10 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E4%B9%94%E6%96%B0%E4%BA%AE%E7%9A%84%20CTO%20%E6%88%90%E9%95%BF%E5%A4%8D%E7%9B%98.html#id34">结束语</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../architectures/%E5%A6%82%E4%BD%95%E8%90%BD%E5%9C%B0%E4%B8%9A%E5%8A%A1%E5%BB%BA%E6%A8%A1.html">如何落地业务建模</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E5%A6%82%E4%BD%95%E8%90%BD%E5%9C%B0%E4%B8%9A%E5%8A%A1%E5%BB%BA%E6%A8%A1.html#id3">开篇词</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E5%A6%82%E4%BD%95%E8%90%BD%E5%9C%B0%E4%B8%9A%E5%8A%A1%E5%BB%BA%E6%A8%A1.html#id4">旧约: “前云时代” 的领域驱动设计 (11 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E5%A6%82%E4%BD%95%E8%90%BD%E5%9C%B0%E4%B8%9A%E5%8A%A1%E5%BB%BA%E6%A8%A1.html#id6">深度答疑专题 (4 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E5%A6%82%E4%BD%95%E8%90%BD%E5%9C%B0%E4%B8%9A%E5%8A%A1%E5%BB%BA%E6%A8%A1.html#id7">新约: 云时代的业务建模 (2 讲)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../architectures/%E9%83%AD%E4%B8%9C%E7%99%BD%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html">郭东白的架构课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E9%83%AD%E4%B8%9C%E7%99%BD%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id3">我的收获</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E9%83%AD%E4%B8%9C%E7%99%BD%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id4">课程设计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E9%83%AD%E4%B8%9C%E7%99%BD%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id5">00开篇词|没有战略意图,就成不了一个顶尖的架构师</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E9%83%AD%E4%B8%9C%E7%99%BD%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id6">01模块一:生存法则 (15 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E9%83%AD%E4%B8%9C%E7%99%BD%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id45">02模块二:创造价值 (21讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E9%83%AD%E4%B8%9C%E7%99%BD%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id98">03模块三:职业成长 (9讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E9%83%AD%E4%B8%9C%E7%99%BD%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id113">04模块四:思考力 (11讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E9%83%AD%E4%B8%9C%E7%99%BD%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id138">05结束语</a></li>
<li class="toctree-l4"><a class="reference internal" href="../architectures/%E9%83%AD%E4%B8%9C%E7%99%BD%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AF%BE.html#id139">06加餐</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../architectures/%E6%9D%8E%E6%99%BA%E6%85%A7%20%C2%B7%20%E9%AB%98%E5%B9%B6%E5%8F%91%E6%9E%B6%E6%9E%84%E5%AE%9E%E6%88%98%E8%AF%BE.html">李智慧 · 高并发架构实战课</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../secure.html">安全</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html">实用密码学</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id4">00开篇词 _ 人人都要会点密码学</a></li>
<li class="toctree-l4"><a class="reference internal" href="../secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id5">01 | 学习密码学有什么用</a></li>
<li class="toctree-l4"><a class="reference internal" href="../secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id6">02 | 单向散列函数: 如何保证信息完整性</a></li>
<li class="toctree-l4"><a class="reference internal" href="../secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id7">03 | 如何设置合适的安全强度</a></li>
<li class="toctree-l4"><a class="reference internal" href="../secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id11">04 | 选择哈希算法应该考虑哪些因素</a></li>
<li class="toctree-l4"><a class="reference internal" href="../secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id14">05|如何有效避免长度延展攻击</a></li>
<li class="toctree-l4"><a class="reference internal" href="../secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id15">06|对称密钥: 如何保护私密数据</a></li>
<li class="toctree-l4"><a class="reference internal" href="../secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id18">07 | 怎么选择对称密钥算法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#ecb">09 | 为什么ECB模式不安全</a></li>
<li class="toctree-l4"><a class="reference internal" href="../secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#cbc">10 | 怎么防止数据重放攻击CBC</a></li>
<li class="toctree-l4"><a class="reference internal" href="../secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id32">11 | 怎么利用解密端攻击</a></li>
<li class="toctree-l4"><a class="reference internal" href="../secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id39">12 | 怎么利用加密端攻击</a></li>
<li class="toctree-l4"><a class="reference internal" href="../secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id45">13 | 如何防止数据被调包</a></li>
<li class="toctree-l4"><a class="reference internal" href="../secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id50">14 | 加密数据能够自我验证吗</a></li>
<li class="toctree-l4"><a class="reference internal" href="../secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#aead">15 | AEAD 有哪些安全陷阱</a></li>
<li class="toctree-l4"><a class="reference internal" href="../secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id57">16 | 为什么说随机数都是骗人的</a></li>
<li class="toctree-l4"><a class="reference internal" href="../secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id65">17 | 加密密钥是怎么来的</a></li>
<li class="toctree-l4"><a class="reference internal" href="../secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id69">18 | 如何管理对称密钥</a></li>
<li class="toctree-l4"><a class="reference internal" href="../secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id74">19|量子时代,你准备好了吗</a></li>
<li class="toctree-l4"><a class="reference internal" href="../secures/%E5%AE%9E%E7%94%A8%E5%AF%86%E7%A0%81%E5%AD%A6.html#id78">结束语</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../secures/Web%20%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E5%AE%9E%E6%88%98.html">Web 安全攻防实战</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../secures/Web%20%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E5%AE%9E%E6%88%98.html#id2">1. 前端基础</a></li>
<li class="toctree-l4"><a class="reference internal" href="../secures/Web%20%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E5%AE%9E%E6%88%98.html#id5">2. Web安全之后端安全</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../testing.html">测试相关</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../testings/%E6%8E%A5%E5%8F%A3%E6%B5%8B%E8%AF%95%E5%85%A5%E9%97%A8%E8%AF%BE.html">接口测试入门课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../testings/%E6%8E%A5%E5%8F%A3%E6%B5%8B%E8%AF%95%E5%85%A5%E9%97%A8%E8%AF%BE.html#id3">点评</a></li>
<li class="toctree-l4"><a class="reference internal" href="../testings/%E6%8E%A5%E5%8F%A3%E6%B5%8B%E8%AF%95%E5%85%A5%E9%97%A8%E8%AF%BE.html#id4">开篇词 | 把接口测试这件小事做深/做透</a></li>
<li class="toctree-l4"><a class="reference internal" href="../testings/%E6%8E%A5%E5%8F%A3%E6%B5%8B%E8%AF%95%E5%85%A5%E9%97%A8%E8%AF%BE.html#id5">01 | 基础: 跳出细节看全局</a></li>
<li class="toctree-l4"><a class="reference internal" href="../testings/%E6%8E%A5%E5%8F%A3%E6%B5%8B%E8%AF%95%E5%85%A5%E9%97%A8%E8%AF%BE.html#id6">02 | 方法论: 没有任何文档, 怎么才能快速了解接口的信息</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../testings/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%B5%8B%E8%AF%95%E8%AF%BE.html">程序员的测试课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../testings/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%B5%8B%E8%AF%95%E8%AF%BE.html#id3">开篇词</a></li>
<li class="toctree-l4"><a class="reference internal" href="../testings/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%B5%8B%E8%AF%95%E8%AF%BE.html#id5">基础篇 (11 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../testings/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%B5%8B%E8%AF%95%E8%AF%BE.html#id36">应用篇 (5 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../testings/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%B5%8B%E8%AF%95%E8%AF%BE.html#id40">03扩展篇 (2 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../testings/%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%B5%8B%E8%AF%95%E8%AF%BE.html#id41">结束语</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../testings/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%2052%20%E8%AE%B2.html">软件测试 52 讲</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../testings/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%2052%20%E8%AE%B2.html#id3">01测试基础知识篇 (11讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../testings/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%2052%20%E8%AE%B2.html#gui-10">02GUI自动化测试篇 (10讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../testings/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%2052%20%E8%AE%B2.html#api-3">03API自动化测试篇 (3讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../testings/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%2052%20%E8%AE%B2.html#id14">04代码测试篇 (3讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../testings/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%2052%20%E8%AE%B2.html#id16">05性能测试篇 (7讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../testings/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%2052%20%E8%AE%B2.html#id17">06测试数据准备篇 (4讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../testings/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%2052%20%E8%AE%B2.html#id18">07测试基础架构篇 (4讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../testings/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%2052%20%E8%AE%B2.html#id19">08测试新技术篇 (5讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../testings/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%2052%20%E8%AE%B2.html#id24">09测试人员的互联网架构核心知识篇 (5讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../testings/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%2052%20%E8%AE%B2.html#id25">10特别放送篇 (8讲)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../cloudnative.html">云原生</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../cloudnatives/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE.html">容器实战高手课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../cloudnatives/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE.html#namespace">Namespace</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cloudnatives/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE.html#cgroups">Cgroups</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cloudnatives/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE.html#linux-kernel">Linux Kernel</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cloudnatives/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE.html#load-average">Load Average</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cloudnatives/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE.html#memory-cgroup">Memory Cgroup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cloudnatives/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE.html#id4">存储</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cloudnatives/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE.html#network">Network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cloudnatives/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE.html#id5">容器安全</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cloudnatives/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE.html#k8s">k8s</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cloudnatives/%E5%AE%B9%E5%99%A8%E5%AE%9E%E6%88%98%E9%AB%98%E6%89%8B%E8%AF%BE.html#id6">思考</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../manager.html">管理&amp;长成</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../managers/%E8%B7%9F%E7%9D%80%E9%AB%98%E6%89%8B%E5%AD%A6%E5%A4%8D%E7%9B%98.html">跟着高手学复盘</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E8%B7%9F%E7%9D%80%E9%AB%98%E6%89%8B%E5%AD%A6%E5%A4%8D%E7%9B%98.html#id3">01基础概念篇 (3 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E8%B7%9F%E7%9D%80%E9%AB%98%E6%89%8B%E5%AD%A6%E5%A4%8D%E7%9B%98.html#id8">02实操流程篇 (9 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E8%B7%9F%E7%9D%80%E9%AB%98%E6%89%8B%E5%AD%A6%E5%A4%8D%E7%9B%98.html#id64">03实战案例篇 (7 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E8%B7%9F%E7%9D%80%E9%AB%98%E6%89%8B%E5%AD%A6%E5%A4%8D%E7%9B%98.html#id76">结束语</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E8%B7%9F%E7%9D%80%E9%AB%98%E6%89%8B%E5%AD%A6%E5%A4%8D%E7%9B%98.html#id77">春节荐书</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../managers/%E7%A8%8B%E5%BA%8F%E5%91%98%E8%BF%9B%E9%98%B6%E6%94%BB%E7%95%A5.html">程序员进阶攻略</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E7%A8%8B%E5%BA%8F%E5%91%98%E8%BF%9B%E9%98%B6%E6%94%BB%E7%95%A5.html#id4">启程</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E7%A8%8B%E5%BA%8F%E5%91%98%E8%BF%9B%E9%98%B6%E6%94%BB%E7%95%A5.html#id7">修炼</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E7%A8%8B%E5%BA%8F%E5%91%98%E8%BF%9B%E9%98%B6%E6%94%BB%E7%95%A5.html#id22">修行</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E7%A8%8B%E5%BA%8F%E5%91%98%E8%BF%9B%E9%98%B6%E6%94%BB%E7%95%A5.html#id92">徘徊</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E7%A8%8B%E5%BA%8F%E5%91%98%E8%BF%9B%E9%98%B6%E6%94%BB%E7%95%A5.html#id124">寻路</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E7%A8%8B%E5%BA%8F%E5%91%98%E8%BF%9B%E9%98%B6%E6%94%BB%E7%95%A5.html#id137">蜕变</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../managers/10x%20%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B7%A5%E4%BD%9C%E6%B3%95.html">10x 程序员工作法</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../managers/10x%20%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B7%A5%E4%BD%9C%E6%B3%95.html#id3">思考框架</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/10x%20%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B7%A5%E4%BD%9C%E6%B3%95.html#id4">四个思考原则</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/10x%20%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B7%A5%E4%BD%9C%E6%B3%95.html#id5">总结</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/10x%20%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B7%A5%E4%BD%9C%E6%B3%95.html#id6">一. 以终为始</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/10x%20%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B7%A5%E4%BD%9C%E6%B3%95.html#id12">二. 任务分解</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/10x%20%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B7%A5%E4%BD%9C%E6%B3%95.html#id17">三. 沟通反馈</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/10x%20%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B7%A5%E4%BD%9C%E6%B3%95.html#id18">四. 自动化</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/10x%20%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B7%A5%E4%BD%9C%E6%B3%95.html#id19">五. 综合运用</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/10x%20%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B7%A5%E4%BD%9C%E6%B3%95.html#id20">好书推荐</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/10x%20%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B7%A5%E4%BD%9C%E6%B3%95.html#id28">提问</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html">大厂晋升指南</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id4">晋升原则</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id5">晋升逻辑</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id6">能力模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id7">职级档次</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#p7">P7</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#p8">P8</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#p9">P9</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#p10-p11">P10/P11</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#ppt">面评技巧-PPT框架</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id18">面评技巧-PPT 讲解</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id19">面评技巧-PPT 答辩</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id20">面评技巧-注意点</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id24">面评技巧-技术大会</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id25">面评技巧-其他</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id26">学习方法-指导原则</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id27">学习方法-找时间：海绵学习法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id28">学习方法-学什么：三段分解法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id29">学习方法-怎么学</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id33">学习方法-保证效果</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id34">做事方法-总</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#kpi-okr">做事方法-KPI&amp;OKR</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#c">做事方法-3C 方案设计法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#pdca">做事方法-PDCA执行法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#w">做事方法-5W根因分析法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#s">做事方法-5S 问题处理法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#d">做事方法-4D 总结法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id35">做事方法-金字塔汇报法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id37">做事方法-四线复盘法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id38">专项提升-业务</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#w1h8c1d">专项提升-业务:5W1H8C1D 分析法</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#aarrr">专项提升-业务:AARRR 漏斗模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id39">专项提升-业务:宝洁战略模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id40">专项提升-管理</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id41">专项提升-管理:管理四象限</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id42">专项提升-管理:管理五模式</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id43">别人的心得</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id44">其他</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id46">10000小时定律</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id47">领域分层图</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id48">参考</a></li>
<li class="toctree-l4"><a class="reference internal" href="../managers/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97.html#id53">其他</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../analysis.html">数据分析</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2.html">数据分析实战 45 讲</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2.html#id4">思维导图</a></li>
<li class="toctree-l4"><a class="reference internal" href="../analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2.html#id5">开篇词 | 你为什么需要数据分析能力</a></li>
<li class="toctree-l4"><a class="reference internal" href="../analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2.html#id10">01基础篇 (16 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2.html#id24">02算法篇 (20 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2.html#id37">03实战篇 (7 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2.html#id44">04工作篇 (2 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845%E8%AE%B2.html#id47">结束语</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%80%9D%E7%BB%B4%E8%AF%BE.html">数据分析思维课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%80%9D%E7%BB%B4%E8%AF%BE.html#id4">思维导图</a></li>
<li class="toctree-l4"><a class="reference internal" href="../analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%80%9D%E7%BB%B4%E8%AF%BE.html#id5">00开篇词 (2 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%80%9D%E7%BB%B4%E8%AF%BE.html#id7">01数据分析基础 (11 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%80%9D%E7%BB%B4%E8%AF%BE.html#id34">02数据算法基础 (9 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%80%9D%E7%BB%B4%E8%AF%BE.html#id50">03如何用数据说话 (6 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%80%9D%E7%BB%B4%E8%AF%BE.html#id68">04分析工具 (5 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%80%9D%E7%BB%B4%E8%AF%BE.html#id74">05特别放送 (6 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%80%9D%E7%BB%B4%E8%AF%BE.html#id75">其他</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="../ai.html">AI 相关</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80%E8%AF%BE.html">人工智能基础课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80%E8%AF%BE.html#id4">数学基础</a></li>
<li class="toctree-l4"><a class="reference internal" href="%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80%E8%AF%BE.html#id12">机器学习</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F.html">推荐系统三十六式</a><ul>
<li class="toctree-l4"><a class="reference internal" href="%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F.html#id4">内容推荐</a></li>
<li class="toctree-l4"><a class="reference internal" href="%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F.html#id9">近邻推荐</a></li>
<li class="toctree-l4"><a class="reference internal" href="%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F.html#id18">矩阵分解</a></li>
<li class="toctree-l4"><a class="reference internal" href="%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%89%E5%8D%81%E5%85%AD%E5%BC%8F.html#id19">个人成长</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E7%BE%8E.html">AI 大模型之美</a><ul>
<li class="toctree-l4"><a class="reference internal" href="AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E7%BE%8E.html#id2">课前必读 (2 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E7%BE%8E.html#id5">基础知识篇: 探索大型语言模型的能力 (8 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E7%BE%8E.html#nlp-10">实战提高篇一: 利用NLP技术完成高级任务 (10讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E7%BE%8E.html#id42">实战提高篇(二) 大型语音与图像模型的应用 (9讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B9%8B%E7%BE%8E.html#id55">扩展</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2040%20%E8%AE%B2.html">机器学习 40 讲</a><ul>
<li class="toctree-l4"><a class="reference internal" href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2040%20%E8%AE%B2.html#id3">01机器学习概观 (10 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2040%20%E8%AE%B2.html#id5">02统计机器学习模型 (18 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2040%20%E8%AE%B2.html#id6">03概率图模型 (14 讲)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="PyTorch%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98.html">PyTorch 深度学习实战</a><ul>
<li class="toctree-l4"><a class="reference internal" href="PyTorch%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98.html#id2">开篇词 | 如何高效入门 PyTorch</a></li>
<li class="toctree-l4"><a class="reference internal" href="PyTorch%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98.html#id3">01基础篇 (5 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="PyTorch%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98.html#id5">02模型训练篇 (12 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="PyTorch%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98.html#id26">03实战篇 (9 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="PyTorch%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98.html#id56">加餐| 基础模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="PyTorch%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98.html#id60">结束语| 人生充满选择, 选择与努力同样重要</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="%E9%9B%B6%E5%9F%BA%E7%A1%80%20GPT%20%E5%BA%94%E7%94%A8%E5%85%A5%E9%97%A8%E8%AF%BE.html">零基础 GPT 应用入门课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="%E9%9B%B6%E5%9F%BA%E7%A1%80%20GPT%20%E5%BA%94%E7%94%A8%E5%85%A5%E9%97%A8%E8%AF%BE.html#id2">开篇词</a></li>
<li class="toctree-l4"><a class="reference internal" href="%E9%9B%B6%E5%9F%BA%E7%A1%80%20GPT%20%E5%BA%94%E7%94%A8%E5%85%A5%E9%97%A8%E8%AF%BE.html#id7">基础速通 (3讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="%E9%9B%B6%E5%9F%BA%E7%A1%80%20GPT%20%E5%BA%94%E7%94%A8%E5%85%A5%E9%97%A8%E8%AF%BE.html#id10">黄金密钥 (7讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="%E9%9B%B6%E5%9F%BA%E7%A1%80%20GPT%20%E5%BA%94%E7%94%A8%E5%85%A5%E9%97%A8%E8%AF%BE.html#id18">综合实战 (6讲)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98.html">AI 大模型系统实战</a><ul>
<li class="toctree-l4"><a class="reference internal" href="AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98.html#id2">热身篇 (4讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98.html#id6">架构基础篇 (6讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98.html#id33">技术原理篇 (5讲)</a></li>
</ul>
</li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">AI 绘画核心技术与实战</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id2">开篇词 (2讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#ai-4">热身篇:AI 绘画初体验 (4讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#ai-9">基础篇:AI 绘画原理揭秘 (9讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#dall-e-2-stable-diffusion-5">进阶篇:从 DALL-E 2 到 Stable Diffusion (5讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#ai-8">综合演练篇:AI 绘画高手养成计划 (8讲)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html">零基础实战机器学习</a><ul>
<li class="toctree-l4"><a class="reference internal" href="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html#id3">08 | 模型优化1: 怎么用特征工程提高模型效率</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../blockchain.html">区块链</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../blockchains/%E8%AF%B4%E9%80%8F%E5%8C%BA%E5%9D%97%E9%93%BE.html">说透区块链</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../blockchains/%E8%AF%B4%E9%80%8F%E5%8C%BA%E5%9D%97%E9%93%BE.html#id3">数字人民币</a></li>
<li class="toctree-l4"><a class="reference internal" href="../blockchains/%E8%AF%B4%E9%80%8F%E5%8C%BA%E5%9D%97%E9%93%BE.html#id4">书籍</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../coding.html">代码精进</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../codings/%E4%BB%A3%E7%A0%81%E4%B9%8B%E4%B8%91.html">代码之丑</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../codings/%E4%BB%A3%E7%A0%81%E4%B9%8B%E4%B8%91.html#id3">开篇词</a></li>
<li class="toctree-l4"><a class="reference internal" href="../codings/%E4%BB%A3%E7%A0%81%E4%B9%8B%E4%B8%91.html#id4">13 类典型坏味道 (13 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../codings/%E4%BB%A3%E7%A0%81%E4%B9%8B%E4%B8%91.html#id5">延伸阅读 (4 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../codings/%E4%BB%A3%E7%A0%81%E4%B9%8B%E4%B8%91.html#id10">参考</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../codings/%E8%BD%AF%E4%BB%B6%E8%AE%BE%E8%AE%A1%E4%B9%8B%E7%BE%8E.html">软件设计之美</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../codings/md/%E8%BD%AF%E4%BB%B6%E8%AE%BE%E8%AE%A1%E4%B9%8B%E7%BE%8E.html">软件设计之美</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../codings/%E4%BB%A3%E7%A0%81%E7%B2%BE%E8%BF%9B%E4%B9%8B%E8%B7%AF.html">代码精进之路</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../codings/%E4%BB%A3%E7%A0%81%E7%B2%BE%E8%BF%9B%E4%B9%8B%E8%B7%AF.html#id3">01第一模块: 代码 “规范” 篇 (16 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../codings/%E4%BB%A3%E7%A0%81%E7%B2%BE%E8%BF%9B%E4%B9%8B%E8%B7%AF.html#id19">02第二模块: 代码 “经济” 篇 (14 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../codings/%E4%BB%A3%E7%A0%81%E7%B2%BE%E8%BF%9B%E4%B9%8B%E8%B7%AF.html#id48">03第三模块: 代码 “安全” 篇 (14 讲)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../lang.html">编程语言</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../langs/Go%E8%AF%AD%E8%A8%80%E6%A0%B8%E5%BF%8336%E8%AE%B2.html">Go 语言核心 36 讲</a></li>
<li class="toctree-l3"><a class="reference internal" href="../langs/Tony-Bai-Go-%E8%AF%AD%E8%A8%80%E7%AC%AC%E4%B8%80%E8%AF%BE.html">TonyBai Go语言第一课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../langs/Tony-Bai-Go-%E8%AF%AD%E8%A8%80%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id2">课程设计</a></li>
<li class="toctree-l4"><a class="reference internal" href="../langs/Tony-Bai-Go-%E8%AF%AD%E8%A8%80%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id3">00开篇</a></li>
<li class="toctree-l4"><a class="reference internal" href="../langs/Tony-Bai-Go-%E8%AF%AD%E8%A8%80%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id5">01入门篇: 勤加练手 (7 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../langs/Tony-Bai-Go-%E8%AF%AD%E8%A8%80%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id6">02基础篇: “脑勤” 多理解 (20 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../langs/Tony-Bai-Go-%E8%AF%AD%E8%A8%80%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id8">03核心篇: “脑勤 +” 洞彻核心 (5 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../langs/Tony-Bai-Go-%E8%AF%AD%E8%A8%80%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id16">04实战篇: 打通“最后一公里” (4讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../langs/Tony-Bai-Go-%E8%AF%AD%E8%A8%80%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id17">大咖助阵</a></li>
<li class="toctree-l4"><a class="reference internal" href="../langs/Tony-Bai-Go-%E8%AF%AD%E8%A8%80%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id18">加餐</a></li>
<li class="toctree-l4"><a class="reference internal" href="../langs/Tony-Bai-Go-%E8%AF%AD%E8%A8%80%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id26">泛型</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../langs/Python%20%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98.html">Python 核心技术与实战</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../product.html">产品&amp;运营</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../products/%E6%A2%81%E5%AE%81%E3%83%BB%E4%BA%A7%E5%93%81%E6%80%9D%E7%BB%B4%2030%20%E8%AE%B2.html">梁宁-产品思维 30 讲</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../products/%E6%A2%81%E5%AE%81%E3%83%BB%E4%BA%A7%E5%93%81%E6%80%9D%E7%BB%B4%2030%20%E8%AE%B2.html#id4">发刊词</a></li>
<li class="toctree-l4"><a class="reference internal" href="../products/%E6%A2%81%E5%AE%81%E3%83%BB%E4%BA%A7%E5%93%81%E6%80%9D%E7%BB%B4%2030%20%E8%AE%B2.html#id7">模块一: 同理心</a></li>
<li class="toctree-l4"><a class="reference internal" href="../products/%E6%A2%81%E5%AE%81%E3%83%BB%E4%BA%A7%E5%93%81%E6%80%9D%E7%BB%B4%2030%20%E8%AE%B2.html#id23">模块二: 机会判断</a></li>
<li class="toctree-l4"><a class="reference internal" href="../products/%E6%A2%81%E5%AE%81%E3%83%BB%E4%BA%A7%E5%93%81%E6%80%9D%E7%BB%B4%2030%20%E8%AE%B2.html#id31">模块三: 系统能力</a></li>
<li class="toctree-l4"><a class="reference internal" href="../products/%E6%A2%81%E5%AE%81%E3%83%BB%E4%BA%A7%E5%93%81%E6%80%9D%E7%BB%B4%2030%20%E8%AE%B2.html#id45">模块四: 用户体验</a></li>
<li class="toctree-l4"><a class="reference internal" href="../products/%E6%A2%81%E5%AE%81%E3%83%BB%E4%BA%A7%E5%93%81%E6%80%9D%E7%BB%B4%2030%20%E8%AE%B2.html#id66">模块五: 创新模式</a></li>
<li class="toctree-l4"><a class="reference internal" href="../products/%E6%A2%81%E5%AE%81%E3%83%BB%E4%BA%A7%E5%93%81%E6%80%9D%E7%BB%B4%2030%20%E8%AE%B2.html#id73">产品世界观</a></li>
<li class="toctree-l4"><a class="reference internal" href="../products/%E6%A2%81%E5%AE%81%E3%83%BB%E4%BA%A7%E5%93%81%E6%80%9D%E7%BB%B4%2030%20%E8%AE%B2.html#id80">彩蛋</a></li>
<li class="toctree-l4"><a class="reference internal" href="../products/%E6%A2%81%E5%AE%81%E3%83%BB%E4%BA%A7%E5%93%81%E6%80%9D%E7%BB%B4%2030%20%E8%AE%B2.html#id90">参考</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../interview.html">面试</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../interviews/%E5%90%8E%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E9%AB%98%E9%98%B6%E9%9D%A2%E7%BB%8F.html">后端工程师的高阶面经</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../interviews/%E5%90%8E%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E9%AB%98%E9%98%B6%E9%9D%A2%E7%BB%8F.html#id3">开篇词</a></li>
<li class="toctree-l4"><a class="reference internal" href="../interviews/%E5%90%8E%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E9%AB%98%E9%98%B6%E9%9D%A2%E7%BB%8F.html#id5">01微服务架构 (10讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../interviews/%E5%90%8E%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E9%AB%98%E9%98%B6%E9%9D%A2%E7%BB%8F.html#mysql-13">数据库与MySQL (13讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../interviews/%E5%90%8E%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E9%AB%98%E9%98%B6%E9%9D%A2%E7%BB%8F.html#id269">消息队列 (10讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../interviews/%E5%90%8E%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E9%AB%98%E9%98%B6%E9%9D%A2%E7%BB%8F.html#id321">缓存 (9讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../interviews/%E5%90%8E%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E9%AB%98%E9%98%B6%E9%9D%A2%E7%BB%8F.html#nosql-5">NoSQL (5讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../interviews/%E5%90%8E%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E9%AB%98%E9%98%B6%E9%9D%A2%E7%BB%8F.html#id394">结束语</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../softengineering.html">软件工程</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../softengineers/%E8%AF%B4%E9%80%8F%E6%95%8F%E6%8D%B7.html">说透敏捷</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../softengineers/%E8%AF%B4%E9%80%8F%E6%95%8F%E6%8D%B7.html#id3">开篇词</a></li>
<li class="toctree-l4"><a class="reference internal" href="../softengineers/%E8%AF%B4%E9%80%8F%E6%95%8F%E6%8D%B7.html#id4">原理篇 (2 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../softengineers/%E8%AF%B4%E9%80%8F%E6%95%8F%E6%8D%B7.html#id14">实战篇 (4 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../softengineers/%E8%AF%B4%E9%80%8F%E6%95%8F%E6%8D%B7.html#id26">策略篇 (2 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../softengineers/%E8%AF%B4%E9%80%8F%E6%95%8F%E6%8D%B7.html#id29">管理篇 (2 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../softengineers/%E8%AF%B4%E9%80%8F%E6%95%8F%E6%8D%B7.html#id32">结束语</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../other.html">其它</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html">互联网人的英语私教课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#ksa">KSA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id4">独立主格结构</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id5">介词</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id6">收集</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id8">关键英语</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#vs">并列句 VS 复杂句</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id9">单词</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id10">英语谚语</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id11">常用短语</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id12">口语专用词汇</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id13">好的英文网站</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id15">其他</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id16">会不会阅读</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id17">词汇学习</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#paraphrase">paraphrase</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id18">动词</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id19">其他</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%BA%92%E8%81%94%E7%BD%91%E4%BA%BA%E7%9A%84%E8%8B%B1%E8%AF%AD%E7%A7%81%E6%95%99%E8%AF%BE.html#id20">参考</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../others/%E4%BB%8E%200%20%E6%89%93%E9%80%A0%E9%9F%B3%E8%A7%86%E9%A2%91%E7%9B%B4%E6%92%AD%E7%B3%BB%E7%BB%9F.html">从 0 打造音视频直播系统</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%BB%8E%200%20%E6%89%93%E9%80%A0%E9%9F%B3%E8%A7%86%E9%A2%91%E7%9B%B4%E6%92%AD%E7%B3%BB%E7%BB%9F.html#webrtc-1-1-23">WebRTC 1 对 1 通话 (23 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%BB%8E%200%20%E6%89%93%E9%80%A0%E9%9F%B3%E8%A7%86%E9%A2%91%E7%9B%B4%E6%92%AD%E7%B3%BB%E7%BB%9F.html#webrtc-7">WebRTC 多人音视频实时通话 (7 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%BB%8E%200%20%E6%89%93%E9%80%A0%E9%9F%B3%E8%A7%86%E9%A2%91%E7%9B%B4%E6%92%AD%E7%B3%BB%E7%BB%9F.html#id22">支持上万人同时在线的直播系统 (8 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%BB%8E%200%20%E6%89%93%E9%80%A0%E9%9F%B3%E8%A7%86%E9%A2%91%E7%9B%B4%E6%92%AD%E7%B3%BB%E7%BB%9F.html#id27">其他</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../others/%E5%BF%AB%E6%89%8B%C2%B7%E9%9F%B3%E8%A7%86%E9%A2%91%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8%E8%AF%BE.html">快手·音视频技术入门课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../others/%E5%BF%AB%E6%89%8B%C2%B7%E9%9F%B3%E8%A7%86%E9%A2%91%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8%E8%AF%BE.html#id3">开篇基础 (4讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E5%BF%AB%E6%89%8B%C2%B7%E9%9F%B3%E8%A7%86%E9%A2%91%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8%E8%AF%BE.html#id29">流媒体技术速成 (5讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E5%BF%AB%E6%89%8B%C2%B7%E9%9F%B3%E8%A7%86%E9%A2%91%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8%E8%AF%BE.html#ffmpeg-api-4">FFmpeg API 应用 (4讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E5%BF%AB%E6%89%8B%C2%B7%E9%9F%B3%E8%A7%86%E9%A2%91%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8%E8%AF%BE.html#ffmpeg-2">FFmpeg 社区“玩法” (2讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E5%BF%AB%E6%89%8B%C2%B7%E9%9F%B3%E8%A7%86%E9%A2%91%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8%E8%AF%BE.html#id55">结束语 | 音视频技术更宠爱脚踏实地的人</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../others/%E6%94%BB%E5%85%8B%E8%A7%86%E9%A2%91%E6%8A%80%E6%9C%AF.html">攻克视频技术</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../others/%E6%94%BB%E5%85%8B%E8%A7%86%E9%A2%91%E6%8A%80%E6%9C%AF.html#id3">图像基础和前处理 (3 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E6%94%BB%E5%85%8B%E8%A7%86%E9%A2%91%E6%8A%80%E6%9C%AF.html#id12">视频编码 (5讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E6%94%BB%E5%85%8B%E8%A7%86%E9%A2%91%E6%8A%80%E6%9C%AF.html#id22">参考</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E6%94%BB%E5%85%8B%E8%A7%86%E9%A2%91%E6%8A%80%E6%9C%AF.html#id23">评论</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../others/%E6%90%9E%E5%AE%9A%E9%9F%B3%E9%A2%91%E6%8A%80%E6%9C%AF.html">搞定音频技术</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../others/%E6%90%9E%E5%AE%9A%E9%9F%B3%E9%A2%91%E6%8A%80%E6%9C%AF.html#id3">音频基础 (4 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E6%90%9E%E5%AE%9A%E9%9F%B3%E9%A2%91%E6%8A%80%E6%9C%AF.html#id13">02音频降噪 (2 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E6%90%9E%E5%AE%9A%E9%9F%B3%E9%A2%91%E6%8A%80%E6%9C%AF.html#id15">03回声消除 (2 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E6%90%9E%E5%AE%9A%E9%9F%B3%E9%A2%91%E6%8A%80%E6%9C%AF.html#id18">04音频网络传输 (3 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E6%90%9E%E5%AE%9A%E9%9F%B3%E9%A2%91%E6%8A%80%E6%9C%AF.html#id22">05空间音频 (2 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E6%90%9E%E5%AE%9A%E9%9F%B3%E9%A2%91%E6%8A%80%E6%9C%AF.html#id24">06音频特效生成与算法 (3 讲)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../others/%E4%B8%93%E5%88%A9%E5%86%99%E4%BD%9C%E7%AC%AC%E4%B8%80%E8%AF%BE.html">专利写作第一课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%B8%93%E5%88%A9%E5%86%99%E4%BD%9C%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id3">开篇词 | 写专利, 将是知识工作者的核心产出</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%B8%93%E5%88%A9%E5%86%99%E4%BD%9C%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id4">01 _ 为什么我推荐互联网人要积极写专利</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%B8%93%E5%88%A9%E5%86%99%E4%BD%9C%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id5">02 _ 奖金是专利写作中最不值得一提的事儿</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%B8%93%E5%88%A9%E5%86%99%E4%BD%9C%E7%AC%AC%E4%B8%80%E8%AF%BE.html#keyperson">03 _ 找到KeyPerson利益点, 提升专利通过率</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%B8%93%E5%88%A9%E5%86%99%E4%BD%9C%E7%AC%AC%E4%B8%80%E8%AF%BE.html#prd-1">04 _ 像写PRD一样, 撰写专利交底书1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%B8%93%E5%88%A9%E5%86%99%E4%BD%9C%E7%AC%AC%E4%B8%80%E8%AF%BE.html#prd-2">05 _ 像写PRD一样, 撰写专利交底书2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%B8%93%E5%88%A9%E5%86%99%E4%BD%9C%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id14">06 _ 如何把常见的生活问题变成专利(案例-节假日不响起闹钟)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%B8%93%E5%88%A9%E5%86%99%E4%BD%9C%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id23">07 _ 专利创新的步伐不必迈得特别大</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%B8%93%E5%88%A9%E5%86%99%E4%BD%9C%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id28">08 _ 那些异想天开的专利是怎么诞生的</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/%E4%B8%93%E5%88%A9%E5%86%99%E4%BD%9C%E7%AC%AC%E4%B8%80%E8%AF%BE.html#id32">答疑 _ 专利申请十大常见问题</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../others/WebAssembly%20%E5%85%A5%E9%97%A8%E8%AF%BE.html">WebAssembly 入门课</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../others/WebAssembly%20%E5%85%A5%E9%97%A8%E8%AF%BE.html#id2">课前必读</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/WebAssembly%20%E5%85%A5%E9%97%A8%E8%AF%BE.html#id9">01核心原理篇 (6 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/WebAssembly%20%E5%85%A5%E9%97%A8%E8%AF%BE.html#id21">02应用篇 (6 讲)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../others/WebAssembly%20%E5%85%A5%E9%97%A8%E8%AF%BE.html#id22">03实战篇 (6 讲)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../others/other.html">其他</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../matter.html">Matter 协议</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../matters/matter.html">Matter Core</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../matters/matter.html#chapter-1-introduction">Chapter 1. Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/matter.html#chapter-2-architecture">Chapter 2. Architecture</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#overview">2.1. Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#layered-architecture">2.2. Layered Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#network-topology">2.3. Network Topology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#scoped-names">2.4. Scoped names</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#identifiers">2.5. Identifiers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#device-identity">2.6. Device identity</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#security">2.7. Security</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#device-commissioning">2.8. Device Commissioning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#sleepy-end-device-sed">2.9. Sleepy End Device (SED)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#data-model-root">2.10. Data Model Root</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#stack-limits">2.11. Stack Limits</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#list-of-provisional-items">2.12. List of Provisional Items</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/matter.html#chapter-3-cryptographic-primitives">Chapter 3. Cryptographic Primitives</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/matter.html#chapter-4-secure-channel">Chapter 4. Secure Channel</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#general-description">4.1. General Description</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#ipv6-reachability">4.2. IPv6 Reachability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#discovery">4.3. Discovery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#message-frame-format">4.4. Message Frame Format</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#message-counters">4.5. Message Counters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#message-processing">4.6. Message Processing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#message-security">4.7. Message Security</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#message-privacy">4.8. Message Privacy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#message-exchanges">4.9. Message Exchanges</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#secure-channel-protocol">4.10. Secure Channel Protocol</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#message-reliability-protocol-mrp">4.11. Message Reliability Protocol (MRP)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#unicast-communication">4.12. Unicast Communication</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#session-establishment">4.13. Session Establishment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#group-communication">4.14. Group Communication</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#group-key-management">4.15. Group Key Management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#message-counter-synchronization-protocol-mcsp">4.16. Message Counter Synchronization Protocol(MCSP)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#bluetooth-transport-protocol-btp">4.17. Bluetooth Transport Protocol (BTP)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/matter.html#chapter-5-commissioning">Chapter 5. Commissioning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#onboarding-payload">5.1. Onboarding Payload</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#initiating-commissioning">5.2. Initiating Commissioning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#user-directed-commissioning">5.3. User Directed Commissioning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#device-discovery">5.4. Device Discovery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#commissioning-flows">5.5. Commissioning Flows</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#administrator-assisted-commissioning-flows">5.6. Administrator Assisted Commissioning Flows</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#device-commissioning-flows">5.7. Device Commissioning Flows</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#in-field-upgrade-to-matter">5.8. In-field Upgrade to Matter</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/matter.html#chapter-6-device-attestation-and-operational-credentials">Chapter 6. Device Attestation and Operational Credentials</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#common-conventions">6.1. Common Conventions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#device-attestation">6.2. Device Attestation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#certification-declaration">6.3. Certification Declaration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#node-operational-credentials-specification">6.4. Node Operational Credentials Specification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#operational-certificate-encoding">6.5. Operational Certificate Encoding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#access-control">6.6. Access Control</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/matter.html#chapter-7-data-model-specification">Chapter 7. Data Model Specification</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#practical-information">7.1. Practical Information</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#data-qualities">7.2. Data Qualities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#conformance">7.3. Conformance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#element">7.4. Element</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#fabric">7.5. Fabric</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#access">7.6. Access</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#other-qualities">7.7. Other Qualities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#node">7.8. Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#endpoint">7.9. Endpoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#cluster">7.10. Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#command">7.11. Command</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#attribute">7.12. Attribute</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#global-elements">7.13. Global Elements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#event">7.14. Event</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#device-type">7.15. Device Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#non-standard">7.16. Non-Standard</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#data-field">7.17. Data Field</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#data-types">7.18. Data Types</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#manufacturer-specific-extensions">7.19. Manufacturer Specific Extensions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/matter.html#chapter-8-interaction-model-specification">Chapter 8. Interaction Model Specification</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#id17">8.1. Practical Information</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#concepts">8.2. Concepts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#status-and-interaction">8.3. Status and Interaction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#read-interaction">8.4. Read Interaction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#subscribe-interaction">8.5. Subscribe Interaction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#report-transaction">8.6. Report Transaction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#write-interaction">8.7. Write Interaction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#invoke-interaction">8.8. Invoke Interaction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#common-action-information-blocks-and-paths">8.9. Common Action Information Blocks and Paths</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#status-codes">8.10. Status Codes</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/matter.html#chapter-9-system-model-specification">Chapter 9. System Model Specification</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#id18">9.1. Practical Information</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#endpoint-composition">9.2. Endpoint Composition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#interaction-model-relationships">9.3. Interaction Model Relationships</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#binding-relationship">9.4. Binding Relationship</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#descriptor-cluster">9.5. Descriptor Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#binding-cluster">9.6. Binding Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#label-cluster">9.7. Label Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#fixed-label-cluster">9.8. Fixed Label Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#user-label-cluster">9.9. User Label Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#access-control-cluster">9.10. Access Control Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#group-relationship">9.11. Group Relationship</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#bridge-for-non-matter-devices">9.12. Bridge for non-Matter devices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#bridged-device-basic-information-cluster">9.13. Bridged Device Basic Information Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#actions-cluster">9.14. Actions Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#proxy-architecture">9.15. Proxy Architecture</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/matter.html#chapter-10-interaction-model-encoding-specification">Chapter 10. Interaction Model Encoding Specification</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#id23">10.1. Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#messages">10.2. Messages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#id24">10.3. Data Types</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#sample-cluster">10.4. Sample Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#information-blocks">10.5. Information Blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#message-definitions">10.6. Message Definitions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/matter.html#chapter-11-service-and-device-management">Chapter 11. Service and Device Management</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#basic-information-cluster">11.1. Basic Information Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#group-key-management-cluster">11.2. Group Key Management Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#localization-configuration-cluster">11.3. Localization Configuration Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#time-format-localization-cluster">11.4. Time Format Localization Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#unit-localization-cluster">11.5. Unit Localization Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#power-source-configuration-cluster">11.6. Power Source Configuration Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#power-source-cluster">11.7. Power Source Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#network-commissioning-cluster">11.8. Network Commissioning Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#general-commissioning-cluster">11.9. General Commissioning Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#diagnostic-logs-cluster">11.10. Diagnostic Logs Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#general-diagnostics-cluster">11.11. General Diagnostics Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#software-diagnostics-cluster">11.12. Software Diagnostics Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#thread-network-diagnostics-cluster">11.13. Thread Network Diagnostics Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#wi-fi-network-diagnostics-cluster">11.14. Wi-Fi Network Diagnostics Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#ethernet-network-diagnostics-cluster">11.15. Ethernet Network Diagnostics Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#time-synchronization">11.16. Time Synchronization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#node-operational-credentials-cluster">11.17. Node Operational Credentials Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#administrator-commissioning-cluster">11.18. Administrator Commissioning Cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#over-the-air-ota-software-update">11.19. Over-the-Air (OTA) Software Update</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#over-the-air-ota-software-update-file-format">11.20. Over-the-Air (OTA) Software Update File Format</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#bulk-data-exchange-protocol-bdx">11.21. Bulk Data Exchange Protocol (BDX)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#distributed-compliance-ledger">11.22. Distributed Compliance Ledger</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/matter.html#chapter-12-multiple-fabrics">Chapter 12. Multiple Fabrics</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#multiple-fabrics">12.1. Multiple Fabrics</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/matter.html#chapter-13-security-requirements">Chapter 13. Security Requirements</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#device-vs-node">13.2. Device vs. Node</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#factory-reset">13.4. Factory Reset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#threats-and-countermeasures">13.7. Threats and Countermeasures</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/matter.html#appendix-a-tag-length-value-tlv-encoding-format">Appendix A: Tag-length-value (TLV) Encoding Format</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#a-1-scope-purpose">A.1. Scope &amp; Purpose</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#a-2-tags">A.2. Tags</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#a-9-length-encoding">A.9. Length Encoding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#a-10-end-of-container-encoding">A.10. End of Container Encoding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#a-11-value-encodings">A.11. Value Encodings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#a-12-tlv-encoding-examples">A.12. TLV Encoding Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/matter.html#appendix-b-tag-length-value-tlv-schema-definitions">Appendix B: Tag-length-value (TLV) Schema Definitions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#b-1-introduction">B.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#b-2-definitions">B.2. Definitions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#b-3-types">B.3. Types</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#b-4-pseudo-types">B.4. Pseudo-Types</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#b-5-qualifiers">B.5. Qualifiers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/matter.html#appendix-c-tag-length-value-tlv-payload-text-representation-format">Appendix C: Tag-length-value (TLV) Payload Text Representation Format</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#c-1-introduction">C.1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#c-3-examples">C.3. Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/matter.html#appendix-d-status-report-messages">Appendix D: Status Report Messages</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../matters/matter.html#d-3-message-format">D.3. Message Format</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/matter.html#appendix-e-matter-specific-asn-1-object-identifiers-oids">Appendix E: Matter-Specific ASN.1 Object Identifiers (OIDs)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/matter.html#appendix-f-cryptographic-test-vectors-for-some-procedures">Appendix F: Cryptographic test vectors for some procedures</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/matter.html#appendix-g-minimal-resource-requirements">Appendix G: Minimal Resource Requirements</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../matters/Matter%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90.html">Matter协议分析</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../matters/Matter%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90.html#id2">简介</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/Matter%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90.html#id3">算法</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/Matter%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90.html#ecc">椭圆曲线密码学 (ECC) 原理</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/Matter%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90.html#bridge">Bridge</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/Matter%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90.html#factory-data">Factory Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/Matter%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90.html#id4">安全</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/Matter%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90.html#pase">PASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/Matter%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90.html#id5">配网过程</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/Matter%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90.html#case">CASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/Matter%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90.html#group">Group</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/Matter%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90.html#cluster">cluster</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/Matter%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90.html#ota">OTA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/Matter%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90.html#id6">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../matters/chatgpt.html">chatGPT学习</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../matters/chatgpt.html#chapter-01-introduction-document">Chapter 01 — Introduction Document</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/chatgpt.html#chapter-02-architecture-document">Chapter 02 — Architecture Document</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/chatgpt.html#chapter-03-cryptographic-primitives-document">Chapter 03 — Cryptographic Primitives Document</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/chatgpt.html#chapter-04-secure-channel-document">Chapter 04 — Secure Channel Document</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/chatgpt.html#chapter-05-commissioning-document">Chapter 05 — Commissioning Document</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/chatgpt.html#chapter-06-device-attestation-document">Chapter 06 — Device Attestation Document</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/chatgpt.html#chapter-07-data-model-document">Chapter 07 — Data Model Document</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/chatgpt.html#chapter-08-interaction-model-document">Chapter 08 — Interaction Model Document</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/chatgpt.html#chapter-09-system-model-document">Chapter 09 — System Model Document</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../matters/chatgpt.html#id2">概述和定义</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/chatgpt.html#id3">设备类型和服务类型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/chatgpt.html#id4">特征</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/chatgpt.html#id5">系统模型实例</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/chatgpt.html#chapter-10-interaction-encoding-document">Chapter 10 — Interaction Encoding Document</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../matters/chatgpt.html#id6">概述和定义</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/chatgpt.html#id7">数据类型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/chatgpt.html#id8">交互编码格式</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/chatgpt.html#chapter-11-device-management-document">Chapter 11 — Device Management Document</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../matters/chatgpt.html#id9">概述和定义</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/chatgpt.html#id10">设备组成</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/chatgpt.html#id11">设备状态</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../matters/chatgpt.html#id12">设备操作</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/chatgpt.html#chapter-12-multiple-fabrics-document">Chapter 12 — Multiple Fabrics Document</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/chatgpt.html#chapter-13-security-requirements-document">Chapter 13 — Security Requirements Document</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/chatgpt.html#appendix-a-tag-length-value-tlv-encoding-format">Appendix A: Tag-length-value (TLV) Encoding Format</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/chatgpt.html#appendix-b-tag-length-value-tlv-schema-definitions">Appendix B: Tag-length-value (TLV) Schema Definitions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/chatgpt.html#appendix-c-tag-length-value-tlv-payload-text-representation-format">Appendix C: Tag-length-value (TLV) Payload Text Representation Format</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../matters/chatgpt.html#appendix-d-status-report-messages">Appendix D: Status Report Messages</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../rfc.html">rfc</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/ips/rfc0791-IP%20Spec.html">RFC791: IP: INTERNET PROTOCOL</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ips/rfc0791-IP%20Spec.html#preface">PREFACE</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ips/rfc0791-IP%20Spec.html#introduction">1.  INTRODUCTION</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ips/rfc0791-IP%20Spec.html#overview">2.  OVERVIEW</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ips/rfc0791-IP%20Spec.html#relation-to-other-protocols">2.1.  Relation to Other Protocols</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ips/rfc0791-IP%20Spec.html#model-of-operation">2.2.  Model of Operation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ips/rfc0791-IP%20Spec.html#function-description">2.3.  Function Description</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ips/rfc0791-IP%20Spec.html#gateways">2.4.  Gateways</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ips/rfc0791-IP%20Spec.html#specification">3.  SPECIFICATION</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ips/rfc0791-IP%20Spec.html#internet-header-format">3.1.  Internet Header Format</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ips/rfc0791-IP%20Spec.html#discussion">3.2  Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ips/rfc0791-IP%20Spec.html#interfaces">3.3  Interfaces</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ips/rfc0791-IP%20Spec.html#appendix-a-examples-scenarios">APPENDIX A:  Examples &amp; Scenarios</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ips/rfc0791-IP%20Spec.html#minimal-data-carrying-internet-datagram">minimal data carrying internet datagram</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ips/rfc0791-IP%20Spec.html#moderate-size-internet-datagram-452-data-octets">moderate size internet datagram (452 data octets)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ips/rfc0791-IP%20Spec.html#datagram-containing-options">datagram containing options</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ips/rfc0791-IP%20Spec.html#appendix-b-data-transmission-order">APPENDIX B:  Data Transmission Order</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ips/rfc0791-IP%20Spec.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/ips/rfc0792-ICMP.html">RFC792: ICMP</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ips/rfc0792-ICMP.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/ips/rfc3569-SSM.html">RFC3569: An Overview of Source-Specific Multicast (SSM)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ips/rfc3569-SSM.html#introduction">1.  Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ips/rfc3569-SSM.html#terminology">2.  Terminology</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ips/rfc3569-SSM.html#any-source-multicast-asm">Any-Source Multicast (ASM)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ips/rfc3569-SSM.html#source-specific-multicast-ssm">Source-Specific Multicast (SSM)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ips/rfc3569-SSM.html#source-filtered-multicast-sfm">Source-Filtered Multicast (SFM)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ips/rfc3569-SSM.html#the-igmp-pim-sm-msdp-mbgp-protocol-suite-for-asm">3.  The IGMP/PIM-SM/MSDP/MBGP Protocol Suite for ASM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ips/rfc3569-SSM.html#problems-with-current-architecture">4.  Problems with Current Architecture</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ips/rfc3569-SSM.html#source-specific-multicast-ssm-benefits-and-requirements">5.  Source Specific Multicast (SSM): Benefits and Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ips/rfc3569-SSM.html#ssm-framework">6.  SSM Framework</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ips/rfc3569-SSM.html#address-allocation">6.1.  Address Allocation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ips/rfc3569-SSM.html#session-description-and-channel-discovery">6.2.  Session Description and Channel Discovery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ips/rfc3569-SSM.html#ssm-aware-applications">6.3.  SSM-Aware Applications</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ips/rfc3569-SSM.html#igmpv3-mldv2-host-reporting-and-querier">6.4.  IGMPv3/MLDv2 Host Reporting and Querier</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ips/rfc3569-SSM.html#pim-ssm-routing">6.5.  PIM-SSM Routing</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ips/rfc3569-SSM.html#interoperability-with-existing-multicast-service-models">7.  Interoperability with Existing Multicast Service Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ips/rfc3569-SSM.html#id2">应用</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ips/rfc3569-SSM.html#ssm">SSM示例</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ips/rfc3569-SSM.html#id3">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/ips/rfc4301.html">RFC4301: Security Architecture for the IP</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ips/rfc4301.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/ips/rfc4302-IP%20Authentication%20Header.html">RFC4302: IP Authentication Header</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ips/rfc4302-IP%20Authentication%20Header.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/ips/rfc4303.html">RFC4303: IP Encapsulating Security Payload (ESP)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ips/rfc4303.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/ips/rfc4693-CIDR.html">RFC4693: Classless Inter-domain Routing (CIDR)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/ipv6/rfc3306-Unicast-Prefix-based%20IPv6%20Multicast%20Addresses.html">RFC3306: Unicast-Prefix-based IPv6 Multicast Addresses</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc3306-Unicast-Prefix-based%20IPv6%20Multicast%20Addresses.html#ipv6">IPv6 多播地址中前缀长度的取值范围</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc3306-Unicast-Prefix-based%20IPv6%20Multicast%20Addresses.html#id2">多播地址的分配规则</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc3306-Unicast-Prefix-based%20IPv6%20Multicast%20Addresses.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc3306-Unicast-Prefix-based%20IPv6%20Multicast%20Addresses.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc3306-Unicast-Prefix-based%20IPv6%20Multicast%20Addresses.html#motivation">2. Motivation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc3306-Unicast-Prefix-based%20IPv6%20Multicast%20Addresses.html#multicast-address-format">4. Multicast Address Format</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc3306-Unicast-Prefix-based%20IPv6%20Multicast%20Addresses.html#ssm-source-specific-multicast-addresses">6. SSM(Source-Specific Multicast Addresses)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc3306-Unicast-Prefix-based%20IPv6%20Multicast%20Addresses.html#examples">7. Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc3306-Unicast-Prefix-based%20IPv6%20Multicast%20Addresses.html#id3">参考</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/ipv6/rfc4007-IPv6%20Scoped%20Address%20Architecture.html">RFC4007: IPv6 Scoped Address Architecture</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc4007-IPv6%20Scoped%20Address%20Architecture.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc4007-IPv6%20Scoped%20Address%20Architecture.html#introduction">1.  Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc4007-IPv6%20Scoped%20Address%20Architecture.html#address-scope">4.  Address Scope</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc4007-IPv6%20Scoped%20Address%20Architecture.html#scope-zones">5.  Scope Zones</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc4007-IPv6%20Scoped%20Address%20Architecture.html#zone-indices">6.  Zone Indices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc4007-IPv6%20Scoped%20Address%20Architecture.html#sending-packets">7.  Sending Packets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc4007-IPv6%20Scoped%20Address%20Architecture.html#receiving-packets">8.  Receiving Packets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc4007-IPv6%20Scoped%20Address%20Architecture.html#forwarding">9.  Forwarding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc4007-IPv6%20Scoped%20Address%20Architecture.html#routing">10.  Routing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc4007-IPv6%20Scoped%20Address%20Architecture.html#textual-representation">11.  Textual Representation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc4007-IPv6%20Scoped%20Address%20Architecture.html#examples">Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc4007-IPv6%20Scoped%20Address%20Architecture.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html">RFC4291: IP Version 6 Addressing Architecture</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#id2">学习</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#keypoints">keypoints</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#id3">地址类型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#id4">地址分配</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#introduction">1.  Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#ipv6-addressing">2.  IPv6 Addressing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#addressing-model">2.1.  Addressing Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#text-representation-of-addresses">2.2.  Text Representation of Addresses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#text-representation-of-address-prefixes">2.3.  Text Representation of Address Prefixes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#address-type-identification">2.4. Address Type Identification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#unicast-addresses">2.5.  Unicast Addresses</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#anycast-addresses">2.6.  Anycast Addresses</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#multicast-addresses">2.7.  Multicast Addresses</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#pre-defined-multicast-addresses">2.7.1.  Pre-Defined Multicast Addresses</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#a-node-s-required-addresses">2.8. A Node’s Required Addresses</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#security-considerations">3. Security Considerations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#appendix-a-creating-modified-eui-64-format-interface-identifiers">Appendix A: Creating Modified EUI-64 Format Interface Identifiers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#links-or-nodes-with-ieee-eui-64-identifiers">Links or Nodes with IEEE EUI-64 Identifiers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#links-or-nodes-with-ieee-802-48-bit-macs">Links or Nodes with IEEE 802 48-bit MACs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#links-with-other-kinds-of-identifiers">Links with Other Kinds of Identifiers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#links-without-identifiers">Links without Identifiers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc4291-IPv6%20Addressing%20Architecture.html#id5">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/ipv6/rfc6437.html">RFC6437: IPv6 Flow Label Specification</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc6437.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/ipv6/rfc7346-IPv6%20Multicast%20Address%20Scopes.html">RFC7346: IPv6 Multicast Address Scopes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc7346-IPv6%20Multicast%20Address%20Scopes.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc7346-IPv6%20Multicast%20Address%20Scopes.html#introduction">1.  Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc7346-IPv6%20Multicast%20Address%20Scopes.html#definition-of-ipv6-multicast-address-scopes-updates-rfc-4291">2.  Definition of IPv6 Multicast Address Scopes (Updates RFC 4291)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc7346-IPv6%20Multicast%20Address%20Scopes.html#definition-of-realm-local-scopes">3.  Definition of Realm-Local Scopes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc7346-IPv6%20Multicast%20Address%20Scopes.html#definition-of-realm-local-scope-for-ieee-802-15-4">5.  Definition of Realm-Local Scope for IEEE 802.15.4</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc7346-IPv6%20Multicast%20Address%20Scopes.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/ipv6/rfc7707.html">RFC7707: Network Reconnaissance in IPv6 Networks</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc7707.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html">RFC8200 Internet Protocol, Version 6 (IPv6) Specification</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#introduction">1.  Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#changes-from-ipv4-to-ipv6">changes from IPv4 to IPv6</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#related-rfc">related RFC</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#terminology">2.  Terminology</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#ipv6-header-format">3.  IPv6 Header Format</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#ipv6-extension-headers">4.  IPv6 Extension Headers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#extension-header-order">4.1.  Extension Header Order</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#options">4.2.  Options</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#hop-by-hop-options-header">4.3.  Hop-by-Hop Options Header</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#routing-header">4.4.  Routing Header</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#fragment-header">4.5.  Fragment Header</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#destination-options-header">4.6.  Destination Options Header</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#no-next-header">4.7.  No Next Header</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#defining-new-extension-headers-and-options">4.8.  Defining New Extension Headers and Options</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#packet-size-issues">5.  Packet Size Issues</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#flow-labels">6.  Flow Labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#traffic-classes">7.  Traffic Classes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#upper-layer-protocol-issues">8.  Upper-Layer Protocol Issues</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#upper-layer-checksums">8.1.  Upper-Layer Checksums</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#maximum-packet-lifetime">8.2.  Maximum Packet Lifetime</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#maximum-upper-layer-payload-size">8.3.  Maximum Upper-Layer Payload Size</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#responding-to-packets-carrying-routing-headers">8.4.  Responding to Packets Carrying Routing Headers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#iana-considerations">9.  IANA Considerations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#security-considerations">10. Security Considerations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#same-with-ipv4">same with ipv4</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#compare-with-ipv4">compare with ipv4</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#references">11. References</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#appendix-a-formatting-guidelines-for-options">Appendix A.  Formatting Guidelines for Options</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#appendix-b-changes-since-rfc-2460">Appendix B.  Changes Since RFC 2460</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc8200-IPv6%20Spec.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/ipv6/rfc8201.html">RFC8201: Path MTU Discovery for IP version 6</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/ipv6/rfc8201.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/tcps/rfc9293-TCP.html">RFC9293: Transmission Control Protocol (TCP)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/tcps/rfc9293-TCP.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/tcps/rfc0768-UDP.html">RFC0768: User Datagram Protocol</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/tcps/rfc0768-UDP.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html">rfc7230: HTTP/1.1: Message Syntax and Routing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#id2">定义</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#hop-by-hop-and-end-to-end">hop-by-hop and end-to-end</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#inbound-and-outbound">Inbound and Outbound</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#head-of-line-hol-blocking-problem">head-of-line (HOL) blocking problem</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#abnf">ABNF语法</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#introduction">1.  Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#syntax-notation">1.2.  Syntax Notation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#architecture">2.  Architecture</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#client-server-messaging">2.1.  Client/Server Messaging</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#implementation-diversity">2.2.  Implementation Diversity</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#intermediaries">2.3.  Intermediaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#caches">2.4.  Caches</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#conformance-and-error-handling">2.5.  Conformance and Error Handling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#protocol-versioning">2.6. Protocol Versioning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#uniform-resource-identifiers">2.7. Uniform Resource Identifiers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#message-format">3. Message Format</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#start-line">3.1. Start Line</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#header-fields">3.2. Header Fields</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#message-body">3.3. Message Body</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#handling-incomplete-messages">3.4. Handling Incomplete Messages</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#transfer-codings">4. Transfer Codings</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#chunked-transfer-coding">4.1.  Chunked Transfer Coding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#compression-codings">4.2. Compression Codings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#te">4.3. TE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#trailer">4.4. Trailer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#message-routing">5. Message Routing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#identifying-a-target-resource">5.1.  Identifying a Target Resource</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#connecting-inbound">5.2.  Connecting Inbound</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#request-target">5.3.  Request Target</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#host">5.4. Host</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#effective-request-uri">5.5. Effective Request URI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#associating-a-response-to-a-request">5.6. Associating a Response to a Request</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#message-forwarding">5.7. Message Forwarding</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#connection-management">6. Connection Management</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#connection">6.1.  Connection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#establishment">6.2. Establishment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#persistence">6.3. Persistence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#concurrency">6.4. Concurrency</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#failures-and-timeouts">6.5. Failures and Timeouts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#tear-down">6.6. Tear-down</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#upgrade">6.7. Upgrade</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#abnf-list-extension-rule">7. ABNF List Extension: #rule</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#iana-considerations">8.  IANA Considerations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#header-field-registration">8.1.  Header Field Registration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#uri-scheme-registration">8.2.  URI Scheme Registration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#internet-media-type-registration">8.3.  Internet Media Type Registration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#transfer-coding-registry">8.4.  Transfer Coding Registry</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#content-coding-registration">8.5.  Content Coding Registration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7230%20HTTP-Message%20Syntax%20and%20Routing.html#upgrade-token-registry">8.6.  Upgrade Token Registry</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7231%20HTTP-Semantics%20and%20Content.html">rfc7231: HTTP/1.1: Semantics and Content</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7232%20HTTP-Conditional%20Requests.html">rfc7232: HTTP/1.1: Conditional Requests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7233%20HTTP-Range%20Requests.html">rfc7233: HTTP/1.1: Range Requests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7234%20HTTP-Caching.html">rfc7234: HTTP/1.1: Caching</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/http/obsoleted-rfc7235%20HTTP-Authentication.html">rfc7235: HTTP/1.1: Authentication</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/http/rfc9110-HTTP%20Semantics.html">rfc9110: HTTP Semantics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/http/rfc9110-HTTP%20Semantics.html#introduction">1. Introduction</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/http/rfc9111-HTTP%20Caching.html">rfc9111: HTTP Caching</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/http/rfc9112-HTTP1.1.html">rfc9112: HTTP/1.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/http3/rfc9000.html">RFC9000: QUIC: A UDP-Based Multiplexed and Secure Transport</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/http3/rfc9000.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/http3/rfc9001.html">RFC9001: Using TLS to Secure QUIC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/http3/rfc9002.html">RFC9002: QUIC Loss Detection and Congestion Control</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/http3/rfc9002.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/http3/rfc9114.html">RFC9114: HTTP/3</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/http3/rfc9114.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/http3/rfc9204.html">RFC9204: QPACK: Field Compression for HTTP/3</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/http3/rfc9204.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/dns/rfc1035.html">RFC1035: DOMAIN NAMES-IMPLEMENTATION AND SPECIFICATION</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/dns/rfc2782.html">RFC2782: DNS SRV</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/dns/rfc6762.html">RFC6762: mDNS</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#id2">收集</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#chatgpt">chatGPT</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#id3">规范和要求</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#id4">实现和应用</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#id5">安全性</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#id6">性能和可扩展性</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#introduction">1.  Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#mdns-names">3.  mDNS Names</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#reverse-address-mapping">4. Reverse Address Mapping</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#querying">5. Querying</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#one-shot-mdns-queries">5.1.  One-Shot mDNS Queries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#continuous-mdns-querying">5.2.  Continuous mDNS Querying</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#multiple-questions-per-query">5.3.  Multiple Questions per Query</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#questions-requesting-unicast-responses">5.4.  Questions Requesting Unicast Responses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#direct-unicast-queries-to-port-5353">5.5.  Direct Unicast Queries to Port 5353</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#responding">6. Responding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#common">common</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#negative-responses">6.1.  Negative Responses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#responding-to-address-queries">6.2.  Responding to Address Queries</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#traffic-reduction">7. Traffic Reduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#probing-and-announcing-on-startup">8. Probing and Announcing on Startup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#conflict-resolution">9. Conflict Resolution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#resource-record-ttl-values-and-cache-coherency">10. Resource Record TTL Values and Cache Coherency</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#source-address-check">11.  Source Address Check</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#special-characteristics-of-mdns-domains">12.  Special Characteristics of mDNS Domains</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#enabling-and-disabling-mdns">13.  Enabling and Disabling mDNS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#considerations-for-multiple-interfaces">14.  Considerations for Multiple Interfaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#considerations-for-multiple-responders-on-the-same-machine">15.  Considerations for Multiple Responders on the Same Machine</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#mdns-character-set">16.  mDNS Character Set</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#mdns-message-size">17.  mDNS Message Size</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#mdns-message-format">18.  mDNS Message Format</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#id-query-identifier">18.1.  ID (Query Identifier)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#qr-query-response-bit">18.2.  QR (Query/Response) Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#opcode">18.3.  OPCODE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#aa-authoritative-answer-bit">18.4.  AA (Authoritative Answer) Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#tc-truncated-bit">18.5.  TC (Truncated) Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#rd-recursion-desired-bit">18.6.  RD (Recursion Desired) Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#ra-recursion-available-bit">18.7.  RA (Recursion Available) Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#z-zero-bit">18.8.  Z (Zero) Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#ad-authentic-data-bit">18.9.  AD (Authentic Data) Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#cd-checking-disabled-bit">18.10.  CD (Checking Disabled) Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#rcode-response-code">18.11.  RCODE (Response Code)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#repurposing-of-top-bit-of-qclass-in-question-section">18.12.  Repurposing of Top Bit of qclass in Question Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#repurposing-of-top-bit-of-rrclass-in-resource-record-sections">18.13.  Repurposing of Top Bit of rrclass in Resource Record Sections</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#name-compression">18.14.  Name Compression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#id7">18.5.  TC (Truncated) Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#id8">18.6.  RD (Recursion Desired) Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#id9">18.7.  RA (Recursion Available) Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#id10">18.8.  Z (Zero) Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#id11">18.9.  AD (Authentic Data) Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#id12">18.10.  CD (Checking Disabled) Bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#id13">18.11.  RCODE (Response Code)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#id14">18.12.  Repurposing of Top Bit of qclass in Question Section</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#id15">18.13.  Repurposing of Top Bit of rrclass in Resource Record Sections</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#id16">18.14.  Name Compression</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#summary-of-differences-between-mdns-and-unicast-dns">19.  Summary of Differences between mDNS and Unicast DNS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#ipv6-considerations">20.  IPv6 Considerations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#security-considerations">21.  Security Considerations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#iana-considerations">22. IANA Considerations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#appendix-a-design-rationale-for-choice-of-udp-port-number">Appendix A. Design Rationale for Choice of UDP Port Number</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#appendix-b-design-rationale-for-not-using-hashed-multicast-addresses">Appendix B. Design Rationale for Not Using Hashed Multicast Addresses</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#appendix-c-design-rationale-for-maximum-multicast-dns-name-length">Appendix C. Design Rationale for Maximum Multicast DNS Name Length</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#appendix-d-benefits-of-multicast-responses">Appendix D. Benefits of Multicast Responses</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#appendix-e-design-rationale-for-encoding-negative-responses">Appendix E. Design Rationale for Encoding Negative Responses</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#appendix-f-use-of-utf-8">Appendix F. Use of UTF-8</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#appendix-g-private-dns-namespaces">Appendix G. Private DNS Namespaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#appendix-h-deployment-history">Appendix H.  Deployment History</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6762.html#id17">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/dns/rfc6763.html">RFC6763: DNS-Based Service Discovery</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#id2">收集</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#introduction">1.  Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#design-goals">3.  Design Goals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#service-instance-enumeration-browsing">4.  Service Instance Enumeration (Browsing)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#structured-service-instance-names">4.1.  Structured Service Instance Names</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#user-interface-presentation">4.2.  User Interface Presentation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#internal-handling-of-names">4.3.  Internal Handling of Names</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#service-instance-resolution">5. Service Instance Resolution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#data-syntax-for-dns-sd-txt-records">6. Data Syntax for DNS-SD TXT Records</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#general-format-rules-for-dns-txt-records">6.1. General Format Rules for DNS TXT Records</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#dns-sd-txt-record-size">6.2. DNS-SD TXT Record Size</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#dns-txt-record-format-rules-for-use-in-dns-sd">6.3. DNS TXT Record Format Rules for Use in DNS-SD</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#rules-for-keys-in-dns-sd-key-value-pairs">6.4. Rules for Keys in DNS-SD Key/Value Pairs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#rules-for-values-in-dns-sd-key-value-pairs">6.5. Rules for Values in DNS-SD Key/Value Pairs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#example-txt-record">6.6. Example TXT Record</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#version-tag">6.7. Version Tag</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#service-instances-with-multiple-txt-records">6.8. Service Instances with Multiple TXT Records</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#id3">7. Service Names</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#selective-instance-enumeration-subtypes">7.1. Selective Instance Enumeration (Subtypes)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#service-name-length-limits">7.2. Service Name Length Limits</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#flagship-naming">8. Flagship Naming</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#service-type-enumeration">9. Service Type Enumeration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#populating-the-dns-with-information">10. Populating the DNS with Information</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#domain-enumeration">11. Domain Enumeration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#dns-additional-record-generation">12.  DNS Additional Record Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#ptr-records">12.1.  PTR Records</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#srv-records">12.2.  SRV Records</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#txt-records">12.3.  TXT Records</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#other-record-types">12.4.  Other Record Types</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#working-examples">13.  Working Examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#ipv6-considerations">14.  IPv6 Considerations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#security-considerations">15.  Security Considerations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#iana-considerations">16.  IANA Considerations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#appendix-a-rationale-for-using-dns-as-a-basis-for-service-discovery">Appendix A.  Rationale for Using DNS as a Basis for Service Discovery</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#appendix-b-ordering-of-service-instance-name-components">Appendix B.  Ordering of Service Instance Name Components</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#b-1-semantic-structure">B.1.  Semantic Structure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#b-2-network-efficiency">B.2.  Network Efficiency</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#b-3-operational-flexibility">B.3.  Operational Flexibility</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#appendix-c-what-you-see-is-what-you-get">Appendix C.  What You See Is What You Get</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#appendix-d-choice-of-factory-default-names">Appendix D.  Choice of Factory-Default Names</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#appendix-e-name-encodings-in-the-domain-name-system">Appendix E.  Name Encodings in the Domain Name System</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#appendix-f-continuous-live-update-browsing-model">Appendix F.  “Continuous Live Update” Browsing Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc6763.html#id4">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/dns/rfc8766.html">RFC8766: Discovery Proxy for Multicast DNS-Based Service Discovery</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/dns/rfc8766.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/streamings/rfc2974-Session%20Announcement%20Protocol.html">RFC2974: Session Announcement Protocol</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html">RFC3261: SIP: Session Initiation Protocol</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#introduction">1 Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#overview-of-sip-functionality">2 Overview of SIP Functionality</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#overview-of-operation">4 Overview of Operation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#structure-of-the-protocol">5 Structure of the Protocol</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#definitions">6 Definitions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#sip-messages">7 SIP Messages</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#requests">7.1 Requests</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#responses">7.2 Responses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#header-fields">7.3 Header Fields</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#bodies">7.4 Bodies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#framing-sip-messages">7.5 Framing SIP Messages</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#general-user-agent-behavior">8 General User Agent Behavior</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#uac-behavior">8.1 UAC Behavior</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#uas-behavior">8.2 UAS Behavior</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#redirect-servers">8.3 Redirect Servers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#canceling-a-request">9 Canceling a Request</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#client-behavior">9.1 Client Behavior</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#server-behavior">9.2 Server Behavior</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#registrations">10 Registrations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#overview">10.1 Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#constructing-the-register-request">10.2 Constructing the REGISTER Request</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#processing-register-requests">10.3 Processing REGISTER Requests</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#querying-for-capabilities">11 Querying for Capabilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#dialogs">12 Dialogs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#creation-of-a-dialog">12.1 Creation of a Dialog</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#requests-within-a-dialog">12.2 Requests within a Dialog</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#termination-of-a-dialog">12.3 Termination of a Dialog</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#initiating-a-session">13 Initiating a Session</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#id3">13.1 Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#uac-processing">13.2 UAC Processing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#uas-processing">13.3 UAS Processing</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#modifying-an-existing-session">14 Modifying an Existing Session</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#id4">14.1 UAC Behavior</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#id5">14.2 UAS Behavior</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#terminating-a-session">15 Terminating a Session</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#terminating-a-session-with-a-bye-request">15.1 Terminating a Session with a BYE Request</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#proxy-behavior">16 Proxy Behavior</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#id8">16.1 Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#stateful-proxy">16.2 Stateful Proxy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#request-validation">16.3 Request Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#route-information-preprocessing">16.4 Route Information Preprocessing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#determining-request-targets">16.5 Determining Request Targets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#request-forwarding">16.6 Request Forwarding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#response-processing">16.7 Response Processing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#processing-timer-c">16.8 Processing Timer C</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#handling-transport-errors">16.9 Handling Transport Errors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#cancel-processing">16.10 CANCEL Processing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#stateless-proxy">16.11 Stateless Proxy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#summary-of-proxy-route-processing">16.12 Summary of Proxy Route Processing</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#transactions">17 Transactions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#client-transaction">17.1 Client Transaction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#server-transaction">17.2 Server Transaction</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#transport">18 Transport</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#common-message-components">19 Common Message Components</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#sip-and-sips-uniform-resource-indicators">19.1 SIP and SIPS Uniform Resource Indicators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#option-tags">19.2 Option Tags</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#tags">19.3 Tags</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#id10">20 Header Fields</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#accept">20.1 Accept</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#accept-encoding">20.2 Accept-Encoding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#accept-language">20.3 Accept-Language</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#alert-info">20.4 Alert-Info</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#allow">20.5 Allow</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#authentication-info">20.6 Authentication-Info</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#authorization">20.7 Authorization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#call-id">20.8 Call-ID</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#call-info">20.9 Call-Info</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#contact">20.10 Contact</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#content-disposition">20.11 Content-Disposition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#content-encoding">20.12 Content-Encoding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#content-language">20.13 Content-Language</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#content-length">20.14 Content-Length</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#content-type">20.15 Content-Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#cseq">20.16 CSeq</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#date">20.17 Date</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#error-info">20.18 Error-Info</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#expires">20.19 Expires</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#from">20.20 From</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#in-reply-to">20.21 In-Reply-To</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#max-forwards">20.22 Max-Forwards</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#min-expires">20.23 Min-Expires</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#mime-version">20.24 MIME-Version</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#organization">20.25 Organization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#priority">20.26 Priority</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#proxy-authenticate">20.27 Proxy-Authenticate</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#proxy-authorization">20.28 Proxy-Authorization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#proxy-require">20.29 Proxy-Require</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#record-route">20.30 Record-Route</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#reply-to">20.31 Reply-To</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#id11">20.32 Require</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#retry-after">20.33 Retry-After</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#route">20.34 Route</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#server">20.35 Server</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#subject">20.36 Subject</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#supported">20.37 Supported</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#timestamp">20.38 Timestamp</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#to">20.39 To</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#unsupported">20.40 Unsupported</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#user-agent">20.41 User-Agent</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#via">20.42 Via</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#warning">20.43 Warning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#www-authenticate">20.44 WWW-Authenticate</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#response-codes">21 Response Codes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#provisional-1xx">21.1 Provisional 1xx</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#successful-2xx">21.2 Successful 2xx</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#redirection-3xx">21.3 Redirection 3xx</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#request-failure-4xx">21.4 Request Failure 4xx</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#server-failure-5xx">21.5 Server Failure 5xx</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#global-failures-6xx">21.6 Global Failures 6xx</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#usage-of-http-authentication">22 Usage of HTTP Authentication</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#framework">22.1 Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#user-to-user-authentication">22.2 User-to-User Authentication</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#proxy-to-user-authentication">22.3 Proxy-to-User Authentication</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#the-digest-authentication-scheme">22.4 The Digest Authentication Scheme</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#s-mime">23 S/MIME</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#s-mime-certificates">23.1 S/MIME Certificates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#s-mime-key-exchange">23.2 S/MIME Key Exchange</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#securing-mime-bodies">23.3 Securing MIME bodies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#sip-header-privacy-and-integrity-using-s-mime-tunneling-sip">23.4 SIP Header Privacy and Integrity using S/MIME: Tunneling SIP</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#id12">24 Examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#registration">24.1 Registration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#session-setup">24.2 Session Setup</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#augmented-bnf-for-the-sip-protocol">25 Augmented BNF for the SIP Protocol</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#security-considerations-threat-model-and-security-usage-recommendations">26 Security Considerations: Threat Model and Security Usage Recommendations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#iana-considerations">27 IANA Considerations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#changes-from-rfc-2543">28 Changes From RFC 2543</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#major-functional-changes">28.1 Major Functional Changes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#minor-functional-changes">28.2 Minor Functional Changes</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3261-SIP-Session%20Initiation%20Protocol.html#a-table-of-timer-values">A Table of Timer Values</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html">RFC3550: RTP: A Transport Protocol for Real-Time Applications</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#introduction">1. Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#rtp-use-scenarios">2. RTP Use Scenarios</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#simple-multicast-audio-conference">2.1 Simple Multicast Audio Conference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#audio-and-video-conference">2.2 Audio and Video Conference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#mixers-and-translators">2.3 Mixers and Translators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#layered-encodings">2.4 Layered Encodings</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#definitions">3. Definitions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#byte-order-alignment-and-time-format">4. Byte Order, Alignment, and Time Format</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#rtp-data-transfer-protocol">5. RTP Data Transfer Protocol</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#rtp-fixed-header-fields">5.1 RTP Fixed Header Fields</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#multiplexing-rtp-sessions">5.2 Multiplexing RTP Sessions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#profile-specific-modifications-to-the-rtp-header">5.3  Profile-Specific Modifications to the RTP Header</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#rtp-control-protocol-rtcp">6.  RTP Control Protocol – RTCP</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#rtcp-packet-format">6.1  RTCP Packet Format</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#rtcp-transmission-interval">6.2  RTCP Transmission Interval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#rtcp-packet-send-and-receive-rules">6.3  RTCP Packet Send and Receive Rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#sender-and-receiver-reports">6.4  Sender and Receiver Reports</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#sdes-source-description-rtcp-packet">6.5  SDES: Source Description RTCP Packet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#bye-goodbye-rtcp-packet">6.6  BYE: Goodbye RTCP Packet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#app-application-defined-rtcp-packet">6.7  APP: Application-Defined RTCP Packet</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#rtp-translators-and-mixers">7.  RTP Translators and Mixers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#general-description">7.1  General Description</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#rtcp-processing-in-translators">7.2  RTCP Processing in Translators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#rtcp-processing-in-mixers">7.3  RTCP Processing in Mixers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#cascaded-mixers">7.4  Cascaded Mixers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#ssrc-identifier-allocation-and-use">8.  SSRC Identifier Allocation and Use</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#security">9.  Security</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#confidentiality">9.1 Confidentiality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#authentication-and-message-integrity">9.2 Authentication and Message Integrity</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#congestion-control">10. Congestion Control</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#rtp-over-network-and-transport-protocols">11. RTP over Network and Transport Protocols</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#summary-of-protocol-constants">12. Summary of Protocol Constants</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#rtcp-packet-types">12.1 RTCP Packet Types</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#sdes-types">12.2 SDES Types</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#rtp-profiles-and-payload-format-specifications">13. RTP Profiles and Payload Format Specifications</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#appendix-a-algorithms">Appendix A.   Algorithms</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3550-RTP-A%20Transport%20Protocol%20for%20Real-Time%20Applications.html#appendix-b-changes-from-rfc-1889">Appendix B.   Changes from RFC 1889</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html">RFC3551: RTP Profile for Audio and Video Conferences with Minimal Control</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#introduction">1. Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#rtp-and-rtcp-packet-forms-and-protocol-behavior">2. RTP and RTCP Packet Forms and Protocol Behavior</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#registering-additional-encodings">3.  Registering Additional Encodings</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#audio">4.  Audio</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#encoding-independent-rules">4.1  Encoding-Independent Rules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#operating-recommendations">4.2  Operating Recommendations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#guidelines-for-sample-based-audio-encodings">4.3  Guidelines for Sample-Based Audio Encodings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#guidelines-for-frame-based-audio-encodings">4.4  Guidelines for Frame-Based Audio Encodings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#audio-encodings">4.5 Audio Encodings</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#video">5.  Video</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#payload-type-definitions">6.  Payload Type Definitions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#rtp-over-tcp-and-similar-byte-stream-protocols">7.  RTP over TCP and Similar Byte Stream Protocols</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#port-assignment">8.  Port Assignment</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc3551-RTP%20Profile%20for%20Audio%20and%20Video%20Conferences%20with%20Minimal%20Control.html#changes-from-rfc-1890">9.  Changes from RFC 1890</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html">RFC6184: RTP Payload Format for H.264 Video</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#introduction">1. Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#the-h-264-codec">1.1.  The H.264 Codec</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#parameter-set-concept">1.2.  Parameter Set Concept</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#network-abstraction-layer-unit-types">1.3.  Network Abstraction Layer Unit Types</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#conventions">2. Conventions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#scope">3. Scope</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#definitions-and-abbreviations">4. Definitions and Abbreviations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#definitions">4.1.  Definitions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#abbreviations">4.2.  Abbreviations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#rtp-payload-format">5. RTP Payload Format</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#rtp-header-usage">5.1.  RTP Header Usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#payload-structures">5.2.  Payload Structures</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#nal-unit-header-usage">5.3.  NAL Unit Header Usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#packetization-modes">5.4.  Packetization Modes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#decoding-order-number-don">5.5.  Decoding Order Number (DON)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#single-nal-unit-packet">5.6.  Single NAL Unit Packet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#aggregation-packets">5.7.  Aggregation Packets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#fragmentation-units-fus">5.8.  Fragmentation Units (FUs)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#packetization-rules">6. Packetization Rules</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#de-packetization-process">7. De-Packetization Process</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#payload-format-parameters">8. Payload Format Parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#media-type-registration">8.1.  Media Type Registration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#sdp-parameters">8.2.  SDP Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#examples">8.3.  Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#parameter-set-considerations">8.4.  Parameter Set Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#decoder-refresh-point-procedure-using-in-band-transport-of-parameter-sets-informative">8.5.  Decoder Refresh Point Procedure Using In-Band Transport of Parameter Sets (Informative)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#informative-appendix-application-examples">12. Informative Appendix: Application Examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#video-telephony-according-to-annex-a-of-itu-t-recommendation-h-241">12.1.  Video Telephony According to Annex A of ITU-T Recommendation H.241</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#video-telephony-no-slice-data-partitioning-no-nal-unit-aggregation">12.2.  Video Telephony, No Slice Data Partitioning, No NAL Unit Aggregation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#video-telephony-interleaved-packetization-using-nal-unit-aggregation">12.3.  Video Telephony, Interleaved Packetization Using NAL Unit Aggregation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#video-telephony-with-data-partitioning">12.4.  Video Telephony with Data Partitioning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#video-telephony-or-streaming-with-fus-and-forward-error-correction">12.5.  Video Telephony or Streaming with FUs and Forward Error Correction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#low-bitrate-streaming">12.6.  Low Bitrate Streaming</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#robust-packet-scheduling-in-video-streaming">12.7.  Robust Packet Scheduling in Video Streaming</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#informative-appendix-rationale-for-decoding-order-number">13. Informative Appendix: Rationale for Decoding Order Number</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc6184-RTP%20Payload%20Format%20for%20H.264%20Video.html#example-of-robust-packet-scheduling">13.3.  Example of Robust Packet Scheduling</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html">RFC7826: Real-Time Streaming Protocol</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#abstract">Abstract</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#introduction">1.  Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#protocol-overview">2.  Protocol Overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#presentation-description">2.1.  Presentation Description</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#session-establishment">2.2.  Session Establishment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#media-delivery-control">2.3.  Media Delivery Control</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#session-parameter-manipulations">2.4. Session Parameter Manipulations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#media-delivery">2.5. Media Delivery</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#session-maintenance-and-termination">2.6. Session Maintenance and Termination</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#extending-rtsp">2.7. Extending RTSP</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#document-conventions">3. Document Conventions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#terminology">3.2. Terminology</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#protocol-parameters">4. Protocol Parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#rtsp-version">4.1.  RTSP Version</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#rtsp-iri-and-uri">4.2.  RTSP IRI and URI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#session-identifiers">4.3.  Session Identifiers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#media-time-formats">4.4.  Media-Time Formats</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#feature-tags">4.5.  Feature Tags</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#message-body-tags">4.6.  Message Body Tags</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#media-properties">4.7.  Media Properties</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#rtsp-message">5. RTSP Message</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#message-types">5.1. Message Types</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#message-headers">5.2. Message Headers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#message-body">5.3. Message Body</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#message-length">5.4. Message Length</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#general-header-fields">6. General-Header Fields</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#request">7. Request</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#request-line">7.1.  Request Line</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#request-header-fields">7.2.  Request-Header Fields</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#response">8. Response</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#status-line">8.1.  Status-Line</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#response-headers">8.2.  Response Headers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#id2">9. Message Body</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#message-body-header-fields">9.1.  Message Body Header Fields</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#id3">9.2. Message Body</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#message-body-format-negotiation">9.3. Message Body Format Negotiation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#connections">10. Connections</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#reliability-and-acknowledgements">10.1. Reliability and Acknowledgements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#using-connections">10.2. Using Connections</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#closing-connections">10.3. Closing Connections</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#timing-out-connections-and-rtsp-messages">10.4.  Timing Out Connections and RTSP Messages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#showing-liveness">10.5.  Showing Liveness</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#use-of-ipv6">10.6.  Use of IPv6</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#overload-control">10.7.  Overload Control</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#capability-handling">11. Capability Handling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#pipelining-support">12. Pipelining Support</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#method-definitions">13. Method Definitions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#options">13.1.  OPTIONS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#describe">13.2. DESCRIBE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#setup">13.3.  SETUP</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#play">13.4.  PLAY</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#play-notify">13.5.  PLAY_NOTIFY</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#pause">13.6.  PAUSE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#teardown">13.7.  TEARDOWN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#get-parameter">13.8.  GET_PARAMETER</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#redirect">13.10.  REDIRECT</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#embedded-interleaved-binary-data">14. Embedded (Interleaved) Binary Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#proxies">15. Proxies</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#proxies-and-protocol-extensions">15.1.  Proxies and Protocol Extensions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#multiplexing-and-demultiplexing-of-messages">15.2.  Multiplexing and Demultiplexing of Messages</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#caching">16. Caching</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#validation-model">16.1.  Validation Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#invalidation-after-updates-or-deletions">16.2.  Invalidation after Updates or Deletions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#status-code-definitions">17. Status Code Definitions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#header-field-definitions">18. Header Field Definitions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#pipelined-requests">18.33.  Pipelined-Requests</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#security-framework">19. Security Framework</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#rtsp-and-http-authentication">19.1.  RTSP and HTTP Authentication</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#rtsp-over-tls">19.2. RTSP over TLS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#security-and-proxies">19.3. Security and Proxies</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#syntax">20. Syntax</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#base-syntax">20.1.  Base Syntax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#rtsp-protocol-definition">20.2.  RTSP Protocol Definition</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#security-considerations">21. Security Considerations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#signaling-protocol-threats">21.1.  Signaling Protocol Threats</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#appendix-a-examples">Appendix A.  Examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#a-1-media-on-demand-unicast">A.1.  Media on Demand (Unicast)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#a-2-media-on-demand-using-pipelining">A.2.  Media on Demand Using Pipelining</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#a-3-secured-media-session-for-on-demand-content">A.3.  Secured Media Session for On-Demand Content</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#a-4-media-on-demand-unicast">A.4.  Media on Demand (Unicast)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#a-5-single-stream-container-files">A.5.  Single-Stream Container Files</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#a-6-live-media-presentation-using-multicast">A.6.  Live Media Presentation Using Multicast</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#a-7-capability-negotiation">A.7.  Capability Negotiation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#appendix-b-rtsp-protocol-state-machine">Appendix B.  RTSP Protocol State Machine</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#b-1-states">B.1.  States</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#b-2-state-variables">B.2.  State Variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#b-3-abbreviations">B.3.  Abbreviations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#b-4-state-tables">B.4.  State Tables</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#appendix-c-media-transport-alternatives">Appendix C.  Media-Transport Alternatives</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#c-1-rtp">C.1.  RTP</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#c-2-rtp-over-tcp">C.2. RTP over TCP</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#c-3-handling-media-clock-time-jumps-in-the-rtp-media-layer">C.3.  Handling Media-Clock Time Jumps in the RTP Media Layer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#c-4-handling-rtp-timestamps-after-pause">C.4. Handling RTP Timestamps after PAUSE</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#c-5-rtsp-rtp-integration">C.5.  RTSP/RTP Integration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#c-6-scaling-with-rtp">C.6.  Scaling with RTP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#c-7-maintaining-npt-synchronization-with-rtp-timestamps">C.7.  Maintaining NPT Synchronization with RTP Timestamps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#c-8-continuous-audio">C.8.  Continuous Audio</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#c-9-multiple-sources-in-an-rtp-session">C.9.  Multiple Sources in an RTP Session</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#c-10-usage-of-ssrcs-and-the-rtcp-bye-message-during-an-rtsp-session">C.10.  Usage of SSRCs and the RTCP BYE Message during an RTSP Session</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#c-11-future-additions">C.11.  Future Additions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#appendix-d-use-of-sdp-for-rtsp-session-descriptions">Appendix D. Use of SDP for RTSP Session Descriptions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#d-1-definitions">D.1.  Definitions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#d-2-aggregate-control-not-available">D.2.  Aggregate Control Not Available</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#d-3-aggregate-control-available">D.3.  Aggregate Control Available</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#d-4-grouping-of-media-lines-in-sdp">D.4.  Grouping of Media Lines in SDP</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#d-5-rtsp-external-sdp-delivery">D.5.  RTSP External SDP Delivery</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#appendix-e-rtsp-use-cases">Appendix E. RTSP Use Cases</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#e-1-on-demand-playback-of-stored-content">E.1.  On-Demand Playback of Stored Content</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#e-2-unicast-distribution-of-live-content">E.2.  Unicast Distribution of Live Content</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#e-3-on-demand-playback-using-multicast">E.3.  On-Demand Playback Using Multicast</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#e-4-inviting-an-rtsp-server-into-a-conference">E.4.  Inviting an RTSP Server into a Conference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#e-5-live-content-using-multicast">E.5.  Live Content Using Multicast</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#appendix-f-text-format-for-parameters">Appendix F.  Text Format for Parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#appendix-g-requirements-for-unreliable-transport-of-rtsp">Appendix G.  Requirements for Unreliable Transport of RTSP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#appendix-h-backwards-compatibility-considerations">Appendix H.  Backwards-Compatibility Considerations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#h-1-play-request-in-play-state">H.1.  Play Request in Play State</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#h-2-using-persistent-connections">H.2.  Using Persistent Connections</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#appendix-i-changes">Appendix I.  Changes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#i-1-brief-overview">I.1.  Brief Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc7826-Real-Time%20Streaming%20Protocol.html#i-2-detailed-list-of-changes">I.2.  Detailed List of Changes</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html">RFC8866: SDP-Session Description Protocol</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#introduction">1. Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#glossary-of-terms">2. Glossary of Terms</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#examples-of-sdp-usage">3. Examples of SDP Usage</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#session-initiation">3.1. Session Initiation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#streaming-media">3.2. Streaming Media</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#email-and-the-world-wide-web">3.3. Email and the World Wide Web</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#multicast-session-announcement">3.4. Multicast Session Announcement</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#requirements-and-recommendations">4. Requirements and Recommendations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#media-and-transport-information">4.1. Media and Transport Information</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#timing-information">4.2. Timing Information</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#sdp-specification">5. SDP Specification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#protocol-version-v">5.1. Protocol Version (“v=”)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#origin-o">5.2. Origin (“o=”)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#session-name-s">5.3. Session Name (“s=”)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#session-information-i">5.4. Session Information (“i=”)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#uri-u">5.5. URI (“u=”)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#email-address-and-phone-number-e-and-p">5.6. Email Address and Phone Number (“e=” and “p=”)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#connection-information-c">5.7. Connection Information (“c=”)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#bandwidth-information-b">5.8. Bandwidth Information (“b=”)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#time-active-t">5.9. Time Active (“t=”)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#repeat-times-r">5.10. Repeat Times (“r=”)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#time-zone-adjustment-z">5.11. Time Zone Adjustment (“z=”)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#encryption-keys-k">5.12. Encryption Keys (“k=”)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#attributes-a">5.13. Attributes (“a=”)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#media-descriptions-m">5.14. Media Descriptions (“m=”)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#sdp-attributes">6. SDP Attributes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#cat-category">6.1. cat (Category)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#keywds-keywords">6.2. keywds (Keywords)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#tool">6.3. tool</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#ptime-packet-time">6.4. ptime (Packet Time)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#maxptime-maximum-packet-time">6.5. maxptime (Maximum Packet Time)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#rtpmap">6.6. rtpmap</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#media-direction-attributes">6.7. Media Direction Attributes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#orient-orientation">6.8. orient (Orientation)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#type-conference-type">6.9. type (Conference Type)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#charset-character-set">6.10. charset (Character Set)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#sdplang-sdp-language">6.11. sdplang (SDP Language)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#lang-language">6.12. lang (Language)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#framerate-frame-rate">6.13. framerate (Frame Rate)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#quality">6.14. quality</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#fmtp-format-parameters">6.15. fmtp (Format Parameters)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#security-considerations">7. Security Considerations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#iana-considerations">8. IANA Considerations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#sdp-grammar">9. SDP Grammar</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/streamings/rfc8866-SDP-Session%20Description%20Protocol.html#summary-of-changes-from-rfc-4566">10. Summary of Changes from RFC 4566</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/STUNs/rfc7350.html">rfc7350: DTLS as Transport for STUN</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/STUNs/rfc5769.html">RFC5769: Test Vectors for STUN</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/STUNs/rfc5780.html">rfc5780: NAT Behavior Discovery Using STUN</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/STUNs/rfc7443.html">rfc7443: ALPN Labels for STUN Usages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/STUNs/rfc7635.html">rfc7635: STUN Extension for Third-Party Authorization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/STUNs/rfc8489.html">RFC8489: STUN - Session Traversal Utilities for NAT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/x.509/rfc5280.html">RFC5280: Internet X.509 PKIC and CRL Profile</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/x.509/rfc5280.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/x.509/rfc5652.html">RFC5652: Cryptographic Message Syntax (CMS)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/x.509/rfc5652.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/x.509/rfc5912.html">RFC5912: New ASN.1 Modules for the PKIX</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/x.509/rfc5912.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/MIME/rfc2045-MIME1.html">RFC2045: (MIME) Part One: Format of Internet Message Bodies</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2045-MIME1.html#introduction">1.  Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2045-MIME1.html#definitions-conventions-and-generic-bnf-grammar">2.  Definitions, Conventions, and Generic BNF Grammar</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2045-MIME1.html#mime-header-fields">3.  MIME Header Fields</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2045-MIME1.html#mime-version-header-field">4.  MIME-Version Header Field</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2045-MIME1.html#id2">示例</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2045-MIME1.html#content-type-header-field">5.  Content-Type Header Field</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2045-MIME1.html#syntax-of-the-content-type-header-field">5.1 Syntax of the Content-Type Header Field</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2045-MIME1.html#content-type-defaults">5.2 Content-Type Defaults</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2045-MIME1.html#content-transfer-encoding-header-field">6. Content-Transfer-Encoding Header Field</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2045-MIME1.html#content-transfer-encoding-syntax">6.1.  Content-Transfer-Encoding Syntax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2045-MIME1.html#content-transfer-encodings-semantics">6.2.  Content-Transfer-Encodings Semantics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2045-MIME1.html#new-content-transfer-encodings">6.3.  New Content-Transfer-Encodings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2045-MIME1.html#interpretation-and-use">6.4.  Interpretation and Use</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2045-MIME1.html#translating-encodings">6.5.  Translating Encodings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2045-MIME1.html#canonical-encoding-model">6.6.  Canonical Encoding Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2045-MIME1.html#quoted-printable-content-transfer-encoding">6.7.  Quoted-Printable Content-Transfer-Encoding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2045-MIME1.html#base64-content-transfer-encoding">6.8.  Base64 Content-Transfer-Encoding</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2045-MIME1.html#content-id-header-field">7.  Content-ID Header Field</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2045-MIME1.html#content-description-header-field">8.  Content-Description Header Field</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2045-MIME1.html#additional-mime-header-fields">9.  Additional MIME Header Fields</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2045-MIME1.html#appendix-a-collected-grammar">Appendix A – Collected Grammar</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2045-MIME1.html#content">content</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2045-MIME1.html#encoding">encoding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2045-MIME1.html#id">id</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2045-MIME1.html#description">description</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2045-MIME1.html#mime-extension-field">MIME-extension-field</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2045-MIME1.html#id3">通用</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/MIME/rfc2046-MIME2.html">RFC2046: (MIME) Part Two: Media Types</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2046-MIME2.html#overview-of-the-initial-top-level-media-types">3. Overview Of The Initial Top-Level Media Types</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2046-MIME2.html#discrete-media-type-values">4. Discrete Media Type Values</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2046-MIME2.html#text-media-type">4.1.  Text Media Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2046-MIME2.html#image-media-type">4.2.  Image Media Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2046-MIME2.html#audio-media-type">4.3.  Audio Media Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2046-MIME2.html#video-media-type">4.4.  Video Media Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2046-MIME2.html#application-media-type">4.5.  Application Media Type</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2046-MIME2.html#composite-media-type-values">5. Composite Media Type Values</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2046-MIME2.html#multipart-media-type">5.1.  Multipart Media Type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2046-MIME2.html#message-media-type">5.2 Message Media Type</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2046-MIME2.html#experimental-media-type-values">6.  Experimental Media Type Values</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/MIME/rfc2047-MIME3.html">RFC2047: (MIME) Part Three: Message Header Extensions for Non-ASCII Text</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2047-MIME3.html#introduction">1. Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2047-MIME3.html#syntax-of-encoded-words">2. Syntax of encoded-words</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2047-MIME3.html#character-sets">3. Character sets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2047-MIME3.html#encodings">4. Encodings</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2047-MIME3.html#use-of-encoded-words-in-message-headers">5. Use of encoded-words in message headers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2047-MIME3.html#support-of-encoded-word-s-by-mail-readers">6. Support of ‘encoded-word’s by mail readers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2047-MIME3.html#conformance">7. Conformance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2047-MIME3.html#examples">8. Examples</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/MIME/rfc2048-MIME4.html">RFC2048: (MIME) Part Four: Registration Procedures</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2048-MIME4.html#introduction">1. Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2048-MIME4.html#media-type-registration">2. Media Type Registration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2048-MIME4.html#registration-trees-and-subtype-names">2.1.  Registration Trees and Subtype Names</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2048-MIME4.html#registration-requirements">2.2 Registration Requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2048-MIME4.html#registration-procedure">2.3 Registration Procedure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2048-MIME4.html#comments-on-media-type-registrations">2.4 Comments on Media Type Registrations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2048-MIME4.html#location-of-registered-media-type-list">2.5 Location of Registered Media Type List</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2048-MIME4.html#iana-procedures-for-registering-media-types">2.6.  IANA Procedures for Registering Media Types</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2048-MIME4.html#change-control">2.7.  Change Control</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../rfcs/MIME/rfc2048-MIME4.html#registration-template">2.8 Registration Template</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2048-MIME4.html#external-body-access-types">3. External Body Access Types</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2048-MIME4.html#transfer-encodings">4. Transfer Encodings</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/MIME/rfc2049-MIME5.html">RFC2049: (MIME) Part Five: Conformance Criteria and Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2049-MIME5.html#introduction">1. Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2049-MIME5.html#mime-conformance">2.  MIME Conformance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2049-MIME5.html#guidelines-for-sending-email-data">3.  Guidelines for Sending Email Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2049-MIME5.html#canonical-encoding-model">4.  Canonical Encoding Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/MIME/rfc2049-MIME5.html#appendix-a-a-complex-multipart-example">Appendix A – A Complex Multipart Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/rfc1123.html">rfc1123</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/rfc3232.html">RFC3232: ASSIGNED NUMBERS</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/rfc3232.html#rfc1700">RFC1700</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/rfc3339.html">rfc3339</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/rfc3339.html#id3">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../rfcs/rfc5234-ABNF.html">RFC5234: Augmented BNF for Syntax Specifications: ABNF</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../rfcs/rfc5234-ABNF.html#id2">示例</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../iana.html">iana</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../IEEE.html">IEEE</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../IEEEs/normal.html">常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../IEEEs/754.html">IEEE 754</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../IEEEs/754.html#id1">工具</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../IEEEs/754.html#id2">📦 IEEE 754 定义的内容包括：</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../IEEEs/754.html#id3">✅ 1. <strong>浮点数格式</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../IEEEs/754.html#id4">✅ 2. <strong>浮点数结构（三部分）</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../IEEEs/754.html#id5">✅ 3. <strong>特殊值支持</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../IEEEs/754.html#id6">📚 衍生标准（对深度学习重要）</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../IEEEs/754.html#fp4">FP4</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../IEEEs/802.3.html">IEEE 802.3</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../IEEEs/802.3.html#ethernet-ii">Ethernet II</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../IEEEs/802.11.html">802.11: Wireless LAN &amp; Mesh</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../IEEEs/802.11.html#protocol">Protocol</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../IEEEs/802.11.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../IEEEs/802.15.html">802.15: Wireless PAN</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../IEEEs/802.15.html#low-rate-wireless-pan">802.15.4: Low-Rate wireless PAN</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../ITU.html">ITU</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../ITUs/normal.html">常用</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../ITUs/normal.html#id3">电信标准化</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../ITUs/normal.html#id4">研究组</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../ITUs/X%20Series.html">X-Series</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../ITUs/X%20Series.html#directory">DIRECTORY</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../ITUs/X%20Series.html#asn-1">ASN.1</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../ITUs/X%20Series.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../ITUs/G%20Series.html">G-Series</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../ITUs/G%20Series.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../ITUs/H%20Series.html">H-Series</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../ITUs/H%20Series.html#id2">参考</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../ISO.html">ISO</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../ISOs/normal.html">常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ISOs/iso10646.html">ISO/IEC 10646: Universal coded character set (UCS)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ISOs/iso13818.html">ISO/IEC 13818</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../ISOs/iso13818.html#part-1-systems">Part 1: Systems</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../ISOs/iso13818.html#part-6-extensions-for-dsm-cc">Part 6: Extensions for DSM-CC</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../GB.html">中标</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../GBs/T28181.html">GB/T28181安全技术视频监控联网系统信息传输, 交换, 控制技术要求</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../pep.html">pep</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../peps/pep-3333.html">pep-3333</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../peps/pep-3333.html#id3">背景与动机</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../peps/pep-3333.html#id4">pep-3333主要变化</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../peps/pep-3333.html#id5">规范概述</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../peps/pep-3333.html#id6">应用程序端</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../peps/pep-3333.html#id7">服务器端</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../peps/pep-3333.html#id8">中间件</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../peps/pep-0440.html">pep-0440</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../peps/pep-0440.html#id2">简介</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../peps/pep-0440.html#id3">基本格式</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../peps/pep-0440.html#id4">版本号的比较</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../peps/pep-0420.html">PEP 420 – Implicit Namespace Packages</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../peps/pep-0420.html#id2">核心要点</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../peps/pep-0420.html#id3">主要优势</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../peps/pep-0420.html#id4">当前现有方案</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../peps/pep-0420.html#pkgutil-style-namespace-packages">pkgutil-style namespace packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../peps/pep-0420.html#pkg-resources-style-namespace-packages">pkg_resources-style namespace packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../peps/pep-0420.html#id5">两方案的不足</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../peps/pep-0420.html#specification">Specification 规范</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../peps/pep-0420.html#id6">说明</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../peps/pep-0420.html#id7">命名空间包和常规包之间的区别</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../peps/pep-0420.html#examples">Examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../peps/pep-0420.html#nested-namespace-packages">Nested namespace packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../peps/pep-0420.html#dynamic-path-computation">Dynamic path computation</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../paper.html">论文</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../paper.html#id3">通用</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../papers/normals/normal.html">通用</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/normals/normal.html#id3">如何看一个论文是不是重要</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/normals/website.html">学术网站</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/normals/website.html#id3">学术搜索平台</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/normals/website.html#id5">资源共享</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/normals/website.html#id6">论文数据库</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../paper.html#agents">Agents</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Agents/2210.03629_ReAct.html">2210.03629_ReAct</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Agents/2303.08268_Chat-with-the-Environment.html">2303.08268_Chat-with-the-Environment</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agents/2303.08268_Chat-with-the-Environment.html#id2">正文</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Agents/2303.11366_Reflexion.html">2303.11366_Reflexion: Language Agents with Verbal Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Agents/2303.16434_TaskMatrix.AI.html">2303.16434_TaskMatrix.AI</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agents/2303.16434_TaskMatrix.AI.html#id2">大脑</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agents/2303.16434_TaskMatrix.AI.html#id3">接口平台</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agents/2303.16434_TaskMatrix.AI.html#api">API 选择器</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Agents/2304.03442_Generative-Agents.html">2304.03442_Generative-Agents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agents/2304.03442_Generative-Agents.html#generative-agent-architecture">Generative Agent Architecture</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Agents/2307.07924_ChatDev.html">2307.07924_ChatDev: Communicative Agents for Software Development</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Agents/2308.00352_MetaGPT.html">2308.00352_MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Agents/2308.04026_AgentSims.html">2308.04026_AgentSims: An Open-Source Sandbox for Large Language Model Evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Agents/2308.08155_AutoGen.html">2308.08155_AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Agents/2308.10848_AgentVerse.html">2308.10848_AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agents/2308.10848_AgentVerse.html#id2">理念</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Agents/2310.06117_Step-Back.html">2310.06117_Step-Back: Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Agents/2402.18679_MetaGPT_DI.html">2402.18679_MetaGPT_DI: Data Interpreter: An LLM Agent For Data Science</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agents/2402.18679_MetaGPT_DI.html#introduction">INTRODUCTION</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Agents/2407.07061_IoA.html">2407.07061_IoA: Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agents/2407.07061_IoA.html#overview-of-ioa">2.1 OVERVIEW OF IOA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agents/2407.07061_IoA.html#architecture-of-ioa">2.2 ARCHITECTURE OF IOA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agents/2407.07061_IoA.html#key-mechanisms">2.3 KEY MECHANISMS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agents/2407.07061_IoA.html#putting-it-all-together">2.5 Putting It All Together</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Agents/2408.08435_ADAS.html">2408.08435_ADAS: Automated Design of Agentic Systems</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agents/2408.08435_ADAS.html#prompt">Prompt</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Agents/2410.17238_SELA.html">2410.17238_SELA: Tree-Search Enhanced LLM Agents for Automated Machine Learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agents/2410.17238_SELA.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agents/2410.17238_SELA.html#related-works">2 Related Works</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agents/2410.17238_SELA.html#method">3 Method</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Agents/2410.10762_AFlow.html">2408.08435_ADAS: Automating Agentic Workflow Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agents/2410.10762_AFlow.html#introduce">Introduce</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agents/2410.10762_AFlow.html#preliminary">PRELIMINARY</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Agents/2410.21012_FACT.html">2410.21012_FACT: Examining the Effectiveness of Iterative Context Rewriting for Multi-fact Retrieval</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agents/2410.21012_FACT.html#introduce">Introduce</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Agents/2504.01990_foundation-agents.html">2504.01990_Advances and Challenges in Foundation Agents</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Agents/2506.12508_AgentOrchestra.html">2506.12508_AgentOrchestra: A Hierarchical Multi-Agent Framework for General-Purpose Task Solving</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agents/2506.12508_AgentOrchestra.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agents/2506.12508_AgentOrchestra.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agents/2506.12508_AgentOrchestra.html#agentorchestra">3.AgentOrchestra</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agents/2506.12508_AgentOrchestra.html#experiments">4.Experiments</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../paper.html#agent-aios">视觉 Agent&amp;AIOS</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Agent_Visions/2312.13771_AppAgent.html">2312.13771_AppAgent: Multimodal Agents as Smartphone Users</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2312.13771_AppAgent.html#environment-and-action-space">3.1 Environment and Action Space</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2312.13771_AppAgent.html#exploration-phase">3.2 Exploration Phase</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2312.13771_AppAgent.html#deployment-phase">3.3 Deployment Phase</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Agent_Visions/2402.07939_UFO.html">2402.07939_UFO: A UI-Focused Agent for Windows OS Interaction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2402.07939_UFO.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2402.07939_UFO.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2402.07939_UFO.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2402.07939_UFO.html#the-design-of-ufo">3.The Design of UFO</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2402.07939_UFO.html#experiment">4.Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2402.07939_UFO.html#limitations-lessons-learned">5.Limitations &amp; Lessons Learned</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2402.07939_UFO.html#conclusion">6.Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Agent_Visions/2406.01014_Mobile-Agent-v2.html">2406.01014_Mobile-Agent-v2: Mobile Device Operation Assistant with Effective Navigation via Multi-Agent Collaboration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Agent_Visions/2501.11733_Mobile-Agent-E.html">2501.11733_Mobile-Agent-E: Self-Evolving Mobile Assistant for Complex Tasks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2501.11733_Mobile-Agent-E.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2501.11733_Mobile-Agent-E.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2501.11733_Mobile-Agent-E.html#mobile-agent-e">2. Mobile-Agent-E</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2501.11733_Mobile-Agent-E.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2501.11733_Mobile-Agent-E.html#results">4. Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2501.11733_Mobile-Agent-E.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2501.11733_Mobile-Agent-E.html#conclusion-and-future-work">6. Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-a-full-trajectory-comparison-example-with-previous-sota">Appendix A Full Trajectory Comparison Example with Previous SOTA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-b-error-recovery-with-escalation-to-manager">Appendix B Error Recovery with Escalation to Manager</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-c-remaining-limitations">Appendix C Remaining Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-d-all-tasks-in-mobile-eval-e-benchmark">Appendix D All Tasks in Mobile-Eval-E Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-e-atomic-operation-space">Appendix E Atomic Operation Space</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-f-full-list-of-self-evolved-shortcuts">Appendix F Full list of Self-Evolved Shortcuts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2501.11733_Mobile-Agent-E.html#appendix-g-full-list-of-self-evolved-tips">Appendix G Full list of Self-Evolved Tips</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Agent_Visions/2501.12326_UI-TARS.html">2501.12326_UI-TARS: Pioneering Automated GUI Interaction with Native Agents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2501.12326_UI-TARS.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2501.12326_UI-TARS.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2501.12326_UI-TARS.html#evolution-path-of-gui-agents">2. Evolution Path of GUI Agents</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2501.12326_UI-TARS.html#core-capabilities-of-native-agent-model">3. Core Capabilities of Native Agent Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2501.12326_UI-TARS.html#ui-tars">4. UI-TARS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2501.12326_UI-TARS.html#experiment">5. Experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2501.12326_UI-TARS.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Agent_Visions/2502.14282_PC-Agent.html">2502.14282_PC-Agent: A Hierarchical Multi-Agent Collaboration Framework for Complex Task Automation on PC</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2502.14282_PC-Agent.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2502.14282_PC-Agent.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2502.14282_PC-Agent.html#pc-agent">2. PC-Agent</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2502.14282_PC-Agent.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2502.14282_PC-Agent.html#related-work">4. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2502.14282_PC-Agent.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Agent_Visions/2403.16971_AIOS.html">2403.16971_AIOS: LLM Agent Operating System</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2403.16971_AIOS.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2403.16971_AIOS.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2403.16971_AIOS.html#the-architecture-of-aios">2. The Architecture of AIOS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2403.16971_AIOS.html#aios-kernel">3. AIOS Kernel</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2403.16971_AIOS.html#evaluation">4 Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2403.16971_AIOS.html#appendix-e-discussion">Appendix E Discussion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Agent_Visions/2504.14603_UFO2.html">2504.14603_UFO2: The Desktop AgentOS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2504.14603_UFO2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2504.14603_UFO2.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2504.14603_UFO2.html#background">2.Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2504.14603_UFO2.html#system-design-of-ufo2">3.System Design of UFO2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2504.14603_UFO2.html#picture-in-picture-interface">4.Picture-in-Picture Interface</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2504.14603_UFO2.html#implementation-and-specialized-engineering-design">5.Implementation and Specialized Engineering Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2504.14603_UFO2.html#evaluation">6.Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2504.14603_UFO2.html#discussion-future-work">7.Discussion &amp; Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2504.14603_UFO2.html#related-work">8.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Agent_Visions/2504.14603_UFO2.html#conclusion">9.Conclusion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../paper.html#id4">大模型调优</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMFineTunes/2101.00190_Prefix-Tuning.html">2101.00190_Prefix-Tuning: Optimizing Continuous Prompts for Generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMFineTunes/2103.10385_p-tuning.html">2103.10385_p-tuning: GPT Understands, Too</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMFineTunes/2104.08691_Prompt_Tuning.html">2104.08691_Prompt Tuning: The Power of Scale for Parameter-Efficient Prompt Tuning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMFineTunes/2106.09685_LoRA.html">2106.09685_LoRA: Low-Rank Adaptation of Large Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMFineTunes/2401.01335_Self-Play.html">2401.01335_Self-Play: Fine-Tuning Converts Weak Language Models to Strong Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMFineTunes/2402.09353_DoRA.html">2402.09353_DoRA: Weight-Decomposed Low-Rank Adaptation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMFineTunes/2402.12354_LoRA%2B.html">2402.12354_LoRA+: Efficient Low Rank Adaptation of Large Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMFineTunes/2403.03507_GaLore.html">2403.03507_GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMFineTunes/2403.13372_LlamaFactory.html">2403.13372_LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/2403.13372_LlamaFactory.html#id2">竞争框架</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/2403.13372_LlamaFactory.html#efficient-fine-tuning-techniques">3. Efficient Fine-Tuning Techniques</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/2403.13372_LlamaFactory.html#llamafactory-framework">4 LlamaFactory Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/2403.13372_LlamaFactory.html#conclusion-and-future-work">6 Conclusion and Future Work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMFineTunes/a/2203.02155_InstructGPT.html">2203.02155_Training language models to follow instructions with human feedback(InstructGPT)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/a/2203.02155_InstructGPT.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/a/2203.02155_InstructGPT.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/a/2203.02155_InstructGPT.html#related-work">2. Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/a/2203.02155_InstructGPT.html#methods-and-experimental-details">3. Methods and experimental details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/a/2203.02155_InstructGPT.html#results">4. Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/a/2203.02155_InstructGPT.html#discussion">5. Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/a/2203.02155_InstructGPT.html#appendix-a-additional-prompt-data-details">Appendix A Additional prompt data details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/a/2203.02155_InstructGPT.html#appendix-b-additional-human-data-collection-details">Appendix B Additional human data collection details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/a/2203.02155_InstructGPT.html#appendix-c-additional-model-details">Appendix C Additional model details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/a/2203.02155_InstructGPT.html#appendix-d-automatic-evaluation-details">Appendix D Automatic evaluation details</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMFineTunes/a/2305.20050_LetsVerifyStepbyStep.html">2305.20050_Let’s Verify Step by Step</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/a/2305.20050_LetsVerifyStepbyStep.html#id2">1. 研究背景</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/a/2305.20050_LetsVerifyStepbyStep.html#id3">2. 监督方法对比</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/a/2305.20050_LetsVerifyStepbyStep.html#id4">3. 核心发现</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/a/2305.20050_LetsVerifyStepbyStep.html#id5">总结</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMFineTunes/a/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html">2408.03314_Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/a/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/a/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html#how-to-scale-test-time-computation-optimally">3. How to Scale Test-Time Computation Optimally</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/a/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html#scaling-test-time-compute-via-verifiers">5. Scaling Test-Time Compute via Verifiers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/a/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html#refining-the-proposal-distribution">6. Refining the Proposal Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/a/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally.html#id7">其他</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMFineTunes/a/2412.14135_Scaling_of_Search_and_Learning.html">2412.14135_Scaling of Search and Learning: A Roadmap to Reproduce o1 from Reinforcement Learning Perspective</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/a/2412.14135_Scaling_of_Search_and_Learning.html#fromgpt">FromGPT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/a/2412.14135_Scaling_of_Search_and_Learning.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/a/2412.14135_Scaling_of_Search_and_Learning.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/a/2412.14135_Scaling_of_Search_and_Learning.html#id2">3. Policy Initialization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/a/2412.14135_Scaling_of_Search_and_Learning.html#id3">4. Reward Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/a/2412.14135_Scaling_of_Search_and_Learning.html#id5">5. Search</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/a/2412.14135_Scaling_of_Search_and_Learning.html#id8">6. Learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/a/2412.14135_Scaling_of_Search_and_Learning.html#open-source-o1-project">7 Open-source o1 Project</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/a/2412.14135_Scaling_of_Search_and_Learning.html#future-directions">8. Future Directions</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../paper.html#id5">分布式模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/normal.html">通用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1701.06538_MoE.html">1701.06538_MoE: Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1806.03377_PipeDream.html">1806.03377_PipeDream: Fast and Efficient Pipeline Parallel DNN Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1806.03377_PipeDream.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1806.03377_PipeDream.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1806.03377_PipeDream.html#background-related-work">2. Background &amp; Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1806.03377_PipeDream.html#parallel-training-in-pipedream">3. Parallel Training in PipeDream</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1806.03377_PipeDream.html#implementation">4. Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1806.03377_PipeDream.html#evaluation">5. Evaluation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1811.06965_GPipe.html">1811.06965_GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1811.06965_GPipe.html#id2">收集</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1811.06965_GPipe.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1811.06965_GPipe.html#the-gpipe-library">2. The GPipe Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1811.06965_GPipe.html#performance-analyses">3. Performance Analyses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1811.06965_GPipe.html#image-classification">4. Image Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1811.06965_GPipe.html#massive-massively-multilingual-machine-translation">5. Massive Massively Multilingual Machine Translation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1811.06965_GPipe.html#design-features-and-trade-offs">6. Design Features and Trade-Offs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1909.08053_Megatron-LM.html">1909.08053_Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1909.08053_Megatron-LM.html#id2">收集</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1909.08053_Megatron-LM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1909.08053_Megatron-LM.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1909.08053_Megatron-LM.html#background-and-challenges">2. Background and Challenges</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1909.08053_Megatron-LM.html#model-parallel-transformers">3. Model Parallel Transformers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1910_PipeDream2.html">19xx_PipeDream: Generalized Pipeline Parallelism for DNN Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1910_PipeDream2.html#id2">收集</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1910_PipeDream2.html#abstract">ABSTRACT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1910_PipeDream2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1910_PipeDream2.html#background-and-related-work">2. BACKGROUND AND RELATED WORK</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1910_PipeDream2.html#pipeline-parallelism">3. 流水线并行(PIPELINE PARALLELISM)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1910_PipeDream2.html#id5">4. 实现</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/1910_PipeDream2.html#id6">6. 结论</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/2006.15704DataParallel.html">2006.15704_PyTorch Distributed: Experiences on Accelerating Data Parallel Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/2006.16668_GShard.html">2006.16668_GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/2006.09503_PipeDream-2BW.html">2006.09503_PipeDream-2BW: Memory-Efficient Pipeline-Parallel DNN Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/2006.09503_PipeDream-2BW.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/2104.04473_Megatron-LM2.html">2104.04473_Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/2104.04473_Megatron-LM2.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/2205.14135_FlashAttention.html">2205.14135_FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/2205.14135_FlashAttention.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/2205.14135_FlashAttention.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/2205.14135_FlashAttention.html#background">2 Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/2205.14135_FlashAttention.html#flashattention-algorithm-analysis-and-extensions">3. FLASHATTENTION: Algorithm, Analysis, and Extensions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/2205.14135_FlashAttention.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/2205.14135_FlashAttention.html#limitations-and-future-directions">5. Limitations and Future Directions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/2205.14135_FlashAttention.html#appendix-a-related-work">Appendix A Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/2205.14135_FlashAttention.html#appendix-b-algorithm-details">Appendix B Algorithm Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/2205.14135_FlashAttention.html#appendix-c-proofs">Appendix C Proofs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/2205.14135_FlashAttention.html#appendix-d-extension-details">Appendix D Extension Details</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/2307.08691_FlashAttention2.html">2307.08691_FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/2307.08691_FlashAttention2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/2307.08691_FlashAttention2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/2307.08691_FlashAttention2.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/2307.08691_FlashAttention2.html#flashattention-2-algorithm-parallelism-and-work-partitioning">3. FlashAttention-2: Algorithm, Parallelism, and Work Partitioning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/2307.08691_FlashAttention2.html#empirical-validation">4. Empirical Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMFineTunes/Parallelism/2307.08691_FlashAttention2.html#discussion-and-future-directions">5. Discussion and Future Directions</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../paper.html#llm-nlp">LLM NLP</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMs/18_GPT1.html">18xx_GPT1: Improving Language Understanding by Generative Pre-Training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/18_GPT1.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/18_GPT1.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/18_GPT1.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/18_GPT1.html#framework">3. Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/18_GPT1.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/18_GPT1.html#analysis">5 Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/18_GPT1.html#conclusion">6 Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/18_GPT1.html#id3">引文口碑</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/18_GPT1.html#id4">要点解读</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMs/1810.04805_BERT.html">1810.04805_BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/1810.04805_BERT.html#introduction">1 Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/1810.04805_BERT.html#related-work">2 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/1810.04805_BERT.html#bert">3 BERT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/1810.04805_BERT.html#appendix-a-additional-details-for-bert">Appendix A Additional Details for BERT</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMs/19_GPT2.html">19xx_GPT2: Language Models are Unsupervised Multitask Learners</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/19_GPT2.html#the-illustrated-gpt-2">The Illustrated GPT-2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/19_GPT2.html#id2">参考</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMs/2012.00413_CPM.html">2012.00413_CPM: A Large-scale Generative Chinese Pre-trained Language Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMs/2302.13971_LLaMA.html">2302.13971_LLaMA: Open and Efficient Foundation Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMs/2307.09288_Llama2.html">2307.09288_Llama 2: Open Foundation and Fine-Tuned Chat Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMs/2309.16609_Qwen.html">2309.16609_Qwen Technical Report</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2309.16609_Qwen.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2309.16609_Qwen.html#pretraining">2. Pretraining</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2309.16609_Qwen.html#alignment">3. Alignment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2309.16609_Qwen.html#code-qwen-specialized-model-for-coding">4. CODE-QWEN: SPECIALIZED MODEL FOR CODING</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2309.16609_Qwen.html#math-qwen-specialized-model-for-mathematics-reasoning">5. MATH-QWEN: SPECIALIZED MODEL FOR MATHEMATICS REASONING</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2309.16609_Qwen.html#related-work">6. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2309.16609_Qwen.html#conclusion">7. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2309.16609_Qwen.html#a-1-more-training-details">A.1 MORE TRAINING DETAILS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2309.16609_Qwen.html#a-2-evaluation">A.2 EVALUATION</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMs/2401.14196_DeepSeek-Coder.html">2401.14196_DeepSeek-Coder: When the Large Language Model Meets Programming – The Rise of Code Intelligence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMs/2404.06395_MiniCPM.html">2404.06395_MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2404.06395_MiniCPM.html#two-stage-pre-training-strategy">5. Two Stage Pre-training Strategy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2404.06395_MiniCPM.html#model">6. Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2404.06395_MiniCPM.html#minicpm-family">7 MiniCPM Family</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMs/2405.04434_DeepSeek-V2.html">2405.04434_DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMs/2406.12793_ChatGLM.html">2406.12793_ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMs/2407.10671_Qwen2.html">2407.10671_Qwen2 Technical Report</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2407.10671_Qwen2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2407.10671_Qwen2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2407.10671_Qwen2.html#tokenizer-model">2. Tokenizer &amp; Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2407.10671_Qwen2.html#pre-training">3. Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2407.10671_Qwen2.html#post-training">4. Post-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2407.10671_Qwen2.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2407.10671_Qwen2.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMs/2412.15115_Qwen2.5.html">2412.15115_Qwen2.5</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2412.15115_Qwen2.5.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2412.15115_Qwen2.5.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2412.15115_Qwen2.5.html#architecture-and-tokenizer">2. Architecture and Tokenizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2412.15115_Qwen2.5.html#pre-training">3. Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2412.15115_Qwen2.5.html#post-training">4. Post-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2412.15115_Qwen2.5.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2412.15115_Qwen2.5.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMs/2505.09388_Qwen3.html">2505.09388_Qwen3</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2505.09388_Qwen3.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2505.09388_Qwen3.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2505.09388_Qwen3.html#architecture">2. Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2505.09388_Qwen3.html#pre-training">3. Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2505.09388_Qwen3.html#post-training">4. Post-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMs/2505.09388_Qwen3.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../paper.html#llm-moe">LLM MoE</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMMoEs/2410.07490_MoDEM.html">2410.07490_MoDEM: Mixture of Domain Expert Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMMoEs/2408.15664_AUXILIARY-LOSS-FREE_LB.html">2408.15664_AUXILIARY-LOSS-FREE LOAD BALANCING STRATEGY FOR MIXTURE-OF-EXPERTS</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../paper.html#llm">LLM 多模态</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMMultimodals/2304.08485_LLaVA.html">2304.08485_LLaVA: Visual Instruction Tuning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2304.08485_LLaVA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2304.08485_LLaVA.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2304.08485_LLaVA.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2304.08485_LLaVA.html#gpt-assisted-visual-instruction-data-generation">3. GPT-assisted Visual Instruction Data Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2304.08485_LLaVA.html#visual-instruction-tuning">4. Visual Instruction Tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2304.08485_LLaVA.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2304.08485_LLaVA.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMMultimodals/2308.12966_Qwen-VL.html">2308.12966_Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2308.12966_Qwen-VL.html#methodology">Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2308.12966_Qwen-VL.html#training">Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2308.12966_Qwen-VL.html#evaluation">Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2308.12966_Qwen-VL.html#b-data-format-details-of-training">B. Data Format Details of Training</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMMultimodals/2310.03744_LLaVA2.html">2310.03744_LLaVA2: Improved Baselines with Visual Instruction Tuning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2310.03744_LLaVA2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2310.03744_LLaVA2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2310.03744_LLaVA2.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2310.03744_LLaVA2.html#approach">3. Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2310.03744_LLaVA2.html#empirical-evaluation">4. Empirical Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2310.03744_LLaVA2.html#open-problems-in-lmms">5. Open Problems in LMMs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2310.03744_LLaVA2.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2310.03744_LLaVA2.html#a-implementation-details">A. Implementation Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2310.03744_LLaVA2.html#b-qualitative-results">B. Qualitative Results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMMultimodals/2312.07533_VILA.html">2312.07533_VILA: On Pre-training for Visual Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2312.07533_VILA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2312.07533_VILA.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2312.07533_VILA.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2312.07533_VILA.html#on-pre-training-for-visual-language-models">3. On Pre-training for Visual Language Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2312.07533_VILA.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2312.07533_VILA.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2312.07533_VILA.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMMultimodals/2403.05525_DeepSeek-VL.html">2403.05525_DeepSeek-VL: Towards Real-World Vision-Language Understanding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2403.05525_DeepSeek-VL.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMMultimodals/2408.01800_MiniCPM-V.html">2408.01800_MiniCPM-V: A GPT-4V Level MLLM on Your Phone</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2408.01800_MiniCPM-V.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2408.01800_MiniCPM-V.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2408.01800_MiniCPM-V.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2408.01800_MiniCPM-V.html#model-architecture">3. Model Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2408.01800_MiniCPM-V.html#training">4. Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2408.01800_MiniCPM-V.html#end-side-deployment">5. End-side Deployment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2408.01800_MiniCPM-V.html#experiments">6. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2408.01800_MiniCPM-V.html#conclusion">7. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMMultimodals/2409.17146_Molmo_and_PixMo.html">2409.17146_Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Vision-Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#architecture">2. Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#data">3. Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#training">4. Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#ablations">6. Ablations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-a-model-details">Appendix A: Model Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-b-training-details">Appendix B: Training Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-c-evaluation-results">Appendix C: Evaluation Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-d-result-details">Appendix D: Result Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-e-ablations-details">Appendix E Ablations Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-f-data-details">Appendix F Data Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-g-dataset-examples">Appendix G Dataset Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2409.17146_Molmo_and_PixMo.html#appendix-h-related-work">Appendix H Related Work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMMultimodals/2411.00774_Freeze-Omni.html">2411.00774_Freeze-Omni: A Smart and Low Latency Speech-to-speech Dialogue Model with Frozen LLM</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2411.00774_Freeze-Omni.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2411.00774_Freeze-Omni.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2411.00774_Freeze-Omni.html#model">2. Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2411.00774_Freeze-Omni.html#experience">3. Experience</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2411.00774_Freeze-Omni.html#conclusion-and-future-work">4. Conclusion and Future Work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMMultimodals/2412.04468_NVILA.html">2412.04468_NVILA: Efficient Frontier Visual Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2412.04468_NVILA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2412.04468_NVILA.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2412.04468_NVILA.html#approach">2. Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2412.04468_NVILA.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2412.04468_NVILA.html#more-capabilities">4. More Capabilities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2412.04468_NVILA.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2412.04468_NVILA.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMMultimodals/2502.13923_Qwen2.5-VL.html">2502.13923_Qwen2.5-VL</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2502.13923_Qwen2.5-VL.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2502.13923_Qwen2.5-VL.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2502.13923_Qwen2.5-VL.html#approach">2. Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2502.13923_Qwen2.5-VL.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2502.13923_Qwen2.5-VL.html#conclusion">4. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMMultimodals/2503.20215_Qwen2.5-Omni.html">2503.20215_Qwen2.5-Omni Technical Report</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#archtecture">2. Archtecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#id2">3 预训练</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#post-training">4 后训练（Post-training）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2503.20215_Qwen2.5-Omni.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMMultimodals/2506.13642_Stream-Omni.html">2506.13642_Stream-Omni: Simultaneous Multimodal Interactions with Large Language-Vision-Speech Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2506.13642_Stream-Omni.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2506.13642_Stream-Omni.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2506.13642_Stream-Omni.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2506.13642_Stream-Omni.html#id4">3. Stream-Omni</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2506.13642_Stream-Omni.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2506.13642_Stream-Omni.html#results-and-analyses">5. Results and Analyses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2506.13642_Stream-Omni.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2506.13642_Stream-Omni.html#appendix-a-construction-of-instructomni">Appendix A Construction of InstructOmni</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMMultimodals/2506.13642_Stream-Omni.html#appendix-b-construction-of-spokenvisit">Appendix B Construction of SpokenVisIT</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../paper.html#id6">LLM 音频</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMAudio/2005.08100_Conformer.html">2005.08100_Conformer: Convolution-augmented Transformer for Speech Recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMAudio/2112.02418_YourTTS.html">2112.02418_YourTTS: Towards Zero-Shot Multi-Speaker TTS and Zero-Shot Voice Conversion for everyone</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2112.02418_YourTTS.html#id1">关键概念</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2112.02418_YourTTS.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2112.02418_YourTTS.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2112.02418_YourTTS.html#yourtts-model">2. YourTTS Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2112.02418_YourTTS.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2112.02418_YourTTS.html#results-and-discussion">4. Results and Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2112.02418_YourTTS.html#zero-shot-voice-conversion">5. Zero-Shot Voice Conversion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2112.02418_YourTTS.html#speaker-adaptation">6. Speaker Adaptation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2112.02418_YourTTS.html#conclusions-limitations-and-future-work">7. Conclusions, limitations and future work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMAudio/2212.04356_whisper.html">2212.04356_whisper: Robust Speech Recognition via Large-Scale Weak Supervision</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2212.04356_whisper.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2212.04356_whisper.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2212.04356_whisper.html#approach">2. Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2212.04356_whisper.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2212.04356_whisper.html#analysis-and-ablations">4. Analysis and Ablations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2212.04356_whisper.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2212.04356_whisper.html#limitations-and-future-work">6. Limitations and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2212.04356_whisper.html#conclusions">7. Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2212.04356_whisper.html#a-evaluation-datasets">A. Evaluation Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2212.04356_whisper.html#b-compared-models">B Compared Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2212.04356_whisper.html#c-text-standardization">C. Text Standardization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMAudio/2301.02111_Vall-E.html">2301.02111_Vall-E: Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2301.02111_Vall-E.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2301.02111_Vall-E.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2301.02111_Vall-E.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2301.02111_Vall-E.html#background-speech-quantization">3. Background: Speech Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2301.02111_Vall-E.html#id9">4. VALL-E</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2301.02111_Vall-E.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2301.02111_Vall-E.html#conclusion-limitations-and-future-work">6. Conclusion, Limitations, and Future Work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMAudio/2303.03926_VALL-E_X.html">2303.03926_VALL-E_X: Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural Codec Language Modeling</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2303.03926_VALL-E_X.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2303.03926_VALL-E_X.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2303.03926_VALL-E_X.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2303.03926_VALL-E_X.html#cross-lingual-codec-language-model">3 Cross-Lingual Codec Language Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2303.03926_VALL-E_X.html#vall-e-x-application">4. VALL-E X Application</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2303.03926_VALL-E_X.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2303.03926_VALL-E_X.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2303.03926_VALL-E_X.html#a-appendix">A. Appendix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMAudio/2406.05370_VALL-E2.html">2406.05370_VALL-E2: Neural Codec Language Models are Human Parity Zero-Shot Text to Speech Synthesizers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2406.05370_VALL-E2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2406.05370_VALL-E2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2406.05370_VALL-E2.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2406.05370_VALL-E2.html#id5">3. VALL-E 2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2406.05370_VALL-E2.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2406.05370_VALL-E2.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMAudio/2407.05407_CosyVoice.html">2407.05407_CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2407.05407_CosyVoice.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2407.05407_CosyVoice.html#instructions">1. Instructions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2407.05407_CosyVoice.html#cosyvoice-a-scalable-tts-model-using-supervised-semantic-tokens">2. CosyVoice: A Scalable TTS model using Supervised Semantic Tokens</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2407.05407_CosyVoice.html#dataset">3. Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2407.05407_CosyVoice.html#experimental-settings">4. Experimental Settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2407.05407_CosyVoice.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMAudio/2407.10759_Qwen2-Audio.html">2407.10759_Qwen2-Audio Technical Report</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2407.10759_Qwen2-Audio.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2407.10759_Qwen2-Audio.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2407.10759_Qwen2-Audio.html#methodology">2. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2407.10759_Qwen2-Audio.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2407.10759_Qwen2-Audio.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMAudio/2410.00037_Moshi.html">2410.00037_Moshi: a speech-text foundation model for real-time dialogue</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2410.00037_Moshi.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2410.00037_Moshi.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2410.00037_Moshi.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2410.00037_Moshi.html#model">3.Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2410.00037_Moshi.html#datasets-and-training">4. Datasets and Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2410.00037_Moshi.html#evaluation">5. Evaluation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMAudio/2412.10117_CosyVoice2.html">2412.10117_CosyVoice2: Scalable Streaming Speech Synthesis with Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2412.10117_CosyVoice2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2412.10117_CosyVoice2.html#instroduction">1. Instroduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2412.10117_CosyVoice2.html#id5">2. CosyVoice 2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2412.10117_CosyVoice2.html#experimental-settings">3. Experimental Settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2412.10117_CosyVoice2.html#experimental-results">4. Experimental Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2412.10117_CosyVoice2.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMAudio/2501.06282_MinMo.html">2501.06282_MinMo: A Multimodal Large Language Model for Seamless Voice Interaction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2501.06282_MinMo.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2501.06282_MinMo.html#instruction">1.Instruction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2501.06282_MinMo.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2501.06282_MinMo.html#id9">3.MinMo</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2501.06282_MinMo.html#experiments">4.Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2501.06282_MinMo.html#conclusion">5.Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2501.06282_MinMo.html#limitations">6.Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2501.06282_MinMo.html#a-prompts-for-voice-understanding-tasks">A. Prompts for Voice Understanding Tasks</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMAudio/2505.02707_Voila.html">2505.02707_Voila: Voice-Language Foundation Models for Real-Time Autonomous Interaction and Voice Role-Play</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2505.02707_Voila.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2505.02707_Voila.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2505.02707_Voila.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2505.02707_Voila.html#voila-voice-language-foundation-models">3. Voila: Voice-Language Foundation Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2505.02707_Voila.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2505.02707_Voila.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMAudio/2505.17589_CosyVoice3.html">2505.17589_CosyVoice3: Towards In-the-wild Speech Generation via Scaling-up and Post-training</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2505.17589_CosyVoice3.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2505.17589_CosyVoice3.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2505.17589_CosyVoice3.html#id3">2.CosyVoice 3</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2505.17589_CosyVoice3.html#the-multilingual-data-pipeline">3.The Multilingual Data Pipeline</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2505.17589_CosyVoice3.html#experimental-settings">4.Experimental Settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2505.17589_CosyVoice3.html#experimental-results">5.Experimental Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2505.17589_CosyVoice3.html#conclusion">6.Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMAudio/2505.17589_CosyVoice3.html#limitations">7.Limitations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../paper.html#id7">LLM强化学习</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMRLs/1703.03864_EvolutionStrategies.html">1703.03864_Evolution Strategies: as a Scalable Alternative to Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMRLs/2504.02495_DeepSeek_GRM.html">2504.02495_DeepSeek-GRM: Inference-Time Scaling for Generalist Reward Modeling</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMRLs/2504.02495_DeepSeek_GRM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMRLs/2504.02495_DeepSeek_GRM.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMRLs/2504.02495_DeepSeek_GRM.html#preliminaries">2. Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMRLs/2504.02495_DeepSeek_GRM.html#self-principled-critique-tuning-spct">3. Self-Principled Critique Tuning (SPCT)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMRLs/2504.02495_DeepSeek_GRM.html#inference-time-scaling-with-spct">4. Inference-Time Scaling with SPCT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMRLs/2504.02495_DeepSeek_GRM.html#results-on-reward-modeling-benchmarks">5. Results on Reward Modeling Benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMRLs/2504.02495_DeepSeek_GRM.html#related-work">6. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMRLs/2504.02495_DeepSeek_GRM.html#conclusion-and-future-work">7. Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMRLs/2504.02495_DeepSeek_GRM.html#a-additional-related-work">A. Additional Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMRLs/2504.02495_DeepSeek_GRM.html#b-limitations-and-future-directions">B. Limitations and Future Directions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMRLs/2504.02495_DeepSeek_GRM.html#g-prompt-templates">G. Prompt Templates</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMRLs/2504.13958_ToolRL.html">2504.13958_ToolRL: Reward is All Tool Learning Needs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../paper.html#id8">LLM 量化</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMQuantizations/0normal.html">通用</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/0normal.html#id2">混合精度</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/0normal.html#id3">浮点数格式</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/0normal.html#weight-only-quantization">weight-only quantization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMQuantizations/2110.02861_bitsandbytes.html">2110.02861_bitsandbytes: 8-bit Optimizers via Block-wise Quantization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2110.02861_bitsandbytes.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2110.02861_bitsandbytes.html#background">1. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2110.02861_bitsandbytes.html#bit-optimizers">2. 8-bit Optimizers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2110.02861_bitsandbytes.html#bit-vs-32-bit-optimizer-performance-for-common-benchmarks">3. 8-bit vs 32-bit Optimizer Performance for common Benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2110.02861_bitsandbytes.html#analysis">4. Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2110.02861_bitsandbytes.html#related-work">5. Related Work</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMQuantizations/2206.01861_ZeroQuant.html">2206.01861_ZeroQuant: Efficient and Affordable Post-Training Quantization for Large-Scale Transformers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2206.01861_ZeroQuant.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2206.01861_ZeroQuant.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2206.01861_ZeroQuant.html#relative-work">2. Relative Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2206.01861_ZeroQuant.html#background-and-challenges">3. Background and Challenges</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2206.01861_ZeroQuant.html#methodology">4. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2206.01861_ZeroQuant.html#results">5. Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2206.01861_ZeroQuant.html#conclusions">6. Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2206.01861_ZeroQuant.html#appendix-a-background">Appendix A Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2206.01861_ZeroQuant.html#appendix-d-details-about-system-optimization">Appendix D Details about System Optimization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMQuantizations/2206.09557_LUT-GEMM.html">2206.09557_LUT-GEMM: Quantized Matrix Multiplication based on LUTs for Efficient Inference in Large-Scale Generative Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2206.09557_LUT-GEMM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2206.09557_LUT-GEMM.html#instructions">1. Instructions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2206.09557_LUT-GEMM.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2206.09557_LUT-GEMM.html#design-methodology-of-lut-gemm">3. Design Methodology of LUT-GEMM</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2206.09557_LUT-GEMM.html#experimental-results">4. Experimental results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2206.09557_LUT-GEMM.html#accelerating-quantized-opt-175b">5. Accelerating Quantized OPT-175B</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2206.09557_LUT-GEMM.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2206.09557_LUT-GEMM.html#appendix-a-llm-inference-latency-breakdown">Appendix A LLM Inference Latency Breakdown</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2206.09557_LUT-GEMM.html#appendix-b-detailed-implementation">Appendix B Detailed Implementation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMQuantizations/2208.07339_LLM.int8.html">2208.07339_LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2208.07339_LLM.int8.html#id1">相关参考</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2208.07339_LLM.int8.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2208.07339_LLM.int8.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2208.07339_LLM.int8.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2208.07339_LLM.int8.html#int8-matrix-multiplication-at-scale">3. Int8 Matrix Multiplication at Scale</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2208.07339_LLM.int8.html#emergent-large-magnitude-features-in-transformers-at-scale">4. Emergent Large Magnitude Features in Transformers at Scale</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2208.07339_LLM.int8.html#related-work">5. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2208.07339_LLM.int8.html#discussion-and-limitations">6. Discussion and Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2208.07339_LLM.int8.html#broader-impacts">7. Broader Impacts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2208.07339_LLM.int8.html#id17">其他</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMQuantizations/2209.05433_FP8.html">2209.05433_FP8: FP8 Formats For Deep Learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2209.05433_FP8.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2209.05433_FP8.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2209.05433_FP8.html#aspects-of-fp8-usage-in-deep-learning">2. Aspects of FP8 Usage in Deep Learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2209.05433_FP8.html#fp8-binary-interchange-format">3. FP8 Binary Interchange Format</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2209.05433_FP8.html#id3">示例讲解</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2209.05433_FP8.html#empirical-results">4. Empirical Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2209.05433_FP8.html#conclusions">5. Conclusions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMQuantizations/2210.17323_GPTQ.html">2210.17323_GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2210.17323_GPTQ.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2210.17323_GPTQ.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2210.17323_GPTQ.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2210.17323_GPTQ.html#background">3. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2210.17323_GPTQ.html#the-gptq-algorithm">4. The GPTQ Algorithm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2210.17323_GPTQ.html#experimental-validation">5. Experimental Validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2210.17323_GPTQ.html#summary-and-limitations">6. Summary and Limitations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMQuantizations/2211.10438_SmoothQuant.html">2211.10438_SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2211.10438_SmoothQuant.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2211.10438_SmoothQuant.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2211.10438_SmoothQuant.html#preliminaries">2. Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2211.10438_SmoothQuant.html#review-of-quantization-difficulty">3. Review of Quantization Difficulty</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2211.10438_SmoothQuant.html#id9">4. SmoothQuant</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2211.10438_SmoothQuant.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2211.10438_SmoothQuant.html#related-work">6. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2211.10438_SmoothQuant.html#conclusion">7. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2211.10438_SmoothQuant.html#appendix-a-discussion-on-weight-only-quantization">Appendix A. Discussion on Weight-Only Quantization</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMQuantizations/2305.14314_QLoRA.html">2305.14314_QLoRA: Efficient Finetuning of Quantized LLMs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2305.14314_QLoRA.html#id1">关键词</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2305.14314_QLoRA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2305.14314_QLoRA.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2305.14314_QLoRA.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2305.14314_QLoRA.html#qlora-finetuning">3. QLoRA Finetuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2305.14314_QLoRA.html#qlora-vs-standard-finetuning">4. QLoRA vs. Standard Finetuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2305.14314_QLoRA.html#pushing-the-chatbot-state-of-the-art-with-qlora">5. Pushing the Chatbot State-of-the-art with QLoRA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2305.14314_QLoRA.html#qualitative-analysis">6. Qualitative Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2305.14314_QLoRA.html#related-work">7. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2305.14314_QLoRA.html#limitations-and-discussion">8. Limitations and Discussion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMQuantizations/2306.00978_AWQ.html">2306.00978_AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2306.00978_AWQ.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2306.00978_AWQ.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2306.00978_AWQ.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2306.00978_AWQ.html#awq-activation-aware-weight-quantization">3. AWQ: Activation-aware Weight Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2306.00978_AWQ.html#tinychat-mapping-awq-onto-edge-platforms">4. TinyChat: Mapping AWQ onto Edge Platforms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2306.00978_AWQ.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2306.00978_AWQ.html#conclusion">6. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMQuantizations/2309.05516_AutoRound.html">2309.05516_AutoRound: Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2309.05516_AutoRound.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2309.05516_AutoRound.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2309.05516_AutoRound.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2309.05516_AutoRound.html#methodology">3. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2309.05516_AutoRound.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMQuantizations/2309.05516_AutoRound.html#conclusion">5. Conclusion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../paper.html#id9">LLM 闭源模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMCommercials/2303.08774_GPT4.html">2303.08774_GPT-4 Technical Report</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMCommercials/2312.11805_Gemini.html">2312.11805_Gemini: A Family of Highly Capable Multimodal Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMCommercials/2312.11805_Gemini.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMCommercials/2312.11805_Gemini.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMCommercials/2312.11805_Gemini.html#model-architecture">2. Model Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMCommercials/2312.11805_Gemini.html#training-infrastructure">3. Training Infrastructure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMCommercials/2312.11805_Gemini.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMCommercials/2312.11805_Gemini.html#post-training-models">6. Post-Training Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMCommercials/2312.11805_Gemini.html#responsible-deployment">7. Responsible Deployment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/LLMCommercials/2312.11805_Gemini.html#discussion-and-conclusion">8. Discussion and Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMCommercials/2403.05530_Gemini1.5.html">2403.05530_Gemini1.5: Unlocking multimodal understanding across millions of tokens of context</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMCommercials/2503.20020_Gemini2.html">2503.20020_Gemini2: Gemini Robotics: Bringing AI into the Physical World</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../paper.html#d">3D</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../papers/3D/2003.08934_NeRF.html">2003.08934_NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2003.08934_NeRF.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2003.08934_NeRF.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2003.08934_NeRF.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2003.08934_NeRF.html#neural-radiance-field-scene-representation">3. Neural Radiance Field Scene Representation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2003.08934_NeRF.html#volume-rendering-with-radiance-fields">4. Volume Rendering with Radiance Fields</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2003.08934_NeRF.html#optimizing-a-neural-radiance-field">5. Optimizing a Neural Radiance Field</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2003.08934_NeRF.html#result">6. Result</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2003.08934_NeRF.html#conclusion">7. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/3D/2203.08586_VanishingPointEstimation.html">2203.08586: Deep vanishing point detection: Geometric priors make dataset variations vanish</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2203.08586_VanishingPointEstimation.html#id1">概念</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2203.08586_VanishingPointEstimation.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2203.08586_VanishingPointEstimation.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2203.08586_VanishingPointEstimation.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2203.08586_VanishingPointEstimation.html#geometric-priors-for-vp-detection">3. Geometric priors for VP detection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2203.08586_VanishingPointEstimation.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2203.08586_VanishingPointEstimation.html#conclusion-and-limitations">5. Conclusion and limitations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/3D/2312.14132_DUSt3R.html">2312.14132_DUSt3R: Geometric 3D Vision Made Easy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2312.14132_DUSt3R.html#id1">关键词</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2312.14132_DUSt3R.html#id2">相关概念</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2312.14132_DUSt3R.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2312.14132_DUSt3R.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2312.14132_DUSt3R.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2312.14132_DUSt3R.html#method">3. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2312.14132_DUSt3R.html#experiments-with-dust3r">4. Experiments with DUSt3R</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2312.14132_DUSt3R.html#conclusion">5. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2312.14132_DUSt3R.html#appendix-a">Appendix A <strong>附录概览</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2312.14132_DUSt3R.html#appendix-b-qualitative-results">Appendix B.  Qualitative results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2312.14132_DUSt3R.html#appendix-c-extended-related-work">Appendix C. Extended Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2312.14132_DUSt3R.html#appendix-d-multi-view-pose-estimation">Appendix D. 多视角姿态估计（Multi-view Pose Estimation）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2312.14132_DUSt3R.html#appendix-e-visual-localization">Appendix E. 视觉定位（Visual Localization）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2312.14132_DUSt3R.html#appendix-f-training-details">Appendix F. Training details</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/3D/2406.09756_MASt3R.html">2406.09756_MASt3R: Grounding Image Matching in 3D with MASt3R</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2406.09756_MASt3R.html#id1">前言</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2406.09756_MASt3R.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2406.09756_MASt3R.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2406.09756_MASt3R.html#id2">🧠 思维导图式总结</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2406.09756_MASt3R.html#related-works">2. Related works</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2406.09756_MASt3R.html#id3">🧠 总结思维导图</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2406.09756_MASt3R.html#method">3. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2406.09756_MASt3R.html#experimental-results">4. Experimental results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2406.09756_MASt3R.html#conclusion">5. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2406.09756_MASt3R.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2406.09756_MASt3R.html#appendix-a-additional-qualitative-results">Appendix A Additional Qualitative Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2406.09756_MASt3R.html#b-fast-reciprocal-matching">B. Fast Reciprocal Matching</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2406.09756_MASt3R.html#c-coarse-to-fine">C. Coarse-to-Fine</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2406.09756_MASt3R.html#d-detailed-experimental-settings">D. Detailed experimental settings</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/3D/2412.09401_SLAM3R.html">2412.09401_SLAM3R: Real-Time Dense Scene Reconstruction from Monocular RGB Videos</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2412.09401_SLAM3R.html#id1">术语</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2412.09401_SLAM3R.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2412.09401_SLAM3R.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2412.09401_SLAM3R.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2412.09401_SLAM3R.html#method">3. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2412.09401_SLAM3R.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2412.09401_SLAM3R.html#conclusion">5. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2412.09401_SLAM3R.html#id14">6. 致谢</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2412.09401_SLAM3R.html#appendix">Appendix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2412.09401_SLAM3R.html#appendix-a-implementation-details">Appendix A Implementation details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2412.09401_SLAM3R.html#appendix-b-details-for-experimental-settings">Appendix B Details for experimental settings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2412.09401_SLAM3R.html#appendix-c-additional-comparisons-and-analyses">Appendix C Additional comparisons and analyses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2412.09401_SLAM3R.html#d-more-visual-results">D. More visual results</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/3D/2412.12392_MASt3R-SLAM.html">2412.12392_MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2412.12392_MASt3R-SLAM.html#gpt">GPT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2412.12392_MASt3R-SLAM.html#id1">先验知识</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2412.12392_MASt3R-SLAM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2412.12392_MASt3R-SLAM.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2412.12392_MASt3R-SLAM.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2412.12392_MASt3R-SLAM.html#method">3. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2412.12392_MASt3R-SLAM.html#results">4. Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2412.12392_MASt3R-SLAM.html#limitations-and-future-work">5. Limitations and Future Work（局限与未来工作）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2412.12392_MASt3R-SLAM.html#conclusion">🧾 6. Conclusion（总结）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2412.12392_MASt3R-SLAM.html#id32">🧠 总结一句话版：</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2412.12392_MASt3R-SLAM.html#initialisation">8. Initialisation（初始化）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2412.12392_MASt3R-SLAM.html#runtime-breakdown">9. Runtime Breakdown（运行时分析）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2412.12392_MASt3R-SLAM.html#evaluation-setup">10. Evaluation Setup（评估设置）</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2412.12392_MASt3R-SLAM.html#id35">11. EuRoC 结果总结</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/3D/2503.11651_VGGT.html">2503.11651_VGGT: Visual Geometry Grounded Transformer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2503.11651_VGGT.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2503.11651_VGGT.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2503.11651_VGGT.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2503.11651_VGGT.html#method">3. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2503.11651_VGGT.html#experiments">4. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2503.11651_VGGT.html#discussions">5. Discussions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2503.11651_VGGT.html#conclusions">6. Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2503.11651_VGGT.html#appendix-a-formal-definitions">Appendix A Formal Definitions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2503.11651_VGGT.html#appendix-b-implementation-details">Appendix B Implementation Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2503.11651_VGGT.html#appendix-c-additional-experiments">Appendix C Additional Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2503.11651_VGGT.html#appendix-d-qualitative-examples">Appendix D Qualitative Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/3D/2503.11651_VGGT.html#appendix-e-related-work">Appendix E Related Work</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../paper.html#id10">LLM 安全</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../papers/LLMSecuritys/2312.06674_Llama_Guard.html">2312.06674_Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../paper.html#benchmarking">Benchmarking</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Benchmarkings/0normal.html">通用</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/0normal.html#id2">评测标准</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/0normal.html#accuracy">准确率(Accuracy)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/0normal.html#precision">精确率(Precision, 精准率)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/0normal.html#recall">召回率(Recall)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/0normal.html#f1-score">F1 Score</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/0normal.html#id3">可视化精度和召回率</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Benchmarkings/2009.03300_MMLU.html">2009.03300_MMLU: Measuring Massive Multitask Language Understanding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2009.03300_MMLU.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2009.03300_MMLU.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2009.03300_MMLU.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2009.03300_MMLU.html#a-multitask-test">3.A Multitask Test</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2009.03300_MMLU.html#experiments">4.Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2009.03300_MMLU.html#discussion">5.Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2009.03300_MMLU.html#conclusion">6.Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Benchmarkings/2103.03874_MATH.html">2103.03874_MATH: Measuring Mathematical Problem Solving With the MATH Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Benchmarkings/2311.12022_GPQA.html">2311.12022_GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2311.12022_GPQA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2311.12022_GPQA.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2311.12022_GPQA.html#data-collection">2.Data Collection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2311.12022_GPQA.html#dataset-analysis">3.Dataset Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2311.12022_GPQA.html#baseline">4.Baseline</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2311.12022_GPQA.html#related-work">5.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2311.12022_GPQA.html#limitations">6.Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2311.12022_GPQA.html#conclusion">7.Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Benchmarkings/2311.12983_GAIA.html">2311.12983_GAIA: a benchmark for General AI Assistants</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2311.12983_GAIA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2311.12983_GAIA.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2311.12983_GAIA.html#related-work">2.Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2311.12983_GAIA.html#id3">3.GAIA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2311.12983_GAIA.html#llms-results-on-gaia">4.LLMs results on GAIA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2311.12983_GAIA.html#discussion">5.Discussion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2311.12983_GAIA.html#limitations">6.Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2311.12983_GAIA.html#appendix-a-extended-related-work">Appendix A Extended related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2311.12983_GAIA.html#appendix-c-extended-description-of-gaia">Appendix C Extended description of GAIA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2311.12983_GAIA.html#appendix-d-extended-description-of-our-question-design-framework">Appendix D Extended description of our question design framework</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Benchmarkings/2404.07972_OSWorld.html">2404.07972_OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2404.07972_OSWorld.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2404.07972_OSWorld.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2404.07972_OSWorld.html#osworld-environment">2. OSWORLD Environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2404.07972_OSWorld.html#osworld-benchmark">3. OSWORLD Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2404.07972_OSWorld.html#benchmarking-llm-and-vlm-agent-baselines">4. Benchmarking LLM and VLM Agent Baselines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2404.07972_OSWorld.html#analysis">5. Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2404.07972_OSWorld.html#related-work">6. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2404.07972_OSWorld.html#conclusion-and-future-work">7. Conclusion and Future Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2404.07972_OSWorld.html#a-details-of-osworld-environment">A. Details of OSWORLD Environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2404.07972_OSWorld.html#c-details-of-baseline-methods">C. Details of Baseline Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2404.07972_OSWorld.html#d-examples-of-qualitative-analysis">D. Examples of Qualitative Analysis</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Benchmarkings/2411.04368_SimpleQA.html">2411.04368_SimpleQA: Measuring short-form factuality in large language models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2411.04368_SimpleQA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2411.04368_SimpleQA.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2411.04368_SimpleQA.html#data-collection-and-verification">2.Data Collection and Verification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2411.04368_SimpleQA.html#measuring-calibration">4.Measuring calibration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2411.04368_SimpleQA.html#appendix-b-guessing-strategy-and-f-score">Appendix B Guessing strategy and F-score</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Benchmarkings/2501.14249_HLE.html">2501.14249_HLE: Humanity’s Last Exam</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2501.14249_HLE.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2501.14249_HLE.html#introduction">1.Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2501.14249_HLE.html#related-work">2.Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2501.14249_HLE.html#dataset">3.Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2501.14249_HLE.html#evaluation">4.Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Benchmarkings/2501.14249_HLE.html#discussion">5.Discussion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../paper.html#id11">数据集&amp;数据蒸馏</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../papers/DataSets/normal.html">通用</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/DataSets/normal.html#dataset-distillation">Dataset distillation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/DataSets/1811.10959v3_Dataset_Distillation.html">1811.10959v3_Dataset Distillation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/DataSets/1811.10959v3_Dataset_Distillation.html#abstract">ABSTRACT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/DataSets/1811.10959v3_Dataset_Distillation.html#llm">LLM总结</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/DataSets/1811.10959v3_Dataset_Distillation.html#introduction">1. INTRODUCTION</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/DataSets/1811.10959v3_Dataset_Distillation.html#approach">3. APPROACH</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/DataSets/2112.15093_CTR.html">2112.15093_CTR: Benchmarking Chinese Text Recognition: Datasets, Baselines, and an Empirical Study</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/DataSets/2112.15093_CTR.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/DataSets/2112.15093_CTR.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/DataSets/2112.15093_CTR.html#preliminaries">2. Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/DataSets/2112.15093_CTR.html#datasets">3. Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/DataSets/2112.15093_CTR.html#baselines">4. Baselines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/DataSets/2112.15093_CTR.html#an-empirical-study">5. An Empirical Study</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/DataSets/2112.15093_CTR.html#conclusions">6. Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/DataSets/2112.15093_CTR.html#appendix-a-details-of-prab">Appendix A Details of PRAB</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/DataSets/2112.15093_CTR.html#appendix-c-visualization-of-failure-cases">Appendix C Visualization of Failure Cases.</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/DataSets/2502.20653_Dataset_Distillation.html">2502.20653_Dataset Distillation with Neural Characteristic Function: A Minmax Perspective</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/DataSets/2502.20653_Dataset_Distillation.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/DataSets/2502.20653_Dataset_Distillation.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/DataSets/2502.20653_Dataset_Distillation.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/DataSets/2502.20653_Dataset_Distillation.html#conclusion">7. Conclusion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../paper.html#framework">Framework</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Frameworks/1712.05889_Ray.html">1712.05889_Ray: A Distributed Framework for Emerging AI Applications</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/1712.05889_Ray.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/1712.05889_Ray.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/1712.05889_Ray.html#motivation-and-requirements">2. Motivation and Requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/1712.05889_Ray.html#programming-and-computation-model">3. Programming and Computation Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/1712.05889_Ray.html#architecture">4. Architecture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/1712.05889_Ray.html#evaluation">5. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/1712.05889_Ray.html#related-work">6 Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/1712.05889_Ray.html#discussion-and-experiences">7 Discussion and Experiences</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/1712.05889_Ray.html#conclusion">8. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Frameworks/1910.02054_DeepSpeed_ZeRO.html">1910.02054_DeepSpeed_ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/1910.02054_DeepSpeed_ZeRO.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/1910.02054_DeepSpeed_ZeRO.html#extended-introduction">1. Extended Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/1910.02054_DeepSpeed_ZeRO.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/1910.02054_DeepSpeed_ZeRO.html#where-did-all-the-memory-go">3 Where Did All the Memory Go?</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/1910.02054_DeepSpeed_ZeRO.html#zero-insights-and-overview">4 ZeRO: Insights and Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/1910.02054_DeepSpeed_ZeRO.html#deep-dive-into-zero-dp">5 Deep Dive into ZeRO-DP</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/1910.02054_DeepSpeed_ZeRO.html#deep-dive-into-zero-r">6 Deep Dive into ZeRO-R</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/1910.02054_DeepSpeed_ZeRO.html#communication-analysis-of-zero-dp">7 Communication Analysis of ZeRO-DP</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/1910.02054_DeepSpeed_ZeRO.html#communication-analysis-of-zero-r">8. Communication Analysis of ZeRO-R</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/1910.02054_DeepSpeed_ZeRO.html#step-towards-1-trillion-parameters">9. Step Towards 1 Trillion Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/1910.02054_DeepSpeed_ZeRO.html#implementation-and-evaluation">10. Implementation and Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/1910.02054_DeepSpeed_ZeRO.html#concluding-remarks">11. Concluding Remarks</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Frameworks/19XX_PyTorch.html">PyTorch: An Imperative Style, High-Performance Deep Learning Library</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Frameworks/20XX_Transformers.html">Transformers: State-of-the-Art Natural Language Processing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Frameworks/2210.XX_Ray_v2.html">2210.XX_Ray v2 Architecture</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/2210.XX_Ray_v2.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/2210.XX_Ray_v2.html#architecture-overview">Architecture Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/2210.XX_Ray_v2.html#object-management">Object Management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/2210.XX_Ray_v2.html#task-management">Task Management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/2210.XX_Ray_v2.html#resource-management-and-scheduling">Resource Management and Scheduling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/2210.XX_Ray_v2.html#actor-management">Actor management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/2210.XX_Ray_v2.html#global-control-service">Global Control Service</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/2210.XX_Ray_v2.html#cluster-management">Cluster Management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/2210.XX_Ray_v2.html#appendix">Appendix</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Frameworks/2309.06180_vLLM.html">2309.06180_Efficient Memory Management for Large Language Model Serving with PagedAttention</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/2309.06180_vLLM.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/2309.06180_vLLM.html#background">2. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/2309.06180_vLLM.html#memory-challenges-in-llm-serving">3. Memory Challenges in LLM Serving</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/2309.06180_vLLM.html#method">4. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/2309.06180_vLLM.html#implementation">5. Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/2309.06180_vLLM.html#evaluation">6. Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/2309.06180_vLLM.html#ablation-studies">7. Ablation Studies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/Frameworks/2309.06180_vLLM.html#conclusion">10. Conclusion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../paper.html#ml">ML</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../papers/MLs/2112.09332_WebGPT.html">2112.09332_WebGPT: Browser-assisted question-answering with human feedback</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/MLs/2203.11147_GopherCite.html">2203.11147_GopherCite: Teaching language models to support answers with verified quotes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/MLs/2305.14251_FActScore.html">2305.14251_FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/MLs/2304.09848_Generative_Search.html">2304.09848_Generative_Search: Evaluating Verifiability in Generative Search Engines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/MLs/2307.02185_Citation.html">2307.02185_Citation: A Key to Building Responsible and Accountable Large Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/MLs/2307.16883_HAGRID.html">2307.16883_HAGRID: A Human-LLM Collaborative Dataset for Generative Information-Seeking with Attribution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/MLs/2305.14627_ALCE.html">2305.14627_ALCE: Enabling Large Language Models to Generate Text with Citations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLs/2305.14627_ALCE.html#nli">NLI 在引用质量评估中的应用</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLs/2305.14627_ALCE.html#prompt">论文中用的prompt</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../paper.html#id12">ML 多模态相关</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../papers/MLMultimodals/2108.03353_Screen2Words.html">2108.03353_ Screen2Words: Automatic Mobile UI Summarization with Multimodal Learning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2108.03353_Screen2Words.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2108.03353_Screen2Words.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2108.03353_Screen2Words.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2108.03353_Screen2Words.html#dataset-creation">3. Dataset Creation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2108.03353_Screen2Words.html#model-design">4. Model Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2108.03353_Screen2Words.html#id3">其它</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/MLMultimodals/2209.08199_ScreenQA.html">2209.08199_ScreenQA: Large-Scale Question-Answer Pairs over Mobile App Screenshots</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2209.08199_ScreenQA.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2209.08199_ScreenQA.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2209.08199_ScreenQA.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2209.08199_ScreenQA.html#problem-setting-tasks-and-metrics">3. Problem Setting: Tasks and Metrics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2209.08199_ScreenQA.html#data-annotation">4. Data Annotation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2209.08199_ScreenQA.html#dataset-analysis">5. Dataset Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2209.08199_ScreenQA.html#experiments-and-baselines">6. Experiments and Baselines</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2209.08199_ScreenQA.html#conclusion">7. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2209.08199_ScreenQA.html#limitations">8. Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2209.08199_ScreenQA.html#ethical-considerations">9. Ethical Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2209.08199_ScreenQA.html#a-data-annotation-details">A. Data Annotation Details</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2209.08199_ScreenQA.html#b-data-examples">B. Data Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/MLMultimodals/2212.06817_RT-1.html">2212.06817_RT-1: ROBOTICS TRANSFORMER FOR REAL-WORLD CONTROL AT SCALE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2212.06817_RT-1.html#abstract">ABSTRACT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2212.06817_RT-1.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2212.06817_RT-1.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2212.06817_RT-1.html#preliminaries">3. Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2212.06817_RT-1.html#system-overview">4. System Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2212.06817_RT-1.html#rt-1-robotics-transformer">5. RT-1: ROBOTICS TRANSFORMER</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2212.06817_RT-1.html#experiments">6. EXPERIMENTS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2212.06817_RT-1.html#conclusions-limitations-and-future-work">7. CONCLUSIONS, LIMITATIONS AND FUTURE WORK</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2212.06817_RT-1.html#b-model-card">B. MODEL CARD</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2212.06817_RT-1.html#c-model-and-data">C. MODEL AND DATA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2212.06817_RT-1.html#d-experiments">D. EXPERIMENTS</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/MLMultimodals/2401.10935_SeeClick.html">2401.10935_SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2401.10935_SeeClick.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2401.10935_SeeClick.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2401.10935_SeeClick.html#related-work">2. Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2401.10935_SeeClick.html#approach">3. Approach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2401.10935_SeeClick.html#screenspot-a-grounding-benchmark">4. ScreenSpot: A Grounding Benchmark</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2401.10935_SeeClick.html#experiments">5. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2401.10935_SeeClick.html#conclusion">6. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2401.10935_SeeClick.html#limitations">Limitations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2401.10935_SeeClick.html#ethical-considerations">Ethical considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2401.10935_SeeClick.html#a-details-of-seeclick-pre-training">A. Details of SeeClick Pre-training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2401.10935_SeeClick.html#b-screenspot-annotation-evaluation">B ScreenSpot Annotation &amp; Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2401.10935_SeeClick.html#c-downstream-agent-tasks">C. Downstream Agent Tasks</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/MLMultimodals/2402.04615_ScreenAI.html">2402.04615_ScreenAI: A Vision-Language Model for UI and Infographics Understanding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2402.04615_ScreenAI.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2402.04615_ScreenAI.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2402.04615_ScreenAI.html#methodology">2. Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2402.04615_ScreenAI.html#automatic-data-generation">3. Automatic data generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2402.04615_ScreenAI.html#data-mixtures">4. Data Mixtures</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2402.04615_ScreenAI.html#experiments-and-results">5. Experiments and Results</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2402.04615_ScreenAI.html#conclusions">6. Conclusions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2402.04615_ScreenAI.html#a-definitions-of-metrics">A Definitions of Metrics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2402.04615_ScreenAI.html#b-screen-schema-examples">B. Screen Schema Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2402.04615_ScreenAI.html#c-prompts-for-llm-generated-content">C. Prompts For LLM Generated Content</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2402.04615_ScreenAI.html#d-screen-navigation-generated-examples">D. Screen Navigation Generated Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2402.04615_ScreenAI.html#f-screenqa-short-answers-generation">F. ScreenQA Short Answers Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2402.04615_ScreenAI.html#g-complex-question-answering-datasets">G. Complex Question Answering Datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2402.04615_ScreenAI.html#h-new-benchmarks-repositories">H. New Benchmarks Repositories</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/MLMultimodals/2411.02059_TableGPT2.html">2411.02059_TableGPT2: A Large Multimodal Model with Tabular Data Integration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLMultimodals/2411.02059_TableGPT2.html#abstract">Abstract</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../paper.html#ml-vision">ML Vision</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../papers/MLVisions/1506.02640_YOLO.html">1506.02640_You Only Look Once: Unified, Real-Time Object Detection</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLVisions/1506.02640_YOLO.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/MLVisions/1612.08242_YOLO9000.html">1612.08242_YOLO9000: Better, Faster, Stronger</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLVisions/1612.08242_YOLO9000.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/MLVisions/1804.02767_YOLOv3.html">1804.02767_YOLOv3</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/MLVisions/2004.10934_YOLOv4.html">2004.10934_YOLOv4: Optimal Speed and Accuracy of Object Detection</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLVisions/2004.10934_YOLOv4.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/MLVisions/2205.00159_SVTR.html">2205.00159_SVTR: Scene Text Recognition with a Single Visual Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLVisions/2205.00159_SVTR.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLVisions/2205.00159_SVTR.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLVisions/2205.00159_SVTR.html#method">2. Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLVisions/2205.00159_SVTR.html#experiments">3. Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLVisions/2205.00159_SVTR.html#conclusion">4. Conclusion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/MLVisions/2207.02696_YOLOv7.html">2207.02696_YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLVisions/2207.02696_YOLOv7.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/MLVisions/2303.05499_GroundingDINO.html">Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/MLVisions/2304.08485_VisualInstructionTuning.html">2304.08485_Visual Instruction Tuning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/MLVisions/2402.13616_YOLOv9.html">2402.13616_YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLVisions/2402.13616_YOLOv9.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/MLVisions/2405.14458_YOLOv10.html">2405.14458_YOLOv10: Real-Time End-to-End Object Detection</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLVisions/2405.14458_YOLOv10.html#abstract">Abstract</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/MLVisions/2411.15858_SVTRv2.html">2411.15858_SVTRv2: CTC Beats Encoder-Decoder Models in Scene Text Recognition</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLVisions/2411.15858_SVTRv2.html#id1">定义</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLVisions/2411.15858_SVTRv2.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLVisions/2411.15858_SVTRv2.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLVisions/2411.15858_SVTRv2.html#related-work">2. Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLVisions/2411.15858_SVTRv2.html#methods">3. Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLVisions/2411.15858_SVTRv2.html#experiments">4 Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLVisions/2411.15858_SVTRv2.html#conclusion">5. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/MLVisions/2411.15858_SVTRv2.html#more-detail-of-real-world-datasets">8. More detail of real-world datasets</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../paper.html#rag">RAG</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../papers/RAGs/2005.11401_RAG_for_KI_NLP_task.html">2005.11401_Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/RAGs/2312.10997_RAG_for_LLM.html">2312.10997_Retrieval-Augmented Generation for Large Language Models: A Survey</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2312.10997_RAG_for_LLM.html#ii-overview-of-rag">II. Overview of RAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2312.10997_RAG_for_LLM.html#iii-retrieval">III. Retrieval</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2312.10997_RAG_for_LLM.html#iv-generation">IV. Generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2312.10997_RAG_for_LLM.html#v-augmentation-process-in-rag">V. Augmentation process in RAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2312.10997_RAG_for_LLM.html#vi-task-and-evaluation">VI. Task and Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2312.10997_RAG_for_LLM.html#vii-discussion-and-future-prospects">VII. Discussion and Future Prospects</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/RAGs/2401.15884_CRAG.html">2401.15884_CRAG: Corrective Retrieval Augmented Generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/RAGs/2403.14403_Adaptive-RAG.html">2403.14403_Adaptive-RAG</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/RAGs/2404.16130_GRAG.html">2404.16130_From Local to Global: A Graph RAG Approach to Query-Focused Summarization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2404.16130_GRAG.html#id2">简介</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2404.16130_GRAG.html#id3">相关的技术讨论</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/RAGs/2405.16506_GRAG.html">2405.16506_GRAG: Graph Retrieval-Augmented Generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/RAGs/graphrag.html">GraphRAG 官方文档</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/graphrag.html#indexing">Indexing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/graphrag.html#query">Query</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/RAGs/2406.13213_Multi-Meta-RAG.html">2406.13213_Multi-Meta-RAG: Improving RAG for Multi-Hop Queries using Database Filtering with LLM-Extracted Metadata</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/RAGs/2410.10450_KBLaM.html">2410.10450_KBLaM: Knowledge Base augmented Language Model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2410.10450_KBLaM.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2410.10450_KBLaM.html#introduction">1. Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2410.10450_KBLaM.html#related-work">2. Related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2410.10450_KBLaM.html#background">3. Background</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2410.10450_KBLaM.html#augmenting-llm-with-the-kb">4. Augmenting LLM with the KB</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2410.10450_KBLaM.html#kb-instruction-tuning">5. KB instruction tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2410.10450_KBLaM.html#experiments">6. EXPERIMENTS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2410.10450_KBLaM.html#conclusion">7. CONCLUSION</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2410.10450_KBLaM.html#limitations-and-future-work">8. LIMITATIONS AND FUTURE WORK</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2410.10450_KBLaM.html#appendix-a-extended-related-work">Appendix A Extended related work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2410.10450_KBLaM.html#appendix-b-ablation-study">Appendix B Ablation study</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2410.10450_KBLaM.html#appendix-c-sample-kb">Appendix C Sample KB</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2410.10450_KBLaM.html#sample-q-a">SAMPLE Q&amp;A</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2410.10450_KBLaM.html#prompt">PROMPT</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2410.10450_KBLaM.html#sample-output">SAMPLE OUTPUT</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/RAGs/2504.03137_LightPROF.html">2504.03137_LightPROF: A Lightweight Reasoning Framework for Large Language Model on Knowledge Graph</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2504.03137_LightPROF.html#abstract">Abstract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2504.03137_LightPROF.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2504.03137_LightPROF.html#related-work">Related Work</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2504.03137_LightPROF.html#preliminaries">Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2504.03137_LightPROF.html#methodology">Methodology</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2504.03137_LightPROF.html#experiments">Experiments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/RAGs/2504.03137_LightPROF.html#conclusion">Conclusion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../paper.html#tools">Tools</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Tools/2205.00445_MRKL.html">2205.00445_MRKL</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Tools/2302.04761_Toolformer.html">2302.04761_Toolformer: Language Models Can Teach Themselves to Use Tools</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/Tools/2303.17580_HuggingGPT.html">2303.17580_HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../paper.html#agi">AGI</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../papers/AGIs/1905.10985_AI-GA.html">1905.10985_AI-GA: AI-generating algorithms, an alternate paradigm for producing general artificial intelligence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/AGIs/2408.06292_AI-Scientist.html">2408.06292_The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../paper.html#others">others</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../papers/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html">A PAINLESS GUIDE TO CRC ERROR DETECTION ALGORITHMS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#the-basic-idea-behind-crc-algorithms">The Basic Idea Behind CRC Algorithms</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#polynomical-arithmetic">Polynomical Arithmetic</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#binary-arithmetic-with-no-carries">Binary Arithmetic with No Carries</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#id2">一个可用的实例</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#choosing-a-poly">Choosing A Poly</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#a-straightforward-crc-implementation">A Straightforward CRC Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#a-table-driven-implementation">A Table-Driven Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#a-slightly-mangled-table-driven-implementation">A Slightly Mangled Table-Driven Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/others/A%20PAINLESS%20GUIDE%20TO%20CRC%20ERROR%20DETECTION%20ALGORITHMS.html#id3">参考</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/others/Distributed%20Representations%20of%20Sentences%20and%20Documents.html">Distributed Representations of Sentences and Documents</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../papers/TODO.html">TODO</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../papers/TODO.html#id2">大模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../papers/TODO.html#id3">别人的收集</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../tmp.html">临时</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tmps/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95.html">学习记录</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../tmps/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95.html#id3">局域网内的服务发现会有什么方法</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../tmps/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95.html#mdns">mDNS协议</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../tmps/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95.html#id4">命令工具</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../tmps/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95.html#id5">组播&amp;广播</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../tmps/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95.html#ipv4">IPv4多播转发</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../tmps/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95.html#id6">多播功能</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../tmps/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95.html#id7">任播</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">新溪-gordon</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../geek.html">极客时间</a> &raquo;</li>
        
          <li><a href="../ai.html">AI 相关</a> &raquo;</li>
        
      <li>AI 绘画核心技术与实战</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/geeks/ais/AI 绘画核心技术与实战.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            <nav id="local-table-of-contents" role="navigation" aria-labelledby="local-table-of-contents-title">
              <h4 id="local-table-of-contents-title">On This Page</h4>
              <ul>
<li><a class="reference internal" href="#">AI 绘画核心技术与实战</a><ul>
<li><a class="reference internal" href="#id2">开篇词 (2讲)</a><ul>
<li><a class="reference internal" href="#id3">视频生成</a></li>
<li><a class="reference internal" href="#id4">定义</a></li>
</ul>
</li>
<li><a class="reference internal" href="#ai-4">热身篇:AI 绘画初体验 (4讲)</a><ul>
<li><a class="reference internal" href="#webui">01|WebUI</a></li>
<li><a class="reference internal" href="#prompt">02|Prompt使用技巧</a></li>
<li><a class="reference internal" href="#id5">03|进阶应用</a></li>
<li><a class="reference internal" href="#id6">04|实战项目1</a></li>
</ul>
</li>
<li><a class="reference internal" href="#ai-9">基础篇:AI 绘画原理揭秘 (9讲)</a><ul>
<li><a class="reference internal" href="#gan">05| 旧画师GAN</a></li>
<li><a class="reference internal" href="#id7">06 | 颠覆者扩散模型</a></li>
<li><a class="reference internal" href="#aigc-transformer">07|AIGC的核心魔法:搞懂Transformer</a><ul>
<li><a class="reference internal" href="#transformer">Transformer 的整体方案</a></li>
<li><a class="reference internal" href="#id8">4 个关键的概念</a></li>
<li><a class="reference internal" href="#self-attention">Self-Attention 模块</a></li>
<li><a class="reference internal" href="#encoder-decoder-attention">Encoder-Decoder Attention 模块</a></li>
<li><a class="reference internal" href="#id9">多头注意力机制的设计和优势</a></li>
<li><a class="reference internal" href="#transformer-vs-lstm">Transformer vs LSTM</a></li>
</ul>
</li>
<li><a class="reference internal" href="#unet">08|巧用神经网络:如何用UNet预测噪声</a><ul>
<li><a class="reference internal" href="#id10">基本结构</a></li>
<li><a class="reference internal" href="#id11">损失函数</a></li>
<li><a class="reference internal" href="#id12">UNet 的应用</a></li>
<li><a class="reference internal" href="#id13">与扩散模型结合</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id14">09|采样器</a><ul>
<li><a class="reference internal" href="#id15">三个老派采样器</a></li>
<li><a class="reference internal" href="#ancestral-samplers">祖先采样器(ancestral samplers)</a></li>
<li><a class="reference internal" href="#karras">采用Karras 文章中推荐的噪声策略</a></li>
<li><a class="reference internal" href="#id16">过时采集器</a></li>
<li><a class="reference internal" href="#dpm">DPM</a></li>
<li><a class="reference internal" href="#id17">使用效果</a></li>
</ul>
</li>
<li><a class="reference internal" href="#clip">10|CLIP</a><ul>
<li><a class="reference internal" href="#id18">CLIP 的提出背景</a></li>
<li><a class="reference internal" href="#id19">CLIP 解决方案</a><ul>
<li><a class="reference internal" href="#id20">数据来源</a></li>
<li><a class="reference internal" href="#id21">监督信号</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id22">CLIP 进阶探索</a><ul>
<li><a class="reference internal" href="#id23">CLIP 应用</a></li>
<li><a class="reference internal" href="#id24">CLIP 增强版</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id26">如何使用 CLIP</a></li>
<li><a class="reference internal" href="#id27">小结</a></li>
</ul>
</li>
<li><a class="reference internal" href="#vae">11|VAE系列</a><ul>
<li><a class="reference internal" href="#id28">VAE简介</a></li>
<li><a class="reference internal" href="#id29">VAE 细节探究</a><ul>
<li><a class="reference internal" href="#ae">AE 的长处和短板</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id30">VAE 的工作原理</a><ul>
<li><a class="reference internal" href="#id31">用 VAE 做图像插值</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id32">VAE 的应用</a><ul>
<li><a class="reference internal" href="#id33">VAE 与经典任务</a></li>
<li><a class="reference internal" href="#id34">VAE 与扩散模型</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id35">总结</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id36">12|实战项目2: 动手训练一个你自己的扩散模型</a><ul>
<li><a class="reference internal" href="#id37">关键知识串联</a></li>
<li><a class="reference internal" href="#id38">训练扩散模型</a></li>
<li><a class="reference internal" href="#diffusers">进阶到 diffusers 训练</a></li>
<li><a class="reference internal" href="#stable-diffusion">微调 Stable Diffusion</a></li>
<li><a class="reference internal" href="#sd">如何调用各种 SD 模型</a></li>
<li><a class="reference internal" href="#id39">总结</a></li>
<li><a class="reference internal" href="#id40">评论</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#dall-e-2-stable-diffusion-5">进阶篇:从 DALL-E 2 到 Stable Diffusion (5讲)</a><ul>
<li><a class="reference internal" href="#dall-e-2">13|前浪DALL-E 2</a><ul>
<li><a class="reference internal" href="#id41">初识 DALL-E 2</a></li>
<li><a class="reference internal" href="#id42">工作原理</a><ul>
<li><a class="reference internal" href="#id43">扩散先验模型该如何训练</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id44">图像变体</a></li>
<li><a class="reference internal" href="#id45">局限性</a></li>
</ul>
</li>
<li><a class="reference internal" href="#imagen">14|挑战者Imagen</a><ul>
<li><a class="reference internal" href="#id46">初识 Imagen</a></li>
<li><a class="reference internal" href="#id47">工作原理</a></li>
<li><a class="reference internal" href="#id48">从文本表征到图像</a></li>
<li><a class="reference internal" href="#id49">巧用动态阈值策略</a></li>
<li><a class="reference internal" href="#deepfloyd-if">DeepFloyd IF</a></li>
<li><a class="reference internal" href="#id50">评论</a></li>
</ul>
</li>
<li><a class="reference internal" href="#stable-diffusion1">15|显微镜下的Stable Diffusion1</a><ul>
<li><a class="reference internal" href="#id51">SD 模型的演化之路</a></li>
<li><a class="reference internal" href="#id52">SD 模型简单串联</a></li>
<li><a class="reference internal" href="#id53">文本引导原理探秘</a><ul>
<li><a class="reference internal" href="#id54">有分类器引导</a></li>
<li><a class="reference internal" href="#id55">无分类器引导</a></li>
<li><a class="reference internal" href="#cfg-classifier-free-guidance">CFG: Classifier Free Guidance</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id56">注意力机制是如何起作用的</a></li>
<li><a class="reference internal" href="#id57">重新探讨图生图</a></li>
<li><a class="reference internal" href="#negative-prompt-clip-skip">Negative Prompt 和 CLIP Skip</a></li>
<li><a class="reference internal" href="#id58">小结</a></li>
</ul>
</li>
<li><a class="reference internal" href="#stable-diffusion2">16|显微镜下的Stable Diffusion2</a><ul>
<li><a class="reference internal" href="#id59">SD 图像变体</a></li>
<li><a class="reference internal" href="#id60">SD 图像变体的使用</a></li>
<li><a class="reference internal" href="#sdxl">SDXL(神雕侠侣)</a><ul>
<li><a class="reference internal" href="#id61">初识 SDXL</a></li>
<li><a class="reference internal" href="#id62">SDXL 的使用</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#midjourney">17|巅峰画师Midjourney</a><ul>
<li><a class="reference internal" href="#id63">回顾 Midjourney 的发展</a></li>
<li><a class="reference internal" href="#id64">Midjourney 的长处与不足</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#ai-8">综合演练篇:AI 绘画高手养成计划 (8讲)</a><ul>
<li><a class="reference internal" href="#dreamboothlora-ipai">18|DreamBooth和LoRA:低成本实现IP专属的AI绘画模型</a><ul>
<li><a class="reference internal" href="#textual-inversion">Textual Inversion</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
  <table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference external" href="/index.html">主页</a></p></td>
<td><p><a class="reference internal" href="../../genindex.html"><span class="std std-ref">索引</span></a></p></td>
<td><p><a class="reference internal" href="../../py-modindex.html"><span class="std std-ref">模块索引</span></a></p></td>
<td><p><a class="reference internal" href="../../search.html"><span class="std std-ref">搜索页面</span></a></p></td>
</tr>
</tbody>
</table>
<section id="ai">
<h1>AI 绘画核心技术与实战<a class="headerlink" href="#ai" title="此标题的永久链接">¶</a></h1>
<ul class="simple">
<li><p>南柯  某头部大厂图像团队技术 leader，高级算法专家</p></li>
<li><p>目前在某头部大厂工作，带领团队推动多模态大模型领域的能力建设。长期活跃于 AI 绘画技术领域，对 AIGC 内容生成、数字人技术（AI 捏脸、数字人驱动）、传统图像、深度学习相关的图像技术（目标检测、分割、分类、人脸识别等），都有深入的理解和丰富的项目经验。有 100 余项算法创新专利，在视觉领域顶会发表过多篇论文。</p></li>
<li><p><a class="reference external" href="https://time.geekbang.org/column/intro/100555001">https://time.geekbang.org/column/intro/100555001</a></p></li>
<li><p>热身篇: 开启 AI 绘画旅程，带你熟悉各种 AI 绘画工具与模型，带你安装和部署 WebUI，体验 Midjourney 和 LoRA 的玩法，探索 AI 绘画的无限潜能。</p></li>
<li><p>基础篇: 深入剖析 AI 绘画背后的“黑魔法”，让你真正了解 AI 算法从业者需要掌握的理论技术基础，理解图像生成如何从 GAN 过渡到扩散模型的全过程，并掌握扩散模型各个模块的算法原理。这个模块的最后，还会带你自己动手训练一个扩散模型，为后续进阶学习做好准备。</p></li>
<li><p>进阶篇: 了解主流模型技术方案，包括 DALL-E 2、Imagen、Stable Diffusion、DeepFloyd、Midjourney 等业界最新最火的模型。掌握了这类技术的学习方法，未来你遇到新的 AI 绘画论文、代码、模型，也能举一反三。这部分还会带你训练一个扩散模型，为后续实战演练打牢基础。</p></li>
<li><p>综合演练篇: 结合前面所学，带你动手尝试各类 AI 绘画项目，包括训练 DreamBooth、LoRA 模型，使用 ControlNet 精细化控制内容的生成，做出类似于 LensaAI 这样的相册类效果，借助 Stable Diffusion 给你的照片渲染出各色风格等等。最后，还会分享 AI 视觉相关的前沿应用，帮你开阔视野。</p></li>
</ul>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/jxOopS.png" src="https://img.zhaoweiguo.com/uPic/2023/09/jxOopS.png" />
</figure>
<section id="id2">
<h2>开篇词 (2讲)<a class="headerlink" href="#id2" title="此标题的永久链接">¶</a></h2>
<figure class="align-default" id="id66">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/VVAIuB.png" src="https://img.zhaoweiguo.com/uPic/2023/09/VVAIuB.png" />
<figcaption>
<p><span class="caption-text">从 DALL-E 2 推出以来，AI 绘画领域一些有影响力的模型和算法</span><a class="headerlink" href="#id66" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<figure class="align-default" id="id67">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/EXppgt.png" src="https://img.zhaoweiguo.com/uPic/2023/09/EXppgt.png" />
<figcaption>
<p><span class="caption-text">思维导图</span><a class="headerlink" href="#id67" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<section id="id3">
<h3>视频生成<a class="headerlink" href="#id3" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p>Meta 提出的 Make-a-video 技术: <a class="reference external" href="https://makeavideo.studio/">https://makeavideo.studio/</a></p></li>
<li><p>runway 提出的 Gen-2 技术: <a class="reference external" href="https://research.runwayml.com/gen2">https://research.runwayml.com/gen2</a></p></li>
<li><p>英伟达的 Video LDM 技术: <a class="reference external" href="https://research.nvidia.com/labs/toronto-ai/VideoLDM/">https://research.nvidia.com/labs/toronto-ai/VideoLDM/</a></p></li>
</ul>
</section>
<section id="id4">
<h3>定义<a class="headerlink" href="#id4" title="此标题的永久链接">¶</a></h3>
<ul>
<li><p>Realistic Vision（现实视觉）:在计算机图形学和计算机视觉领域，”Realistic Vision”通常指的是产生逼真、仿真度高的图像或视频的技术。这包括使用光照模型、材质模型、阴影生成、纹理映射等技术来模拟真实世界中的光影效果、物体外观和场景。</p></li>
<li><p>Stable Diffusion（稳定扩散）:在物理学和化学领域，”Stable Diffusion”通常指的是扩散过程中的稳定性。扩散是指物质在空间中由高浓度区域向低浓度区域的自然传播。稳定扩散表示在扩散过程中，物质的浓度分布保持稳定，不会出现剧烈的波动或不稳定现象。</p></li>
<li><p>生成对抗网络（GANs）:由 Ian Goodfellow 和他的同事于2014年提出的。它由两个主要部分组成:生成器（Generator）和判别器（Discriminator）。这两个部分通过博弈的方式相互竞争，使得生成器能够生成逼真的数据样本。以下是 GANs 的关键概念和工作原理:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>生成器（Generator）:生成器是一个神经网络，它接受一个随机噪声向量作为输入，并尝试生成与训练数据相似的图像或数据样本。
        生成器的目标是欺骗判别器，使其无法区分生成的样本和真实数据。
判别器（Discriminator）:判别器也是一个神经网络，它的任务是评估给定的数据样本是真实数据还是生成器生成的假数据。
        判别器的目标是尽可能准确地区分真假样本。
对抗训练（Adversarial Training）:GANs 的训练过程涉及到生成器和判别器之间的对抗训练。
        生成器试图生成更逼真的数据来愚弄判别器，而判别器则努力提高其区分真伪的能力。
        这个过程持续进行，直到生成器生成的样本足够逼真为止。
</pre></div>
</div>
</li>
<li><p>变分自动编码器（VAEs）:一种生成模型，旨在通过学习潜在变量的分布来生成数据。它于2013年由 Kingma 和 Welling 提出。VAEs 的关键概念包括以下要点:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>编码器（Encoder）:编码器是一个神经网络，它将输入数据映射到潜在空间中的潜在变量（通常是高维度的向量）。
        这个潜在变量表示了输入数据的特征。
解码器（Decoder）:解码器是另一个神经网络，它接受潜在变量作为输入，并尝试从中生成与原始数据相似的数据样本。
变分推断（Variational Inference）:VAEs 使用变分推断来训练模型。
        这意味着模型试图学习数据的潜在分布，并通过最大化似然性来近似这个分布。
        同时，模型还受到正则化项的约束，以确保生成的潜在表示在潜在空间中均匀分布。
</pre></div>
</div>
</li>
</ul>
<p>常见的基础模型:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>生成对抗网络 (GANs):
        GANs 被广泛用于生成逼真的图像和艺术作品。通过训练生成器和判别器网络，GANs 能够生成高质量的图像，这些图像在视觉上难以与真实世界中的图像区分开。例如，DeepDream 和 DCGAN（Deep Convolutional GAN）都是使用 GANs 的变种来生成艺术作品。
风格迁移网络 (Style Transfer Networks):
        风格迁移网络允许将一个图像的艺术风格应用于另一个图像。这些模型可以将一幅图像的绘画风格（如梵高的星空、毕加索的立体主义等）应用于输入图像，从而创建出具有不同艺术风格的图像。
变分自动编码器 (VAEs):
        VAEs 可以用于生成具有潜在连续变化的图像。它们通过学习数据的潜在分布来生成图像，因此可以生成具有多样性和连续性的艺术作品。
循环神经网络 (RNNs) 和卷积神经网络 (CNNs):
        RNNs 和 CNNs 被用于生成手写字体、文本艺术、字符生成等任务。这些模型可以生成具有时间序列性质的图像，如手写字体的生成或基于文本描述的图像生成。
自动绘图算法:
        一些基于规则或算法的方法可以用于生成特定类型的艺术作品，例如分形艺术、自动绘制算法、以及根据数学公式生成的艺术作品。
图像转换网络 (Image-to-Image Translation Networks):
        这些网络用于将一种图像转换为另一种图像，例如将素描转换为彩色图像、将黑白照片转换为彩色照片等。
</pre></div>
</div>
</section>
</section>
<section id="ai-4">
<h2>热身篇:AI 绘画初体验 (4讲)<a class="headerlink" href="#ai-4" title="此标题的永久链接">¶</a></h2>
<section id="webui">
<h3>01|WebUI<a class="headerlink" href="#webui" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p>🌟Stable Diffusion AI绘画模型分享平台: <a class="reference external" href="https://civitai.com/">https://civitai.com/</a></p></li>
<li><p>Realistic Vision V5.1模型下载地址: <a class="reference external" href="https://civitai.com/models/4201?modelVersionId=6987">https://civitai.com/models/4201?modelVersionId=6987</a></p></li>
<li><p>人工智能和机器学习的博客网站: <a class="reference external" href="https://www.happyaccidents.ai/">https://www.happyaccidents.ai/</a></p></li>
<li><p>在线工具网站: <a class="reference external" href="https://www.happyaccidents.ai/tools">https://www.happyaccidents.ai/tools</a></p></li>
</ul>
<p>AI绘画功能:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">txt2img</span><span class="p">:</span><span class="n">文生图</span>
<span class="n">img2img</span><span class="p">:</span><span class="n">图生图</span>
<span class="n">Outpainting</span><span class="p">:</span><span class="n">延展图像</span>
<span class="n">Inpainting</span><span class="p">:</span><span class="n">局部重绘</span>
</pre></div>
</div>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/AUTOMATIC1111/stable-diffusion-webui">https://github.com/AUTOMATIC1111/stable-diffusion-webui</a></p></li>
</ul>
</section>
<section id="prompt">
<h3>02|Prompt使用技巧<a class="headerlink" href="#prompt" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p>ControlNet 模型。它能够更精确地控制生成的图像，让我们能够更好地实现自己的创作愿景。</p></li>
<li><p>LoRA 模型可以看作是原始模型的新特效，你可以这样理解:LoRA 相当于给原有模型穿上了“新服饰”一样，能让图像呈现出不同的表现。</p></li>
<li><p>在 prompt 中添加 () ，默认情况下会让对应的单词产生 1.1 倍的强度。双括号 (()) ，则表示 1.1 x 1.1 倍的加强。当然，我们也可以直接将数字写上去，例如 (dog:1.2) 。通常情况下，我不建议该权重超过 1.3，否则对画面的影响很大，甚至不能产生正常的图像。</p></li>
</ul>
<p>WebUI 咒语指南:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">1.</span> <span class="n">初阶咒语</span><span class="p">:</span><span class="n">直接描述</span>
<span class="mf">2.</span> <span class="n">二阶咒语</span><span class="p">:</span><span class="n">巧用标签</span>
<span class="mf">3.</span> <span class="n">三阶咒语</span><span class="p">:</span><span class="n">负面提示词</span>
<span class="mf">4.</span> <span class="n">四阶咒语</span><span class="p">:</span><span class="n">文本权重调整</span>
<span class="mf">5.</span> <span class="n">中型法阵</span><span class="p">:</span><span class="n">引入</span> <span class="n">LoRA</span>
</pre></div>
</div>
<ul class="simple">
<li><p>魔法法典: <a class="reference external" href="https://docs.qq.com/doc/DWHl3am5Zb05QbGVs">https://docs.qq.com/doc/DWHl3am5Zb05QbGVs</a></p></li>
</ul>
<p>重要参数:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>CFG Scale(Guidance Scale)，“提示词相关性”
</pre></div>
</div>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/k0fhfb.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/k0fhfb.jpg" />
</figure>
<ul class="simple">
<li><p>激活词网站: <a class="reference external" href="https://stablediffusion.fr/prompts">https://stablediffusion.fr/prompts</a></p></li>
<li><p>提示词入门: <a class="reference external" href="https://github.com/ivon852/stable-diffusion-webui-manuals/blob/main/content.zh-cn/prompts/general-prompt-guide.md">https://github.com/ivon852/stable-diffusion-webui-manuals/blob/main/content.zh-cn/prompts/general-prompt-guide.md</a></p></li>
</ul>
</section>
<section id="id5">
<h3>03|进阶应用<a class="headerlink" href="#id5" title="此标题的永久链接">¶</a></h3>
<p>图生图可以做哪些事情:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>1. 输入一张真实拍摄的照片，保持图像构图输出一张风格化的绘画结果
2. 输入一张低分辨率的照片，输出一张高分辨率的清晰照片
3. 输入一件衣服，输出一个模特穿着这件衣服
4. 输入一张局部涂抹的照片，输出一张 AI 算法补全后的照片
5. 输入一张图片，输出这种图片向外延展之后的效果等等
</pre></div>
</div>
</section>
<section id="id6">
<h3>04|实战项目1<a class="headerlink" href="#id6" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p>两个要点。</p></li>
<li><p>第一，选择不同功能的 LoRA 模型。根据创作需求，可以选择风格化的 LoRA 或人物化的 LoRA。风格化的 LoRA 可用于生成具有特定风格的图像，而人物化的 LoRA 则更适用于创建独特的人物形象。</p></li>
<li><p>第二，选择合适的 LoRA 权重。权重越高，生成的图像越接近 LoRA 模型的效果。但在 AI 绘画中，并不是权值越高越好。权重的选择需要根据设计师的意图和具体应用场景来权衡。</p></li>
</ul>
</section>
</section>
<section id="ai-9">
<h2>基础篇:AI 绘画原理揭秘 (9讲)<a class="headerlink" href="#ai-9" title="此标题的永久链接">¶</a></h2>
<section id="gan">
<h3>05| 旧画师GAN<a class="headerlink" href="#gan" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p>2022 年以前，GAN 才是业界公认的 AI 绘画技术首选。在老一辈的 AI 画图中，GAN（生成对抗网络）可以说是唯一的选择。在各种社交软件上见到过各种变小孩、变老、性别变换的视觉特效，这类效果通常就是靠 GAN 完成的。</p></li>
<li><p>2022 年 DALL-E 2、Stable Diffusion 的推出，扩散模型技术逐渐成为了 AI 绘画的主流技术。</p></li>
<li><p>2014 年说起。Ian Goodfellow 等人提出了生成对抗网络——也就是 GAN 这个全新的概念。GAN 模型由两个模块构成，也就是常说的生成器（Generator）和判别器（Discriminator）。可以这样类比，生成器是一位名画伪造家，目标是创作出逼真的艺术品，判别器是一位艺术鉴赏家，目标是从细节中找出伪造破绽。生成器与判别器在模型训练的过程中持续更新与对抗，最终达到平衡。它的精髓在于对抗训练思想。GAN 通过生成器和判别器的竞争和学习，使得生成的图像逐渐趋近于真实图像。在现实世界中，GAN 的应用场景广泛，包括图像合成、图像修复、图像风格转换等。</p></li>
<li><p>2015 年由 Radford 等人提出的深度卷积 GAN（DCGAN）给 GAN 带来了进化可能。主要创新就是引入卷积神经网络（CNN）结构，通过卷积层和反卷积层替代全连接层，使得生成器和判别器能够感知和利用图像的局部关系，更好地处理图像数据，从而生成更逼真的图像。</p></li>
<li><p>条件 GAN，简称 cGAN，允许我们在生成图像的过程中引入额外的条件信息。这样一来，我们可以控制生成图像的特征，比如生成特定类别的图像。</p></li>
<li><p>Wasserstein GAN，简称 wGAN，是另一个重要的改进，它通过使用 Wasserstein 距离（瓦瑟斯坦距离，也被称为地面距离）来衡量生成图像和真实图像之间的差异，这样就能提升训练的稳定性和生成图像的质量。</p></li>
<li><p>后来的 PGGAN、BigGAN、StyleGAN 等，将生成图像的分辨率提高了 1024x1024 分辨率之上。</p></li>
<li><p>Pix2Pix 系列工作延续了 cGAN 的思想，将 cGAN 的条件换成了与原图尺寸大小相同的图片，可以实现类似轮廓图转真实图片、黑白图转彩色图等效果(GAN 时代的 ControlNet)。Pix2Pix 最大的缺点就是训练需要大量目标图像与输入图像的图像对，优点是模型可以做到很轻很快，甚至能在很低端的手机上也能达到实时效果。从 18 年至今，我们在短视频平台上看到的各种实时变脸特效，比如年龄转换、性别编辑等特效，都是基于这个技术。</p></li>
<li><p>2017 年 Jun-Yan Zhu 等人提出了 CycleGAN，也就是循环一致性生成对抗网络(解决获取大师困难且耗时的成对的图数据)。CycleGAN 的核心要点就是让两个不同领域的图像可以互相转换。它有两个生成器，分别是 G（A→B）和 G（B→A），它们的任务是把 A 领域的图像变成 B 领域的，反之亦然。同时，还有两个判别器，D_A 和 D_B，负责分辨 A 和 B 领域里的真实图像和生成的图像。CycleGAN 的关键点在于循环一致性损失。这个方法把原图像转换到目标领域，然后再转换回原来的领域，就可以确保生成的图像跟原图像差别不大。CycleGAN 的优势是不需要成对的训练数据便可以实现图像转换，在很多图像转换任务上都表现得非常出色，比如风景、动物、风格等转换。</p></li>
<li><p>英伟达在 2018 年提出的生成对抗网络模型 StyleGAN，彻底改变了 GAN 在图像合成和风格迁移方面的应用前景。与传统的 GAN 模型相比，StyleGAN 在图像生成的质量、多样性和可控性方面取得了显著的突破。StyleGAN 的核心思想是用风格向量来控制生成图像的各种属性特点，并通过自适应实例归一化（AdaIN）把风格向量和生成器的特征图结合在一起。另外，用渐进式的生成器结构逐渐提高分辨率，这样可以提高训练的稳定性和生成图像的质量。</p></li>
<li><p>超分辨率生成对抗网络（SRGAN）的模型，它的目标是将低分辨率图像转换成高分辨率的图像。</p></li>
<li><p>有兴趣的话你可以了解下 BigGAN、StarGAN、Progressive GAN 等模型。</p></li>
<li><p>GAN 的局限性主要表现在训练不稳定性、生成图像模糊、难以评估和控制生成质量等问题。此外，在图像风格化、图像编辑等任务中，通常是每个任务一个 GAN。训练成本、数据需求量、使用场景局限性都是实际工作中的痛点。</p></li>
<li><p>2015 年就有人提出了图像扩散模型的概念。扩散模型在很大程度上解决了 GAN 的痛点。</p></li>
<li><p>2021 年之前 GAN 一直在图像生成领域处于制霸地位，直到 2021 年 10 月，一篇名为“扩散模型在图像生成领域击败了 GAN” 的文章横空出世，扩散模型在图像生成领域的潜力才广为人知。</p></li>
<li><p>2023 年 3 月，Adobe 的学者提出了 GigaGAN, 一个新的 GAN 架构。热衷于 GAN 的研究人员并没有放弃。</p></li>
<li><p>DragGAN 是一种交互式图像操作方法，为各种 GAN 开发提供了一种神奇的功能，我们用鼠标简单拉伸图像，就能够生成全新的图像。</p></li>
</ul>
</section>
<section id="id7">
<h3>06 | 颠覆者扩散模型<a class="headerlink" href="#id7" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p>扩散模型的灵感源自热力学。我们可以想象一下这样的过程，朝着一杯清水中滴入一滴有色碘伏，然后观察这杯水。</p></li>
<li><p>基于扩散模型实现 AI 绘画包括两个过程——加噪过程和去噪过程。即把一张图片加噪到纯噪声（即全是噪点的图片），还是把纯噪声做去噪处理，生成一张干净的图片</p></li>
<li><p>马尔可夫链: <a class="reference external" href="https://en.wikipedia.org/wiki/Markov_chain">https://en.wikipedia.org/wiki/Markov_chain</a></p></li>
</ul>
<figure class="align-default" id="id68">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/UU6lIl.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/UU6lIl.jpg" />
<figcaption>
<p><span class="caption-text">扩散模型和 GAN 的原理:GAN 是通过生成器、判别器对抗训练的方式来实现图像生成能力的，本质上是神经网络的左右互搏。而扩散模型，则是通过学习一个去除噪声的过程来实现图像生成的。</span><a class="headerlink" href="#id68" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>加噪过程的是通过参数化马尔可夫链将干净的图片逐步变为纯噪声；去噪的过程就是从噪声出发，逐步预测噪声并去除噪声。神经网络 UNet 被用于预测噪声，各式各样的采样器则用于去除噪声。</p></li>
</ul>
</section>
<section id="aigc-transformer">
<h3>07|AIGC的核心魔法:搞懂Transformer<a class="headerlink" href="#aigc-transformer" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p>Stable Diffusion 模型在原始的 UNet 模型中加入了 Transformer 结构，这么做可谓一举两得，因为 Transformer 结构不但能提升噪声去除效果，还是实现 prompt 控制图像内容的关键技术。</p></li>
<li><p>在深度学习中，有很多需要处理时序数据的任务，比如语音识别、文本理解、机器翻译、音乐生成等。不过，经典的卷积神经网络，也就是 CNN 结构，主要擅长处理空间相关的任务，比如图像分类、目标检测等。因此，RNN（循环神经网络）、LSTM（长短时记忆网络）以及 Transformers 这些解决时序任务的方案便应运而生。</p></li>
<li><p>RNN 的主要特点是在处理序列数据时，对前面的信息会产生某种“记忆”，通过这种记忆效果，RNN 可以捕捉序列中的时间依赖关系。这种“记忆”在 RNN 中被称为隐藏状态（hidden state）。</p></li>
</ul>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/47Tw8Q.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/47Tw8Q.jpg" />
</figure>
<ul class="simple">
<li><p>传统的 RNN 存在一个关键的问题，即“长时依赖问题”——当序列很长时，RNN 在处理过程中会出现梯度消失（梯度趋近于 0）或梯度爆炸（梯度趋近于无穷大）现象。这种情况下，RNN 可能无法有效地捕捉长距离的时间依赖信息。</p></li>
<li><p>为了解决这个问题， LSTM 这种特殊的 RNN 结构就派上用场了。LSTM 通过加入遗忘门、记忆门和输出门来处理长时依赖问题。这些门有助于 LSTM 更有效地保留和更新序列中的长距离信息。</p></li>
</ul>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/3Dbhi4.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/3Dbhi4.jpg" />
</figure>
<ul class="simple">
<li><p>以 LSTM 为代表的 RNN 类方案虽然在许多时序任务中取得了良好的效果，但是也有它的局限，主要是三个方面。</p></li>
<li><p>第一，并行计算问题。由于 LSTM 需要递归地处理序列数据，所以在计算过程中无法充分利用并行计算资源，处理长序列数据时效率较低。</p></li>
<li><p>第二，长时依赖问题。虽然 LSTM 有效地改善了传统 RNN 中的长时依赖问题，但在处理特别长的序列时，仍然可能出现依赖关系捕捉不足的问题。</p></li>
<li><p>第三，复杂性高。LSTM 相比简单的 RNN 结构更复杂，增加了网络参数和计算量，这在一定程度上影响了训练速度和模型性能。</p></li>
</ul>
<section id="transformer">
<h4>Transformer 的整体方案<a class="headerlink" href="#transformer" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>在 2017 年由 Google 提出的 Transformer，是一种基于自注意力机制（self-attention）的模型，它有效解决了 RNN 类方法的并行计算和长时依赖两大痛点。</p></li>
<li><p>Transformer 结构包括编码器（Encoder）和解码器（Decoder）两个部分，通过这两个部分完成对输入序列的表示学习和输出序列的生成。</p></li>
</ul>
<figure class="align-default" id="id69">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/AfoWCG.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/AfoWCG.jpg" />
<figcaption>
<p><span class="caption-text">编码器和解码器分别由 6 层相同的结构堆叠而成</span><a class="headerlink" href="#id69" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">编码器</span></code> 负责处理输入序列。它会根据全局上下文，提取输入数据中的有用信息，并学习输入序列的有效表示。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">解码器</span></code> 则会根据编码器输出的表示，生成目标输出序列。它会关注并利用输入序列的表示以及当前位置的上下文信息，生成输出序列中每个元素的预测。</p></li>
</ul>
<figure class="align-default" id="id70">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/CWsOUX.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/CWsOUX.jpg" />
<figcaption>
<p><span class="caption-text">编码器负责对输入序列进行抽象表示，解码器根据这些表示构建合适的输出序列。</span><a class="headerlink" href="#id70" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
</section>
<section id="id8">
<h4>4 个关键的概念<a class="headerlink" href="#id8" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>首先是源序列。源序列是输入的文本序列。例如在机器翻译任务中，源序列就是待翻译的文本。</p></li>
<li><p>其次是目标序列。目标序列是输出的文本序列，例如在机器翻译任务中，目标序列代表翻译后的文本，通常为目标语言。</p></li>
<li><p>之后是 Token（词符）。Token 是文本序列中的最小单位，可以是单词、字符等形式。文本可以拆分为一系列 tokens。</p></li>
<li><p>最后是词嵌入（Word Embedding）。词嵌入的目标是把每个 token 转换为固定长度的向量表示，这些向量可以根据 token ID 在预训练好的词嵌入库（例如 Word2Vec 等）中拿到。在 Transformer 中，编码器和解码器的输入的都是序列经过 token 化之后得到的词嵌入。</p></li>
</ul>
</section>
<section id="self-attention">
<h4>Self-Attention 模块<a class="headerlink" href="#self-attention" title="此标题的永久链接">¶</a></h4>
<p>各种不同类型的注意力机制:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>1. 自注意力 (Self-Attention)
2. 交叉注意力 (Cross Attention)
3. 单向注意力 (Unidirectional Attention)
4. 双向注意力 (Bidirectional Attention)
5. 因果注意力 (Causal Attention)
6. 多头注意力（Multi-Head Attention）
7. 编码器 - 解码器注意力（Encoder-Decoder Attention）
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>注意力模块通常作为一个子结构嵌入到更大的模型中，作用是提供全局上下文信息的感知能力。</p>
</div>
<figure class="align-default" id="id71">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/4pPxIr.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/4pPxIr.jpg" />
<figcaption>
<p><span class="caption-text">自注意力模块</span><a class="headerlink" href="#id71" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<figure class="align-default" id="id72">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/ozh4CA.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/ozh4CA.jpg" />
<figcaption>
<p><span class="caption-text">交叉注意力模块</span><a class="headerlink" href="#id72" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>最基础的自注意力模块，计算方法你可以看下面这张图。自注意力模块会计算输入序列中所有元素之间的相似性得分，再通过归一化处理得到注意力权重。这些权重可以视为输入元素与其他元素之间的联系强度。注意力模块通过对权重与输入元素做加权求和来生成输出，输出的向量维度与输入相同。</p>
</div>
<figure class="align-default" id="id73">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/OtZmgQ.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/OtZmgQ.jpg" />
<figcaption>
<p><span class="caption-text">首先通过三个可学习的权重矩阵 W_Q, W_K, W_V 分别将模块输入序列投影成 Q、K、V 三个向量。Q 代表 Query，K 代表 Key，V 代表 Value。然后通过计算 Q、K 之间的关系，获得注意力权重，最后将这些权重与 V 向量相结合，得到输出向量。(图片来源:<a class="reference external" href="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</a>)</span><a class="headerlink" href="#id73" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<p>整个计算过程伪代码:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># 从同一个输入序列产生Q、K和V向量。</span>
<span class="n">Q</span> <span class="o">=</span> <span class="n">X</span> <span class="o">*</span> <span class="n">W_Q</span>
<span class="n">K</span> <span class="o">=</span> <span class="n">X</span> <span class="o">*</span> <span class="n">W_K</span>
<span class="n">V</span> <span class="o">=</span> <span class="n">X</span> <span class="o">*</span> <span class="n">W_V</span>

<span class="c1"># 计算Q和K向量之间的点积，得到注意力分数。</span>
<span class="n">Scaled_Dot_Product</span> <span class="o">=</span> <span class="p">(</span><span class="n">Q</span> <span class="o">*</span> <span class="n">K</span><span class="o">^</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">d_k</span><span class="p">)</span>

<span class="c1"># 应用Softmax函数对注意力分数进行归一化处理，获得注意力权重。</span>
<span class="n">Attention_Weights</span> <span class="o">=</span> <span class="n">Softmax</span><span class="p">(</span><span class="n">Scaled_Dot_Product</span><span class="p">)</span>

<span class="c1"># 将注意力权重与V向量相乘，得到输出向量。</span>
<span class="n">Output</span> <span class="o">=</span> <span class="n">Attention_Weights</span> <span class="o">*</span> <span class="n">V</span>
</pre></div>
</div>
<ul class="simple">
<li><p>三个小细节</p></li>
<li><p>Q 和 K 的向量维度是相同的，比如都是 d_k，V 和 Q、K 的向量维度可以不同，称之为 d_v。</p></li>
<li><p>缩放因子 Scale 的计算方式是对 d_k 开根号之后的结果，在 Transformer 论文中，d_k 的取值为 64，因此 Scale 的取值为 8。</p></li>
<li><p>图中被标记为可选（Opt）的 Mask 模块的作用是屏蔽部分注意力权重，限制模型关注特定范围内的元素。你可别小看这个 Mask 模块，它便是自注意力升级为单向注意力、双向注意力、因果注意力的精髓所在！</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>自注意力和交叉注意力的区别你只需要记住一句话:自注意力的 Q、K、V 都源自同一个输入序列，而交叉注意力的 K、V 源自源序列，Q 源自目标序列，其余计算过程完全相同。对于 Transformer 这类编码器 - 解码器结构来说，源序列从编码器输出，目标序列从解码器输出。</p>
</div>
</section>
<section id="encoder-decoder-attention">
<h4>Encoder-Decoder Attention 模块<a class="headerlink" href="#encoder-decoder-attention" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>编码器 - 解码器注意力（Encoder-Decoder Attention）模块是解码器中的一个关键子模块，实际上它是一个交叉注意力模块</p></li>
</ul>
<figure class="align-default" id="id74">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/ZJBlGj.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/ZJBlGj.jpg" />
<figcaption>
<p><span class="caption-text">如图:这个模块的 Q、K、V 源自不同序列。编码器 - 解码器注意力模块的目标是统合源序列和目标序列之间的关系，以便生成更准确的输出序列。</span><a class="headerlink" href="#id74" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
</section>
<section id="id9">
<h4>多头注意力机制的设计和优势<a class="headerlink" href="#id9" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>多头注意力（Multi-head Attention）是 Transformer 的工作里首次提出和使用的，它强化了编码器解码器的能力，你可以把它看作注意力模块的升级版。</p></li>
</ul>
</section>
<section id="transformer-vs-lstm">
<h4>Transformer vs LSTM<a class="headerlink" href="#transformer-vs-lstm" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>尽管 Transformer 在很多任务中表现出优越性能，但它的训练通常需要大量的数据，对内存和计算资源的需求通常较高。另外，LSTM 和 Transformer 在特定任务上可能具有各自的优势，我们仍然需要根据具体问题和数据情况来选择最合适的模型。</p></li>
</ul>
</section>
</section>
<section id="unet">
<h3>08|巧用神经网络:如何用UNet预测噪声<a class="headerlink" href="#unet" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p>UNet 出现之前，图像分割采用的主要方法是 2015 年提出的 FCN（全卷积网络）。与传统的 CNN（卷积神经网络）不同，FCN 去掉了最后的全连接层，而是使用转置卷积层实现上采样的过程。通过这样的操作，FCN 可以获得与输入图像相同尺寸的输出。</p></li>
<li><p>FCN 为图像分割任务带来了显著的改进，但仍然有一定的局限性。比如，FCN 结构无法最大限度地利用不同层级的特征，这会导致分割结果中存在边缘细节丢失等问题。</p></li>
<li><p>同样出现在 2015 年的UNet是一种 U 型的全卷积神经网络，存在一个明显的编码、解码过程，并且编码器和解码器中间存在特征融合。UNet 一经提出，便成为处理图像分割任务的经典模型。</p></li>
</ul>
<figure class="align-default" id="id75">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/nqoPnw.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/nqoPnw.jpg" />
<figcaption>
<p><span class="caption-text">UNet 的 U 型结构:左侧是编码器，右侧是解码器。</span><a class="headerlink" href="#id75" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<section id="id10">
<h4>基本结构<a class="headerlink" href="#id10" title="此标题的永久链接">¶</a></h4>
<p>UNet 的基本结构:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">第一是它独特的</span> <span class="n">U</span> <span class="n">形结构</span>
<span class="n">第二是其基于编码器</span> <span class="o">-</span> <span class="n">解码器设计思想</span>
<span class="n">第三是编码器和解码器之间的跳跃连接</span>
</pre></div>
</div>
<ul class="simple">
<li><p>对于图像分割任务，编码器的输入是原始图像，解码器的输出是分割结果。</p></li>
<li><p>UNet 的编码器由连续的卷积层和池化层交替组成，每个卷积层用于提取更深层次的图像特征，通常在卷积之后使用非线性激活函数（如 ReLU）以引入非线性。随后，池化层（如最大池化）用于进行降采样，以减小每一层的空间尺寸。经过编码器阶段后，高分辨率的输入图像就转化成了具备较低空间尺寸的特征图。</p></li>
</ul>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/oED2ju.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/oED2ju.jpg" />
</figure>
<ul class="simple">
<li><p>UNet 的解码器与编码器相反，它通过连续的反卷积或转置卷积层进行上采样，逐步将低维特征图恢复到原始图像的分辨率。每个反卷积或转置卷积操作后，得到的特征同样会执行非线性激活函数，以增加模型的非线性。解码器的目的是利用编码器生成的深层特征，生成与输入图像空间维度相同的结果（可能需要插值后处理），以便进行像素级预测。</p></li>
</ul>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/nnG0uH.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/nnG0uH.jpg" />
</figure>
<ul class="simple">
<li><p>最后我们来看跳跃连接。编码器和解码器之间的特征融合是通过跳跃连接实现的。跳跃连接将编码器中相应层级的特征图与解码器中的特征图连接在一起，这样解码器才能捕捉更丰富的细节信息，进一步提高网络性能。</p></li>
</ul>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/pshVe3.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/pshVe3.jpg" />
</figure>
</section>
<section id="id11">
<h4>损失函数<a class="headerlink" href="#id11" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>对于图像分割任务，交叉熵损失函数（Cross Entropy Loss）是一种常用的损失函数。</p></li>
<li><p>交叉熵损失函数广泛用于分类任务，它能度量模型的预测概率分布与真实标签分布之间的差异。</p></li>
<li><p>对于图像分割任务，每个像素都需要进行分类，也就是判断这个像素属于哪一个类别。因此，我们需要对图像中每一个像素都计算交叉熵损失，用平均或者求和的方式将这些损失合并，得到最终的损失值。</p></li>
</ul>
<p>图像分类任务和图像分割任务中交叉熵损失函数的代码实现:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="k">def</span><span class="w"> </span><span class="nf">cross_entropy_classification</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    y_true: 真实标签。这是任务的真实答案，通常由人类标注或事先知道。</span>
<span class="sd">    对于分类任务（如猫狗分类），y_true可以是类别的索引或 one-hot 编码表示。</span>
<span class="sd">    y_pred: 预测标签。这是模型预测的结果。</span>
<span class="sd">    对于分类任务，y_pred是一个概率分布向量，表示每个类别的预测概率。</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="mf">1e-9</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="mf">1e-9</span><span class="p">)</span>  <span class="c1"># 数值稳定性处理，将预测值限制在[1e-9, 1-1e-9]范围内</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_true</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_pred</span><span class="p">))</span>

<span class="k">def</span><span class="w"> </span><span class="nf">cross_entropy_segmentation</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    y_true: 真实标签。这是任务的真实答案，通常由人类标注或事先知道。</span>
<span class="sd">    对于分割任务（如语义分割），y_true是一个二维或多维数组，</span>
<span class="sd">    表示每个像素对应的类别索引或 one-hot 编码表示。</span>
<span class="sd">    y_pred: 预测标签。这是模型预测的结果。</span>
<span class="sd">    对于分割任务，y_pred是一个三维数组，存储每个类别在每个像素位置的预测概率。</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="mf">1e-9</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="mf">1e-9</span><span class="p">)</span>  <span class="c1"># 数值稳定性处理，将预测值限制在[1e-9, 1-1e-9]范围内</span>
    <span class="n">num_classes</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="n">y_true</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_classes</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">height</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">width</span><span class="p">):</span>
                <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">y_true</span><span class="p">[</span><span class="n">c</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_pred</span><span class="p">[</span><span class="n">c</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">total_loss</span>

<span class="c1"># 示例代码（假设类别是经过 one-hot 编码的）</span>
<span class="n">y_true_class</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">y_pred_class</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">])</span>
<span class="n">y_true_segment</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
<span class="n">y_pred_segment</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>

<span class="c1"># 计算分类任务损失</span>
<span class="n">classification_loss</span> <span class="o">=</span> <span class="n">cross_entropy_classification</span><span class="p">(</span><span class="n">y_true_class</span><span class="p">,</span> <span class="n">y_pred_class</span><span class="p">)</span>
<span class="c1"># 计算分割任务损失</span>
<span class="n">segmentation_loss</span> <span class="o">=</span> <span class="n">cross_entropy_segmentation</span><span class="p">(</span><span class="n">y_true_segment</span><span class="p">,</span> <span class="n">y_pred_segment</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;分类任务损失:&quot;</span><span class="p">,</span> <span class="n">classification_loss</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;分割任务损失:&quot;</span><span class="p">,</span> <span class="n">segmentation_loss</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id12">
<h4>UNet 的应用<a class="headerlink" href="#id12" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>医学图像分割领域。UNet 可以用于细胞分割，识别生物显微镜下的细胞边界，用于计数、分型等任务。UNet 也可以用于器官分割，识别 MRI 或 CT 等影像中的目标结构，比如识别脑部病变、肝脏肿瘤或肺结节等。UNet 应用于血管分割，可以识别眼底图像中的血管结构，有助于眼科疾病的诊断。</p></li>
<li><p>自然图像分割。对于街景分割任务，可用于识别道路、行人、车辆等元素，辅助无人驾驶、智慧交通等领域。对于航拍图像分割，UNet 可以从高分辨率的航空图像中提取建筑、湖泊、森林等地物信息，帮助城市规划和资源调查。此外，UNet 还能用于人像分割，可以识别人像照片的背景，实现背景替换、虚化等目的。</p></li>
<li><p>用于 AI 绘画，具体的用法就是把 UNet 用于扩散模型的噪声预测</p></li>
</ul>
</section>
<section id="id13">
<h4>与扩散模型结合<a class="headerlink" href="#id13" title="此标题的永久链接">¶</a></h4>
<figure class="align-default" id="id76">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/Qs673S.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/Qs673S.jpg" />
<figcaption>
<p><span class="caption-text">交叉注意力机制（Cross Attention）:交叉注意力机制从源序列产生 K 和 V 向量，从目标序列产生 Q 向量。在 Stable Diffusion 中，我们将 Z_T 视为目标序列，得到 Q；将 prompt 描述经过 CLIP 模型得到的特征向量作为源序列，得到 K 和 V。</span><a class="headerlink" href="#id76" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="id14">
<h3>09|采样器<a class="headerlink" href="#id14" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p>采样器存在的价值就是从噪声出发，逐步去噪，得到一张清晰的图像。</p></li>
<li><p>UNet 负责预测噪声，采样器负责“减去”噪声。这个过程反复迭代，我们就能从噪声图 x_t 得到 x_t−1 ，然后得到 x_t−2 ，最终得到 x_0 ，也就是清晰可辨的图像。</p></li>
</ul>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/IwCRgQ.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/IwCRgQ.jpg" />
</figure>
<section id="id15">
<h4>三个老派采样器<a class="headerlink" href="#id15" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>Euler，可以看作是最简单的求解器。</p></li>
<li><p>Heun，比欧拉法更准确但速度较慢。</p></li>
<li><p>LMS (Linear multi-step method)，与欧拉法速度差不多，但（据说）更准确。</p></li>
</ul>
</section>
<section id="ancestral-samplers">
<h4>祖先采样器(ancestral samplers)<a class="headerlink" href="#ancestral-samplers" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>采样器的名称中有一个字母 a</p></li>
<li><p>如Euler a、DPM2 a、DPM++ 2S a、DPM++ 2S a Karras</p></li>
<li><p>祖先采样器会在每个采样步骤中向图像添加噪声。因为采样结果有一定的随机性，所以它们是随机采样器。</p></li>
</ul>
</section>
<section id="karras">
<h4>采用Karras 文章中推荐的噪声策略<a class="headerlink" href="#karras" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>文章: <a class="reference external" href="https://arxiv.org/abs/2206.00364">https://arxiv.org/abs/2206.00364</a></p></li>
<li><p>采样器的名称中带有 “Karras” 标签</p></li>
<li><p>在接近去噪过程结束时，将噪声步长变小。研究人员发现这可以提高图像的质量。</p></li>
</ul>
</section>
<section id="id16">
<h4>过时采集器<a class="headerlink" href="#id16" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>最初发布的 SD 模型 v1 中附带的采样器。</p></li>
<li><p>DDIM（去噪扩散隐式模型）和 PLMS（伪线性多步方法）</p></li>
</ul>
</section>
<section id="dpm">
<h4>DPM<a class="headerlink" href="#dpm" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>2022 年发布的专为扩散模型设计的新采样器。</p></li>
<li><p>DPM（扩散概率模型求解器）和 DPM++ 采样器</p></li>
</ul>
</section>
<section id="id17">
<h4>使用效果<a class="headerlink" href="#id17" title="此标题的永久链接">¶</a></h4>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/zXWc3i.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/zXWc3i.jpg" />
</figure>
<ul class="simple">
<li><p>选择采样器的建议。</p></li>
<li><p>如果你想使用快速、新颖且质量不错的算法，最好的选择是 DPM++ 2M Karras，设置 20~30 步。</p></li>
<li><p>如果你想要高质量的图像，那么可以考虑使用 DPM++ SDE Karras，设置 10~15 步，但要注意这是一个计算较慢的采样器。或者使用 DDIM 求解器，设置 10~15 步。</p></li>
<li><p>如果你喜欢稳定、可重现的图像，请避免使用任何原始采样器（SDE 类采样器）。</p></li>
<li><p>如果你喜欢简单算法，Euler 和 Heun 是不错的选择。</p></li>
</ul>
</section>
</section>
<section id="clip">
<h3>10|CLIP<a class="headerlink" href="#clip" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p>OpenAI 在 2021 年提出的 CLIP 算法。</p></li>
<li><p>在 AI 绘画的过程中，CLIP 的作用是理解我们给到模型的 prompt 指令，将 prompt 指令编码为模型能理解的“语言”。</p></li>
<li><p>最早提出 CLIP 模型并不是帮助 AI 绘画模型理解 prompt 指令，而是用于连接图像和文本这两种模态。如今，随着 AIGC 技术的大爆发，CLIP 模型又在 AI 绘画、多模态大模型等方向发挥了巨大价值。</p></li>
<li><p>模态（Modality）的概念:在深度学习领域，模态可以用于描述输入数据的不同形式，比如图像、文本、音频等。不同的模态可以提供不同的特征，使模型能够从更多的角度理解和处理数据。在实践中，通过整合多种模态的信息，通常能够帮助模型获得更好的性能。</p></li>
</ul>
<section id="id18">
<h4>CLIP 的提出背景<a class="headerlink" href="#id18" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>在 NLP 领域，早在 2020 年，OpenAI 便已经发布了 GPT-3 这个技术，证明了使用海量互联网数据得到的预训练模型可以用于各种文本类任务，比如文本分类、机器翻译、文本情感分析、文本问答等，GPT-3 的工作直接衍生出后来大火的 ChatGPT。</p></li>
<li><p>在 CV 领域里，最常见的模式还是使用各种各样既定任务的数据集，通过标注员的标注获得训练样本，针对特定任务来训练。CV 任务千千万，便催生了各式各样的数据集，比如图像分类、目标检测、图像分割、图像生成等。不过，在每个训练集上得到的模型通常只能完成特定的任务，无法在其他任务上推广。</p></li>
</ul>
<p>CLIP 被提出之前主要有这样两个痛点:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>第一，CV 数据集标注是个劳动密集型任务，标注成本高昂。
第二，每个 CV 模型通常只能胜任一个任务，无法轻易迁移到新的任务。
</pre></div>
</div>
</section>
<section id="id19">
<h4>CLIP 解决方案<a class="headerlink" href="#id19" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>CLIP 工作的初衷:将 GPT-3 的经验迁移到图像领域，使用海量互联网数据做一个大一统的模型，同时能够很好地支持各种图像任务，比如图像分类、文字识别、视频理解等等</p></li>
<li><p>要达成这个目的，有两个关键点，一是怎么利用海量的互联网数据，二是如何训练这样一个模型。</p></li>
</ul>
<section id="id20">
<h5>数据来源<a class="headerlink" href="#id20" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>首先，为了解决数据的问题，OpenAI 选定了 50 万条不同的查询请求，从互联网上获取到 4 亿图像 - 文本对，来源包括 Google 这类通用搜索引擎和 Twitter 这类垂直领域社区。</p></li>
<li><p>互联网上天然就存在已经标注好的 CV 数据集，而且每天还在飞速新增。此外，使用互联网数据的另一个优势是它的数据非常多样，包含各种各样的图像内容，因此训练得到的模型自然就可以迁移到各种各样的场景。</p></li>
</ul>
</section>
<section id="id21">
<h5>监督信号<a class="headerlink" href="#id21" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>CLIP 通过巧妙的设计利用了图像模态和文本模态的对应关系。CLIP 分别构造了一个图像编码器和一个文本编码器，将图像及其文本描述映射到一个特征空间，比如我们可以映射到 512 维度的特征空间。简言之，一张图或者一个文本描述，经过映射都是 512 个浮点数。</p></li>
<li><p>利用图文成对的关系，通过对比学习，驱动两个编码器模型学习到有效的特征提取能力。</p></li>
<li><p>具体思路是这样的。我们可以计算图像特征向量和文本特征向量之间的余弦距离，余弦距离的范围是 -1 到 1，越大表示距离越接近。CLIP 的训练目标是让对应的图像、文本得到的特征向量靠近，也就是余弦距离越大越好，让不对应的图像、文本得到的特征向量远离，也就是余弦距离尽可能小。</p></li>
</ul>
<figure class="align-default" id="id77">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/0Sbqhd.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/0Sbqhd.jpg" />
<figcaption>
<p><span class="caption-text">CLIP 通过 4 亿图文对数据进行对比学习，得到一个图像编码器和一个文本编码器。在使用 CLIP 时，成对的图像文本经过对应模态的编码器后，得到的特征会更接近。(图片来源:<a class="reference external" href="https://openai.com/research/clip">https://openai.com/research/clip</a>)</span><a class="headerlink" href="#id77" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<p>这个过程的伪代码:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># image_encoder - 图像编码器可以使用ResNet或者Vision Transformer结构</span>
<span class="c1"># text_encoder - 文本编码器可以使用CBOW或者Text Transformer结构</span>
<span class="c1"># I[n, h, w, c] - 一个训练批次的图像</span>
<span class="c1"># T[n, l] - 一个训练批次的对应文本图像</span>
<span class="c1"># W_i[d_i, d_e] - 可学习的图像特征投影层权重</span>
<span class="c1"># W_t[d_t, d_e] - 可学习的文本特征投影层权重</span>
<span class="c1"># t - 一个可学习的温度系数</span>

<span class="c1"># 1. 提取图像和文本模态的表征</span>
<span class="n">I_f</span> <span class="o">=</span> <span class="n">image_encoder</span><span class="p">(</span><span class="n">I</span><span class="p">)</span> <span class="c1">#[n, d_i]</span>
<span class="n">T_f</span> <span class="o">=</span> <span class="n">text_encoder</span><span class="p">(</span><span class="n">T</span><span class="p">)</span> <span class="c1">#[n, d_t]</span>

<span class="c1"># 2. 图像表征和文本表征分别映射到共同的多模态空间 [n, d_e]</span>
<span class="n">I_e</span> <span class="o">=</span> <span class="n">l2_normalize</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">I_f</span><span class="p">,</span> <span class="n">W_i</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">T_e</span> <span class="o">=</span> <span class="n">l2_normalize</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">T_f</span><span class="p">,</span> <span class="n">W_t</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># 3. 计算余弦相似度 [n, n]</span>
<span class="n">logits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">I_e</span><span class="p">,</span> <span class="n">T_e</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>

<span class="c1"># 4. 计算损失值</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="n">loss_i</span> <span class="o">=</span> <span class="n">cross_entropy_loss</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">loss_t</span> <span class="o">=</span> <span class="n">cross_entropy_loss</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss_i</span> <span class="o">+</span> <span class="n">loss_t</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
</pre></div>
</div>
<ul class="simple">
<li><p>训练过程分为四步:提取表征、映射和归一化、计算距离和更新模型权重。</p></li>
<li><p>首先，使用图像编码器提取图像表征 I_f，使用文本编码器提取文本表征 T_f。</p></li>
<li><p>然后，分别引入一个线性投影（Linear Projection），将图像表征和文本表征分别映射到共同的多模态空间。这里线性投影的参数对应伪代码中的 W_i 和 W_t，然后将投影后的特征向量分别进行归一化，归一化后的表征平方和等于 1。</p></li>
<li><p>之后，我们要计算这批图文归一化表征两两之间的距离，距离范围是 -1 到 1，然后再乘以一个温度系数相关的数值项（伪代码第 18 行），这里的温度系数是一个可学习的参数。</p></li>
<li><p>最后，通过交叉熵损失函数进行模型监督，匹配的图文对距离拉近、不匹配的图文对距离拉远。</p></li>
</ul>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/17befe1b7beaea9a5b0fbc08de6cb8bc.gif" src="https://img.zhaoweiguo.com/uPic/2023/09/17befe1b7beaea9a5b0fbc08de6cb8bc.gif" />
</figure>
</section>
</section>
<section id="id22">
<h4>CLIP 进阶探索<a class="headerlink" href="#id22" title="此标题的永久链接">¶</a></h4>
<section id="id23">
<h5>CLIP 应用<a class="headerlink" href="#id23" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>经典的图像分类任务通常需要使用人工标注的标签数据来训练，训练完成后只能区分训练时限定的类别。</p></li>
<li><p>而CLIP使用的可以称为跨模态检索:由于 CLIP 见过 4 亿图文，拥有海量的知识，我们便可以直接通过跨模态检索的方式直接进行分类。以 ImageNet 的 1000 类别为例，得到 1000 个不同的 prompt。这 1000 个 prompt 经过预训练得到的文本编码器之后，便得到 1000 个文本表征；对于输入图像，我们经过预训练的图像编码器可以得到 1 个图像表征。将图像表征和 1000 个文本表征线性投影、归一化之后计算余弦距离，余弦距离最大的 prompt 对应的类别便是 CLIP 模型预测的类别。</p></li>
<li><p>检索方案的扩展性要强于分类方案，比如上面这个任务的候选类别，你可以随意设计。</p></li>
<li><p>再举个人脸识别的例子，如果我们把人脸识别当做是分类任务，那么每次系统中录入一个新人，都需要将分类类别数加一，然后重新训练模型；如果我们将人脸识别建模为检索任务，我们只需要像 CLIP 这样，对每个人脸提一个特征，然后通过检索的方式进行身份定位即可。这样就不需要重新训练模型了。</p></li>
</ul>
<figure class="align-default" id="id78">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/9YXGjo.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/9YXGjo.jpg" />
<figcaption>
<p><span class="caption-text">CLIP 通过检索为图像分类的整体过程</span><a class="headerlink" href="#id78" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>对于我们 AI 绘画这门课，CLIP 模型便是让 AI 绘画模型听我们话的关键！在 CLIP 的训练过程中，图像表征和文本表征被线性投影到共同的多模态空间，在文本生图的过程中，prompt 信息便可以通过 CLIP 抽取特征，然后指导模型作画。</p></li>
</ul>
<figure class="align-default" id="id79">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/sal6c8.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/sal6c8.jpg" />
<figcaption>
<p><span class="caption-text">(图片来源:<a class="reference external" href="https://arxiv.org/abs/2112.10752">https://arxiv.org/abs/2112.10752</a>)</span><a class="headerlink" href="#id79" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>DALL-E 2 模型，在 CLIP 的基础上进一步扩展，提出 unCLIP 结构，不仅能够用文本指导图像生成，还能输入图像生成多个相似变体。</p></li>
</ul>
</section>
<section id="id24">
<h5>CLIP 增强版<a class="headerlink" href="#id24" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>OpenAI 只是开源了 CLIP 模型的权重，并没有开源对应的 4 亿图文对。后来的学者便开始复现 OpenAI 的工作。比较有代表性的工作包括 OpenCLIP、ChineseCLIP 和 EVA-CLIP。</p></li>
<li><p>OpenCLIP 基于 LAION 公司收集的 <a class="reference external" href="https://arxiv.org/abs/2111.02114">4 亿开源图文数据</a> 训练而成，相当于是对 OpenAI 的 CLIP 模型的复现。公开的 LAION 5B 数据集和开源的 OpenCLIP 代码库，打破了此前 OpenAI 的“数据垄断”。你可以点开`这个链接 &lt;<a class="reference external" href="https://github.com/mlfoundations/open_clip">https://github.com/mlfoundations/open_clip</a>&gt;`_了解更多细节。</p></li>
<li><p>ChineseCLIP 的目标是用中文的图文数据完成 CLIP 训练，强化文本编码器的中文理解能力。比如说，ChineseCLIP 模型可以帮助 AI 绘画模型更好地理解中文。ChineseCLIP 使用大约 2 亿中文图文对数据进行训练，你可以点开`这个链接 &lt;<a class="reference external" href="https://github.com/OFA-Sys/Chinese-CLIP">https://github.com/OFA-Sys/Chinese-CLIP</a>&gt;`_了解更多细节。</p></li>
<li><p>EVA-CLIP 是 2023 年 3 月由北京智源研究院提出的模型，通过提高训练效率和优化模型设计，取得了比传统 CLIP 更好的性能。感兴趣的同学可以点开`这个链接 &lt;<a class="reference external" href="https://arxiv.org/abs/2303.15389">https://arxiv.org/abs/2303.15389</a>&gt;`_了解更多细节。</p></li>
</ul>
</section>
</section>
<section id="id26">
<h4>如何使用 CLIP<a class="headerlink" href="#id26" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>示例: <a class="reference external" href="https://colab.research.google.com/github/NightWalker888/ai_painting_journey/blob/main/lesson10/CLIP_demo.ipynb">Colab 链接</a></p></li>
</ul>
</section>
<section id="id27">
<h4>小结<a class="headerlink" href="#id27" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>CLIP 模型的两种常用用法</p></li>
<li><ol class="arabic simple">
<li><p>基于检索的方式为图像分类</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="2">
<li><p>实现 AI 绘画模型的 prompt 信息提取</p></li>
</ol>
</li>
<li><p>原始论文(Learning Transferable Visual Models From Natural Language Supervision): <a class="reference external" href="https://readpaper.com/pdf-annotate/note?pdfId=4557522938392223745&amp;noteId=1772676889632149504">https://readpaper.com/pdf-annotate/note?pdfId=4557522938392223745&amp;noteId=1772676889632149504</a></p></li>
</ul>
</section>
</section>
<section id="vae">
<h3>11|VAE系列<a class="headerlink" href="#vae" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p>【概念】潜在空间:通过神经网络，在保留原始数据的关键信息的条件下，将输入的原始数据压缩到一个更低维度的空间，得到一个低维的向量表示，并且这个低维的向量表示可以通过解码恢复出原始的数据。这里的低维空间就是潜在空间（latent space，也称为隐空间），低维的向量也叫潜在表示（latent representation）。你可以这样理解，潜在空间是较低维度的空间，用于表示原始数据的结构和特征。潜在表示便是原始数据在潜在空间中对应的特征向量。</p></li>
</ul>
<section id="id28">
<h4>VAE简介<a class="headerlink" href="#id28" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>VAE 的全称是变分自动编码器（Variational Autoencoder），在 2013 年被提出，是自动编码器（AE，Autoencoder）的一种扩展。你可能听过很多不同的名词，比如 AE、VAE、DAE、MAE、VQVAE 等。其实这些带 “AE” 的名字，你都可以理解成是一个编码器和一个解码器。</p></li>
<li><p>尽管术语一样，但是 VAE 和 Transformer 中的编码器、解码器解决的是不同类型的问题，并具有不同的结构和原理。</p></li>
</ul>
<figure class="align-default" id="id80">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/T9gS4t.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/T9gS4t.jpg" />
<figcaption>
<p><span class="caption-text">以 VAE 为代表的 “AE” 系列工作，都是希望编码器将原始数据编码成低维的潜在表示，并且这个潜在表示可以通过解码器近乎无损地恢复出原始数据。这里的原始数据，可以是图像、文本等多种模态。</span><a class="headerlink" href="#id80" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
</section>
<section id="id29">
<h4>VAE 细节探究<a class="headerlink" href="#id29" title="此标题的永久链接">¶</a></h4>
<section id="ae">
<h5>AE 的长处和短板<a class="headerlink" href="#ae" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>优点</p></li>
<li><p>首先是 AE 结构（自编码器）。AE 结构使用无监督的方式进行训练，以图像任务为例，使用大量的图像数据，依次经过编码器和解码器得到重建图像，训练目标是最小化原始数据与重构数据之间的差异。实际操作中，损失函数可以是 L1 损失或者 L2 损失。</p></li>
<li><p>AE 结构是无监督学习，是因为损失函数的计算只依赖于输入数据本身，而不涉及任何标签或类别信息。</p></li>
<li><p>缺点</p></li>
<li><p>第一，潜在表示缺乏直接的约束，在潜在空间中一个个孤立的点。如果对于输入图像的潜在表示稍加扰动，比如加上一个标准高斯噪声，解码器便会得到无意义的输出。</p></li>
<li><p>第二，潜在表示难以解释和编辑。我举个例子来说明，比如我们想得到“半月图像”的潜在表示，但手里又只有满月和新月图片。</p></li>
<li><p>改进</p></li>
<li><p>针对第一个缺点，DAE（去噪自编码器）的改进方式就是故意在输入数据中加入噪声，这样得到的潜在表示更加鲁棒。（DAE 只是改善了 AE 的表现，并没有真正补全 AE 的短板。）</p></li>
</ul>
</section>
</section>
<section id="id30">
<h4>VAE 的工作原理<a class="headerlink" href="#id30" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>真正解决 AE 两大痛点的工作就是 VAE。在 VAE 中，编码器的输出不再是潜在表示，而是某种已知概率分布的均值 μ 和方差 σ，比如最常用的高斯分布。根据均值、方差和一个随机噪声 ϵ，我们便可以根据下面的公式计算出最终的潜在表示，给到解码器。</p></li>
<li><p>VAE 中计算潜在表示的过程便是大名鼎鼎的重参数化技巧，解决了梯度不能直接通过随机采样操作进行传播的问题。</p></li>
</ul>
<figure class="align-default" id="id81">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/eDGPFM.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/eDGPFM.jpg" />
<figcaption>
<p><span class="caption-text">VAE 的整体过程</span><a class="headerlink" href="#id81" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<section id="id31">
<h5>用 VAE 做图像插值<a class="headerlink" href="#id31" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>讲了这么多原理，也是在为 VAE 的应用做铺垫。VAE 不仅可以有效地压缩和重构图像，它得到的潜在表示还可以进行插值编辑。</p></li>
<li><p>Colab 代码: <a class="reference external" href="https://colab.research.google.com/github/NightWalker888/ai_painting_journey/blob/main/lesson11/VAE%E4%BD%BF%E7%94%A8update.ipynb">https://colab.research.google.com/github/NightWalker888/ai_painting_journey/blob/main/lesson11/VAE%E4%BD%BF%E7%94%A8update.ipynb</a></p></li>
<li><p>使用 Stable Diffusion 中使用的 VAE 权重进行重建，从我们视觉来看，几乎是 100% 复原</p></li>
</ul>
<figure class="align-default" id="id82">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/x17MAm.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/x17MAm.jpg" />
<figcaption>
<p><span class="caption-text">左边是原始图像，右边是 VAE 重建图像</span><a class="headerlink" href="#id82" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="id32">
<h4>VAE 的应用<a class="headerlink" href="#id32" title="此标题的永久链接">¶</a></h4>
<section id="id33">
<h5>VAE 与经典任务<a class="headerlink" href="#id33" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>VAE 可以用于图像生成，比如人脸、动漫等角色的创建。以动漫角色生成为例，VAE 可以用来创建具有独特外观和特征的全新动漫角色。为此，我们首先需要使用现有的动漫角色数据集训练 VAE 的编码器和解码器。完成后，我们在潜在空间中采样，便可以得到新的角色图像。</p></li>
<li><p>VAE 可以用于自然语言处理，比如用于带情感的评论生成等任务。假设我们有一个餐馆评论数据集（包含正、负评论），我们可以使用第 7 讲提到的时序模型设计 VAE 的编码器，比如 RNN、LSTM、Transformer 等，得到潜在表示，然后再把潜在表示与特定情感信息（如正面或负面）一起传递至解码器进行训练。训练完成后，我们便得到了一个能够控制情感倾向的餐馆评论生成模型。</p></li>
<li><p>VAE 还可以用于聚类分析和异常检测。比如，在数据的潜在空间中把具有相似结构和内容的数据聚集在一起，为后续的聚类分析提供便利，或者用于识别潜在空间中明显异常的数据。</p></li>
</ul>
</section>
<section id="id34">
<h5>VAE 与扩散模型<a class="headerlink" href="#id34" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>原始的扩散模型需要在原图上进行加噪和去噪操作，过程非常耗时。Stable Diffusion 在 VAE 的潜在空间上进行加噪和去噪</p></li>
</ul>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/pldWqJ.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/pldWqJ.jpg" />
</figure>
<ul class="simple">
<li><p>VAE 模型是按照我们前面讲的 VAE 训练过程预先获得的。我们使用 LoRA 等技术训练自己的 AI 绘画模型时，并不会改变 VAE 模型的权重。但这并不意味着 VAE 对图像质量没有影响。其实在某种程度上，VAE 代表了 AI 绘画生成质量的上限。</p></li>
<li><p>虽然我们上面新月满月的例子证明了 VAE 的图像重建能力几乎无损，但如果是更困难复杂的场景，VAE 重建的图像会存在明显的模糊。</p></li>
<li><p>重新训练 VAE: <a class="reference external" href="https://github.com/cccntu/fine-tune-models/#fine-tuning-vae-decoder-of-stable-diffusion">https://github.com/cccntu/fine-tune-models/#fine-tuning-vae-decoder-of-stable-diffusion</a></p></li>
</ul>
</section>
</section>
<section id="id35">
<h4>总结<a class="headerlink" href="#id35" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>结构:VAE通常是简单的全连接网络或卷积神经网络；Transformer基于多头注意力机制，结构更复杂。</p></li>
<li><p>原理:VAE关注于在潜在空间中建立数据的概率分布；Transformer通过自注意力机制捕获长距离的依赖关系。</p></li>
<li><p>功能:VAE主要是为了生成数据和降维；而Transformer则是为了处理序列到序列的任务，捕获序列中的依赖关系。</p></li>
<li><p>Pytorch的VAE实现可以看这个代码:<a class="reference external" href="https://github.com/AntixK/PyTorch-VAE/blob/master/models/vanilla_vae.py">https://github.com/AntixK/PyTorch-VAE/blob/master/models/vanilla_vae.py</a></p></li>
</ul>
</section>
</section>
<section id="id36">
<h3>12|实战项目2: 动手训练一个你自己的扩散模型<a class="headerlink" href="#id36" title="此标题的永久链接">¶</a></h3>
<section id="id37">
<h4>关键知识串联<a class="headerlink" href="#id37" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>标准扩散模型的训练过程包含 6 个步骤，分别是随机选取训练图像、随机选择时间步 t、随机生成高斯噪声、一步计算第 t 步加噪图、使用 UNet 预测噪声值和计算噪声数值误差。</p></li>
<li><p>Stable Diffusion 在此基础上，增加了 VAE 模块和 CLIP 模块。VAE 模块的作用是降低输入图像的维度，从而加快模型训练、给 GPU 腾腾地方；CLIP 模块的作用则是将文本描述通过交叉注意力机制注入到 UNet 模块，让 AI 绘画模型做到言出法随。</p></li>
<li><p>在 Stable Diffusion 中，还有很多其他黑魔法，比如无条件引导控制（Classifier-Free Guidance）、引导强度（Guidance Scale）等</p></li>
</ul>
<figure class="align-default" id="id83">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/R1Jrco.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/R1Jrco.jpg" />
<figcaption>
<p><span class="caption-text">图中最左侧粉色区域便是 VAE 模块，最右侧的条件控制模块便可以是 CLIP（也可以是其他控制条件），而中间 UNet 部分展示的 QKV 模块，便是 prompt 通过交叉注意力机制引导图像生成。</span><a class="headerlink" href="#id83" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
</section>
<section id="id38">
<h4>训练扩散模型<a class="headerlink" href="#id38" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>Colab 链接: <a class="reference external" href="https://colab.research.google.com/github/NightWalker888/ai_painting_journey/blob/main/lesson12/train_diffusion_v2.ipynb">https://colab.research.google.com/github/NightWalker888/ai_painting_journey/blob/main/lesson12/train_diffusion_v2.ipynb</a></p></li>
<li><p>通过两种方式来训练扩散模型。</p></li>
<li><p>第一种是使用 denoising_diffusion_pytorch 这个高度集成的工具包</p></li>
<li><p>第二种则是基于 diffusers 这种更多开发者使用的工具包。</p></li>
</ul>
</section>
<section id="diffusers">
<h4>进阶到 diffusers 训练<a class="headerlink" href="#diffusers" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>Colab 链接: <a class="reference external" href="https://colab.research.google.com/github/NightWalker888/ai_painting_journey/blob/main/lesson12/diffusers_training_example_annotated.ipynb">https://colab.research.google.com/github/NightWalker888/ai_painting_journey/blob/main/lesson12/diffusers_training_example_annotated.ipynb</a></p></li>
</ul>
</section>
<section id="stable-diffusion">
<h4>微调 Stable Diffusion<a class="headerlink" href="#stable-diffusion" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>diffusers 官方提供的训练代码: <a class="reference external" href="https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py">https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image.py</a></p></li>
<li><p>比于上面提到的标准扩散模型训练，核心也只是多了 VAE 和 CLIP 的部分。</p></li>
<li><p>要进一步确认文本描述如何通过交叉注意力机制起作用: 推荐你去看看 <a class="reference external" href="https://github.com/huggingface/diffusers/blob/v0.19.3/src/diffusers/models/unet_2d_condition.py#L66">UNet2DConditionModel</a> 这个模块的代码</p></li>
</ul>
</section>
<section id="sd">
<h4>如何调用各种 SD 模型<a class="headerlink" href="#sd" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>Colab 链接: <a class="reference external" href="https://colab.research.google.com/github/NightWalker888/ai_painting_journey/blob/main/lesson12/%E5%BC%80%E6%BA%90AI%E7%BB%98%E7%94%BB%E6%A8%A1%E5%9E%8B%E4%BD%BF%E7%94%A8.ipynb">https://colab.research.google.com/github/NightWalker888/ai_painting_journey/blob/main/lesson12/%E5%BC%80%E6%BA%90AI%E7%BB%98%E7%94%BB%E6%A8%A1%E5%9E%8B%E4%BD%BF%E7%94%A8.ipynb</a></p></li>
</ul>
</section>
<section id="id39">
<h4>总结<a class="headerlink" href="#id39" title="此标题的永久链接">¶</a></h4>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/joXatQ.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/joXatQ.jpg" />
</figure>
</section>
<section id="id40">
<h4>评论<a class="headerlink" href="#id40" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>换脸换衣服这类任务选择生成能力较强的真人模型，比如墨幽人造人、Realistic这类</p></li>
<li><p>关掉NSFW检测，可以参考这个链接: <a class="reference external" href="https://stackoverflow.com/questions/73828107/how-to-fix-nsfw-error-for-stable-diffusion">https://stackoverflow.com/questions/73828107/how-to-fix-nsfw-error-for-stable-diffusion</a></p></li>
</ul>
</section>
</section>
</section>
<section id="dall-e-2-stable-diffusion-5">
<h2>进阶篇:从 DALL-E 2 到 Stable Diffusion (5讲)<a class="headerlink" href="#dall-e-2-stable-diffusion-5" title="此标题的永久链接">¶</a></h2>
<section id="dall-e-2">
<h3>13|前浪DALL-E 2<a class="headerlink" href="#dall-e-2" title="此标题的永久链接">¶</a></h3>
<section id="id41">
<h4>初识 DALL-E 2<a class="headerlink" href="#id41" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>DALL-E 2 是 2022 年 4 月由 OpenAI 发布的 AI 绘画模型，它的绘画效果相比过去的工作有了质的飞跃，而且它提出的 unCLIP 结构、图像变体能力也被后来的方法所效仿。</p></li>
<li><p>DALL-E 这个名字源自西班牙艺术家 Salvador Dali 和皮克斯动画机器人 Wall-E 的组合。</p></li>
</ul>
<p>功能:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>1. 基于文本描述生成高清图像
2. 生成图像变体(对经典画作进行“魔改”)
3. 图像的融合
4. 局部编辑
</pre></div>
</div>
<figure class="align-default" id="id84">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/xEqE4j.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/xEqE4j.jpg" />
<figcaption>
<p><span class="caption-text">生成图像变体(对经典画作进行“魔改”)</span><a class="headerlink" href="#id84" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<figure class="align-default" id="id85">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/TY4Qnv.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/TY4Qnv.jpg" />
<figcaption>
<p><span class="caption-text">图像的融合。比如输入两张图片，DALL-E 2 可以对两张图片进行插值，生成融合后的新图片。这里的融合既可以是图像风格上的融合，也可以是图像内容上的融合，或者是图像内容和图像风格二者的融合。</span><a class="headerlink" href="#id85" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<figure class="align-default" id="id86">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/sW7eyT.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/sW7eyT.jpg" />
<figcaption>
<p><span class="caption-text">局部编辑。输入一张图片，DALL-E 2 可以根据我们的指令局部编辑图像，让我们仿佛拥有了指令级 PS 的能力。</span><a class="headerlink" href="#id86" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
</section>
<section id="id42">
<h4>工作原理<a class="headerlink" href="#id42" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>DALL-E 2 就是个“缝合怪”。我们把 CLIP 和扩散模型，或者 CLIP 和自回归模型组合到一起，引入大量图像文本数据进行模型训练后，便得到了 DALL-E 2。</p></li>
<li><p>标记 1。它是原始的 CLIP 结构，这部分在 DALL-E 2 的链路中是固定住的，无需训练。</p></li>
<li><p>标记 2。它代表 CLIP 的文本编码器提取的文本表征。文本表征是指根据输入的文本，用 CLIP 文本编码器提取得到的数值特征。图中三处标记为 2 的表征是完全相同的。</p></li>
<li><p>标记 3 和标记 4 是两种可以互相替代的方案。标记 3 代表需要训练的自回归先验模型，也称为 Prior 模型。先验模型的作用，就是将 CLIP 提取的文本表征转换为 CLIP 图像表征。</p></li>
<li><p>标记 4 表示需要训练的扩散先验模型。DALL-E 2 经过实验验证，使用扩散先验模型和自回归先验模型在生成效果上差不太多，扩散先验模型在计算效率上更有优势。</p></li>
<li><p>标记 5 是先验模块输出的图像表征，该表征类似于 CLIP 图像编码器提取的特征。</p></li>
<li><p>标记 6 则是扩散模型，作用是将上一步得到的图像表征转换为图像。</p></li>
</ul>
<figure class="align-default" id="id87">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/7xwLWH.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/7xwLWH.jpg" />
<figcaption>
<p><span class="caption-text">DALL-E 2 标记后的整体方案说明</span><a class="headerlink" href="#id87" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>DALL-E 2 的结构可以归纳为后面这三个步骤</p></li>
<li><p>首先，使用一个预训练好的 CLIP 文本编码器将文本描述映射为文本表征。</p></li>
<li><p>然后，训练一个扩散先验模型，将文本表征映射为对应的图像表征。</p></li>
<li><p>最后，训练一个基于扩散模型的图像解码器，该解码器可以基于图像表征生成图像。</p></li>
<li><p>这三步便是 DALL-E 2 实现 AI 绘画能力的全部过程。</p></li>
</ul>
<figure class="align-default" id="id88">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/0zOvC9.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/0zOvC9.jpg" />
<figcaption>
<p><span class="caption-text">用一句话总结就是，DALL-E 2 设计的核心思路是，用 CLIP 提取文本表征，通过一个扩散模型将文本表征转换为图像表征，然后通过另一个扩散模型指导图像的生成。</span><a class="headerlink" href="#id88" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<section id="id43">
<h5>扩散先验模型该如何训练<a class="headerlink" href="#id43" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>扩散先验模型的目标是将 CLIP 文本表征转换为 CLIP 图像表征。DALL-E 2 的扩散先验模型并没有使用 UNet 结构，而是直接使用一个 Transformer 解码器。</p></li>
<li><p>UNet 结构擅长解决图像分割问题，因为 UNet 的输入和输出都是类似于图像的特征图；而 Transformer 的输入输出是序列化的特征，更适合完成 CLIP 文本表征到图像表征的转换。基于 Transformer 的扩散先验并不是预测每一步的噪声值，而是直接预测每一步去噪后的图像表征。</p></li>
</ul>
<figure class="align-default" id="id89">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/5jemJr.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/5jemJr.jpg" />
<figcaption>
<p><span class="caption-text">基于 Transformer 的扩散先验模型和普通扩散模型的区别</span><a class="headerlink" href="#id89" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>基于图像 - 文本成对训练数据，扩散先验模型的训练可以分为以下几个步骤</p></li>
<li><p>首先，使用预训练好的 CLIP 文本编码器提取文本描述的文本表征</p></li>
<li><p>然后，使用预训练好的 CLIP 图像编码器提取对应的图像表征</p></li>
<li><p>之后，随机采样一个时间步 t，以时间步 t、CLIP 提取的文本表征、加噪之后的图像表征作为条件，基于 Transformer 去预测下一步去噪后的图像表征</p></li>
</ul>
</section>
</section>
<section id="id44">
<h4>图像变体<a class="headerlink" href="#id44" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>虽然在生图效果、生图速度等方面，标准的 Stable Diffusion 毫不逊色于 DALL-E 2，但图像变体功能仍是 DALL-E 2 的亮点功能之一。</p></li>
<li><p>我们常常把 DALL-E 2 的文生图方案称为 unCLIP，这种方案和 Stable Diffusion 的技术链路是不同的。unCLIP 模型有一些独特的优势，比如用户输入一张图像，unCLIP 模型可以保留原始图像的关键信息，生成一系列图像变体。</p></li>
<li><p>预训练好的 CLIP 图像编码器可以提取到图像表征，文本编码器可以提取到文本表征。DALL-E 2 从图像表征直接生成图像，正好和 CLIP 从图像提取图像表征是一个相反的过程，这个过程被称为 unCLIP。</p></li>
</ul>
<figure class="align-default" id="id90">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/QypUIS.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/QypUIS.jpg" />
<figcaption>
<p><span class="caption-text">生成图像变体的过程:用户输入一张图像，使用 CLIP 的图像编码器提取图像表征作为图像解码器的输入，这样就实现了生成图像变体的能力。前面我们提到扩散先验模型的作用是得到类似于 CLIP 图像编码器提取的图像表征，而图像变体功能使用 CLIP 图像编码器提取图像表征，二者是类似的。unCLIP 的精妙之处就在这里</span><a class="headerlink" href="#id90" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>虽然 CLIP 的图像编码器是固定的，从给定原始图像得到的图像表征是一个确定性的过程。但扩散解码器每次从随机噪声出发，结合 CLIP 图像表征会生成变体图像，这个生成图像的过程是有随机性的，所以 DALL-E 2 才会轻易得到很多变体图像。</p></li>
<li><p>Imagen 模型并没有使用扩散先验，而是直接从文本表征生成图像，效果优于 DALL-E 2。从后来主流模型如 Stable Diffusion 的做法来看，扩散先验并不是必须的，代价是失去了生成图像变体的能力。</p></li>
</ul>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/tIfWGs.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/tIfWGs.jpg" />
</figure>
</section>
<section id="id45">
<h4>局限性<a class="headerlink" href="#id45" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>首先，DALL-E 2 并不擅长处理逻辑关系。如下图，我们要求其生成“蓝色方块上面放一个红色的方块”，对比 GLIDE 这个论文，DALL-E 2 得到的效果并不准确。</p></li>
</ul>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/7DusS9.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/7DusS9.jpg" />
</figure>
<ul class="simple">
<li><p>其次，DALL-E 2 并不擅长在生成的图像中写出要求的文字。比如我们要求 DALL-E 2 生成一幅图，“写着 Deep Learning 的标志板”，结果并不理想。</p></li>
</ul>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/fvwC6v.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/fvwC6v.jpg" />
</figure>
<ul class="simple">
<li><p>此外，DALL-E 2 不擅长生成复杂的场景，细节不足。比如我们要求其生成“一张高质量的时代广场的照片”，得到的结果很粗糙。</p></li>
<li><p>除了上面这些，DALL-E 2 生成的内容还存在一些种族偏见，比如一些特定的职业会生成特定的有色人种；DALL-E 2 也会生成一些色情暴力的内容，这是由于训练的数据中包括这类内容。</p></li>
</ul>
</section>
</section>
<section id="imagen">
<h3>14|挑战者Imagen<a class="headerlink" href="#imagen" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p>OpenAI 推出的 DALL-E 2 后仅仅过去一个月，在 2022 年 5 月，Google 便发布了自己的 AI 绘画模型 Imagen。Imagen 在效果上显著优于 DALL-E 2，并且通过实验证明，只要文本模型足够大，就不再需要扩散先验模型。</p></li>
<li><p>2023 年的 4 月 28 日，后来者 StabilityAI，也就是搞出来 Stable Diffusion 这个模型的公司，发布了 DeepFloyd 模型。这个模型完美地解决了 DALL-E 2 不能在生成图像中指定文字内容的问题，是当下公认的效果最好的 AI 绘画模型之一。而DeepFloyd 模型的技术方案，恰恰就是我们今天要讲的主角 Imagen。</p></li>
</ul>
<section id="id46">
<h4>初识 Imagen<a class="headerlink" href="#id46" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>在 Imagen 的论文中，作者认为 Imagen 的两个核心优势是:图像真实感（photorealism）和更强的语言理解能力（language understanding）。</p></li>
</ul>
<figure class="align-default" id="id91">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/SWce0f.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/SWce0f.jpg" />
<figcaption>
<p><span class="caption-text">DALL-E 2 和 Imagen 在“Text-in-Image”能力的效果对比</span><a class="headerlink" href="#id91" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<figure class="align-default" id="id92">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/63gKqi.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/63gKqi.jpg" />
<figcaption>
<p><span class="caption-text">DALL-E 2 和 Imagen 在“处理逻辑关系”能力的效果对比</span><a class="headerlink" href="#id92" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
</section>
<section id="id47">
<h4>工作原理<a class="headerlink" href="#id47" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>项目官网: <a class="reference external" href="https://imagen.research.google/">https://imagen.research.google/</a></p></li>
</ul>
<figure class="align-default" id="id93">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/PGaDol.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/PGaDol.jpg" />
<figcaption>
<p><span class="caption-text">Imagen整体方案流程:首先要将文本表征、初始噪声作为扩散模型的输入，去噪后的图像作为目标输出，就得到了低分辨率扩散模型；然后将低分辨率图像、文本表征作为输入，去噪后的图像作为目标输出，得到更高分辨率的扩散模型。</span><a class="headerlink" href="#id93" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/fo66p4.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/fo66p4.jpg" />
</figure>
<ul class="simple">
<li><p>Imagen 相比于 DALL- E 2 在方法上主要有三点不同。</p></li>
<li><p>第一，Imagen 没有使用 CLIP 的文本编码器和图像编码器，而是直接使用纯文本大模型 T5 来完成文本编码任务。Imagen 用到的 T5 模型（T5-XXL）参数量共计 110 亿，CLIP 的文本编码器参数量约为 6300 万。这意味着 Imagen 拥有更强大的文本描述理解能力。</p></li>
<li><p>第二，Imagen 没有使用 unCLIP 结构，而是直接把文本表征输入给图像解码器，生成目标图像。</p></li>
<li><p>第三，Imagen 对扩散模型预测的噪声使用了动态阈值的策略，提升了 AI 绘画效果的稳定性。这一点我们稍后解释。</p></li>
</ul>
</section>
<section id="id48">
<h4>从文本表征到图像<a class="headerlink" href="#id48" title="此标题的永久链接">¶</a></h4>
<figure class="align-default" id="id94">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/3iFDYs.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/3iFDYs.jpg" />
<figcaption>
<p><span class="caption-text">扩散模型的过程图解:扩散模型的主要功能是从噪声通过多步去噪的过程，得到一张清晰的图像。=&gt;扩散模型生成图片的过程需要多个采样步，每一步都使用权重共享的 UNet 结构。对于文生图任务来说，UNet 的输入信息包括当前带噪声的图像、时间步编码、文本表征编码。</span><a class="headerlink" href="#id94" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<figure class="align-default" id="id95">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/Ku0VYh.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/Ku0VYh.jpg" />
<figcaption>
<p><span class="caption-text">在 Imagen 项目中，图像解码器使用的同样是扩散模型。扩散过程需要多步来完成，逐渐从噪声得到清晰图像。对于每一步去噪，Imagen 都会将当前带噪声图像、时间步编码、文本表征编码进行求和，作为 UNet 模型的输入信息。通过这种方式，T5 模型提取的文本表征就能直接用来指导图像的生成了。这个过程既没有用到 CLIP，也没有文本表征到图像表征的显式转换，自然就不是 unCLIP 的方案了。</span><a class="headerlink" href="#id95" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
</section>
<section id="id49">
<h4>巧用动态阈值策略<a class="headerlink" href="#id49" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>动态阈值（Dynamic Threshold）策略为什么能生成更真实的图像。</p></li>
<li><p>在扩散模型生成图像的过程中，每一步都会预测一个噪声值，然后基于采样器去除这个噪声。Imagen 的作者发现，预测的噪声如果在数值上不做约束（比如限制到 -1 到 1 的范围），最终可能会生成纯黑图像。</p></li>
<li><p>静态阈值策略可以用于缓解这个问题。它的做法是把 UNet 预测的噪声超过 1 的部分全部设置为 1，小于 -1 的部分全部设置为 -1。静态阈值是一种常见的噪声图数值处理方法。作者实验发现使用静态阈值虽然有效果，但还是会产生图像过度饱和的问题。</p></li>
<li><p>在已有静态阈值的基础上，作者又提出了动态阈值的策略，解决了 AI 绘画过程中的黑图、过饱和等问题。具体就是先确定一个百分比，比如 90%。对于每一步去噪，都可以计算出一个数值 s，噪声图中 90% 的元素都位于 -s 到 s 的范围内。小于 -s 的部分全部设置为 -s，大于 s 的部分全部设置为 s。然后对于所有元素都除以 s，将最终噪声图标归一化到 -1 到 1 的范围。</p></li>
<li><p>这种策略可以有效地动态约束每一步去噪过程的数值范围，提升文生图过程的稳定性。</p></li>
</ul>
</section>
<section id="deepfloyd-if">
<h4>DeepFloyd IF<a class="headerlink" href="#deepfloyd-if" title="此标题的永久链接">¶</a></h4>
<figure class="align-default" id="id96">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/iNK9dD.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/iNK9dD.jpg" />
<figcaption>
<p><span class="caption-text">DeepFloyd IF 模型的整体结构</span><a class="headerlink" href="#id96" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>它和 Imagen 的结构一模一样。然而，DeepFloyd IF 这个模型，在生成图像的效果上显著优于原始的 Imagen。</p></li>
<li><p>DeepFloyd IF 模型能有这样的生成能力，主要源于这两个原因。</p></li>
<li><ol class="arabic simple">
<li><p>扩散模型解码器 IF-I-XL 的参数量达到 43 亿，大力出奇迹。</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="2">
<li><p>DeepFloyd 使用的是和 Imagen 一样的 T5 模型，但对 T5 得到的文本表征设计了一个叫最优注意力池化的模块。</p></li>
</ol>
</li>
</ul>
</section>
<section id="id50">
<h4>评论<a class="headerlink" href="#id50" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>DeepFloyd IF是Imagen的延续；SD模型和Imagen都是基于扩散模型的AI绘画方案，SD模型中使用了VAE和CLIP，而Imagen用到的则是T5大语言模型做文本编码。生成效果而言，DeepFloyd IF和SDXL应该可以一比，几乎算是同时期的工作，效果优于Imagen和SD1.x。如果算力有限推荐使用SDXL。</p></li>
<li><p>Google的research团队最新Text-in-Image模型: <a class="reference external" href="https://ideogram.ai/">https://ideogram.ai/</a></p></li>
</ul>
</section>
</section>
<section id="stable-diffusion1">
<h3>15|显微镜下的Stable Diffusion1<a class="headerlink" href="#stable-diffusion1" title="此标题的永久链接">¶</a></h3>
<section id="id51">
<h4>SD 模型的演化之路<a class="headerlink" href="#id51" title="此标题的永久链接">¶</a></h4>
<figure class="align-default" id="id97">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/vRB57o.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/vRB57o.jpg" />
<figcaption>
<p><span class="caption-text">SD1.x系列</span><a class="headerlink" href="#id97" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<figure class="align-default" id="id98">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/4IGjl7.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/4IGjl7.jpg" />
<figcaption>
<p><span class="caption-text">SD新模型</span><a class="headerlink" href="#id98" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
</section>
<section id="id52">
<h4>SD 模型简单串联<a class="headerlink" href="#id52" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>SD 的技术思路来自一篇名为潜在扩散模型的论文（2021 年底发表）。</p></li>
<li><p>原始扩散模型有两个短板。第一是不能通过 prompt 指令来完成 AI 绘画，而是从纯噪声出发，绘画过程有点类似于开盲盒。第二是加噪和去噪的过程都是在图像空间完成，使用高分辨率训练扩散模型，会占用较多的显存。</p></li>
<li><p>潜在扩散模型的前身便是扩散模型，它一方面将扩散过程从图像空间转移到了潜在空间，通过使用 VAE 变分自编码器来压缩和恢复图像，大大提高了速度和效率；另一方面利用 CLIP 等模型的文本编码器，将文本信息转化为文本表征，并通过交叉注意力机制将这些文本信息融入到图像信息空间中，最终实现文本生图。</p></li>
</ul>
</section>
<section id="id53">
<h4>文本引导原理探秘<a class="headerlink" href="#id53" title="此标题的永久链接">¶</a></h4>
<section id="id54">
<h5>有分类器引导<a class="headerlink" href="#id54" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>原始的扩散模型从随机噪声出发，并不能用文本控制内容。于是，OpenAI 在论文中便提出了有分类器引导。</p></li>
<li><p>具体做法是训练一个图像分类器，这个分类器需要在加噪之后的数据上进行训练。在文生图的过程中，每一步去噪都需要使用这个分类器计算梯度，用该梯度修正预测的噪声（对应 DDIM 采样），或者用来修正去噪后的图像（DDPM 采样）。</p></li>
<li><p>有分类器引导的方案需要训练额外的分类器，并且文本对于图像生成的控制能力不强，因此，它逐渐被无分类器引导的方法取代。我们熟悉的 DALL-E 2、Imagen 以及 SD 模型使用的方案都是无分类器引导。</p></li>
</ul>
</section>
<section id="id55">
<h5>无分类器引导<a class="headerlink" href="#id55" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>无分类器引导技术巧妙地引入了一个 Guidance Scale 参数，无需训练额外的分类器，就能实现文本对图像生成的控制。</p></li>
<li><p>具体来说，在每次扩散模型预测噪声的过程中，我们需要使用 UNet 预测两次。两次预测有着不同的目的:一次完成有条件的预测，一次完成无条件的预测。我们通过控制有条件预测和无条件预测的插值，便能更好地平衡生成图像的随机性、多样性和图文一致性。</p></li>
<li><p>缺点:相比有分类器引导，无分类器引导的计算成本几乎是翻倍的！</p></li>
<li><p>第一次预测是用 prompt 文本表征预测噪声结果，我们称之为条件预测。第二次则是使用空字符串的文本表征预测噪声结果，我们称之为无条件预测。</p></li>
</ul>
</section>
<section id="cfg-classifier-free-guidance">
<h5>CFG: Classifier Free Guidance<a class="headerlink" href="#cfg-classifier-free-guidance" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>当训练完成后，文生图的采样过程会用到有条件预测和无条件预测。然后通过引导权重 w（即 Guidance Scale）进行插值。在 WebUI 中，这个参数被称为 CFG Scale，就是 Classifier Free Guidance 的缩写。</p></li>
<li><p>引导权重越大，生成的图像与给定的文本越相关。一般来说，引导权重取 3-15 这个范围。继续加大权重，生成的图像容易出现各种不稳定的问题，如图像过饱和（颜色过于鲜艳以至于失真）。当引导权重设置为 0 时，相当于输入的文本信息对于 AI 绘画结果不产生任何作用，产生的图像内容是完全随机的。</p></li>
</ul>
</section>
</section>
<section id="id56">
<h4>注意力机制是如何起作用的<a class="headerlink" href="#id56" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>SD 的扩散模型是一个 0.86B 的 UNet</p></li>
</ul>
<figure class="align-default" id="id99">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/p1x4p8.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/p1x4p8.jpg" />
<figcaption>
<p><span class="caption-text">经过 VAE 模块之后，我们可以得到 64x64x4 维度的潜在表示。使用这个潜在表示作为 UNet 的输入，可以得到同样维度的输出，预测的是需要去除的噪声值。 UNet 结构如本图所示。</span><a class="headerlink" href="#id99" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>对于 UNet 的编码器部分，潜在表示分别经过 3 个连续的 CADB（CrossAttnDownBlock2D）模块，分辨率从 64x64x4 降采样到 8x8x1280，得到了对应的特征。</p></li>
<li><p>接着，这些特征被送入一个不带注意力机制的 DB（DownBLlock2D）模块和一个 MBCA（MidBlock2DCrossAttn）注意力模块。这样，就完成了 UNet 的特征编码。</p></li>
<li><p>UNet 的解码器部分与编码器部分完全对应，只不过用上采样计算替代了编码器部分的降采样计算。编码器和解码器之间存在跳跃连接，这是为了进一步强化 UNet 模型的表达能力。</p></li>
</ul>
<figure class="align-default" id="id100">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/gXcZhk.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/gXcZhk.jpg" />
<figcaption>
<p><span class="caption-text">CADB 模块的内部结构</span><a class="headerlink" href="#id100" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>对照图解可以看到，CADB 模块包括自注意力模块和交叉注意力模块。我们可以把每个 CADB 中从 ResNetBlock2D 到 FeedForward 的部分，理解成是一层 Transformer，那么图中的 x2 就表示有两层 Transformer 结构。</p></li>
<li><p>在实际操作中，prompt 的文本表征通过交叉注意力模块完成信息注入，用于计算得到对应的 K、V 向量。而 Q 向量源自 CADB 模块中自注意力模块输出的结果。</p></li>
</ul>
</section>
<section id="id57">
<h4>重新探讨图生图<a class="headerlink" href="#id57" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>对于 SD 模型而言，图生图的过程只需要在文生图的基础上做一点改变。在文生图中，我们选择一个随机噪声作为初始潜在表示。在图生图中，我们对原始图像进行加噪，通过重绘强度这个参数控制加噪的步数，然后以加噪的结果作为图像生成的初始潜在表示。</p></li>
</ul>
<figure class="align-default" id="id101">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/KHiBpJ.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/KHiBpJ.jpg" />
<figcaption>
<p><span class="caption-text">注意:去噪过程的步数要与加噪过程步数一致。换句话说，你在原始图像上加了多少步噪声，就要去除多少步噪声。如果去噪步数过少，有可能会得到“不干净”的图片；如果去噪步数过多，得到的结果和原图之间的相似度会有折损。</span><a class="headerlink" href="#id101" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
</section>
<section id="negative-prompt-clip-skip">
<h4>Negative Prompt 和 CLIP Skip<a class="headerlink" href="#negative-prompt-clip-skip" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>进行 AI 绘画的时候，还有一些关键魔法参数，比如反向描述词（Negative Prompt）、CLIP Skip 两个操作。</p></li>
<li><p>首先是反向描述词。其实当我们理解了无分类器引导，反向描述词的作用就非常好理解了。我们知道，正常的无条件预测使用的是空字符串作为 UNet 的输入。我们只需要把无条件预测中的空字符串替换成反向描述词，就能告诉模型不要去生成什么。</p></li>
<li><p>另一个常见魔法操作是“CLIP Skip = 2”这个设置。CLIP 文本编码器是一个深度学习模型，拥有多层神经网络结构。研究表明，使用文本编码器倒数第二层获得的特征要比使用最后一层输出的特征效果更好。</p></li>
</ul>
</section>
<section id="id58">
<h4>小结<a class="headerlink" href="#id58" title="此标题的永久链接">¶</a></h4>
<figure class="align-default">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/2nJCx1.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/2nJCx1.jpg" />
</figure>
</section>
</section>
<section id="stable-diffusion2">
<h3>16|显微镜下的Stable Diffusion2<a class="headerlink" href="#stable-diffusion2" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p>SD 图像变体（Stable Diffusion Reimagine）</p></li>
<li><p>“神雕侠侣”（SDXL）</p></li>
</ul>
<section id="id59">
<h4>SD 图像变体<a class="headerlink" href="#id59" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>在 SD 模型中，图生图能力通过重绘强度这个超参数向原始图像添加噪声，并根据 prompt 文本描述重新去噪得到新图像。这种方式生成的新图像在轮廓上会和原始图像非常接近，而内容和风格上则会更接近文本引导。</p></li>
<li><p>而图像变体，生成的图像与输入图像在色调、构图和人物形象方面具有相似性。</p></li>
</ul>
<figure class="align-default" id="id102">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/5fNQXb.png" src="https://img.zhaoweiguo.com/uPic/2023/09/5fNQXb.png" />
<figcaption>
<p><span class="caption-text">图像变体与图生图的效果图</span><a class="headerlink" href="#id102" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>图生图和图像变体，它们都是以图像为主进行变化。图生图本质是依赖于 prompt 来引导相似轮廓下的内容变化；图像变体则以输入图像为基础，生成具有相似内容但不同样式的图像，过程不需要描述语句的引导。</p></li>
</ul>
</section>
<section id="id60">
<h4>SD 图像变体的使用<a class="headerlink" href="#id60" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>Stable unCLIP 2.1: <a class="reference external" href="https://huggingface.co/stabilityai/stable-diffusion-2-1-unclip">https://huggingface.co/stabilityai/stable-diffusion-2-1-unclip</a></p></li>
<li><p>不需要复杂的 prompt，SD 图像变体功能从图像中提取需要使用的信息，帮助用户生成输入图片的多种变化。</p></li>
<li><p>SD 图像变体实际上是一个全新的 SD 模型，其官方名称为 Stable unCLIP 2.1，与 DALL-E 2 一样，也属于 unCLIP 模型</p></li>
<li><p>SD 图像变体模型是基于 SD2.1 模型微调而来的，能生成 768x768 分辨率的图像。</p></li>
</ul>
</section>
<section id="sdxl">
<h4>SDXL(神雕侠侣)<a class="headerlink" href="#sdxl" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>标准 SD 模型和 SD 图像变体模型，都是 StabilityAI 这家公司推出的开源 AI 绘画模型，在 Hugging Face、Civitai 这些论坛备受追捧。但遗憾的是，Midjourney 在 AI 绘画生成效果上始终一骑绝尘。为了证明 SD 模型同样拥有无限的 AI 绘画潜力，StabilityAI 决定大力出奇迹，开发一款能与 Midjourney 效果相匹配的模型。于是，SDXL 便应运而生。</p></li>
</ul>
<section id="id61">
<h5>初识 SDXL<a class="headerlink" href="#id61" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>2023 年 6 月，Stable Diffusion XL 0.9 正式发布</p></li>
</ul>
<figure class="align-default" id="id103">
<img alt="https://img.zhaoweiguo.com/uPic/2023/09/bnYakI.jpg" src="https://img.zhaoweiguo.com/uPic/2023/09/bnYakI.jpg" />
<figcaption>
<p><span class="caption-text">SDXL 和 DeepFloyd IF、Midjourney v5.2、DALL-E 2 等方案生成效果图对比</span><a class="headerlink" href="#id103" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>SDXL 采用级联模型的方式完成图像生成。所谓级联模型，就是将多个模型按照顺序串联，目的是完成更复杂的任务。</p></li>
</ul>
</section>
<section id="id62">
<h5>SDXL 的使用<a class="headerlink" href="#id62" title="此标题的永久链接">¶</a></h5>
<ul class="simple">
<li><p>官方平台 clipdrop: <a class="reference external" href="https://clipdrop.co/stable-diffusion">https://clipdrop.co/stable-diffusion</a></p></li>
<li><p>dreamstudio: <a class="reference external" href="https://beta.dreamstudio.ai/generate">https://beta.dreamstudio.ai/generate</a></p></li>
<li><p>Colab 链接: <a class="reference external" href="https://colab.research.google.com/github/NightWalker888/ai_painting_journey/blob/main/lesson16/SDXL%E4%BD%BF%E7%94%A8.ipynb">https://colab.research.google.com/github/NightWalker888/ai_painting_journey/blob/main/lesson16/SDXL%E4%BD%BF%E7%94%A8.ipynb</a></p></li>
<li><p>代码中我们加载了 Base 和 Refiner 两个扩散模型，AI 绘画的过程也是使用这两个模型通过“接力”的方式生成的。</p></li>
</ul>
</section>
</section>
</section>
<section id="midjourney">
<h3>17|巅峰画师Midjourney<a class="headerlink" href="#midjourney" title="此标题的永久链接">¶</a></h3>
<section id="id63">
<h4>回顾 Midjourney 的发展<a class="headerlink" href="#id63" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>2019 年的时候，David Holz 卖掉了手中的 Leap Motion 公司，创建了 Midjourney。David 上一家公司做的是手部跟踪器，与我们今天要聊的 AI 绘画没有直接关系。但他的技术背景和创业精神为 Midjourney 的发展奠定了基础。</p></li>
<li><p>2022 年 2 月，Midjourney v1 模型正式推出。紧接着 4 月，v2 版本正式推出；7 月，v3 版本正式推出；11 月，我们熟悉的 v4 版本正式推出；2023 年 3 月，v5 版本正式推出；6 月，v5.2 版本正式推出。我们惊奇地发现，从 v1 到 v5，其实只用了一年时间。</p></li>
<li><p>2022 年 11 月 MJ v4 推出后不久，MJ 公司引入大量二次元数据微调 v4 模型，于是得到了 Nijijourney 这个专注于动漫垂类生成的模型。</p></li>
<li><p>All Midjourney Versions [V1-V5.2] Compared: The Evolution of Midjourney: <a class="reference external" href="https://aituts.com/midjourney-versions/">https://aituts.com/midjourney-versions/</a></p></li>
</ul>
</section>
<section id="id64">
<h4>Midjourney 的长处与不足<a class="headerlink" href="#id64" title="此标题的永久链接">¶</a></h4>
<ul class="simple">
<li><p>缺点</p></li>
<li><p>不能很好的处理“Text-in-Image”的任务</p></li>
<li><p>无法正确地处理帽子颜色和手套颜色</p></li>
</ul>
</section>
</section>
</section>
<section id="ai-8">
<h2>综合演练篇:AI 绘画高手养成计划 (8讲)<a class="headerlink" href="#ai-8" title="此标题的永久链接">¶</a></h2>
<section id="dreamboothlora-ipai">
<h3>18|DreamBooth和LoRA:低成本实现IP专属的AI绘画模型<a class="headerlink" href="#dreamboothlora-ipai" title="此标题的永久链接">¶</a></h3>
<p>3种经典的定制化算法方案，分别是:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Textual Inversion
DreamBooth
LoRA

海外非常流行的 LensaAI 和国内风靡一时的“妙鸭相机”
</pre></div>
</div>
<section id="textual-inversion">
<h4>Textual Inversion<a class="headerlink" href="#textual-inversion" title="此标题的永久链接">¶</a></h4>
<figure class="align-default" id="id104">
<img alt="https://img.zhaoweiguo.com/uPic/2023/10/UQ522b.jpg" src="https://img.zhaoweiguo.com/uPic/2023/10/UQ522b.jpg" />
<figcaption>
<p><span class="caption-text">SD 词嵌入向量的使用方式:输入的 prompt 首先会经过 tokenizer 完成分词，得到每个分词的 token_id。之后在预训练的词嵌入库中根据 token_id 拿到词嵌入向量，并将这些词嵌入向量拼接在一起，输入到 CLIP 的文本编码器。接着，经过 CLIP 文本编码器提取到的文本表征，便可以通过交叉注意力机制控制图像生成。</span><a class="headerlink" href="#id104" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>Textual Inversion 算法的本质是学习一个全新的词嵌入向量，用于指代定制化的内容。其核心思想便是，对于一个给定的物体或者风格，去学习一个全新的词嵌入向量，并绑定一个符号比如 S*，为其分配一个新的 token_id。这样，每次文生图的时候只需要带上 S*，就能生成我们想要定制化的物体或者风格。</p>
</div>
<figure class="align-default" id="id105">
<img alt="https://img.zhaoweiguo.com/uPic/2023/10/1BaW29.jpg" src="https://img.zhaoweiguo.com/uPic/2023/10/1BaW29.jpg" />
<figcaption>
<p><span class="caption-text">图片来源:<a class="reference external" href="https://arxiv.org/pdf/2208.01618.pdf">https://arxiv.org/pdf/2208.01618.pdf</a></span><a class="headerlink" href="#id105" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<figure class="align-default" id="id106">
<img alt="https://img.zhaoweiguo.com/uPic/2023/10/HVNpTl.jpg" src="https://img.zhaoweiguo.com/uPic/2023/10/HVNpTl.jpg" />
<figcaption>
<p><span class="caption-text">对于一个物体或者风格，我们只需要使用 3～5 张图训练，便可以得到新的关键词 S*，从而完成定制化图像生成的任务。</span><a class="headerlink" href="#id106" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<figure class="align-default" id="id107">
<img alt="https://img.zhaoweiguo.com/uPic/2023/10/ziNxOv.jpg" src="https://img.zhaoweiguo.com/uPic/2023/10/ziNxOv.jpg" />
<figcaption>
<p><span class="caption-text">算法原理图</span><a class="headerlink" href="#id107" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Textual Inversion 的训练过程一共分两步。</p></li>
<li><p>第一，我们需要为你提供的关键词（比如 S*），绑定一个新的 token_id，并初始化这个 token_id 对应的词嵌入向量。举例来说，比如原始词嵌入库中包括 20000 个关键词，token_id 对应的数值就是 1～20000，那么我们新增关键词 S* 的 token_id 便应该是 20001。</p></li>
<li><p>第二，准备好前人已经训练好的 AI 绘画模型，比如 Stable Diffusion 模型或者 DALL-E 2 模型。训练过程中 CLIP 文本编码器、UNet 等模型的权重需要全部固定住。按照对应 AI 绘画模型的标准训练方法，在你提供的 3-5 张图片上进行训练。</p></li>
</ul>
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference external" href="/index.html">主页</a></p></td>
<td><p><a class="reference internal" href="../../genindex.html"><span class="std std-ref">索引</span></a></p></td>
<td><p><a class="reference internal" href="../../py-modindex.html"><span class="std std-ref">模块索引</span></a></p></td>
<td><p><a class="reference internal" href="../../search.html"><span class="std std-ref">搜索页面</span></a></p></td>
</tr>
</tbody>
</table>
</section>
</section>
</section>
</section>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%AE%9E%E6%88%98%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html" class="btn btn-neutral float-right" title="零基础实战机器学习" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="AI%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98.html" class="btn btn-neutral" title="AI 大模型系统实战" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>
  
  <div id="gitalk-container"></div>
  <div role="contentinfo">
    <p>
        &copy; Copyright 2010-2025, 新溪-gordon.

    </p>
  </div>
  <div>备案号 <a href="http://www.beian.miit.gov.cn">京ICP备16018553号</a></div><div>Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a></div>. 


</footer>

<script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?042289284b8eb33866001347a3e0b129";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
</script>     
        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'V2025.06',
            LANGUAGE:'zh-CN',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="../../_static/sphinx_highlight.js"></script>
      <script type="text/javascript" src="../../_static/clipboard.min.js"></script>
      <script type="text/javascript" src="../../_static/copybutton.js"></script>
      <script type="text/javascript" src="../../_static/translations.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>

  

  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });


      // var gitalk = new Gitalk({
      //         clientID: '565177626b5d46427009',
      //         clientSecret: 'b2a36e67e1d2a73e43667f46d571c2624f8e1026',
      //         repo: 'knowledge',
      //         owner: 'zhaoweiguo',
      //         admin: ['zhaoweiguo'],
      //         id: location.pathname,      // Ensure uniqueness and length less than 50
      //         distractionFreeMode: false  // Facebook-like distraction free mode
      //       })
      // gitalk.render('gitalk-container')

  </script>


<script type="text/javascript" src="../../_static/js/table-of-contents-sidebar.js"></script>
<!-- <script type="text/javascript" src="https://table-of-contents-sidebar.github.io/table-of-contents-sidebar-lib/table-of-contents-sidebar.js"></script> -->
<script type="text/javascript">
    window.onload = function(e){
        TableOfContents.init({
            basePath: "https://table-of-contents-sidebar.github.io/table-of-contents-sidebar-lib/",
            querySelector: "body" // or other css querySelector
        });
    }
</script> 

</body>
</html>