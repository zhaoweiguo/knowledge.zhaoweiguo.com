论文
####

通用
====

.. toctree::
   :maxdepth: 1

   papers/normals/normal
   papers/normals/website




Agents
======

.. toctree::
   :maxdepth: 1

   papers/Agents/2210.03629_ReAct
   papers/Agents/2303.08268_Chat-with-the-Environment
   papers/Agents/2303.11366_Reflexion
   papers/Agents/2303.16434_TaskMatrix.AI
   papers/Agents/2304.03442_Generative-Agents
   papers/Agents/2307.07924_ChatDev
   papers/Agents/2308.00352_MetaGPT
   papers/Agents/2308.04026_AgentSims
   papers/Agents/2308.08155_AutoGen
   papers/Agents/2308.10848_AgentVerse
   papers/Agents/2310.06117_Step-Back
   papers/Agents/2402.18679_MetaGPT_DI
   papers/Agents/2407.07061_IoA
   papers/Agents/2408.08435_ADAS
   papers/Agents/2410.17238_SELA
   papers/Agents/2410.10762_AFlow
   papers/Agents/2410.21012_FACT
   papers/Agents/2504.01990_foundation-agents
   papers/Agents/2506.12508_AgentOrchestra



视觉 Agent&AIOS
===============

.. toctree::
   :maxdepth: 1

   papers/Agent_Visions/2312.13771_AppAgent
   papers/Agent_Visions/2402.07939_UFO
   papers/Agent_Visions/2406.01014_Mobile-Agent-v2
   papers/Agent_Visions/2501.11733_Mobile-Agent-E
   papers/Agent_Visions/2501.12326_UI-TARS
   papers/Agent_Visions/2502.14282_PC-Agent.md
   papers/Agent_Visions/2403.16971_AIOS
   papers/Agent_Visions/2504.14603_UFO2






大模型调优
==========

.. toctree::
   :maxdepth: 1


   papers/LLMFineTunes/2101.00190_Prefix-Tuning
   papers/LLMFineTunes/2103.10385_p-tuning
   papers/LLMFineTunes/2104.08691_Prompt_Tuning
   papers/LLMFineTunes/2106.09685_LoRA
   papers/LLMFineTunes/2401.01335_Self-Play
   papers/LLMFineTunes/2402.09353_DoRA.rst
   papers/LLMFineTunes/2402.12354_LoRA+
   papers/LLMFineTunes/2403.03507_GaLore
   papers/LLMFineTunes/2403.13372_LlamaFactory

   papers/LLMFineTunes/a/2203.02155_InstructGPT
   papers/LLMFineTunes/a/2305.20050_LetsVerifyStepbyStep
   papers/LLMFineTunes/a/2408.03314_Scaling_LLM_Test-Time_Compute_Optimally
   papers/LLMFineTunes/a/2412.14135_Scaling_of_Search_and_Learning




分布式模型
==========

.. toctree::
   :maxdepth: 1

   papers/LLMFineTunes/Parallelism/normal
   papers/LLMFineTunes/Parallelism/1701.06538_MoE
   papers/LLMFineTunes/Parallelism/1806.03377_PipeDream
   papers/LLMFineTunes/Parallelism/1811.06965_GPipe
   papers/LLMFineTunes/Parallelism/1909.08053_Megatron-LM
   papers/LLMFineTunes/Parallelism/1910_PipeDream2
   papers/LLMFineTunes/Parallelism/2006.15704DataParallel
   papers/LLMFineTunes/Parallelism/2006.16668_GShard
   papers/LLMFineTunes/Parallelism/2006.09503_PipeDream-2BW
   papers/LLMFineTunes/Parallelism/2104.04473_Megatron-LM2
   papers/LLMFineTunes/Parallelism/2205.14135_FlashAttention
   papers/LLMFineTunes/Parallelism/2307.08691_FlashAttention2




LLM NLP
=======

.. toctree::
   :maxdepth: 1

   papers/LLMs/18_GPT1
   papers/LLMs/1810.04805_BERT
   papers/LLMs/19_GPT2
   papers/LLMs/2012.00413_CPM
   papers/LLMs/2302.13971_LLaMA
   papers/LLMs/2307.09288_Llama2
   papers/LLMs/2309.16609_Qwen
   papers/LLMs/2401.14196_DeepSeek-Coder
   papers/LLMs/2404.06395_MiniCPM
   papers/LLMs/2405.04434_DeepSeek-V2
   papers/LLMs/2406.12793_ChatGLM
   papers/LLMs/2407.10671_Qwen2
   papers/LLMs/2412.15115_Qwen2.5
   papers/LLMs/2505.09388_Qwen3


LLM MoE
=======

.. toctree::
   :maxdepth: 1

   papers/LLMMoEs/2410.07490_MoDEM
   papers/LLMMoEs/2408.15664_AUXILIARY-LOSS-FREE_LB


LLM 多模态
==========

.. toctree::
   :maxdepth: 1

   papers/LLMMultimodals/2304.08485_LLaVA
   papers/LLMMultimodals/2308.12966_Qwen-VL
   papers/LLMMultimodals/2310.03744_LLaVA2.md
   papers/LLMMultimodals/2312.07533_VILA
   papers/LLMMultimodals/2403.05525_DeepSeek-VL
   papers/LLMMultimodals/2408.01800_MiniCPM-V
   papers/LLMMultimodals/2409.17146_Molmo_and_PixMo
   papers/LLMMultimodals/2411.00774_Freeze-Omni
   papers/LLMMultimodals/2412.04468_NVILA
   papers/LLMMultimodals/2502.13923_Qwen2.5-VL
   papers/LLMMultimodals/2503.20215_Qwen2.5-Omni
   papers/LLMMultimodals/2506.13642_Stream-Omni


LLM 音频
=========

.. toctree::
   :maxdepth: 1

   papers/LLMAudio/2005.08100_Conformer
   papers/LLMAudio/2112.02418_YourTTS
   papers/LLMAudio/2212.04356_whisper
   papers/LLMAudio/2301.02111_Vall-E
   papers/LLMAudio/2303.03926_VALL-E_X
   papers/LLMAudio/2406.05370_VALL-E2
   papers/LLMAudio/2407.05407_CosyVoice
   papers/LLMAudio/2407.10759_Qwen2-Audio
   papers/LLMAudio/2410.00037_Moshi
   papers/LLMAudio/2412.10117_CosyVoice2
   papers/LLMAudio/2501.06282_MinMo
   papers/LLMAudio/2505.02707_Voila
   papers/LLMAudio/2505.17589_CosyVoice3


LLM强化学习
===========

.. toctree::
   :maxdepth: 1

   papers/LLMRLs/1703.03864_EvolutionStrategies
   papers/LLMRLs/2504.02495_DeepSeek_GRM
   papers/LLMRLs/2504.13958_ToolRL



LLM 量化
========

.. toctree::
   :maxdepth: 1

   papers/LLMQuantizations/0normal
   papers/LLMQuantizations/2110.02861_bitsandbytes
   papers/LLMQuantizations/2206.01861_ZeroQuant
   papers/LLMQuantizations/2206.09557_LUT-GEMM
   papers/LLMQuantizations/2208.07339_LLM.int8
   papers/LLMQuantizations/2209.05433_FP8
   papers/LLMQuantizations/2210.17323_GPTQ
   papers/LLMQuantizations/2211.10438_SmoothQuant
   papers/LLMQuantizations/2305.14314_QLoRA
   papers/LLMQuantizations/2306.00978_AWQ
   papers/LLMQuantizations/2309.05516_AutoRound


LLM 闭源模型
=================

.. toctree::
   :maxdepth: 1

   papers/LLMCommercials/2303.08774_GPT4
   papers/LLMCommercials/2312.11805_Gemini
   papers/LLMCommercials/2403.05530_Gemini1.5
   papers/LLMCommercials/2503.20020_Gemini2



3D
====

.. toctree::
   :maxdepth: 1

   papers/3D/2003.08934_NeRF
   papers/3D/2203.08586_VanishingPointEstimation
   papers/3D/2312.14132_DUSt3R
   papers/3D/2406.09756_MASt3R
   papers/3D/2412.09401_SLAM3R
   papers/3D/2412.12392_MASt3R-SLAM
   papers/3D/2503.11651_VGGT



LLM 安全
========

.. toctree::
   :maxdepth: 1

   papers/LLMSecuritys/2312.06674_Llama_Guard

Benchmarking
============

.. toctree::
   :maxdepth: 1

   papers/Benchmarkings/0normal
   papers/Benchmarkings/2009.03300_MMLU
   papers/Benchmarkings/2103.03874_MATH
   papers/Benchmarkings/2311.12022_GPQA
   papers/Benchmarkings/2311.12983_GAIA
   papers/Benchmarkings/2404.07972_OSWorld
   papers/Benchmarkings/2411.04368_SimpleQA
   papers/Benchmarkings/2501.14249_HLE




数据集&数据蒸馏
===============

.. toctree::
   :maxdepth: 1

   papers/DataSets/normal
   papers/DataSets/1811.10959v3_Dataset_Distillation
   papers/DataSets/2112.15093_CTR
   papers/DataSets/2502.20653_Dataset_Distillation



Framework
=========

.. toctree::
   :maxdepth: 1

   papers/Frameworks/1712.05889_Ray
   papers/Frameworks/1910.02054_DeepSpeed_ZeRO
   papers/Frameworks/19XX_PyTorch
   papers/Frameworks/20XX_Transformers
   papers/Frameworks/2210.XX_Ray_v2
   papers/Frameworks/2309.06180_vLLM





ML
====

.. toctree::
   :maxdepth: 1

   papers/MLs/2112.09332_WebGPT
   papers/MLs/2203.11147_GopherCite
   papers/MLs/2305.14251_FActScore
   papers/MLs/2304.09848_Generative_Search
   papers/MLs/2307.02185_Citation
   papers/MLs/2307.16883_HAGRID
   papers/MLs/2305.14627_ALCE



ML 多模态相关
=============

.. toctree::
   :maxdepth: 1

   papers/MLMultimodals/2108.03353_Screen2Words
   papers/MLMultimodals/2209.08199_ScreenQA
   papers/MLMultimodals/2212.06817_RT-1
   papers/MLMultimodals/2401.10935_SeeClick
   papers/MLMultimodals/2402.04615_ScreenAI
   papers/MLMultimodals/2411.02059_TableGPT2




ML Vision
=========

.. toctree::
   :maxdepth: 1

   papers/MLVisions/1506.02640_YOLO
   papers/MLVisions/1612.08242_YOLO9000
   papers/MLVisions/1804.02767_YOLOv3
   papers/MLVisions/2004.10934_YOLOv4
   papers/MLVisions/2205.00159_SVTR
   papers/MLVisions/2207.02696_YOLOv7
   papers/MLVisions/2303.05499_GroundingDINO
   papers/MLVisions/2304.08485_VisualInstructionTuning
   papers/MLVisions/2402.13616_YOLOv9
   papers/MLVisions/2405.14458_YOLOv10
   papers/MLVisions/2411.15858_SVTRv2





RAG
===


.. toctree::
   :maxdepth: 1

   papers/RAGs/2005.11401_RAG_for_KI_NLP_task
   papers/RAGs/2312.10997_RAG_for_LLM
   papers/RAGs/2401.15884_CRAG
   papers/RAGs/2403.14403_Adaptive-RAG
   papers/RAGs/2404.16130_GRAG
   papers/RAGs/2405.16506_GRAG
   papers/RAGs/graphrag
   papers/RAGs/2406.13213_Multi-Meta-RAG
   papers/RAGs/2410.10450_KBLaM
   papers/RAGs/2504.03137_LightPROF


Tools
=====


.. toctree::
   :maxdepth: 1

   papers/Tools/2205.00445_MRKL
   papers/Tools/2302.04761_Toolformer
   papers/Tools/2303.17580_HuggingGPT




AGI
===

.. toctree::
   :maxdepth: 1

   papers/AGIs/1905.10985_AI-GA
   papers/AGIs/2408.06292_AI-Scientist

others
======


.. toctree::
   :maxdepth: 1

   papers/others/A PAINLESS GUIDE TO CRC ERROR DETECTION ALGORITHMS
   papers/others/Distributed Representations of Sentences and Documents
   papers/TODO




* Highlighting the top ML papers every week: https://github.com/dair-ai/ML-Papers-of-the-Week














