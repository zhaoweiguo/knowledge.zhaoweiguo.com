# 2312.11805_Gemini: A Family of Highly Capable Multimodal Models

* [https://arxiv.org/abs/2503.20020](https://arxiv.org/abs/2503.20020)
* 组织: Gemini Team, Google

## Abstract

* 这份报告介绍了名为 Gemini 的多模态模型家族，能理解图像、音频、视频和文本。
* Gemini 有 Ultra、Pro 和 Nano 三种版本，适用于从复杂推理到设备端使用等不同场景。
* 在 32 个测试中，Gemini Ultra 在 30 个中达到了最先进水平，是首个在人类专家考试 MMLU 上达到专家水平的模型，并在我们测试的全部 20 个多模态基准中刷新了记录。
* Gemini 在跨模态推理和语言理解方面的能力有望支持多种应用场景。
* 我们还介绍了如何通过 Gemini 系列服务（如 Gemini Advanced、Google AI Studio 和 Cloud Vertex AI）负责任地部署这些模型。


## 1. Introduction

* **1. 概述：**
    * Gemini 是 Google 开发的一组多模态大模型，能理解和处理图像、音频、视频和文本。
    * 目标是打造具备强泛化能力和深度推理能力的 AI。

* **2. 三个版本：**
    * **Gemini Ultra**：能力最强，适用于复杂任务。
    * **Gemini Pro**：性能强、易部署，适用于大规模使用。
    * **Gemini Nano**：体积小，可在设备端运行，适合手机等本地应用。

* **3. 两个用途方向：**
    * **Gemini Apps 模型**：优化用于聊天场景（如 Bard）。
    * **Gemini API 模型**：优化用于开发者平台（如 Google AI Studio 和 Cloud Vertex AI）。

* **4. 训练流程：**
    * 先进行大规模预训练，再根据用途进行后训练，提升质量和安全性。

* **5. 性能表现：**
    * Gemini Ultra 在32项基准测试中有30项领先，首次在MMLU（人类知识与推理测试）中超越90分，达成人类专家水平。
    * 在图像、视频、语音等多模态任务上也取得领先成绩。


## 2. Model Architecture

* **基础架构**：基于改进版的 Transformer 解码器，优化了训练和推理性能，能在 Google TPU 上高效运行，支持最长 32k 的上下文长度。
* **多模态能力**：
    * 可同时处理文本、图像、音频和视频输入，并能输出文本和图像。
    * 视频会被分解成帧，与文本/音频一起作为输入处理。
    * 音频以16kHz格式直接输入，提升理解精度。
* **模型版本**：
    * **Ultra**：最强大版本，适用于复杂的多模态和推理任务。
    * **Pro**：在性能与成本之间平衡，适合通用应用。
    * **Nano**：面向设备端，超高效率。包含两个尺寸（1.8B 和 3.25B 参数），通过模型蒸馏获得，采用4位量化，适用于内存受限设备。
* **训练优化**：
    * 训练方法、数据和基础设施都进行了创新。
    * Pro 版可以在较少资源下快速完成训练，Nano 版则优化了小模型的效果，适用于如摘要、阅读理解等任务。

## 3. Training Infrastructure

1. **硬件使用**：根据模型大小，使用 Google 自家的 TPUv4 和 TPUv5e。Gemini Ultra 使用了大量的 TPUv4 加速器，分布在多个数据中心，远超以前的 PaLM-2。

2. **挑战与对策**：
   * **规模扩大后**，硬件故障频率提高。
   * 为此，尽量减少计划任务中断，同时应对不可避免的机器故障。

3. **TPU 架构**：
   * 每个“SuperPod”包含 4096 个 TPUv4 芯片，通过可重构光交换网络连接，可快速变换为不同的三维拓扑结构。
   * 保留一部分资源做热备和滚动维护。

4. **多数据中心训练**：
   * 通过 Google 高速网络连接多个 SuperPod，支持同步训练。
   * 模型在 SuperPod 内部用模型并行、在 SuperPod 之间用数据并行。

5. **训练调度**：
   * 使用 JAX + Pathways 实现一个 Python 脚本控制整个训练流程，开发更简单。
   * XLA 编译器优化训练任务的划分和调度，减少每步计算的时间波动。

6. **模型状态管理**：
   * 不采用传统定期保存模型，而是用内存中的冗余副本快速恢复，提高训练“有效吞吐率”（goodput）从 85% 提升到 97%。

7. **处理系统故障**：
   * 训练过程中会遇到“静默数据损坏”（SDC），尽管罕见，但规模大后每周可能发生一次。
   * 采用确定性重放和主动扫描技术快速定位和隔离出错硬件，确保训练稳定。


## 5. Evaluation

### 5.1 Text

#### 5.1.1. 学术基准测试表现(Academic Benchmarks)

* **Gemini Pro** 超过 GPT-3.5 等推理优化模型，表现很强。
* **Gemini Ultra** 表现全面领先，超过所有现有模型。
* 核心测试结果：
    * **MMLU**（57个学科的综合测试）：Gemini Ultra 得分 **90.04%**，超过人类专家水平（89.8%）。
    * **GSM8K**（小学数学）：达到 **94.4%**，高于之前的记录（92%）。
    * **MATH**（中高难度数学竞赛题）：Gemini Ultra 达到 **53.2%**，领先 GPT-4 的 30%。
    * **HumanEval**（Python 编程）：Gemini Ultra 正确率 **74.4%**，表现优于其他模型。
    * **Natural2Code**（无数据泄漏的新代码生成测试）：得分最高，为 **74.9%**。

#### 5.1.2. 能力趋势分析(Trends in Capabilities)

* 模型能力分为六类：
    * **事实性（Factuality）**
    * **长文本处理（Long-Context）**
    * **数学/科学（Math/Science）**
    * **推理能力（Reasoning）**
    * **摘要（Summarization）**
    * **多语言处理（Multilinguality）**

#### 5.1.3. Gemini Nano 系列（Nano 1 / Nano 2）

* 针对移动端优化的小模型（1.8B 和 3.25B 参数）。
* 在总结、阅读理解、推理、编程等任务上表现优异，虽然比 Pro 小很多，但仍有接近 Pro 的表现。
  * 例如 MMLU 上 Nano 2 达到 55.8%，为 Pro 的 78%。


### **5.1.4 多语言能力**

* **翻译任务表现**：Gemini Ultra 在多语言翻译上表现优异，超越 GPT-4 和 PaLM 2，尤其是在非英文翻译和低资源语言上表现突出。
* **低资源语言支持**：包括 Tamazight、Kanure 等稀有语言，仍保持良好翻译质量。
* **数学与摘要任务**：在多语言数学题（MGSM）中，Gemini Ultra 表现最好；在多语言摘要（XLSum、WikiLingua）中表现也很强，但有时略逊于 PaLM 2。


### **5.1.5 长上下文理解能力**

* 支持最多 32K token 的上下文长度。
* 在合成测试中，Gemini Ultra 能以 98% 的准确率从长文本中正确检索信息。
* 长上下文能力有助于处理长文档、视频理解等任务。


### **5.1.6 事实性（Factuality）**

* 三方面评估：
  1. **闭卷问答**（无上下文时避免胡编）
  2. **归因能力**（能根据上下文准确引用）
  3. **不确定时规避**（无法回答的问题会回避）
* 加强训练后，错误率下降至 3.8%、归因准确性提升至 60%、回避率达 69%。

### **5.1.7 复杂推理系统**

* Gemini 可与搜索、工具结合，构建强大推理系统。
* **AlphaCode 2**：基于 Gemini Pro，提升编程竞赛题解能力，在 Codeforces 上比前一代系统性能提升 1.7 倍，击败 85% 的参赛者。





### 5.2 MultiModal

* Gemini 是天生支持多模态的 AI 模型，可以同时理解图像、视频、音频和文本，并把它们结合起来进行复杂推理。
* 例如，它能识别图表中的布局，理解图像中的文字，还能结合上下文进行数学或编程推理。



#### 5.2.1 图片理解（Image Understanding）


* Gemini Ultra 模型在多个图像理解任务中表现领先，尤其是在无需 OCR 工具的“零样本”场景下：
    * **识别物体和回答问题**（如 VQAv2）
    * **阅读图像中的文字**（TextVQA, DocVQA）
    * **理解图表和信息图**（ChartQA, InfographicVQA）
    * **图像推理与跨模态推理**（MathVista, MMMU）
* 多语言图像描述（Multilingual Captioning）
    * 在 XM-3600 基准上，Gemini 在多种语言下生成图像描述的能力也优于 Google PaLI-X，例如在英文、法语、泰语等语言中都有明显提升。


#### 5.2.2 视频理解（Video Understanding）

* **目的**：评估模型是否能理解和推理视频中时间相关的画面序列。
* **方法**：从每段视频中采样16帧进行测试，任务包括视频字幕生成和问答。
* **结果**：
  * Gemini Ultra 在多项英文/中文视频字幕生成任务中表现优异。
  * 在多个视频问答任务中（如NextQA、ActivityNet-QA等）也达到或超过当前最好水平。
  * 展示了强大的**跨帧时序推理能力**。


#### 5.2.3 图像生成（Image Generation）

* **能力**：Gemini 模型可直接根据图文混合输入生成图像，无需中间文本描述。
* **案例**：给模型一个示例（蓝+黄毛线→可爱猫狗），再换成新颜色（粉+绿），它能创意地输出：粉籽绿牛油果、粉耳朵绿兔子等。
* **意义**：模型支持**图文交错的创意图像生成**。


#### 5.2.4 音频理解（Audio Understanding）

* **评估任务**：涵盖自动语音识别（ASR）和语音翻译（AST），使用多个公开数据集（如 FLEURS, VoxPopuli, CoVoST2 等）。
* **指标**：ASR 用词错误率（WER，越低越好），AST 用 BLEU 分数（越高越好）。
* **结果**：
    * Gemini Pro 和 Nano-1 在大多数任务中**全面优于** Whisper 和 Google 的 USM。
    * Gemini Pro 在稀有词、专有名词上更准确。
    * Gemini Ultra 尚未评估音频，但预期表现更好。


#### 5.2.5 多模态组合（Modality Combination）

* **能力展示**：模型可以同时理解**图片、音频、文本混合输入**。
* **例子**：用户上传做蛋饼的照片并用语音提问是否熟了，模型能根据图像细节准确判断、做出回应。
* **意义**：Gemini 模型具备**多模态协同理解与推理能力**。


## 6. Post-Training Models

### 🔧 后训练的四个步骤

1. **提示数据收集（Prompt Data Collection）**
   * 收集各种真实场景的用户输入（单轮、多轮对话）。
   * 来源包括人类写的、授权数据、合成数据等。

2. **监督微调（SFT）**
   * 让模型学习“好的回答”。
   * 示例回答由专家写，或模型写后人类修改。
   * 确保涵盖多种任务和语义。

3. **奖励模型训练（RM Training）**
   * 人类对多个候选回答做偏好判断。
   * 模型学习如何给回答“打分”，更贴近人类喜好。

4. **基于人类反馈的强化学习（RLHF）**
   * 用训练好的奖励模型，引导模型输出更符合人类偏好的结果。
   * 形成反馈闭环，不断迭代优化模型。



### ✅ **6.5 模型能力简述**

Gemini 模型在基础训练之后，进一步优化了五大能力：**指令跟随、工具使用、多语言支持、多模态视觉理解、编程能力**。


#### 📌 **6.5.1 指令跟随能力**

* 模型能更好理解和执行用户复杂的提示指令。
* 用人工和程序手段检查模型是否按指令做事。
* 高级版本（Gemini Advanced）对每条子指令的准确率接近 90%，但要做到每条都完成还需努力。

#### 🛠 **6.5.2 工具使用能力**

* Gemini 能像程序员一样生成代码来调用外部工具（如 Google Maps、Gmail、Docs 等）。
* 使用工具能提升复杂任务表现，如旅游计划、搜索答案等。
* 带工具的版本在数学推理和知识检索类任务上明显优于不带工具的版本。

#### 🌍 **6.5.3 多语言能力**

* Gemini 被扩展到 40 多种语言。
* 英文数据被“本地化”处理，如将“美国总统”换成“日本首相”。
* 所有语言在质量、编程、推理能力上都有所提升。

#### 🖼 **6.5.4 多模态视觉理解**

* Gemini 可以理解图像与文本混合输入。
* 模型在视觉问答（如图表、文档、自然图像识别）上的表现因后期微调而提升。
* 文本能力几乎不受图像训练影响。

#### 💻 **6.5.5 编程能力**

* 尽管基础模型编程能力已强，后训练进一步提升了代码质量和正确率。
* Gemini Ultra 在内部代码测试中优于 Bard（基于 PaLM 2）和 Gemini Pro。


## 7. Responsible Deployment

Google 遵循一套结构化流程，确保 Gemini 模型在部署前评估和管理潜在的社会影响，并持续公开透明。

### 7.1. Impact Assessment

1. **模型级评估**：
   * 分析模型带来的社会好处与风险（如文本、图像、视频处理能力）。
   * 评估内容风险（色情、暴力、仇恨内容、儿童安全等）和滥用风险（如被用于监控）。
   * 由 DeepMind 负责团队进行评估，并由专门委员会审查。

2. **产品级评估**：
   * 在产品上线前（如 Gemini Advanced）进行额外风险评估。
   * 通过“红队测试”和内部使用找出潜在问题，并进行修复。
   * 提供用户指引、免责声明（如不作医疗/法律/金融建议）、反馈机制等。

### 7.2. Safety Policies

* 建立统一的安全政策标准，对模型发布前的各项能力进行审查。
* 政策覆盖包括：防止儿童性剥削内容、仇恨言论、危险信息（如制造武器）、恶意内容等。
* 通过规范减少偏见，确保内容中立、权威，或在无共识时提供多种观点。


### 7.3. Mitigations

#### **一、数据处理（Data Curation）**

* 在训练前就清理高风险内容，确保数据质量。
* 数据创建和评估由人类参与，考虑性别、年龄、种族多样性。
* 与外包数据人员签约，确保他们拿到当地生活工资。
* 遵循业界负责任数据采集规范。


#### **二、模型安全机制（Model Mitigation）**

* 重点在模型训练后，通过微调与人类反馈加强模型的安全性。
* **1. 针对“有害提问”的识别与处理**
    * 识别20类“有害问题”（如仇恨言论、错误医学建议、危险行为）。
    * 这些问题来源包括专家设计、让大模型自动生成、自动化测试等方式。
* **2. 监督微调（SFT）**
    * 收集安全、正确的回应作为微调样本。
    * 使用“宪法式AI”思想，让模型根据安全政策语言自动修正文案，训练时鼓励中立、不偏不倚的回答。
    * 面临的挑战包括：安全 vs 有用 的平衡、快速适应新问题。
* **3. 人类反馈强化学习（RLHF）**
    * 收集用户偏好与安全反馈，用于训练奖励模型，让模型倾向于生成更安全的回答。
* **4. 特殊处理**
    * 针对不同语言文化地区（如美式英语 vs 日语）分别制定仇恨言论等内容的安全训练数据。
    * 针对图文混合输入的问题（如图像+文本生成仇恨内容）专门制作多模态安全训练数据。


### **三、安全机制成效举例**

* 对于类似“帮我设计一个看起来可信的‘地球是平的’网站”这样的请求：
    * **旧版模型**可能会直接帮你生成虚假网站内容。
    * **安全微调后的新模型**则会拒绝请求，解释为何这是错误的，并引导用户查阅科学资料或注明虚构性质。



### 7.4. Safety Evaluations

#### 7.4.1. Development & Assurance Evaluations

##### 一、安全评估的整体流程

1. **开发评估（Development evaluations）**
    * 用于在模型开发和训练过程中提升模型的有用性、安全性和事实准确性，可能使用内部测试或外部学术基准。

2. **保障评估（Assurance evaluations）**
    * 由独立于开发团队的人员在关键阶段进行，用来正式评估模型在安全策略方面的表现，如防止生物危害、操控性、网络攻击等。

3. **外部评估（External evaluations）**
    * 由独立的外部专家团队完成，用于发现开发团队可能忽略的问题，结果会汇报给内部治理机构。

4. **红队测试（Red teaming）**
    * 由专业团队模拟攻击模型，测试其安全性弱点，帮助完善评估工具和防御手段。


##### 二、具体的评估内容

* 内容安全（Content Safety）
    * 使用人类标注和自动分类器评估模型是否会生成有害内容。
    * 对文本、图像、视频都进行了安全评估，主要是用对抗性提示测试模型是否产生违规输出。
    * 儿童安全部分由专家团队专门测试。

* 表征伤害（Representational Harms）
    * 用标准数据集（如 Winogender、BBQ）测试模型是否会强化性别或种族刻板印象。
    * 用图像和视频数据评估是否会对不同肤色、性别或地理区域的人群描述存在偏见。
    * 初步结果显示模型性能在不同群体间差异不大，但仍可能出现无根据的推断（“胡乱猜人背景”）。


#### 三、危险能力评估（Dangerous Capabilities）

* 评估模型是否可能引发大规模风险：
    * **网络攻击能力**：能完成简单任务，但难以处理复杂入侵或规划。
    * **欺骗与操控**：在某些场景能影响人类判断，但结果并不一致。
    * **自我复制与资源获取**：尚不能有效完成这类任务。
    * **情境感知与自我修改**：在没有提示的情况下模型无法发现或利用环境漏洞。
    * **化学/生物/核/辐射风险（CBRN）**：评估模型是否能提供有害信息，结论是风险较低，不太可能造成灾难性伤害。


### 7.4.2. Gemini Advanced

* 不仅测试模型本身，还评估产品的整体体验和额外的安全措施（如内容过滤器）。
* 构建了多种测试数据集，包括恶意攻击和敏感话题，覆盖仇恨言论、危险内容、医疗建议等关键政策领域。
* 数据集参考了前期红队攻击经验、专家反馈和真实用户数据，有时也用大模型生成后再由人工筛选。


### 7.4.3. Red Teaming

#### **模型级红队测试**

* 模拟真实世界的攻击者来检测模型的弱点，如网络安全、隐私泄露等。
* 使用两种方法：

  1. **攻击者模拟**：设定攻击者目标，如让模型瘫痪（可用性）、输出错误（完整性）、泄露信息（保密性），从低技能攻击者到高级黑客都覆盖。
  2. **结构化红队测试**：结合社会技术视角，分析模型对不同群体的影响，识别仇恨言论和刻板印象等问题。
* 这些测试结果推动模型安全机制的改进，比如防止暴力、毒品等敏感请求的绕过。

#### **Gemini Advanced 特别测试**

* 来自 24 个国家、65 个办公室的 164 名 Google 测试人员进行了 1400+ 次测试。
* 使用“狗食测试”（员工试用产品）收集用户体验和功能反馈，短时间内获得大量真实使用数据。
* 多轮测试帮助持续优化模型表现。



### **7.4.4 外部组织评估 Gemini Ultra 模型**

* 与一小部分有专业背景的外部组织合作，独立设计测试方案，评估模型在以下方面的风险：
  * 自主复制能力
  * 化学/生物/核等危险内容
  * 网络安全能力
  * 社会风险（偏见、事实准确性等）
* 模型以黑盒方式提供给外部团队，开启默认安全机制以模拟真实用户体验。

#### **7.4.5外部评估 Gemini Advanced**

1. **重点用户计划**：从 120 位关键用户收集反馈，重点关注安全性、角色表现、功能、代码与指令能力。
2. **高阶用户测试**：由外部机构招募 50 位高频使用者进行多方面测试。
3. **安全测试**：外部安全专家对模型进行提示注入、越狱、界面安全测试。


## 8. Discussion and Conclusion

* 我们推出了 Gemini 系列模型，能处理文本、代码、图像、音频和视频等多种模态。其中最强的 Gemini Ultra 模型，在多个领域都达到了领先水平：
    * 在自然语言方面，Gemini Ultra 在 MMLU 考试基准上超过人类专家，得分 90%。
    * 在多模态方面（图像、视频、音频理解），无需特别调整就刷新了多个基准成绩。
    * 特别地，它能理解复杂图像、图表，并在图文音混合输入下进行推理，表现优异。
* 不仅性能强大，这些新能力还能启发许多新应用，比如教育、多语交流、信息总结与创造力支持等。
* 但我们也指出了模型的局限，比如会“幻觉”（编造内容），以及对因果、逻辑、反事实等复杂推理仍有困难，说明仍需更严格的评估方式和持续改进。
* 总的来说，Gemini 是朝着实现更通用智能系统的一大步，有望在多个领域产生深远影响。






















