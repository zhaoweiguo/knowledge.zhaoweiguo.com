1701.06538_MoE: Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer
###############################################################################################

* https://arxiv.org/abs/1701.06538
* 组织: Google, Jagiellonian University
* Label: MoE






































