2411.02059_TableGPT2: A Large Multimodal Model with Tabular Data Integration
############################################################################

* https://arxiv.org/abs/2411.02059
* GitHub: https://github.com/tablegpt/tablegpt-agent
* 文档: https://tablegpt.github.io/tablegpt-agent/



Abstract
========

* 像GPTs、Claude、LLaMA和Qwen这样的模型的出现已经重塑了人工智能应用，在众多行业中展现了广阔的新机遇。然而，尽管表格数据在许多现实世界的领域中扮演着基础性角色，其集成的应用仍然显著不足。
* 这一差距至关重要的原因有三点。首先，数据库或数据仓库的数据集成对于高级应用至关重要；其次，大量且在很大程度上未被充分利用的表格数据资源为分析提供了巨大的潜力；第三，商业智能领域特别需要灵活而精确的解决方案，这是当前许多大型语言模型（LLMs）可能难以提供的。
* 为此，我们推出了TableGPT2，这是一个经过严格预训练和微调的模型，使用了超过593.8万个表格和236万高质量查询-表格-输出元组，其规模的表格相关数据是前所未有的研究。这种广泛的训练使得TableGPT2在以表格为中心的任务中表现出色，同时保持强大的通用语言和编码能力。
* TableGPT2的关键创新之一是其新颖的表格编码器，专门设计用于捕捉模式级和单元格级别的信息。此编码器增强了模型处理模糊查询、缺失列名和不规则表格的能力，这些都是在实际应用中常见的挑战。类似于视觉语言模型，这种开创性的方法与解码器结合，形成一个强大的大型多模态模型。
* 我们认为结果令人信服：在超过23个基准指标上，TableGPT2相比于之前的无偏向基准大型语言模型，在70亿参数模型中实现了平均35.20%的性能提升，在720亿参数模型中则达到了49.32%的提升，同时保持了稳健的通用功能。


































