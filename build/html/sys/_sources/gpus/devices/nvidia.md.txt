# Nvidia通用GPU

## NVIDIA产品系列


### 消费级GPU系列-GeForce系列


```note
消费级游戏和娱乐
```


* Nvidia GeForce RTX 2080 Ti - 这是Turing架构的旗舰显卡,于2018年发布。它拥有4352个CUDA核心,11GB GDDR6视频内存,接口为PCIe 3.0 x16。2080 Ti在发布时是性能最强的消费级显卡
* Nvidia GeForce RTX 3080 - 这是Ampere架构的高端显卡,于2020年发布。它拥有8704个CUDA核心,10GB GDDR6X视频内存,接口为PCIe 4.0
* NVIDIA GeForce RTX 3060 - 这是Ampere架构的入门级显卡,于2021年发布。它拥有3584个CUDA核心,12GB GDDR6视频内存,接口为PCIe 4.0
* NVIDIA GeForce RTX 3060 Mobile - 这是Ampere架构的移动版GPU,于2021年发布。它有1024-2560个CUDA核心,6GB或8GB GDDR6视频内存
* NVIDIA GeForce RTX 3090: 较大的显存（24GB）



### 专业级GPU系列-Quadro系列


```note
面向专业图形应用
```


* Quadro系列是NVIDIA面向专业图形应用市场的GPU产品系列，包括设计、视觉化和虚拟现实等领域


| 旧名称           | 新名称             | 代表产品              |
| ------------- | --------------- | ----------------- |
| Quadro RTX    | NVIDIA RTX A 系列 | RTX A6000、A5000 等 |
| Quadro P 系列   | 基于 Pascal 架构    | Quadro P5000 等    |
| Quadro M/K 系列 | 较老的架构           | M4000、K6000 等     |



### 专业级GPU系列-Tesla系列


```note
针对HPC和数据中心
```


* Tesla系列是NVIDIA针对高性能计算（HPC）和数据中心应用而设计的GPU产品系列


| 旧名称（Tesla） | 新名称            | 架构         | 应用场景     |
| ---------- | -------------- | ---------- | -------- |
| Tesla V100 | A100 / H100 前身 | Volta 架构   | AI训练、HPC |
| A100       | Ampere         | 数据中心 AI    | 训练/推理    |
| H100       | Hopper         | 超大模型训练     |          |
| H200       | Hopper + HBM3e | LLM 加速     |          |
| B100（未发）   | Blackwell      | 下一代 AI GPU |          |




### 面向自动驾驶/边缘计算的 GPU 系列-Jetson 系列


* 用于边缘 AI 和嵌入式计算平台，广泛用于机器人、无人车、工业设备等：


| 系列          | 代表产品              | 核心架构           |
| ----------- | ----------------- | -------------- |
| Jetson AGX  | AGX Orin、Xavier   | Ampere、Volta 等 |
| Jetson NX   | Orin NX、Xavier NX |                |
| Jetson Nano | Nano、Nano 2GB     | Maxwell        |







## 常用显卡

NVIDIA L20::

    GPU: 48G
    内存: 96G
    CPU: 32vCPU

    显存：48 GB GDDR6，带宽 864 GB/s





NVIDIA H20::

    GPU: 96G
    内存: 240G
    CPU: 22vCPU



## GPU架构


### Ada Lovelace架构


* 代表产品::

    GeForce RTX 4080
    GeForce RTX 4090(旗舰级桌面GPU)
    NVIDIA L20(针对中国市场)
    NVIDIA L40


* 特点：专为光线追踪和基于AI的神经图形设计，引入了第四代Tensor Core和第三代RT Core。



### Pascal架构

* **Tesla P4** 基于 Pascal 架构，这与后来更为常见的 Volta 和 Ampere 架构相比属于上一代


### Volta架构


* **Tesla V100** : ``Volta架构`` 的一部分。它采用了16nm FinFET工艺，具有5120个CUDA核心和16GB到32GB的HBM2显存。



### Ampere架构


* **Tesla A100**: 目前世界上最强大的数据中心GPU之一，采用了全新的``Ampere架构``，具有高达6,912个CUDA核心和40GB的高速HBM2显存。A100还包括第二代NVLink技术，可实现高速的GPU到GPU通信，从而加快大型模型的训练速度。此外，A100还支持英伟达自主研发的Tensor Cores加速器，可在深度学习中提供高达20倍的性能提升。


NVIDIA A100 Tensor Core GPU（标准版本）的主要规格::

    架构：Ampere
    CUDA 核心：6912 个
    Tensor 核心：432 个
    显存：40GB 或 80GB HBM2e
    显存带宽：1.6 TB/s
    FP64 性能：9.7 TFLOPS
    FP32 性能：19.5 TFLOPS
    FP16 性能：312 TFLOPS（使用 Tensor Cores）
    功耗：400W（可调至 250W）



```note
A800和H800是英伟达针对中国市场推出的特供版（或称为带宽缩减版）GPU。它们分别基于A100和H100的架构，但在Nvlink最大总网络带宽上有所降低，以适应特定的市场需求和监管要求。
```


### Hopper架构

* **Tesla H100**: 英伟达最新的GPU，基于``Hopper架构``，采用了定制的台积电N4（4纳米）工艺制造。

























