统计-最大似然原理(Maximum Likelihood Principle)
###############################################

* 最大似然原理（Maximum Likelihood Principle）是统计学和机器学习中的一种基本方法，用于从数据中估计模型的参数。它的核心思想是：寻找一组参数，使得在这些参数下，观测到的数据出现的概率最大。
* 最大似然原理是参数估计的核心思想之一，通过最大化观测数据的概率来确定模型参数。在简单问题中，最大似然估计可以通过代数方法解析求解，而在复杂模型中，则需要借助数值优化方法。



核心思想
========

* 假设我们有一个参数化的概率模型  :math:`p(x \mid \theta)` , 其中:
    -  x  是观测数据,
    -  :math:`\theta`  是需要估计的参数。

* 最大似然原理的目标是选择参数  :math:`\theta` , 使得给定数据  x  的似然函数  :math:`L(\theta \mid x)`  最大化:

.. math::

    \hat{\theta}=\arg \max _{\theta} L(\theta \mid x)

    其中:\\
    L(\theta \mid x)=p(x \mid \theta) \\
    即数据  x  在参数  \theta  下的概率

在数据集上的应用
================

* 如果我们有一个独立同分布（i.i.d.）的数据集  :math:`\left\{x_{1}, x_{2}, \ldots, x_{n}\right\}` , 则似然函数是所有样本的联合概率（似然函数是每个样本概率的乘积）：

.. math::

    L\left(\theta \mid x_{1}, x_{2}, \ldots, x_{n}\right)=\prod_{i=1}^{n} p\left(x_{i} \mid \theta\right)


为了方便计算, 我们通常取对数, 将似然函数转化为对数似然函数（对数似然函数则是对每个样本对数概率的和）:

.. math::

    \log L\left(\theta \mid x_{1}, x_{2}, \ldots, x_{n}\right)=\sum_{i=1}^{n} \log p\left(x_{i} \mid \theta\right)


最大似然估计（Maximum Likelihood Estimation, MLE）的目标就是找到参数  :math:`\theta` , 使对数似然函数达到最大值。


举例说明
========

1. 抛硬币问题
-------------

* 假设我们有一个硬币, 目标是估计硬币正面朝上的概率  :math:`\theta`  。给定观测数据  :math:`x=\{H, T, H, H, T\}` ,假设硬币的结果服从伯努利分布：

.. math::

    p(x \mid \theta)=\theta^{k}(1-\theta)^{n-k}

其中::

    -  k  是正面朝上的次数
    -  n  是总实验次数

* 最大似然估计就是找到  :math:`\theta` , 使得  :math:`p(x \mid \theta)`  最大。取对数后, 目标变为:

.. math::

    \log L(\theta)=k \log \theta+(n-k) \log (1-\theta) \\
    对  \theta  求导并设导数为零, 可以得到: \\
    => k(\frac{1}{\theta}) + (n-k)(-1)\frac{1}{1-\theta} =0 \\
    => k(\frac{1}{\theta}) = (n-k)\frac{1}{1-\theta} \\
    => k(1-\theta) = (n-k)\theta \\
    => k = n\theta \\
    => \hat{\theta}=\frac{k}{n},

    即正面朝上的频率。


.. note:: 本示例是直接使用公式算出来。当然算出的结果中参数 ``k`` 是和观测数据 ``x`` 有关的


2. 高斯分布
-----------

* 假设数据服从正态分布  :math:`\mathcal{N}\left(\mu, \sigma^{2}\right)` , 参数为均值  :math:`\mu`  和方差  :math:`\sigma^{2}`  。给定数据  :math:`\left\{x_{1}, x_{2}, \ldots, x_{n}\right\}` , 最大似然估计的目标是：

.. math::

    \hat{\mu}, \hat{\sigma}^{2}=\arg \max _{\mu, \sigma^{2}} \prod_{i=1}^{n} \frac{1}{\sqrt{2 \pi \sigma^{2}}} e^{-\frac{\left(x_{i}-\mu\right)^{2}}{2 \sigma^{2}}}


通过对数变换和推导, 可以得到:

.. math::

    \hat{\mu}=\frac{1}{n} \sum_{i=1}^{n} x_{i} \\
    \hat{\sigma}^{2}=\frac{1}{n} \sum_{i=1}^{n}\left(x_{i}-\hat{\mu}\right)^{2}

    即均值和方差的样本估计


优缺点
======

优点::

    直观简单：直接利用数据的概率模型，理论上明确。
    统计效率高：在许多情形下，最大似然估计具有良好的统计性质，例如一致性和渐近正态性。
    广泛适用：适用于各种分布模型。

局限性::

    模型假设敏感：如果模型假设（如分布）不准确，估计结果会失效。
    计算复杂：对于复杂模型，最大似然估计可能需要复杂的优化算法。
    可能过拟合：特别是当数据量少且参数较多时，容易导致过拟合。






































