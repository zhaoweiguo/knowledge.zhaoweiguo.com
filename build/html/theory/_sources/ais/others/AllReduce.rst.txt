AllReduce
#########

* keyword: AllReduce, All-Reduce

.. note:: AllReduce = 多节点数据归约 + 全部同步，保证所有节点看到相同的全局结果。


* allreduce 是 分布式计算 中非常核心的一个通信操作，尤其在 分布式机器学习 和 并行计算 场景（如 PyTorch 的分布式训练、MPI 等）被广泛使用。

* AllReduce = All + Reduce
    - Reduce：对多台机器/多个进程的张量数据，进行某种归约操作（如求和、求最大值、平均等）。
    - All：归约后，将结果同步广播到所有参与计算的进程/节点，每个进程都拿到相同的结果。



常见 Reduce 操作::

    sum
    mean
    max
    min



* 一种常见的并行计算中的通信操作，通常用于分布式深度学习训练中，尤其是在多个 GPU 之间共享数据时。
* 它的作用是将所有参与计算的设备（如多个 GPU）的数据进行 合并（reduce），并将最终的结果 广播（broadcast） 到所有设备。
* 具体步骤
    * Reduce（合并）：每个设备（如每个 GPU）都有一份数据，它们会将数据合并（通常是按元素求和、平均或其他操作）到一个共同的结果。
    * Broadcast（广播）：将合并后的结果传递给所有设备，这样每个设备都可以得到相同的数据副本。
* 举个例子
    * 假设我们有 3 个 GPU，每个 GPU 上有一个向量：
    * GPU 1 的数据是 𝐴=[1,2]
    * GPU 2 的数据是 𝐵=[3,4]
    * GPU 3 的数据是 𝐶=[5,6]
    * 然后，这个结果会被广播回所有的设备，即 GPU 1、GPU 2 和 GPU 3 都会获得 [9,12] 这个数据。
* 为什么使用 all-reduce
    * 在分布式训练中，尤其是多 GPU 训练时，每个 GPU 都会计算自己的一部分梯度。在更新模型时，所有 GPU 需要共享这些梯度信息，以确保每个 GPU 都有相同的模型参数。
* 应用场景
    * 梯度合并：在分布式训练中，每个 GPU 计算自己的梯度，然后通过 all-reduce 将梯度合并，并广播回所有 GPU，确保每个 GPU 拥有相同的梯度信息，从而进行统一的参数更新。
    * 模型同步：在多个设备上训练时，每个设备都有自己的一份模型，all-reduce 可以用来同步这些模型的权重，使得每个设备的模型在每轮训练结束时都能保持一致。
* 性能优化
    * 通信延迟：all-reduce 操作涉及多个设备间的通信，因此可能带来通信开销。为了优化性能，通常会采用一些技巧，比如分层通信、环形通信等方式减少延迟。
    * 数据切分与计算并行化：结合像 model parallelism 和 data parallelism 这样的策略，可以将 all-reduce 操作与并行计算结合，使得训练过程更加高效。





优势
====

* 同步性强：所有进程最终拿到相同数据。
* 效率高：底层通常采用优化过的通信算法（如树状规约、环形规约），减少带宽和延迟。
* 易用：高层框架封装好，用户只需调用。




典型应用
========

分布式深度学习模型参数同步::

    场景：每个 GPU/节点在训练自己的数据批次，得到梯度。
    使用 AllReduce：将所有节点的梯度进行求和或平均，保证模型参数更新一致。
    框架中支持：
    PyTorch → torch.distributed.all_reduce






















