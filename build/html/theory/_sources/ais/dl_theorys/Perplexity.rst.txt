.. _Perplexity:

Perplexity(PPL)困惑度
#####################

* 困惑度是衡量语言模型质量的一种指标，反映模型预测序列中下一个词的确定性或不确定性。简言之，它表示模型在生成下一个词时的“迷惑程度”，困惑度越低，模型的预测越好，越接近真实分布。
    * 高困惑度：模型预测模糊，对下一个词有很多不确定性。
    * 低困惑度：模型预测清晰，接近真实分布。

* 困惑度（Perplexity, PPL） 是衡量语言模型性能的重要指标之一，特别常用于评估语言模型（如 GPT、LSTM）的好坏。它反映了模型对测试数据的预测准确性，数值越小，模型的性能越好。

定义
====

生成式语言模型困惑度
--------------------

* 困惑度的定义来源于信息理论, 它表示模型对测试数据的"不确定性"。对于一个给定的语言模型  P  和一段测试文本  T , 困惑度的公式为:

.. math::

    P P L=2^{-\frac{1}{N} \sum_{i=1}^{N} \log _{2} P\left(w_{i} \mid w_{1}, w_{2}, \ldots, w_{i-1}\right)}


- 其中:
    -  N  ：测试文本中的单词总数。
    -  :math:`w_{i}`  ：第  i  个单词。
    -  :math:`P\left(w_{i} \mid w_{1}, w_{2}, \ldots, w_{i-1}\right)`  ：模型对第  i  个单词的条件概率。

更通用的公式：使用自然对数时, 公式可以写为:

.. math::

    P P L=e^{-\frac{1}{N} \sum_{i=1}^{N} \ln P\left(w_{i} \mid w_{1}, w_{2}, \ldots, w_{i-1}\right)}


直观理解
========

* 意义：
    * 困惑度可以看作是模型对单词序列的平均分支选择数。如果困惑度为 10，意味着模型在预测每个单词时，平均有 10 种选择的“困惑”。
    * 困惑度越小，模型对文本的预测越准确，表示模型对语言的理解能力更强。
* 完美模型的困惑度：
    * 如果模型能够完美预测每个单词的概率 ``𝑃(𝑤𝑖∣𝑤1,…,𝑤𝑖−1)=1`` ，那么困惑度为 1。
    * 如果模型完全随机分配概率，那么困惑度接近词典大小。



计算示例
========

* 假设一个语言模型预测了如下单词序列, 并给出相应概率:
    - 文本：I love NLP
    - 模型给出的条件概率:
        -  :math:`P(\mathrm{I})=0.5`
        -  :math:`P(  love  \mid \mathrm{I})=0.2`
        -  :math:`P(\mathrm{NLP} \mid \mathrm{I}  love  )=0.1`

* 困惑度计算:

.. math::

    P P L=e^{-\frac{1}{3}(\ln (0.5)+\ln (0.2)+\ln (0.1))}=e^{-\frac{1}{3}(-0.693-1.609-2.303)}=e^{1.535} \approx 4.64


注意事项
========

困惑度的局限性::

    与真实质量的差异:
        低困惑度的模型可能生成质量差的文本，因为困惑度只衡量预测概率，而不直接衡量生成内容的连贯性或可读性
    不适用于非概率模型:
        困惑度依赖于概率分布，对于非概率模型（如某些规则系统）无法使用

与训练数据相关::

    如果测试数据与训练数据非常相似，困惑度可能会较低，但这并不表示模型对真实世界的广泛数据有较强的泛化能力。

依赖词表大小::

    困惑度对词汇表大小敏感。大词汇表通常会增加困惑度，模型需要更好地分配概率来降低困惑。


总结
====

* 困惑度是交叉熵的指数形式，反映模型对下一个词预测的平均不确定性。
* 公式： :math:`Perplexity=exp(CrossEntropyLoss)`
* 低困惑度表示模型性能更好，对序列的预测更加准确。
* 优点：易解释、适合性能评估和优化反馈。
* 不足：不能单独衡量语言流畅性或语法质量。

























