

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="zh-CN" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="zh-CN" > <!--<![endif]-->
<head>


<!-- start added 2025-04-14   增加对markdown中公式的支持 -->
<script>
window.MathJax = {
    tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true
    },
    options: {
        ignoreHtmlClass: "tex2jax_ignore|mathjax_ignore",
        processHtmlClass: "tex2jax_process|mathjax_process|math|output_area"
    }
};
</script>
<script defer="defer" src="https://fastly.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<!-- end added 2025-04-14   增加对markdown中公式的支持 -->


  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>LLM &mdash; 新溪-gordon V2025.05 文档</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="搜索" href="../../search.html" />
    <link rel="next" title="Kullback-Leibler 散度" href="KL%E6%95%A3%E5%BA%A6.html" />
    <link rel="prev" title="BPE" href="BPE.html" /> 

  
  <script src="../../_static/js/modernizr.min.js"></script>
  <script src="../../_static/js/jquery.min.js"></script>


<!-- 评论插件 gittalk start -->
<!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script> -->
<!-- 评论插件 gittalk end -->


</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> 新溪-gordon
          

          
          </a>

          
            
            
              <div class="version">
                V2025.05
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">理论</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../normal.html">常用</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../normals/normal.html">常用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../normals/iceberg_theory.html">冰山理论</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../normals/Six_Degrees.html">Six Degrees of Kevin Bacon</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../normals/Forgetting_Curve.html">Forgetting Curve-遗忘曲线</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../%E5%88%9B%E6%96%B0%E6%80%9D%E7%BB%B4.html">创新思维</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../inovative_thinkings/TRIZ.html">TRIZ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../inovative_thinkings/design_thinking.html">设计思维</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../inovative_thinkings/%E5%A4%B4%E8%84%91%E9%A3%8E%E6%9A%B4.html">头脑风暴</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../../ai.html">关键定义</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../Parallelism/normal.html">通用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Parallelism/PipelineParallelism.html">Pipeline Parallelism</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Parallelism/TensorParallesim.html">Tensor Parallesim</a></li>
<li class="toctree-l2"><a class="reference internal" href="../func_activations/activation_Sigmoid.html">激活函数-Sigmoid</a></li>
<li class="toctree-l2"><a class="reference internal" href="../func_activations/activation_RELU.html">激活函数-ReLU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../func_activations/activation_Leaky-ReLU.html">激活函数-Leaky ReLU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../func_activations/activation_Tanh.html">激活函数-Tanh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../func_activations/activation_GELU.html">激活函数-GELU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../func_activations/normalization_L1.html">归一化-L1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../func_activations/normalization_L2.html">归一化-L2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../func_activations/probabilistic_Softmax.html">概率分布-Softmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="../func_activations/probabilistic_logSoftmax.html">概率分布-logsoftmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="../func_activations/probabilistic_Sparsemax.html">概率分布-Sparsemax</a></li>
<li class="toctree-l2"><a class="reference internal" href="../func_loss/classify_cross_entropy.html">损失函数-分类-cross-entropy(交叉熵)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../func_loss/classify_NLL.html">损失函数-分类-负对数似然损失NLL Loss</a></li>
<li class="toctree-l2"><a class="reference internal" href="../func_loss/classify_log.html">损失函数-分类-对数损失(Log Loss)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../func_loss/classify_kl.html">损失函数-分类-KL 散度(KL Loss)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../func_loss/regression_MSE.html">损失函数-回归-均方误差(MSE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../func_loss/regression_MAE.html">损失函数-回归-平均绝对误差(MAE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../func_loss/regression_Huber.html">损失函数-回归-Huber 损失</a></li>
<li class="toctree-l2"><a class="reference internal" href="../func_loss/regression_log_cosh.html">损失函数-回归-对数余弦损失(Log-Cosh Loss)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../func_loss/%E6%9D%83%E9%87%8D%E8%A1%B0%E5%87%8F-L2%E6%AD%A3%E5%88%99%E5%8C%96.html">权重衰减(L2正则化)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../func_optims/GD.html">GD(梯度下降)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../func_optims/SGD.html">SGD随机梯度下降</a></li>
<li class="toctree-l2"><a class="reference internal" href="../func_optims/RMSprop.html">RMSprop</a></li>
<li class="toctree-l2"><a class="reference internal" href="../func_optims/Adam.html">Adam</a></li>
<li class="toctree-l2"><a class="reference internal" href="../func_optims/AdamW.html">AdamW</a></li>
<li class="toctree-l2"><a class="reference internal" href="../func_optims/Momentum.html">Momentum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ners/HMM-%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B.html">HMM-隐马尔可夫模型</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ners/WWM-%E5%85%A8%E8%AF%8DMask.html">WWM-Whole Word Masking</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ners/CRF-%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA.html">CRF-条件随机场</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dls/ANN.html">ANN(NN)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dls/DNN-%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html">深度神经网络(Deep Neural Network, DNN)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dls/CNN-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html">卷积神经网络(Convolutional Neural Network, CNN)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dls/RNN-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91.html">RNN: 循环神经网(Recurrent Neural Network, RNN)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dls/LSTM-%E9%95%BF%E7%9F%AD%E6%97%B6%E8%AE%B0%E5%BF%86.html">LSTM: 长短时记忆(Long Short Term Memory, LSTM)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dl_theorys/propagation.html">前向/反向传播</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dl_theorys/LinearLayer.html">Linear Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dl_theorys/FFN.html">Feedforward Network-前馈网络</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dl_theorys/LayerNorm.html">LayerNorm(层归一化)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dl_theorys/WeightTying.html">Weight Tying</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dl_theorys/GreedyDecoding.html">Greedy Decoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dl_theorys/ImageGrounding.html">Image Grounding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dl_theorys/Perplexity.html">Perplexity(PPL)困惑度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../3Ds/ManhattanWorld%E6%9B%BC%E5%93%88%E9%A1%BF%E4%B8%96%E7%95%8C.html">Manhattan World(曼哈顿世界)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../3Ds/HoughTransform%E9%9C%8D%E5%A4%AB%E5%8F%98%E6%8D%A2.html">Hough Transform（霍夫变换）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../3Ds/PolarCoordinateSystem%E6%9E%81%E5%9D%90%E6%A0%87%E8%A1%A8%E7%A4%BA%E6%B3%95.html">极坐标表示法(Polar Coordinate System)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../3Ds/GaussianSphere%E9%AB%98%E6%96%AF%E7%90%83.html">Gaussian Sphere（高斯球）</a></li>
<li class="toctree-l2"><a class="reference internal" href="../3Ds/edge_direction%E8%BE%B9%E7%BC%98%E6%96%B9%E5%90%91.html">边缘方向 Edge Direction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../3Ds/NormalVector%E6%B3%95%E5%90%91%E9%87%8F.html">NormalVector法向量</a></li>
<li class="toctree-l2"><a class="reference internal" href="%E5%88%A4%E5%88%AB%E5%BC%8F%E6%A8%A1%E5%9E%8Bvs%E7%94%9F%E6%88%90%E5%BC%8F%E6%A8%A1%E5%9E%8B.html">判别式模型vs生成式模型</a></li>
<li class="toctree-l2"><a class="reference internal" href="AllReduce.html">AllReduce</a></li>
<li class="toctree-l2"><a class="reference internal" href="Embedding%E6%A8%A1%E5%9E%8B.html">Embedding 模型</a></li>
<li class="toctree-l2"><a class="reference internal" href="BPE.html">BPE</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">LLM</a></li>
<li class="toctree-l2"><a class="reference internal" href="KL%E6%95%A3%E5%BA%A6.html">Kullback-Leibler 散度</a></li>
<li class="toctree-l2"><a class="reference internal" href="deeplearning.html">深度学习相关</a></li>
<li class="toctree-l2"><a class="reference internal" href="%E7%9F%A2%E9%87%8F%E5%8C%96%E8%AE%A1%E7%AE%97.html">矢量化计算(Vectorize calculations)</a></li>
<li class="toctree-l2"><a class="reference internal" href="other.html">其他</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../math.html">数学方法</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E5%9F%BA%E6%9C%AC-%E6%96%B9%E5%B7%AE_%E6%A0%87%E5%87%86%E5%B7%AE.html">方差/标准差</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E5%9F%BA%E6%9C%AC-%E5%AF%B9%E6%95%B0.html">基本-对数(logarithmic)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E5%9F%BA%E6%9C%AC-%E5%AF%BC%E6%95%B0.html">基本-导数</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E5%9F%BA%E6%9C%AC-%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95.html">基本-矩阵乘法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E5%88%86%E5%B8%83-%E5%9D%87%E5%8C%80%E5%88%86%E5%B8%83.html">分布-均匀分布(Uniform Distribution)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E5%88%86%E5%B8%83-%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83.html">分布-正态分布(Normal Distribution)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E5%88%86%E5%B8%83-%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83.html">分布-高斯分布(Gaussian Distribution)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E5%88%86%E5%B8%83-%E4%BC%AF%E5%8A%AA%E5%88%A9%E5%88%86%E5%B8%83.html">分布-伯努利分布(Bernoulli Distribution)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E5%88%86%E5%B8%83-%E5%87%A0%E4%BD%95%E5%88%86%E5%B8%83.html">分布-几何分布(Geometric Distribution)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E5%88%86%E5%B8%83-%E6%B3%8A%E6%9D%BE%E5%88%86%E5%B8%83.html">分布-泊松分布(Poisson Distribution)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E5%88%86%E5%B8%83-%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83.html">分布-二项分布</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E5%87%BD%E6%95%B0.html">概率密度函数(Probability Density Function, PDF)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E6%A6%82%E7%8E%87%E8%B4%A8%E9%87%8F%E5%87%BD%E6%95%B0.html">概率质量函数(Probability Mass Function, PMF)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E8%8C%83%E6%95%B0-%E6%9B%BC%E5%93%88%E9%A1%BF%E8%B7%9D%E7%A6%BB.html">L1 范数(曼哈顿距离)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E8%8C%83%E6%95%B0-%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E8%8C%83%E6%95%B0.html">L2 范数(欧几里得范数)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E8%8C%83%E6%95%B0-%E6%9C%80%E5%A4%A7%E8%8C%83%E6%95%B0.html">L∞ 范数(最大范数)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E8%8C%83%E6%95%B0-Frobenius%E8%8C%83%E6%95%B0.html">范数-Frobenius范数</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E7%BB%9F%E8%AE%A1-%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E5%8E%9F%E7%90%86_MLP.html">统计-最大似然原理(Maximum Likelihood Principle)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E7%BB%9F%E8%AE%A1-%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1_MLE.html">MLE-最大似然估计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E7%BB%9F%E8%AE%A1-%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0.html">统计-似然函数(Likelihood)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E7%BB%9F%E8%AE%A1-%E8%BE%9B%E6%99%AE%E6%A3%AE%E6%B3%95%E5%88%99.html">统计-辛普森法则(Simpson’s Paradox)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E7%BB%9F%E8%AE%A1-%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86_CLT.html">统计-中心极限定理(Central Limit Theorem, CLT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E4%BA%8C%E5%85%AB%E5%AE%9A%E5%BE%8B.html">二八定律</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E5%90%88%E7%90%86%E8%BF%90%E7%94%A8%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97.html">合理运用时间序列</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E5%A4%9A%E5%9B%A0%E7%B4%A0%E5%88%86%E6%9E%90%E9%97%AE%E9%A2%98.html">多因素分析问题</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E8%BF%B9%E5%87%BD%E6%95%B0.html">迹函数(trace function)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E7%89%B9%E5%BE%81%E5%80%BC.html">特征值(Eigenvalue)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E8%A1%8C%E5%88%97%E5%BC%8F.html">行列式(determinant)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E8%BD%AC%E7%BD%AE%E7%9F%A9%E9%98%B5.html">矩阵-转置矩阵</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E8%A7%A3%E6%9E%90%E8%A7%A3.html">解析解(Analytic Solution)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E5%87%BD%E6%95%B0-%E4%BB%BF%E5%B0%84%E5%87%BD%E6%95%B0.html">函数-仿射函数(affine functions)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../maths/%E5%87%BD%E6%95%B0-%E7%BA%BF%E6%80%A7%E5%87%BD%E6%95%B0.html">函数-线性函数(Linear Function)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../analysis.html">分析方法</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../analysis/%E8%BE%A9%E8%AF%81%E6%B3%95.html">辩证法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../analysis/%E5%BD%92%E7%BA%B3%E6%B3%95.html">归纳法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../analysis/%E6%BC%94%E7%BB%8E%E6%B3%95.html">演绎法</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../secure.html">安全</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../secures/KMS.html">KMS-密钥管理服务(Key Management Service)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../secures/%E5%9F%BA%E7%BA%BF%E7%AE%A1%E7%90%86.html">基线管理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../secures/%E8%BF%9C%E7%A8%8B%E8%AF%81%E6%98%8E.html">远程证明</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../theorem.html">定理-原理</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../theorems/law.html">Law定理/定律</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/laws/Murphys_Law.html">墨菲定律(Murphy’s Law)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/laws/Parkinsons_Law.html">帕金森定律(Parkinson’s Law)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/laws/Peter_Principle.html">彼得原理(peterPrinciple)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/laws/Conways_Law.html">康威定律(Conway’s Law)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/laws/Dunbars_Number.html">Dunbar Number</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/laws/Benfords_Law.html">Benford’s law</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/laws/Zipfs_Law.html">Zipf’s law</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/laws/Clarkes_3Laws.html">Clarke’s three laws</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/laws/Occams_Razor.html">奥卡姆剃刀原则</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/laws/Law_of_Thermodynamics2.html">second law of thermodynamics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/laws/Law_of_Diminishing_Marginal_Utility.html">The Law Of Diminishing Marginal Utility</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/laws/X-Y_PROBLEM.html">X-Y PROBLEM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/laws/Amdahls_Law.html">Amdahl’s Law</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/laws/Scaling_Law.html">scaling law</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/laws/Scaling_Law.html#id2">一种本质性的思维方式</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/laws/Scaling_Law.html#id3">各领域的应用</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/laws/Power_Law.html">Power Law(幂律)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/laws/%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B.html">大数定律(law of large numbers)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../theorems/question.html">问问题的技巧</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/questions/%E6%B5%B7%E5%B0%94%E8%BF%88%E8%80%B6%E7%B3%BB%E5%88%97%E9%97%AE%E9%A2%98.html">海尔迈耶系列问题</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../theorems/rule.html">Rule原则/规则</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/rules/ruleofthree.html">三次法则</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/rules/Peak-End%20Rule.html">峰终定律-Peak-End Rule</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/rules/MECE.html">MECE</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/rules/SMART.html">SMART 原则</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../theorems/model.html">模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/models/%E6%B3%A2%E5%A3%AB%E9%A1%BF%E7%9F%A9%E9%98%B5%E6%A8%A1%E5%9E%8B.html">波士顿矩阵模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/models/%E8%89%BE%E6%A3%AE%E8%B1%AA%E5%A8%81%E5%B0%94%E7%9F%A9%E9%98%B5.html">艾森豪威尔矩阵</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/models/Wardley%20Map.html">Wardley Map</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/models/ARCI%E6%A8%A1%E5%9E%8B.html">ARCI模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/models/%E8%BE%9B%E6%99%AE%E6%A3%AE%E6%82%96%E8%AE%BA.html">辛普森悖论</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../theorems/models/WBS.html">工作分解结构Work Breakdown Structure</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../learning.html">学习相关</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../learnings/study.html">如何学习</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/studys/fast-learn-new-field.html">如何快速学习</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/studys/%E4%BB%A5%E6%95%99%E4%B8%BA%E5%AD%A6.html">以教为学</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/studys/ZTD%E5%AD%A6%E4%B9%A0%E6%B3%95.html">ZTD学习套路</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/studys/%E5%A6%82%E4%BD%95%E6%88%90%E4%B8%BA%E5%A4%A7%E7%89%9B.html">如何成为大师/大牛</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/studys/%E9%AB%98%E6%95%88%E5%AD%A6%E4%B9%A0.html">高效学习</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/studys/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E8%AE%BA%E5%AF%BC%E5%9B%BE.html">学习方法论导图</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/studys/%E5%85%AD%E6%AD%A5%E5%AD%A6%E4%B9%A0%E6%B3%95.html">六步学习法</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/studys/%E8%B4%B9%E6%9B%BC%E5%AD%A6%E4%B9%A0%E6%B3%95.html">费曼学习法</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/studys/%E5%A4%96%E8%AF%AD%E5%AD%A6%E4%B9%A0%E6%8A%80%E5%B7%A7.html">外语学习技巧</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/studys/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1.html">知识图谱</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/studys/%E5%A6%82%E4%BD%95%E8%AE%B0%E7%AC%94%E8%AE%B0.html">如何记笔记</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/studys/tmp.html">临时</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../learnings/source_code.html">源码学习</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/source_codes/learn-method.html">如何高效学习</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/source_codes/why-read-code.html">为何阅读源码</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/source_codes/how-to-read-code.html">如何阅读源码</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/source_codes/how-to-read-code2.html">如何阅读源码2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/source_codes/how-to-read-code3.html">如何阅读源码3</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/source_codes/efficient-read-code.html">如何高效阅读源码</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../learnings/lifelong-learning.html">终身学习方法论</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/lifelong-learnings/learning1.html">终身学习方法论1</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/lifelong-learnings/%E6%8E%A8%E6%BC%94-%E5%81%9A-%E5%A4%8D%E7%9B%98.html">推演-做-复盘</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/lifelong-learnings/%E5%A4%8D%E7%9B%98.html">复盘</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/lifelong-learnings/%E4%BA%BA%E7%94%9F%E7%9A%84%E4%B8%89%E4%B8%AA%E9%98%B6%E6%AE%B5.html">人生的三个阶段</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/lifelong-learnings/mental-model.html">思维模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/lifelong-learnings/question.html">关键问题</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../learnings/read.html">如何阅读</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/reads/%E5%A6%82%E4%BD%95%E9%98%85%E8%AF%BB.html">如何阅读</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/reads/%E5%A6%82%E4%BD%95%E8%AF%BB%E4%B8%80%E6%9C%AC%E9%9D%9E%E8%99%9A%E6%9E%84%E5%9B%BE%E4%B9%A6.html">如何读一本非虚构图书</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/reads/%E5%BF%AB%E9%80%9F%E9%98%85%E8%AF%BB.html">快速阅读</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../learnings/write.html">如何写作</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/writes/how-to-write.html">如何写作</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/writes/%E5%86%99%E4%BD%9C%E5%A6%82%E7%BC%96%E7%A0%81.html">写作如编码</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/writes/%E9%87%91%E5%AD%97%E5%A1%94%E5%8E%9F%E7%90%86%E8%AE%B2%E5%86%99%E4%BD%9C.html">金字塔原理讲写作</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/writes/%E5%A6%82%E4%BD%95%E6%94%B6%E9%9B%86%E7%B4%A0%E6%9D%90.html">如何收集素材</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/writes/%E7%A8%8B%E5%BA%8F%E5%91%98%E6%80%8E%E6%A0%B7%E5%86%99%E5%A5%BD%E6%96%87%E7%AB%A0.html">程序员怎样写好文章</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../learnings/speech.html">如何演讲</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/speechs/%E8%A1%A8%E8%BE%BE%E5%A5%97%E8%B7%AF.html">表达套路</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learnings/speechs/%E5%A6%82%E4%BD%95%E6%BC%94%E8%AE%B2.html">如何演讲</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../learnings/opensource.html">开源</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../economy.html">经济</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../psychics.html">心理学</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../startup.html">创业</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../other.html">其他</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">新溪-gordon</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../ai.html">关键定义</a> &raquo;</li>
        
      <li>LLM</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/ais/others/LLM.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            <nav id="local-table-of-contents" role="navigation" aria-labelledby="local-table-of-contents-title">
              <h4 id="local-table-of-contents-title">On This Page</h4>
              <ul>
<li><a class="reference internal" href="#">LLM</a><ul>
<li><a class="reference internal" href="#moe">MoE架构</a></li>
<li><a class="reference internal" href="#nli">NLI</a></li>
<li><a class="reference internal" href="#id2">生成文本验证</a><ul>
<li><a class="reference internal" href="#safe">SAFE</a></li>
<li><a class="reference internal" href="#factscore">FActScore</a></li>
<li><a class="reference internal" href="#id3">参考</a></li>
</ul>
</li>
<li><a class="reference internal" href="#alce">ALCE</a></li>
<li><a class="reference internal" href="#id4">训练方法</a><ul>
<li><a class="reference internal" href="#id5">预训练</a></li>
<li><a class="reference internal" href="#id6">微调</a></li>
<li><a class="reference internal" href="#id7">再次预训练</a></li>
<li><a class="reference internal" href="#id8">推理</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id9">其他</a><ul>
<li><a class="reference internal" href="#id10">消融实验</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
  <table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference external" href="/index.html">主页</a></p></td>
<td><p><a class="reference internal" href="../../genindex.html"><span class="std std-ref">索引</span></a></p></td>
<td><p><a class="reference internal" href="../../py-modindex.html"><span class="std std-ref">模块索引</span></a></p></td>
<td><p><a class="reference internal" href="../../search.html"><span class="std std-ref">搜索页面</span></a></p></td>
</tr>
</tbody>
</table>
<section id="llm">
<h1>LLM<a class="headerlink" href="#llm" title="此标题的永久链接">¶</a></h1>
<section id="moe">
<h2>MoE架构<a class="headerlink" href="#moe" title="此标题的永久链接">¶</a></h2>
<ul>
<li><p>混合专家(MoE)架构</p></li>
<li><p>混合专家(MoE)架构是一种神经网络设计，通过为每个输入动态激活称为“专家”的专用网络子集来提高效率和性能。门控网络决定激活哪些专家导致稀疏激活和减少计算成本。MoE架构由两个关键组件组成：门控网络和专家网络。</p></li>
<li><p>从本质上来说，MoE架构的功能就像一个高效的交通系统，根据实时情况和期望的目的地，将每辆车(或在这种情况下是数据)导向最佳路线。每个任务都被路由到最合适的专门处理该特定任务的专家或子模型。这种动态路由确保为每个任务使用最有能力的资源，从而提高模型的整体效率和有效性。</p></li>
<li><p>MoE架构利用了三种方法来提高模型的保真度:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>1. 通过多个专家完成任务，MoE通过为每个专家添加更多参数来增加模型的参数大小
2. MoE改变了经典的神经网络架构，它包含了一个门控网络，以确定哪些专家被用于指定的任务
3. 每个人工智能模型都有一定程度的微调，因此MoE中的每个专家都经过微调，以达到传统模型无法利用的额外调整层的预期效果
</pre></div>
</div>
</li>
</ul>
</section>
<section id="nli">
<h2>NLI<a class="headerlink" href="#nli" title="此标题的永久链接">¶</a></h2>
<ul>
<li><p>自然语言推理（Natural Language Inference，NLI）是自然语言处理（NLP）领域中的一个重要任务，旨在判断两个给定的文本（通常称为前提和假设）之间的逻辑关系。</p></li>
<li><p>LI任务涉及识别以下三种可能的关系:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>1.蕴含（Entailment）：假设从前提中可以推出。
  如果前提为真，那么假设也必须为真。
  例如：
    前提：所有的鸟都会飞。
    假设：麻雀会飞。
    关系：蕴含。
2.矛盾（Contradiction）：假设与前提相矛盾。
  如果前提为真，那么假设必定为假。
  例如：
    前提：所有的鸟都会飞。
    假设：企鹅不会飞。
    关系：矛盾。
3.中立（Neutral）：假设与前提之间没有直接的逻辑关系
  前提的真实性并不能影响假设的真实性。
  例如：
    前提：所有的鸟都会飞。
    假设：有些鸟是红色的。
    关系：中立。
</pre></div>
</div>
</li>
</ul>
<p>应用:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>信息检索：帮助搜索引擎理解用户查询与文档内容之间的逻辑关系。
问答系统：确保系统给出的答案与用户问题逻辑一致。
文本摘要：验证摘要内容是否能够从原文中推导出来。
对话系统：确保对话内容的一致性和逻辑性。
</pre></div>
</div>
<p>NLI数据集:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>SNLI（Stanford Natural Language Inference）：由斯坦福大学创建的用于训练和评估NLI模型的大型数据集。
MultiNLI（Multi-Genre Natural Language Inference）：包含多种领域的文本，旨在评估NLI模型在不同文本领域中的表现。
</pre></div>
</div>
</section>
<section id="id2">
<h2>生成文本验证<a class="headerlink" href="#id2" title="此标题的永久链接">¶</a></h2>
<section id="safe">
<h3>SAFE<a class="headerlink" href="#safe" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p>Search-Augmented Factuality Evaluator</p></li>
<li><p><a class="reference external" href="https://github.com/google-deepmind/long-form-factuality/tree/main/eval/safe">https://github.com/google-deepmind/long-form-factuality/tree/main/eval/safe</a></p></li>
<li><p>为解决「幻觉（Hallucination）」问题</p></li>
<li><p>与自然语言处理（NLP）领域的模型评估或校验相关的工具或方法，特别是在验证生成文本（如新闻、报告、摘要等）事实性</p></li>
<li><p>与 FActScore 相比，主要区别在于，对于每个自包含的原子事实，SAFE 使用语言模型作为代理，在多步骤过程中迭代发出 Google 搜索查询，并推断搜索结果是否支持该事实。在每个步骤中，代理都会根据要检查的给定事实以及先前获得的搜索结果生成搜索查询。经过多个步骤后，模型执行推理以确定搜索结果是否支持该事实。根据实验，SAFE方法比人类注释者效果更好，尽管便宜20倍：与人类的一致率为72%，当他们不同意时，比人类的胜率为76%。</p></li>
</ul>
<figure class="align-default" id="id12">
<img alt="https://img.zhaoweiguo.com/uPic/2024/08/7m6R5E.png" src="https://img.zhaoweiguo.com/uPic/2024/08/7m6R5E.png" />
<figcaption>
<p><span class="caption-text">Overview of SAFE for factuality evaluation of long-form LLM generation. (Image source: <a class="reference external" href="https://arxiv.org/abs/2403.18802">Wei et al. 2024</a> )</span><a class="headerlink" href="#id12" title="此图像的永久链接">¶</a></p>
</figcaption>
</figure>
</section>
<section id="factscore">
<h3>FActScore<a class="headerlink" href="#factscore" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p>为解决「幻觉（Hallucination）」问题</p></li>
<li><p>FActScore 是一种用于衡量生成文本中事实性的方法。它旨在评估自动生成的文本（如摘要、新闻或对话）在多大程度上与真实信息或事实保持一致。</p></li>
<li><p>原理：FActScore 主要通过衡量生成文本与事实性信息源之间的一致性来评估文本的真实性。这个信息源可以是结构化数据、知识图谱、或经过验证的文本（如维基百科文章）。</p></li>
<li><p>方法：FActScore 通过使用自然语言处理技术，如信息检索、文本匹配和相似度计算，来确定生成文本中的陈述是否与事实性信息源中的陈述相符。FActScore 的计算可能会涉及多个子任务，例如命名实体识别、关系抽取和文本相似度评估。</p></li>
</ul>
</section>
<section id="id3">
<h3>参考<a class="headerlink" href="#id3" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p>Extrinsic Hallucinations in LLMs: <a class="reference external" href="https://lilianweng.github.io/posts/2024-07-07-hallucination/">https://lilianweng.github.io/posts/2024-07-07-hallucination/</a></p></li>
</ul>
</section>
</section>
<section id="alce">
<h2>ALCE<a class="headerlink" href="#alce" title="此标题的永久链接">¶</a></h2>
<ul>
<li><p>Automatic LLM Citation Evaluation</p></li>
<li><p>一个用于评估大语言模型（LLM）生成的文本中引用质量的基准工具或框架</p></li>
<li><p>设计目标是通过自动化的方式来评估 LLM 生成的带有引用的文本，特别是关注引用的准确性、相关性和可验证性。</p></li>
<li><p>大语言模型生成的内容有时会出现虚构现象（即所谓的“幻觉”），这会导致生成的文本与事实不符，甚至在引用部分出现不可靠的信息。</p></li>
<li><p>因此，ALCE 的出现旨在解决以下几个关键问题：</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>提高生成内容的可信度：通过评估 LLM 引用的质量，ALCE 能够帮助改进模型，使其生成更具事实性和可验证性的文本</p></li>
<li><p>自动化评估：与依赖人类评估不同，ALCE 提供了一个自动化的基准，用于在不同的模型和方法之间进行可重复的比较。这有助于推动研究的标准化，并降低复现和比较不同方法的难度</p></li>
<li><p>与现有方法的区别：现有的方法往往依赖于商业搜索引擎和人工评估，而 ALCE 提供了一个独立的、可重复的自动评估基准。这使得研究人员可以在没有外部依赖的情况下，对 LLM 的引用生成能力进行系统化的评价</p></li>
</ol>
</div></blockquote>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>可以查看相关论文</p>
</div>
</section>
<section id="id4">
<h2>训练方法<a class="headerlink" href="#id4" title="此标题的永久链接">¶</a></h2>
<section id="id5">
<h3>预训练<a class="headerlink" href="#id5" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p>所有LLM都依赖于在互联网文本数据上进行大规模的自监督预训练。</p></li>
<li><p>仅解码器的LLM遵循因果语言建模目标，通过该目标，模型学习根据之前的token序列预测下一个token。</p></li>
<li><p>根据开源LLM分享的预训练细节，文本数据的来源包括CommonCrawl、C4、GitHub、Wikipedia、书籍和在线讨论，如Reddit或StackOverFlow。人们普遍认为，扩展预训练语料库的大小可以提高模型的性能，并与扩展模型大小密切相关，这种现象被称为缩放定律。现代的LLM在数千亿到数万亿token的语料库上进行预训练。</p></li>
</ul>
</section>
<section id="id6">
<h3>微调<a class="headerlink" href="#id6" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p>微调的目的是通过使用可用的监督来更新权重，使预训练的LLM适应下游任务，这些监督通常时比预训练使用的数据集小一个量级的数据集。</p></li>
<li><p>T5是最早将微调框架构建为文本到文本统一框架的之一，用自然语言指令描述每个任务。指令微调后来通过在几个任务上联合训练扩展了微调，每个都用自然语言指令进行描述。指令微调迅速流行起来，因为它能够大幅提高LLM的零样本性能，包括在unseen任务上，特别是在更大的模型规模上。</p></li>
<li><p>使用多任务监督微调(通常称为SFT)的标准指令微调仍然可以保证模型在安全、道德和无害的同时遵循人类意图，并可以通过从人类反馈中强化学习(RLHF)进一步改进。</p></li>
<li><p>RLHF指的是人类标注者对微调模型的输出进行排序，用于通过强化学习再次微调。最近的工作表明，人类反馈可以被LLM的反馈取代，这一过程称为从人工智能反馈中强化学习(RLAIF)。</p></li>
<li><p>直接偏好优化(DPO)绕过了像RLHF那样将奖励模型拟合人类偏好的需要，而是用交叉熵目标直接微调策略，实现了LLM与人类偏好的更有效对齐。</p></li>
</ul>
<p>在构建不同任务的指令微调数据集时，重点是质量而不是数量:Lima仅在1000个示例上微调Llama-65B，表现优于GPT-3，而Alpagasus通过将其指令微调数据集从52k清理到9k，对Alpaca进行了改进。</p>
</section>
<section id="id7">
<h3>再次预训练<a class="headerlink" href="#id7" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p>再预训练包括从预训练的LLM执行另一轮的预训练，通常比第一阶段的数据量更少。</p></li>
<li><p>这样的过程可能有助于快速适应新领域或在LLM中引出新属性。</p></li>
<li><p>例如，对Lemur进行再次预训练，以提高编码和推理能力，对Llama-2-long进行扩展上下文窗口。</p></li>
</ul>
</section>
<section id="id8">
<h3>推理<a class="headerlink" href="#id8" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p>存在几种使用LLM进行自回归解码的序列生成的替代方法，它们的区别在于输出的随机性和多样性程度。</p></li>
<li><p>在采样期间增加温度使输出更加多样化，而将其设置为0则会退回到贪婪解码，这在需要确定性输出的场景中可能需要。采样方法top-k和top-p限制了每个解码步骤要采样的token池。</p></li>
<li><p>注意力复杂度是关于输入长度的二次型，因此一些技术旨在提高推理速度，特别是在较长的序列长度时。</p></li>
<li><p>FlashAttention优化了GPU内存级之间的读写，加速了训练和推理。</p></li>
<li><p>FlashDecoding将注意力机制中的key-value(KV)缓存加载并行化，产生8倍的端到端加速。</p></li>
<li><p>推测解码使用一个额外的小型语言模型来近似来自LLM的下一个token分布，这在不损失性能的情况下加速了解码。</p></li>
<li><p>vLLM使用PagedAttention加速LLM推理和服务，</p></li>
<li><p>PagedAttention是一种优化注意力键和值的内存使用的算法。</p></li>
</ul>
</section>
</section>
<section id="id9">
<h2>其他<a class="headerlink" href="#id9" title="此标题的永久链接">¶</a></h2>
<section id="id10">
<h3>消融实验<a class="headerlink" href="#id10" title="此标题的永久链接">¶</a></h3>
<ul class="simple">
<li><p>ablation</p></li>
<li><p>在机器学习和人工智能领域，消融实验是一种通过逐步移除或禁用系统的某个组件，来研究该组件对整体系统性能或行为的影响的方法。</p></li>
</ul>
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference external" href="/index.html">主页</a></p></td>
<td><p><a class="reference internal" href="../../genindex.html"><span class="std std-ref">索引</span></a></p></td>
<td><p><a class="reference internal" href="../../py-modindex.html"><span class="std std-ref">模块索引</span></a></p></td>
<td><p><a class="reference internal" href="../../search.html"><span class="std std-ref">搜索页面</span></a></p></td>
</tr>
</tbody>
</table>
</section>
</section>
</section>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="KL%E6%95%A3%E5%BA%A6.html" class="btn btn-neutral float-right" title="Kullback-Leibler 散度" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="BPE.html" class="btn btn-neutral" title="BPE" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>
  
  <div id="gitalk-container"></div>
  <div role="contentinfo">
    <p>
        &copy; Copyright 2010-2025, 新溪-gordon.

    </p>
  </div>
  <div>备案号 <a href="http://www.beian.miit.gov.cn">京ICP备16018553号</a></div><div>Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a></div>. 


</footer>

<script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?042289284b8eb33866001347a3e0b129";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
</script>     
        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'V2025.05',
            LANGUAGE:'zh-CN',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../_static/documentation_options.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="../../_static/sphinx_highlight.js"></script>
      <script type="text/javascript" src="../../_static/clipboard.min.js"></script>
      <script type="text/javascript" src="../../_static/copybutton.js"></script>
      <script type="text/javascript" src="../../_static/translations.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>

  

  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });


      // var gitalk = new Gitalk({
      //         clientID: '565177626b5d46427009',
      //         clientSecret: 'b2a36e67e1d2a73e43667f46d571c2624f8e1026',
      //         repo: 'knowledge',
      //         owner: 'zhaoweiguo',
      //         admin: ['zhaoweiguo'],
      //         id: location.pathname,      // Ensure uniqueness and length less than 50
      //         distractionFreeMode: false  // Facebook-like distraction free mode
      //       })
      // gitalk.render('gitalk-container')

  </script>


<script type="text/javascript" src="../../_static/js/table-of-contents-sidebar.js"></script>
<!-- <script type="text/javascript" src="https://table-of-contents-sidebar.github.io/table-of-contents-sidebar-lib/table-of-contents-sidebar.js"></script> -->
<script type="text/javascript">
    window.onload = function(e){
        TableOfContents.init({
            basePath: "https://table-of-contents-sidebar.github.io/table-of-contents-sidebar-lib/",
            querySelector: "body" // or other css querySelector
        });
    }
</script> 

</body>
</html>